# LSTMæ¨¡å‹æ„å»ºç³»åˆ— - æ¶æ„ä¸å®ç°

## ğŸ“š ç³»åˆ—æ¦‚è¿°
æœ¬ç³»åˆ—æ–‡æ¡£æ¶µç›–LSTMæ¨¡å‹çš„å„ç§æ¶æ„ã€æ¨¡å‹å®šä¹‰ã€è¶…å‚æ•°é…ç½®å’Œå˜ä½“ã€‚

---

## ğŸ“– æ–‡æ¡£åˆ—è¡¨

1. [LSTMæ¨¡å‹æ¶æ„](#lstmæ¨¡å‹æ¶æ„)
2. [å•å±‚LSTM](#å•å±‚lstm)
3. [å¤šå±‚LSTM](#å¤šå±‚lstm)
4. [åŒå‘LSTM](#åŒå‘lstm)
5. [LSTMå˜ä½“](#lstmå˜ä½“)
6. [è¶…å‚æ•°é€‰æ‹©](#è¶…å‚æ•°é€‰æ‹©)

---

## LSTMæ¨¡å‹æ¶æ„

### å®Œæ•´LSTMæ¨¡å‹ç»“æ„

```
è¾“å…¥ (batch, seq_len, input_size)
    â†“
LSTMå±‚ (å¤šå±‚)
    â†“
Dropoutå±‚ (é˜²æ­¢è¿‡æ‹Ÿåˆ)
    â†“
å…¨è¿æ¥å±‚
    â†“
è¾“å‡º (batch, output_size)
```

### å‚æ•°è¯´æ˜

#### è¾“å…¥å‚æ•°
- `input_size`: ç‰¹å¾ç»´åº¦
- `hidden_size`: LSTMéšè—å•å…ƒæ•°
- `num_layers`: LSTMå±‚æ•°
- `dropout`: Dropoutæ¯”ä¾‹
- `output_size`: è¾“å‡ºç»´åº¦

#### æ¨¡å‹å‚æ•°

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ | å½±å“ |
|------|------|--------|------|
| **input_size** | è¾“å…¥ç‰¹å¾ç»´åº¦ | ç”±æ•°æ®å†³å®š | ä¸å¯æ”¹å˜ |
| **hidden_size** | éšè—å•å…ƒæ•° | 32-128 | æ¨¡å‹å®¹é‡ |
| **num_layers** | LSTMå±‚æ•° | 1-3 | æ¨¡å‹æ·±åº¦ |
| **dropout** | Dropoutæ¯”ä¾‹ | 0.1-0.3 | é˜²æ­¢è¿‡æ‹Ÿåˆ |
| **batch_first** | batchæ˜¯å¦åœ¨å‰ | True | æ•°æ®æ ¼å¼ |

---

## å•å±‚LSTM

### æ¨¡å‹å®šä¹‰

```python
import torch.nn as nn

class SingleLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):
        super().__init__()
        self.hidden_size = hidden_size

        # LSTMå±‚
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            batch_first=True
        )

        # Dropoutå±‚
        self.dropout = nn.Dropout(dropout)

        # å…¨è¿æ¥å±‚
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """
        è¾“å…¥: (batch, seq_len, input_size)
        è¾“å‡º: (batch, output_size)
        """
        # å‰å‘ä¼ æ’­
        lstm_out, _ = self.lstm(x)

        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_output = lstm_out[:, -1, :]

        # Dropout
        last_output = self.dropout(last_output)

        # å…¨è¿æ¥å±‚
        output = self.fc(last_output)

        return output
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ¨¡å‹
model = SingleLSTM(
    input_size=10,
    hidden_size=64,
    output_size=1,
    dropout=0.2
)

# è¾“å…¥æ•°æ®
x = torch.randn(32, 20, 10)  # (batch=32, seq_len=20, input_size=10)

# å‰å‘ä¼ æ’­
output = model(x)

print(output.shape)  # torch.Size([32, 1])
```

### é€‚ç”¨åœºæ™¯
- ç®€å•æ—¶åºé¢„æµ‹ä»»åŠ¡
- æ•°æ®é‡æœ‰é™
- å¿«é€ŸåŸå‹å¼€å‘

---

## å¤šå±‚LSTM

### æ¨¡å‹å®šä¹‰

```python
class MultiLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # å¤šå±‚LSTM
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )

        # Dropout
        self.dropout = nn.Dropout(dropout)

        # å…¨è¿æ¥å±‚
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """
        è¾“å…¥: (batch, seq_len, input_size)
        è¾“å‡º: (batch, output_size)
        """
        lstm_out, _ = self.lstm(x)
        last_output = lstm_out[:, -1, :]
        last_output = self.dropout(last_output)
        output = self.fc(last_output)
        return output
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ¨¡å‹
model = MultiLSTM(
    input_size=10,
    hidden_size=64,
    num_layers=3,
    dropout=0.2,
    output_size=1
)

# è¾“å…¥æ•°æ®
x = torch.randn(32, 20, 10)

# å‰å‘ä¼ æ’­
output = model(x)

print(output.shape)  # torch.Size([32, 1])
```

### å¤šå±‚LSTMçš„ç‰¹ç‚¹

**ä¼˜åŠ¿**:
- å¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›
- å­¦ä¹ æ›´å¤æ‚çš„ç‰¹å¾
- æå‡æ¨¡å‹æ€§èƒ½

**åŠ£åŠ¿**:
- å‚æ•°é‡å¢åŠ 
- è®­ç»ƒæ—¶é—´å¢åŠ 
- è¿‡æ‹Ÿåˆé£é™©å¢åŠ 

### é€‚ç”¨åœºæ™¯
- å¤æ‚æ—¶åºæ¨¡å¼
- æ•°æ®é‡å……è¶³
- éœ€è¦æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›

---

## åŒå‘LSTMï¼ˆBi-LSTMï¼‰

### æ¨¡å‹å®šä¹‰

```python
class BiLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # åŒå‘LSTM
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=True,  # åŒå‘
            dropout=dropout if num_layers > 1 else 0
        )

        # åŒå‘è¾“å‡ºç»´åº¦æ˜¯hidden_size * 2
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size * 2, output_size)

    def forward(self, x):
        """
        è¾“å…¥: (batch, seq_len, input_size)
        è¾“å‡º: (batch, output_size)
        """
        lstm_out, _ = self.lstm(x)
        last_output = lstm_out[:, -1, :]
        last_output = self.dropout(last_output)
        output = self.fc(last_output)
        return output
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ¨¡å‹
model = BiLSTM(
    input_size=10,
    hidden_size=64,
    num_layers=2,
    dropout=0.2,
    output_size=1
)

# è¾“å…¥æ•°æ®
x = torch.randn(32, 20, 10)

# å‰å‘ä¼ æ’­
output = model(x)

print(output.shape)  # torch.Size([32, 1])
```

### åŒå‘LSTMçš„ç‰¹ç‚¹

**ä¼˜åŠ¿**:
- åŒæ—¶åˆ©ç”¨è¿‡å»å’Œæœªæ¥ä¿¡æ¯
- é€‚åˆéœ€è¦ä¸Šä¸‹æ–‡çš„ä»»åŠ¡
- æ€§èƒ½é€šå¸¸æ›´å¥½

**åŠ£åŠ¿**:
- å‚æ•°é‡å¢åŠ ä¸€å€
- ä¸èƒ½ç”¨äºå®æ—¶é¢„æµ‹ï¼ˆéœ€è¦æœªæ¥æ•°æ®ï¼‰
- è®­ç»ƒæ—¶é—´å¢åŠ 

### é€‚ç”¨åœºæ™¯
- æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æ
- æœºå™¨ç¿»è¯‘
- éœ€è¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ä»»åŠ¡
- âŒ **ä¸æ¨è**: å®æ—¶è‚¡ç¥¨é¢„æµ‹

---

## LSTMå˜ä½“

### 1. å †å LSTMï¼ˆStacked LSTMï¼‰

#### å®šä¹‰
- å¤šå±‚LSTMå †å 
- æ¯å±‚å­¦ä¹ ä¸åŒå±‚æ¬¡çš„æŠ½è±¡

#### æ¶æ„
```
è¾“å…¥ â†’ LSTMå±‚1 â†’ LSTMå±‚2 â†’ ... â†’ LSTMå±‚N â†’ è¾“å‡º
```

#### å®ç°
```python
class StackedLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super().__init__()

        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )

        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        output = self.fc(lstm_out[:, -1, :])
        return output
```

### 2. ç¼–ç å™¨-è§£ç å™¨LSTM

#### å®šä¹‰
- ç¼–ç å™¨ï¼šå°†åºåˆ—ç¼–ç ä¸ºå›ºå®šé•¿åº¦å‘é‡
- è§£ç å™¨ï¼šä»å‘é‡ç”Ÿæˆè¾“å‡ºåºåˆ—

#### æ¶æ„
```
è¾“å…¥åºåˆ— â†’ ç¼–ç å™¨LSTM â†’ ä¸Šä¸‹æ–‡å‘é‡ â†’ è§£ç å™¨LSTM â†’ è¾“å‡ºåºåˆ—
```

#### å®ç°
```python
class EncoderDecoderLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super().__init__()

        # ç¼–ç å™¨
        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)

        # è§£ç å™¨
        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)

        # è¾“å‡ºå±‚
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # ç¼–ç 
        _, (h_n, c_n) = self.encoder(x)

        # è§£ç 
        decoder_input = h_n[-1].unsqueeze(1).repeat(1, x.size(1), 1)
        decoder_output, _ = self.decoder(decoder_input, (h_n, c_n))

        # è¾“å‡º
        output = self.fc(decoder_output)

        return output
```

### 3. æ³¨æ„åŠ›LSTMï¼ˆAttention LSTMï¼‰

#### å®šä¹‰
- æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶
- åŠ¨æ€å…³æ³¨é‡è¦æ—¶é—´æ­¥

#### å®ç°
```python
class AttentionLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super().__init__()

        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)

        # æ³¨æ„åŠ›å±‚
        self.attention = nn.Linear(hidden_size, 1)

        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # LSTMè¾“å‡º
        lstm_out, _ = self.lstm(x)

        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)

        # åŠ æƒæ±‚å’Œ
        context = torch.sum(attention_weights * lstm_out, dim=1)

        # è¾“å‡º
        output = self.fc(context)

        return output
```

---

## è¶…å‚æ•°é€‰æ‹©

### å…³é”®è¶…å‚æ•°

#### 1. hidden_sizeï¼ˆéšè—å•å…ƒæ•°ï¼‰

| ä»»åŠ¡è§„æ¨¡ | hidden_size | è¯´æ˜ |
|---------|-------------|------|
| **å°è§„æ¨¡** | 32-64 | ç®€å•ä»»åŠ¡ï¼Œæ•°æ®é‡å° |
| **ä¸­ç­‰è§„æ¨¡** | 64-128 | ä¸€èˆ¬ä»»åŠ¡ |
| **å¤§è§„æ¨¡** | 128-256 | å¤æ‚ä»»åŠ¡ï¼Œæ•°æ®é‡å¤§ |

**é€‰æ‹©åŸåˆ™**:
- ä»å°å¼€å§‹ï¼Œé€æ­¥å¢åŠ 
- ç›‘æ§è¿‡æ‹Ÿåˆ
- è€ƒè™‘è®¡ç®—èµ„æº

#### 2. num_layersï¼ˆLSTMå±‚æ•°ï¼‰

| æ¨¡å¼ | num_layers | è¯´æ˜ |
|------|-----------|------|
| **ç®€å•** | 1 | ç®€å•ä»»åŠ¡ |
| **ä¸­ç­‰** | 2-3 | ä¸€èˆ¬ä»»åŠ¡ |
| **å¤æ‚** | 3-5 | å¤æ‚ä»»åŠ¡ |

**é€‰æ‹©åŸåˆ™**:
- ä¸è¦è¿‡åº¦å †å 
- 2-3å±‚é€šå¸¸è¶³å¤Ÿ
- è¶…è¿‡5å±‚æ”¶ç›Šé€’å‡

#### 3. dropoutï¼ˆDropoutæ¯”ä¾‹ï¼‰

| åœºæ™¯ | dropout | è¯´æ˜ |
|------|---------|------|
| **æ— è¿‡æ‹Ÿåˆ** | 0.0-0.1 | è®­ç»ƒé›†è¡¨ç°å¥½ |
| **è½»å¾®è¿‡æ‹Ÿåˆ** | 0.1-0.3 | è½»å¾®è¿‡æ‹Ÿåˆ |
| **ä¸¥é‡è¿‡æ‹Ÿåˆ** | 0.3-0.5 | ä¸¥é‡è¿‡æ‹Ÿåˆ |

**é€‰æ‹©åŸåˆ™**:
- ä»0.1å¼€å§‹
- æ ¹æ®éªŒè¯é›†è°ƒæ•´
- ä¸è¦è¶…è¿‡0.5

#### 4. learning_rateï¼ˆå­¦ä¹ ç‡ï¼‰

| ä¼˜åŒ–å™¨ | learning_range | è¯´æ˜ |
|--------|---------------|------|
| **Adam** | 0.0001-0.001 | æ¨èé»˜è®¤å€¼ |
| **SGD** | 0.01-0.1 | éœ€è¦momentum |
| **RMSprop** | 0.001-0.01 | RNNä¸“ç”¨ |

**å­¦ä¹ ç‡è°ƒåº¦**:
```python
# åˆå§‹å­¦ä¹ ç‡
learning_rate = 0.001

# å­¦ä¹ ç‡è¡°å‡
scheduler = torch.optim.lr_scheduler.StepLR(
    optimizer,
    step_size=10,  # æ¯10ä¸ªepoch
    gamma=0.1      # å­¦ä¹ ç‡ä¹˜0.1
)

# ä½™å¼¦é€€ç«
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer,
    T_max=50  # æ€»epochæ•°
)
```

#### 5. batch_sizeï¼ˆæ‰¹å¤§å°ï¼‰

| ç¡¬ä»¶ | batch_size | è¯´æ˜ |
|------|-----------|------|
| **CPU** | 16-32 | å†…å­˜æœ‰é™ |
| **å•GPU** | 32-128 | GPUå†…å­˜ |
| **å¤šGPU** | 64-256 | å¹¶è¡Œè®¡ç®— |

**é€‰æ‹©åŸåˆ™**:
- 2çš„å¹‚æ¬¡æ–¹ï¼ˆ32, 64, 128ï¼‰
- æ ¹æ®GPUå†…å­˜è°ƒæ•´
- è¶Šå¤§è¶Šç¨³å®šï¼Œä½†è¶Šæ…¢

#### 6. seq_lenï¼ˆåºåˆ—é•¿åº¦ï¼‰

| é¢„æµ‹ç›®æ ‡ | seq_len | è¯´æ˜ |
|---------|---------|------|
| **çŸ­æœŸ** | 5-10 | æ—¥å†…äº¤æ˜“ |
| **ä¸­æœŸ** | 20-60 | å‡ å¤©åˆ°å‡ å‘¨ |
| **é•¿æœŸ** | 60-120 | å‡ ä¸ªæœˆ |

**é€‰æ‹©åŸåˆ™**:
- åŸºäºä¸šåŠ¡é€»è¾‘
- é€šè¿‡å®éªŒç¡®å®š
- è€ƒè™‘è®¡ç®—æˆæœ¬

### è¶…å‚æ•°æœç´¢

#### ç½‘æ ¼æœç´¢

```python
from itertools import product

# å‚æ•°ç½‘æ ¼
param_grid = {
    'hidden_size': [32, 64, 128],
    'num_layers': [1, 2, 3],
    'dropout': [0.1, 0.2, 0.3],
    'learning_rate': [0.0001, 0.001, 0.01],
    'batch_size': [16, 32, 64]
}

# ç”Ÿæˆæ‰€æœ‰ç»„åˆ
param_combinations = list(product(
    param_grid['hidden_size'],
    param_grid['num_layers'],
    param_grid['dropout'],
    param_grid['learning_rate'],
    param_grid['batch_size']
))
```

#### éšæœºæœç´¢

```python
import random

# éšæœºæœç´¢næ¬¡
n_trials = 20

for _ in range(n_trials):
    # éšæœºé€‰æ‹©å‚æ•°
    hidden_size = random.choice([32, 64, 128])
    num_layers = random.choice([1, 2, 3])
    dropout = random.uniform(0.1, 0.3)
    learning_rate = random.choice([0.0001, 0.001, 0.01])
    batch_size = random.choice([16, 32, 64])

    # è®­ç»ƒå’Œè¯„ä¼°
    # ...
```

#### è´å¶æ–¯ä¼˜åŒ–

```python
from skopt import gp_minimize

# å®šä¹‰æœç´¢ç©ºé—´
space = [
    (32, 256),           # hidden_size
    (1, 4),              # num_layers
    (0.1, 0.5),          # dropout
    (0.0001, 0.01, 'log'),  # learning_rate
    (16, 128)            # batch_size
]

# å®šä¹‰ç›®æ ‡å‡½æ•°
def objective(params):
    hidden_size, num_layers, dropout, learning_rate, batch_size = params

    # è®­ç»ƒæ¨¡å‹
    model = MultiLSTM(
        input_size=10,
        hidden_size=hidden_size,
        num_layers=int(num_layers),
        dropout=dropout,
        output_size=1
    )

    # è¿”å›éªŒè¯æŸå¤±
    return val_loss

# ä¼˜åŒ–
result = gp_minimize(objective, space, n_calls=50)
```

---

## æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LSTMæ¨¡å‹æ¶æ„
- âœ… å®Œæ•´LSTMç»“æ„
- âœ… å‚æ•°è¯´æ˜
- âœ… æ•°æ®æµ

### å•å±‚LSTM
- âœ… æ¨¡å‹å®šä¹‰
- âœ… ä½¿ç”¨ç¤ºä¾‹
- âœ… é€‚ç”¨åœºæ™¯

### å¤šå±‚LSTM
- âœ… æ¨¡å‹å®šä¹‰
- âœ… ä¼˜åŠ£åŠ¿åˆ†æ
- âœ… é€‚ç”¨åœºæ™¯

### åŒå‘LSTM
- âœ… æ¨¡å‹å®šä¹‰
- âœ… ä¼˜åŠ£åŠ¿åˆ†æ
- âœ… é€‚ç”¨åœºæ™¯

### LSTMå˜ä½“
- âœ… å †å LSTM
- âœ… ç¼–ç å™¨-è§£ç å™¨LSTM
- âœ… æ³¨æ„åŠ›LSTM

### è¶…å‚æ•°é€‰æ‹©
- âœ… å…³é”®è¶…å‚æ•°
- âœ… æ¨èå€¼
- âœ… è¶…å‚æ•°æœç´¢æ–¹æ³•

---

## ä¸‹ä¸€æ­¥

ç»§ç»­å­¦ä¹ : [æ—¶åºæ•°æ®å¤„ç†ç³»åˆ—](../04_æ—¶åºæ•°æ®å¤„ç†ç³»åˆ—/README.md)
