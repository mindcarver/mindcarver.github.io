---
layout: default
section: Week6
title: 02-æ»šåŠ¨é‡è®­ç»ƒå®ç°
---

# 02. æ»šåŠ¨é‡è®­ç»ƒå®ç° ğŸ—ï¸

> "çº¸ä¸Šå¾—æ¥ç»ˆè§‰æµ…ï¼Œç»çŸ¥æ­¤äº‹è¦èº¬è¡Œ" ~ å¤äººè¯šä¸æ¬ºæˆ‘

ä¸ŠèŠ‚è¯¾æˆ‘ä»¬è®²äº†æ»šåŠ¨é‡è®­ç»ƒçš„**åŸç†**ï¼Œè¿™èŠ‚è¯¾æˆ‘ä»¬è¦**åŠ¨æ‰‹å®ç°**å®ƒï¼ğŸ’ª

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

é¦–å…ˆï¼Œçœ‹çœ‹æˆ‘ä»¬çš„æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿé•¿ä»€ä¹ˆæ ·ï¼š

```python
# ç³»ç»Ÿæ¶æ„å›¾
"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿæ¶æ„                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    è°ƒåº¦å™¨ (Scheduler)         â”‚
    â”‚  - å®šæ—¶è§¦å‘é‡è®­ç»ƒ              â”‚
    â”‚  - ç®¡ç†é‡è®­ç»ƒé˜Ÿåˆ—              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    æ•°æ®ç®¡ç†å™¨ (DataManager)    â”‚
    â”‚  - prepare_training_data()     â”‚
    â”‚  - prepare_prediction_data()   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    æ¨¡å‹è®­ç»ƒå™¨ (ModelTrainer)   â”‚
    â”‚  - train()                    â”‚
    â”‚  - validate()                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    æ¨¡å‹ç®¡ç†å™¨ (ModelManager)   â”‚
    â”‚  - save_model()               â”‚
    â”‚  - load_model()               â”‚
    â”‚  - get_current_model()        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    é¢„æµ‹å¼•æ“ (Predictor)        â”‚
    â”‚  - load_latest_model()        â”‚
    â”‚  - predict()                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
```

---

## ğŸ“¦ æ•°æ®ç®¡ç†å™¨ (DataManager)

æ•°æ®ç®¡ç†å™¨è´Ÿè´£å‡†å¤‡è®­ç»ƒå’Œé¢„æµ‹æ‰€éœ€çš„æ•°æ®ã€‚

```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

class DataManager:
    """æ•°æ®ç®¡ç†å™¨ - ä½ çš„æ•°æ®ç®¡å®¶ ğŸ’"""
    
    def __init__(self, data_source, feature_cols, label_col):
        """
        åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        
        Args:
            data_source: æ•°æ®æº (å¯ä»¥æ˜¯æ•°æ®åº“ã€æ–‡ä»¶ç­‰)
            feature_cols: ç‰¹å¾åˆ—ååˆ—è¡¨
            label_col: æ ‡ç­¾åˆ—å
        """
        self.data_source = data_source
        self.feature_cols = feature_cols
        self.label_col = label_col
        self.cache = {}  # æ•°æ®ç¼“å­˜
        
    def prepare_training_data(self, end_date, window_size):
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            end_date: è®­ç»ƒæ•°æ®ç»“æŸæ—¥æœŸ
            window_size: è®­ç»ƒçª—å£å¤§å°ï¼ˆå¤©ï¼‰
            
        Returns:
            X_train, y_train: ç‰¹å¾å’Œæ ‡ç­¾
        """
        # è®¡ç®—è®­ç»ƒæ•°æ®çš„æ—¶é—´èŒƒå›´
        start_date = end_date - timedelta(days=window_size)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"train_{end_date}_{window_size}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # ä»æ•°æ®æºè·å–æ•°æ®
        print(f"ğŸ“¦ å‡†å¤‡è®­ç»ƒæ•°æ®: {start_date} ~ {end_date}")
        
        # è¿™é‡Œå‡è®¾data_sourceæ˜¯ä¸€ä¸ªDataFrame
        # å®é™…åº”ç”¨ä¸­å¯èƒ½ä»æ•°æ®åº“è¯»å–
        train_data = self.data_source.loc[
            (self.data_source.index >= start_date) &
            (self.data_source.index <= end_date)
        ].copy()
        
        # æå–ç‰¹å¾å’Œæ ‡ç­¾
        X_train = train_data[self.feature_cols]
        y_train = train_data[self.label_col]
        
        # æ•°æ®æ¸…æ´—
        X_train, y_train = self._clean_data(X_train, y_train)
        
        # ç¼“å­˜ç»“æœ
        result = (X_train, y_train)
        self.cache[cache_key] = result
        
        return result
    
    def prepare_prediction_data(self, start_date, end_date):
        """
        å‡†å¤‡é¢„æµ‹æ•°æ®
        
        Args:
            start_date: é¢„æµ‹æ•°æ®å¼€å§‹æ—¥æœŸ
            end_date: é¢„æµ‹æ•°æ®ç»“æŸæ—¥æœŸ
            
        Returns:
            X_pred: é¢„æµ‹ç‰¹å¾
        """
        print(f"ğŸ“¦ å‡†å¤‡é¢„æµ‹æ•°æ®: {start_date} ~ {end_date}")
        
        # è·å–é¢„æµ‹æœŸé—´çš„æ•°æ®
        pred_data = self.data_source.loc[
            (self.data_source.index >= start_date) &
            (self.data_source.index <= end_date)
        ].copy()
        
        X_pred = pred_data[self.feature_cols]
        
        return X_pred
    
    def _clean_data(self, X, y):
        """
        æ•°æ®æ¸…æ´—
        
        Args:
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
            
        Returns:
            æ¸…æ´—åçš„X, y
        """
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        mask = ~(X.isna().any(axis=1) | y.isna())
        X_clean = X[mask]
        y_clean = y[mask]
        
        # åˆ é™¤å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
        for col in X_clean.columns:
            Q1 = X_clean[col].quantile(0.25)
            Q3 = X_clean[col].quantile(0.75)
            IQR = Q3 - Q1
            
            # å®šä¹‰å¼‚å¸¸å€¼èŒƒå›´
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºè¾¹ç•Œå€¼
            X_clean[col] = X_clean[col].clip(lower_bound, upper_bound)
        
        print(f"  âœ… æ¸…æ´—å: {len(X_clean)} æ¡è®°å½• (åŸ {len(X)} æ¡)")
        
        return X_clean, y_clean
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
        print("ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç©º")
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ•°æ®ç®¡ç†å™¨
data_manager = DataManager(
    data_source=stock_data,  # å‡è®¾è¿™æ˜¯ä½ çš„æ•°æ®
    feature_cols=['factor1', 'factor2', 'factor3'],
    label_col='future_return'
)

# å‡†å¤‡è®­ç»ƒæ•°æ®
end_date = datetime(2024, 1, 1)
X_train, y_train = data_manager.prepare_training_data(
    end_date=end_date,
    window_size=365  # 1å¹´çš„æ•°æ®
)

print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: X={X_train.shape}, y={y_train.shape}")
```

---

## ğŸ“ æ¨¡å‹è®­ç»ƒå™¨ (ModelTrainer)

æ¨¡å‹è®­ç»ƒå™¨è´Ÿè´£è®­ç»ƒå’ŒéªŒè¯æ¨¡å‹ã€‚

```python
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error
import lightgbm as lgb

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨ - ä½ çš„ç§äººæ•™ç»ƒ ğŸ‘¨â€ğŸ«"""
    
    def __init__(self, model_params=None, validation_split=0.2):
        """
        åˆå§‹åŒ–æ¨¡å‹è®­ç»ƒå™¨
        
        Args:
            model_params: æ¨¡å‹å‚æ•°
            validation_split: éªŒè¯é›†æ¯”ä¾‹
        """
        self.model_params = model_params or {
            'objective': 'regression',
            'metric': 'rmse',
            'num_leaves': 31,
            'learning_rate': 0.05,
            'feature_fraction': 0.9,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'verbose': -1
        }
        self.validation_split = validation_split
        self.model = None
        
    def train(self, X, y, early_stopping_rounds=100):
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            X: è®­ç»ƒç‰¹å¾
            y: è®­ç»ƒæ ‡ç­¾
            early_stopping_rounds: æ—©åœè½®æ•°
            
        Returns:
            è®­ç»ƒå¥½çš„æ¨¡å‹
        """
        print("ğŸ“ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        # æ—¶åºäº¤å‰éªŒè¯åˆ†å‰²
        split_idx = int(len(X) * (1 - self.validation_split))
        
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        print(f"  è®­ç»ƒé›†: {X_train.shape}, éªŒè¯é›†: {X_val.shape}")
        
        # åˆ›å»ºLightGBMæ•°æ®é›†
        train_data = lgb.Dataset(X_train, label=y_train)
        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
        
        # è®­ç»ƒæ¨¡å‹
        self.model = lgb.train(
            params=self.model_params,
            train_set=train_data,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'valid'],
            num_boost_round=10000,
            early_stopping_rounds=early_stopping_rounds,
            verbose_eval=100
        )
        
        # è¯„ä¼°æ¨¡å‹
        y_pred_val = self.model.predict(X_val)
        rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))
        
        print(f"  âœ… è®­ç»ƒå®Œæˆ! éªŒè¯é›†RMSE: {rmse:.6f}")
        print(f"  ğŸ“Š æœ€ä½³è¿­ä»£æ¬¡æ•°: {self.model.best_iteration}")
        
        return self.model
    
    def validate(self, X, y, metrics=['rmse', 'mae', 'r2']):
        """
        éªŒè¯æ¨¡å‹
        
        Args:
            X: éªŒè¯ç‰¹å¾
            y: éªŒè¯æ ‡ç­¾
            metrics: è¯„ä¼°æŒ‡æ ‡åˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼")
        
        y_pred = self.model.predict(X)
        
        results = {}
        for metric in metrics:
            if metric == 'rmse':
                results[metric] = np.sqrt(mean_squared_error(y, y_pred))
            elif metric == 'mae':
                results[metric] = np.mean(np.abs(y - y_pred))
            elif metric == 'r2':
                from sklearn.metrics import r2_score
                results[metric] = r2_score(y, y_pred)
        
        print("ğŸ“Š éªŒè¯ç»“æœ:")
        for metric, value in results.items():
            print(f"  {metric.upper()}: {value:.6f}")
        
        return results
    
    def get_feature_importance(self, importance_type='gain'):
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        Args:
            importance_type: é‡è¦æ€§ç±»å‹ ('gain' æˆ– 'split')
            
        Returns:
            ç‰¹å¾é‡è¦æ€§DataFrame
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼")
        
        importance = self.model.feature_importance(importance_type=importance_type)
        
        df_importance = pd.DataFrame({
            'feature': self.model.feature_name(),
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        return df_importance
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ¨¡å‹è®­ç»ƒå™¨
trainer = ModelTrainer(
    model_params={
        'objective': 'regression',
        'metric': 'rmse',
        'learning_rate': 0.05,
        'num_leaves': 31,
        'verbose': -1
    },
    validation_split=0.2
)

# è®­ç»ƒæ¨¡å‹
model = trainer.train(X_train, y_train, early_stopping_rounds=100)

# æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§
importance_df = trainer.get_feature_importance()
print("\nğŸ“ˆ ç‰¹å¾é‡è¦æ€§:")
print(importance_df.head(10))
```

---

## ğŸ’¾ æ¨¡å‹ç®¡ç†å™¨ (ModelManager)

æ¨¡å‹ç®¡ç†å™¨è´Ÿè´£ä¿å­˜ã€åŠ è½½å’Œç®¡ç†æ¨¡å‹ã€‚

```python
import pickle
import os
import json
from datetime import datetime

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - ä½ çš„æ¨¡å‹ç®¡å®¶ ğŸ—„ï¸"""
    
    def __init__(self, model_dir='./models'):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
        
        Args:
            model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        self.model_dir = model_dir
        os.makedirs(model_dir, exist_ok=True)
        
    def save_model(self, model, model_name, metadata=None):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            model: è¦ä¿å­˜çš„æ¨¡å‹
            model_name: æ¨¡å‹åç§°
            metadata: å…ƒæ•°æ®å­—å…¸
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{model_name}_{timestamp}.pkl"
        filepath = os.path.join(self.model_dir, filename)
        
        # ä¿å­˜æ¨¡å‹
        with open(filepath, 'wb') as f:
            pickle.dump(model, f)
        
        # ä¿å­˜å…ƒæ•°æ®
        if metadata:
            metadata_filename = f"{model_name}_{timestamp}_metadata.json"
            metadata_filepath = os.path.join(self.model_dir, metadata_filename)
            
            metadata['saved_at'] = timestamp
            metadata['model_file'] = filename
            
            with open(metadata_filepath, 'w') as f:
                json.dump(metadata, f, indent=2)
        
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {filepath}")
        return filepath
    
    def load_model(self, model_file):
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            model_file: æ¨¡å‹æ–‡ä»¶åæˆ–è·¯å¾„
            
        Returns:
            åŠ è½½çš„æ¨¡å‹
        """
        if not os.path.isabs(model_file):
            filepath = os.path.join(self.model_dir, model_file)
        else:
            filepath = model_file
        
        with open(filepath, 'rb') as f:
            model = pickle.load(f)
        
        print(f"ğŸ“‚ æ¨¡å‹å·²åŠ è½½: {filepath}")
        return model
    
    def get_current_model(self, model_prefix):
        """
        è·å–æœ€æ–°çš„æ¨¡å‹
        
        Args:
            model_prefix: æ¨¡å‹å‰ç¼€å
            
        Returns:
            æœ€æ–°æ¨¡å‹å’Œå…ƒæ•°æ®
        """
        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ¨¡å‹æ–‡ä»¶
        model_files = [f for f in os.listdir(self.model_dir) 
                      if f.startswith(model_prefix) and f.endswith('.pkl')]
        
        if not model_files:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°å‰ç¼€ä¸º {model_prefix} çš„æ¨¡å‹")
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
        model_files.sort(reverse=True)
        latest_model_file = model_files[0]
        
        # åŠ è½½æ¨¡å‹
        model = self.load_model(latest_model_file)
        
        # åŠ è½½å…ƒæ•°æ®
        metadata_filename = latest_model_file.replace('.pkl', '_metadata.json')
        metadata_filepath = os.path.join(self.model_dir, metadata_filename)
        
        if os.path.exists(metadata_filepath):
            with open(metadata_filepath, 'r') as f:
                metadata = json.load(f)
        else:
            metadata = {}
        
        print(f"âœ… å·²åŠ è½½æœ€æ–°æ¨¡å‹: {latest_model_file}")
        return model, metadata
    
    def list_models(self, model_prefix=None):
        """
        åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
        
        Args:
            model_prefix: æ¨¡å‹å‰ç¼€ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ¨¡å‹åˆ—è¡¨
        """
        all_files = os.listdir(self.model_dir)
        
        if model_prefix:
            model_files = [f for f in all_files 
                          if f.startswith(model_prefix) and f.endswith('.pkl')]
        else:
            model_files = [f for f in all_files if f.endswith('.pkl')]
        
        model_files.sort(reverse=True)
        
        print(f"ğŸ“‹ æ¨¡å‹åˆ—è¡¨ ({len(model_files)} ä¸ª):")
        for i, model_file in enumerate(model_files, 1):
            print(f"  {i}. {model_file}")
        
        return model_files
    
    def delete_old_models(self, model_prefix, keep=5):
        """
        åˆ é™¤æ—§æ¨¡å‹ï¼Œåªä¿ç•™æœ€æ–°çš„å‡ ä¸ª
        
        Args:
            model_prefix: æ¨¡å‹å‰ç¼€
            keep: ä¿ç•™çš„æ¨¡å‹æ•°é‡
        """
        model_files = self.list_models(model_prefix)
        
        if len(model_files) <= keep:
            print(f"âœ… åªæœ‰ {len(model_files)} ä¸ªæ¨¡å‹ï¼Œæ— éœ€åˆ é™¤")
            return
        
        # åˆ é™¤æ—§çš„æ¨¡å‹
        for old_model in model_files[keep:]:
            filepath = os.path.join(self.model_dir, old_model)
            os.remove(filepath)
            
            # åŒæ—¶åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶
            metadata_file = old_model.replace('.pkl', '_metadata.json')
            metadata_filepath = os.path.join(self.model_dir, metadata_file)
            if os.path.exists(metadata_filepath):
                os.remove(metadata_filepath)
            
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤: {old_model}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œä¿ç•™äº†æœ€æ–°çš„ {keep} ä¸ªæ¨¡å‹")
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
model_manager = ModelManager(model_dir='./models')

# ä¿å­˜æ¨¡å‹
model_manager.save_model(
    model=model,
    model_name='lgb_model',
    metadata={
        'window_size': 365,
        'ic': 0.05,
        'rank_ic': 0.06,
        'notes': 'åŸºç¡€æ¨¡å‹'
    }
)

# åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
model_manager.list_models('lgb_model')

# è·å–æœ€æ–°æ¨¡å‹
latest_model, metadata = model_manager.get_current_model('lgb_model')

# æ¸…ç†æ—§æ¨¡å‹
model_manager.delete_old_models('lgb_model', keep=5)
```

---

## ğŸ”„ å®Œæ•´çš„æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿ

ç°åœ¨ï¼ŒæŠŠæ‰€æœ‰ç»„ä»¶ç»„åˆèµ·æ¥ï¼

```python
import schedule
import time
from datetime import datetime, timedelta

class RollingRetrainSystem:
    """æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿ - ä½ çš„è‡ªåŠ¨åŒ–åŠ©æ‰‹ ğŸ¤–"""
    
    def __init__(self, data_manager, model_trainer, model_manager, 
                 window_size=365, retrain_frequency='monthly'):
        """
        åˆå§‹åŒ–æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿ
        
        Args:
            data_manager: æ•°æ®ç®¡ç†å™¨
            model_trainer: æ¨¡å‹è®­ç»ƒå™¨
            model_manager: æ¨¡å‹ç®¡ç†å™¨
            window_size: è®­ç»ƒçª—å£å¤§å°ï¼ˆå¤©ï¼‰
            retrain_frequency: é‡è®­é¢‘ç‡ ('daily', 'weekly', 'monthly')
        """
        self.data_manager = data_manager
        self.model_trainer = model_trainer
        self.model_manager = model_manager
        self.window_size = window_size
        self.retrain_frequency = retrain_frequency
        
    def run_retrain(self, end_date=None):
        """
        æ‰§è¡Œä¸€æ¬¡é‡è®­ç»ƒ
        
        Args:
            end_date: è®­ç»ƒæ•°æ®ç»“æŸæ—¥æœŸï¼ˆé»˜è®¤ä¸ºä»Šå¤©ï¼‰
        """
        if end_date is None:
            end_date = datetime.now()
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹æ»šåŠ¨é‡è®­ç»ƒ - {end_date.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
        print("\n[æ­¥éª¤1/4] å‡†å¤‡è®­ç»ƒæ•°æ®...")
        X_train, y_train = self.data_manager.prepare_training_data(
            end_date=end_date,
            window_size=self.window_size
        )
        
        # 2. è®­ç»ƒæ¨¡å‹
        print("\n[æ­¥éª¤2/4] è®­ç»ƒæ¨¡å‹...")
        model = self.model_trainer.train(X_train, y_train)
        
        # 3. éªŒè¯æ¨¡å‹
        print("\n[æ­¥éª¤3/4] éªŒè¯æ¨¡å‹...")
        validation_results = self.model_trainer.validate(X_train, y_train)
        
        # 4. ä¿å­˜æ¨¡å‹
        print("\n[æ­¥éª¤4/4] ä¿å­˜æ¨¡å‹...")
        metadata = {
            'window_size': self.window_size,
            'end_date': end_date.strftime('%Y-%m-%d'),
            'validation_results': validation_results,
            'retrain_frequency': self.retrain_frequency
        }
        
        self.model_manager.save_model(
            model=model,
            model_name='rolling_model',
            metadata=metadata
        )
        
        print(f"\n{'='*60}")
        print(f"âœ… é‡è®­ç»ƒå®Œæˆï¼")
        print(f"{'='*60}\n")
    
    def run_prediction(self, start_date, end_date):
        """
        ä½¿ç”¨æœ€æ–°æ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            start_date: é¢„æµ‹å¼€å§‹æ—¥æœŸ
            end_date: é¢„æµ‹ç»“æŸæ—¥æœŸ
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        print(f"\nğŸ”® å¼€å§‹é¢„æµ‹: {start_date} ~ {end_date}")
        
        # 1. åŠ è½½æœ€æ–°æ¨¡å‹
        model, metadata = self.model_manager.get_current_model('rolling_model')
        
        # 2. å‡†å¤‡é¢„æµ‹æ•°æ®
        X_pred = self.data_manager.prepare_prediction_data(
            start_date=start_date,
            end_date=end_date
        )
        
        # 3. è¿›è¡Œé¢„æµ‹
        predictions = model.predict(X_pred)
        
        print(f"âœ… é¢„æµ‹å®Œæˆï¼å…± {len(predictions)} æ¡è®°å½•")
        
        return predictions
    
    def start_scheduler(self):
        """å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨"""
        print(f"ğŸ• å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨ - é¢‘ç‡: {self.retrain_frequency}")
        
        # æ ¹æ®é¢‘ç‡è®¾ç½®è°ƒåº¦
        if self.retrain_frequency == 'daily':
            schedule.every().day.at("02:00").do(self.run_retrain)
        elif self.retrain_frequency == 'weekly':
            schedule.every().monday.at("02:00").do(self.run_retrain)
        elif self.retrain_frequency == 'monthly':
            schedule.every().month.do(self.run_retrain)
        
        print("âœ… è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œæ­£åœ¨è¿è¡Œä¸­...")
        print("ğŸ’¡ æç¤º: æŒ‰ Ctrl+C åœæ­¢\n")
        
        # æŒç»­è¿è¡Œ
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        except KeyboardInterrupt:
            print("\n\nğŸ›‘ è°ƒåº¦å™¨å·²åœæ­¢")
    
    def run_backtest(self, start_date, end_date, step_days=30):
        """
        å›æµ‹æ»šåŠ¨é‡è®­ç»ƒç­–ç•¥
        
        Args:
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ
            step_days: æ»šåŠ¨æ­¥é•¿ï¼ˆå¤©ï¼‰
            
        Returns:
            å›æµ‹ç»“æœ
        """
        print(f"\nğŸ¬ å¼€å§‹å›æµ‹æ»šåŠ¨é‡è®­ç»ƒç­–ç•¥")
        print(f"   æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        print(f"   æ»šåŠ¨æ­¥é•¿: {step_days} å¤©\n")
        
        results = []
        current_date = start_date + timedelta(days=self.window_size)
        
        while current_date <= end_date:
            # é‡è®­ç»ƒ
            self.run_retrain(end_date=current_date)
            
            # é¢„æµ‹ä¸‹ä¸€æ®µæ—¶é—´
            pred_start = current_date
            pred_end = min(current_date + timedelta(days=step_days), end_date)
            
            if pred_start < pred_end:
                predictions = self.run_prediction(pred_start, pred_end)
                
                results.append({
                    'train_end': current_date,
                    'pred_start': pred_start,
                    'pred_end': pred_end,
                    'predictions': predictions
                })
            
            current_date = pred_end
        
        print(f"\nâœ… å›æµ‹å®Œæˆï¼å…± {len(results)} è½®")
        return results
```

### ä½¿ç”¨ç¤ºä¾‹

```python
# åˆ›å»ºæ‰€æœ‰ç»„ä»¶
data_manager = DataManager(data_source=stock_data, ...)
model_trainer = ModelTrainer(model_params=...)
model_manager = ModelManager(model_dir='./models')

# åˆ›å»ºæ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿ
rolling_system = RollingRetrainSystem(
    data_manager=data_manager,
    model_trainer=model_trainer,
    model_manager=model_manager,
    window_size=365,  # 1å¹´çª—å£
    retrain_frequency='monthly'  # æ¯æœˆé‡è®­
)

# æ–¹å¼1: æ‰‹åŠ¨è¿è¡Œä¸€æ¬¡
rolling_system.run_retrain(end_date=datetime(2024, 1, 1))

# æ–¹å¼2: è¿è¡Œé¢„æµ‹
predictions = rolling_system.run_prediction(
    start_date=datetime(2024, 1, 1),
    end_date=datetime(2024, 2, 1)
)

# æ–¹å¼3: å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨
# rolling_system.start_scheduler()

# æ–¹å¼4: å›æµ‹æ•´ä¸ªç­–ç•¥
backtest_results = rolling_system.run_backtest(
    start_date=datetime(2020, 1, 1),
    end_date=datetime(2024, 1, 1),
    step_days=30
)
```

---

## ğŸ¯ å®æˆ˜æŠ€å·§

### æŠ€å·§1: å¢é‡æ›´æ–°æ¨¡å‹

```python
class IncrementalTrainer:
    """å¢é‡è®­ç»ƒå™¨ - åªæ›´æ–°æœ€æ–°æ•°æ®"""
    
    def incremental_train(self, old_model, new_X, new_y, epochs=10):
        """
        å¢é‡æ›´æ–°æ¨¡å‹
        
        Args:
            old_model: æ—§æ¨¡å‹
            new_X: æ–°æ•°æ®ç‰¹å¾
            new_y: æ–°æ•°æ®æ ‡ç­¾
            epochs: å¢é‡è®­ç»ƒè½®æ•°
        """
        # è·å–æ—§æ¨¡å‹å‚æ•°
        old_trees = old_model.dump_model()['tree_info']
        
        # åœ¨æ–°æ•°æ®ä¸Šç»§ç»­è®­ç»ƒ
        new_model = lgb.train(
            params=self.model_params,
            train_set=lgb.Dataset(new_X, label=new_y),
            num_boost_round=epochs,
            init_model=old_model  # ä»æ—§æ¨¡å‹å¼€å§‹
        )
        
        return new_model
```

### æŠ€å·§2: å¤šæ¨¡å‹é›†æˆ

```python
class EnsembleRetrainer:
    """é›†æˆè®­ç»ƒå™¨ - è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶é›†æˆ"""
    
    def train_ensemble(self, X, y, n_models=5):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        models = []
        
        for i in range(n_models):
            # ä½¿ç”¨ä¸åŒçš„æ•°æ®å­é›†
            idx = np.random.choice(len(X), size=len(X), replace=True)
            X_sample, y_sample = X.iloc[idx], y.iloc[idx]
            
            # è®­ç»ƒæ¨¡å‹
            model = self.model_trainer.train(X_sample, y_sample)
            models.append(model)
        
        return models
    
    def predict_ensemble(self, models, X):
        """é›†æˆé¢„æµ‹"""
        predictions = [model.predict(X) for model in models]
        return np.mean(predictions, axis=0)
```

### æŠ€å·§3: æ€§èƒ½ç›‘æ§

```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨ - è¿½è¸ªæ¨¡å‹æ€§èƒ½"""
    
    def __init__(self):
        self.history = []
    
    def track_performance(self, date, metrics):
        """è®°å½•æ€§èƒ½"""
        self.history.append({
            'date': date,
            **metrics
        })
    
    def detect_degradation(self, window=3, threshold=0.1):
        """æ£€æµ‹æ€§èƒ½ä¸‹é™"""
        if len(self.history) < window:
            return False
        
        recent_metrics = self.history[-window:]
        avg_ic = np.mean([m['ic'] for m in recent_metrics])
        
        # å¦‚æœå¹³å‡ICä½äºé˜ˆå€¼ï¼Œè®¤ä¸ºæ€§èƒ½ä¸‹é™
        if avg_ic < threshold:
            return True
        
        return False
```

---

## ğŸ“ æ€»ç»“

**å®Œæ•´æµç¨‹**ï¼š

```
1ï¸âƒ£ åˆ›å»º DataManager (æ•°æ®ç®¡ç†å™¨)
   â†“
2ï¸âƒ£ åˆ›å»º ModelTrainer (æ¨¡å‹è®­ç»ƒå™¨)
   â†“
3ï¸âƒ£ åˆ›å»º ModelManager (æ¨¡å‹ç®¡ç†å™¨)
   â†“
4ï¸âƒ£ åˆ›å»º RollingRetrainSystem (æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿ)
   â†“
5ï¸âƒ£ é€‰æ‹©è¿è¡Œæ¨¡å¼:
   - æ‰‹åŠ¨è¿è¡Œä¸€æ¬¡
   - å®šæ—¶è°ƒåº¦è¿è¡Œ
   - å›æµ‹ç­–ç•¥
   â†“
6ï¸âƒ£ ç›‘æ§æ€§èƒ½ï¼ŒæŒç»­ä¼˜åŒ–
```

**æ ¸å¿ƒè¦ç‚¹**ï¼š

1. âœ… æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤
2. âœ… æ•°æ®ç¼“å­˜ï¼Œæé«˜æ•ˆç‡
3. âœ… æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ï¼Œå¯è¿½æº¯
4. âœ… å®šæ—¶è°ƒåº¦ï¼Œè‡ªåŠ¨åŒ–è¿è¡Œ
5. âœ… å®Œæ•´çš„å›æµ‹æµç¨‹

**ä¸‹ä¸€æ­¥**ï¼šæ¨¡å‹å»ºå¥½äº†ï¼Œä½†æ€ä¹ˆ**æ§åˆ¶é£é™©**å‘¢ï¼Ÿ

[â†’ å‰å¾€ 03-é£é™©æ§åˆ¶æ–¹æ³•](03-é£é™©æ§åˆ¶æ–¹æ³•.md)

---

**ğŸ’ª æ­å–œï¼ä½ å·²ç»æ‹¥æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„æ»šåŠ¨é‡è®­ç»ƒç³»ç»Ÿï¼ä¸‹èŠ‚è¯¾å­¦ä¹ é£é™©æ§åˆ¶ï¼Œè®©ä½ çš„ç³»ç»Ÿæ›´ç¨³å¥ï¼**
