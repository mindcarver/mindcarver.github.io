---
layout: default
section: Week6
title: 06-æ€§èƒ½ç›‘æ§ä¸è¯„ä¼°
---

# 06. æ€§èƒ½ç›‘æ§ä¸è¯„ä¼° ğŸ“Š

> "ä½ æ— æ³•ç®¡ç†ä½ æ— æ³•è¡¡é‡çš„ä¸œè¥¿" ~ å½¼å¾—Â·å¾·é²å…‹

ä¸€ä¸ªä¼˜ç§€çš„é‡åŒ–ç³»ç»Ÿï¼Œå¿…é¡»å…·å¤‡**å…¨é¢çš„ç›‘æ§å’Œè¯„ä¼°èƒ½åŠ›**ï¼

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§æŒ‡æ ‡

### è®­ç»ƒæ€§èƒ½æŒ‡æ ‡

```python
import time
from typing import Dict, Any

class TrainingMonitor:
    """è®­ç»ƒæ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.metrics = {
            'training_time': [],
            'prediction_time': [],
            'memory_usage': [],
            'iterations': []
        }
    
    def record_training(self, start_time: float, end_time: float, 
                       iterations: int, memory_usage: float = None):
        """
        è®°å½•è®­ç»ƒæ€§èƒ½
        
        Args:
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            iterations: è¿­ä»£æ¬¡æ•°
            memory_usage: å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰
        """
        training_time = end_time - start_time
        
        self.metrics['training_time'].append(training_time)
        self.metrics['iterations'].append(iterations)
        
        if memory_usage is not None:
            self.metrics['memory_usage'].append(memory_usage)
        
        print(f"ğŸ“Š è®­ç»ƒæ€§èƒ½:")
        print(f"  è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print(f"  è¿­ä»£æ¬¡æ•°: {iterations}")
        print(f"  å¹³å‡æ¯æ¬¡è¿­ä»£: {training_time/iterations:.4f}ç§’")
        
        if memory_usage:
            print(f"  å†…å­˜ä½¿ç”¨: {memory_usage:.2f}MB")
    
    def record_prediction(self, start_time: float, end_time: float, 
                         n_samples: int):
        """
        è®°å½•é¢„æµ‹æ€§èƒ½
        
        Args:
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            n_samples: æ ·æœ¬æ•°é‡
        """
        prediction_time = end_time - start_time
        throughput = n_samples / prediction_time
        
        self.metrics['prediction_time'].append(prediction_time)
        
        print(f"ğŸ“Š é¢„æµ‹æ€§èƒ½:")
        print(f"  é¢„æµ‹æ—¶é—´: {prediction_time:.4f}ç§’")
        print(f"  æ ·æœ¬æ•°é‡: {n_samples}")
        print(f"  ååé‡: {throughput:.0f} æ ·æœ¬/ç§’")
    
    def get_summary(self) -> Dict[str, Any]:
        """
        è·å–æ€§èƒ½æ‘˜è¦
        
        Returns:
            æ€§èƒ½æ‘˜è¦å­—å…¸
        """
        summary = {}
        
        # è®­ç»ƒæ—¶é—´
        if self.metrics['training_time']:
            summary['avg_training_time'] = np.mean(self.metrics['training_time'])
            summary['min_training_time'] = np.min(self.metrics['training_time'])
            summary['max_training_time'] = np.max(self.metrics['training_time'])
        
        # é¢„æµ‹æ—¶é—´
        if self.metrics['prediction_time']:
            summary['avg_prediction_time'] = np.mean(self.metrics['prediction_time'])
            summary['min_prediction_time'] = np.min(self.metrics['prediction_time'])
            summary['max_prediction_time'] = np.max(self.metrics['prediction_time'])
        
        # å†…å­˜ä½¿ç”¨
        if self.metrics['memory_usage']:
            summary['avg_memory'] = np.mean(self.metrics['memory_usage'])
            summary['max_memory'] = np.max(self.metrics['memory_usage'])
        
        return summary
```

### é¢„æµ‹ç²¾åº¦æŒ‡æ ‡

```python
from scipy import stats

class PredictionAccuracyMonitor:
    """é¢„æµ‹ç²¾åº¦ç›‘æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.history = []
    
    def evaluate(self, predictions: np.ndarray, 
                 returns: np.ndarray, 
                 date: str = None):
        """
        è¯„ä¼°é¢„æµ‹ç²¾åº¦
        
        Args:
            predictions: é¢„æµ‹å€¼
            returns: å®é™…å€¼
            date: æ—¥æœŸ
        """
        # IC (Information Coefficient)
        ic, ic_pvalue = stats.pearsonr(predictions, returns)
        
        # Rank IC
        rank_ic, rank_ic_pvalue = stats.spearmanr(predictions, returns)
        
        # MAE (Mean Absolute Error)
        mae = np.mean(np.abs(predictions - returns))
        
        # RMSE (Root Mean Squared Error)
        rmse = np.sqrt(np.mean((predictions - returns) ** 2))
        
        # ICåˆ†ç»„åˆ†æ
        n_groups = 5
        group_indices = np.array_split(np.argsort(predictions), n_groups)
        group_returns = [np.mean(returns[idx]) for idx in group_indices]
        
        results = {
            'date': date,
            'ic': ic,
            'ic_pvalue': ic_pvalue,
            'rank_ic': rank_ic,
            'rank_ic_pvalue': rank_ic_pvalue,
            'mae': mae,
            'rmse': rmse,
            'group_returns': group_returns
        }
        
        self.history.append(results)
        
        # æ‰“å°ç»“æœ
        print(f"ğŸ“Š é¢„æµ‹ç²¾åº¦è¯„ä¼° ({date or 'å½“å‰'}):")
        print(f"  IC: {ic:.4f} (p-value: {ic_pvalue:.4f})")
        print(f"  Rank IC: {rank_ic:.4f} (p-value: {rank_ic_pvalue:.4f})")
        print(f"  MAE: {mae:.4f}")
        print(f"  RMSE: {rmse:.4f}")
        print(f"  ICåˆ†ç»„åˆ†æ:")
        for i, ret in enumerate(group_returns):
            print(f"    ç»„{i+1}: {ret:.4f}")
        
        return results
    
    def get_ic_series(self) -> pd.Series:
        """è·å–ICæ—¶é—´åºåˆ—"""
        dates = [h['date'] for h in self.history if h['date']]
        ics = [h['ic'] for h in self.history]
        return pd.Series(ics, index=dates)
    
    def get_mean_ic(self) -> float:
        """è·å–å¹³å‡IC"""
        ics = [h['ic'] for h in self.history]
        return np.mean(ics)
    
    def get_mean_rank_ic(self) -> float:
        """è·å–å¹³å‡Rank IC"""
        rank_ics = [h['rank_ic'] for h in self.history]
        return np.mean(rank_ics)
```

### ç³»ç»Ÿå»¶è¿ŸæŒ‡æ ‡

```python
class LatencyMonitor:
    """ç³»ç»Ÿå»¶è¿Ÿç›‘æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.latencies = {
            'data_fetch': [],
            'feature_extraction': [],
            'model_prediction': [],
            'portfolio_construction': [],
            'trade_execution': [],
            'total': []
        }
    
    def record_latency(self, component: str, latency: float):
        """
        è®°å½•å»¶è¿Ÿ
        
        Args:
            component: ç»„ä»¶åç§°
            latency: å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        if component in self.latencies:
            self.latencies[component].append(latency)
    
    def record_total_latency(self, latency: float):
        """
        è®°å½•æ€»å»¶è¿Ÿ
        
        Args:
            latency: æ€»å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        self.latencies['total'].append(latency)
    
    def get_p50_latency(self, component: str = 'total') -> float:
        """
        è·å–P50å»¶è¿Ÿï¼ˆä¸­ä½æ•°ï¼‰
        
        Args:
            component: ç»„ä»¶åç§°
            
        Returns:
            P50å»¶è¿Ÿ
        """
        if component not in self.latencies:
            raise ValueError(f"æœªçŸ¥ç»„ä»¶: {component}")
        
        latencies = self.latencies[component]
        if not latencies:
            return 0.0
        
        return np.median(latencies)
    
    def get_p95_latency(self, component: str = 'total') -> float:
        """
        è·å–P95å»¶è¿Ÿ
        
        Args:
            component: ç»„ä»¶åç§°
            
        Returns:
            P95å»¶è¿Ÿ
        """
        if component not in self.latencies:
            raise ValueError(f"æœªçŸ¥ç»„ä»¶: {component}")
        
        latencies = self.latencies[component]
        if not latencies:
            return 0.0
        
        return np.percentile(latencies, 95)
    
    def get_p99_latency(self, component: str = 'total') -> float:
        """
        è·å–P99å»¶è¿Ÿ
        
        Args:
            component: ç»„ä»¶åç§°
            
        Returns:
            P99å»¶è¿Ÿ
        """
        if component not in self.latencies:
            raise ValueError(f"æœªçŸ¥ç»„ä»¶: {component}")
        
        latencies = self.latencies[component]
        if not latencies:
            return 0.0
        
        return np.percentile(latencies, 99)
    
    def print_summary(self):
        """æ‰“å°å»¶è¿Ÿæ‘˜è¦"""
        print("ğŸ“Š ç³»ç»Ÿå»¶è¿Ÿæ‘˜è¦:")
        
        for component, latencies in self.latencies.items():
            if latencies:
                p50 = np.percentile(latencies, 50)
                p95 = np.percentile(latencies, 95)
                p99 = np.percentile(latencies, 99)
                
                print(f"  {component}:")
                print(f"    P50: {p50:.4f}ç§’")
                print(f"    P95: {p95:.4f}ç§’")
                print(f"    P99: {p99:.4f}ç§’")
```

---

## ğŸ¯ è¯„ä¼°æ¡†æ¶

### ç»¼åˆè¯„ä¼°æ¡†æ¶

```python
class EvaluationFramework:
    """ç»¼åˆè¯„ä¼°æ¡†æ¶"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯„ä¼°æ¡†æ¶"""
        self.training_monitor = TrainingMonitor()
        self.accuracy_monitor = PredictionAccuracyMonitor()
        self.latency_monitor = LatencyMonitor()
        self.performance_tracker = PerformanceTracker()
    
    def evaluate_training(self, model, X_train, y_train, X_test, y_test):
        """
        è¯„ä¼°è®­ç»ƒæ€§èƒ½
        
        Args:
            model: æ¨¡å‹
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•æ ‡ç­¾
        """
        print("\n" + "="*60)
        print("ğŸ“Š è®­ç»ƒæ€§èƒ½è¯„ä¼°")
        print("="*60)
        
        # è®­ç»ƒæ—¶é—´
        import time
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        start_mem = process.memory_info().rss / 1024 / 1024  # MB
        
        start_time = time.time()
        model.fit(X_train, y_train)
        end_time = time.time()
        
        end_mem = process.memory_info().rss / 1024 / 1024  # MB
        memory_usage = end_mem - start_mem
        
        # è®°å½•è®­ç»ƒæ€§èƒ½
        iterations = getattr(model, 'best_iteration', 0) or getattr(model, 'n_estimators', 0)
        self.training_monitor.record_training(
            start_time=start_time,
            end_time=end_time,
            iterations=iterations,
            memory_usage=memory_usage
        )
        
        # é¢„æµ‹æ—¶é—´
        start_time = time.time()
        predictions = model.predict(X_test)
        end_time = time.time()
        
        self.training_monitor.record_prediction(
            start_time=start_time,
            end_time=end_time,
            n_samples=len(X_test)
        )
        
        # é¢„æµ‹ç²¾åº¦
        print("\n" + "="*60)
        print("ğŸ“Š é¢„æµ‹ç²¾åº¦è¯„ä¼°")
        print("="*60)
        self.accuracy_monitor.evaluate(predictions, y_test)
        
        return predictions
    
    def evaluate_performance(self, returns: pd.Series, 
                            benchmark: pd.Series = None):
        """
        è¯„ä¼°ç­–ç•¥ç»©æ•ˆ
        
        Args:
            returns: ç­–ç•¥æ”¶ç›Š
            benchmark: åŸºå‡†æ”¶ç›Š
        """
        print("\n" + "="*60)
        print("ğŸ“Š ç»©æ•ˆè¯„ä¼°")
        print("="*60)
        
        metrics = self.performance_tracker.calculate_metrics(
            returns, benchmark
        )
        
        self.performance_tracker.print_metrics(metrics)
        
        return metrics
```

### ç»©æ•ˆè¿½è¸ªå™¨

```python
class PerformanceTracker:
    """ç»©æ•ˆè¿½è¸ªå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»©æ•ˆè¿½è¸ªå™¨"""
        self.history = []
    
    def calculate_metrics(self, returns: pd.Series, 
                         benchmark: pd.Series = None) -> dict:
        """
        è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        
        Args:
            returns: ç­–ç•¥æ”¶ç›Š
            benchmark: åŸºå‡†æ”¶ç›Š
            
        Returns:
            ç»©æ•ˆæŒ‡æ ‡å­—å…¸
        """
        # ç´¯è®¡æ”¶ç›Š
        cumulative_returns = (1 + returns).cumprod()
        total_return = cumulative_returns.iloc[-1] - 1
        
        # å¹´åŒ–æ”¶ç›Š
        n_days = len(returns)
        annual_return = (1 + total_return) ** (252 / n_days) - 1
        
        # æ³¢åŠ¨ç‡
        volatility = returns.std() * np.sqrt(252)
        
        # å¤æ™®æ¯”ç‡
        risk_free_rate = 0.03  # å‡è®¾æ— é£é™©åˆ©ç‡3%
        sharpe_ratio = (annual_return - risk_free_rate) / volatility
        
        # æœ€å¤§å›æ’¤
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min()
        
        # ä¿¡æ¯æ¯”ç‡ï¼ˆç›¸å¯¹äºåŸºå‡†ï¼‰
        if benchmark is not None:
            active_returns = returns - benchmark
            information_ratio = active_returns.mean() / active_returns.std() * np.sqrt(252)
        else:
            information_ratio = None
        
        # èƒœç‡
        win_rate = (returns > 0).mean()
        
        # ç›ˆäºæ¯”
        winning_returns = returns[returns > 0]
        losing_returns = returns[returns < 0]
        if len(winning_returns) > 0 and len(losing_returns) > 0:
            profit_loss_ratio = winning_returns.mean() / abs(losing_returns.mean())
        else:
            profit_loss_ratio = None
        
        metrics = {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'information_ratio': information_ratio,
            'win_rate': win_rate,
            'profit_loss_ratio': profit_loss_ratio
        }
        
        return metrics
    
    def print_metrics(self, metrics: dict):
        """
        æ‰“å°ç»©æ•ˆæŒ‡æ ‡
        
        Args:
            metrics: ç»©æ•ˆæŒ‡æ ‡å­—å…¸
        """
        print(f"  æ€»æ”¶ç›Šç‡: {metrics['total_return']:.2%}")
        print(f"  å¹´åŒ–æ”¶ç›Šç‡: {metrics['annual_return']:.2%}")
        print(f"  å¹´åŒ–æ³¢åŠ¨ç‡: {metrics['volatility']:.2%}")
        print(f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.2f}")
        print(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}")
        
        if metrics['information_ratio'] is not None:
            print(f"  ä¿¡æ¯æ¯”ç‡: {metrics['information_ratio']:.2f}")
        
        print(f"  èƒœç‡: {metrics['win_rate']:.2%}")
        
        if metrics['profit_loss_ratio'] is not None:
            print(f"  ç›ˆäºæ¯”: {metrics['profit_loss_ratio']:.2f}")
    
    def track_performance(self, date: str, returns: float, 
                         portfolio_value: float):
        """
        è¿½è¸ªç»©æ•ˆ
        
        Args:
            date: æ—¥æœŸ
            returns: æ”¶ç›Š
            portfolio_value: ç»„åˆä»·å€¼
        """
        self.history.append({
            'date': date,
            'returns': returns,
            'portfolio_value': portfolio_value
        })
    
    def get_performance_series(self) -> pd.DataFrame:
        """
        è·å–ç»©æ•ˆæ—¶é—´åºåˆ—
        
        Returns:
            ç»©æ•ˆDataFrame
        """
        return pd.DataFrame(self.history).set_index('date')
```

---

## ğŸ“¡ å®æ—¶ç›‘æ§

### å®æ—¶ç›‘æ§ç³»ç»Ÿ

```python
from typing import Callable, Optional
import threading

class RealtimeMonitor:
    """å®æ—¶ç›‘æ§å™¨"""
    
    def __init__(self, check_interval: int = 60):
        """
        åˆå§‹åŒ–å®æ—¶ç›‘æ§å™¨
        
        Args:
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        self.check_interval = check_interval
        self.running = False
        self.monitors = []
        self.alert_callbacks = []
    
    def add_monitor(self, monitor: Callable):
        """
        æ·»åŠ ç›‘æ§
        
        Args:
            monitor: ç›‘æ§å‡½æ•°
        """
        self.monitors.append(monitor)
    
    def add_alert_callback(self, callback: Callable):
        """
        æ·»åŠ æŠ¥è­¦å›è°ƒ
        
        Args:
            callback: å›è°ƒå‡½æ•°
        """
        self.alert_callbacks.append(callback)
    
    def start(self):
        """å¯åŠ¨ç›‘æ§"""
        self.running = True
        
        def monitor_loop():
            while self.running:
                try:
                    # æ‰§è¡Œæ‰€æœ‰ç›‘æ§
                    for monitor in self.monitors:
                        alert = monitor()
                        
                        # å¦‚æœè§¦å‘æŠ¥è­¦ï¼Œæ‰§è¡Œå›è°ƒ
                        if alert:
                            for callback in self.alert_callbacks:
                                callback(alert)
                    
                    # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                    time.sleep(self.check_interval)
                
                except Exception as e:
                    print(f"ç›‘æ§é”™è¯¯: {e}")
                    time.sleep(self.check_interval)
        
        self.thread = threading.Thread(target=monitor_loop, daemon=True)
        self.thread.start()
        
        print("âœ… å®æ—¶ç›‘æ§å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        if hasattr(self, 'thread'):
            self.thread.join()
        print("âœ… å®æ—¶ç›‘æ§å·²åœæ­¢")
```

### æŠ¥è­¦ç³»ç»Ÿ

```python
class AlertSystem:
    """æŠ¥è­¦ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŠ¥è­¦ç³»ç»Ÿ"""
        self.alerts = []
        self.alert_history = []
    
    def create_alert(self, name: str, condition: Callable, 
                     message: str, severity: str = 'warning'):
        """
        åˆ›å»ºæŠ¥è­¦
        
        Args:
            name: æŠ¥è­¦åç§°
            condition: æ¡ä»¶å‡½æ•°
            message: æŠ¥è­¦æ¶ˆæ¯
            severity: ä¸¥é‡ç¨‹åº¦ ('info', 'warning', 'error', 'critical')
        """
        alert = {
            'name': name,
            'condition': condition,
            'message': message,
            'severity': severity
        }
        
        self.alerts.append(alert)
        print(f"âœ… æŠ¥è­¦å·²åˆ›å»º: {name}")
    
    def check_alerts(self) -> Optional[dict]:
        """
        æ£€æŸ¥æ‰€æœ‰æŠ¥è­¦
        
        Returns:
            è§¦å‘çš„æŠ¥è­¦ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        for alert in self.alerts:
            if alert['condition']():
                # è®°å½•æŠ¥è­¦å†å²
                self.alert_history.append({
                    **alert,
                    'timestamp': datetime.now()
                })
                
                print(f"\nğŸš¨ æŠ¥è­¦è§¦å‘: {alert['name']}")
                print(f"  æ¶ˆæ¯: {alert['message']}")
                print(f"  ä¸¥é‡ç¨‹åº¦: {alert['severity']}")
                print(f"  æ—¶é—´: {datetime.now()}")
                
                return alert
        
        return None
    
    def get_alert_history(self) -> list:
        """
        è·å–æŠ¥è­¦å†å²
        
        Returns:
            æŠ¥è­¦å†å²åˆ—è¡¨
        """
        return self.alert_history
```

### ç›‘æ§ç¤ºä¾‹

```python
# åˆ›å»ºæŠ¥è­¦ç³»ç»Ÿ
alert_system = AlertSystem()

# åˆ›å»ºæŠ¥è­¦
alert_system.create_alert(
    name='ICä¸‹é™',
    condition=lambda: accuracy_monitor.get_mean_ic() < 0.02,
    message='ICå€¼è¿‡ä½ï¼Œæ¨¡å‹å¯èƒ½å¤±æ•ˆ',
    severity='warning'
)

alert_system.create_alert(
    name='å›æ’¤è¿‡å¤§',
    condition=lambda: performance_tracker.get_max_drawdown() < -0.10,
    message='å›æ’¤è¶…è¿‡10%',
    severity='critical'
)

alert_system.create_alert(
    name='ç³»ç»Ÿå»¶è¿Ÿ',
    condition=lambda: latency_monitor.get_p95_latency('total') > 5.0,
    message='ç³»ç»Ÿå»¶è¿Ÿè¶…è¿‡5ç§’',
    severity='warning'
)

# åˆ›å»ºå®æ—¶ç›‘æ§
realtime_monitor = RealtimeMonitor(check_interval=60)

# æ·»åŠ ç›‘æ§
realtime_monitor.add_monitor(lambda: alert_system.check_alerts())

# æ·»åŠ æŠ¥è­¦å›è°ƒ
def on_alert(alert):
    # å‘é€é‚®ä»¶/çŸ­ä¿¡/é’‰é’‰é€šçŸ¥
    send_notification(alert)

realtime_monitor.add_alert_callback(on_alert)

# å¯åŠ¨ç›‘æ§
realtime_monitor.start()

# ç³»ç»Ÿè¿è¡Œ...
```

---

## ğŸ“Š åŸºå‡†æ¯”è¾ƒ

### åŸºå‡†æ¯”è¾ƒå™¨

```python
class BenchmarkComparator:
    """åŸºå‡†æ¯”è¾ƒå™¨"""
    
    def __init__(self, benchmarks: dict):
        """
        åˆå§‹åŒ–åŸºå‡†æ¯”è¾ƒå™¨
        
        Args:
            benchmarks: åŸºå‡†å­—å…¸ {åç§°: æ”¶ç›ŠSeries}
        """
        self.benchmarks = benchmarks
    
    def compare(self, strategy_returns: pd.Series) -> pd.DataFrame:
        """
        æ¯”è¾ƒç­–ç•¥ä¸åŸºå‡†
        
        Args:
            strategy_returns: ç­–ç•¥æ”¶ç›Š
            
        Returns:
            æ¯”è¾ƒç»“æœDataFrame
        """
        results = []
        
        # è®¡ç®—ç­–ç•¥æŒ‡æ ‡
        strategy_metrics = PerformanceTracker().calculate_metrics(
            strategy_returns
        )
        
        results.append({
            'Strategy': 'Strategy',
            'Total Return': strategy_metrics['total_return'],
            'Annual Return': strategy_metrics['annual_return'],
            'Volatility': strategy_metrics['volatility'],
            'Sharpe Ratio': strategy_metrics['sharpe_ratio'],
            'Max Drawdown': strategy_metrics['max_drawdown']
        })
        
        # è®¡ç®—æ¯ä¸ªåŸºå‡†çš„æŒ‡æ ‡
        for name, benchmark_returns in self.benchmarks.items():
            benchmark_metrics = PerformanceTracker().calculate_metrics(
                benchmark_returns
            )
            
            results.append({
                'Strategy': name,
                'Total Return': benchmark_metrics['total_return'],
                'Annual Return': benchmark_metrics['annual_return'],
                'Volatility': benchmark_metrics['volatility'],
                'Sharpe Ratio': benchmark_metrics['sharpe_ratio'],
                'Max Drawdown': benchmark_metrics['max_drawdown']
            })
        
        df = pd.DataFrame(results).set_index('Strategy')
        
        return df
    
    def print_comparison(self, strategy_returns: pd.Series):
        """
        æ‰“å°æ¯”è¾ƒç»“æœ
        
        Args:
            strategy_returns: ç­–ç•¥æ”¶ç›Š
        """
        df = self.compare(strategy_returns)
        
        print("\nğŸ“Š ç­–ç•¥ vs åŸºå‡†:")
        print(df.round(4))
        
        # é«˜äº®æœ€ä½³è¡¨ç°
        print("\nğŸ† æœ€ä½³è¡¨ç°:")
        for col in df.columns:
            if col in ['Total Return', 'Annual Return', 'Sharpe Ratio']:
                best = df[col].idxmax()
            else:
                best = df[col].idxmin()
            
            print(f"  {col}: {best}")
```

---

## ğŸ“ æœ¬èŠ‚å°ç»“

**æ ¸å¿ƒè¦ç‚¹**ï¼š

1. âœ… ç›‘æ§è®­ç»ƒã€é¢„æµ‹ã€ç³»ç»Ÿå»¶è¿Ÿç­‰æ€§èƒ½æŒ‡æ ‡
2. âœ… è¯„ä¼°é¢„æµ‹ç²¾åº¦ï¼ˆICã€Rank ICç­‰ï¼‰
3. âœ… è¿½è¸ªç­–ç•¥ç»©æ•ˆï¼ˆæ”¶ç›Šç‡ã€å¤æ™®æ¯”ç‡ã€å›æ’¤ç­‰ï¼‰
4. âœ… å®æ—¶ç›‘æ§å’ŒæŠ¥è­¦ç³»ç»Ÿ
5. âœ… ä¸åŸºå‡†æ¯”è¾ƒï¼Œè¯„ä¼°ç›¸å¯¹è¡¨ç°

**ç›‘æ§ä¸‰å±‚æ¬¡**ï¼š

```python
monitoring_levels = {
    "å±‚æ¬¡1": "å®æ—¶ç›‘æ§",  # æ¯ç§’/æ¯åˆ†é’Ÿæ£€æŸ¥
    "å±‚æ¬¡2": "æ—¥åº¦ç›‘æ§",  # æ¯å¤©è¯„ä¼°
    "å±‚æ¬¡3": "é•¿æœŸç›‘æ§"   # æ¯æœˆ/æ¯å­£åº¦å›é¡¾
}
```

**ä¸‹ä¸€æ­¥**ï¼šç›‘æ§åšå¥½äº†ï¼Œå¦‚ä½•**å¤„ç†å¼‚å¸¸å’Œæ¢å¤ç³»ç»Ÿ**å‘¢ï¼Ÿ

[â†’ å‰å¾€ 07-å¼‚å¸¸å¤„ç†ä¸æ¢å¤](07-å¼‚å¸¸å¤„ç†ä¸æ¢å¤.md)

---

**ğŸ“Š ç›‘æ§è®©ç³»ç»Ÿé€æ˜ï¼Œä¸‹èŠ‚è¯¾å­¦ä¹ å¼‚å¸¸å¤„ç†ï¼Œè®©ç³»ç»Ÿæ›´ç¨³å¥ï¼**
