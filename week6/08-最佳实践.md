---
layout: default
section: Week6
title: 08-æœ€ä½³å®è·µ
---

# 08. æœ€ä½³å®è·µ ğŸ’

> "ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Š" ~ ç‰›é¡¿

æœ¬èŠ‚è¯¾æ€»ç»“é‡åŒ–ç³»ç»Ÿå¼€å‘çš„**æœ€ä½³å®è·µ**ï¼Œå¸®åŠ©ä½ é¿å…å¸¸è§å‘ç‚¹ï¼Œæ„å»ºæ›´ä¸“ä¸šçš„ç³»ç»Ÿï¼

---

## ğŸ“ å¼€å‘è§„èŒƒ

### å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„å‘½å
class DataFetcher:              # ç±»åï¼šå¤§é©¼å³°
    def fetch_data(self):        # æ–¹æ³•åï¼šå°å†™+ä¸‹åˆ’çº¿
        self.data_source = None  # å±æ€§åï¼šå°å†™+ä¸‹åˆ’çº¿
        self.max_retries = 3     # å¸¸é‡åï¼šå°å†™+ä¸‹åˆ’çº¿

DATA_DIR = './data'             # å…¨å±€å¸¸é‡ï¼šå¤§å†™+ä¸‹åˆ’çº¿

def calculate_ic(predictions, returns):  # å‡½æ•°åï¼šå°å†™+ä¸‹åˆ’çº¿
    """è®¡ç®—ICå€¼"""
    return np.corrcoef(predictions, returns)[0, 1]

# âŒ åçš„å‘½å
class datafetcher:               # ç±»ååº”è¯¥å¤§é©¼å³°
    def FetchData(self):         # æ–¹æ³•åä¸åº”è¯¥å¤§é©¼å³°
        self.dataSource = None   # å±æ€§åä¸åº”è¯¥é©¼å³°
        self.MaxRetries = 3      # å¸¸é‡ååº”è¯¥å…¨å¤§å†™

datadir = './data'               # å…¨å±€å¸¸é‡åº”è¯¥å¤§å†™

def CalcIC(pred, ret):           # å‡½æ•°åä¸åº”è¯¥ç¼©å†™
    pass
```

### ä»£ç é£æ ¼

```python
# âœ… å¥½çš„ä»£ç é£æ ¼ - æ¸…æ™°ã€æœ‰æ³¨é‡Šã€æœ‰ç±»å‹æç¤º
from typing import Dict, List, Optional
import numpy as np
import pandas as pd

class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, params: Dict[str, Any]):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            params: æ¨¡å‹å‚æ•°
        """
        self.params = params
        self.model = None
    
    def train(self, X: pd.DataFrame, 
              y: pd.Series) -> None:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            X: è®­ç»ƒç‰¹å¾
            y: è®­ç»ƒæ ‡ç­¾
        """
        # æ•°æ®éªŒè¯
        if len(X) != len(y):
            raise ValueError("Xå’Œyé•¿åº¦ä¸ä¸€è‡´")
        
        # è®­ç»ƒ
        self.model.fit(X, y)
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        é¢„æµ‹
        
        Args:
            X: é¢„æµ‹ç‰¹å¾
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        return self.model.predict(X)

# âŒ åçš„ä»£ç é£æ ¼ - æ··ä¹±ã€æ— æ³¨é‡Šã€æ— ç±»å‹æç¤º
class mt:
    def __init__(self, p):
        self.p = p
        self.m = None
    
    def train(self, x, y):
        self.m.fit(x, y)
    
    def predict(self, x):
        return self.m.predict(x)
```

### æ–‡æ¡£è§„èŒƒ

```python
# âœ… å¥½çš„æ–‡æ¡£ - è¯¦ç»†çš„docstring
def calculate_ic(predictions: np.ndarray, 
                returns: np.ndarray) -> float:
    """
    è®¡ç®—ä¿¡æ¯ç³»æ•°ï¼ˆICï¼‰
    
    ICæ˜¯é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹é—´çš„ç›¸å…³ç³»æ•°ï¼Œç”¨äºè¡¡é‡é¢„æµ‹å‡†ç¡®æ€§ã€‚
    ICå€¼èŒƒå›´ï¼š-1åˆ°1
    - IC > 0.05: é¢„æµ‹èƒ½åŠ›è¾ƒå¼º
    - IC > 0.03: é¢„æµ‹èƒ½åŠ›ä¸€èˆ¬
    - IC < 0.02: é¢„æµ‹èƒ½åŠ›è¾ƒå¼±
    
    Args:
        predictions: é¢„æµ‹å€¼æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (n_samples,)
        returns: çœŸå®æ”¶ç›Šæ•°ç»„ï¼Œå½¢çŠ¶ä¸º (n_samples,)
        
    Returns:
        ICå€¼ï¼ŒèŒƒå›´åœ¨[-1, 1]ä¹‹é—´
        
    Raises:
        ValueError: å½“è¾“å…¥æ•°ç»„é•¿åº¦ä¸ä¸€è‡´æ—¶
        
    Examples:
        >>> pred = np.array([0.1, 0.2, 0.3])
        >>> ret = np.array([0.05, 0.15, 0.25])
        >>> ic = calculate_ic(pred, ret)
        >>> print(f"IC: {ic:.3f}")
    """
    if len(predictions) != len(returns):
        raise ValueError("predictionså’Œreturnsé•¿åº¦ä¸ä¸€è‡´")
    
    ic, _ = pearsonr(predictions, returns)
    
    return ic

# âŒ åçš„æ–‡æ¡£ - ç®€é™‹çš„docstring
def calculate_ic(p, r):
    """è®¡ç®—IC"""
    return pearsonr(p, r)[0]
```

---

## ğŸ›¡ï¸ é£é™©æ§åˆ¶

### ç›‘æ§åŸåˆ™

```python
class RiskMonitor:
    """é£é™©ç›‘æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é£é™©ç›‘æ§å™¨"""
        self.alerts = []
    
    def monitor(self, portfolio: Dict[str, float], 
                returns: pd.Series):
        """
        ç›‘æ§é£é™©
        
        ç›‘æ§åŸåˆ™:
        1. å®æ—¶ç›‘æ§ï¼šæ¯ç§’/æ¯åˆ†é’Ÿæ£€æŸ¥å…³é”®æŒ‡æ ‡
        2. å¤šå±‚ç›‘æ§ï¼šä»“ä½ã€è¡Œä¸šã€å¸‚åœºç­‰å¤šå±‚æ¬¡
        3. é˜ˆå€¼è®¾ç½®ï¼šæ ¹æ®å†å²æ•°æ®ç§‘å­¦è®¾ç½®
        4. åŠæ—¶æŠ¥è­¦ï¼šè§¦å‘é˜ˆå€¼ç«‹å³é€šçŸ¥
        5. è®°å½•æ—¥å¿—ï¼šæ‰€æœ‰é£é™©äº‹ä»¶ç•™ç—•
        
        Args:
            portfolio: æŠ•èµ„ç»„åˆæƒé‡
            returns: æ”¶ç›Šåºåˆ—
        """
        # 1. ä»“ä½ç›‘æ§
        self._monitor_position(portfolio)
        
        # 2. å›æ’¤ç›‘æ§
        self._monitor_drawdown(returns)
        
        # 3. æ³¢åŠ¨ç‡ç›‘æ§
        self._monitor_volatility(returns)
        
        # 4. è¡Œä¸šæš´éœ²ç›‘æ§
        self._monitor_industry_exposure(portfolio)
    
    def _monitor_position(self, portfolio: Dict[str, float]):
        """ç›‘æ§ä»“ä½"""
        # æ£€æŸ¥å•ä¸€è‚¡ç¥¨ä»“ä½
        for stock, weight in portfolio.items():
            if weight > 0.10:
                self.alerts.append({
                    'type': 'position_too_high',
                    'stock': stock,
                    'weight': weight,
                    'threshold': 0.10
                })
        
        # æ£€æŸ¥æ€»ä»“ä½
        total_position = sum(portfolio.values())
        if total_position > 0.95:
            self.alerts.append({
                'type': 'total_position_too_high',
                'total': total_position,
                'threshold': 0.95
            })
    
    def _monitor_drawdown(self, returns: pd.Series):
        """ç›‘æ§å›æ’¤"""
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        
        max_dd = drawdown.min()
        if max_dd < -0.10:
            self.alerts.append({
                'type': 'drawdown_too_large',
                'max_drawdown': max_dd,
                'threshold': 0.10
            })
    
    def _monitor_volatility(self, returns: pd.Series):
        """ç›‘æ§æ³¢åŠ¨ç‡"""
        vol = returns.std() * np.sqrt(252)
        
        if vol > 0.30:
            self.alerts.append({
                'type': 'volatility_too_high',
                'volatility': vol,
                'threshold': 0.30
            })
    
    def _monitor_industry_exposure(self, portfolio: Dict[str, float]):
        """ç›‘æ§è¡Œä¸šæš´éœ²"""
        # å‡è®¾æœ‰è¡Œä¸šæ˜ å°„
        industry_mapping = self._get_industry_mapping()
        
        # è®¡ç®—è¡Œä¸šæƒé‡
        industry_weights = {}
        for stock, weight in portfolio.items():
            industry = industry_mapping.get(stock, 'Other')
            industry_weights[industry] = industry_weights.get(industry, 0) + weight
        
        # æ£€æŸ¥è¡Œä¸šæš´éœ²
        for industry, weight in industry_weights.items():
            if weight > 0.30:
                self.alerts.append({
                    'type': 'industry_exposure_too_high',
                    'industry': industry,
                    'weight': weight,
                    'threshold': 0.30
                })
```

### ä»“ä½é™åˆ¶

```python
class PositionLimit:
    """ä»“ä½é™åˆ¶"""
    
    def __init__(self, 
                 max_single_position=0.10,
                 max_total_position=0.95,
                 max_industry_position=0.30):
        """
        åˆå§‹åŒ–ä»“ä½é™åˆ¶
        
        Args:
            max_single_position: å•ä¸€è‚¡ç¥¨æœ€å¤§ä»“ä½
            max_total_position: æ€»ä»“ä½ä¸Šé™
            max_industry_position: å•ä¸€è¡Œä¸šæœ€å¤§ä»“ä½
        """
        self.max_single_position = max_single_position
        self.max_total_position = max_total_position
        self.max_industry_position = max_industry_position
    
    def apply(self, portfolio: Dict[str, float],
              industry_mapping: Dict[str, str]) -> Dict[str, float]:
        """
        åº”ç”¨ä»“ä½é™åˆ¶
        
        Args:
            portfolio: åŸå§‹æŠ•èµ„ç»„åˆ
            industry_mapping: è¡Œä¸šæ˜ å°„
            
        Returns:
            è°ƒæ•´åçš„æŠ•èµ„ç»„åˆ
        """
        adjusted = portfolio.copy()
        
        # 1. é™åˆ¶å•ä¸€è‚¡ç¥¨ä»“ä½
        for stock, weight in adjusted.items():
            if weight > self.max_single_position:
                adjusted[stock] = self.max_single_position
        
        # 2. é™åˆ¶è¡Œä¸šä»“ä½
        industry_weights = {}
        for stock, weight in adjusted.items():
            industry = industry_mapping.get(stock, 'Other')
            industry_weights[industry] = industry_weights.get(industry, 0) + weight
        
        # è°ƒæ•´è¶…é™è¡Œä¸š
        for industry, weight in industry_weights.items():
            if weight > self.max_industry_position:
                scale = self.max_industry_position / weight
                
                # è°ƒæ•´è¯¥è¡Œä¸šçš„æ‰€æœ‰è‚¡ç¥¨
                for stock, _weight in adjusted.items():
                    ind = industry_mapping.get(stock, 'Other')
                    if ind == industry:
                        adjusted[stock] = _weight * scale
        
        # 3. é™åˆ¶æ€»ä»“ä½
        total = sum(adjusted.values())
        if total > self.max_total_position:
            scale = self.max_total_position / total
            adjusted = {k: v * scale for k, v in adjusted.items()}
        
        return adjusted
```

### æ­¢æŸè®¾ç½®

```python
class StopLossStrategy:
    """æ­¢æŸç­–ç•¥"""
    
    def __init__(self, 
                 stop_loss_type='trailing',
                 stop_loss_percent=0.10,
                 take_profit_percent=0.20):
        """
        åˆå§‹åŒ–æ­¢æŸç­–ç•¥
        
        Args:
            stop_loss_type: æ­¢æŸç±»å‹ ('fixed', 'trailing')
            stop_loss_percent: æ­¢æŸç™¾åˆ†æ¯”
            take_profit_percent: æ­¢ç›ˆç™¾åˆ†æ¯”
        """
        self.stop_loss_type = stop_loss_type
        self.stop_loss_percent = stop_loss_percent
        self.take_profit_percent = take_profit_percent
        self.positions = {}
    
    def open_position(self, symbol: str, entry_price: float):
        """
        å¼€ä»“
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            entry_price: å¼€ä»“ä»·æ ¼
        """
        self.positions[symbol] = {
            'entry_price': entry_price,
            'max_price': entry_price,
            'stop_loss_price': entry_price * (1 - self.stop_loss_percent),
            'take_profit_price': entry_price * (1 + self.take_profit_percent)
        }
    
    def check_exit(self, symbol: str, current_price: float) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦å¹³ä»“
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            current_price: å½“å‰ä»·æ ¼
            
        Returns:
            æ˜¯å¦éœ€è¦å¹³ä»“
        """
        if symbol not in self.positions:
            return False
        
        position = self.positions[symbol]
        
        # æ›´æ–°è¿½è¸ªæ­¢æŸ
        if self.stop_loss_type == 'trailing':
            position['max_price'] = max(position['max_price'], current_price)
            position['stop_loss_price'] = max(
                position['stop_loss_price'],
                position['max_price'] * (1 - self.stop_loss_percent)
            )
        
        # æ£€æŸ¥æ­¢æŸ
        if current_price <= position['stop_loss_price']:
            print(f"ğŸ›‘ è§¦å‘æ­¢æŸ: {symbol} @ {current_price:.2f}")
            return True
        
        # æ£€æŸ¥æ­¢ç›ˆ
        if current_price >= position['take_profit_price']:
            print(f"ğŸ’° è§¦å‘æ­¢ç›ˆ: {symbol} @ {current_price:.2f}")
            return True
        
        return False
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### å¹¶è¡Œè®¡ç®—

```python
import multiprocessing
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Callable, List

class ParallelProcessor:
    """å¹¶è¡Œå¤„ç†å™¨"""
    
    def __init__(self, n_workers: int = None):
        """
        åˆå§‹åŒ–å¹¶è¡Œå¤„ç†å™¨
        
        Args:
            n_workers: å·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°ï¼‰
        """
        self.n_workers = n_workers or multiprocessing.cpu_count()
    
    def map(self, func: Callable, data: List) -> List:
        """
        å¹¶è¡Œmap
        
        Args:
            func: è¦æ‰§è¡Œçš„å‡½æ•°
            data: æ•°æ®åˆ—è¡¨
            
        Returns:
            ç»“æœåˆ—è¡¨
        """
        with ProcessPoolExecutor(max_workers=self.n_workers) as executor:
            results = list(executor.map(func, data))
        
        return results
    
    def map_async(self, func: Callable, data: List) -> List:
        """
        å¼‚æ­¥å¹¶è¡Œmapï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰
        
        Args:
            func: è¦æ‰§è¡Œçš„å‡½æ•°
            data: æ•°æ®åˆ—è¡¨
            
        Returns:
            ç»“æœåˆ—è¡¨
        """
        results = []
        
        with ProcessPoolExecutor(max_workers=self.n_workers) as executor:
            futures = {executor.submit(func, item): i 
                      for i, item in enumerate(data)}
            
            for future in as_completed(futures):
                idx = futures[future]
                try:
                    result = future.result()
                    results.append((idx, result))
                except Exception as e:
                    print(f"ä»»åŠ¡ {idx} å¤±è´¥: {e}")
        
        # æŒ‰åŸå§‹é¡ºåºæ’åº
        results.sort(key=lambda x: x[0])
        return [r[1] for r in results]

# ä½¿ç”¨ç¤ºä¾‹
def train_model(stock_data):
    """è®­ç»ƒå•ä¸ªè‚¡ç¥¨çš„æ¨¡å‹"""
    # è®­ç»ƒé€»è¾‘
    pass

processor = ParallelProcessor(n_workers=4)
results = processor.map(train_model, stock_data_list)
```

### ç¼“å­˜ä¼˜åŒ–

```python
from functools import lru_cache
import pickle
from typing import Any
from pathlib import Path

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir='./cache'):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def get(self, key: str) -> Any:
        """
        è·å–ç¼“å­˜
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        """
        cache_file = self.cache_dir / f"{key}.pkl"
        
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        
        return None
    
    def set(self, key: str, value: Any):
        """
        è®¾ç½®ç¼“å­˜
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
        """
        cache_file = self.cache_dir / f"{key}.pkl"
        
        with open(cache_file, 'wb') as f:
            pickle.dump(value, f)
    
    def exists(self, key: str) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            æ˜¯å¦å­˜åœ¨
        """
        cache_file = self.cache_dir / f"{key}.pkl"
        return cache_file.exists()
    
    def delete(self, key: str):
        """
        åˆ é™¤ç¼“å­˜
        
        Args:
            key: ç¼“å­˜é”®
        """
        cache_file = self.cache_dir / f"{key}.pkl"
        if cache_file.exists():
            cache_file.unlink()

# è£…é¥°å™¨ç‰ˆæœ¬
def disk_cache(key_func=None):
    """
    ç£ç›˜ç¼“å­˜è£…é¥°å™¨
    
    Args:
        key_func: ç”Ÿæˆç¼“å­˜é”®çš„å‡½æ•°
    """
    cache_manager = CacheManager()
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                cache_key = f"{func.__name__}_{args}_{kwargs}"
            
            # æ£€æŸ¥ç¼“å­˜
            cached = cache_manager.get(cache_key)
            if cached is not None:
                print(f"âœ… å‘½ä¸­ç¼“å­˜: {cache_key}")
                return cached
            
            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)
            
            # è®¾ç½®ç¼“å­˜
            cache_manager.set(cache_key, result)
            
            return result
        
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@disk_cache(lambda symbol, date: f"{symbol}_{date}")
def fetch_data(symbol: str, date: str):
    """è·å–æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # æ•°æ®è·å–é€»è¾‘
    pass
```

### ç®—æ³•é€‰æ‹©

```python
# æ ¹æ®æ•°æ®è§„æ¨¡é€‰æ‹©åˆé€‚çš„ç®—æ³•

def choose_algorithm(n_samples: int):
    """
    é€‰æ‹©åˆé€‚çš„ç®—æ³•
    
    Args:
        n_samples: æ ·æœ¬æ•°é‡
    """
    if n_samples < 1000:
        print("ä½¿ç”¨: ç®€å•ç®—æ³•ï¼ˆæš´åŠ›æœç´¢ï¼‰")
        # O(n^2) ç®—æ³•ä¹Ÿå¯ä»¥æ¥å—
        pass
    
    elif n_samples < 100000:
        print("ä½¿ç”¨: ä¸­ç­‰ç®—æ³•ï¼ˆæ’åº+äºŒåˆ†ï¼‰")
        # O(n log n) ç®—æ³•
        pass
    
    else:
        print("ä½¿ç”¨: é«˜æ•ˆç®—æ³•ï¼ˆå“ˆå¸Œè¡¨ï¼‰")
        # O(n) ç®—æ³•
        pass

# ç‰¹å¾å·¥ç¨‹ä¸­çš„ä¼˜åŒ–
def efficient_feature_engineering(data: pd.DataFrame):
    """é«˜æ•ˆç‰¹å¾å·¥ç¨‹"""
    
    # âŒ æ…¢ï¼šé€è¡Œéå†
    # for i in range(len(data)):
    #     data.loc[i, 'ma'] = data.loc[:i, 'price'].mean()
    
    # âœ… å¿«ï¼šå‘é‡åŒ–æ“ä½œ
    data['ma'] = data['price'].rolling(5).mean()
    
    # âŒ æ…¢ï¼šå¤šæ¬¡æ‰«æ
    # data['rank1'] = data['factor1'].rank()
    # data['rank2'] = data['factor2'].rank()
    # data['rank3'] = data['factor3'].rank()
    
    # âœ… å¿«ï¼šä¸€æ¬¡æ‰«æ
    rank_cols = ['factor1', 'factor2', 'factor3']
    data[[f'rank_{c}' for c in rank_cols]] = data[rank_cols].rank(axis=0)
```

---

## ğŸ”’ ç¨³å®šæ€§ä¿éšœ

### ç‰ˆæœ¬æ§åˆ¶

```python
# ä½¿ç”¨Gitè¿›è¡Œç‰ˆæœ¬æ§åˆ¶
# è§„èŒƒï¼š
# 1. æ¯æ¬¡é‡è¦ä¿®æ”¹éƒ½è¦æäº¤
# 2. æäº¤ä¿¡æ¯è¦æ¸…æ™°
# 3. ä½¿ç”¨åˆ†æ”¯è¿›è¡Œå®éªŒ
# 4. å®šæœŸæ‰“æ ‡ç­¾

# .gitignore ç¤ºä¾‹
"""
# Python
__pycache__/
*.py[cod]
*$py.class
*.so

# Jupyter Notebook
.ipynb_checkpoints

# ç¯å¢ƒå˜é‡
.env
*.secret

# æ•°æ®æ–‡ä»¶
data/*.csv
models/*.pkl
checkpoints/

# IDE
.vscode/
.idea/

# æ—¥å¿—
*.log
"""
```

### æ—¥å¿—è®°å½•

```python
import logging
from logging.handlers import RotatingFileHandler

def setup_logger(name: str, log_file: str, 
                level=logging.INFO):
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨
    
    Args:
        name: æ—¥å¿—è®°å½•å™¨åç§°
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        level: æ—¥å¿—çº§åˆ«
        
    Returns:
        æ—¥å¿—è®°å½•å™¨
    """
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(level)
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(level)
    
    # æ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - '
        '%(filename)s:%(lineno)d - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

# ä½¿ç”¨ç¤ºä¾‹
logger = setup_logger('trading_system', 'trading.log')

logger.info("ç³»ç»Ÿå¯åŠ¨")
logger.warning("ICå€¼ä¸‹é™")
logger.error("æ•°æ®è·å–å¤±è´¥")
```

### æµ‹è¯•

```python
import unittest
import pandas as pd
import numpy as np

class TestModelTrainer(unittest.TestCase):
    """æ¨¡å‹è®­ç»ƒå™¨æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.trainer = ModelTrainer(params={})
        self.X = pd.DataFrame({
            'factor1': np.random.randn(100),
            'factor2': np.random.randn(100)
        })
        self.y = np.random.randn(100)
    
    def test_train(self):
        """æµ‹è¯•è®­ç»ƒåŠŸèƒ½"""
        # è®­ç»ƒ
        self.trainer.train(self.X, self.y)
        
        # æ–­è¨€æ¨¡å‹å·²è®­ç»ƒ
        self.assertIsNotNone(self.trainer.model)
    
    def test_predict(self):
        """æµ‹è¯•é¢„æµ‹åŠŸèƒ½"""
        # è®­ç»ƒ
        self.trainer.train(self.X, self.y)
        
        # é¢„æµ‹
        predictions = self.trainer.predict(self.X)
        
        # æ–­è¨€é¢„æµ‹ç»“æœ
        self.assertEqual(len(predictions), len(self.X))
    
    def test_input_validation(self):
        """æµ‹è¯•è¾“å…¥éªŒè¯"""
        # æµ‹è¯•é•¿åº¦ä¸ä¸€è‡´
        with self.assertRaises(ValueError):
            self.trainer.train(
                self.X.iloc[:50],
                self.y
            )

# è¿è¡Œæµ‹è¯•
if __name__ == '__main__':
    unittest.main()
```

---

## ğŸ’° æˆæœ¬æ§åˆ¶

### äº¤æ˜“é¢‘ç‡æ§åˆ¶

```python
class TradingFrequencyController:
    """äº¤æ˜“é¢‘ç‡æ§åˆ¶å™¨"""
    
    def __init__(self, 
                 min_trade_interval=5,
                 max_daily_trades=100):
        """
        åˆå§‹åŒ–äº¤æ˜“é¢‘ç‡æ§åˆ¶å™¨
        
        Args:
            min_trade_interval: æœ€å°äº¤æ˜“é—´éš”ï¼ˆå¤©ï¼‰
            max_daily_trades: æ¯æ—¥æœ€å¤§äº¤æ˜“æ¬¡æ•°
        """
        self.min_trade_interval = min_trade_interval
        self.max_daily_trades = max_daily_trades
        self.last_trade_date = {}
        self.daily_trade_count = {}
    
    def can_trade(self, symbol: str, date: pd.Timestamp) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å¯ä»¥äº¤æ˜“
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            date: äº¤æ˜“æ—¥æœŸ
            
        Returns:
            æ˜¯å¦å¯ä»¥äº¤æ˜“
        """
        # æ£€æŸ¥äº¤æ˜“é—´éš”
        if symbol in self.last_trade_date:
            days_since_last = (date - self.last_trade_date[symbol]).days
            if days_since_last < self.min_trade_interval:
                return False
        
        # æ£€æŸ¥æ¯æ—¥äº¤æ˜“æ¬¡æ•°
        date_str = date.strftime('%Y-%m-%d')
        if date_str in self.daily_trade_count:
            if self.daily_trade_count[date_str] >= self.max_daily_trades:
                return False
        
        return True
    
    def record_trade(self, symbol: str, date: pd.Timestamp):
        """
        è®°å½•äº¤æ˜“
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            date: äº¤æ˜“æ—¥æœŸ
        """
        self.last_trade_date[symbol] = date
        
        date_str = date.strftime('%Y-%m-%d')
        self.daily_trade_count[date_str] = self.daily_trade_count.get(date_str, 0) + 1
```

### æ»‘ç‚¹æˆæœ¬æ§åˆ¶

```python
def calculate_slippage(order_size: float, 
                       volume: float,
                       price: float,
                       slippage_rate: float = 0.0001) -> float:
    """
    è®¡ç®—æ»‘ç‚¹æˆæœ¬
    
    Args:
        order_size: è®¢å•å¤§å°
        volume: æˆäº¤é‡
        price: ä»·æ ¼
        slippage_rate: æ»‘ç‚¹ç‡
        
    Returns:
        æ»‘ç‚¹æˆæœ¬
    """
    # è®¢å•å æ¯”
    impact = order_size / volume
    
    # æ»‘ç‚¹æˆæœ¬
    slippage = price * slippage_rate * (1 + impact)
    
    return slippage

def limit_order_size(portfolio_value: float,
                    price: float,
                    volume: float,
                    max_impact: float = 0.01) -> float:
    """
    é™åˆ¶è®¢å•å¤§å°ï¼ˆæ§åˆ¶å†²å‡»æˆæœ¬ï¼‰
    
    Args:
        portfolio_value: ç»„åˆä»·å€¼
        price: ä»·æ ¼
        volume: æˆäº¤é‡
        max_impact: æœ€å¤§å†²å‡»
        
    Returns:
        æœ€å¤§è®¢å•å¤§å°ï¼ˆé‡‘é¢ï¼‰
    """
    # æœ€å¤§è®¢å•å¤§å°ï¼ˆæŒ‰å†²å‡»é™åˆ¶ï¼‰
    max_size_by_impact = volume * max_impact
    
    # æœ€å¤§è®¢å•å¤§å°ï¼ˆé‡‘é¢ï¼‰
    max_order_value = max_size_by_impact * price
    
    # é™åˆ¶ä¸ºç»„åˆä»·å€¼çš„ä¸€å®šæ¯”ä¾‹
    max_order_value = min(max_order_value, portfolio_value * 0.05)
    
    return max_order_value
```

---

## ğŸ“ æœ¬èŠ‚å°ç»“

**æ ¸å¿ƒè¦ç‚¹**ï¼š

1. âœ… éµå¾ªå¼€å‘è§„èŒƒï¼Œæé«˜ä»£ç è´¨é‡
2. âœ… ä¸¥æ ¼æ§åˆ¶é£é™©ï¼Œé¿å…çˆ†ä»“
3. âœ… ä¼˜åŒ–æ€§èƒ½ï¼Œæé«˜æ•ˆç‡
4. âœ… ä¿éšœç¨³å®šæ€§ï¼Œç¡®ä¿é•¿æœŸè¿è¡Œ
5. âœ… æ§åˆ¶æˆæœ¬ï¼Œæé«˜å‡€æ”¶ç›Š

**æœ€ä½³å®è·µäº”è¦ç´ **ï¼š

```python
best_practices = {
    "è¦ç´ 1": "å¼€å‘è§„èŒƒ",  # å‘½åã€é£æ ¼ã€æ–‡æ¡£
    "è¦ç´ 2": "é£é™©æ§åˆ¶",  # ç›‘æ§ã€ä»“ä½ã€æ­¢æŸ
    "è¦ç´ 3": "æ€§èƒ½ä¼˜åŒ–",  # å¹¶è¡Œã€ç¼“å­˜ã€ç®—æ³•
    "è¦ç´ 4": "ç¨³å®šæ€§",   # ç‰ˆæœ¬æ§åˆ¶ã€æ—¥å¿—ã€æµ‹è¯•
    "è¦ç´ 5": "æˆæœ¬æ§åˆ¶"   # äº¤æ˜“é¢‘ç‡ã€æ»‘ç‚¹
}
```

**ä¸‹ä¸€æ­¥**ï¼šå­¦ä¹ äº†æœ€ä½³å®è·µï¼Œæœ‰å“ªäº›**å¸¸è§é—®é¢˜**å‘¢ï¼Ÿ

[â†’ å‰å¾€ 09-å¸¸è§é—®é¢˜](09-å¸¸è§é—®é¢˜.md)

---

**ğŸ’ æœ€ä½³å®è·µæ˜¯ç»éªŒçš„ç»“æ™¶ï¼Œä¸‹èŠ‚è¯¾å­¦ä¹ å¸¸è§é—®é¢˜ï¼Œå°‘èµ°å¼¯è·¯ï¼**
